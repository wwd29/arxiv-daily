<link rel="stylesheet" href="../../css/markdown.css" />
<article class="markdown-body">
<h1>2025-02-27</h1>
<h3>Title: ELBA-Bench: An Efficient Learning Backdoor Attacks Benchmark for Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Xuxu Liu, Siyuan Liang, Mengya Han, Yong Luo, Aishan Liu, Xiantao Cai, Zheng He, Dacheng Tao</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.18511">https://arxiv.org/abs/2502.18511</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.18511">https://arxiv.org/pdf/2502.18511</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.18511]] ELBA-Bench: An Efficient Learning Backdoor Attacks Benchmark for Large Language Models(https://arxiv.org/abs/2502.18511)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative, in-context</a></li>
<li><strong>Abstract: </strong>Generative large language models are crucial in natural language processing, but they are vulnerable to backdoor attacks, where subtle triggers compromise their behavior. Although backdoor attacks against LLMs are constantly emerging, existing benchmarks remain limited in terms of sufficient coverage of attack, metric system integrity, backdoor attack alignment. And existing pre-trained backdoor attacks are idealized in practice due to resource access constraints. Therefore we establish $\textit{ELBA-Bench}$, a comprehensive and unified framework that allows attackers to inject backdoor through parameter efficient fine-tuning ($\textit{e.g.,}$ LoRA) or without fine-tuning techniques ($\textit{e.g.,}$ In-context-learning). $\textit{ELBA-Bench}$ provides over 1300 experiments encompassing the implementations of 12 attack methods, 18 datasets, and 12 LLMs. Extensive experiments provide new invaluable findings into the strengths and limitations of various attack strategies. For instance, PEFT attack consistently outperform without fine-tuning approaches in classification tasks while showing strong cross-dataset generalization with optimized triggers boosting robustness; Task-relevant backdoor optimization techniques or attack prompts along with clean and adversarial demonstrations can enhance backdoor attack success while preserving model performance on clean samples. Additionally, we introduce a universal toolbox designed for standardized backdoor attack research, with the goal of propelling further progress in this vital area.</li>
</ul>

<h3>Title: Revisiting Convolution Architecture in the Realm of DNA Foundation Models</h3>
<ul>
<li><strong>Authors: </strong>Yu Bo, Weian Mao, Yanjun Shao, Weiqiang Bai, Peng Ye, Xinzhu Ma, Junbo Zhao, Hao Chen, Chunhua Shen</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.18538">https://arxiv.org/abs/2502.18538</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.18538">https://arxiv.org/pdf/2502.18538</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.18538]] Revisiting Convolution Architecture in the Realm of DNA Foundation Models(https://arxiv.org/abs/2502.18538)</code><input type="text"></li>
<li><strong>Keywords: </strong>foundation model</a></li>
<li><strong>Abstract: </strong>In recent years, a variety of methods based on Transformer and state space model (SSM) architectures have been proposed, advancing foundational DNA language models. However, there is a lack of comparison between these recent approaches and the classical architecture convolutional networks (CNNs) on foundation model benchmarks. This raises the question: are CNNs truly being surpassed by these recent approaches based on transformer and SSM architectures? In this paper, we develop a simple but well-designed CNN-based method termed ConvNova. ConvNova identifies and proposes three effective designs: 1) dilated convolutions, 2) gated convolutions, and 3) a dual-branch framework for gating mechanisms. Through extensive empirical experiments, we demonstrate that ConvNova significantly outperforms recent methods on more than half of the tasks across several foundation model benchmarks. For example, in histone-related tasks, ConvNova exceeds the second-best method by an average of 5.8%, while generally utilizing fewer parameters and enabling faster computation. In addition, the experiments observed findings that may be related to biological characteristics. This indicates that CNNs are still a strong competitor compared to Transformers and SSMs. We anticipate that this work will spark renewed interest in CNN-based methods for DNA foundation models.</li>
</ul>

<h3>Title: FactReasoner: A Probabilistic Approach to Long-Form Factuality Assessment for Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Radu Marinescu, Debarun Bhattacharjya, Junkyu Lee, Tigran Tchrakian, Javier Carnerero Cano, Yufang Hou, Elizabeth Daly, Alessandra Pascale</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.18573">https://arxiv.org/abs/2502.18573</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.18573">https://arxiv.org/pdf/2502.18573</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.18573]] FactReasoner: A Probabilistic Approach to Long-Form Factuality Assessment for Large Language Models(https://arxiv.org/abs/2502.18573)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>Large language models (LLMs) have demonstrated vast capabilities on generative tasks in recent years, yet they struggle with guaranteeing the factual correctness of the generated content. This makes these models unreliable in realistic situations where factually accurate responses are expected. In this paper, we propose FactReasoner, a new factuality assessor that relies on probabilistic reasoning to assess the factuality of a long-form generated response. Specifically, FactReasoner decomposes the response into atomic units, retrieves relevant contexts for them from an external knowledge source, and constructs a joint probability distribution over the atoms and contexts using probabilistic encodings of the logical relationships (entailment, contradiction) between the textual utterances corresponding to the atoms and contexts. FactReasoner then computes the posterior probability of whether atomic units in the response are supported by the retrieved contexts. Our experiments on labeled and unlabeled benchmark datasets demonstrate clearly that FactReasoner improves considerably over state-of-the-art prompt-based approaches in terms of both factual precision and recall.</li>
</ul>

<h3>Title: What are Foundation Models Cooking in the Post-Soviet World?</h3>
<ul>
<li><strong>Authors: </strong>Anton Lavrouk, Tarek Naous, Alan Ritter, Wei Xu</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.18583">https://arxiv.org/abs/2502.18583</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.18583">https://arxiv.org/pdf/2502.18583</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.18583]] What are Foundation Models Cooking in the Post-Soviet World?(https://arxiv.org/abs/2502.18583)</code><input type="text"></li>
<li><strong>Keywords: </strong>foundation model</a></li>
<li><strong>Abstract: </strong>The culture of the Post-Soviet states is complex, shaped by a turbulent history that continues to influence current events. In this study, we investigate the Post-Soviet cultural food knowledge of foundation models by constructing BORSch, a multimodal dataset encompassing 1147 and 823 dishes in the Russian and Ukrainian languages, centered around the Post-Soviet region. We demonstrate that leading models struggle to correctly identify the origins of dishes from Post-Soviet nations in both text-only and multimodal Question Answering (QA), instead over-predicting countries linked to the language the question is asked in. Through analysis of pretraining data, we show that these results can be explained by misleading dish-origin co-occurrences, along with linguistic phenomena such as Russian-Ukrainian code mixing. Finally, to move beyond QA-based assessments, we test models' abilities to produce accurate visual descriptions of dishes. The weak correlation between this task and QA suggests that QA alone may be insufficient as an evaluation of cultural understanding. To foster further research, we will make BORSch publicly available at this https URL.</li>
</ul>

<h3>Title: Tighten The Lasso: A Convex Hull Volume-based Anomaly Detection Method</h3>
<ul>
<li><strong>Authors: </strong>Uri Itai, Asael Bar Ilan, Teddy Lazebnik</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.18601">https://arxiv.org/abs/2502.18601</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.18601">https://arxiv.org/pdf/2502.18601</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.18601]] Tighten The Lasso: A Convex Hull Volume-based Anomaly Detection Method(https://arxiv.org/abs/2502.18601)</code><input type="text"></li>
<li><strong>Keywords: </strong>anomaly</a></li>
<li><strong>Abstract: </strong>The rapid advancements in data-driven methodologies have underscored the critical importance of ensuring data quality. Consequently, detecting out-of-distribution (OOD) data has emerged as an essential task to maintain the reliability and robustness of data-driven models, in general, and machine and deep learning models, in particular. In this study, we leveraged the convex hull property of a dataset and the fact that anomalies highly contribute to the increase of the CH's volume to propose a novel anomaly detection algorithm. Our algorithm computes the CH's volume as an increasing number of data points are removed from the dataset to define a decision line between OOD and in-distribution data points. We compared the proposed algorithm to seven widely used anomaly detection algorithms over ten datasets, showing comparable results for state-of-the-art (SOTA) algorithms. Moreover, we show that with a computationally cheap and simple check, one can detect datasets that are well-suited for the proposed algorithm which outperforms the SOTA anomaly detection algorithms.</li>
</ul>

<h3>Title: Diffusion Models for conditional MRI generation</h3>
<ul>
<li><strong>Authors: </strong>Miguel Herencia García del Castillo, Ricardo Moya Garcia, Manuel Jesús Cerezo Mazón, Ekaitz Arriola Garcia, Pablo Menéndez Fernández-Miranda</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.18620">https://arxiv.org/abs/2502.18620</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.18620">https://arxiv.org/pdf/2502.18620</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.18620]] Diffusion Models for conditional MRI generation(https://arxiv.org/abs/2502.18620)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>In this article, we present a Latent Diffusion Model (LDM) for the generation of brain Magnetic Resonance Imaging (MRI), conditioning its generation based on pathology (Healthy, Glioblastoma, Sclerosis, Dementia) and acquisition modality (T1w, T1ce, T2w, Flair, PD). To evaluate the quality of the generated images, the Fréchet Inception Distance (FID) and Multi-Scale Structural Similarity Index (MS-SSIM) metrics were employed. The results indicate that the model generates images with a distribution similar to real ones, maintaining a balance between visual fidelity and diversity. Additionally, the model demonstrates extrapolation capability, enabling the generation of configurations that were not present in the training data. The results validate the potential of the model to increase in the number of samples in clinical datasets, balancing underrepresented classes, and evaluating AI models in medicine, contributing to the development of diagnostic tools in radiology without compromising patient privacy.</li>
</ul>

<h3>Title: CayleyPy RL: Pathfinding and Reinforcement Learning on Cayley Graphs</h3>
<ul>
<li><strong>Authors: </strong>A.Chervov, A.Soibelman, S.Lytkin, I.Kiselev, S.Fironov, A.Lukyanenko, A.Dolgorukova, A.Ogurtsov, F.Petrov, S.Krymskii, M.Evseev, L.Grunvald, D.Gorodkov, G.Antiufeev, G.Verbii, V.Zamkovoy, L.Cheldieva, I.Koltsov, A. Sychev, M.Obozov, A.Eliseev, S.Nikolenko, N.Narynbaev, R.Turtayev, N. Rokotyan, S.Kovalev, A.Rozanov, V.Nelin, S.Ermilov, L.Shishina, D.Mamayeva, A.Korolkova, K.Khoruzhii, A.Romanov</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.DM, math.CO, math.GR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.18663">https://arxiv.org/abs/2502.18663</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.18663">https://arxiv.org/pdf/2502.18663</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.18663]] CayleyPy RL: Pathfinding and Reinforcement Learning on Cayley Graphs(https://arxiv.org/abs/2502.18663)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>This paper is the second in a series of studies on developing efficient artificial intelligence-based approaches to pathfinding on extremely large graphs (e.g. $10^{70}$ nodes) with a focus on Cayley graphs and mathematical applications. The open-source CayleyPy project is a central component of our research. The present paper proposes a novel combination of a reinforcement learning approach with a more direct diffusion distance approach from the first paper. Our analysis includes benchmarking various choices for the key building blocks of the approach: architectures of the neural network, generators for the random walks and beam search pathfinding. We compared these methods against the classical computer algebra system GAP, demonstrating that they "overcome the GAP" for the considered examples. As a particular mathematical application we examine the Cayley graph of the symmetric group with cyclic shift and transposition generators. We provide strong support for the OEIS-A186783 conjecture that the diameter is equal to n(n-1)/2 by machine learning and mathematical methods. We identify the conjectured longest element and generate its decomposition of the desired length. We prove a diameter lower bound of n(n-1)/2-n/2 and an upper bound of n(n-1)/2+ 3n by presenting the algorithm with given complexity. We also present several conjectures motivated by numerical experiments, including observations on the central limit phenomenon (with growth approximated by a Gumbel distribution), the uniform distribution for the spectrum of the graph, and a numerical study of sorting networks. To stimulate crowdsourcing activity, we create challenges on the Kaggle platform and invite contributions to improve and benchmark approaches on Cayley graph pathfinding and other tasks.</li>
</ul>

<h3>Title: Discriminative Finetuning of Generative Large Language Models without Reward Models and Preference Data</h3>
<ul>
<li><strong>Authors: </strong>Siqi Guo, Ilgee Hong, Vicente Balmaseda, Tuo Zhao, Tianbao Yang</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.18679">https://arxiv.org/abs/2502.18679</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.18679">https://arxiv.org/pdf/2502.18679</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.18679]] Discriminative Finetuning of Generative Large Language Models without Reward Models and Preference Data(https://arxiv.org/abs/2502.18679)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>Supervised fine-tuning (SFT) followed by preference optimization (PO) denoted by SFT$\rightarrow$PO has become the standard for improving pretrained large language models (LLMs), with PO demonstrating significant performance gains. However, PO methods rely on either human-labeled preference data or a strong reward model to generate preference data. Can we fine-tune LLMs without preference data or reward models while achieving competitive performance to SFT$\rightarrow$PO? We address this question by introducing Discriminative Fine-Tuning (DFT), a novel approach that eliminates the need for preference data. Unlike SFT, which employs a generative approach and overlooks negative data, DFT adopts a discriminative paradigm that that increases the probability of positive answers while suppressing potentially negative ones, shifting from token prediction to data prediction. Our contributions include: (i) a discriminative probabilistic framework for fine-tuning LLMs by explicitly modeling the discriminative likelihood of an answer among all possible outputs given an input; (ii) efficient algorithms to optimize this discriminative likelihood; and (iii) extensive experiments demonstrating DFT's effectiveness, achieving performance better than SFT and comparable to if not better than SFT$\rightarrow$PO. The code can be found at this https URL.</li>
</ul>

<h3>Title: Spectral-Enhanced Transformers: Leveraging Large-Scale Pretrained Models for Hyperspectral Object Tracking</h3>
<ul>
<li><strong>Authors: </strong>Shaheer Mohamed, Tharindu Fernando, Sridha Sridharan, Peyman Moghadam, Clinton Fookes</a></li>
<li><strong>Subjects: </strong>cs.CV, eess.IV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.18748">https://arxiv.org/abs/2502.18748</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.18748">https://arxiv.org/pdf/2502.18748</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.18748]] Spectral-Enhanced Transformers: Leveraging Large-Scale Pretrained Models for Hyperspectral Object Tracking(https://arxiv.org/abs/2502.18748)</code><input type="text"></li>
<li><strong>Keywords: </strong>foundation model</a></li>
<li><strong>Abstract: </strong>Hyperspectral object tracking using snapshot mosaic cameras is emerging as it provides enhanced spectral information alongside spatial data, contributing to a more comprehensive understanding of material properties. Using transformers, which have consistently outperformed convolutional neural networks (CNNs) in learning better feature representations, would be expected to be effective for Hyperspectral object tracking. However, training large transformers necessitates extensive datasets and prolonged training periods. This is particularly critical for complex tasks like object tracking, and the scarcity of large datasets in the hyperspectral domain acts as a bottleneck in achieving the full potential of powerful transformer models. This paper proposes an effective methodology that adapts large pretrained transformer-based foundation models for hyperspectral object tracking. We propose an adaptive, learnable spatial-spectral token fusion module that can be extended to any transformer-based backbone for learning inherent spatial-spectral features in hyperspectral data. Furthermore, our model incorporates a cross-modality training pipeline that facilitates effective learning across hyperspectral datasets collected with different sensor modalities. This enables the extraction of complementary knowledge from additional modalities, whether or not they are present during testing. Our proposed model also achieves superior performance with minimal training iterations.</li>
</ul>

<h3>Title: Seeing the Forest for the Trees: A Large Scale, Continuously Updating Meta-Analysis of Frontier LLMs</h3>
<ul>
<li><strong>Authors: </strong>Jungsoo Park, Junmo Kang, Gabriel Stanovsky, Alan Ritter</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.18791">https://arxiv.org/abs/2502.18791</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.18791">https://arxiv.org/pdf/2502.18791</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.18791]] Seeing the Forest for the Trees: A Large Scale, Continuously Updating Meta-Analysis of Frontier LLMs(https://arxiv.org/abs/2502.18791)</code><input type="text"></li>
<li><strong>Keywords: </strong>in-context</a></li>
<li><strong>Abstract: </strong>The surge of LLM studies makes synthesizing their findings challenging. Meta-analysis can uncover important trends across studies, but its use is limited by the time-consuming nature of manual data extraction. Our study presents a semi-automated approach for meta-analysis that accelerates data extraction using LLMs. It automatically identifies relevant arXiv papers, extracts experimental results and related attributes, and organizes them into a structured dataset. We conduct a comprehensive meta-analysis of frontier LLMs using an automatically extracted dataset, reducing the effort of paper surveying and data extraction by more than 93\% compared to manual approaches. We validate our dataset by showing that it reproduces key findings from a recent manual meta-analysis about Chain-of-Thought (CoT), and also uncovers new insights that go beyond it, showing for example that in-context examples benefit multimodal tasks but offer limited gains in mathematical tasks compared to CoT. Our automatically updatable dataset enables continuous tracking of target models by extracting evaluation studies as new data becomes available. Through our scientific artifacts and empirical analysis, we provide novel insights into LLMs while facilitating ongoing meta-analyses of their behavior.</li>
</ul>

<h3>Title: Optimal Stochastic Trace Estimation in Generative Modeling</h3>
<ul>
<li><strong>Authors: </strong>Xinyang Liu, Hengrong Du, Wei Deng, Ruqi Zhang</a></li>
<li><strong>Subjects: </strong>cs.LG, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.18808">https://arxiv.org/abs/2502.18808</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.18808">https://arxiv.org/pdf/2502.18808</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.18808]] Optimal Stochastic Trace Estimation in Generative Modeling(https://arxiv.org/abs/2502.18808)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, generative</a></li>
<li><strong>Abstract: </strong>Hutchinson estimators are widely employed in training divergence-based likelihoods for diffusion models to ensure optimal transport (OT) properties. However, this estimator often suffers from high variance and scalability concerns. To address these challenges, we investigate Hutch++, an optimal stochastic trace estimator for generative models, designed to minimize training variance while maintaining transport optimality. Hutch++ is particularly effective for handling ill-conditioned matrices with large condition numbers, which commonly arise when high-dimensional data exhibits a low-dimensional structure. To mitigate the need for frequent and costly QR decompositions, we propose practical schemes that balance frequency and accuracy, backed by theoretical guarantees. Our analysis demonstrates that Hutch++ leads to generations of higher quality. Furthermore, this method exhibits effective variance reduction in various applications, including simulations, conditional time series forecasts, and image generation.</li>
</ul>

<h3>Title: TabGLM: Tabular Graph Language Model for Learning Transferable Representations Through Multi-Modal Consistency Minimization</h3>
<ul>
<li><strong>Authors: </strong>Anay Majee, Maria Xenochristou, Wei-Peng Chen</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.18847">https://arxiv.org/abs/2502.18847</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.18847">https://arxiv.org/pdf/2502.18847</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.18847]] TabGLM: Tabular Graph Language Model for Learning Transferable Representations Through Multi-Modal Consistency Minimization(https://arxiv.org/abs/2502.18847)</code><input type="text"></li>
<li><strong>Keywords: </strong>self-supervised</a></li>
<li><strong>Abstract: </strong>Handling heterogeneous data in tabular datasets poses a significant challenge for deep learning models. While attention-based architectures and self-supervised learning have achieved notable success, their application to tabular data remains less effective over linear and tree based models. Although several breakthroughs have been achieved by models which transform tables into uni-modal transformations like image, language and graph, these models often underperform in the presence of feature heterogeneity. To address this gap, we introduce TabGLM (Tabular Graph Language Model), a novel multi-modal architecture designed to model both structural and semantic information from a table. TabGLM transforms each row of a table into a fully connected graph and serialized text, which are then encoded using a graph neural network (GNN) and a text encoder, respectively. By aligning these representations through a joint, multi-modal, self-supervised learning objective, TabGLM leverages complementary information from both modalities, thereby enhancing feature learning. TabGLM's flexible graph-text pipeline efficiently processes heterogeneous datasets with significantly fewer parameters over existing Deep Learning approaches. Evaluations across 25 benchmark datasets demonstrate substantial performance gains, with TabGLM achieving an average AUC-ROC improvement of up to 5.56% over State-of-the-Art (SoTA) tabular learning methods.</li>
</ul>

<h3>Title: Exploring Rewriting Approaches for Different Conversational Tasks</h3>
<ul>
<li><strong>Authors: </strong>Md Mehrab Tanjim, Ryan A. Rossi, Mike Rimer, Xiang Chen, Sungchul Kim, Vaishnavi Muppala, Tong Yu, Zhengmian Hu, Ritwik Sinha, Wei Zhang, Iftikhar Ahamath Burhanuddin, Franck Dernoncourt</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.18860">https://arxiv.org/abs/2502.18860</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.18860">https://arxiv.org/pdf/2502.18860</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.18860]] Exploring Rewriting Approaches for Different Conversational Tasks(https://arxiv.org/abs/2502.18860)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>Conversational assistants often require a question rewriting algorithm that leverages a subset of past interactions to provide a more meaningful (accurate) answer to the user's question or request. However, the exact rewriting approach may often depend on the use case and application-specific tasks supported by the conversational assistant, among other constraints. In this paper, we systematically investigate two different approaches, denoted as rewriting and fusion, on two fundamentally different generation tasks, including a text-to-text generation task and a multimodal generative task that takes as input text and generates a visualization or data table that answers the user's question. Our results indicate that the specific rewriting or fusion approach highly depends on the underlying use case and generative task. In particular, we find that for a conversational question-answering assistant, the query rewriting approach performs best, whereas for a data analysis assistant that generates visualizations and data tables based on the user's conversation with the assistant, the fusion approach works best. Notably, we explore two datasets for the data analysis assistant use case, for short and long conversations, and we find that query fusion always performs better, whereas for the conversational text-based question-answering, the query rewrite approach performs best.</li>
</ul>

<h3>Title: Sherlock: Towards Multi-scene Video Abnormal Event Extraction and Localization via a Global-local Spatial-sensitive LLM</h3>
<ul>
<li><strong>Authors: </strong>Junxiao Ma, Jingjing Wang, Jiamin Luo, Peiying Yu, Guodong Zhou</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.18863">https://arxiv.org/abs/2502.18863</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.18863">https://arxiv.org/pdf/2502.18863</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.18863]] Sherlock: Towards Multi-scene Video Abnormal Event Extraction and Localization via a Global-local Spatial-sensitive LLM(https://arxiv.org/abs/2502.18863)</code><input type="text"></li>
<li><strong>Keywords: </strong>anomaly</a></li>
<li><strong>Abstract: </strong>Prior studies on Video Anomaly Detection (VAD) mainly focus on detecting whether each video frame is abnormal or not in the video, which largely ignore the structured video semantic information (i.e., what, when, and where does the abnormal event happen). With this in mind, we propose a new chat-paradigm \textbf{M}ulti-scene Video Abnormal Event Extraction and Localization (M-VAE) task, aiming to extract the abnormal event quadruples (i.e., subject, event type, object, scene) and localize such event. Further, this paper believes that this new task faces two key challenges, i.e., global-local spatial modeling and global-local spatial balancing. To this end, this paper proposes a Global-local Spatial-sensitive Large Language Model (LLM) named Sherlock, i.e., acting like Sherlock Holmes to track down the criminal events, for this M-VAE task. Specifically, this model designs a Global-local Spatial-enhanced MoE (GSM) module and a Spatial Imbalance Regulator (SIR) to address the two challenges respectively. Extensive experiments on our M-VAE instruction dataset show the significant advantages of Sherlock over several advanced Video-LLMs. This justifies the importance of global-local spatial information for the M-VAE task and the effectiveness of Sherlock in capturing such information.</li>
</ul>

<h3>Title: A Theoretical Perspective: How to Prevent Model Collapse in Self-consuming Training Loops</h3>
<ul>
<li><strong>Authors: </strong>Shi Fu, Yingjie Wang, Yuzhu Chen, Xinmei Tian, Dacheng Tao</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.18865">https://arxiv.org/abs/2502.18865</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.18865">https://arxiv.org/pdf/2502.18865</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.18865]] A Theoretical Perspective: How to Prevent Model Collapse in Self-consuming Training Loops(https://arxiv.org/abs/2502.18865)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative, in-context</a></li>
<li><strong>Abstract: </strong>High-quality data is essential for training large generative models, yet the vast reservoir of real data available online has become nearly depleted. Consequently, models increasingly generate their own data for further training, forming Self-consuming Training Loops (STLs). However, the empirical results have been strikingly inconsistent: some models degrade or even collapse, while others successfully avoid these failures, leaving a significant gap in theoretical understanding to explain this discrepancy. This paper introduces the intriguing notion of recursive stability and presents the first theoretical generalization analysis, revealing how both model architecture and the proportion between real and synthetic data influence the success of STLs. We further extend this analysis to transformers in in-context learning, showing that even a constant-sized proportion of real data ensures convergence, while also providing insights into optimal synthetic data sizing.</li>
</ul>

<h3>Title: Dynamic Classification: Leveraging Self-Supervised Classification to Enhance Prediction Performance</h3>
<ul>
<li><strong>Authors: </strong>Ziyuan Zhong, Junyang Zhou</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.18891">https://arxiv.org/abs/2502.18891</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.18891">https://arxiv.org/pdf/2502.18891</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.18891]] Dynamic Classification: Leveraging Self-Supervised Classification to Enhance Prediction Performance(https://arxiv.org/abs/2502.18891)</code><input type="text"></li>
<li><strong>Keywords: </strong>self-supervised</a></li>
<li><strong>Abstract: </strong>In this paper, we propose an innovative dynamic classification algorithm designed to achieve the objective of zero missed detections and minimal false positives. The algorithm partitions the data into N equivalent training subsets and N prediction subsets using a supervised model, followed by independent predictions from N separate predictive models. This enables each predictive model to operate within a smaller data range, thereby improving overall accuracy. Additionally, the algorithm leverages data generated through supervised learning to further refine prediction results, filtering out predictions that do not meet accuracy requirements without the need to introduce additional models. Experimental results demonstrate that, when data partitioning errors are minimal, the dynamic classification algorithm achieves exceptional performance with zero missed detections and minimal false positives, significantly outperforming existing model ensembles. Even in cases where classification errors are larger, the algorithm remains comparable to state of the art models. The key innovations of this study include self-supervised classification learning, the use of small-range subset predictions, and the direct rejection of substandard predictions. While the current algorithm still has room for improvement in terms of automatic parameter tuning and classification model efficiency, it has demonstrated outstanding performance across multiple datasets. Future research will focus on optimizing the classification component to further enhance the algorithm's robustness and adaptability.</li>
</ul>

<h3>Title: END: Early Noise Dropping for Efficient and Effective Context Denoising</h3>
<ul>
<li><strong>Authors: </strong>Hongye Jin, Pei Chen, Jingfeng Yang, Zhengyang Wang, Meng Jiang, Yifan Gao, Binxuan Huang, Xinyang Zhang, Zheng Li, Tianyi Liu, Huasheng Li, Bing Yin</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.18915">https://arxiv.org/abs/2502.18915</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.18915">https://arxiv.org/pdf/2502.18915</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.18915]] END: Early Noise Dropping for Efficient and Effective Context Denoising(https://arxiv.org/abs/2502.18915)</code><input type="text"></li>
<li><strong>Keywords: </strong>in-context</a></li>
<li><strong>Abstract: </strong>Large Language Models (LLMs) have demonstrated remarkable performance across a wide range of natural language processing tasks. However, they are often distracted by irrelevant or noisy context in input sequences that degrades output quality. This problem affects both long- and short-context scenarios, such as retrieval-augmented generation, table question-answering, and in-context learning. We reveal that LLMs can implicitly identify whether input sequences contain useful information at early layers, prior to token generation. Leveraging this insight, we introduce Early Noise Dropping (\textsc{END}), a novel approach to mitigate this issue without requiring fine-tuning the LLMs. \textsc{END} segments input sequences into chunks and employs a linear prober on the early layers of LLMs to differentiate between informative and noisy chunks. By discarding noisy chunks early in the process, \textsc{END} preserves critical information, reduces distraction, and lowers computational overhead. Extensive experiments demonstrate that \textsc{END} significantly improves both performance and efficiency across different LLMs on multiple evaluation datasets. Furthermore, by investigating LLMs' implicit understanding to the input with the prober, this work also deepens understanding of how LLMs do reasoning with contexts internally.</li>
</ul>

<h3>Title: (Mis)Fitting: A Survey of Scaling Laws</h3>
<ul>
<li><strong>Authors: </strong>Margaret Li, Sneha Kudugunta, Luke Zettlemoyer</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CL, stat.ME</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.18969">https://arxiv.org/abs/2502.18969</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.18969">https://arxiv.org/pdf/2502.18969</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.18969]] (Mis)Fitting: A Survey of Scaling Laws(https://arxiv.org/abs/2502.18969)</code><input type="text"></li>
<li><strong>Keywords: </strong>foundation model</a></li>
<li><strong>Abstract: </strong>Modern foundation models rely heavily on using scaling laws to guide crucial training decisions. Researchers often extrapolate the optimal architecture and hyper parameters settings from smaller training runs by describing the relationship between, loss, or task performance, and scale. All components of this process vary, from the specific equation being fit, to the training setup, to the optimization method. Each of these factors may affect the fitted law, and therefore, the conclusions of a given study. We discuss discrepancies in the conclusions that several prior works reach, on questions such as the optimal token to parameter ratio. We augment this discussion with our own analysis of the critical impact that changes in specific details may effect in a scaling study, and the resulting altered conclusions. Additionally, we survey over 50 papers that study scaling trends: while 45 of these papers quantify these trends using a power law, most under-report crucial details needed to reproduce their findings. To mitigate this, we we propose a checklist for authors to consider while contributing to scaling law research.</li>
</ul>

<h3>Title: Distilling Reinforcement Learning Algorithms for In-Context Model-Based Planning</h3>
<ul>
<li><strong>Authors: </strong>Jaehyeon Son, Soochan Lee, Gunhee Kim</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.19009">https://arxiv.org/abs/2502.19009</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.19009">https://arxiv.org/pdf/2502.19009</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.19009]] Distilling Reinforcement Learning Algorithms for In-Context Model-Based Planning(https://arxiv.org/abs/2502.19009)</code><input type="text"></li>
<li><strong>Keywords: </strong>in-context</a></li>
<li><strong>Abstract: </strong>Recent studies have shown that Transformers can perform in-context reinforcement learning (RL) by imitating existing RL algorithms, enabling sample-efficient adaptation to unseen tasks without parameter updates. However, these models also inherit the suboptimal behaviors of the RL algorithms they imitate. This issue primarily arises due to the gradual update rule employed by those algorithms. Model-based planning offers a promising solution to this limitation by allowing the models to simulate potential outcomes before taking action, providing an additional mechanism to deviate from the suboptimal behavior. Rather than learning a separate dynamics model, we propose Distillation for In-Context Planning (DICP), an in-context model-based RL framework where Transformers simultaneously learn environment dynamics and improve policy in-context. We evaluate DICP across a range of discrete and continuous environments, including Darkroom variants and Meta-World. Our results show that DICP achieves state-of-the-art performance while requiring significantly fewer environment interactions than baselines, which include both model-free counterparts and existing meta-RL methods.</li>
</ul>

<h3>Title: A Dual-Purpose Framework for Backdoor Defense and Backdoor Amplification in Diffusion Models</h3>
<ul>
<li><strong>Authors: </strong>Vu Tuan Truong Long, Bao Le</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.19047">https://arxiv.org/abs/2502.19047</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.19047">https://arxiv.org/pdf/2502.19047</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.19047]] A Dual-Purpose Framework for Backdoor Defense and Backdoor Amplification in Diffusion Models(https://arxiv.org/abs/2502.19047)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, generative</a></li>
<li><strong>Abstract: </strong>Diffusion models have emerged as state-of-the-art generative frameworks, excelling in producing high-quality multi-modal samples. However, recent studies have revealed their vulnerability to backdoor attacks, where backdoored models generate specific, undesirable outputs called backdoor target (e.g., harmful images) when a pre-defined trigger is embedded to their inputs. In this paper, we propose PureDiffusion, a dual-purpose framework that simultaneously serves two contrasting roles: backdoor defense and backdoor attack amplification. For defense, we introduce two novel loss functions to invert backdoor triggers embedded in diffusion models. The first leverages trigger-induced distribution shifts across multiple timesteps of the diffusion process, while the second exploits the denoising consistency effect when a backdoor is activated. Once an accurate trigger inversion is achieved, we develop a backdoor detection method that analyzes both the inverted trigger and the generated backdoor targets to identify backdoor attacks. In terms of attack amplification with the role of an attacker, we describe how our trigger inversion algorithm can be used to reinforce the original trigger embedded in the backdoored diffusion model. This significantly boosts attack performance while reducing the required backdoor training time. Experimental results demonstrate that PureDiffusion achieves near-perfect detection accuracy, outperforming existing defenses by a large margin, particularly against complex trigger patterns. Additionally, in an attack scenario, our attack amplification approach elevates the attack success rate (ASR) of existing backdoor attacks to nearly 100\% while reducing training time by up to 20x.</li>
</ul>

<h3>Title: Foundation Inference Models for Stochastic Differential Equations: A Transformer-based Approach for Zero-shot Function Estimation</h3>
<ul>
<li><strong>Authors: </strong>Patrick Seifner, Kostadin Cvejoski, David Berghaus, Cesar Ojeda, Ramses J. Sanchez</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.19049">https://arxiv.org/abs/2502.19049</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.19049">https://arxiv.org/pdf/2502.19049</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.19049]] Foundation Inference Models for Stochastic Differential Equations: A Transformer-based Approach for Zero-shot Function Estimation(https://arxiv.org/abs/2502.19049)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>Stochastic differential equations (SDEs) describe dynamical systems where deterministic flows, governed by a drift function, are superimposed with random fluctuations dictated by a diffusion function. The accurate estimation (or discovery) of these functions from data is a central problem in machine learning, with wide application across natural and social sciences alike. Yet current solutions are brittle, and typically rely on symbolic regression or Bayesian non-parametrics. In this work, we introduce FIM-SDE (Foundation Inference Model for SDEs), a transformer-based recognition model capable of performing accurate zero-shot estimation of the drift and diffusion functions of SDEs, from noisy and sparse observations on empirical processes of different dimensionalities. Leveraging concepts from amortized inference and neural operators, we train FIM-SDE in a supervised fashion, to map a large set of noisy and discretely observed SDE paths to their corresponding drift and diffusion functions. We demonstrate that one and the same (pretrained) FIM-SDE achieves robust zero-shot function estimation (i.e. without any parameter fine-tuning) across a wide range of synthetic and real-world processes, from canonical SDE systems (e.g. double-well dynamics or weakly perturbed Hopf bifurcations) to human motion recordings and oil price and wind speed fluctuations.</li>
</ul>

<h3>Title: A Sample-Level Evaluation and Generative Framework for Model Inversion Attacks</h3>
<ul>
<li><strong>Authors: </strong>Haoyang Li, Li Bai, Qingqing Ye, Haibo Hu, Yaxin Xiao, Huadi Zheng, Jianliang Xu</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.19070">https://arxiv.org/abs/2502.19070</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.19070">https://arxiv.org/pdf/2502.19070</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.19070]] A Sample-Level Evaluation and Generative Framework for Model Inversion Attacks(https://arxiv.org/abs/2502.19070)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>Model Inversion (MI) attacks, which reconstruct the training dataset of neural networks, pose significant privacy concerns in machine learning. Recent MI attacks have managed to reconstruct realistic label-level private data, such as the general appearance of a target person from all training images labeled on him. Beyond label-level privacy, in this paper we show sample-level privacy, the private information of a single target sample, is also important but under-explored in the MI literature due to the limitations of existing evaluation metrics. To address this gap, this study introduces a novel metric tailored for training-sample analysis, namely, the Diversity and Distance Composite Score (DDCS), which evaluates the reconstruction fidelity of each training sample by encompassing various MI attack attributes. This, in turn, enhances the precision of sample-level privacy assessments. Leveraging DDCS as a new evaluative lens, we observe that many training samples remain resilient against even the most advanced MI attack. As such, we further propose a transfer learning framework that augments the generative capabilities of MI attackers through the integration of entropy loss and natural gradient descent. Extensive experiments verify the effectiveness of our framework on improving state-of-the-art MI attacks over various metrics including DDCS, coverage and FID. Finally, we demonstrate that DDCS can also be useful for MI defense, by identifying samples susceptible to MI attacks in an unsupervised manner.</li>
</ul>

<h3>Title: EndoMamba: An Efficient Foundation Model for Endoscopic Videos</h3>
<ul>
<li><strong>Authors: </strong>Qingyao Tian, Huai Liao, Xinyan Huang, Bingyu Yang, Dongdong Lei, Sebastien Ourselin, Hongbin Liu</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.19090">https://arxiv.org/abs/2502.19090</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.19090">https://arxiv.org/pdf/2502.19090</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.19090]] EndoMamba: An Efficient Foundation Model for Endoscopic Videos(https://arxiv.org/abs/2502.19090)</code><input type="text"></li>
<li><strong>Keywords: </strong>self-supervised, foundation model</a></li>
<li><strong>Abstract: </strong>Endoscopic video-based tasks, such as visual navigation and surgical phase recognition, play a crucial role in minimally invasive surgeries by providing real-time assistance. While recent video foundation models have shown promise, their applications are hindered by (1) computational inefficiencies and (2) suboptimal performance caused by limited data for pre-training in endoscopy. To address these issues, we present EndoMamba, a foundation model designed for real-time inference while learning generalized spatiotemporal representations. First, to mitigate computational inefficiencies, we propose the EndoMamba backbone, optimized for real-time inference. Inspired by recent advancements in state space models, EndoMamba integrates Bidirectional Mamba blocks for spatial modeling within individual frames and vanilla Mamba blocks for past-to-present reasoning across the temporal domain. This design enables both strong spatiotemporal modeling and efficient inference in online video streams. Second, we propose a self-supervised hierarchical pre-training diagram to enhance EndoMamba's representation learning using endoscopic videos and incorporating general video domain knowledge. Specifically, our approach combines masked reconstruction with auxiliary supervision, leveraging low-level reconstruction to capture spatial-temporal structures and high-level alignment to transfer broader knowledge from a pretrained general-video domain foundation model. Extensive experiments on four downstream tasks--classification, segmentation, surgical phase recognition, and localization--demonstrate that EndoMamba outperforms existing foundation models and task-specific methods while maintaining real-time inference speed. The source code will be released upon acceptance.</li>
</ul>

<h3>Title: A Survey on Foundation-Model-Based Industrial Defect Detection</h3>
<ul>
<li><strong>Authors: </strong>Tianle Yang, Luyao Chang, Jiadong Yan, Juntao Li, Zhi Wang, Ke Zhang</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.19106">https://arxiv.org/abs/2502.19106</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.19106">https://arxiv.org/pdf/2502.19106</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.19106]] A Survey on Foundation-Model-Based Industrial Defect Detection(https://arxiv.org/abs/2502.19106)</code><input type="text"></li>
<li><strong>Keywords: </strong>foundation model</a></li>
<li><strong>Abstract: </strong>As industrial products become abundant and sophisticated, visual industrial defect detection receives much attention, including two-dimensional and three-dimensional visual feature modeling. Traditional methods use statistical analysis, abnormal data synthesis modeling, and generation-based models to separate product defect features and complete defect detection. Recently, the emergence of foundation models has brought visual and textual semantic prior knowledge. Many methods are based on foundation models (FM) to improve the accuracy of detection, but at the same time, increase model complexity and slow down inference speed. Some FM-based methods have begun to explore lightweight modeling ways, which have gradually attracted attention and deserve to be systematically analyzed. In this paper, we conduct a systematic survey with comparisons and discussions of foundation model methods from different aspects and briefly review non-foundation model (NFM) methods recently published. Furthermore, we discuss the differences between FM and NFM methods from training objectives, model structure and scale, model performance, and potential directions for future exploration. Through comparison, we find FM methods are more suitable for few-shot and zero-shot learning, which are more in line with actual industrial application scenarios and worthy of in-depth research.</li>
</ul>

<h3>Title: Towards Privacy-Preserving Anomaly-Based Intrusion Detection in Energy Communities</h3>
<ul>
<li><strong>Authors: </strong>Zeeshan Afzal, Giovanni Gaggero, Mikael Asplund</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.19154">https://arxiv.org/abs/2502.19154</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.19154">https://arxiv.org/pdf/2502.19154</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.19154]] Towards Privacy-Preserving Anomaly-Based Intrusion Detection in Energy Communities(https://arxiv.org/abs/2502.19154)</code><input type="text"></li>
<li><strong>Keywords: </strong>anomaly</a></li>
<li><strong>Abstract: </strong>Energy communities consist of decentralized energy production, storage, consumption, and distribution and are gaining traction in modern power systems. However, these communities may increase the vulnerability of the grid to cyber threats. We propose an anomaly-based intrusion detection system to enhance the security of energy communities. The system leverages deep autoencoders to detect deviations from normal operational patterns in order to identify anomalies induced by malicious activities and attacks. Operational data for training and evaluation are derived from a Simulink model of an energy community. The results show that the autoencoder-based intrusion detection system achieves good detection performance across multiple attack scenarios. We also demonstrate potential for real-world application of the system by training a federated model that enables distributed intrusion detection while preserving data privacy.</li>
</ul>

<h3>Title: Detecting Linguistic Indicators for Stereotype Assessment with Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Rebekka Görge, Michael Mock, Héctor Allende-Cid</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.19160">https://arxiv.org/abs/2502.19160</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.19160">https://arxiv.org/pdf/2502.19160</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.19160]] Detecting Linguistic Indicators for Stereotype Assessment with Large Language Models(https://arxiv.org/abs/2502.19160)</code><input type="text"></li>
<li><strong>Keywords: </strong>in-context</a></li>
<li><strong>Abstract: </strong>Social categories and stereotypes are embedded in language and can introduce data bias into Large Language Models (LLMs). Despite safeguards, these biases often persist in model behavior, potentially leading to representational harm in outputs. While sociolinguistic research provides valuable insights into the formation of stereotypes, NLP approaches for stereotype detection rarely draw on this foundation and often lack objectivity, precision, and interpretability. To fill this gap, in this work we propose a new approach that detects and quantifies the linguistic indicators of stereotypes in a sentence. We derive linguistic indicators from the Social Category and Stereotype Communication (SCSC) framework which indicate strong social category formulation and stereotyping in language, and use them to build a categorization scheme. To automate this approach, we instruct different LLMs using in-context learning to apply the approach to a sentence, where the LLM examines the linguistic properties and provides a basis for a fine-grained assessment. Based on an empirical evaluation of the importance of different linguistic indicators, we learn a scoring function that measures the linguistic indicators of a stereotype. Our annotations of stereotyped sentences show that these indicators are present in these sentences and explain the strength of a stereotype. In terms of model performance, our results show that the models generally perform well in detecting and classifying linguistic indicators of category labels used to denote a category, but sometimes struggle to correctly evaluate the associated behaviors and characteristics. Using more few-shot examples within the prompts, significantly improves performance. Model performance increases with size, as Llama-3.3-70B-Instruct and GPT-4 achieve comparable results that surpass those of Mixtral-8x7B-Instruct, GPT-4-mini and Llama-3.1-8B-Instruct.</li>
</ul>

<h3>Title: A Model-Centric Review of Deep Learning for Protein Design</h3>
<ul>
<li><strong>Authors: </strong>Gregory W. Kyro, Tianyin Qiu, Victor S. Batista</a></li>
<li><strong>Subjects: </strong>cs.LG, q-bio.BM</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.19173">https://arxiv.org/abs/2502.19173</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.19173">https://arxiv.org/pdf/2502.19173</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.19173]] A Model-Centric Review of Deep Learning for Protein Design(https://arxiv.org/abs/2502.19173)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, generative</a></li>
<li><strong>Abstract: </strong>Deep learning has transformed protein design, enabling accurate structure prediction, sequence optimization, and de novo protein generation. Advances in single-chain protein structure prediction via AlphaFold2, RoseTTAFold, ESMFold, and others have achieved near-experimental accuracy, inspiring successive work extended to biomolecular complexes via AlphaFold Multimer, RoseTTAFold All-Atom, AlphaFold 3, Chai-1, Boltz-1 and others. Generative models such as ProtGPT2, ProteinMPNN, and RFdiffusion have enabled sequence and backbone design beyond natural evolution-based limitations. More recently, joint sequence-structure co-design models, including ESM3, have integrated both modalities into a unified framework, resulting in improved designability. Despite these advances, challenges still exist pertaining to modeling sequence-structure-function relationships and ensuring robust generalization beyond the regions of protein space spanned by the training data. Future advances will likely focus on joint sequence-structure-function co-design frameworks that are able to model the fitness landscape more effectively than models that treat these modalities independently. Current capabilities, coupled with the dizzying rate of progress, suggest that the field will soon enable rapid, rational design of proteins with tailored structures and functions that transcend the limitations imposed by natural evolution. In this review, we discuss the current capabilities of deep learning methods for protein design, focusing on some of the most revolutionary and capable models with respect to their functionality and the applications that they enable, leading up to the current challenges of the field and the optimal path forward.</li>
</ul>

<h3>Title: AutoML for Multi-Class Anomaly Compensation of Sensor Drift</h3>
<ul>
<li><strong>Authors: </strong>Melanie Schaller, Mathis Kruse, Antonio Ortega, Marius Lindauer, Bodo Rosenhahn</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.19180">https://arxiv.org/abs/2502.19180</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.19180">https://arxiv.org/pdf/2502.19180</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.19180]] AutoML for Multi-Class Anomaly Compensation of Sensor Drift(https://arxiv.org/abs/2502.19180)</code><input type="text"></li>
<li><strong>Keywords: </strong>anomaly</a></li>
<li><strong>Abstract: </strong>Addressing sensor drift is essential in industrial measurement systems, where precise data output is necessary for maintaining accuracy and reliability in monitoring processes, as it progressively degrades the performance of machine learning models over time. Our findings indicate that the standard cross-validation method used in existing model training overestimates performance by inadequately accounting for drift. This is primarily because typical cross-validation techniques allow data instances to appear in both training and testing sets, thereby distorting the accuracy of the predictive evaluation. As a result, these models are unable to precisely predict future drift effects, compromising their ability to generalize and adapt to evolving data conditions. This paper presents two solutions: (1) a novel sensor drift compensation learning paradigm for validating models, and (2) automated machine learning (AutoML) techniques to enhance classification performance and compensate sensor drift. By employing strategies such as data balancing, meta-learning, automated ensemble learning, hyperparameter optimization, feature selection, and boosting, our AutoML-DC (Drift Compensation) model significantly improves classification performance against sensor drift. AutoML-DC further adapts effectively to varying drift severities.</li>
</ul>

<h3>Title: INFO-SEDD: Continuous Time Markov Chains as Scalable Information Metrics Estimators</h3>
<ul>
<li><strong>Authors: </strong>Alberto Foresti, Giulio Franzese, Pietro Michiardi</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.19183">https://arxiv.org/abs/2502.19183</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.19183">https://arxiv.org/pdf/2502.19183</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.19183]] INFO-SEDD: Continuous Time Markov Chains as Scalable Information Metrics Estimators(https://arxiv.org/abs/2502.19183)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>Information-theoretic quantities play a crucial role in understanding non-linear relationships between random variables and are widely used across scientific disciplines. However, estimating these quantities remains an open problem, particularly in the case of high-dimensional discrete distributions. Current approaches typically rely on embedding discrete data into a continuous space and applying neural estimators originally designed for continuous distributions, a process that may not fully capture the discrete nature of the underlying data. We consider Continuous-Time Markov Chains (CTMCs), stochastic processes on discrete state-spaces which have gained popularity due to their generative modeling applications. In this work, we introduce INFO-SEDD, a novel method for estimating information-theoretic quantities of discrete data, including mutual information and entropy. Our approach requires the training of a single parametric model, offering significant computational and memory advantages. Additionally, it seamlessly integrates with pretrained networks, allowing for efficient reuse of pretrained generative models. To evaluate our approach, we construct a challenging synthetic benchmark. Our experiments demonstrate that INFO-SEDD is robust and outperforms neural competitors that rely on embedding techniques. Moreover, we validate our method on a real-world task: estimating the entropy of an Ising model. Overall, INFO-SEDD outperforms competing methods and shows scalability to high-dimensional scenarios, paving the way for new applications where estimating MI between discrete distribution is the focus. The promising results in this complex, high-dimensional scenario highlight INFO-SEDD as a powerful new estimator in the toolkit for information-theoretical analysis.</li>
</ul>

<h3>Title: Self-supervised conformal prediction for uncertainty quantification in Poisson imaging problems</h3>
<ul>
<li><strong>Authors: </strong>Bernardin Tamo Amougou, Marcelo Pereyra, Barbara Pascal</a></li>
<li><strong>Subjects: </strong>cs.CV, eess.IV, eess.SP</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.19194">https://arxiv.org/abs/2502.19194</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.19194">https://arxiv.org/pdf/2502.19194</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.19194]] Self-supervised conformal prediction for uncertainty quantification in Poisson imaging problems(https://arxiv.org/abs/2502.19194)</code><input type="text"></li>
<li><strong>Keywords: </strong>self-supervised</a></li>
<li><strong>Abstract: </strong>Image restoration problems are often ill-posed, leading to significant uncertainty in reconstructed images. Accurately quantifying this uncertainty is essential for the reliable interpretation of reconstructed images. However, image restoration methods often lack uncertainty quantification capabilities. Conformal prediction offers a rigorous framework to augment image restoration methods with accurate uncertainty quantification estimates, but it typically requires abundant ground truth data for calibration. This paper presents a self-supervised conformal prediction method for Poisson imaging problems which leverages Poisson Unbiased Risk Estimator to eliminate the need for ground truth data. The resulting self-calibrating conformal prediction approach is applicable to any Poisson linear imaging problem that is ill-conditioned, and is particularly effective when combined with modern self-supervised image restoration techniques trained directly on measurement data. The proposed method is demonstrated through numerical experiments on image denoising and deblurring; its performance are comparable to supervised conformal prediction methods relying on ground truth data.</li>
</ul>

<h3>Title: HDM: Hybrid Diffusion Model for Unified Image Anomaly Detection</h3>
<ul>
<li><strong>Authors: </strong>Zekang Weng, Jinjin Shi, Jinwei Wang, Zeming Han</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.19200">https://arxiv.org/abs/2502.19200</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.19200">https://arxiv.org/pdf/2502.19200</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.19200]] HDM: Hybrid Diffusion Model for Unified Image Anomaly Detection(https://arxiv.org/abs/2502.19200)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, anomaly</a></li>
<li><strong>Abstract: </strong>Image anomaly detection plays a vital role in applications such as industrial quality inspection and medical imaging, where it directly contributes to improving product quality and system reliability. However, existing methods often struggle with complex and diverse anomaly patterns. In particular, the separation between generation and discrimination tasks limits the effective coordination between anomaly sample generation and anomaly region detection. To address these challenges, we propose a novel hybrid diffusion model (HDM) that integrates generation and discrimination into a unified framework. The model consists of three key modules: the Diffusion Anomaly Generation Module (DAGM), the Diffusion Discriminative Module (DDM), and the Probability Optimization Module (POM). DAGM generates realistic and diverse anomaly samples, improving their representativeness. DDM then applies a reverse diffusion process to capture the differences between generated and normal samples, enabling precise anomaly region detection and localization based on probability distributions. POM refines the probability distributions during both the generation and discrimination phases, ensuring high-quality samples are used for training. Extensive experiments on multiple industrial image datasets demonstrate that our method outperforms state-of-the-art approaches, significantly improving both image-level and pixel-level anomaly detection performance, as measured by AUROC.</li>
</ul>

<h3>Title: LiGT: Layout-infused Generative Transformer for Visual Question Answering on Vietnamese Receipts</h3>
<ul>
<li><strong>Authors: </strong>Thanh-Phong Le, Trung Le Chi Phan, Nghia Hieu Nguyen, Kiet Van Nguyen</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.19202">https://arxiv.org/abs/2502.19202</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.19202">https://arxiv.org/pdf/2502.19202</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.19202]] LiGT: Layout-infused Generative Transformer for Visual Question Answering on Vietnamese Receipts(https://arxiv.org/abs/2502.19202)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>\textbf{Purpose:} Document Visual Question Answering (document VQA) challenges multimodal systems to holistically handle textual, layout, and visual modalities to provide appropriate answers. Document VQA has gained popularity in recent years due to the increasing amount of documents and the high demand for digitization. Nonetheless, most of document VQA datasets are developed in high-resource languages such as English. \textbf{Methods:} In this paper, we present ReceiptVQA (\textbf{Receipt} \textbf{V}isual \textbf{Q}uestion \textbf{A}nswering), the initial large-scale document VQA dataset in Vietnamese dedicated to receipts, a document kind with high commercial potentials. The dataset encompasses \textbf{9,000+} receipt images and \textbf{60,000+} manually annotated question-answer pairs. In addition to our study, we introduce LiGT (\textbf{L}ayout-\textbf{i}nfused \textbf{G}enerative \textbf{T}ransformer), a layout-aware encoder-decoder architecture designed to leverage embedding layers of language models to operate layout embeddings, minimizing the use of additional neural modules. \textbf{Results:} Experiments on ReceiptVQA show that our architecture yielded promising performance, achieving competitive results compared with outstanding baselines. Furthermore, throughout analyzing experimental results, we found evident patterns that employing encoder-only model architectures has considerable disadvantages in comparison to architectures that can generate answers. We also observed that it is necessary to combine multiple modalities to tackle our dataset, despite the critical role of semantic understanding from language models. \textbf{Conclusion:} We hope that our work will encourage and facilitate future development in Vietnamese document VQA, contributing to a diverse multimodal research community in the Vietnamese language.</li>
</ul>

<h3>Title: A Lightweight and Extensible Cell Segmentation and Classification Model for Whole Slide Images</h3>
<ul>
<li><strong>Authors: </strong>Nikita Shvetsov, Thomas K. Kilvaer, Masoud Tafavvoghi, Anders Sildnes, Kajsa Møllersen, Lill-Tove Rasmussen Busund, Lars Ailo Bongo</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.19217">https://arxiv.org/abs/2502.19217</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.19217">https://arxiv.org/pdf/2502.19217</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.19217]] A Lightweight and Extensible Cell Segmentation and Classification Model for Whole Slide Images(https://arxiv.org/abs/2502.19217)</code><input type="text"></li>
<li><strong>Keywords: </strong>foundation model</a></li>
<li><strong>Abstract: </strong>Developing clinically useful cell-level analysis tools in digital pathology remains challenging due to limitations in dataset granularity, inconsistent annotations, high computational demands, and difficulties integrating new technologies into workflows. To address these issues, we propose a solution that enhances data quality, model performance, and usability by creating a lightweight, extensible cell segmentation and classification model. First, we update data labels through cross-relabeling to refine annotations of PanNuke and MoNuSAC, producing a unified dataset with seven distinct cell types. Second, we leverage the H-Optimus foundation model as a fixed encoder to improve feature representation for simultaneous segmentation and classification tasks. Third, to address foundation models' computational demands, we distill knowledge to reduce model size and complexity while maintaining comparable performance. Finally, we integrate the distilled model into QuPath, a widely used open-source digital pathology platform. Results demonstrate improved segmentation and classification performance using the H-Optimus-based model compared to a CNN-based model. Specifically, average $R^2$ improved from 0.575 to 0.871, and average $PQ$ score improved from 0.450 to 0.492, indicating better alignment with actual cell counts and enhanced segmentation quality. The distilled model maintains comparable performance while reducing parameter count by a factor of 48. By reducing computational complexity and integrating into workflows, this approach may significantly impact diagnostics, reduce pathologist workload, and improve outcomes. Although the method shows promise, extensive validation is necessary prior to clinical deployment.</li>
</ul>

<h3>Title: Anomaly Detection in Complex Dynamical Systems: A Systematic Framework Using Embedding Theory and Physics-Inspired Consistency</h3>
<ul>
<li><strong>Authors: </strong>Michael Somma, Thomas Gallien, Branka Stojanovic</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.19307">https://arxiv.org/abs/2502.19307</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.19307">https://arxiv.org/pdf/2502.19307</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.19307]] Anomaly Detection in Complex Dynamical Systems: A Systematic Framework Using Embedding Theory and Physics-Inspired Consistency(https://arxiv.org/abs/2502.19307)</code><input type="text"></li>
<li><strong>Keywords: </strong>anomaly</a></li>
<li><strong>Abstract: </strong>Anomaly detection in complex dynamical systems is essential for ensuring reliability, safety, and efficiency in industrial and cyber-physical infrastructures. Predictive maintenance helps prevent costly failures, while cybersecurity monitoring has become critical as digitized systems face growing threats. Many of these systems exhibit oscillatory behaviors and bounded motion, requiring anomaly detection methods that capture structured temporal dependencies while adhering to physical consistency principles. In this work, we propose a system-theoretic approach to anomaly detection, grounded in classical embedding theory and physics-inspired consistency principles. We build upon the Fractal Whitney Embedding Prevalence Theorem, extending traditional embedding techniques to complex system dynamics. Additionally, we introduce state-derivative pairs as an embedding strategy to capture system evolution. To enforce temporal coherence, we develop a Temporal Differential Consistency Autoencoder (TDC-AE), incorporating a TDC-Loss that aligns the approximated derivatives of latent variables with their dynamic representations. We evaluate our method on the C-MAPSS dataset, a benchmark for turbofan aeroengine degradation. TDC-AE outperforms LSTMs and Transformers while achieving a 200x reduction in MAC operations, making it particularly suited for lightweight edge computing. Our findings support the hypothesis that anomalies disrupt stable system dynamics, providing a robust, interpretable signal for anomaly detection.</li>
</ul>

<h3>Title: FSPO: Few-Shot Preference Optimization of Synthetic Preference Data in LLMs Elicits Effective Personalization to Real Users</h3>
<ul>
<li><strong>Authors: </strong>Anikait Singh, Sheryl Hsu, Kyle Hsu, Eric Mitchell, Stefano Ermon, Tatsunori Hashimoto, Archit Sharma, Chelsea Finn</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CL, cs.HC, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.19312">https://arxiv.org/abs/2502.19312</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.19312">https://arxiv.org/pdf/2502.19312</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.19312]] FSPO: Few-Shot Preference Optimization of Synthetic Preference Data in LLMs Elicits Effective Personalization to Real Users(https://arxiv.org/abs/2502.19312)</code><input type="text"></li>
<li><strong>Keywords: </strong>in-context</a></li>
<li><strong>Abstract: </strong>Effective personalization of LLMs is critical for a broad range of user-interfacing applications such as virtual assistants and content curation. Inspired by the strong in-context learning capabilities of LLMs, we propose Few-Shot Preference Optimization (FSPO), which reframes reward modeling as a meta-learning problem. Under this framework, an LLM learns to quickly adapt to a user via a few labeled preferences from that user, constructing a personalized reward function for them. Additionally, since real-world preference data is scarce and challenging to collect at scale, we propose careful design choices to construct synthetic preference datasets for personalization, generating over 1M synthetic personalized preferences using publicly available LLMs. In particular, to successfully transfer from synthetic data to real users, we find it crucial for the data to exhibit both high diversity and coherent, self-consistent structure. We evaluate FSPO on personalized open-ended generation for up to 1,500 synthetic users across across three domains: movie reviews, pedagogical adaptation based on educational background, and general question answering, along with a controlled human study. Overall, FSPO achieves an 87% Alpaca Eval winrate on average in generating responses that are personalized to synthetic users and a 72% winrate with real human users in open-ended question answering.</li>
</ul>

<h3>Title: Model Adaptation: Unsupervised Domain Adaptation without Source Data</h3>
<ul>
<li><strong>Authors: </strong>Rui Li, Qianfen Jiao, Wenming Cao, Hau-San Wong, Si Wu</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.19316">https://arxiv.org/abs/2502.19316</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.19316">https://arxiv.org/pdf/2502.19316</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.19316]] Model Adaptation: Unsupervised Domain Adaptation without Source Data(https://arxiv.org/abs/2502.19316)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>In this paper, we investigate a challenging unsupervised domain adaptation setting -- unsupervised model adaptation. We aim to explore how to rely only on unlabeled target data to improve performance of an existing source prediction model on the target domain, since labeled source data may not be available in some real-world scenarios due to data privacy issues. For this purpose, we propose a new framework, which is referred to as collaborative class conditional generative adversarial net to bypass the dependence on the source data. Specifically, the prediction model is to be improved through generated target-style data, which provides more accurate guidance for the generator. As a result, the generator and the prediction model can collaborate with each other without source data. Furthermore, due to the lack of supervision from source data, we propose a weight constraint that encourages similarity to the source model. A clustering-based regularization is also introduced to produce more discriminative features in the target domain. Compared to conventional domain adaptation methods, our model achieves superior performance on multiple adaptation tasks with only unlabeled target data, which verifies its effectiveness in this challenging setting.</li>
</ul>

<h3>Title: Consistent Amortized Clustering via Generative Flow Networks</h3>
<ul>
<li><strong>Authors: </strong>Irit Chelly, Roy Uziel, Oren Freifeld, Ari Pakman</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.19337">https://arxiv.org/abs/2502.19337</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.19337">https://arxiv.org/pdf/2502.19337</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.19337]] Consistent Amortized Clustering via Generative Flow Networks(https://arxiv.org/abs/2502.19337)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>Neural models for amortized probabilistic clustering yield samples of cluster labels given a set-structured input, while avoiding lengthy Markov chain runs and the need for explicit data likelihoods. Existing methods which label each data point sequentially, like the Neural Clustering Process, often lead to cluster assignments highly dependent on the data order. Alternatively, methods that sequentially create full clusters, do not provide assignment probabilities. In this paper, we introduce GFNCP, a novel framework for amortized clustering. GFNCP is formulated as a Generative Flow Network with a shared energy-based parametrization of policy and reward. We show that the flow matching conditions are equivalent to consistency of the clustering posterior under marginalization, which in turn implies order invariance. GFNCP also outperforms existing methods in clustering performance on both synthetic and real-world data.</li>
</ul>

<h3>Title: DataMan: Data Manager for Pre-training Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Ru Peng, Kexin Yang, Yawen Zeng, Junyang Lin, Dayiheng Liu, Junbo Zhao</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.19363">https://arxiv.org/abs/2502.19363</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.19363">https://arxiv.org/pdf/2502.19363</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.19363]] DataMan: Data Manager for Pre-training Large Language Models(https://arxiv.org/abs/2502.19363)</code><input type="text"></li>
<li><strong>Keywords: </strong>in-context</a></li>
<li><strong>Abstract: </strong>The performance emergence of large language models (LLMs) driven by data scaling laws makes the selection of pre-training data increasingly important. However, existing methods rely on limited heuristics and human intuition, lacking comprehensive and clear guidelines. To address this, we are inspired by ``reverse thinking'' -- prompting LLMs to self-identify which criteria benefit its performance. As its pre-training capabilities are related to perplexity (PPL), we derive 14 quality criteria from the causes of text perplexity anomalies and introduce 15 common application domains to support domain mixing. In this paper, we train a Data Manager (DataMan) to learn quality ratings and domain recognition from pointwise rating, and use it to annotate a 447B token pre-training corpus with 14 quality ratings and domain type. Our experiments validate our approach, using DataMan to select 30B tokens to train a 1.3B-parameter language model, demonstrating significant improvements in in-context learning (ICL), perplexity, and instruction-following ability over the state-of-the-art baseline. The best-performing model, based on the Overall Score l=5 surpasses a model trained with 50% more data using uniform sampling. We continue pre-training with high-rated, domain-specific data annotated by DataMan to enhance domain-specific ICL performance and thus verify DataMan's domain mixing ability. Our findings emphasize the importance of quality ranking, the complementary nature of quality criteria, and their low correlation with perplexity, analyzing misalignment between PPL and ICL performance. We also thoroughly analyzed our pre-training dataset, examining its composition, the distribution of quality ratings, and the original document sources.</li>
</ul>

<h3>Title: Deep Learning For Time Series Analysis With Application On Human Motion</h3>
<ul>
<li><strong>Authors: </strong>Ali Ismail-Fawaz</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.19364">https://arxiv.org/abs/2502.19364</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.19364">https://arxiv.org/pdf/2502.19364</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.19364]] Deep Learning For Time Series Analysis With Application On Human Motion(https://arxiv.org/abs/2502.19364)</code><input type="text"></li>
<li><strong>Keywords: </strong>self-supervised, foundation model, generative</a></li>
<li><strong>Abstract: </strong>Time series data, defined by equally spaced points over time, is essential in fields like medicine, telecommunications, and energy. Analyzing it involves tasks such as classification, clustering, prototyping, and regression. Classification identifies normal vs. abnormal movements in skeleton-based motion sequences, clustering detects stock market behavior patterns, prototyping expands physical therapy datasets, and regression predicts patient recovery. Deep learning has recently gained traction in time series analysis due to its success in other domains. This thesis leverages deep learning to enhance classification with feature engineering, introduce foundation models, and develop a compact yet state-of-the-art architecture. We also address limited labeled data with self-supervised learning. Our contributions apply to real-world tasks, including human motion analysis for action recognition and rehabilitation. We introduce a generative model for human motion data, valuable for cinematic production and gaming. For prototyping, we propose a shape-based synthetic sample generation method to support regression models when data is scarce. Lastly, we critically evaluate discriminative and generative models, identifying limitations in current methodologies and advocating for a robust, standardized evaluation framework. Our experiments on public datasets provide novel insights and methodologies, advancing time series analysis with practical applications.</li>
</ul>

<h3>Title: Preference-Based Gradient Estimation for ML-Based Approximate Combinatorial Optimization</h3>
<ul>
<li><strong>Authors: </strong>Arman Mielke, Uwe Bauknecht, Thilo Strauss, Mathias Niepert</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.19377">https://arxiv.org/abs/2502.19377</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.19377">https://arxiv.org/pdf/2502.19377</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.19377]] Preference-Based Gradient Estimation for ML-Based Approximate Combinatorial Optimization(https://arxiv.org/abs/2502.19377)</code><input type="text"></li>
<li><strong>Keywords: </strong>self-supervised</a></li>
<li><strong>Abstract: </strong>Combinatorial optimization (CO) problems arise in a wide range of fields from medicine to logistics and manufacturing. While exact solutions are often not necessary, many applications require finding high-quality solutions quickly. For this purpose, we propose a data-driven approach to improve existing non-learned approximation algorithms for CO. We parameterize the approximation algorithm and train a graph neural network (GNN) to predict parameter values that lead to the best possible solutions. Our pipeline is trained end-to-end in a self-supervised fashion using gradient estimation, treating the approximation algorithm as a black box. We propose a novel gradient estimation scheme for this purpose, which we call preference-based gradient estimation. Our approach combines the benefits of the neural network and the non-learned approximation algorithm: The GNN leverages the information from the dataset to allow the approximation algorithm to find better solutions, while the approximation algorithm guarantees that the solution is feasible. We validate our approach on two well-known combinatorial optimization problems, the travelling salesman problem and the minimum k-cut problem, and show that our method is competitive with state of the art learned CO solvers.</li>
</ul>

<h3>Title: Residual Speech Embeddings for Tone Classification: Removing Linguistic Content to Enhance Paralinguistic Analysis</h3>
<ul>
<li><strong>Authors: </strong>Hamdan Al Ahbabi, Gautier Marti, Saeed AlMarri, Ibrahim Elfadel</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.19387">https://arxiv.org/abs/2502.19387</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.19387">https://arxiv.org/pdf/2502.19387</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.19387]] Residual Speech Embeddings for Tone Classification: Removing Linguistic Content to Enhance Paralinguistic Analysis(https://arxiv.org/abs/2502.19387)</code><input type="text"></li>
<li><strong>Keywords: </strong>self-supervised</a></li>
<li><strong>Abstract: </strong>Self-supervised learning models for speech processing, such as wav2vec2, HuBERT, WavLM, and Whisper, generate embeddings that capture both linguistic and paralinguistic information, making it challenging to analyze tone independently of spoken content. In this work, we introduce a method for disentangling paralinguistic features from linguistic content by regressing speech embeddings onto their corresponding text embeddings and using the residuals as a representation of vocal tone. We evaluate this approach across multiple self-supervised speech embeddings, demonstrating that residual embeddings significantly improve tone classification performance compared to raw speech embeddings. Our results show that this method enhances linear separability, enabling improved classification even with simple models such as logistic regression. Visualization of the residual embeddings further confirms the successful removal of linguistic information while preserving tone-related features. These findings highlight the potential of residual embeddings for applications in sentiment analysis, speaker characterization, and paralinguistic speech processing.</li>
</ul>

<button id="copy">Copy All</button>
</article>
<script src="../../javascript/clipboard.min.js"></script>
<script src="../../javascript/clipboard.js"></script>
