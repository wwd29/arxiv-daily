<link rel="stylesheet" href="../../css/markdown.css" />
<article class="markdown-body">
<h1>2024-08-08</h1>
<h3>Title: Adversarial Domain Adaptation for Cross-user Activity Recognition Using Diffusion-based Noise-centred Learning</h3>
<ul>
<li><strong>Authors: </strong>Xiaozhou Ye, Kevin I-Kai Wang</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.HC</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2408.03353">https://arxiv.org/abs/2408.03353</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2408.03353">https://arxiv.org/pdf/2408.03353</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2408.03353]] Adversarial Domain Adaptation for Cross-user Activity Recognition Using Diffusion-based Noise-centred Learning(https://arxiv.org/abs/2408.03353)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, generative</a></li>
<li><strong>Abstract: </strong>Human Activity Recognition (HAR) plays a crucial role in various applications such as human-computer interaction and healthcare monitoring. However, challenges persist in HAR models due to the data distribution differences between training and real-world data distributions, particularly evident in cross-user scenarios. This paper introduces a novel framework, termed Diffusion-based Noise-centered Adversarial Learning Domain Adaptation (Diff-Noise-Adv-DA), designed to address these challenges by leveraging generative diffusion modeling and adversarial learning techniques. Traditional HAR models often struggle with the diversity of user behaviors and sensor data distributions. Diff-Noise-Adv-DA innovatively integrates the inherent noise within diffusion models, harnessing its latent information to enhance domain adaptation. Specifically, the framework transforms noise into a critical carrier of activity and domain class information, facilitating robust classification across different user domains. Experimental evaluations demonstrate the effectiveness of Diff-Noise-Adv-DA in improving HAR model performance across different users, surpassing traditional domain adaptation methods. The framework not only mitigates distribution mismatches but also enhances data quality through noise-based denoising techniques.</li>
</ul>

<h3>Title: FastEdit: Fast Text-Guided Single-Image Editing via Semantic-Aware Diffusion Fine-Tuning</h3>
<ul>
<li><strong>Authors: </strong>Zhi Chen, Zecheng Zhao, Yadan Luo, Zi Huang</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2408.03355">https://arxiv.org/abs/2408.03355</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2408.03355">https://arxiv.org/pdf/2408.03355</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2408.03355]] FastEdit: Fast Text-Guided Single-Image Editing via Semantic-Aware Diffusion Fine-Tuning(https://arxiv.org/abs/2408.03355)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, generative</a></li>
<li><strong>Abstract: </strong>Conventional Text-guided single-image editing approaches require a two-step process, including fine-tuning the target text embedding for over 1K iterations and the generative model for another 1.5K iterations. Although it ensures that the resulting image closely aligns with both the input image and the target text, this process often requires 7 minutes per image, posing a challenge for practical application due to its time-intensive nature. To address this bottleneck, we introduce FastEdit, a fast text-guided single-image editing method with semantic-aware diffusion fine-tuning, dramatically accelerating the editing process to only 17 seconds. FastEdit streamlines the generative model's fine-tuning phase, reducing it from 1.5K to a mere 50 iterations. For diffusion fine-tuning, we adopt certain time step values based on the semantic discrepancy between the input image and target text. Furthermore, FastEdit circumvents the initial fine-tuning step by utilizing an image-to-image model that conditions on the feature space, rather than the text embedding space. It can effectively align the target text prompt and input image within the same feature space and save substantial processing time. Additionally, we apply the parameter-efficient fine-tuning technique LoRA to U-net. With LoRA, FastEdit minimizes the model's trainable parameters to only 0.37\% of the original size. At the same time, we can achieve comparable editing outcomes with significantly reduced computational overhead. We conduct extensive experiments to validate the editing performance of our approach and show promising editing capabilities, including content addition, style transfer, background replacement, and posture manipulation, etc.</li>
</ul>

<h3>Title: LAMPO: Large Language Models as Preference Machines for Few-shot Ordinal Classification</h3>
<ul>
<li><strong>Authors: </strong>Zhen Qin, Junru Wu, Jiaming Shen, Tianqi Liu, Xuanhui Wang</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2408.03359">https://arxiv.org/abs/2408.03359</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2408.03359">https://arxiv.org/pdf/2408.03359</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2408.03359]] LAMPO: Large Language Models as Preference Machines for Few-shot Ordinal Classification(https://arxiv.org/abs/2408.03359)</code><input type="text"></li>
<li><strong>Keywords: </strong>self-supervised</a></li>
<li><strong>Abstract: </strong>We introduce LAMPO, a novel paradigm that leverages Large Language Models (LLMs) for solving few-shot multi-class ordinal classification tasks. Unlike conventional methods, which concatenate all demonstration examples with the test instance and prompt LLMs to produce the pointwise prediction, our framework uses the LLM as a preference machine that makes a relative comparative decision between the test instance and each demonstration. A self-supervised method is then introduced to aggregate these binary comparisons into the final ordinal decision. LAMPO addresses several limitations inherent in previous methods, including context length constraints, ordering biases, and challenges associated with absolute point-wise estimation. Extensive experiments on seven public datasets demonstrate LAMPO's remarkably competitive performance across a diverse spectrum of applications (e.g., movie review analysis and hate speech detection). Notably, in certain applications, the improvement can be substantial, exceeding 20% in an absolute term. Moreover, we believe LAMPO represents an interesting addition to the non-parametric application layered on top of LLMs, as it supports black-box LLMs without necessitating the outputting of LLM's internal states (e.g., embeddings), as seen in previous approaches.</li>
</ul>

<h3>Title: A Non-negative VAE:the Generalized Gamma Belief Network</h3>
<ul>
<li><strong>Authors: </strong>Zhibin Duan, Tiansheng Wen, Muyao Wang, Bo Chen, Mingyuan Zhou</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2408.03388">https://arxiv.org/abs/2408.03388</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2408.03388">https://arxiv.org/pdf/2408.03388</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2408.03388]] A Non-negative VAE:the Generalized Gamma Belief Network(https://arxiv.org/abs/2408.03388)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>The gamma belief network (GBN), often regarded as a deep topic model, has demonstrated its potential for uncovering multi-layer interpretable latent representations in text data. Its notable capability to acquire interpretable latent factors is partially attributed to sparse and non-negative gamma-distributed latent variables. However, the existing GBN and its variations are constrained by the linear generative model, thereby limiting their expressiveness and applicability. To address this limitation, we introduce the generalized gamma belief network (Generalized GBN) in this paper, which extends the original linear generative model to a more expressive non-linear generative model. Since the parameters of the Generalized GBN no longer possess an analytic conditional posterior, we further propose an upward-downward Weibull inference network to approximate the posterior distribution of the latent variables. The parameters of both the generative model and the inference network are jointly trained within the variational inference framework. Finally, we conduct comprehensive experiments on both expressivity and disentangled representation learning tasks to evaluate the performance of the Generalized GBN against state-of-the-art Gaussian variational autoencoders serving as baselines.</li>
</ul>

<h3>Title: Attacks and Defenses for Generative Diffusion Models: A Comprehensive Survey</h3>
<ul>
<li><strong>Authors: </strong>Vu Tuan Truong, Luan Ba Dang, Long Bao Le</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2408.03400">https://arxiv.org/abs/2408.03400</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2408.03400">https://arxiv.org/pdf/2408.03400</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2408.03400]] Attacks and Defenses for Generative Diffusion Models: A Comprehensive Survey(https://arxiv.org/abs/2408.03400)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, generative</a></li>
<li><strong>Abstract: </strong>Diffusion models (DMs) have achieved state-of-the-art performance on various generative tasks such as image synthesis, text-to-image, and text-guided image-to-image generation. However, the more powerful the DMs, the more harmful they potentially are. Recent studies have shown that DMs are prone to a wide range of attacks, including adversarial attacks, membership inference, backdoor injection, and various multi-modal threats. Since numerous pre-trained DMs are published widely on the Internet, potential threats from these attacks are especially detrimental to the society, making DM-related security a worth investigating topic. Therefore, in this paper, we conduct a comprehensive survey on the security aspect of DMs, focusing on various attack and defense methods for DMs. First, we present crucial knowledge of DMs with five main types of DMs, including denoising diffusion probabilistic models, denoising diffusion implicit models, noise conditioned score networks, stochastic differential equations, and multi-modal conditional DMs. We further survey a variety of recent studies investigating different types of attacks that exploit the vulnerabilities of DMs. Then, we thoroughly review potential countermeasures to mitigate each of the presented threats. Finally, we discuss open challenges of DM-related security and envision certain research directions for this topic.</li>
</ul>

<h3>Title: ULLME: A Unified Framework for Large Language Model Embeddings with Generation-Augmented Learning</h3>
<ul>
<li><strong>Authors: </strong>Hieu Man, Nghia Trung Ngo, Franck Dernoncourt, Thien Huu Nguyen</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.IR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2408.03402">https://arxiv.org/abs/2408.03402</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2408.03402">https://arxiv.org/pdf/2408.03402</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2408.03402]] ULLME: A Unified Framework for Large Language Model Embeddings with Generation-Augmented Learning(https://arxiv.org/abs/2408.03402)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>Large Language Models (LLMs) excel in various natural language processing tasks, but leveraging them for dense passage embedding remains challenging. This is due to their causal attention mechanism and the misalignment between their pre-training objectives and the text ranking tasks. Despite some recent efforts to address these issues, existing frameworks for LLM-based text embeddings have been limited by their support for only a limited range of LLM architectures and fine-tuning strategies, limiting their practical application and versatility. In this work, we introduce the Unified framework for Large Language Model Embedding (ULLME), a flexible, plug-and-play implementation that enables bidirectional attention across various LLMs and supports a range of fine-tuning strategies. We also propose Generation-augmented Representation Learning (GRL), a novel fine-tuning method to boost LLMs for text embedding tasks. GRL enforces consistency between representation-based and generation-based relevance scores, leveraging LLMs' powerful generative abilities for learning passage embeddings. To showcase our framework's flexibility and effectiveness, we release three pre-trained models from ULLME with different backbone architectures, ranging from 1.5B to 8B parameters, all of which demonstrate strong performance on the Massive Text Embedding Benchmark. Our framework is publicly available at: this https URL. A demo video for ULLME can also be found at this https URL.</li>
</ul>

<h3>Title: A TVD neural network closure and application to turbulent combustion</h3>
<ul>
<li><strong>Authors: </strong>Seung Won Suh, Jonathan F MacArt, Luke N Olson, Jonathan B Freund</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CE, physics.flu-dyn</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2408.03413">https://arxiv.org/abs/2408.03413</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2408.03413">https://arxiv.org/pdf/2408.03413</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2408.03413]] A TVD neural network closure and application to turbulent combustion(https://arxiv.org/abs/2408.03413)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>Trained neural networks (NN) have attractive features for closing governing equations, but in the absence of additional constraints, they can stray from physical reality. A NN formulation is introduced to preclude spurious oscillations that violate solution boundedness or positivity. It is embedded in the discretized equations as a machine learning closure and strictly constrained, inspired by total variation diminishing (TVD) methods for hyperbolic conservation laws. The constraint is exactly enforced during gradient-descent training by rescaling the NN parameters, which maps them onto an explicit feasible set. Demonstrations show that the constrained NN closure model usefully recovers linear and nonlinear hyperbolic phenomena and anti-diffusion while enforcing the non-oscillatory property. Finally, the model is applied to subgrid-scale (SGS) modeling of a turbulent reacting flow, for which it suppresses spurious oscillations in scalar fields that otherwise violate the solution boundedness. It outperforms a simple penalization of oscillations in the loss function.</li>
</ul>

<h3>Title: Logistic Regression makes small LLMs strong and explainable "tens-of-shot" classifiers</h3>
<ul>
<li><strong>Authors: </strong>Marcus Buckmann, Edward Hill</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.LG, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2408.03414">https://arxiv.org/abs/2408.03414</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2408.03414">https://arxiv.org/pdf/2408.03414</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2408.03414]] Logistic Regression makes small LLMs strong and explainable "tens-of-shot" classifiers(https://arxiv.org/abs/2408.03414)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>For simple classification tasks, we show that users can benefit from the advantages of using small, local, generative language models instead of large commercial models without a trade-off in performance or introducing extra labelling costs. These advantages, including those around privacy, availability, cost, and explainability, are important both in commercial applications and in the broader democratisation of AI. Through experiments on 17 sentence classification tasks (2-4 classes), we show that penalised logistic regression on the embeddings from a small LLM equals (and usually betters) the performance of a large LLM in the "tens-of-shot" regime. This requires no more labelled instances than are needed to validate the performance of the large LLM. Finally, we extract stable and sensible explanations for classification decisions.</li>
</ul>

<h3>Title: Hybrid diffusion models: combining supervised and generative pretraining for label-efficient fine-tuning of segmentation models</h3>
<ul>
<li><strong>Authors: </strong>Bruno Sauvalle, Mathieu Salzmann</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2408.03433">https://arxiv.org/abs/2408.03433</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2408.03433">https://arxiv.org/pdf/2408.03433</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2408.03433]] Hybrid diffusion models: combining supervised and generative pretraining for label-efficient fine-tuning of segmentation models(https://arxiv.org/abs/2408.03433)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, self-supervised, generative</a></li>
<li><strong>Abstract: </strong>We are considering in this paper the task of label-efficient fine-tuning of segmentation models: We assume that a large labeled dataset is available and allows to train an accurate segmentation model in one domain, and that we have to adapt this model on a related domain where only a few samples are available. We observe that this adaptation can be done using two distinct methods: The first method, supervised pretraining, is simply to take the model trained on the first domain using classical supervised learning, and fine-tune it on the second domain with the available labeled samples. The second method is to perform self-supervised pretraining on the first domain using a generic pretext task in order to get high-quality representations which can then be used to train a model on the second domain in a label-efficient way. We propose in this paper to fuse these two approaches by introducing a new pretext task, which is to perform simultaneously image denoising and mask prediction on the first domain. We motivate this choice by showing that in the same way that an image denoiser conditioned on the noise level can be considered as a generative model for the unlabeled image distribution using the theory of diffusion models, a model trained using this new pretext task can be considered as a generative model for the joint distribution of images and segmentation masks under the assumption that the mapping from images to segmentation masks is deterministic. We then empirically show on several datasets that fine-tuning a model pretrained using this approach leads to better results than fine-tuning a similar model trained using either supervised or unsupervised pretraining only.</li>
</ul>

<h3>Title: AI Foundation Models in Remote Sensing: A Survey</h3>
<ul>
<li><strong>Authors: </strong>Siqi Lu, Junlin Guo, James R Zimmer-Dauphinee, Jordan M Nieusma, Xiao Wang, Parker VanValkenburgh, Steven A Wernke, Yuankai Huo</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2408.03464">https://arxiv.org/abs/2408.03464</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2408.03464">https://arxiv.org/pdf/2408.03464</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2408.03464]] AI Foundation Models in Remote Sensing: A Survey(https://arxiv.org/abs/2408.03464)</code><input type="text"></li>
<li><strong>Keywords: </strong>self-supervised, foundation model</a></li>
<li><strong>Abstract: </strong>Artificial Intelligence (AI) technologies have profoundly transformed the field of remote sensing, revolutionizing data collection, processing, and analysis. Traditionally reliant on manual interpretation and task-specific models, remote sensing has been significantly enhanced by the advent of foundation models--large-scale, pre-trained AI models capable of performing a wide array of tasks with unprecedented accuracy and efficiency. This paper provides a comprehensive survey of foundation models in the remote sensing domain, covering models released between June 2021 and June 2024. We categorize these models based on their applications in computer vision and domain-specific tasks, offering insights into their architectures, pre-training datasets, and methodologies. Through detailed performance comparisons, we highlight emerging trends and the significant advancements achieved by these foundation models. Additionally, we discuss the technical challenges, practical implications, and future research directions, addressing the need for high-quality data, computational resources, and improved model generalization. Our research also finds that pre-training methods, particularly self-supervised learning techniques like contrastive learning and masked autoencoders, significantly enhance the performance and robustness of foundation models in remote sensing tasks such as scene classification, object detection, and other applications. This survey aims to serve as a resource for researchers and practitioners by providing a panorama of advances and promising pathways for continued development and application of foundation models in remote sensing.</li>
</ul>

<h3>Title: Can LLMs Serve As Time Series Anomaly Detectors?</h3>
<ul>
<li><strong>Authors: </strong>Manqing Dong, Hao Huang, Longbing Cao</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2408.03475">https://arxiv.org/abs/2408.03475</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2408.03475">https://arxiv.org/pdf/2408.03475</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2408.03475]] Can LLMs Serve As Time Series Anomaly Detectors?(https://arxiv.org/abs/2408.03475)</code><input type="text"></li>
<li><strong>Keywords: </strong>anomaly, in-context</a></li>
<li><strong>Abstract: </strong>An emerging topic in large language models (LLMs) is their application to time series forecasting, characterizing mainstream and patternable characteristics of time series. A relevant but rarely explored and more challenging question is whether LLMs can detect and explain time series anomalies, a critical task across various real-world applications. In this paper, we investigate the capabilities of LLMs, specifically GPT-4 and LLaMA3, in detecting and explaining anomalies in time series. Our studies reveal that: 1) LLMs cannot be directly used for time series anomaly detection. 2) By designing prompt strategies such as in-context learning and chain-of-thought prompting, GPT-4 can detect time series anomalies with results competitive to baseline methods. 3) We propose a synthesized dataset to automatically generate time series anomalies with corresponding explanations. By applying instruction fine-tuning on this dataset, LLaMA3 demonstrates improved performance in time series anomaly detection tasks. In summary, our exploration shows the promising potential of LLMs as time series anomaly detectors.</li>
</ul>

<h3>Title: D2Styler: Advancing Arbitrary Style Transfer with Discrete Diffusion Methods</h3>
<ul>
<li><strong>Authors: </strong>Onkar Susladkar, Gayatri Deshmukh, Sparsh Mittal, Parth Shastri</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2408.03558">https://arxiv.org/abs/2408.03558</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2408.03558">https://arxiv.org/pdf/2408.03558</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2408.03558]] D2Styler: Advancing Arbitrary Style Transfer with Discrete Diffusion Methods(https://arxiv.org/abs/2408.03558)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>In image processing, one of the most challenging tasks is to render an image's semantic meaning using a variety of artistic approaches. Existing techniques for arbitrary style transfer (AST) frequently experience mode-collapse, over-stylization, or under-stylization due to a disparity between the style and content images. We propose a novel framework called D$^2$Styler (Discrete Diffusion Styler) that leverages the discrete representational capability of VQ-GANs and the advantages of discrete diffusion, including stable training and avoidance of mode collapse. Our method uses Adaptive Instance Normalization (AdaIN) features as a context guide for the reverse diffusion process. This makes it easy to move features from the style image to the content image without bias. The proposed method substantially enhances the visual quality of style-transferred images, allowing the combination of content and style in a visually appealing manner. We take style images from the WikiArt dataset and content images from the COCO dataset. Experimental results demonstrate that D$^2$Styler produces high-quality style-transferred images and outperforms twelve existing methods on nearly all the metrics. The qualitative results and ablation studies provide further insights into the efficacy of our technique. The code is available at this https URL.</li>
</ul>

<h3>Title: A comparative study of generative adversarial networks for image recognition algorithms based on deep learning and traditional methods</h3>
<ul>
<li><strong>Authors: </strong>Yihao Zhong, Yijing Wei, Yingbin Liang, Xiqing Liu, Rongwei Ji, Yiru Cang</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.LG, eess.IV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2408.03568">https://arxiv.org/abs/2408.03568</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2408.03568">https://arxiv.org/pdf/2408.03568</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2408.03568]] A comparative study of generative adversarial networks for image recognition algorithms based on deep learning and traditional methods(https://arxiv.org/abs/2408.03568)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>In this paper, an image recognition algorithm based on the combination of deep learning and generative adversarial network (GAN) is studied, and compared with traditional image recognition methods. The purpose of this study is to evaluate the advantages and application prospects of deep learning technology, especially GAN, in the field of image recognition. Firstly, this paper reviews the basic principles and techniques of traditional image recognition methods, including the classical algorithms based on feature extraction such as SIFT, HOG and their combination with support vector machine (SVM), random forest, and other classifiers. Then, the working principle, network structure, and unique advantages of GAN in image generation and recognition are introduced. In order to verify the effectiveness of GAN in image recognition, a series of experiments are designed and carried out using multiple public image data sets for training and testing. The experimental results show that compared with traditional methods, GAN has excellent performance in processing complex images, recognition accuracy, and anti-noise ability. Specifically, Gans are better able to capture high-dimensional features and details of images, significantly improving recognition performance. In addition, Gans shows unique advantages in dealing with image noise, partial missing information, and generating high-quality images.</li>
</ul>

<h3>Title: CARE: A Clue-guided Assistant for CSRs to Read User Manuals</h3>
<ul>
<li><strong>Authors: </strong>Weihong Du, Jia Liu, Zujie Wen, Dingnan Jin, Hongru Liang, Wenqiang Lei</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2408.03633">https://arxiv.org/abs/2408.03633</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2408.03633">https://arxiv.org/pdf/2408.03633</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2408.03633]] CARE: A Clue-guided Assistant for CSRs to Read User Manuals(https://arxiv.org/abs/2408.03633)</code><input type="text"></li>
<li><strong>Keywords: </strong>self-supervised</a></li>
<li><strong>Abstract: </strong>It is time-saving to build a reading assistant for customer service representations (CSRs) when reading user manuals, especially information-rich ones. Current solutions don't fit the online custom service scenarios well due to the lack of attention to user questions and possible responses. Hence, we propose to develop a time-saving and careful reading assistant for CSRs, named CARE. It can help the CSRs quickly find proper responses from the user manuals via explicit clue chains. Specifically, each of the clue chains is formed by inferring over the user manuals, starting from the question clue aligned with the user question and ending at a possible response. To overcome the shortage of supervised data, we adopt the self-supervised strategy for model learning. The offline experiment shows that CARE is efficient in automatically inferring accurate responses from the user manual. The online experiment further demonstrates the superiority of CARE to reduce CSRs' reading burden and keep high service quality, in particular with >35% decrease in time spent and keeping a >0.75 ICC score.</li>
</ul>

<h3>Title: TALE: Training-free Cross-domain Image Composition via Adaptive Latent Manipulation and Energy-guided Optimization</h3>
<ul>
<li><strong>Authors: </strong>Kien T. Pham, Jingye Chen, Qifeng Chen</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.MM</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2408.03637">https://arxiv.org/abs/2408.03637</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2408.03637">https://arxiv.org/pdf/2408.03637</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2408.03637]] TALE: Training-free Cross-domain Image Composition via Adaptive Latent Manipulation and Energy-guided Optimization(https://arxiv.org/abs/2408.03637)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, generative</a></li>
<li><strong>Abstract: </strong>We present TALE, a novel training-free framework harnessing the generative capabilities of text-to-image diffusion models to address the cross-domain image composition task that focuses on flawlessly incorporating user-specified objects into a designated visual contexts regardless of domain disparity. Previous methods often involve either training auxiliary networks or finetuning diffusion models on customized datasets, which are expensive and may undermine the robust textual and visual priors of pre-trained diffusion models. Some recent works attempt to break the barrier by proposing training-free workarounds that rely on manipulating attention maps to tame the denoising process implicitly. However, composing via attention maps does not necessarily yield desired compositional outcomes. These approaches could only retain some semantic information and usually fall short in preserving identity characteristics of input objects or exhibit limited background-object style adaptation in generated images. In contrast, TALE is a novel method that operates directly on latent space to provide explicit and effective guidance for the composition process to resolve these problems. Specifically, we equip TALE with two mechanisms dubbed Adaptive Latent Manipulation and Energy-guided Latent Optimization. The former formulates noisy latents conducive to initiating and steering the composition process by directly leveraging background and foreground latents at corresponding timesteps, and the latter exploits designated energy functions to further optimize intermediate latents conforming to specific conditions that complement the former to generate desired final results. Our experiments demonstrate that TALE surpasses prior baselines and attains state-of-the-art performance in image-guided composition across various photorealistic and artistic domains.</li>
</ul>

<h3>Title: Consumer Transactions Simulation through Generative Adversarial Networks</h3>
<ul>
<li><strong>Authors: </strong>Sergiy Tkachuk, Szymon Łukasik, Anna Wróblewska</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.IR, q-fin.CP</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2408.03655">https://arxiv.org/abs/2408.03655</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2408.03655">https://arxiv.org/pdf/2408.03655</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2408.03655]] Consumer Transactions Simulation through Generative Adversarial Networks(https://arxiv.org/abs/2408.03655)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>In the rapidly evolving domain of large-scale retail data systems, envisioning and simulating future consumer transactions has become a crucial area of interest. It offers significant potential to fortify demand forecasting and fine-tune inventory management. This paper presents an innovative application of Generative Adversarial Networks (GANs) to generate synthetic retail transaction data, specifically focusing on a novel system architecture that combines consumer behavior modeling with stock-keeping unit (SKU) availability constraints to address real-world assortment optimization challenges. We diverge from conventional methodologies by integrating SKU data into our GAN architecture and using more sophisticated embedding methods (e.g., hyper-graphs). This design choice enables our system to generate not only simulated consumer purchase behaviors but also reflects the dynamic interplay between consumer behavior and SKU availability -- an aspect often overlooked, among others, because of data scarcity in legacy retail simulation models. Our GAN model generates transactions under stock constraints, pioneering a resourceful experimental system with practical implications for real-world retail operation and strategy. Preliminary results demonstrate enhanced realism in simulated transactions measured by comparing generated items with real ones using methods employed earlier in related studies. This underscores the potential for more accurate predictive modeling.</li>
</ul>

<h3>Title: Generative Design of Periodic Orbits in the Restricted Three-Body Problem</h3>
<ul>
<li><strong>Authors: </strong>Alvaro Francisco Gil, Walther Litteri, Victor Rodriguez-Fernandez, David Camacho, Massimiliano Vasile</a></li>
<li><strong>Subjects: </strong>cs.LG, astro-ph.EP, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2408.03691">https://arxiv.org/abs/2408.03691</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2408.03691">https://arxiv.org/pdf/2408.03691</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2408.03691]] Generative Design of Periodic Orbits in the Restricted Three-Body Problem(https://arxiv.org/abs/2408.03691)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>The Three-Body Problem has fascinated scientists for centuries and it has been crucial in the design of modern space missions. Recent developments in Generative Artificial Intelligence hold transformative promise for addressing this longstanding problem. This work investigates the use of Variational Autoencoder (VAE) and its internal representation to generate periodic orbits. We utilize a comprehensive dataset of periodic orbits in the Circular Restricted Three-Body Problem (CR3BP) to train deep-learning architectures that capture key orbital characteristics, and we set up physical evaluation metrics for the generated trajectories. Through this investigation, we seek to enhance the understanding of how Generative AI can improve space mission planning and astrodynamics research, leading to novel, data-driven approaches in the field.</li>
</ul>

<h3>Title: Flexible Bayesian Last Layer Models Using Implicit Priors and Diffusion Posterior Sampling</h3>
<ul>
<li><strong>Authors: </strong>Jian Xu, Zhiqi Lin, Shigui Li, Min Chen, Junmei Yang, Delu Zeng, John Paisley</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2408.03746">https://arxiv.org/abs/2408.03746</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2408.03746">https://arxiv.org/pdf/2408.03746</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2408.03746]] Flexible Bayesian Last Layer Models Using Implicit Priors and Diffusion Posterior Sampling(https://arxiv.org/abs/2408.03746)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>Bayesian Last Layer (BLL) models focus solely on uncertainty in the output layer of neural networks, demonstrating comparable performance to more complex Bayesian models. However, the use of Gaussian priors for last layer weights in Bayesian Last Layer (BLL) models limits their expressive capacity when faced with non-Gaussian, outlier-rich, or high-dimensional datasets. To address this shortfall, we introduce a novel approach that combines diffusion techniques and implicit priors for variational learning of Bayesian last layer weights. This method leverages implicit distributions for modeling weight priors in BLL, coupled with diffusion samplers for approximating true posterior predictions, thereby establishing a comprehensive Bayesian prior and posterior estimation strategy. By delivering an explicit and computationally efficient variational lower bound, our method aims to augment the expressive abilities of BLL models, enhancing model accuracy, calibration, and out-of-distribution detection proficiency. Through detailed exploration and experimental validation, We showcase the method's potential for improving predictive accuracy and uncertainty quantification while ensuring computational efficiency.</li>
</ul>

<h3>Title: Online Model-based Anomaly Detection in Multivariate Time Series: Taxonomy, Survey, Research Challenges and Future Directions</h3>
<ul>
<li><strong>Authors: </strong>Lucas Correia, Jan-Christoph Goos, Philipp Klein, Thomas Bäck, Anna V. Kononova</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, eess.SY</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2408.03747">https://arxiv.org/abs/2408.03747</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2408.03747">https://arxiv.org/pdf/2408.03747</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2408.03747]] Online Model-based Anomaly Detection in Multivariate Time Series: Taxonomy, Survey, Research Challenges and Future Directions(https://arxiv.org/abs/2408.03747)</code><input type="text"></li>
<li><strong>Keywords: </strong>anomaly</a></li>
<li><strong>Abstract: </strong>Time-series anomaly detection plays an important role in engineering processes, like development, manufacturing and other operations involving dynamic systems. These processes can greatly benefit from advances in the field, as state-of-the-art approaches may aid in cases involving, for example, highly dimensional data. To provide the reader with understanding of the terminology, this survey introduces a novel taxonomy where a distinction between online and offline, and training and inference is made. Additionally, it presents the most popular data sets and evaluation metrics used in the literature, as well as a detailed analysis. Furthermore, this survey provides an extensive overview of the state-of-the-art model-based online semi- and unsupervised anomaly detection approaches for multivariate time-series data, categorising them into different model families and other properties. The biggest research challenge revolves around benchmarking, as currently there is no reliable way to compare different approaches against one another. This problem is two-fold: on the one hand, public data sets suffers from at least one fundamental flaw, while on the other hand, there is a lack of intuitive and representative evaluation metrics in the field. Moreover, the way most publications choose a detection threshold disregards real-world conditions, which hinders the application in the real world. To allow for tangible advances in the field, these issues must be addressed in future work.</li>
</ul>

<h3>Title: Data Generation Scheme for Thermal Modality with Edge-Guided Adversarial Conditional Diffusion Model</h3>
<ul>
<li><strong>Authors: </strong>Guoqing Zhu, Honghu Pan, Qiang Wang, Chao Tian, Chao Yang, Zhenyu He</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2408.03748">https://arxiv.org/abs/2408.03748</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2408.03748">https://arxiv.org/pdf/2408.03748</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2408.03748]] Data Generation Scheme for Thermal Modality with Edge-Guided Adversarial Conditional Diffusion Model(https://arxiv.org/abs/2408.03748)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>In challenging low light and adverse weather conditions,thermal vision algorithms,especially object detection,have exhibited remarkable potential,contrasting with the frequent struggles encountered by visible vision algorithms. Nevertheless,the efficacy of thermal vision algorithms driven by deep learning models remains constrained by the paucity of available training data samples. To this end,this paper introduces a novel approach termed the edge guided conditional diffusion model. This framework aims to produce meticulously aligned pseudo thermal images at the pixel level,leveraging edge information extracted from visible images. By utilizing edges as contextual cues from the visible domain,the diffusion model achieves meticulous control over the delineation of objects within the generated images. To alleviate the impacts of those visible-specific edge information that should not appear in the thermal domain,a two-stage modality adversarial training strategy is proposed to filter them out from the generated images by differentiating the visible and thermal modality. Extensive experiments on LLVIP demonstrate ECDM s superiority over existing state-of-the-art approaches in terms of image generation quality.</li>
</ul>

<h3>Title: 'Finance Wizard' at the FinLLM Challenge Task: Financial Text Summarization</h3>
<ul>
<li><strong>Authors: </strong>Meisin Lee, Soon Lay-Ki</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2408.03762">https://arxiv.org/abs/2408.03762</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2408.03762">https://arxiv.org/pdf/2408.03762</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2408.03762]] 'Finance Wizard' at the FinLLM Challenge Task: Financial Text Summarization(https://arxiv.org/abs/2408.03762)</code><input type="text"></li>
<li><strong>Keywords: </strong>foundation model</a></li>
<li><strong>Abstract: </strong>This paper presents our participation under the team name `Finance Wizard' in the FinNLP-AgentScen 2024 shared task #2: Financial Text Summarization. It documents our pipeline approach of fine-tuning a foundation model into a task-specific model for Financial Text Summarization. It involves (1) adapting Llama3 8B, a foundation model, to the Finance domain via continued pre-training, (2) multi-task instruction-tuning to further equip the model with more finance-related capabilities, (3) finally fine-tuning the model into a task-specific `expert'. Our model, FinLlama3\_sum, yielded commendable results, securing the third position in its category with a ROUGE-1 score of 0.521.</li>
</ul>

<h3>Title: Generative Language Models with Retrieval Augmented Generation for Automated Short Answer Scoring</h3>
<ul>
<li><strong>Authors: </strong>Zifan Wang, Christopher Ormerod</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.IR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2408.03811">https://arxiv.org/abs/2408.03811</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2408.03811">https://arxiv.org/pdf/2408.03811</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2408.03811]] Generative Language Models with Retrieval Augmented Generation for Automated Short Answer Scoring(https://arxiv.org/abs/2408.03811)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>Automated Short Answer Scoring (ASAS) is a critical component in educational assessment. While traditional ASAS systems relied on rule-based algorithms or complex deep learning methods, recent advancements in Generative Language Models (GLMs) offer new opportunities for improvement. This study explores the application of GLMs to ASAS, leveraging their off-the-shelf capabilities and performance in various domains. We propose a novel pipeline that combines vector databases, transformer-based encoders, and GLMs to enhance short answer scoring accuracy. Our approach stores training responses in a vector database, retrieves semantically similar responses during inference, and employs a GLM to analyze these responses and determine appropriate scores. We further optimize the system through fine-tuned retrieval processes and prompt engineering. Evaluation on the SemEval 2013 dataset demonstrates a significant improvement on the SCIENTSBANK 3-way and 2-way tasks compared to existing methods, highlighting the potential of GLMs in advancing ASAS technology.</li>
</ul>

<h3>Title: PackMamba: Efficient Processing of Variable-Length Sequences in Mamba training</h3>
<ul>
<li><strong>Authors: </strong>Haoran Xu, Ziqian Liu, Rong Fu, Zhongling Su, Zerui Wang, Zheng Cai, Zhilin Pei, Xingcheng Zhang</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2408.03865">https://arxiv.org/abs/2408.03865</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2408.03865">https://arxiv.org/pdf/2408.03865</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2408.03865]] PackMamba: Efficient Processing of Variable-Length Sequences in Mamba training(https://arxiv.org/abs/2408.03865)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>With the evolution of large language models, traditional Transformer models become computationally demanding for lengthy sequences due to the quadratic growth in computation with respect to the sequence length. Mamba, emerging as a groundbreaking architecture in the field of generative AI, demonstrates remarkable proficiency in handling elongated sequences with reduced computational and memory complexity. Nevertheless, the existing training framework of Mamba presents inefficiency with variable-length sequence inputs. Either single-sequence training results in low GPU utilization, or batched processing of variable-length sequences to a maximum length incurs considerable memory and computational overhead. To address this problem, we analyze the performance of bottleneck operators in Mamba under diverse tensor shapes and proposed PackMamba, a high-throughput Mamba that efficiently handles variable-length sequences. Diving deep into state-space models (SSMs), we modify the parallel operators to avoid passing information between individual sequences while maintaining high performance. Experimental results on an NVIDIA A100 GPU demonstrate throughput exceeding the baseline single-sequence processing scheme: 3.06x speedup on the 1.4B model and 2.62x on the 2.8B model.</li>
</ul>

<h3>Title: Knowledge Probing for Graph Representation Learning</h3>
<ul>
<li><strong>Authors: </strong>Mingyu Zhao, Xingyu Huang, Ziyu Lyu, Yanlin Wang, Lixin Cui, Lu Bai</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2408.03877">https://arxiv.org/abs/2408.03877</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2408.03877">https://arxiv.org/pdf/2408.03877</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2408.03877]] Knowledge Probing for Graph Representation Learning(https://arxiv.org/abs/2408.03877)</code><input type="text"></li>
<li><strong>Keywords: </strong>self-supervised</a></li>
<li><strong>Abstract: </strong>Graph learning methods have been extensively applied in diverse application areas. However, what kind of inherent graph properties e.g. graph proximity, graph structural information has been encoded into graph representation learning for downstream tasks is still under-explored. In this paper, we propose a novel graph probing framework (GraphProbe) to investigate and interpret whether the family of graph learning methods has encoded different levels of knowledge in graph representation learning. Based on the intrinsic properties of graphs, we design three probes to systematically investigate the graph representation learning process from different perspectives, respectively the node-wise level, the path-wise level, and the structural level. We construct a thorough evaluation benchmark with nine representative graph learning methods from random walk based approaches, basic graph neural networks and self-supervised graph methods, and probe them on six benchmark datasets for node classification, link prediction and graph classification. The experimental evaluation verify that GraphProbe can estimate the capability of graph representation learning. Remaking results have been concluded: GCN and WeightedGCN methods are relatively versatile methods achieving better results with respect to different tasks.</li>
</ul>

<h3>Title: Dual-Modeling Decouple Distillation for Unsupervised Anomaly Detection</h3>
<ul>
<li><strong>Authors: </strong>Xinyue Liu, Jianyuan Wang, Biao Leng, Shuo Zhang</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2408.03888">https://arxiv.org/abs/2408.03888</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2408.03888">https://arxiv.org/pdf/2408.03888</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2408.03888]] Dual-Modeling Decouple Distillation for Unsupervised Anomaly Detection(https://arxiv.org/abs/2408.03888)</code><input type="text"></li>
<li><strong>Keywords: </strong>anomaly</a></li>
<li><strong>Abstract: </strong>Knowledge distillation based on student-teacher network is one of the mainstream solution paradigms for the challenging unsupervised Anomaly Detection task, utilizing the difference in representation capabilities of the teacher and student networks to implement anomaly localization. However, over-generalization of the student network to the teacher network may lead to negligible differences in representation capabilities of anomaly, thus affecting the detection effectiveness. Existing methods address the possible over-generalization by using differentiated students and teachers from the structural perspective or explicitly expanding distilled information from the content perspective, which inevitably result in an increased likelihood of underfitting of the student network and poor anomaly detection capabilities in anomaly center or edge. In this paper, we propose Dual-Modeling Decouple Distillation (DMDD) for the unsupervised anomaly detection. In DMDD, a Decouple Student-Teacher Network is proposed to decouple the initial student features into normality and abnormality features. We further introduce Dual-Modeling Distillation based on normal-anomaly image pairs, fitting normality features of anomalous image and the teacher features of the corresponding normal image, widening the distance between abnormality features and the teacher features in anomalous regions. Synthesizing these two distillation ideas, we achieve anomaly detection which focuses on both edge and center of anomaly. Finally, a Multi-perception Segmentation Network is proposed to achieve focused anomaly map fusion based on multiple attention. Experimental results on MVTec AD show that DMDD surpasses SOTA localization performance of previous knowledge distillation-based methods, reaching 98.85% on pixel-level AUC and 96.13% on PRO.</li>
</ul>

<h3>Title: Speech-MASSIVE: A Multilingual Speech Dataset for SLU and Beyond</h3>
<ul>
<li><strong>Authors: </strong>Beomseok Lee, Ioan Calapodescu, Marco Gaido, Matteo Negri, Laurent Besacier</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.SD, eess.AS</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2408.03900">https://arxiv.org/abs/2408.03900</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2408.03900">https://arxiv.org/pdf/2408.03900</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2408.03900]] Speech-MASSIVE: A Multilingual Speech Dataset for SLU and Beyond(https://arxiv.org/abs/2408.03900)</code><input type="text"></li>
<li><strong>Keywords: </strong>foundation model</a></li>
<li><strong>Abstract: </strong>We present Speech-MASSIVE, a multilingual Spoken Language Understanding (SLU) dataset comprising the speech counterpart for a portion of the MASSIVE textual corpus. Speech-MASSIVE covers 12 languages from different families and inherits from MASSIVE the annotations for the intent prediction and slot-filling tasks. Our extension is prompted by the scarcity of massively multilingual SLU datasets and the growing need for versatile speech datasets to assess foundation models (LLMs, speech encoders) across languages and tasks. We provide a multimodal, multitask, multilingual dataset and report SLU baselines using both cascaded and end-to-end architectures in various training scenarios (zero-shot, few-shot, and full fine-tune). Furthermore, we demonstrate the suitability of Speech-MASSIVE for benchmarking other tasks such as speech transcription, language identification, and speech translation. The dataset, models, and code are publicly available at: this https URL</li>
</ul>

<button id="copy">Copy All</button>
</article>
<script src="../../javascript/clipboard.min.js"></script>
<script src="../../javascript/clipboard.js"></script>
