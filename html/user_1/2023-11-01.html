<link rel="stylesheet" href="../../css/markdown.css" />
<article class="markdown-body">
<h2>diffusion</h2>
<h3>Title: Battle of the Backbones: A Large-Scale Comparison of Pretrained Models across Computer Vision Tasks. (arXiv:2310.19909v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.19909">http://arxiv.org/abs/2310.19909</a></li>
<li>Code URL: https://github.com/hsouri/battle-of-the-backbones</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.19909]] Battle of the Backbones: A Large-Scale Comparison of Pretrained Models across Computer Vision Tasks(http://arxiv.org/abs/2310.19909)</code></li>
<li>Summary: <p>Neural network based computer vision systems are typically built on a
backbone, a pretrained or randomly initialized feature extractor. Several years
ago, the default option was an ImageNet-trained convolutional neural network.
However, the recent past has seen the emergence of countless backbones
pretrained using various algorithms and datasets. While this abundance of
choice has led to performance increases for a range of systems, it is difficult
for practitioners to make informed decisions about which backbone to choose.
Battle of the Backbones (BoB) makes this choice easier by benchmarking a
diverse suite of pretrained models, including vision-language models, those
trained via self-supervised learning, and the Stable Diffusion backbone, across
a diverse set of computer vision tasks ranging from classification to object
detection to OOD generalization and more. Furthermore, BoB sheds light on
promising directions for the research community to advance computer vision by
illuminating strengths and weakness of existing approaches through a
comprehensive analysis conducted on more than 1500 training runs. While vision
transformers (ViTs) and self-supervised learning (SSL) are increasingly
popular, we find that convolutional neural networks pretrained in a supervised
fashion on large training sets still perform best on most tasks among the
models we consider. Moreover, in apples-to-apples comparisons on the same
architectures and similarly sized pretraining datasets, we find that SSL
backbones are highly competitive, indicating that future works should perform
SSL pretraining with advanced architectures and larger pretraining datasets. We
release the raw results of our experiments along with code that allows
researchers to put their own backbones through the gauntlet here:
https://github.com/hsouri/Battle-of-the-Backbones
</p></li>
</ul>

<h3>Title: 'Person' == Light-skinned, Western Man, and Sexualization of Women of Color: Stereotypes in Stable Diffusion. (arXiv:2310.19981v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.19981">http://arxiv.org/abs/2310.19981</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.19981]] 'Person' == Light-skinned, Western Man, and Sexualization of Women of Color: Stereotypes in Stable Diffusion(http://arxiv.org/abs/2310.19981)</code></li>
<li>Summary: <p>We study stereotypes embedded within one of the most popular text-to-image
generators: Stable Diffusion. We examine what stereotypes of gender and
nationality/continental identity does Stable Diffusion display in the absence
of such information i.e. what gender and nationality/continental identity is
assigned to `a person', or to `a person from Asia'. Using vision-language model
CLIP's cosine similarity to compare images generated by CLIP-based Stable
Diffusion v2.1 verified by manual examination, we chronicle results from 136
prompts (50 results/prompt) of front-facing images of persons from 6 different
continents, 27 nationalities and 3 genders. We observe how Stable Diffusion
outputs of `a person' without any additional gender/nationality information
correspond closest to images of men and least with persons of nonbinary gender,
and to persons from Europe/North America over Africa/Asia, pointing towards
Stable Diffusion having a concerning representation of personhood to be a
European/North American man. We also show continental stereotypes and resultant
harms e.g. a person from Oceania is deemed to be Australian/New Zealander over
Papua New Guinean, pointing to the erasure of Indigenous Oceanic peoples, who
form a majority over descendants of colonizers both in Papua New Guinea and in
Oceania overall. Finally, we unexpectedly observe a pattern of
oversexualization of women, specifically Latin American, Mexican, Indian and
Egyptian women relative to other nationalities, measured through an NSFW
detector. This demonstrates how Stable Diffusion perpetuates Western
fetishization of women of color through objectification in media, which if left
unchecked will amplify this stereotypical representation. Image datasets are
made publicly available.
</p></li>
</ul>

<h3>Title: Beyond U: Making Diffusion Models Faster & Lighter. (arXiv:2310.20092v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.20092">http://arxiv.org/abs/2310.20092</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.20092]] Beyond U: Making Diffusion Models Faster & Lighter(http://arxiv.org/abs/2310.20092)</code></li>
<li>Summary: <p>Diffusion models are a family of generative models that yield record-breaking
performance in tasks such as image synthesis, video generation, and molecule
design. Despite their capabilities, their efficiency, especially in the reverse
denoising process, remains a challenge due to slow convergence rates and high
computational costs. In this work, we introduce an approach that leverages
continuous dynamical systems to design a novel denoising network for diffusion
models that is more parameter-efficient, exhibits faster convergence, and
demonstrates increased noise robustness. Experimenting with denoising
probabilistic diffusion models, our framework operates with approximately a
quarter of the parameters and 30% of the Floating Point Operations (FLOPs)
compared to standard U-Nets in Denoising Diffusion Probabilistic Models
(DDPMs). Furthermore, our model is up to 70% faster in inference than the
baseline models when measured in equal conditions while converging to better
quality solutions.
</p></li>
</ul>

<h3>Title: SemanticBoost: Elevating Motion Generation with Augmented Textual Cues. (arXiv:2310.20323v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.20323">http://arxiv.org/abs/2310.20323</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.20323]] SemanticBoost: Elevating Motion Generation with Augmented Textual Cues(http://arxiv.org/abs/2310.20323)</code></li>
<li>Summary: <p>Current techniques face difficulties in generating motions from intricate
semantic descriptions, primarily due to insufficient semantic annotations in
datasets and weak contextual understanding. To address these issues, we present
SemanticBoost, a novel framework that tackles both challenges simultaneously.
Our framework comprises a Semantic Enhancement module and a Context-Attuned
Motion Denoiser (CAMD). The Semantic Enhancement module extracts supplementary
semantics from motion data, enriching the dataset's textual description and
ensuring precise alignment between text and motion data without depending on
large language models. On the other hand, the CAMD approach provides an
all-encompassing solution for generating high-quality, semantically consistent
motion sequences by effectively capturing context information and aligning the
generated motion with the given textual descriptions. Distinct from existing
methods, our approach can synthesize accurate orientational movements, combined
motions based on specific body part descriptions, and motions generated from
complex, extended sentences. Our experimental results demonstrate that
SemanticBoost, as a diffusion-based method, outperforms auto-regressive-based
techniques, achieving cutting-edge performance on the Humanml3D dataset while
maintaining realistic and smooth motion generation quality.
</p></li>
</ul>

<h3>Title: Learning Gradient Fields for Scalable and Generalizable Irregular Packing. (arXiv:2310.19814v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.19814">http://arxiv.org/abs/2310.19814</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.19814]] Learning Gradient Fields for Scalable and Generalizable Irregular Packing(http://arxiv.org/abs/2310.19814)</code></li>
<li>Summary: <p>The packing problem, also known as cutting or nesting, has diverse
applications in logistics, manufacturing, layout design, and atlas generation.
It involves arranging irregularly shaped pieces to minimize waste while
avoiding overlap. Recent advances in machine learning, particularly
reinforcement learning, have shown promise in addressing the packing problem.
In this work, we delve deeper into a novel machine learning-based approach that
formulates the packing problem as conditional generative modeling. To tackle
the challenges of irregular packing, including object validity constraints and
collision avoidance, our method employs the score-based diffusion model to
learn a series of gradient fields. These gradient fields encode the
correlations between constraint satisfaction and the spatial relationships of
polygons, learned from teacher examples. During the testing phase, packing
solutions are generated using a coarse-to-fine refinement mechanism guided by
the learned gradient fields. To enhance packing feasibility and optimality, we
introduce two key architectural designs: multi-scale feature extraction and
coarse-to-fine relation extraction. We conduct experiments on two typical
industrial packing domains, considering translations only. Empirically, our
approach demonstrates spatial utilization rates comparable to, or even
surpassing, those achieved by the teacher algorithm responsible for training
data generation. Additionally, it exhibits some level of generalization to
shape variations. We are hopeful that this method could pave the way for new
possibilities in solving the packing problem.
</p></li>
</ul>

<h3>Title: FuXi-Extreme: Improving extreme rainfall and wind forecasts with diffusion model. (arXiv:2310.19822v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.19822">http://arxiv.org/abs/2310.19822</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.19822]] FuXi-Extreme: Improving extreme rainfall and wind forecasts with diffusion model(http://arxiv.org/abs/2310.19822)</code></li>
<li>Summary: <p>Significant advancements in the development of machine learning (ML) models
for weather forecasting have produced remarkable results. State-of-the-art
ML-based weather forecast models, such as FuXi, have demonstrated superior
statistical forecast performance in comparison to the high-resolution forecasts
(HRES) of the European Centre for Medium-Range Weather Forecasts (ECMWF).
However, ML models face a common challenge: as forecast lead times increase,
they tend to generate increasingly smooth predictions, leading to an
underestimation of the intensity of extreme weather events. To address this
challenge, we developed the FuXi-Extreme model, which employs a denoising
diffusion probabilistic model (DDPM) to restore finer-scale details in the
surface forecast data generated by the FuXi model in 5-day forecasts. An
evaluation of extreme total precipitation ($\textrm{TP}$), 10-meter wind speed
($\textrm{WS10}$), and 2-meter temperature ($\textrm{T2M}$) illustrates the
superior performance of FuXi-Extreme over both FuXi and HRES. Moreover, when
evaluating tropical cyclone (TC) forecasts based on International Best Track
Archive for Climate Stewardship (IBTrACS) dataset, both FuXi and FuXi-Extreme
shows superior performance in TC track forecasts compared to HRES, but they
show inferior performance in TC intensity forecasts in comparison to HRES.
</p></li>
</ul>

<h3>Title: Scaling Riemannian Diffusion Models. (arXiv:2310.20030v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.20030">http://arxiv.org/abs/2310.20030</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.20030]] Scaling Riemannian Diffusion Models(http://arxiv.org/abs/2310.20030)</code></li>
<li>Summary: <p>Riemannian diffusion models draw inspiration from standard Euclidean space
diffusion models to learn distributions on general manifolds. Unfortunately,
the additional geometric complexity renders the diffusion transition term
inexpressible in closed form, so prior methods resort to imprecise
approximations of the score matching training objective that degrade
performance and preclude applications in high dimensions. In this work, we
reexamine these approximations and propose several practical improvements. Our
key observation is that most relevant manifolds are symmetric spaces, which are
much more amenable to computation. By leveraging and combining various
ans\"{a}tze, we can quickly compute relevant quantities to high precision. On
low dimensional datasets, our correction produces a noticeable improvement,
allowing diffusion to compete with other methods. Additionally, we show that
our method enables us to scale to high dimensional tasks on nontrivial
manifolds. In particular, we model QCD densities on $SU(n)$ lattices and
contrastively learned embeddings on high dimensional hyperspheres.
</p></li>
</ul>

<h2>self-supervised</h2>
<h3>Title: From Denoising Training to Test-Time Adaptation: Enhancing Domain Generalization for Medical Image Segmentation. (arXiv:2310.20271v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.20271">http://arxiv.org/abs/2310.20271</a></li>
<li>Code URL: https://github.com/wenruxue/detta</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.20271]] From Denoising Training to Test-Time Adaptation: Enhancing Domain Generalization for Medical Image Segmentation(http://arxiv.org/abs/2310.20271)</code></li>
<li>Summary: <p>In medical image segmentation, domain generalization poses a significant
challenge due to domain shifts caused by variations in data acquisition devices
and other factors. These shifts are particularly pronounced in the most common
scenario, which involves only single-source domain data due to privacy
concerns. To address this, we draw inspiration from the self-supervised
learning paradigm that effectively discourages overfitting to the source
domain. We propose the Denoising Y-Net (DeY-Net), a novel approach
incorporating an auxiliary denoising decoder into the basic U-Net architecture.
The auxiliary decoder aims to perform denoising training, augmenting the
domain-invariant representation that facilitates domain generalization.
Furthermore, this paradigm provides the potential to utilize unlabeled data.
Building upon denoising training, we propose Denoising Test Time Adaptation
(DeTTA) that further: (i) adapts the model to the target domain in a
sample-wise manner, and (ii) adapts to the noise-corrupted input. Extensive
experiments conducted on widely-adopted liver segmentation benchmarks
demonstrate significant domain generalization improvements over our baseline
and state-of-the-art results compared to other methods. Code is available at
https://github.com/WenRuxue/DeTTA.
</p></li>
</ul>

<h3>Title: Self-supervised Pre-training for Precipitation Post-processor. (arXiv:2310.20187v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.20187">http://arxiv.org/abs/2310.20187</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.20187]] Self-supervised Pre-training for Precipitation Post-processor(http://arxiv.org/abs/2310.20187)</code></li>
<li>Summary: <p>Securing sufficient forecast lead time for local precipitation is essential
for preventing hazardous weather events. Nonetheless, global warming-induced
climate change is adding to the challenge of accurately predicting severe
precipitation events, such as heavy rainfall. In this work, we propose a deep
learning-based precipitation post-processor approach to numerical weather
prediction (NWP) models. The precipitation post-processor consists of (i)
self-supervised pre-training, where parameters of encoder are pre-trained on
the reconstruction of masked variables of the atmospheric physics domain, and
(ii) transfer learning on precipitation segmentation tasks (target domain) from
the pre-trained encoder. We also introduce a heuristic labeling approach for
effectively training class-imbalanced datasets. Our experiment results in
precipitation correction for regional NWP show that the proposed method
outperforms other approaches.
</p></li>
</ul>

<h2>foundation model</h2>
<h3>Title: Res-Tuning: A Flexible and Efficient Tuning Paradigm via Unbinding Tuner from Backbone. (arXiv:2310.19859v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.19859">http://arxiv.org/abs/2310.19859</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.19859]] Res-Tuning: A Flexible and Efficient Tuning Paradigm via Unbinding Tuner from Backbone(http://arxiv.org/abs/2310.19859)</code></li>
<li>Summary: <p>Parameter-efficient tuning has become a trend in transferring large-scale
foundation models to downstream applications. Existing methods typically embed
some light-weight tuners into the backbone, where both the design and the
learning of the tuners are highly dependent on the base model. This work offers
a new tuning paradigm, dubbed Res-Tuning, which intentionally unbinds tuners
from the backbone. With both theoretical and empirical evidence, we show that
popular tuning approaches have their equivalent counterparts under our
unbinding formulation, and hence can be integrated into our framework
effortlessly. Thanks to the structural disentanglement, we manage to free the
design of tuners from the network architecture, facilitating flexible
combination of various tuning strategies. We further propose a memory-efficient
variant of Res-Tuning, where the bypass i.e., formed by a sequence of tuners)
is effectively detached from the main branch, such that the gradients are
back-propagated only to the tuners but not to the backbone. Such a detachment
also allows one-time backbone forward for multi-task inference. Extensive
experiments on both discriminative and generative tasks demonstrate the
superiority of our method over existing alternatives from the perspectives of
efficacy and efficiency. Project page:
$\href{https://res-tuning.github.io/}{\textit{https://res-tuning.github.io/}}$.
</p></li>
</ul>

<h3>Title: Deep Learning for Spatiotemporal Big Data: A Vision on Opportunities and Challenges. (arXiv:2310.19957v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.19957">http://arxiv.org/abs/2310.19957</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.19957]] Deep Learning for Spatiotemporal Big Data: A Vision on Opportunities and Challenges(http://arxiv.org/abs/2310.19957)</code></li>
<li>Summary: <p>With advancements in GPS, remote sensing, and computational simulation, an
enormous volume of spatiotemporal data is being collected at an increasing
speed from various application domains, spanning Earth sciences, agriculture,
smart cities, and public safety. Such emerging geospatial and spatiotemporal
big data, coupled with recent advances in deep learning technologies, foster
new opportunities to solve problems that have not been possible before. For
instance, remote sensing researchers can potentially train a foundation model
using Earth imagery big data for numerous land cover and land use modeling
tasks. Coastal modelers can train AI surrogates to speed up numerical
simulations. However, the distinctive characteristics of spatiotemporal big
data pose new challenges for deep learning technologies. This vision paper
introduces various types of spatiotemporal big data, discusses new research
opportunities in the realm of deep learning applied to spatiotemporal big data,
lists the unique challenges, and identifies several future research needs.
</p></li>
</ul>

<h3>Title: ExPT: Synthetic Pretraining for Few-Shot Experimental Design. (arXiv:2310.19961v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.19961">http://arxiv.org/abs/2310.19961</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.19961]] ExPT: Synthetic Pretraining for Few-Shot Experimental Design(http://arxiv.org/abs/2310.19961)</code></li>
<li>Summary: <p>Experimental design is a fundamental problem in many science and engineering
fields. In this problem, sample efficiency is crucial due to the time, money,
and safety costs of real-world design evaluations. Existing approaches either
rely on active data collection or access to large, labeled datasets of past
experiments, making them impractical in many real-world scenarios. In this
work, we address the more challenging yet realistic setting of few-shot
experimental design, where only a few labeled data points of input designs and
their corresponding values are available. We approach this problem as a
conditional generation task, where a model conditions on a few labeled examples
and the desired output to generate an optimal input design. To this end, we
introduce Experiment Pretrained Transformers (ExPT), a foundation model for
few-shot experimental design that employs a novel combination of synthetic
pretraining with in-context learning. In ExPT, we only assume knowledge of a
finite collection of unlabelled data points from the input domain and pretrain
a transformer neural network to optimize diverse synthetic functions defined
over this domain. Unsupervised pretraining allows ExPT to adapt to any design
task at test time in an in-context fashion by conditioning on a few labeled
data points from the target task and generating the candidate optima. We
evaluate ExPT on few-shot experimental design in challenging domains and
demonstrate its superior generality and performance compared to existing
methods. The source code is available at https://github.com/tung-nd/ExPT.git.
</p></li>
</ul>

<h3>Title: AutoMixer for Improved Multivariate Time-Series Forecasting on BizITOps Data. (arXiv:2310.20280v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.20280">http://arxiv.org/abs/2310.20280</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.20280]] AutoMixer for Improved Multivariate Time-Series Forecasting on BizITOps Data(http://arxiv.org/abs/2310.20280)</code></li>
<li>Summary: <p>The efficiency of business processes relies on business key performance
indicators (Biz-KPIs), that can be negatively impacted by IT failures. BizITOps
data fuses both Biz-KPIs and IT event channels together as multivariate time
series data. Forecasting Biz-KPIs in advance can enhance efficiency and revenue
through proactive corrective measures. However, BizITOps data generally exhibit
both useful and noisy inter-channel interactions between Biz-KPIs and IT events
that need to be effectively decoupled. This leads to suboptimal forecasting
performance when existing multivariate forecasting models are employed. To
address this, we introduce AutoMixer, a time-series Foundation Model (FM)
approach, grounded on the novel technique of channel-compressed pretrain and
finetune workflows. AutoMixer leverages an AutoEncoder for channel-compressed
pretraining and integrates it with the advanced TSMixer model for multivariate
time series forecasting. This fusion greatly enhances the potency of TSMixer
for accurate forecasts and also generalizes well across several downstream
tasks. Through detailed experiments and dashboard analytics, we show
AutoMixer's capability to consistently improve the Biz-KPI's forecasting
accuracy (by 11-15%) which directly translates to actionable business insights.
</p></li>
</ul>

<h2>generative</h2>
<h3>Title: Addressing Weak Decision Boundaries in Image Classification by Leveraging Web Search and Generative Models. (arXiv:2310.19986v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.19986">http://arxiv.org/abs/2310.19986</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.19986]] Addressing Weak Decision Boundaries in Image Classification by Leveraging Web Search and Generative Models(http://arxiv.org/abs/2310.19986)</code></li>
<li>Summary: <p>Machine learning (ML) technologies are known to be riddled with ethical and
operational problems, however, we are witnessing an increasing thrust by
businesses to deploy them in sensitive applications. One major issue among many
is that ML models do not perform equally well for underrepresented groups. This
puts vulnerable populations in an even disadvantaged and unfavorable position.
We propose an approach that leverages the power of web search and generative
models to alleviate some of the shortcomings of discriminative models. We
demonstrate our method on an image classification problem using ImageNet's
People Subtree subset, and show that it is effective in enhancing robustness
and mitigating bias in certain classes that represent vulnerable populations
(e.g., female doctor of color). Our new method is able to (1) identify weak
decision boundaries for such classes; (2) construct search queries for Google
as well as text for generating images through DALL-E 2 and Stable Diffusion;
and (3) show how these newly captured training samples could alleviate
population bias issue. While still improving the model's overall performance
considerably, we achieve a significant reduction (77.30\%) in the model's
gender accuracy disparity. In addition to these improvements, we observed a
notable enhancement in the classifier's decision boundary, as it is
characterized by fewer weakspots and an increased separation between classes.
Although we showcase our method on vulnerable populations in this study, the
proposed technique is extendable to a wide range of problems and domains.
</p></li>
</ul>

<h3>Title: Visible to Thermal image Translation for improving visual task in low light conditions. (arXiv:2310.20190v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.20190">http://arxiv.org/abs/2310.20190</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.20190]] Visible to Thermal image Translation for improving visual task in low light conditions(http://arxiv.org/abs/2310.20190)</code></li>
<li>Summary: <p>Several visual tasks, such as pedestrian detection and image-to-image
translation, are challenging to accomplish in low light using RGB images. Heat
variation of objects in thermal images can be used to overcome this. In this
work, an end-to-end framework, which consists of a generative network and a
detector network, is proposed to translate RGB image into Thermal ones and
compare generated thermal images with real data. We have collected images from
two different locations using the Parrot Anafi Thermal drone. After that, we
created a two-stream network, preprocessed, augmented, the image data, and
trained the generator and discriminator models from scratch. The findings
demonstrate that it is feasible to translate RGB training data to thermal data
using GAN. As a result, thermal data can now be produced more quickly and
affordably, which is useful for security and surveillance applications.
</p></li>
</ul>

<h3>Title: Muscle volume quantification: guiding transformers with anatomical priors. (arXiv:2310.20355v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.20355">http://arxiv.org/abs/2310.20355</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.20355]] Muscle volume quantification: guiding transformers with anatomical priors(http://arxiv.org/abs/2310.20355)</code></li>
<li>Summary: <p>Muscle volume is a useful quantitative biomarker in sports, but also for the
follow-up of degenerative musculo-skelletal diseases. In addition to volume,
other shape biomarkers can be extracted by segmenting the muscles of interest
from medical images. Manual segmentation is still today the gold standard for
such measurements despite being very time-consuming. We propose a method for
automatic segmentation of 18 muscles of the lower limb on 3D Magnetic Resonance
Images to assist such morphometric analysis. By their nature, the tissue of
different muscles is undistinguishable when observed in MR Images. Thus, muscle
segmentation algorithms cannot rely on appearance but only on contour cues.
However, such contours are hard to detect and their thickness varies across
subjects. To cope with the above challenges, we propose a segmentation approach
based on a hybrid architecture, combining convolutional and visual transformer
blocks. We investigate for the first time the behaviour of such hybrid
architectures in the context of muscle segmentation for shape analysis.
Considering the consistent anatomical muscle configuration, we rely on
transformer blocks to capture the longrange relations between the muscles. To
further exploit the anatomical priors, a second contribution of this work
consists in adding a regularisation loss based on an adjacency matrix of
plausible muscle neighbourhoods estimated from the training data. Our
experimental results on a unique database of elite athletes show it is possible
to train complex hybrid models from a relatively small database of large
volumes, while the anatomical prior regularisation favours better predictions.
</p></li>
</ul>

<h3>Title: Generative retrieval-augmented ontologic graph and multi-agent strategies for interpretive large language model-based materials design. (arXiv:2310.19998v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.19998">http://arxiv.org/abs/2310.19998</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.19998]] Generative retrieval-augmented ontologic graph and multi-agent strategies for interpretive large language model-based materials design(http://arxiv.org/abs/2310.19998)</code></li>
<li>Summary: <p>Transformer neural networks show promising capabilities, in particular for
uses in materials analysis, design and manufacturing, including their capacity
to work effectively with both human language, symbols, code, and numerical
data. Here we explore the use of large language models (LLMs) as a tool that
can support engineering analysis of materials, applied to retrieving key
information about subject areas, developing research hypotheses, discovery of
mechanistic relationships across disparate areas of knowledge, and writing and
executing simulation codes for active knowledge generation based on physical
ground truths. When used as sets of AI agents with specific features,
capabilities, and instructions, LLMs can provide powerful problem solution
strategies for applications in analysis and design problems. Our experiments
focus on using a fine-tuned model, MechGPT, developed based on training data in
the mechanics of materials domain. We first affirm how finetuning endows LLMs
with reasonable understanding of domain knowledge. However, when queried
outside the context of learned matter, LLMs can have difficulty to recall
correct information. We show how this can be addressed using
retrieval-augmented Ontological Knowledge Graph strategies that discern how the
model understands what concepts are important and how they are related.
Illustrated for a use case of relating distinct areas of knowledge - here,
music and proteins - such strategies can also provide an interpretable graph
structure with rich information at the node, edge and subgraph level. We
discuss nonlinear sampling strategies and agent-based modeling applied to
complex question answering, code generation and execution in the context of
automated force field development from actively learned Density Functional
Theory (DFT) modeling, and data analysis.
</p></li>
</ul>

<h3>Title: Automatic Evaluation of Generative Models with Instruction Tuning. (arXiv:2310.20072v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.20072">http://arxiv.org/abs/2310.20072</a></li>
<li>Code URL: https://github.com/shuhaibm/heap</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.20072]] Automatic Evaluation of Generative Models with Instruction Tuning(http://arxiv.org/abs/2310.20072)</code></li>
<li>Summary: <p>Automatic evaluation of natural language generation has long been an elusive
goal in NLP.A recent paradigm fine-tunes pre-trained language models to emulate
human judgements for a particular task and evaluation criterion. Inspired by
the generalization ability of instruction-tuned models, we propose a learned
metric based on instruction tuning. To test our approach, we collected HEAP, a
dataset of human judgements across various NLG tasks and evaluation criteria.
Our findings demonstrate that instruction tuning language models on HEAP yields
good performance on many evaluation tasks, though some criteria are less
trivial to learn than others. Further, jointly training on multiple tasks can
yield additional performance improvements, which can be beneficial for future
tasks with little to no human annotated data.
</p></li>
</ul>

<h3>Title: Generating Continuations in Multilingual Idiomatic Contexts. (arXiv:2310.20195v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.20195">http://arxiv.org/abs/2310.20195</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.20195]] Generating Continuations in Multilingual Idiomatic Contexts(http://arxiv.org/abs/2310.20195)</code></li>
<li>Summary: <p>The ability to process idiomatic or literal multiword expressions is a
crucial aspect of understanding and generating any language. The task of
generating contextually relevant continuations for narratives containing
idiomatic (or literal) expressions can allow us to test the ability of
generative language models (LMs) in understanding nuanced language containing
non-compositional figurative text. We conduct a series of experiments using
datasets in two distinct languages (English and Portuguese) under three
different training settings (zero-shot, few-shot, and fine-tuned). Our results
suggest that the models are only slightly better at generating continuations
for literal contexts than idiomatic contexts, with exceedingly small margins.
Furthermore, the models studied in this work perform equally well across both
languages, indicating the robustness of generative models in performing this
task.
</p></li>
</ul>

<h3>Title: Stochastic Thermodynamics of Learning Generative Parametric Probabilistic Models. (arXiv:2310.19802v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.19802">http://arxiv.org/abs/2310.19802</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.19802]] Stochastic Thermodynamics of Learning Generative Parametric Probabilistic Models(http://arxiv.org/abs/2310.19802)</code></li>
<li>Summary: <p>We have formulated generative machine learning problems as the time evolution
of Parametric Probabilistic Models (PPMs), inherently rendering a thermodynamic
process. Then, we have studied the thermodynamic exchange between the model's
parameters, denoted as $\Theta$, and the model's generated samples, denoted as
$X$. We demonstrate that the training dataset and the action of the Stochastic
Gradient Descent (SGD) optimizer serve as a work source that governs the time
evolution of these two subsystems. Our findings reveal that the model learns
through the dissipation of heat during the generation of samples $X$, leading
to an increase in the entropy of the model's parameters, $\Theta$. Thus, the
parameter subsystem acts as a heat reservoir, effectively storing the learned
information. Furthermore, the role of the model's parameters as a heat
reservoir provides valuable thermodynamic insights into the generalization
power of over-parameterized models. This approach offers an unambiguous
framework for computing information-theoretic quantities within deterministic
neural networks by establishing connections with thermodynamic variables. To
illustrate the utility of this framework, we introduce two
information-theoretic metrics: Memorized-information (M-info) and
Learned-information (L-info), which trace the dynamic flow of information
during the learning process of PPMs.
</p></li>
</ul>

<h3>Title: Model-Based Reparameterization Policy Gradient Methods: Theory and Practical Algorithms. (arXiv:2310.19927v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.19927">http://arxiv.org/abs/2310.19927</a></li>
<li>Code URL: https://github.com/agentification/rp_pgm</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.19927]] Model-Based Reparameterization Policy Gradient Methods: Theory and Practical Algorithms(http://arxiv.org/abs/2310.19927)</code></li>
<li>Summary: <p>ReParameterization (RP) Policy Gradient Methods (PGMs) have been widely
adopted for continuous control tasks in robotics and computer graphics.
However, recent studies have revealed that, when applied to long-term
reinforcement learning problems, model-based RP PGMs may experience chaotic and
non-smooth optimization landscapes with exploding gradient variance, which
leads to slow convergence. This is in contrast to the conventional belief that
reparameterization methods have low gradient estimation variance in problems
such as training deep generative models. To comprehend this phenomenon, we
conduct a theoretical examination of model-based RP PGMs and search for
solutions to the optimization difficulties. Specifically, we analyze the
convergence of the model-based RP PGMs and pinpoint the smoothness of function
approximators as a major factor that affects the quality of gradient
estimation. Based on our analysis, we propose a spectral normalization method
to mitigate the exploding variance issue caused by long model unrolls. Our
experimental results demonstrate that proper normalization significantly
reduces the gradient variance of model-based RP PGMs. As a result, the
performance of the proposed method is comparable or superior to other gradient
estimators, such as the Likelihood Ratio (LR) gradient estimator. Our code is
available at https://github.com/agentification/RP_PGM.
</p></li>
</ul>

<h3>Title: The Acquisition of Physical Knowledge in Generative Neural Networks. (arXiv:2310.19943v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.19943">http://arxiv.org/abs/2310.19943</a></li>
<li>Code URL: https://github.com/cross32768/PlaNet_PyTorch</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.19943]] The Acquisition of Physical Knowledge in Generative Neural Networks(http://arxiv.org/abs/2310.19943)</code></li>
<li>Summary: <p>As children grow older, they develop an intuitive understanding of the
physical processes around them. Their physical understanding develops in
stages, moving along developmental trajectories which have been mapped out
extensively in previous empirical research. Here, we investigate how the
learning trajectories of deep generative neural networks compare to children's
developmental trajectories using physical understanding as a testbed. We
outline an approach that allows us to examine two distinct hypotheses of human
development - stochastic optimization and complexity increase. We find that
while our models are able to accurately predict a number of physical processes,
their learning trajectories under both hypotheses do not follow the
developmental trajectories of children.
</p></li>
</ul>

<h3>Title: GOPlan: Goal-conditioned Offline Reinforcement Learning by Planning with Learned Models. (arXiv:2310.20025v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.20025">http://arxiv.org/abs/2310.20025</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.20025]] GOPlan: Goal-conditioned Offline Reinforcement Learning by Planning with Learned Models(http://arxiv.org/abs/2310.20025)</code></li>
<li>Summary: <p>Offline goal-conditioned RL (GCRL) offers a feasible paradigm to learn
general-purpose policies from diverse and multi-task offline datasets. Despite
notable recent progress, the predominant offline GCRL methods have been
restricted to model-free approaches, constraining their capacity to tackle
limited data budgets and unseen goal generalization. In this work, we propose a
novel two-stage model-based framework, Goal-conditioned Offline Planning
(GOPlan), including (1) pretraining a prior policy capable of capturing
multi-modal action distribution within the multi-goal dataset; (2) employing
the reanalysis method with planning to generate imagined trajectories for
funetuning policies. Specifically, the prior policy is based on an
advantage-weighted Conditioned Generative Adversarial Networks that exhibits
distinct mode separation to overcome the pitfalls of out-of-distribution (OOD)
actions. For further policy optimization, the reanalysis method generates
high-quality imaginary data by planning with learned models for both
intra-trajectory and inter-trajectory goals. Through experimental evaluations,
we demonstrate that GOPlan achieves state-of-the-art performance on various
offline multi-goal manipulation tasks. Moreover, our results highlight the
superior ability of GOPlan to handle small data budgets and generalize to OOD
goals.
</p></li>
</ul>

<h3>Title: Advancing Bayesian Optimization via Learning Correlated Latent Space. (arXiv:2310.20258v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.20258">http://arxiv.org/abs/2310.20258</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.20258]] Advancing Bayesian Optimization via Learning Correlated Latent Space(http://arxiv.org/abs/2310.20258)</code></li>
<li>Summary: <p>Bayesian optimization is a powerful method for optimizing black-box functions
with limited function evaluations. Recent works have shown that optimization in
a latent space through deep generative models such as variational autoencoders
leads to effective and efficient Bayesian optimization for structured or
discrete data. However, as the optimization does not take place in the input
space, it leads to an inherent gap that results in potentially suboptimal
solutions. To alleviate the discrepancy, we propose Correlated latent space
Bayesian Optimization (CoBO), which focuses on learning correlated latent
spaces characterized by a strong correlation between the distances in the
latent space and the distances within the objective function. Specifically, our
method introduces Lipschitz regularization, loss weighting, and trust region
recoordination to minimize the inherent gap around the promising areas. We
demonstrate the effectiveness of our approach on several optimization tasks in
discrete data, such as molecule design and arithmetic expression fitting, and
achieve high performance within a small budget.
</p></li>
</ul>

<h2>anomaly</h2>
<h3>Title: A Low-cost Strategic Monitoring Approach for Scalable and Interpretable Error Detection in Deep Neural Networks. (arXiv:2310.20349v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.20349">http://arxiv.org/abs/2310.20349</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.20349]] A Low-cost Strategic Monitoring Approach for Scalable and Interpretable Error Detection in Deep Neural Networks(http://arxiv.org/abs/2310.20349)</code></li>
<li>Summary: <p>We present a highly compact run-time monitoring approach for deep computer
vision networks that extracts selected knowledge from only a few (down to
merely two) hidden layers, yet can efficiently detect silent data corruption
originating from both hardware memory and input faults. Building on the insight
that critical faults typically manifest as peak or bulk shifts in the
activation distribution of the affected network layers, we use strategically
placed quantile markers to make accurate estimates about the anomaly of the
current inference as a whole. Importantly, the detector component itself is
kept algorithmically transparent to render the categorization of regular and
abnormal behavior interpretable to a human. Our technique achieves up to ~96%
precision and ~98% recall of detection. Compared to state-of-the-art anomaly
detection techniques, this approach requires minimal compute overhead (as
little as 0.3% with respect to non-supervised inference time) and contributes
to the explainability of the model.
</p></li>
</ul>

<h2>in-context</h2>
<h3>Title: Which Examples to Annotate for In-Context Learning? Towards Effective and Efficient Selection. (arXiv:2310.20046v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.20046">http://arxiv.org/abs/2310.20046</a></li>
<li>Code URL: https://github.com/amazon-science/adaptive-in-context-learning</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.20046]] Which Examples to Annotate for In-Context Learning? Towards Effective and Efficient Selection(http://arxiv.org/abs/2310.20046)</code></li>
<li>Summary: <p>Large Language Models (LLMs) can adapt to new tasks via in-context learning
(ICL). ICL is efficient as it does not require any parameter updates to the
trained LLM, but only few annotated examples as input for the LLM. In this
work, we investigate an active learning approach for ICL, where there is a
limited budget for annotating examples. We propose a model-adaptive
optimization-free algorithm, termed AdaICL, which identifies examples that the
model is uncertain about, and performs semantic diversity-based example
selection. Diversity-based sampling improves overall effectiveness, while
uncertainty sampling improves budget efficiency and helps the LLM learn new
information. Moreover, AdaICL poses its sampling strategy as a Maximum Coverage
problem, that dynamically adapts based on the model's feedback and can be
approximately solved via greedy algorithms. Extensive experiments on nine
datasets and seven LLMs show that AdaICL improves performance by 4.4% accuracy
points over SOTA (7.7% relative improvement), is up to 3x more budget-efficient
than performing annotations uniformly at random, while it outperforms SOTA with
2x fewer ICL examples.
</p></li>
</ul>

<h3>Title: Interactive Multi-fidelity Learning for Cost-effective Adaptation of Language Model with Sparse Human Supervision. (arXiv:2310.20153v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.20153">http://arxiv.org/abs/2310.20153</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.20153]] Interactive Multi-fidelity Learning for Cost-effective Adaptation of Language Model with Sparse Human Supervision(http://arxiv.org/abs/2310.20153)</code></li>
<li>Summary: <p>Large language models (LLMs) have demonstrated remarkable capabilities in
various tasks. However, their suitability for domain-specific tasks, is limited
due to their immense scale at deployment, susceptibility to misinformation, and
more importantly, high data annotation costs. We propose a novel Interactive
Multi-Fidelity Learning (IMFL) framework for the cost-effective development of
small domain-specific LMs under limited annotation budgets. Our approach
formulates the domain-specific fine-tuning process as a multi-fidelity learning
problem, focusing on identifying the optimal acquisition strategy that balances
between low-fidelity automatic LLM annotations and high-fidelity human
annotations to maximize model performance. We further propose an
exploration-exploitation query strategy that enhances annotation diversity and
informativeness, incorporating two innovative designs: 1) prompt retrieval that
selects in-context examples from human-annotated samples to improve LLM
annotation, and 2) variable batch size that controls the order for choosing
each fidelity to facilitate knowledge distillation, ultimately enhancing
annotation quality. Extensive experiments on financial and medical tasks
demonstrate that IMFL achieves superior performance compared with single
fidelity annotations. Given a limited budget of human annotation, IMFL
significantly outperforms the human annotation baselines in all four tasks and
achieves very close performance as human annotations on two of the tasks. These
promising results suggest that the high human annotation costs in
domain-specific tasks can be significantly reduced by employing IMFL, which
utilizes fewer human annotations, supplemented with cheaper and faster LLM
(e.g., GPT-3.5) annotations to achieve comparable performance.
</p></li>
</ul>

<button id="copy">Copy All</button>
</article>
<script src="https://cdn.staticfile.org/clipboard.js/2.0.4/clipboard.min.js"></script>
<script src="../../javascript/clipboard.js"></script>
