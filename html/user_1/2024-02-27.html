<link rel="stylesheet" href="../../css/markdown.css" />
<article class="markdown-body">
<h1>2024-02-27</h1>
<h3>Title: Large Scale Generative AI Text Applied to Sports and Music</h3>
<ul>
<li><strong>Authors: </strong>Aaron Baughman, Stephen Hammer, Rahul Agarwal, Gozde Akay, Eduardo Morales, Tony Johnson, Leonid Karlinsky, Rogerio Feris</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.15514">https://arxiv.org/abs/2402.15514</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.15514">https://arxiv.org/pdf/2402.15514</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.15514]] Large Scale Generative AI Text Applied to Sports and Music(https://arxiv.org/abs/2402.15514)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>We address the problem of scaling up the production of media content, including commentary and personalized news stories, for large-scale sports and music events worldwide. Our approach relies on generative AI models to transform a large volume of multimodal data (e.g., videos, articles, real-time scoring feeds, statistics, and fact sheets) into coherent and fluent text. Based on this approach, we introduce, for the first time, an AI commentary system, which was deployed to produce automated narrations for highlight packages at the 2023 US Open, Wimbledon, and Masters tournaments. In the same vein, our solution was extended to create personalized content for ESPN Fantasy Football and stories about music artists for the Grammy awards. These applications were built using a common software architecture achieved a 15x speed improvement with an average Rouge-L of 82.00 and perplexity of 6.6. Our work was successfully deployed at the aforementioned events, supporting 90 million fans around the world with 8 billion page views, continuously pushing the bounds on what is possible at the intersection of sports, entertainment, and AI.</li>
</ul>

<h3>Title: Detecting misinformation through Framing Theory: the Frame Element-based  Model</h3>
<ul>
<li><strong>Authors: </strong>Guan Wang, Rebecca Frederick, Jinglong Duan, William Wong, Verica Rupar, Weihua Li, Quan Bai</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.CY</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.15525">https://arxiv.org/abs/2402.15525</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.15525">https://arxiv.org/pdf/2402.15525</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.15525]] Detecting misinformation through Framing Theory: the Frame Element-based  Model(https://arxiv.org/abs/2402.15525)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>In this paper, we delve into the rapidly evolving challenge of misinformation detection, with a specific focus on the nuanced manipulation of narrative frames - an under-explored area within the AI community. The potential for Generative AI models to generate misleading narratives underscores the urgency of this problem. Drawing from communication and framing theories, we posit that the presentation or 'framing' of accurate information can dramatically alter its interpretation, potentially leading to misinformation. We highlight this issue through real-world examples, demonstrating how shifts in narrative frames can transmute fact-based information into misinformation. To tackle this challenge, we propose an innovative approach leveraging the power of pre-trained Large Language Models and deep neural networks to detect misinformation originating from accurate facts portrayed under different frames. These advanced AI techniques offer unprecedented capabilities in identifying complex patterns within unstructured data critical for examining the subtleties of narrative frames. The objective of this paper is to bridge a significant research gap in the AI domain, providing valuable insights and methodologies for tackling framing-induced misinformation, thus contributing to the advancement of responsible and trustworthy AI technologies. Several experiments are intensively conducted and experimental results explicitly demonstrate the various impact of elements of framing theory proving the rationale of applying framing theory to increase the performance in misinformation detection.</li>
</ul>

<h3>Title: Evaluating the Performance of ChatGPT for Spam Email Detection</h3>
<ul>
<li><strong>Authors: </strong>Yuwei Wu, Shijing Si, Yugui Zhang, Jiawen Gu, Jedrek Wosik</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.CY, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.15537">https://arxiv.org/abs/2402.15537</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.15537">https://arxiv.org/pdf/2402.15537</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.15537]] Evaluating the Performance of ChatGPT for Spam Email Detection(https://arxiv.org/abs/2402.15537)</code><input type="text"></li>
<li><strong>Keywords: </strong>in-context</a></li>
<li><strong>Abstract: </strong>Email continues to be a pivotal and extensively utilized communication medium within professional and commercial domains. Nonetheless, the prevalence of spam emails poses a significant challenge for users, disrupting their daily routines and diminishing productivity. Consequently, accurately identifying and filtering spam based on content has become crucial for cybersecurity. Recent advancements in natural language processing, particularly with large language models like ChatGPT, have shown remarkable performance in tasks such as question answering and text generation. However, its potential in spam identification remains underexplored. To fill in the gap, this study attempts to evaluate ChatGPT's capabilities for spam identification in both English and Chinese email datasets. We employ ChatGPT for spam email detection using in-context learning, which requires a prompt instruction and a few demonstrations. We also investigate how the training example size affects the performance of ChatGPT. For comparison, we also implement five popular benchmark methods, including naive Bayes, support vector machines (SVM), logistic regression (LR), feedforward dense neural networks (DNN), and BERT classifiers. Though extensive experiments, the performance of ChatGPT is significantly worse than deep supervised learning methods in the large English dataset, while it presents superior performance on the low-resourced Chinese dataset, even outperforming BERT in this case.</li>
</ul>

<h3>Title: Foundation Policies with Hilbert Representations</h3>
<ul>
<li><strong>Authors: </strong>Seohong Park, Tobias Kreiman, Sergey Levine</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.RO</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.15567">https://arxiv.org/abs/2402.15567</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.15567">https://arxiv.org/pdf/2402.15567</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.15567]] Foundation Policies with Hilbert Representations(https://arxiv.org/abs/2402.15567)</code><input type="text"></li>
<li><strong>Keywords: </strong>self-supervised</a></li>
<li><strong>Abstract: </strong>Unsupervised and self-supervised objectives, such as next token prediction, have enabled pre-training generalist models from large amounts of unlabeled data. In reinforcement learning (RL), however, finding a truly general and scalable unsupervised pre-training objective for generalist policies from offline data remains a major open question. While a number of methods have been proposed to enable generic self-supervised RL, based on principles such as goal-conditioned RL, behavioral cloning, and unsupervised skill learning, such methods remain limited in terms of either the diversity of the discovered behaviors, the need for high-quality demonstration data, or the lack of a clear prompting or adaptation mechanism for downstream tasks. In this work, we propose a novel unsupervised framework to pre-train generalist policies that capture diverse, optimal, long-horizon behaviors from unlabeled offline data such that they can be quickly adapted to any arbitrary new tasks in a zero-shot manner. Our key insight is to learn a structured representation that preserves the temporal structure of the underlying environment, and then to span this learned latent space with directional movements, which enables various zero-shot policy "prompting" schemes for downstream tasks. Through our experiments on simulated robotic locomotion and manipulation benchmarks, we show that our unsupervised policies can solve goal-conditioned and general RL tasks in a zero-shot fashion, even often outperforming prior methods designed specifically for each setting. Our code and videos are available at https://seohong.me/projects/hilp/</li>
</ul>

<h3>Title: Self-Supervised Pre-Training for Table Structure Recognition Transformer</h3>
<ul>
<li><strong>Authors: </strong>ShengYun Peng, Seongmin Lee, Xiaojing Wang, Rajarajeswari Balasubramaniyan, Duen Horng Chau</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.15578">https://arxiv.org/abs/2402.15578</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.15578">https://arxiv.org/pdf/2402.15578</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.15578]] Self-Supervised Pre-Training for Table Structure Recognition Transformer(https://arxiv.org/abs/2402.15578)</code><input type="text"></li>
<li><strong>Keywords: </strong>self-supervised</a></li>
<li><strong>Abstract: </strong>Table structure recognition (TSR) aims to convert tabular images into a machine-readable format. Although hybrid convolutional neural network (CNN)-transformer architecture is widely used in existing approaches, linear projection transformer has outperformed the hybrid architecture in numerous vision tasks due to its simplicity and efficiency. However, existing research has demonstrated that a direct replacement of CNN backbone with linear projection leads to a marked performance drop. In this work, we resolve the issue by proposing a self-supervised pre-training (SSP) method for TSR transformers. We discover that the performance gap between the linear projection transformer and the hybrid CNN-transformer can be mitigated by SSP of the visual encoder in the TSR model. We conducted reproducible ablation studies and open-sourced our code at https://github.com/poloclub/unitable to enhance transparency, inspire innovations, and facilitate fair comparisons in our domain as tables are a promising modality for representation learning.</li>
</ul>

<h3>Title: CI w/o TN: Context Injection without Task Name for Procedure Planning</h3>
<ul>
<li><strong>Authors: </strong>Xinjie Li</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.15579">https://arxiv.org/abs/2402.15579</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.15579">https://arxiv.org/pdf/2402.15579</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.15579]] CI w/o TN: Context Injection without Task Name for Procedure Planning(https://arxiv.org/abs/2402.15579)</code><input type="text"></li>
<li><strong>Keywords: </strong>foundation model</a></li>
<li><strong>Abstract: </strong>This paper explores the challenge of procedure planning in instructional videos, which involves creating goal-directed plans based on visual start and goal observations from videos. Previous research has tackled this problem with gradually weaker training supervision, from heavy intermediate visual observations or language instructions to task class supervision. However, with the advent of large language models, even given only the task name, these models can produce a detailed plan. In this study, we propose a much weaker setting without task name as supervision, which is not currently solvable by existing large language models since they require good prompts with sufficient information. Specifically, we hypothesize that previous intermediate supervisions can serve as context information, and we use captions of visual start and goal observations as a much cheaper form of supervision. This approach greatly reduces the labeling cost since the captions can be easily obtained by large pre-trained vision-language foundation models. Technically, we apply BLIP to generate captions as supervision to train the context feature with contrastive learning loss. Afterward, the context feature is fed into the generator to aid in plan generation. Our experiments on two datasets with varying scales demonstrate that our model can achieve comparable performance on multiple metrics, which validates our hypothesis.</li>
</ul>

<h3>Title: A Study of Shape Modeling Against Noise</h3>
<ul>
<li><strong>Authors: </strong>Cheng Long, Adrian Barbu</a></li>
<li><strong>Subjects: </strong>cs.CV, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.15587">https://arxiv.org/abs/2402.15587</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.15587">https://arxiv.org/pdf/2402.15587</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.15587]] A Study of Shape Modeling Against Noise(https://arxiv.org/abs/2402.15587)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>Shape modeling is a challenging task with many potential applications in computer vision and medical imaging. There are many shape modeling methods in the literature, each with its advantages and applications. However, many shape modeling methods have difficulties handling shapes that have missing pieces or outliers. In this regard, this paper introduces shape denoising, a fundamental problem in shape modeling that lies at the core of many computer vision and medical imaging applications and has not received enough attention in the literature. The paper introduces six types of noise that can be used to perturb shapes as well as an objective measure for the noise level and for comparing methods on their shape denoising capabilities. Finally, the paper evaluates seven methods capable of accomplishing this task, of which six are based on deep learning, including some generative models.</li>
</ul>

<h3>Title: Prompting LLMs to Compose Meta-Review Drafts from Peer-Review Narratives  of Scholarly Manuscripts</h3>
<ul>
<li><strong>Authors: </strong>Shubhra Kanti Karmaker Santu, Sanjeev Kumar Sinha, Naman Bansal, Alex Knipper, Souvika Sarkar, John Salvador, Yash Mahajan, Sri Guttikonda, Mousumi Akter, Matthew Freestone, Matthew C. Williams Jr</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.LG, cs.NE</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.15589">https://arxiv.org/abs/2402.15589</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.15589">https://arxiv.org/pdf/2402.15589</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.15589]] Prompting LLMs to Compose Meta-Review Drafts from Peer-Review Narratives  of Scholarly Manuscripts(https://arxiv.org/abs/2402.15589)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>One of the most important yet onerous tasks in the academic peer-reviewing process is composing meta-reviews, which involves understanding the core contributions, strengths, and weaknesses of a scholarly manuscript based on peer-review narratives from multiple experts and then summarizing those multiple experts' perspectives into a concise holistic overview. Given the latest major developments in generative AI, especially Large Language Models (LLMs), it is very compelling to rigorously study the utility of LLMs in generating such meta-reviews in an academic peer-review setting. In this paper, we perform a case study with three popular LLMs, i.e., GPT-3.5, LLaMA2, and PaLM2, to automatically generate meta-reviews by prompting them with different types/levels of prompts based on the recently proposed TELeR taxonomy. Finally, we perform a detailed qualitative study of the meta-reviews generated by the LLMs and summarize our findings and recommendations for prompting LLMs for this complex task.</li>
</ul>

<h3>Title: DeepSet SimCLR: Self-supervised deep sets for improved pathology  representation learning</h3>
<ul>
<li><strong>Authors: </strong>David Torpey, Richard Klein</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.15598">https://arxiv.org/abs/2402.15598</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.15598">https://arxiv.org/pdf/2402.15598</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.15598]] DeepSet SimCLR: Self-supervised deep sets for improved pathology  representation learning(https://arxiv.org/abs/2402.15598)</code><input type="text"></li>
<li><strong>Keywords: </strong>self-supervised</a></li>
<li><strong>Abstract: </strong>Often, applications of self-supervised learning to 3D medical data opt to use 3D variants of successful 2D network architectures. Although promising approaches, they are significantly more computationally demanding to train, and thus reduce the widespread applicability of these methods away from those with modest computational resources. Thus, in this paper, we aim to improve standard 2D SSL algorithms by modelling the inherent 3D nature of these datasets implicitly. We propose two variants that build upon a strong baseline model and show that both of these variants often outperform the baseline in a variety of downstream tasks. Importantly, in contrast to previous works in both 2D and 3D approaches for 3D medical data, both of our proposals introduce negligible additional overhead over the baseline, improving the democratisation of these approaches for medical applications.</li>
</ul>

<h3>Title: Training Nonlinear Transformers for Efficient In-Context Learning: A  Theoretical Learning and Generalization Analysis</h3>
<ul>
<li><strong>Authors: </strong>Hongkang Li, Meng Wang, Songtao Lu, Xiaodong Cui, Pin-Yu Chen</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.15607">https://arxiv.org/abs/2402.15607</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.15607">https://arxiv.org/pdf/2402.15607</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.15607]] Training Nonlinear Transformers for Efficient In-Context Learning: A  Theoretical Learning and Generalization Analysis(https://arxiv.org/abs/2402.15607)</code><input type="text"></li>
<li><strong>Keywords: </strong>in-context</a></li>
<li><strong>Abstract: </strong>Transformer-based large language models have displayed impressive in-context learning capabilities, where a pre-trained model can handle new tasks without fine-tuning by simply augmenting the query with some input-output examples from that task. Despite the empirical success, the mechanics of how to train a Transformer to achieve ICL and the corresponding ICL capacity is mostly elusive due to the technical challenges of analyzing the nonconvex training problems resulting from the nonlinear self-attention and nonlinear activation in Transformers. To the best of our knowledge, this paper provides the first theoretical analysis of the training dynamics of Transformers with nonlinear self-attention and nonlinear MLP, together with the ICL generalization capability of the resulting model. Focusing on a group of binary classification tasks, we train Transformers using data from a subset of these tasks and quantify the impact of various factors on the ICL generalization performance on the remaining unseen tasks with and without data distribution shifts. We also analyze how different components in the learned Transformers contribute to the ICL performance. Furthermore, we provide the first theoretical analysis of how model pruning affects the ICL performance and prove that proper magnitude-based pruning can have a minimal impact on ICL while reducing inference costs. These theoretical findings are justified through numerical experiments.</li>
</ul>

<h3>Title: Addressing Order Sensitivity of In-Context Demonstration Examples in  Causal Language Models</h3>
<ul>
<li><strong>Authors: </strong>Yanzheng Xiang, Hanqi Yan, Lin Gui, Yulan He</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.15637">https://arxiv.org/abs/2402.15637</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.15637">https://arxiv.org/pdf/2402.15637</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.15637]] Addressing Order Sensitivity of In-Context Demonstration Examples in  Causal Language Models(https://arxiv.org/abs/2402.15637)</code><input type="text"></li>
<li><strong>Keywords: </strong>in-context</a></li>
<li><strong>Abstract: </strong>In-context learning has become a popular paradigm in natural language processing. However, its performance can be significantly influenced by the order of in-context demonstration examples. In this paper, we found that causal language models (CausalLMs) are more sensitive to this order compared to prefix language models (PrefixLMs). We attribute this phenomenon to the auto-regressive attention masks within CausalLMs, which restrict each token from accessing information from subsequent tokens. This results in different receptive fields for samples at different positions, thereby leading to representation disparities across positions. To tackle this challenge, we introduce an unsupervised fine-tuning method, termed the Information-Augmented and Consistency-Enhanced approach. This approach utilizes contrastive learning to align representations of in-context examples across different positions and introduces a consistency loss to ensure similar representations for inputs with different permutations. This enhances the model's predictive consistency across permutations. Experimental results on four benchmarks suggest that our proposed method can reduce the sensitivity to the order of in-context examples and exhibit robust generalizability, particularly when demonstrations are sourced from a pool different from that used in the training phase, or when the number of in-context examples differs from what is used during training.</li>
</ul>

<h3>Title: Low-Frequency Black-Box Backdoor Attack via Evolutionary Algorithm</h3>
<ul>
<li><strong>Authors: </strong>Yanqi Qiao, Dazhuang Liu, Rui Wang, Kaitai Liang</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.15653">https://arxiv.org/abs/2402.15653</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.15653">https://arxiv.org/pdf/2402.15653</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.15653]] Low-Frequency Black-Box Backdoor Attack via Evolutionary Algorithm(https://arxiv.org/abs/2402.15653)</code><input type="text"></li>
<li><strong>Keywords: </strong>anomaly</a></li>
<li><strong>Abstract: </strong>While convolutional neural networks (CNNs) have achieved success in computer vision tasks, it is vulnerable to backdoor attacks. Such attacks could mislead the victim model to make attacker-chosen prediction with a specific trigger pattern. Until now, the trigger injection of existing attacks is mainly limited to spatial domain. Recent works take advantage of perceptual properties of planting specific patterns in the frequency domain, which only reflect indistinguishable pixel-wise perturbations in pixel domain. However, in the black-box setup, the inaccessibility of training process often renders more complex trigger designs. Existing frequency attacks simply handcraft the magnitude of spectrum, introducing anomaly frequency disparities between clean and poisoned data and taking risks of being removed by image processing operations (such as lossy compression and filtering). In this paper, we propose a robust low-frequency black-box backdoor attack (LFBA), which minimally perturbs low-frequency components of frequency spectrum and maintains the perceptual similarity in spatial space simultaneously. The key insight of our attack restrict the search for the optimal trigger to low-frequency region that can achieve high attack effectiveness, robustness against image transformation defenses and stealthiness in dual space. We utilize simulated annealing (SA), a form of evolutionary algorithm, to optimize the properties of frequency trigger including the number of manipulated frequency bands and the perturbation of each frequency component, without relying on the knowledge from the victim classifier. Extensive experiments on real-world datasets verify the effectiveness and robustness of LFBA against image processing operations and the state-of-the-art backdoor defenses, as well as its inherent stealthiness in both spatial and frequency space, making it resilient against frequency inspection.</li>
</ul>

<h3>Title: Overcoming Pitfalls in Graph Contrastive Learning Evaluation: Toward  Comprehensive Benchmarks</h3>
<ul>
<li><strong>Authors: </strong>Qian Ma, Hongliang Chi, Hengrui Zhang, Kay Liu, Zhiwei Zhang, Lu Cheng, Suhang Wang, Philip S. Yu, Yao Ma</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.15680">https://arxiv.org/abs/2402.15680</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.15680">https://arxiv.org/pdf/2402.15680</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.15680]] Overcoming Pitfalls in Graph Contrastive Learning Evaluation: Toward  Comprehensive Benchmarks(https://arxiv.org/abs/2402.15680)</code><input type="text"></li>
<li><strong>Keywords: </strong>self-supervised</a></li>
<li><strong>Abstract: </strong>The rise of self-supervised learning, which operates without the need for labeled data, has garnered significant interest within the graph learning community. This enthusiasm has led to the development of numerous Graph Contrastive Learning (GCL) techniques, all aiming to create a versatile graph encoder that leverages the wealth of unlabeled data for various downstream tasks. However, the current evaluation standards for GCL approaches are flawed due to the need for extensive hyper-parameter tuning during pre-training and the reliance on a single downstream task for assessment. These flaws can skew the evaluation away from the intended goals, potentially leading to misleading conclusions. In our paper, we thoroughly examine these shortcomings and offer fresh perspectives on how GCL methods are affected by hyper-parameter choices and the choice of downstream tasks for their evaluation. Additionally, we introduce an enhanced evaluation framework designed to more accurately gauge the effectiveness, consistency, and overall capability of GCL methods.</li>
</ul>

<h3>Title: General Purpose Image Encoder DINOv2 for Medical Image Registration</h3>
<ul>
<li><strong>Authors: </strong>Xinrui Song, Xuanang Xu, Pingkun Yan</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.15687">https://arxiv.org/abs/2402.15687</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.15687">https://arxiv.org/pdf/2402.15687</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.15687]] General Purpose Image Encoder DINOv2 for Medical Image Registration(https://arxiv.org/abs/2402.15687)</code><input type="text"></li>
<li><strong>Keywords: </strong>foundation model</a></li>
<li><strong>Abstract: </strong>Existing medical image registration algorithms rely on either dataset specific training or local texture-based features to align images. The former cannot be reliably implemented without large modality-specific training datasets, while the latter lacks global semantics thus could be easily trapped at local minima. In this paper, we present a training-free deformable image registration method, DINO-Reg, leveraging a general purpose image encoder DINOv2 for image feature extraction. The DINOv2 encoder was trained using the ImageNet data containing natural images. We used the pretrained DINOv2 without any finetuning. Our method feeds the DINOv2 encoded features into a discrete optimizer to find the optimal deformable registration field. We conducted a series of experiments to understand the behavior and role of such a general purpose image encoder in the application of image registration. Combined with handcrafted features, our method won the first place in the recent OncoReg Challenge. To our knowledge, this is the first application of general vision foundation models in medical image registration.</li>
</ul>

<h3>Title: Data-Efficient Operator Learning via Unsupervised Pretraining and  In-Context Learning</h3>
<ul>
<li><strong>Authors: </strong>Wuyang Chen, Jialin Song, Pu Ren, Shashank Subramanian, Dmitriy Morozov, Michael W. Mahoney</a></li>
<li><strong>Subjects: </strong>cs.LG, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.15734">https://arxiv.org/abs/2402.15734</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.15734">https://arxiv.org/pdf/2402.15734</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.15734]] Data-Efficient Operator Learning via Unsupervised Pretraining and  In-Context Learning(https://arxiv.org/abs/2402.15734)</code><input type="text"></li>
<li><strong>Keywords: </strong>in-context</a></li>
<li><strong>Abstract: </strong>Recent years have witnessed the promise of coupling machine learning methods and physical domain-specific insight for solving scientific problems based on partial differential equations (PDEs). However, being data-intensive, these methods still require a large amount of PDE data. This reintroduces the need for expensive numerical PDE solutions, partially undermining the original goal of avoiding these expensive simulations. In this work, seeking data efficiency, we design unsupervised pretraining and in-context learning methods for PDE operator learning. To reduce the need for training data with simulated solutions, we pretrain neural operators on unlabeled PDE data using reconstruction-based proxy tasks. To improve out-of-distribution performance, we further assist neural operators in flexibly leveraging in-context learning methods, without incurring extra training costs or designs. Extensive empirical evaluations on a diverse set of PDEs demonstrate that our method is highly data-efficient, more generalizable, and even outperforms conventional vision-pretrained models.</li>
</ul>

<h3>Title: A Generative Machine Learning Model for Material Microstructure 3D  Reconstruction and Performance Evaluation</h3>
<ul>
<li><strong>Authors: </strong>Yilin Zheng, Zhigong Song</a></li>
<li><strong>Subjects: </strong>cs.LG, cond-mat.mtrl-sci, cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.15815">https://arxiv.org/abs/2402.15815</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.15815">https://arxiv.org/pdf/2402.15815</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.15815]] A Generative Machine Learning Model for Material Microstructure 3D  Reconstruction and Performance Evaluation(https://arxiv.org/abs/2402.15815)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>The reconstruction of 3D microstructures from 2D slices is considered to hold significant value in predicting the spatial structure and physical properties of materials.The dimensional extension from 2D to 3D is viewed as a highly challenging inverse problem from the current technological perspective.Recently,methods based on generative adversarial networks have garnered widespread attention.However,they are still hampered by numerous limitations,including oversimplified models,a requirement for a substantial number of training samples,and difficulties in achieving model convergence during training.In light of this,a novel generative model that integrates the multiscale properties of U-net with and the generative capabilities of GAN has been proposed.Based on this,the innovative construction of a multi-scale channel aggregation module,a multi-scale hierarchical feature aggregation module and a convolutional block attention mechanism can better capture the properties of the material microstructure and extract the image information.The model's accuracy is further improved by combining the image regularization loss with the Wasserstein distance loss.In addition,this study utilizes the anisotropy index to accurately distinguish the nature of the image,which can clearly determine the isotropy and anisotropy of the image.It is also the first time that the generation quality of material samples from different domains is evaluated and the performance of the model itself is compared.The experimental results demonstrate that the present model not only shows a very high similarity between the generated 3D structures and real samples but is also highly consistent with real data in terms of statistical data analysis.</li>
</ul>

<h3>Title: Field-based Molecule Generation</h3>
<ul>
<li><strong>Authors: </strong>Alexandru Dumitrescu, Dani Korpela, Markus Heinonen, Yogesh Verma, Valerii Iakovlev, Vikas Garg, Harri Lähdesmäki</a></li>
<li><strong>Subjects: </strong>cs.LG, physics.chem-ph, q-bio.BM</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.15864">https://arxiv.org/abs/2402.15864</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.15864">https://arxiv.org/pdf/2402.15864</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.15864]] Field-based Molecule Generation(https://arxiv.org/abs/2402.15864)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>This work introduces FMG, a field-based model for drug-like molecule generation. We show how the flexibility of this method provides crucial advantages over the prevalent, point-cloud based methods, and achieves competitive molecular stability generation. We tackle optical isomerism (enantiomers), a previously omitted molecular property that is crucial for drug safety and effectiveness, and thus account for all molecular geometry aspects. We demonstrate how previous methods are invariant to a group of transformations that includes enantiomer pairs, leading them invariant to the molecular R and S configurations, while our field-based generative model captures this property.</li>
</ul>

<h3>Title: HIR-Diff: Unsupervised Hyperspectral Image Restoration Via Improved  Diffusion Models</h3>
<ul>
<li><strong>Authors: </strong>Li Pang, Xiangyu Rui, Long Cui, Hongzhong Wang, Deyu Meng, Xiangyong Cao</a></li>
<li><strong>Subjects: </strong>cs.CV, eess.IV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.15865">https://arxiv.org/abs/2402.15865</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.15865">https://arxiv.org/pdf/2402.15865</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.15865]] HIR-Diff: Unsupervised Hyperspectral Image Restoration Via Improved  Diffusion Models(https://arxiv.org/abs/2402.15865)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>Hyperspectral image (HSI) restoration aims at recovering clean images from degraded observations and plays a vital role in downstream tasks. Existing model-based methods have limitations in accurately modeling the complex image characteristics with handcraft priors, and deep learning-based methods suffer from poor generalization ability. To alleviate these issues, this paper proposes an unsupervised HSI restoration framework with pre-trained diffusion model (HIR-Diff), which restores the clean HSIs from the product of two low-rank components, i.e., the reduced image and the coefficient matrix. Specifically, the reduced image, which has a low spectral dimension, lies in the image field and can be inferred from our improved diffusion model where a new guidance function with total variation (TV) prior is designed to ensure that the reduced image can be well sampled. The coefficient matrix can be effectively pre-estimated based on singular value decomposition (SVD) and rank-revealing QR (RRQR) factorization. Furthermore, a novel exponential noise schedule is proposed to accelerate the restoration process (about 5$\times$ acceleration for denoising) with little performance decrease. Extensive experimental results validate the superiority of our method in both performance and speed on a variety of HSI restoration tasks, including HSI denoising, noisy HSI super-resolution, and noisy HSI inpainting. The code is available at https://github.com/LiPang/HIRDiff.</li>
</ul>

<h3>Title: Enhanced Droplet Analysis Using Generative Adversarial Networks</h3>
<ul>
<li><strong>Authors: </strong>Tan-Hanh Pham, Kim-Doang Nguyen</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.15909">https://arxiv.org/abs/2402.15909</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.15909">https://arxiv.org/pdf/2402.15909</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.15909]] Enhanced Droplet Analysis Using Generative Adversarial Networks(https://arxiv.org/abs/2402.15909)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>Precision devices play an important role in enhancing production quality and productivity in agricultural systems. Therefore, the optimization of these devices is essential in precision agriculture. Recently, with the advancements of deep learning, there have been several studies aiming to harness its capabilities for improving spray system performance. However, the effectiveness of these methods heavily depends on the size of the training dataset, which is expensive and time-consuming to collect. To address the challenge of insufficient training samples, this paper proposes an alternative solution by generating artificial images of droplets using generative adversarial networks (GAN). The GAN model is trained by using a small dataset captured by a high-speed camera and capable of generating images with progressively increasing resolution. The results demonstrate that the model can generate high-quality images with the size of $1024\times1024$. Furthermore, this research leverages recent advancements in computer vision and deep learning to develop a light droplet detector using the synthetic dataset. As a result, the detection model achieves a 16.06\% increase in mean average precision (mAP) when utilizing the synthetic dataset. To the best of our knowledge, this work stands as the first to employ a generative model for augmenting droplet detection. Its significance lies not only in optimizing nozzle design for constructing efficient spray systems but also in addressing the common challenge of insufficient data in various precision agriculture tasks. This work offers a critical contribution to conserving resources while striving for optimal and sustainable agricultural practices.</li>
</ul>

<h3>Title: Attention-GAN for Anomaly Detection: A Cutting-Edge Approach to  Cybersecurity Threat Management</h3>
<ul>
<li><strong>Authors: </strong>Mohammed Abo Sen</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.15945">https://arxiv.org/abs/2402.15945</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.15945">https://arxiv.org/pdf/2402.15945</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.15945]] Attention-GAN for Anomaly Detection: A Cutting-Edge Approach to  Cybersecurity Threat Management(https://arxiv.org/abs/2402.15945)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative, anomaly</a></li>
<li><strong>Abstract: </strong>This paper proposes an innovative Attention-GAN framework for enhancing cybersecurity, focusing on anomaly detection. In response to the challenges posed by the constantly evolving nature of cyber threats, the proposed approach aims to generate diverse and realistic synthetic attack scenarios, thereby enriching the dataset and improving threat identification. Integrating attention mechanisms with Generative Adversarial Networks (GANs) is a key feature of the proposed method. The attention mechanism enhances the model's ability to focus on relevant features, essential for detecting subtle and complex attack patterns. In addition, GANs address the issue of data scarcity by generating additional varied attack data, encompassing known and emerging threats. This dual approach ensures that the system remains relevant and effective against the continuously evolving cyberattacks. The KDD Cup and CICIDS2017 datasets were used to validate this model, which exhibited significant improvements in anomaly detection. It achieved an accuracy of 99.69% on the KDD dataset and 97.93% on the CICIDS2017 dataset, with precision, recall, and F1-scores above 97%, demonstrating its effectiveness in recognizing complex attack patterns. This study contributes significantly to cybersecurity by providing a scalable and adaptable solution for anomaly detection in the face of sophisticated and dynamic cyber threats. The exploration of GANs for data augmentation highlights a promising direction for future research, particularly in situations where data limitations restrict the development of cybersecurity systems. The attention-GAN framework has emerged as a pioneering approach, setting a new benchmark for advanced cyber-defense strategies.</li>
</ul>

<h3>Title: Likelihood-based Mitigation of Evaluation Bias in Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Masanari Ohi, Masahiro Kaneko, Ryuto Koike, Mengsay Loem, Naoaki Okazaki</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.15987">https://arxiv.org/abs/2402.15987</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.15987">https://arxiv.org/pdf/2402.15987</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.15987]] Likelihood-based Mitigation of Evaluation Bias in Large Language Models(https://arxiv.org/abs/2402.15987)</code><input type="text"></li>
<li><strong>Keywords: </strong>in-context</a></li>
<li><strong>Abstract: </strong>Large Language Models (LLMs) are widely used to evaluate natural language generation tasks as automated metrics. However, the likelihood, a measure of LLM's plausibility for a sentence, can vary due to superficial differences in sentences, such as word order and sentence structure. It is therefore possible that there might be a likelihood bias if LLMs are used for evaluation: they might overrate sentences with higher likelihoods while underrating those with lower likelihoods. In this paper, we investigate the presence and impact of likelihood bias in LLM-based evaluators. We also propose a method to mitigate the likelihood bias. Our method utilizes highly biased instances as few-shot examples for in-context learning. Our experiments in evaluating the data-to-text and grammatical error correction tasks reveal that several LLMs we test display a likelihood bias. Furthermore, our proposed method successfully mitigates this bias, also improving evaluation performance (in terms of correlation of models with human scores) significantly.</li>
</ul>

<h3>Title: Building Flexible Machine Learning Models for Scientific Computing at  Scale</h3>
<ul>
<li><strong>Authors: </strong>Tianyu Chen, Haoyi Zhou, Ying Li, Hao Wang, Chonghan Gao, Shanghang Zhang, Jianxin Li</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.16014">https://arxiv.org/abs/2402.16014</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.16014">https://arxiv.org/pdf/2402.16014</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.16014]] Building Flexible Machine Learning Models for Scientific Computing at  Scale(https://arxiv.org/abs/2402.16014)</code><input type="text"></li>
<li><strong>Keywords: </strong>foundation model</a></li>
<li><strong>Abstract: </strong>Foundation models have revolutionized knowledge acquisition across domains, and our study introduces OmniArch, a paradigm-shifting approach designed for building foundation models in multi-physics scientific computing. OmniArch's pre-training involves a versatile pipeline that processes multi-physics spatio-temporal data, casting forward problem learning into scalable auto-regressive tasks, while our novel Physics-Informed Reinforcement Learning (PIRL) technique during fine-tuning ensures alignment with physical laws. Pre-trained on the comprehensive PDEBench dataset, OmniArch not only sets new performance benchmarks for 1D, 2D and 3D PDEs but also demonstrates exceptional adaptability to new physics via few-shot and zero-shot learning approaches. The model's representations further extend to inverse problem-solving, highlighting the transformative potential of AI-enabled Scientific Computing(AI4SC) foundation models for engineering applications and physics discovery.</li>
</ul>

<h3>Title: HiGPT: Heterogeneous Graph Language Model</h3>
<ul>
<li><strong>Authors: </strong>Jiabin Tang, Yuhao Yang, Wei Wei, Lei Shi, Long Xia, Dawei Yin, Chao Huang</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.16024">https://arxiv.org/abs/2402.16024</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.16024">https://arxiv.org/pdf/2402.16024</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.16024]] HiGPT: Heterogeneous Graph Language Model(https://arxiv.org/abs/2402.16024)</code><input type="text"></li>
<li><strong>Keywords: </strong>in-context</a></li>
<li><strong>Abstract: </strong>Heterogeneous graph learning aims to capture complex relationships and diverse relational semantics among entities in a heterogeneous graph to obtain meaningful representations for nodes and edges. Recent advancements in heterogeneous graph neural networks (HGNNs) have achieved state-of-the-art performance by considering relation heterogeneity and using specialized message functions and aggregation rules. However, existing frameworks for heterogeneous graph learning have limitations in generalizing across diverse heterogeneous graph datasets. Most of these frameworks follow the "pre-train" and "fine-tune" paradigm on the same dataset, which restricts their capacity to adapt to new and unseen data. This raises the question: "Can we generalize heterogeneous graph models to be well-adapted to diverse downstream learning tasks with distribution shifts in both node token sets and relation type heterogeneity?'' To tackle those challenges, we propose HiGPT, a general large graph model with Heterogeneous graph instruction-tuning paradigm. Our framework enables learning from arbitrary heterogeneous graphs without the need for any fine-tuning process from downstream datasets. To handle distribution shifts in heterogeneity, we introduce an in-context heterogeneous graph tokenizer that captures semantic relationships in different heterogeneous graphs, facilitating model adaptation. We incorporate a large corpus of heterogeneity-aware graph instructions into our HiGPT, enabling the model to effectively comprehend complex relation heterogeneity and distinguish between various types of graph tokens. Furthermore, we introduce the Mixture-of-Thought (MoT) instruction augmentation paradigm to mitigate data scarcity by generating diverse and informative instructions. Through comprehensive evaluations, our proposed framework demonstrates exceptional performance in terms of generalization performance.</li>
</ul>

<h3>Title: LLMs with Chain-of-Thought Are Non-Causal Reasoners</h3>
<ul>
<li><strong>Authors: </strong>Guangsheng Bao, Hongbo Zhang, Linyi Yang, Cunxiang Wang, Yue Zhang</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.16048">https://arxiv.org/abs/2402.16048</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.16048">https://arxiv.org/pdf/2402.16048</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.16048]] LLMs with Chain-of-Thought Are Non-Causal Reasoners(https://arxiv.org/abs/2402.16048)</code><input type="text"></li>
<li><strong>Keywords: </strong>in-context</a></li>
<li><strong>Abstract: </strong>This paper explores the role of the Chain of Thought (CoT) in Large Language Models (LLMs) reasoning. Despite its potential to improve task performance, our analysis reveals a surprising frequency of correct answers following incorrect CoTs and vice versa. We employ causal analysis to assess the cause-effect relationship between CoTs/instructions and answers in LLMs, uncovering the Structural Causal Model (SCM) that LLMs approximate. By comparing the implied SCM with that of human reasoning, we highlight discrepancies between LLM and human reasoning processes. We further examine the factors influencing the causal structure of the implied SCM, revealing that in-context learning, supervised fine-tuning, and reinforcement learning on human feedback significantly impact the causal relations. We release the code and results at https://github.com/StevenZHB/CoT_Causal_Analysis.</li>
</ul>

<h3>Title: How Large Language Models Encode Context Knowledge? A Layer-Wise Probing  Study</h3>
<ul>
<li><strong>Authors: </strong>Tianjie Ju, Weiwei Sun, Wei Du, Xinwei Yuan, Zhaochun Ren, Gongshen Liu</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.16061">https://arxiv.org/abs/2402.16061</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.16061">https://arxiv.org/pdf/2402.16061</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.16061]] How Large Language Models Encode Context Knowledge? A Layer-Wise Probing  Study(https://arxiv.org/abs/2402.16061)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>Previous work has showcased the intriguing capability of large language models (LLMs) in retrieving facts and processing context knowledge. However, only limited research exists on the layer-wise capability of LLMs to encode knowledge, which challenges our understanding of their internal mechanisms. In this paper, we devote the first attempt to investigate the layer-wise capability of LLMs through probing tasks. We leverage the powerful generative capability of ChatGPT to construct probing datasets, providing diverse and coherent evidence corresponding to various facts. We employ $\mathcal V$-usable information as the validation metric to better reflect the capability in encoding context knowledge across different layers. Our experiments on conflicting and newly acquired knowledge show that LLMs: (1) prefer to encode more context knowledge in the upper layers; (2) primarily encode context knowledge within knowledge-related entity tokens at lower layers while progressively expanding more knowledge within other tokens at upper layers; and (3) gradually forget the earlier context knowledge retained within the intermediate layers when provided with irrelevant evidence. Code is publicly available at https://github.com/Jometeorie/probing_llama.</li>
</ul>

<h3>Title: Behavioral Refinement via Interpolant-based Policy Diffusion</h3>
<ul>
<li><strong>Authors: </strong>Kaiqi Chen, Eugene Lim, Kelvin Lin, Yiyang Chen, Harold Soh</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.RO</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.16075">https://arxiv.org/abs/2402.16075</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.16075">https://arxiv.org/pdf/2402.16075</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.16075]] Behavioral Refinement via Interpolant-based Policy Diffusion(https://arxiv.org/abs/2402.16075)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>Imitation learning empowers artificial agents to mimic behavior by learning from demonstrations. Recently, diffusion models, which have the ability to model high-dimensional and multimodal distributions, have shown impressive performance on imitation learning tasks. These models learn to shape a policy by diffusing actions (or states) from standard Gaussian noise. However, the target policy to be learned is often significantly different from Gaussian and this mismatch can result in poor performance when using a small number of diffusion steps (to improve inference speed) and under limited data. The key idea in this work is that initiating from a more informative source than Gaussian enables diffusion methods to overcome the above limitations. We contribute both theoretical results, a new method, and empirical findings that show the benefits of using an informative source policy. Our method, which we call BRIDGER, leverages the stochastic interpolants framework to bridge arbitrary policies, thus enabling a flexible approach towards imitation learning. It generalizes prior work in that standard Gaussians can still be applied, but other source policies can be used if available. In experiments on challenging benchmarks, BRIDGER outperforms state-of-the-art diffusion policies and we provide further analysis on design considerations when applying BRIDGER.</li>
</ul>

<h3>Title: Key Design Choices in Source-Free Unsupervised Domain Adaptation: An  In-depth Empirical Analysis</h3>
<ul>
<li><strong>Authors: </strong>Andrea Maracani, Raffaello Camoriano, Elisa Maiettini, Davide Talon, Lorenzo Rosasco, Lorenzo Natale</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.16090">https://arxiv.org/abs/2402.16090</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.16090">https://arxiv.org/pdf/2402.16090</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.16090]] Key Design Choices in Source-Free Unsupervised Domain Adaptation: An  In-depth Empirical Analysis(https://arxiv.org/abs/2402.16090)</code><input type="text"></li>
<li><strong>Keywords: </strong>self-supervised</a></li>
<li><strong>Abstract: </strong>This study provides a comprehensive benchmark framework for Source-Free Unsupervised Domain Adaptation (SF-UDA) in image classification, aiming to achieve a rigorous empirical understanding of the complex relationships between multiple key design factors in SF-UDA methods. The study empirically examines a diverse set of SF-UDA techniques, assessing their consistency across datasets, sensitivity to specific hyperparameters, and applicability across different families of backbone architectures. Moreover, it exhaustively evaluates pre-training datasets and strategies, particularly focusing on both supervised and self-supervised methods, as well as the impact of fine-tuning on the source domain. Our analysis also highlights gaps in existing benchmark practices, guiding SF-UDA research towards more effective and general approaches. It emphasizes the importance of backbone architecture and pre-training dataset selection on SF-UDA performance, serving as an essential reference and providing key insights. Lastly, we release the source code of our experimental framework. This facilitates the construction, training, and testing of SF-UDA methods, enabling systematic large-scale experimental analysis and supporting further research efforts in this field.</li>
</ul>

<h3>Title: AVI-Talking: Learning Audio-Visual Instructions for Expressive 3D  Talking Face Generation</h3>
<ul>
<li><strong>Authors: </strong>Yasheng Sun, Wenqing Chu, Hang Zhou, Kaisiyuan Wang, Hideki Koike</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.16124">https://arxiv.org/abs/2402.16124</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.16124">https://arxiv.org/pdf/2402.16124</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.16124]] AVI-Talking: Learning Audio-Visual Instructions for Expressive 3D  Talking Face Generation(https://arxiv.org/abs/2402.16124)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, generative</a></li>
<li><strong>Abstract: </strong>While considerable progress has been made in achieving accurate lip synchronization for 3D speech-driven talking face generation, the task of incorporating expressive facial detail synthesis aligned with the speaker's speaking status remains challenging. Our goal is to directly leverage the inherent style information conveyed by human speech for generating an expressive talking face that aligns with the speaking status. In this paper, we propose AVI-Talking, an Audio-Visual Instruction system for expressive Talking face generation. This system harnesses the robust contextual reasoning and hallucination capability offered by Large Language Models (LLMs) to instruct the realistic synthesis of 3D talking faces. Instead of directly learning facial movements from human speech, our two-stage strategy involves the LLMs first comprehending audio information and generating instructions implying expressive facial details seamlessly corresponding to the speech. Subsequently, a diffusion-based generative network executes these instructions. This two-stage process, coupled with the incorporation of LLMs, enhances model interpretability and provides users with flexibility to comprehend instructions and specify desired operations or modifications. Extensive experiments showcase the effectiveness of our approach in producing vivid talking faces with expressive facial movements and consistent emotional status.</li>
</ul>

<h3>Title: What Generative Artificial Intelligence Means for Terminological  Definitions</h3>
<ul>
<li><strong>Authors: </strong>Antonio San Martín</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.16139">https://arxiv.org/abs/2402.16139</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.16139">https://arxiv.org/pdf/2402.16139</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.16139]] What Generative Artificial Intelligence Means for Terminological  Definitions(https://arxiv.org/abs/2402.16139)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>This paper examines the impact of Generative Artificial Intelligence (GenAI) on the creation and consumption of terminological definitions. GenAI tools like ChatGPT present a mix of benefits and drawbacks compared to traditional terminological resources. ChatGPT excels in providing context-specific meanings in an interactive and customized fashion but faces challenges with accuracy. Terminological definitions in recognized resources will likely survive because of their reliability. From the point of view of the terminologist, tools like ChatGPT enable AI-assisted terminography, including post-editing terminography, as an approach blending AI efficiency with human expertise for faster definition creation.</li>
</ul>

<h3>Title: From Text to Transformation: A Comprehensive Review of Large Language  Models' Versatility</h3>
<ul>
<li><strong>Authors: </strong>Pravneet Kaur, Gautam Siddharth Kashyap, Ankit Kumar, Md Tabrez Nafis, Sandeep Kumar, Vikrant Shokeen</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.16142">https://arxiv.org/abs/2402.16142</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.16142">https://arxiv.org/pdf/2402.16142</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.16142]] From Text to Transformation: A Comprehensive Review of Large Language  Models' Versatility(https://arxiv.org/abs/2402.16142)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>This groundbreaking study explores the expanse of Large Language Models (LLMs), such as Generative Pre-Trained Transformer (GPT) and Bidirectional Encoder Representations from Transformers (BERT) across varied domains ranging from technology, finance, healthcare to education. Despite their established prowess in Natural Language Processing (NLP), these LLMs have not been systematically examined for their impact on domains such as fitness, and holistic well-being, urban planning, climate modelling as well as disaster management. This review paper, in addition to furnishing a comprehensive analysis of the vast expanse and extent of LLMs' utility in diverse domains, recognizes the research gaps and realms where the potential of LLMs is yet to be harnessed. This study uncovers innovative ways in which LLMs can leave a mark in the fields like fitness and wellbeing, urban planning, climate modelling and disaster response which could inspire future researches and applications in the said avenues.</li>
</ul>

<h3>Title: Attacking LLM Watermarks by Exploiting Their Strengths</h3>
<ul>
<li><strong>Authors: </strong>Qi Pang, Shengyuan Hu, Wenting Zheng, Virginia Smith</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.CL, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.16187">https://arxiv.org/abs/2402.16187</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.16187">https://arxiv.org/pdf/2402.16187</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.16187]] Attacking LLM Watermarks by Exploiting Their Strengths(https://arxiv.org/abs/2402.16187)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>Advances in generative models have made it possible for AI-generated text, code, and images to mirror human-generated content in many applications. Watermarking, a technique that aims to embed information in the output of a model to verify its source, is useful for mitigating misuse of such AI-generated content. However, existing watermarking schemes remain surprisingly susceptible to attack. In particular, we show that desirable properties shared by existing LLM watermarking systems such as quality preservation, robustness, and public detection APIs can in turn make these systems vulnerable to various attacks. We rigorously study potential attacks in terms of common watermark design choices, and propose best practices and defenses for mitigation -- establishing a set of practical guidelines for embedding and detection of LLM watermarks.</li>
</ul>

<h3>Title: Foundation Model Transparency Reports</h3>
<ul>
<li><strong>Authors: </strong>Rishi Bommasani, Kevin Klyman, Shayne Longpre, Betty Xiong, Sayash Kapoor, Nestor Maslej, Arvind Narayanan, Percy Liang</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CY</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.16268">https://arxiv.org/abs/2402.16268</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.16268">https://arxiv.org/pdf/2402.16268</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.16268]] Foundation Model Transparency Reports(https://arxiv.org/abs/2402.16268)</code><input type="text"></li>
<li><strong>Keywords: </strong>foundation model</a></li>
<li><strong>Abstract: </strong>Foundation models are critical digital technologies with sweeping societal impact that necessitates transparency. To codify how foundation model developers should provide transparency about the development and deployment of their models, we propose Foundation Model Transparency Reports, drawing upon the transparency reporting practices in social media. While external documentation of societal harms prompted social media transparency reports, our objective is to institutionalize transparency reporting for foundation models while the industry is still nascent. To design our reports, we identify 6 design principles given the successes and shortcomings of social media transparency reporting. To further schematize our reports, we draw upon the 100 transparency indicators from the Foundation Model Transparency Index. Given these indicators, we measure the extent to which they overlap with the transparency requirements included in six prominent government policies (e.g., the EU AI Act, the US Executive Order on Safe, Secure, and Trustworthy AI). Well-designed transparency reports could reduce compliance costs, in part due to overlapping regulatory requirements across different jurisdictions. We encourage foundation model developers to regularly publish transparency reports, building upon recommendations from the G7 and the White House.</li>
</ul>

<h3>Title: Few-Shot Learning for Annotation-Efficient Nucleus Instance Segmentation</h3>
<ul>
<li><strong>Authors: </strong>Yu Ming, Zihao Wu, Jie Yang, Danyi Li, Yuan Gao, Changxin Gao, Gui-Song Xia, Yuanqing Li, Li Liang, Jin-Gang Yu</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.16280">https://arxiv.org/abs/2402.16280</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.16280">https://arxiv.org/pdf/2402.16280</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.16280]] Few-Shot Learning for Annotation-Efficient Nucleus Instance Segmentation(https://arxiv.org/abs/2402.16280)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>Nucleus instance segmentation from histopathology images suffers from the extremely laborious and expert-dependent annotation of nucleus instances. As a promising solution to this task, annotation-efficient deep learning paradigms have recently attracted much research interest, such as weakly-/semi-supervised learning, generative adversarial learning, etc. In this paper, we propose to formulate annotation-efficient nucleus instance segmentation from the perspective of few-shot learning (FSL). Our work was motivated by that, with the prosperity of computational pathology, an increasing number of fully-annotated datasets are publicly accessible, and we hope to leverage these external datasets to assist nucleus instance segmentation on the target dataset which only has very limited annotation. To achieve this goal, we adopt the meta-learning based FSL paradigm, which however has to be tailored in two substantial aspects before adapting to our task. First, since the novel classes may be inconsistent with those of the external dataset, we extend the basic definition of few-shot instance segmentation (FSIS) to generalized few-shot instance segmentation (GFSIS). Second, to cope with the intrinsic challenges of nucleus segmentation, including touching between adjacent cells, cellular heterogeneity, etc., we further introduce a structural guidance mechanism into the GFSIS network, finally leading to a unified Structurally-Guided Generalized Few-Shot Instance Segmentation (SGFSIS) framework. Extensive experiments on a couple of publicly accessible datasets demonstrate that, SGFSIS can outperform other annotation-efficient learning baselines, including semi-supervised learning, simple transfer learning, etc., with comparable performance to fully supervised learning with less than 5% annotations.</li>
</ul>

<h3>Title: Graph Diffusion Policy Optimization</h3>
<ul>
<li><strong>Authors: </strong>Yijing Liu, Chao Du, Tianyu Pang, Chongxuan Li, Wei Chen, Min Lin</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CE</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.16302">https://arxiv.org/abs/2402.16302</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.16302">https://arxiv.org/pdf/2402.16302</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.16302]] Graph Diffusion Policy Optimization(https://arxiv.org/abs/2402.16302)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>Recent research has made significant progress in optimizing diffusion models for specific downstream objectives, which is an important pursuit in fields such as graph generation for drug design. However, directly applying these models to graph diffusion presents challenges, resulting in suboptimal performance. This paper introduces graph diffusion policy optimization (GDPO), a novel approach to optimize graph diffusion models for arbitrary (e.g., non-differentiable) objectives using reinforcement learning. GDPO is based on an eager policy gradient tailored for graph diffusion models, developed through meticulous analysis and promising improved performance. Experimental results show that GDPO achieves state-of-the-art performance in various graph generation tasks with complex and diverse objectives. Code is available at https://github.com/sail-sg/GDPO.</li>
</ul>

<h3>Title: Referee Can Play: An Alternative Approach to Conditional Generation via  Model Inversion</h3>
<ul>
<li><strong>Authors: </strong>Xuantong Liu, Tianyang Hu, Wenjia Wang, Kenji Kawaguchi, Yuan Yao</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.16305">https://arxiv.org/abs/2402.16305</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.16305">https://arxiv.org/pdf/2402.16305</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.16305]] Referee Can Play: An Alternative Approach to Conditional Generation via  Model Inversion(https://arxiv.org/abs/2402.16305)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>As a dominant force in text-to-image generation tasks, Diffusion Probabilistic Models (DPMs) face a critical challenge in controllability, struggling to adhere strictly to complex, multi-faceted instructions. In this work, we aim to address this alignment challenge for conditional generation tasks. First, we provide an alternative view of state-of-the-art DPMs as a way of inverting advanced Vision-Language Models (VLMs). With this formulation, we naturally propose a training-free approach that bypasses the conventional sampling process associated with DPMs. By directly optimizing images with the supervision of discriminative VLMs, the proposed method can potentially achieve a better text-image alignment. As proof of concept, we demonstrate the pipeline with the pre-trained BLIP-2 model and identify several key designs for improved image generation. To further enhance the image fidelity, a Score Distillation Sampling module of Stable Diffusion is incorporated. By carefully balancing the two components during optimization, our method can produce high-quality images with near state-of-the-art performance on T2I-Compbench.</li>
</ul>

<h3>Title: BLO-SAM: Bi-level Optimization Based Overfitting-Preventing Finetuning  of SAM</h3>
<ul>
<li><strong>Authors: </strong>Li Zhang, Youwei Liang, Pengtao Xie</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.16338">https://arxiv.org/abs/2402.16338</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.16338">https://arxiv.org/pdf/2402.16338</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.16338]] BLO-SAM: Bi-level Optimization Based Overfitting-Preventing Finetuning  of SAM(https://arxiv.org/abs/2402.16338)</code><input type="text"></li>
<li><strong>Keywords: </strong>foundation model</a></li>
<li><strong>Abstract: </strong>The Segment Anything Model (SAM), a foundation model pretrained on millions of images and segmentation masks, has significantly advanced semantic segmentation, a fundamental task in computer vision. Despite its strengths, SAM encounters two major challenges. Firstly, it struggles with segmenting specific objects autonomously, as it relies on users to manually input prompts like points or bounding boxes to identify targeted objects. Secondly, SAM faces challenges in excelling at specific downstream tasks, like medical imaging, due to a disparity between the distribution of its pretraining data, which predominantly consists of general-domain images, and the data used in downstream tasks. Current solutions to these problems, which involve finetuning SAM, often lead to overfitting, a notable issue in scenarios with very limited data, like in medical imaging. To overcome these limitations, we introduce BLO-SAM, which finetunes SAM based on bi-level optimization (BLO). Our approach allows for automatic image segmentation without the need for manual prompts, by optimizing a learnable prompt embedding. Furthermore, it significantly reduces the risk of overfitting by training the model's weight parameters and the prompt embedding on two separate subsets of the training dataset, each at a different level of optimization. We apply BLO-SAM to diverse semantic segmentation tasks in general and medical domains. The results demonstrate BLO-SAM's superior performance over various state-of-the-art image semantic segmentation methods.</li>
</ul>

<h3>Title: C-GAIL: Stabilizing Generative Adversarial Imitation Learning with  Control Theory</h3>
<ul>
<li><strong>Authors: </strong>Tianjiao Luo, Tim Pearce, Huayu Chen, Jianfei Chen, Jun Zhu</a></li>
<li><strong>Subjects: </strong>cs.LG, eess.SY</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.16349">https://arxiv.org/abs/2402.16349</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.16349">https://arxiv.org/pdf/2402.16349</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.16349]] C-GAIL: Stabilizing Generative Adversarial Imitation Learning with  Control Theory(https://arxiv.org/abs/2402.16349)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>Generative Adversarial Imitation Learning (GAIL) trains a generative policy to mimic a demonstrator. It uses on-policy Reinforcement Learning (RL) to optimize a reward signal derived from a GAN-like discriminator. A major drawback of GAIL is its training instability - it inherits the complex training dynamics of GANs, and the distribution shift introduced by RL. This can cause oscillations during training, harming its sample efficiency and final policy performance. Recent work has shown that control theory can help with the convergence of a GAN's training. This paper extends this line of work, conducting a control-theoretic analysis of GAIL and deriving a novel controller that not only pushes GAIL to the desired equilibrium but also achieves asymptotic stability in a 'one-step' setting. Based on this, we propose a practical algorithm 'Controlled-GAIL' (C-GAIL). On MuJoCo tasks, our controlled variant is able to speed up the rate of convergence, reduce the range of oscillation and match the expert's distribution more closely both for vanilla GAIL and GAIL-DAC.</li>
</ul>

<h3>Title: An Integrated Data Processing Framework for Pretraining Foundation  Models</h3>
<ul>
<li><strong>Authors: </strong>Yiding Sun, Feng Wang, Yutao Zhu, Wayne Xin Zhao, Jiaxin Mao</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CL, cs.IR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.16358">https://arxiv.org/abs/2402.16358</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.16358">https://arxiv.org/pdf/2402.16358</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.16358]] An Integrated Data Processing Framework for Pretraining Foundation  Models(https://arxiv.org/abs/2402.16358)</code><input type="text"></li>
<li><strong>Keywords: </strong>foundation model</a></li>
<li><strong>Abstract: </strong>The ability of the foundation models heavily relies on large-scale, diverse, and high-quality pretraining data. In order to improve data quality, researchers and practitioners often have to manually curate datasets from difference sources and develop dedicated data cleansing pipeline for each data repository. Lacking a unified data processing framework, this process is repetitive and cumbersome. To mitigate this issue, we propose a data processing framework that integrates a Processing Module which consists of a series of operators at different granularity levels, and an Analyzing Module which supports probing and evaluation of the refined data. The proposed framework is easy to use and highly flexible. In this demo paper, we first introduce how to use this framework with some example use cases and then demonstrate its effectiveness in improving the data quality with an automated evaluation with ChatGPT and an end-to-end evaluation in pretraining the GPT-2 model. The code and demonstration videos are accessible on GitHub.</li>
</ul>

<h3>Title: Feedback Efficient Online Fine-Tuning of Diffusion Models</h3>
<ul>
<li><strong>Authors: </strong>Masatoshi Uehara, Yulai Zhao, Kevin Black, Ehsan Hajiramezanali, Gabriele Scalia, Nathaniel Lee Diamant, Alex M Tseng, Sergey Levine, Tommaso Biancalani</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, q-bio.QM, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.16359">https://arxiv.org/abs/2402.16359</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.16359">https://arxiv.org/pdf/2402.16359</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.16359]] Feedback Efficient Online Fine-Tuning of Diffusion Models(https://arxiv.org/abs/2402.16359)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>Diffusion models excel at modeling complex data distributions, including those of images, proteins, and small molecules. However, in many cases, our goal is to model parts of the distribution that maximize certain properties: for example, we may want to generate images with high aesthetic quality, or molecules with high bioactivity. It is natural to frame this as a reinforcement learning (RL) problem, in which the objective is to fine-tune a diffusion model to maximize a reward function that corresponds to some property. Even with access to online queries of the ground-truth reward function, efficiently discovering high-reward samples can be challenging: they might have a low probability in the initial distribution, and there might be many infeasible samples that do not even have a well-defined reward (e.g., unnatural images or physically impossible molecules). In this work, we propose a novel reinforcement learning procedure that efficiently explores on the manifold of feasible samples. We present a theoretical analysis providing a regret guarantee, as well as empirical validation across three domains: images, biological sequences, and molecules.</li>
</ul>

<h3>Title: Generative AI in Vision: A Survey on Models, Metrics and Applications</h3>
<ul>
<li><strong>Authors: </strong>Gaurav Raut, Apoorv Singh</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.16369">https://arxiv.org/abs/2402.16369</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.16369">https://arxiv.org/pdf/2402.16369</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.16369]] Generative AI in Vision: A Survey on Models, Metrics and Applications(https://arxiv.org/abs/2402.16369)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, generative</a></li>
<li><strong>Abstract: </strong>Generative AI models have revolutionized various fields by enabling the creation of realistic and diverse data samples. Among these models, diffusion models have emerged as a powerful approach for generating high-quality images, text, and audio. This survey paper provides a comprehensive overview of generative AI diffusion and legacy models, focusing on their underlying techniques, applications across different domains, and their challenges. We delve into the theoretical foundations of diffusion models, including concepts such as denoising diffusion probabilistic models (DDPM) and score-based generative modeling. Furthermore, we explore the diverse applications of these models in text-to-image, image inpainting, and image super-resolution, along with others, showcasing their potential in creative tasks and data augmentation. By synthesizing existing research and highlighting critical advancements in this field, this survey aims to provide researchers and practitioners with a comprehensive understanding of generative AI diffusion and legacy models and inspire future innovations in this exciting area of artificial intelligence.</li>
</ul>

<h3>Title: Placing Objects in Context via Inpainting for Out-of-distribution  Segmentation</h3>
<ul>
<li><strong>Authors: </strong>Pau de Jorge, Riccardo Volpi, Puneet K. Dokania, Philip H. S. Torr, Gregory Rogez</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.16392">https://arxiv.org/abs/2402.16392</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.16392">https://arxiv.org/pdf/2402.16392</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.16392]] Placing Objects in Context via Inpainting for Out-of-distribution  Segmentation(https://arxiv.org/abs/2402.16392)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, anomaly</a></li>
<li><strong>Abstract: </strong>When deploying a semantic segmentation model into the real world, it will inevitably be confronted with semantic classes unseen during training. Thus, to safely deploy such systems, it is crucial to accurately evaluate and improve their anomaly segmentation capabilities. However, acquiring and labelling semantic segmentation data is expensive and unanticipated conditions are long-tail and potentially hazardous. Indeed, existing anomaly segmentation datasets capture a limited number of anomalies, lack realism or have strong domain shifts. In this paper, we propose the Placing Objects in Context (POC) pipeline to realistically add any object into any image via diffusion models. POC can be used to easily extend any dataset with an arbitrary number of objects. In our experiments, we present different anomaly segmentation datasets based on POC-generated data and show that POC can improve the performance of recent state-of-the-art anomaly fine-tuning methods in several standardized benchmarks. POC is also effective to learn new classes. For example, we use it to edit Cityscapes samples by adding a subset of Pascal classes and show that models trained on such data achieve comparable performance to the Pascal-trained baseline. This corroborates the low sim-to-real gap of models trained on POC-generated images.</li>
</ul>

<h3>Title: Investigating Deep Watermark Security: An Adversarial Transferability  Perspective</h3>
<ul>
<li><strong>Authors: </strong>Biqing Qi, Junqi Gao, Yiang Luo, Jianxing Liu, Ligang Wu, Bowen Zhou</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.16397">https://arxiv.org/abs/2402.16397</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.16397">https://arxiv.org/pdf/2402.16397</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.16397]] Investigating Deep Watermark Security: An Adversarial Transferability  Perspective(https://arxiv.org/abs/2402.16397)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>The rise of generative neural networks has triggered an increased demand for intellectual property (IP) protection in generated content. Deep watermarking techniques, recognized for their flexibility in IP protection, have garnered significant attention. However, the surge in adversarial transferable attacks poses unprecedented challenges to the security of deep watermarking techniques-an area currently lacking systematic investigation. This study fills this gap by introducing two effective transferable attackers to assess the vulnerability of deep watermarks against erasure and tampering risks. Specifically, we initially define the concept of local sample density, utilizing it to deduce theorems on the consistency of model outputs. Upon discovering that perturbing samples towards high sample density regions (HSDR) of the target class enhances targeted adversarial transferability, we propose the Easy Sample Selection (ESS) mechanism and the Easy Sample Matching Attack (ESMA) method. Additionally, we propose the Bottleneck Enhanced Mixup (BEM) that integrates information bottleneck theory to reduce the generator's dependence on irrelevant noise. Experiments show a significant enhancement in the success rate of targeted transfer attacks for both ESMA and BEM-ESMA methods. We further conduct a comprehensive evaluation using ESMA and BEM-ESMA as measurements, considering model architecture and watermark encoding length, and achieve some impressive findings.</li>
</ul>

<h3>Title: TOTEM: TOkenized Time Series EMbeddings for General Time Series Analysis</h3>
<ul>
<li><strong>Authors: </strong>Sabera Talukder, Yisong Yue, Georgia Gkioxari</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.16412">https://arxiv.org/abs/2402.16412</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.16412">https://arxiv.org/pdf/2402.16412</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.16412]] TOTEM: TOkenized Time Series EMbeddings for General Time Series Analysis(https://arxiv.org/abs/2402.16412)</code><input type="text"></li>
<li><strong>Keywords: </strong>self-supervised</a></li>
<li><strong>Abstract: </strong>The field of general time series analysis has recently begun to explore unified modeling, where a common architectural backbone can be retrained on a specific task for a specific dataset. In this work, we approach unification from a complementary vantage point: unification across tasks and domains. To this end, we explore the impact of discrete, learnt, time series data representations that enable generalist, cross-domain training. Our method, TOTEM, or TOkenized Time Series EMbeddings, proposes a simple tokenizer architecture that embeds time series data from varying domains using a discrete vectorized representation learned in a self-supervised manner. TOTEM works across multiple tasks and domains with minimal to no tuning. We study the efficacy of TOTEM with an extensive evaluation on 17 real world time series datasets across 3 tasks. We evaluate both the specialist (i.e., training a model on each domain) and generalist (i.e., training a single model on many domains) settings, and show that TOTEM matches or outperforms previous best methods on several popular benchmarks. The code can be found at: https://github.com/SaberaTalukder/TOTEM.</li>
</ul>

<h3>Title: Predicting Sustainable Development Goals Using Course Descriptions --  from LLMs to Conventional Foundation Models</h3>
<ul>
<li><strong>Authors: </strong>Lev Kharlashkin, Melany Macias, Leo Huovinen, Mika Hämäläinen</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.16420">https://arxiv.org/abs/2402.16420</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.16420">https://arxiv.org/pdf/2402.16420</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.16420]] Predicting Sustainable Development Goals Using Course Descriptions --  from LLMs to Conventional Foundation Models(https://arxiv.org/abs/2402.16420)</code><input type="text"></li>
<li><strong>Keywords: </strong>foundation model</a></li>
<li><strong>Abstract: </strong>We present our work on predicting United Nations sustainable development goals (SDG) for university courses. We use an LLM named PaLM 2 to generate training data given a noisy human-authored course description input as input. We use this data to train several different smaller language models to predict SDGs for university courses. This work contributes to better university level adaptation of SDGs. The best performing model in our experiments was BART with an F1-score of 0.786.</li>
</ul>

<h3>Title: Outline-Guided Object Inpainting with Diffusion Models</h3>
<ul>
<li><strong>Authors: </strong>Markus Pobitzer, Filip Janicki, Mattia Rigotti, Cristiano Malossi</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.16421">https://arxiv.org/abs/2402.16421</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.16421">https://arxiv.org/pdf/2402.16421</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.16421]] Outline-Guided Object Inpainting with Diffusion Models(https://arxiv.org/abs/2402.16421)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>Instance segmentation datasets play a crucial role in training accurate and robust computer vision models. However, obtaining accurate mask annotations to produce high-quality segmentation datasets is a costly and labor-intensive process. In this work, we show how this issue can be mitigated by starting with small annotated instance segmentation datasets and augmenting them to effectively obtain a sizeable annotated dataset. We achieve that by creating variations of the available annotated object instances in a way that preserves the provided mask annotations, thereby resulting in new image-mask pairs to be added to the set of annotated images. Specifically, we generate new images using a diffusion-based inpainting model to fill out the masked area with a desired object class by guiding the diffusion through the object outline. We show that the object outline provides a simple, but also reliable and convenient training-free guidance signal for the underlying inpainting model that is often sufficient to fill out the mask with an object of the correct class without further text guidance and preserve the correspondence between generated images and the mask annotations with high precision. Our experimental results reveal that our method successfully generates realistic variations of object instances, preserving their shape characteristics while introducing diversity within the augmented area. We also show that the proposed method can naturally be combined with text guidance and other image augmentation techniques.</li>
</ul>

<h3>Title: RoCoIns: Enhancing Robustness of Large Language Models through  Code-Style Instructions</h3>
<ul>
<li><strong>Authors: </strong>Yuansen Zhang, Xiao Wang, Zhiheng Xi, Han Xia, Tao Gui, Qi Zhang, Xuanjing Huang</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.16431">https://arxiv.org/abs/2402.16431</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.16431">https://arxiv.org/pdf/2402.16431</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.16431]] RoCoIns: Enhancing Robustness of Large Language Models through  Code-Style Instructions(https://arxiv.org/abs/2402.16431)</code><input type="text"></li>
<li><strong>Keywords: </strong>in-context</a></li>
<li><strong>Abstract: </strong>Large Language Models (LLMs) have showcased remarkable capabilities in following human instructions. However, recent studies have raised concerns about the robustness of LLMs when prompted with instructions combining textual adversarial samples. In this paper, drawing inspiration from recent works that LLMs are sensitive to the design of the instructions, we utilize instructions in code style, which are more structural and less ambiguous, to replace typically natural language instructions. Through this conversion, we provide LLMs with more precise instructions and strengthen the robustness of LLMs. Moreover, under few-shot scenarios, we propose a novel method to compose in-context demonstrations using both clean and adversarial samples (\textit{adversarial context method}) to further boost the robustness of the LLMs. Experiments on eight robustness datasets show that our method consistently outperforms prompting LLMs with natural language instructions. For example, with gpt-3.5-turbo, our method achieves an improvement of 5.68\% in test set accuracy and a reduction of 5.66 points in Attack Success Rate (ASR).</li>
</ul>

<h3>Title: Training Implicit Generative Models via an Invariant Statistical Loss</h3>
<ul>
<li><strong>Authors: </strong>José Manuel de Frutos, Pablo M. Olmos, Manuel A. Vázquez, Joaquín Míguez</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, math.ST, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.16435">https://arxiv.org/abs/2402.16435</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.16435">https://arxiv.org/pdf/2402.16435</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.16435]] Training Implicit Generative Models via an Invariant Statistical Loss(https://arxiv.org/abs/2402.16435)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>Implicit generative models have the capability to learn arbitrary complex data distributions. On the downside, training requires telling apart real data from artificially-generated ones using adversarial discriminators, leading to unstable training and mode-dropping issues. As reported by Zahee et al. (2017), even in the one-dimensional (1D) case, training a generative adversarial network (GAN) is challenging and often suboptimal. In this work, we develop a discriminator-free method for training one-dimensional (1D) generative implicit models and subsequently expand this method to accommodate multivariate cases. Our loss function is a discrepancy measure between a suitably chosen transformation of the model samples and a uniform distribution; hence, it is invariant with respect to the true distribution of the data. We first formulate our method for 1D random variables, providing an effective solution for approximate reparameterization of arbitrary complex distributions. Then, we consider the temporal setting (both univariate and multivariate), in which we model the conditional distribution of each sample given the history of the process. We demonstrate through numerical simulations that this new method yields promising results, successfully learning true distributions in a variety of scenarios and mitigating some of the well-known problems that state-of-the-art implicit methods present.</li>
</ul>

<h3>Title: Stochastic Conditional Diffusion Models for Semantic Image Synthesis</h3>
<ul>
<li><strong>Authors: </strong>Juyeon Ko, Inho Kong, Hyunwoo J. Kim</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.16506">https://arxiv.org/abs/2402.16506</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.16506">https://arxiv.org/pdf/2402.16506</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.16506]] Stochastic Conditional Diffusion Models for Semantic Image Synthesis(https://arxiv.org/abs/2402.16506)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>Semantic image synthesis (SIS) is a task to generate realistic images corresponding to semantic maps (labels). It can be applied to diverse real-world practices such as photo editing or content creation. However, in real-world applications, SIS often encounters noisy user inputs. To address this, we propose Stochastic Conditional Diffusion Model (SCDM), which is a robust conditional diffusion model that features novel forward and generation processes tailored for SIS with noisy labels. It enhances robustness by stochastically perturbing the semantic label maps through Label Diffusion, which diffuses the labels with discrete diffusion. Through the diffusion of labels, the noisy and clean semantic maps become similar as the timestep increases, eventually becoming identical at $t=T$. This facilitates the generation of an image close to a clean image, enabling robust generation. Furthermore, we propose a class-wise noise schedule to differentially diffuse the labels depending on the class. We demonstrate that the proposed method generates high-quality samples through extensive experiments and analyses on benchmark datasets, including a novel experimental setup simulating human errors during real-world applications.</li>
</ul>

<h3>Title: Pre-training Cross-lingual Open Domain Question Answering with  Large-scale Synthetic Supervision</h3>
<ul>
<li><strong>Authors: </strong>Fan Jiang, Tom Drummond, Trevor Cohn</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.IR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.16508">https://arxiv.org/abs/2402.16508</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.16508">https://arxiv.org/pdf/2402.16508</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.16508]] Pre-training Cross-lingual Open Domain Question Answering with  Large-scale Synthetic Supervision(https://arxiv.org/abs/2402.16508)</code><input type="text"></li>
<li><strong>Keywords: </strong>self-supervised</a></li>
<li><strong>Abstract: </strong>Cross-lingual question answering (CLQA) is a complex problem, comprising cross-lingual retrieval from a multilingual knowledge base, followed by answer generation either in English or the query language. Both steps are usually tackled by separate models, requiring substantial annotated datasets, and typically auxiliary resources, like machine translation systems to bridge between languages. In this paper, we show that CLQA can be addressed using a single encoder-decoder model. To effectively train this model, we propose a self-supervised method based on exploiting the cross-lingual link structure within Wikipedia. We demonstrate how linked Wikipedia pages can be used to synthesise supervisory signals for cross-lingual retrieval, through a form of cloze query, and generate more natural queries to supervise answer generation. Together, we show our approach, \texttt{CLASS}, outperforms comparable methods on both supervised and zero-shot language adaptation settings, including those using machine translation.</li>
</ul>

<h3>Title: Generative Pretrained Hierarchical Transformer for Time Series  Forecasting</h3>
<ul>
<li><strong>Authors: </strong>Zhiding Liu, Jiqian Yang, Mingyue Cheng, Yucong Luo, Zhi Li</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.16516">https://arxiv.org/abs/2402.16516</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.16516">https://arxiv.org/pdf/2402.16516</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.16516]] Generative Pretrained Hierarchical Transformer for Time Series  Forecasting(https://arxiv.org/abs/2402.16516)</code><input type="text"></li>
<li><strong>Keywords: </strong>self-supervised, generative</a></li>
<li><strong>Abstract: </strong>Recent efforts have been dedicated to enhancing time series forecasting accuracy by introducing advanced network architectures and self-supervised pretraining strategies. Nevertheless, existing approaches still exhibit two critical drawbacks. Firstly, these methods often rely on a single dataset for training, limiting the model's generalizability due to the restricted scale of the training data. Secondly, the one-step generation schema is widely followed, which necessitates a customized forecasting head and overlooks the temporal dependencies in the output series, and also leads to increased training costs under different horizon length settings. To address these issues, we propose a novel generative pretrained hierarchical transformer architecture for forecasting, named GPHT. There are two aspects of key designs in GPHT. On the one hand, we advocate for constructing a mixed dataset for pretraining our model, comprising various datasets from diverse data scenarios. This approach significantly expands the scale of training data, allowing our model to uncover commonalities in time series data and facilitating improved transfer to specific datasets. On the other hand, GPHT employs an auto-regressive forecasting approach under the channel-independent assumption, effectively modeling temporal dependencies in the output series. Importantly, no customized forecasting head is required, enabling a single model to forecast at arbitrary horizon settings. We conduct sufficient experiments on eight datasets with mainstream self-supervised pretraining models and supervised models. The results demonstrated that GPHT surpasses the baseline models across various fine-tuning and zero/few-shot learning settings in the traditional long-term forecasting task, providing support for verifying the feasibility of pretrained time series large models.</li>
</ul>

<h3>Title: Two-stage Generative Question Answering on Temporal Knowledge Graph  Using Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Yifu Gao, Linbo Qiao, Zhigang Kan, Zhihua Wen, Yongquan He, Dongsheng Li</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.16568">https://arxiv.org/abs/2402.16568</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.16568">https://arxiv.org/pdf/2402.16568</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.16568]] Two-stage Generative Question Answering on Temporal Knowledge Graph  Using Large Language Models(https://arxiv.org/abs/2402.16568)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>Temporal knowledge graph question answering (TKGQA) poses a significant challenge task, due to the temporal constraints hidden in questions and the answers sought from dynamic structured knowledge. Although large language models (LLMs) have made considerable progress in their reasoning ability over structured data, their application to the TKGQA task is a relatively unexplored area. This paper first proposes a novel generative temporal knowledge graph question answering framework, GenTKGQA, which guides LLMs to answer temporal questions through two phases: Subgraph Retrieval and Answer Generation. First, we exploit LLM's intrinsic knowledge to mine temporal constraints and structural links in the questions without extra training, thus narrowing down the subgraph search space in both temporal and structural dimensions. Next, we design virtual knowledge indicators to fuse the graph neural network signals of the subgraph and the text representations of the LLM in a non-shallow way, which helps the open-source LLM deeply understand the temporal order and structural dependencies among the retrieved facts through instruction tuning. Experimental results demonstrate that our model outperforms state-of-the-art baselines, even achieving 100\% on the metrics for the simple question type.</li>
</ul>

<h3>Title: Rethinking Negative Instances for Generative Named Entity Recognition</h3>
<ul>
<li><strong>Authors: </strong>Yuyang Ding, Juntao Li, Pinzheng Wang, Zecheng Tang, Bowen Yan, Min Zhang</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.16602">https://arxiv.org/abs/2402.16602</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.16602">https://arxiv.org/pdf/2402.16602</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.16602]] Rethinking Negative Instances for Generative Named Entity Recognition(https://arxiv.org/abs/2402.16602)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>Large Language Models (LLMs) have demonstrated impressive capabilities for generalizing in unseen tasks. In the Named Entity Recognition (NER) task, recent advancements have seen the remarkable improvement of LLMs in a broad range of entity domains via instruction tuning, by adopting entity-centric schema. In this work, we explore the potential enhancement of the existing methods by incorporating negative instances into training. Our experiments reveal that negative instances contribute to remarkable improvements by (1) introducing contextual information, and (2) clearly delineating label boundaries. Furthermore, we introduce a novel and efficient algorithm named Hierarchical Matching, which is tailored to transform unstructured predictions into structured entities. By integrating these components, we present GNER, a Generative NER system that shows improved zero-shot performance across unseen entity domains. Our comprehensive evaluation illustrates our system's superiority, surpassing state-of-the-art (SoTA) methods by 11 $F_1$ score in zero-shot evaluation.</li>
</ul>

<h3>Title: Long-Context Language Modeling with Parallel Context Encoding</h3>
<ul>
<li><strong>Authors: </strong>Howard Yen, Tianyu Gao, Danqi Chen</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.16617">https://arxiv.org/abs/2402.16617</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.16617">https://arxiv.org/pdf/2402.16617</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.16617]] Long-Context Language Modeling with Parallel Context Encoding(https://arxiv.org/abs/2402.16617)</code><input type="text"></li>
<li><strong>Keywords: </strong>in-context</a></li>
<li><strong>Abstract: </strong>Extending large language models (LLMs) to process longer inputs is crucial for numerous applications. However, the considerable computational cost of transformers, coupled with limited generalization of positional encoding, restricts the size of their context window. We introduce Context Expansion with Parallel Encoding (CEPE), a framework that can be applied to any existing decoder-only LLMs to extend their context window. CEPE adopts a small encoder to process long inputs chunk by chunk and enables the frozen decoder to leverage additional contexts via cross-attention. CEPE is efficient, generalizable, and versatile: trained with 8K-token documents, CEPE extends the context window of LLAMA-2 to 128K tokens, offering 10x the throughput with only 1/6 of the memory. CEPE yields strong performance on language modeling and in-context learning. CEPE also excels in retrieval-augmented applications, while existing long-context models degenerate with retrieved contexts. We further introduce a CEPE variant that can extend the context window of instruction-tuned models with only unlabeled data, and showcase its effectiveness on LLAMA-2-CHAT, leading to a strong instruction-following model that can leverage very long context on downstream tasks.</li>
</ul>

<h3>Title: Cross-Modal Contextualized Diffusion Models for Text-Guided Visual  Generation and Editing</h3>
<ul>
<li><strong>Authors: </strong>Ling Yang, Zhilong Zhang, Zhaochen Yu, Jingwei Liu, Minkai Xu, Stefano Ermon, Bin Cui</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.16627">https://arxiv.org/abs/2402.16627</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.16627">https://arxiv.org/pdf/2402.16627</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.16627]] Cross-Modal Contextualized Diffusion Models for Text-Guided Visual  Generation and Editing(https://arxiv.org/abs/2402.16627)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>Conditional diffusion models have exhibited superior performance in high-fidelity text-guided visual generation and editing. Nevertheless, prevailing text-guided visual diffusion models primarily focus on incorporating text-visual relationships exclusively into the reverse process, often disregarding their relevance in the forward process. This inconsistency between forward and reverse processes may limit the precise conveyance of textual semantics in visual synthesis results. To address this issue, we propose a novel and general contextualized diffusion model (ContextDiff) by incorporating the cross-modal context encompassing interactions and alignments between text condition and visual sample into forward and reverse processes. We propagate this context to all timesteps in the two processes to adapt their trajectories, thereby facilitating cross-modal conditional modeling. We generalize our contextualized diffusion to both DDPMs and DDIMs with theoretical derivations, and demonstrate the effectiveness of our model in evaluations with two challenging tasks: text-to-image generation, and text-to-video editing. In each task, our ContextDiff achieves new state-of-the-art performance, significantly enhancing the semantic alignment between text condition and generated samples, as evidenced by quantitative and qualitative evaluations. Our code is available at https://github.com/YangLing0818/ContextDiff</li>
</ul>

<h3>Title: RepoAgent: An LLM-Powered Open-Source Framework for Repository-level  Code Documentation Generation</h3>
<ul>
<li><strong>Authors: </strong>Qinyu Luo, Yining Ye, Shihao Liang, Zhong Zhang, Yujia Qin, Yaxi Lu, Yesai Wu, Xin Cong, Yankai Lin, Yingli Zhang, Xiaoyin Che, Zhiyuan Liu, Maosong Sun</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.16667">https://arxiv.org/abs/2402.16667</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.16667">https://arxiv.org/pdf/2402.16667</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.16667]] RepoAgent: An LLM-Powered Open-Source Framework for Repository-level  Code Documentation Generation(https://arxiv.org/abs/2402.16667)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>Generative models have demonstrated considerable potential in software engineering, particularly in tasks such as code generation and debugging. However, their utilization in the domain of code documentation generation remains underexplored. To this end, we introduce RepoAgent, a large language model powered open-source framework aimed at proactively generating, maintaining, and updating code documentation. Through both qualitative and quantitative evaluations, we have validated the effectiveness of our approach, showing that RepoAgent excels in generating high-quality repository-level documentation. The code and results are publicly accessible at https://github.com/OpenBMB/RepoAgent.</li>
</ul>

<h3>Title: Look Before You Leap: Towards Decision-Aware and Generalizable  Tool-Usage for Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Anchun Gui, Jian Li, Yong Dai, Nan Du, Han Xiao</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.16696">https://arxiv.org/abs/2402.16696</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.16696">https://arxiv.org/pdf/2402.16696</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.16696]] Look Before You Leap: Towards Decision-Aware and Generalizable  Tool-Usage for Large Language Models(https://arxiv.org/abs/2402.16696)</code><input type="text"></li>
<li><strong>Keywords: </strong>in-context</a></li>
<li><strong>Abstract: </strong>Tool-augmented large language models (LLMs) are attracting widespread attention when accessing up-to-date knowledge and alleviating hallucination issues. Nowadays, advanced closed-source LLMs (e.g., ChatGPT) have demonstrated surprising tool-usage capabilities through prompting and in-context learning techniques. To empower the capabilities of open-source LLMs (e.g., LLaMA) in manipulating tools, current efforts focus on either template-driven or token-triggered tool-usage. However, the former hampers LLMs' flexibility to address diverse user's queries due to constrained tool interactions, while the latter limits the generalizability when engaging with new tools, since tool-usage learning is based on task- and tool-specific datasets. To alleviate these concerns, in this paper, we propose a decision-aware and generalizable tool-usage framework (DEER). Specifically, we first construct the tool-usage samples with multiple decision branches via an automatic generation pipeline, thereby inspiring the decision-making awareness of LLMs under diverse scenarios. Meanwhile, we propose a novel tool sampling strategy to enhance the generalizability of LLMs over unseen tools. Extensive experiments demonstrate that our proposed DEER is effective and significantly outperforms baselines across various datasets.</li>
</ul>

<h3>Title: SelectIT: Selective Instruction Tuning for Large Language Models via  Uncertainty-Aware Self-Reflection</h3>
<ul>
<li><strong>Authors: </strong>Liangxin Liu, Xuebo Liu, Derek F. Wong, Dongfang Li, Ziyi Wang, Baotian Hu, Min Zhang</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.16705">https://arxiv.org/abs/2402.16705</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.16705">https://arxiv.org/pdf/2402.16705</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.16705]] SelectIT: Selective Instruction Tuning for Large Language Models via  Uncertainty-Aware Self-Reflection(https://arxiv.org/abs/2402.16705)</code><input type="text"></li>
<li><strong>Keywords: </strong>foundation model</a></li>
<li><strong>Abstract: </strong>Instruction tuning (IT) is crucial to tailoring large language models (LLMs) towards human-centric interactions. Recent advancements have shown that the careful selection of a small, high-quality subset of IT data can significantly enhance the performance of LLMs. Despite this, common approaches often rely on additional models or data sets, which increases costs and limits widespread adoption. In this work, we propose a novel approach, termed SelectIT, that capitalizes on the foundational capabilities of the LLM itself. Specifically, we exploit the intrinsic uncertainty present in LLMs to more effectively select high-quality IT data, without the need for extra resources. Furthermore, we introduce a novel IT dataset, the Selective Alpaca, created by applying SelectIT to the Alpaca-GPT4 dataset. Empirical results demonstrate that IT using Selective Alpaca leads to substantial model ability enhancement. The robustness of SelectIT has also been corroborated in various foundation models and domain-specific tasks. Our findings suggest that longer and more computationally intensive IT data may serve as superior sources of IT, offering valuable insights for future research in this area. Data, code, and scripts are freely available at https://github.com/Blue-Raincoat/SelectIT.</li>
</ul>

<h3>Title: Investigating the Effectiveness of HyperTuning via Gisting</h3>
<ul>
<li><strong>Authors: </strong>Jason Phang</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.16817">https://arxiv.org/abs/2402.16817</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.16817">https://arxiv.org/pdf/2402.16817</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.16817]] Investigating the Effectiveness of HyperTuning via Gisting(https://arxiv.org/abs/2402.16817)</code><input type="text"></li>
<li><strong>Keywords: </strong>in-context</a></li>
<li><strong>Abstract: </strong>Gisting (Mu et al., 2023) is a simple method for training models to compress information into fewer token representations using a modified attention mask, and can serve as an economical approach to training Transformer-based hypernetworks. We introduce HyperLlama, a set of Gisting-based hypernetworks built on Llama-2 models that generates task-specific soft prefixes based on few-shot inputs. In experiments across P3, Super-NaturalInstructions and Symbol Tuning datasets, we show that HyperLlama models can effectively compress information from few-shot examples into soft prefixes. However, they still underperform multi-task fine-tuned language models with full attention over few-shot in-context examples. We also show that HyperLlama-generated soft prefixes can serve as better initializations for further prefix tuning. Overall, Gisting-based hypernetworks are economical and easy to implement, but have mixed empirical performance.</li>
</ul>

<h3>Title: Asymmetry in Low-Rank Adapters of Foundation Models</h3>
<ul>
<li><strong>Authors: </strong>Jiacheng Zhu, Kristjan Greenewald, Kimia Nadjahi, Haitz Sáez de Ocáriz Borde, Rickard Brüel Gabrielsson, Leshem Choshen, Marzyeh Ghassemi, Mikhail Yurochkin, Justin Solomon</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2402.16842">https://arxiv.org/abs/2402.16842</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2402.16842">https://arxiv.org/pdf/2402.16842</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2402.16842]] Asymmetry in Low-Rank Adapters of Foundation Models(https://arxiv.org/abs/2402.16842)</code><input type="text"></li>
<li><strong>Keywords: </strong>foundation model</a></li>
<li><strong>Abstract: </strong>Parameter-efficient fine-tuning optimizes large, pre-trained foundation models by updating a subset of parameters; in this class, Low-Rank Adaptation (LoRA) is particularly effective. Inspired by an effort to investigate the different roles of LoRA matrices during fine-tuning, this paper characterizes and leverages unexpected asymmetry in the importance of low-rank adapter matrices. Specifically, when updating the parameter matrices of a neural network by adding a product $BA$, we observe that the $B$ and $A$ matrices have distinct functions: $A$ extracts features from the input, while $B$ uses these features to create the desired output. Based on this observation, we demonstrate that fine-tuning $B$ is inherently more effective than fine-tuning $A$, and that a random untrained $A$ should perform nearly as well as a fine-tuned one. Using an information-theoretic lens, we also bound the generalization of low-rank adapters, showing that the parameter savings of exclusively training $B$ improves the bound. We support our conclusions with experiments on RoBERTa, BART-Large, LLaMA-2, and ViTs.</li>
</ul>

<button id="copy">Copy All</button>
</article>
<script src="../../javascript/clipboard.min.js"></script>
<script src="../../javascript/clipboard.js"></script>
