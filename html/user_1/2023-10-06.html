<link rel="stylesheet" href="../../css/markdown.css" />
<article class="markdown-body">
<h2>diffusion</h2>
<h3>Title: EfficientDM: Efficient Quantization-Aware Fine-Tuning of Low-Bit Diffusion Models. (arXiv:2310.03270v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.03270">http://arxiv.org/abs/2310.03270</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.03270]] EfficientDM: Efficient Quantization-Aware Fine-Tuning of Low-Bit Diffusion Models(http://arxiv.org/abs/2310.03270)</code></li>
<li>Summary: <p>Diffusion models have demonstrated remarkable capabilities in image synthesis
and related generative tasks. Nevertheless, their practicality for low-latency
real-world applications is constrained by substantial computational costs and
latency issues. Quantization is a dominant way to compress and accelerate
diffusion models, where post-training quantization (PTQ) and quantization-aware
training (QAT) are two main approaches, each bearing its own properties. While
PTQ exhibits efficiency in terms of both time and data usage, it may lead to
diminished performance in low bit-width. On the other hand, QAT can alleviate
performance degradation but comes with substantial demands on computational and
data resources. To capitalize on the advantages while avoiding their respective
drawbacks, we introduce a data-free and parameter-efficient fine-tuning
framework for low-bit diffusion models, dubbed EfficientDM, to achieve
QAT-level performance with PTQ-like efficiency. Specifically, we propose a
quantization-aware variant of the low-rank adapter (QALoRA) that can be merged
with model weights and jointly quantized to low bit-width. The fine-tuning
process distills the denoising capabilities of the full-precision model into
its quantized counterpart, eliminating the requirement for training data. We
also introduce scale-aware optimization and employ temporal learned step-size
quantization to further enhance performance. Extensive experimental results
demonstrate that our method significantly outperforms previous PTQ-based
diffusion models while maintaining similar time and data efficiency.
Specifically, there is only a marginal 0.05 sFID increase when quantizing both
weights and activations of LDM-4 to 4-bit on ImageNet 256x256. Compared to
QAT-based methods, our EfficientDM also boasts a 16.2x faster quantization
speed with comparable generation quality.
</p></li>
</ul>

<h3>Title: Denoising Diffusion Step-aware Models. (arXiv:2310.03337v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.03337">http://arxiv.org/abs/2310.03337</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.03337]] Denoising Diffusion Step-aware Models(http://arxiv.org/abs/2310.03337)</code></li>
<li>Summary: <p>Denoising Diffusion Probabilistic Models (DDPMs) have garnered popularity for
data generation across various domains. However, a significant bottleneck is
the necessity for whole-network computation during every step of the generative
process, leading to high computational overheads. This paper presents a novel
framework, Denoising Diffusion Step-aware Models (DDSM), to address this
challenge. Unlike conventional approaches, DDSM employs a spectrum of neural
networks whose sizes are adapted according to the importance of each generative
step, as determined through evolutionary search. This step-wise network
variation effectively circumvents redundant computational efforts, particularly
in less critical steps, thereby enhancing the efficiency of the diffusion
model. Furthermore, the step-aware design can be seamlessly integrated with
other efficiency-geared diffusion models such as DDIMs and latent diffusion,
thus broadening the scope of computational savings. Empirical evaluations
demonstrate that DDSM achieves computational savings of 49% for CIFAR-10, 61%
for CelebA-HQ, 59% for LSUN-bedroom, 71% for AFHQ, and 76% for ImageNet, all
without compromising the generation quality. Our code and models will be
publicly available.
</p></li>
</ul>

<h3>Title: Realistic Speech-to-Face Generation with Speech-Conditioned Latent Diffusion Model with Face Prior. (arXiv:2310.03363v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.03363">http://arxiv.org/abs/2310.03363</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.03363]] Realistic Speech-to-Face Generation with Speech-Conditioned Latent Diffusion Model with Face Prior(http://arxiv.org/abs/2310.03363)</code></li>
<li>Summary: <p>Speech-to-face generation is an intriguing area of research that focuses on
generating realistic facial images based on a speaker's audio speech. However,
state-of-the-art methods employing GAN-based architectures lack stability and
cannot generate realistic face images. To fill this gap, we propose a novel
speech-to-face generation framework, which leverages a Speech-Conditioned
Latent Diffusion Model, called SCLDM. To the best of our knowledge, this is the
first work to harness the exceptional modeling capabilities of diffusion models
for speech-to-face generation. Preserving the shared identity information
between speech and face is crucial in generating realistic results. Therefore,
we employ contrastive pre-training for both the speech encoder and the face
encoder. This pre-training strategy facilitates effective alignment between the
attributes of speech, such as age and gender, and the corresponding facial
characteristics in the face images. Furthermore, we tackle the challenge posed
by excessive diversity in the synthesis process caused by the diffusion model.
To overcome this challenge, we introduce the concept of residuals by
integrating a statistical face prior to the diffusion process. This addition
helps to eliminate the shared component across the faces and enhances the
subtle variations captured by the speech condition. Extensive quantitative,
qualitative, and user study experiments demonstrate that our method can produce
more realistic face images while preserving the identity of the speaker better
than state-of-the-art methods. Highlighting the notable enhancements, our
method demonstrates significant gains in all metrics on the AVSpeech dataset
and Voxceleb dataset, particularly noteworthy are the improvements of 32.17 and
32.72 on the cosine distance metric for the two datasets, respectively.
</p></li>
</ul>

<h3>Title: ACT-Net: Anchor-context Action Detection in Surgery Videos. (arXiv:2310.03377v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.03377">http://arxiv.org/abs/2310.03377</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.03377]] ACT-Net: Anchor-context Action Detection in Surgery Videos(http://arxiv.org/abs/2310.03377)</code></li>
<li>Summary: <p>Recognition and localization of surgical detailed actions is an essential
component of developing a context-aware decision support system. However, most
existing detection algorithms fail to provide high-accuracy action classes even
having their locations, as they do not consider the surgery procedure's
regularity in the whole video. This limitation hinders their application.
Moreover, implementing the predictions in clinical applications seriously needs
to convey model confidence to earn entrustment, which is unexplored in surgical
action prediction. In this paper, to accurately detect fine-grained actions
that happen at every moment, we propose an anchor-context action detection
network (ACTNet), including an anchor-context detection (ACD) module and a
class conditional diffusion (CCD) module, to answer the following questions: 1)
where the actions happen; 2) what actions are; 3) how confidence predictions
are. Specifically, the proposed ACD module spatially and temporally highlights
the regions interacting with the extracted anchor in surgery video, which
outputs action location and its class distribution based on anchor-context
interactions. Considering the full distribution of action classes in videos,
the CCD module adopts a denoising diffusion-based generative model conditioned
on our ACD estimator to further reconstruct accurately the action predictions.
Moreover, we utilize the stochastic nature of the diffusion model outputs to
access model confidence for each prediction. Our method reports the
state-of-the-art performance, with improvements of 4.0% mAP against baseline on
the surgical video dataset.
</p></li>
</ul>

<h3>Title: FreeReg: Image-to-Point Cloud Registration Leveraging Pretrained Diffusion Models and Monocular Depth Estimators. (arXiv:2310.03420v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.03420">http://arxiv.org/abs/2310.03420</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.03420]] FreeReg: Image-to-Point Cloud Registration Leveraging Pretrained Diffusion Models and Monocular Depth Estimators(http://arxiv.org/abs/2310.03420)</code></li>
<li>Summary: <p>Matching cross-modality features between images and point clouds is a
fundamental problem for image-to-point cloud registration. However, due to the
modality difference between images and points, it is difficult to learn robust
and discriminative cross-modality features by existing metric learning methods
for feature matching. Instead of applying metric learning on cross-modality
data, we propose to unify the modality between images and point clouds by
pretrained large-scale models first, and then establish robust correspondence
within the same modality. We show that the intermediate features, called
diffusion features, extracted by depth-to-image diffusion models are
semantically consistent between images and point clouds, which enables the
building of coarse but robust cross-modality correspondences. We further
extract geometric features on depth maps produced by the monocular depth
estimator. By matching such geometric features, we significantly improve the
accuracy of the coarse correspondences produced by diffusion features.
Extensive experiments demonstrate that without any task-specific training,
direct utilization of both features produces accurate image-to-point cloud
registration. On three public indoor and outdoor benchmarks, the proposed
method averagely achieves a 20.6 percent improvement in Inlier Ratio, a
three-fold higher Inlier Number, and a 48.6 percent improvement in Registration
Recall than existing state-of-the-arts.
</p></li>
</ul>

<h3>Title: Kandinsky: an Improved Text-to-Image Synthesis with Image Prior and Latent Diffusion. (arXiv:2310.03502v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.03502">http://arxiv.org/abs/2310.03502</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.03502]] Kandinsky: an Improved Text-to-Image Synthesis with Image Prior and Latent Diffusion(http://arxiv.org/abs/2310.03502)</code></li>
<li>Summary: <p>Text-to-image generation is a significant domain in modern computer vision
and has achieved substantial improvements through the evolution of generative
architectures. Among these, there are diffusion-based models that have
demonstrated essential quality enhancements. These models are generally split
into two categories: pixel-level and latent-level approaches. We present
Kandinsky1, a novel exploration of latent diffusion architecture, combining the
principles of the image prior models with latent diffusion techniques. The
image prior model is trained separately to map text embeddings to image
embeddings of CLIP. Another distinct feature of the proposed model is the
modified MoVQ implementation, which serves as the image autoencoder component.
Overall, the designed model contains 3.3B parameters. We also deployed a
user-friendly demo system that supports diverse generative modes such as
text-to-image generation, image fusion, text and image fusion, image variations
generation, and text-guided inpainting/outpainting. Additionally, we released
the source code and checkpoints for the Kandinsky models. Experimental
evaluations demonstrate a FID score of 8.03 on the COCO-30K dataset, marking
our model as the top open-source performer in terms of measurable image
generation quality.
</p></li>
</ul>

<h3>Title: Ctrl-Room: Controllable Text-to-3D Room Meshes Generation with Layout Constraints. (arXiv:2310.03602v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.03602">http://arxiv.org/abs/2310.03602</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.03602]] Ctrl-Room: Controllable Text-to-3D Room Meshes Generation with Layout Constraints(http://arxiv.org/abs/2310.03602)</code></li>
<li>Summary: <p>Text-driven 3D indoor scene generation could be useful for gaming, film
industry, and AR/VR applications. However, existing methods cannot faithfully
capture the room layout, nor do they allow flexible editing of individual
objects in the room. To address these problems, we present Ctrl-Room, which is
able to generate convincing 3D rooms with designer-style layouts and
high-fidelity textures from just a text prompt. Moreover, Ctrl-Room enables
versatile interactive editing operations such as resizing or moving individual
furniture items. Our key insight is to separate the modeling of layouts and
appearance. %how to model the room that takes into account both scene texture
and geometry at the same time. To this end, Our proposed method consists of two
stages, a `Layout Generation Stage' and an `Appearance Generation Stage'. The
`Layout Generation Stage' trains a text-conditional diffusion model to learn
the layout distribution with our holistic scene code parameterization. Next,
the `Appearance Generation Stage' employs a fine-tuned ControlNet to produce a
vivid panoramic image of the room guided by the 3D scene layout and text
prompt. In this way, we achieve a high-quality 3D room with convincing layouts
and lively textures. Benefiting from the scene code parameterization, we can
easily edit the generated room model through our mask-guided editing module,
without expensive editing-specific training. Extensive experiments on the
Structured3D dataset demonstrate that our method outperforms existing methods
in producing more reasonable, view-consistent, and editable 3D rooms from
natural language prompts.
</p></li>
</ul>

<h3>Title: Learning Energy-Based Prior Model with Diffusion-Amortized MCMC. (arXiv:2310.03218v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.03218">http://arxiv.org/abs/2310.03218</a></li>
<li>Code URL: https://github.com/yupeiyu98/diffusion-amortized-mcmc</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.03218]] Learning Energy-Based Prior Model with Diffusion-Amortized MCMC(http://arxiv.org/abs/2310.03218)</code></li>
<li>Summary: <p>Latent space Energy-Based Models (EBMs), also known as energy-based priors,
have drawn growing interests in the field of generative modeling due to its
flexibility in the formulation and strong modeling power of the latent space.
However, the common practice of learning latent space EBMs with non-convergent
short-run MCMC for prior and posterior sampling is hindering the model from
further progress; the degenerate MCMC sampling quality in practice often leads
to degraded generation quality and instability in training, especially with
highly multi-modal and/or high-dimensional target distributions. To remedy this
sampling issue, in this paper we introduce a simple but effective
diffusion-based amortization method for long-run MCMC sampling and develop a
novel learning algorithm for the latent space EBM based on it. We provide
theoretical evidence that the learned amortization of MCMC is a valid long-run
MCMC sampler. Experiments on several image modeling benchmark datasets
demonstrate the superior performance of our method compared with strong
counterparts
</p></li>
</ul>

<h3>Title: Stochastic interpolants with data-dependent couplings. (arXiv:2310.03725v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.03725">http://arxiv.org/abs/2310.03725</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.03725]] Stochastic interpolants with data-dependent couplings(http://arxiv.org/abs/2310.03725)</code></li>
<li>Summary: <p>Generative models inspired by dynamical transport of measure -- such as flows
and diffusions -- construct a continuous-time map between two probability
densities. Conventionally, one of these is the target density, only accessible
through samples, while the other is taken as a simple base density that is
data-agnostic. In this work, using the framework of stochastic interpolants, we
formalize how to \textit{couple} the base and the target densities. This
enables us to incorporate information about class labels or continuous
embeddings to construct dynamical transport maps that serve as conditional
generative models. We show that these transport maps can be learned by solving
a simple square loss regression problem analogous to the standard independent
setting. We demonstrate the usefulness of constructing dependent couplings in
practice through experiments in super-resolution and in-painting.
</p></li>
</ul>

<h2>self-supervised</h2>
<h3>Title: Exploring DINO: Emergent Properties and Limitations for Synthetic Aperture Radar Imagery. (arXiv:2310.03513v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.03513">http://arxiv.org/abs/2310.03513</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.03513]] Exploring DINO: Emergent Properties and Limitations for Synthetic Aperture Radar Imagery(http://arxiv.org/abs/2310.03513)</code></li>
<li>Summary: <p>Self-supervised learning (SSL) models have recently demonstrated remarkable
performance across various tasks, including image segmentation. This study
delves into the emergent characteristics of the Self-Distillation with No
Labels (DINO) algorithm and its application to Synthetic Aperture Radar (SAR)
imagery. We pre-train a vision transformer (ViT)-based DINO model using
unlabeled SAR data, and later fine-tune the model to predict high-resolution
land cover maps. We rigorously evaluate the utility of attention maps generated
by the ViT backbone, and compare them with the model's token embedding space.
We observe a small improvement in model performance with pre-training compared
to training from scratch, and discuss the limitations and opportunities of SSL
for remote sensing and land cover segmentation. Beyond small performance
increases, we show that ViT attention maps hold great intrinsic value for
remote sensing, and could provide useful inputs to other algorithms. With this,
our work lays the ground-work for bigger and better SSL models for Earth
Observation.
</p></li>
</ul>

<h3>Title: Regress Before Construct: Regress Autoencoder for Point Cloud Self-supervised Learning. (arXiv:2310.03670v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.03670">http://arxiv.org/abs/2310.03670</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.03670]] Regress Before Construct: Regress Autoencoder for Point Cloud Self-supervised Learning(http://arxiv.org/abs/2310.03670)</code></li>
<li>Summary: <p>Masked Autoencoders (MAE) have demonstrated promising performance in
self-supervised learning for both 2D and 3D computer vision. Nevertheless,
existing MAE-based methods still have certain drawbacks. Firstly, the
functional decoupling between the encoder and decoder is incomplete, which
limits the encoder's representation learning ability. Secondly, downstream
tasks solely utilize the encoder, failing to fully leverage the knowledge
acquired through the encoder-decoder architecture in the pre-text task. In this
paper, we propose Point Regress AutoEncoder (Point-RAE), a new scheme for
regressive autoencoders for point cloud self-supervised learning. The proposed
method decouples functions between the decoder and the encoder by introducing a
mask regressor, which predicts the masked patch representation from the visible
patch representation encoded by the encoder and the decoder reconstructs the
target from the predicted masked patch representation. By doing so, we minimize
the impact of decoder updates on the representation space of the encoder.
Moreover, we introduce an alignment constraint to ensure that the
representations for masked patches, predicted from the encoded representations
of visible patches, are aligned with the masked patch presentations computed
from the encoder. To make full use of the knowledge learned in the pre-training
stage, we design a new finetune mode for the proposed Point-RAE. Extensive
experiments demonstrate that our approach is efficient during pre-training and
generalizes well on various downstream tasks. Specifically, our pre-trained
models achieve a high accuracy of \textbf{90.28\%} on the ScanObjectNN hardest
split and \textbf{94.1\%} accuracy on ModelNet40, surpassing all the other
self-supervised learning methods. Our code and pretrained model are public
available at: \url{https://github.com/liuyyy111/Point-RAE}.
</p></li>
</ul>

<h3>Title: OMG-ATTACK: Self-Supervised On-Manifold Generation of Transferable Evasion Attacks. (arXiv:2310.03707v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.03707">http://arxiv.org/abs/2310.03707</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.03707]] OMG-ATTACK: Self-Supervised On-Manifold Generation of Transferable Evasion Attacks(http://arxiv.org/abs/2310.03707)</code></li>
<li>Summary: <p>Evasion Attacks (EA) are used to test the robustness of trained neural
networks by distorting input data to misguide the model into incorrect
classifications. Creating these attacks is a challenging task, especially with
the ever-increasing complexity of models and datasets. In this work, we
introduce a self-supervised, computationally economical method for generating
adversarial examples, designed for the unseen black-box setting. Adapting
techniques from representation learning, our method generates on-manifold EAs
that are encouraged to resemble the data distribution. These attacks are
comparable in effectiveness compared to the state-of-the-art when attacking the
model trained on, but are significantly more effective when attacking unseen
models, as the attacks are more related to the data rather than the model
itself. Our experiments consistently demonstrate the method is effective across
various models, unseen data categories, and even defended models, suggesting a
significant role for on-manifold EAs when targeting unseen models.
</p></li>
</ul>

<h3>Title: Evaluating Self-Supervised Speech Representations for Indigenous American Languages. (arXiv:2310.03639v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.03639">http://arxiv.org/abs/2310.03639</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.03639]] Evaluating Self-Supervised Speech Representations for Indigenous American Languages(http://arxiv.org/abs/2310.03639)</code></li>
<li>Summary: <p>The application of self-supervision to speech representation learning has
garnered significant interest in recent years, due to its scalability to large
amounts of unlabeled data. However, much progress, both in terms of
pre-training and downstream evaluation, has remained concentrated in
monolingual models that only consider English. Few models consider other
languages, and even fewer consider indigenous ones. In our submission to the
New Language Track of the ASRU 2023 ML-SUPERB Challenge, we present an ASR
corpus for Quechua, an indigenous South American Language. We benchmark the
efficacy of large SSL models on Quechua, along with 6 other indigenous
languages such as Guarani and Bribri, on low-resource ASR. Our results show
surprisingly strong performance by state-of-the-art SSL models, showing the
potential generalizability of large-scale models to real-world data.
</p></li>
</ul>

<h3>Title: StegGuard: Fingerprinting Self-supervised Pre-trained Encoders via Secrets Embeder and Extractor. (arXiv:2310.03380v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.03380">http://arxiv.org/abs/2310.03380</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.03380]] StegGuard: Fingerprinting Self-supervised Pre-trained Encoders via Secrets Embeder and Extractor(http://arxiv.org/abs/2310.03380)</code></li>
<li>Summary: <p>In this work, we propose StegGuard, a novel fingerprinting mechanism to
verify the ownership of the suspect pre-trained encoder using steganography. A
critical perspective in StegGuard is that the unique characteristic of the
transformation from an image to an embedding, conducted by the pre-trained
encoder, can be equivalently exposed how an embeder embeds secrets into images
and how an extractor extracts the secrets from encoder's embeddings with a
tolerable error after the secrets are subjected to the encoder's
transformation. While each independent encoder has a distinct transformation,
the piracy encoder has a similar transformation to the victim. Based on these,
we learn a pair of secrets embeder and extractor as the fingerprint for the
victim encoder. We introduce a frequency-domain channel attention embedding
block into the embeder to adaptively embed secrets into suitable frequency
bands. During verification, if the secrets embedded into the query images can
be extracted with an acceptable error from the suspect encoder's embeddings,
the suspect encoder is determined as piracy, otherwise independent. Extensive
experiments demonstrate that depending on a very limited number of query
images, StegGuard can reliably identify across varied independent encoders, and
is robust against model stealing related attacks including model extraction,
fine-tuning, pruning, embedding noising and shuffle.
</p></li>
</ul>

<h3>Title: Fragment-based Pretraining and Finetuning on Molecular Graphs. (arXiv:2310.03274v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.03274">http://arxiv.org/abs/2310.03274</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.03274]] Fragment-based Pretraining and Finetuning on Molecular Graphs(http://arxiv.org/abs/2310.03274)</code></li>
<li>Summary: <p>Property prediction on molecular graphs is an important application of Graph
Neural Networks (GNNs). Recently, unlabeled molecular data has become abundant,
which facilitates the rapid development of self-supervised learning for GNNs in
the chemical domain. In this work, we propose pretraining GNNs at the fragment
level, which serves as a promising middle ground to overcome the limitations of
node-level and graph-level pretraining. Borrowing techniques from recent work
on principle subgraph mining, we obtain a compact vocabulary of prevalent
fragments that span a large pretraining dataset. From the extracted vocabulary,
we introduce several fragment-based contrastive and predictive pretraining
tasks. The contrastive learning task jointly pretrains two different GNNs: one
based on molecular graphs and one based on fragment graphs, which represents
high-order connectivity within molecules. By enforcing the consistency between
the fragment embedding and the aggregated embedding of the corresponding atoms
from the molecular graphs, we ensure that both embeddings capture structural
information at multiple resolutions. The structural information of the fragment
graphs is further exploited to extract auxiliary labels for the graph-level
predictive pretraining. We employ both the pretrained molecular-based and
fragment-based GNNs for downstream prediction, thus utilizing the fragment
information during finetuning. Our models advance the performances on 5 out of
8 common molecular benchmarks and improve the performances on long-range
biological benchmarks by at least 11.5%.
</p></li>
</ul>

<h3>Title: How the level sampling process impacts zero-shot generalisation in deep reinforcement learning. (arXiv:2310.03494v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.03494">http://arxiv.org/abs/2310.03494</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.03494]] How the level sampling process impacts zero-shot generalisation in deep reinforcement learning(http://arxiv.org/abs/2310.03494)</code></li>
<li>Summary: <p>A key limitation preventing the wider adoption of autonomous agents trained
via deep reinforcement learning (RL) is their limited ability to generalise to
new environments, even when these share similar characteristics with
environments encountered during training. In this work, we investigate how a
non-uniform sampling strategy of individual environment instances, or levels,
affects the zero-shot generalisation (ZSG) ability of RL agents, considering
two failure modes: overfitting and over-generalisation. As a first step, we
measure the mutual information (MI) between the agent's internal representation
and the set of training levels, which we find to be well-correlated to instance
overfitting. In contrast to uniform sampling, adaptive sampling strategies
prioritising levels based on their value loss are more effective at maintaining
lower MI, which provides a novel theoretical justification for this class of
techniques. We then turn our attention to unsupervised environment design (UED)
methods, which adaptively generate new training levels and minimise MI more
effectively than methods sampling from a fixed set. However, we find UED
methods significantly shift the training distribution, resulting in
over-generalisation and worse ZSG performance over the distribution of
interest. To prevent both instance overfitting and over-generalisation, we
introduce self-supervised environment design (SSED). SSED generates levels
using a variational autoencoder, effectively reducing MI while minimising the
shift with the distribution of interest, and leads to statistically significant
improvements in ZSG over fixed-set level sampling strategies and UED methods.
</p></li>
</ul>

<h2>foundation model</h2>
<h3>Title: Investigating the Limitation of CLIP Models: The Worst-Performing Categories. (arXiv:2310.03324v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.03324">http://arxiv.org/abs/2310.03324</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.03324]] Investigating the Limitation of CLIP Models: The Worst-Performing Categories(http://arxiv.org/abs/2310.03324)</code></li>
<li>Summary: <p>Contrastive Language-Image Pre-training (CLIP) provides a foundation model by
integrating natural language into visual concepts, enabling zero-shot
recognition on downstream tasks. It is usually expected that satisfactory
overall accuracy can be achieved across numerous domains through well-designed
textual prompts. However, we found that their performance in the worst
categories is significantly inferior to the overall performance. For example,
on ImageNet, there are a total of 10 categories with class-wise accuracy as low
as 0\%, even though the overall performance has achieved 64.1\%. This
phenomenon reveals the potential risks associated with using CLIP models,
particularly in risk-sensitive applications where specific categories hold
significant importance. To address this issue, we investigate the alignment
between the two modalities in the CLIP model and propose the Class-wise
Matching Margin (\cmm) to measure the inference confusion. \cmm\ can
effectively identify the worst-performing categories and estimate the potential
performance of the candidate prompts. We further query large language models to
enrich descriptions of worst-performing categories and build a weighted
ensemble to highlight the efficient prompts. Experimental results clearly
verify the effectiveness of our proposal, where the accuracy on the worst-10
categories on ImageNet is boosted to 5.2\%, without manual prompt engineering,
laborious optimization, or access to labeled validation data.
</p></li>
</ul>

<h3>Title: Federated Fine-Tuning of LLMs on the Very Edge: The Good, the Bad, the Ugly. (arXiv:2310.03150v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.03150">http://arxiv.org/abs/2310.03150</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.03150]] Federated Fine-Tuning of LLMs on the Very Edge: The Good, the Bad, the Ugly(http://arxiv.org/abs/2310.03150)</code></li>
<li>Summary: <p>Large Language Models (LLM) and foundation models are popular as they offer
new opportunities for individuals and businesses to improve natural language
processing, interact with data, and retrieve information faster. However,
training or fine-tuning LLMs requires a vast amount of data, which can be
challenging to access due to legal or technical restrictions and may require
private computing resources. Federated Learning (FL) is a solution designed to
overcome these challenges and expand data access for deep learning
applications.
</p>
<p>This paper takes a hardware-centric approach to explore how LLMs can be
brought to modern edge computing systems. Our study fine-tunes the FLAN-T5
model family, ranging from 80M to 3B parameters, using FL for a text
summarization task. We provide a micro-level hardware benchmark, compare the
model FLOP utilization to a state-of-the-art data center GPU, and study the
network utilization in realistic conditions. Our contribution is twofold:
First, we evaluate the current capabilities of edge computing systems and their
potential for LLM FL workloads. Second, by comparing these systems with a
data-center GPU, we demonstrate the potential for improvement and the next
steps toward achieving greater computational efficiency at the edge.
</p></li>
</ul>

<h3>Title: BioBridge: Bridging Biomedical Foundation Models via Knowledge Graph. (arXiv:2310.03320v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.03320">http://arxiv.org/abs/2310.03320</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.03320]] BioBridge: Bridging Biomedical Foundation Models via Knowledge Graph(http://arxiv.org/abs/2310.03320)</code></li>
<li>Summary: <p>Foundation models (FMs) are able to leverage large volumes of unlabeled data
to demonstrate superior performance across a wide range of tasks. However, FMs
developed for biomedical domains have largely remained unimodal, i.e.,
independently trained and used for tasks on protein sequences alone, small
molecule structures alone, or clinical data alone. To overcome this limitation
of biomedical FMs, we present BioBridge, a novel parameter-efficient learning
framework, to bridge independently trained unimodal FMs to establish multimodal
behavior. BioBridge achieves it by utilizing Knowledge Graphs (KG) to learn
transformations between one unimodal FM and another without fine-tuning any
underlying unimodal FMs. Our empirical results demonstrate that BioBridge can
beat the best baseline KG embedding methods (on average by around 76.3%) in
cross-modal retrieval tasks. We also identify BioBridge demonstrates
out-of-domain generalization ability by extrapolating to unseen modalities or
relations. Additionally, we also show that BioBridge presents itself as a
general purpose retriever that can aid biomedical multimodal question answering
as well as enhance the guided generation of novel drugs.
</p></li>
</ul>

<h3>Title: TimeGPT-1. (arXiv:2310.03589v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.03589">http://arxiv.org/abs/2310.03589</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.03589]] TimeGPT-1(http://arxiv.org/abs/2310.03589)</code></li>
<li>Summary: <p>In this paper, we introduce TimeGPT, the first foundation model for time
series, capable of generating accurate predictions for diverse datasets not
seen during training. We evaluate our pre-trained model against established
statistical, machine learning, and deep learning methods, demonstrating that
TimeGPT zero-shot inference excels in performance, efficiency, and simplicity.
Our study provides compelling evidence that insights from other domains of
artificial intelligence can be effectively applied to time series analysis. We
conclude that large-scale time series models offer an exciting opportunity to
democratize access to precise predictions and reduce uncertainty by leveraging
the capabilities of contemporary advancements in deep learning.
</p></li>
</ul>

<h2>generative</h2>
<h3>Title: Shielding the Unseen: Privacy Protection through Poisoning NeRF with Spatial Deformation. (arXiv:2310.03125v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.03125">http://arxiv.org/abs/2310.03125</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.03125]] Shielding the Unseen: Privacy Protection through Poisoning NeRF with Spatial Deformation(http://arxiv.org/abs/2310.03125)</code></li>
<li>Summary: <p>In this paper, we introduce an innovative method of safeguarding user privacy
against the generative capabilities of Neural Radiance Fields (NeRF) models.
Our novel poisoning attack method induces changes to observed views that are
imperceptible to the human eye, yet potent enough to disrupt NeRF's ability to
accurately reconstruct a 3D scene. To achieve this, we devise a bi-level
optimization algorithm incorporating a Projected Gradient Descent (PGD)-based
spatial deformation. We extensively test our approach on two common NeRF
benchmark datasets consisting of 29 real-world scenes with high-quality images.
Our results compellingly demonstrate that our privacy-preserving method
significantly impairs NeRF's performance across these benchmark datasets.
Additionally, we show that our method is adaptable and versatile, functioning
across various perturbation strengths and NeRF architectures. This work offers
valuable insights into NeRF's vulnerabilities and emphasizes the need to
account for such potential privacy risks when developing robust 3D scene
reconstruction algorithms. Our study contributes to the larger conversation
surrounding responsible AI and generative machine learning, aiming to protect
user privacy and respect creative ownership in the digital age.
</p></li>
</ul>

<h3>Title: SimVLG: Simple and Efficient Pretraining of Visual Language Generative Models. (arXiv:2310.03291v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.03291">http://arxiv.org/abs/2310.03291</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.03291]] SimVLG: Simple and Efficient Pretraining of Visual Language Generative Models(http://arxiv.org/abs/2310.03291)</code></li>
<li>Summary: <p>In this paper, we propose ``SimVLG'', a streamlined framework for the
pre-training of computationally intensive vision-language generative models,
leveraging frozen pre-trained large language models (LLMs). The prevailing
paradigm in vision-language pre-training (VLP) typically involves a two-stage
optimization process: an initial resource-intensive phase dedicated to
general-purpose vision-language representation learning, aimed at extracting
and consolidating pertinent visual features, followed by a subsequent phase
focusing on end-to-end alignment between visual and linguistic modalities. Our
one-stage, single-loss framework circumvents the aforementioned computationally
demanding first stage of training by gradually merging similar visual tokens
during training. This gradual merging process effectively compacts the visual
information while preserving the richness of semantic content, leading to fast
convergence without sacrificing performance. Our experiments show that our
approach can speed up the training of vision-language models by a factor
$\times 5$ without noticeable impact on the overall performance. Additionally,
we show that our models can achieve comparable performance to current
vision-language models with only $1/10$ of the data. Finally, we demonstrate
how our image-text models can be easily adapted to video-language generative
tasks through a novel soft attentive temporal token merging modules.
</p></li>
</ul>

<h3>Title: Retrieval-augmented Generation to Improve Math Question-Answering: Trade-offs Between Groundedness and Human Preference. (arXiv:2310.03184v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.03184">http://arxiv.org/abs/2310.03184</a></li>
<li>Code URL: https://github.com/digitalharborfoundation/rag-for-math-qa</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.03184]] Retrieval-augmented Generation to Improve Math Question-Answering: Trade-offs Between Groundedness and Human Preference(http://arxiv.org/abs/2310.03184)</code></li>
<li>Summary: <p>For middle-school math students, interactive question-answering (QA) with
tutors is an effective way to learn. The flexibility and emergent capabilities
of generative large language models (LLMs) has led to a surge of interest in
automating portions of the tutoring process - including interactive QA to
support conceptual discussion of mathematical concepts. However, LLM responses
to math questions can be incorrect or mismatched to the educational context -
such as being misaligned with a school's curriculum. One potential solution is
retrieval-augmented generation (RAG), which involves incorporating a vetted
external knowledge source in the LLM prompt to increase response quality. In
this paper, we designed prompts that retrieve and use content from a
high-quality open-source math textbook to generate responses to real student
questions. We evaluate the efficacy of this RAG system for middle-school
algebra and geometry QA by administering a multi-condition survey, finding that
humans prefer responses generated using RAG, but not when responses are too
grounded in the textbook content. We argue that while RAG is able to improve
response quality, designers of math QA systems must consider trade-offs between
generating responses preferred by students and responses closely matched to
specific educational resources.
</p></li>
</ul>

<h3>Title: Procedural Text Mining with Large Language Models. (arXiv:2310.03376v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.03376">http://arxiv.org/abs/2310.03376</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.03376]] Procedural Text Mining with Large Language Models(http://arxiv.org/abs/2310.03376)</code></li>
<li>Summary: <p>Recent advancements in the field of Natural Language Processing, particularly
the development of large-scale language models that are pretrained on vast
amounts of knowledge, are creating novel opportunities within the realm of
Knowledge Engineering. In this paper, we investigate the usage of large
language models (LLMs) in both zero-shot and in-context learning settings to
tackle the problem of extracting procedures from unstructured PDF text in an
incremental question-answering fashion. In particular, we leverage the current
state-of-the-art GPT-4 (Generative Pre-trained Transformer 4) model,
accompanied by two variations of in-context learning that involve an ontology
with definitions of procedures and steps and a limited number of samples of
few-shot learning. The findings highlight both the promise of this approach and
the value of the in-context learning customisations. These modifications have
the potential to significantly address the challenge of obtaining sufficient
training data, a hurdle often encountered in deep learning-based Natural
Language Processing techniques for procedure extraction.
</p></li>
</ul>

<h3>Title: TacoGFN: Target Conditioned GFlowNet for Structure-Based Drug Design. (arXiv:2310.03223v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.03223">http://arxiv.org/abs/2310.03223</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.03223]] TacoGFN: Target Conditioned GFlowNet for Structure-Based Drug Design(http://arxiv.org/abs/2310.03223)</code></li>
<li>Summary: <p>We seek to automate the generation of drug-like compounds conditioned to
specific protein pocket targets. Most current methods approximate the
protein-molecule distribution of a finite dataset and, therefore struggle to
generate molecules with significant binding improvement over the training
dataset. We instead frame the pocket-conditioned molecular generation task as
an RL problem and develop TacoGFN, a target conditional Generative Flow Network
model. Our method is explicitly encouraged to generate molecules with desired
properties as opposed to fitting on a pre-existing data distribution. To this
end, we develop transformer-based docking score prediction to speed up docking
score computation and propose TacoGFN to explore molecule space efficiently.
Furthermore, we incorporate several rounds of active learning where generated
samples are queried using a docking oracle to improve the docking score
prediction. This approach allows us to accurately explore as much of the
molecule landscape as we can afford computationally. Empirically, molecules
generated using TacoGFN and its variants significantly outperform all baseline
methods across every property (Docking score, QED, SA, Lipinski), while being
orders of magnitude faster.
</p></li>
</ul>

<h3>Title: UniPredict: Large Language Models are Universal Tabular Predictors. (arXiv:2310.03266v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.03266">http://arxiv.org/abs/2310.03266</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.03266]] UniPredict: Large Language Models are Universal Tabular Predictors(http://arxiv.org/abs/2310.03266)</code></li>
<li>Summary: <p>Tabular data prediction is a fundamental machine learning task for many
applications. Existing methods predominantly employ discriminative modeling and
operate under the assumption of a fixed target column, necessitating
re-training for every new predictive task. Inspired by the generative power of
large language models (LLMs), this paper exploits the idea of building
universal tabular data predictors based on generative modeling, namely
UniPredict. Here, we show that scaling up an LLM to extensive tabular datasets
with the capability of comprehending diverse tabular inputs and predicting for
target variables following the input instructions. Specifically, we train a
single LLM on an aggregation of 169 tabular datasets with diverse targets and
compare its performance against baselines that are trained on each dataset
separately. We observe this versatile UniPredict model demonstrates an
advantage over other models, ranging from 5.4% to 13.4%, when compared with the
best tree-boosting baseline and the best neural network baseline, respectively.
We further test UniPredict in few-shot learning settings on another 62 tabular
datasets. Our method achieves strong performance in quickly adapting to new
tasks, where our method outperforms XGBoost over 100% on the low-resource setup
and shows a significant margin over all baselines. We envision that UniPredict
sheds light on developing a universal tabular data prediction system that
learns from data at scale and serves a wide range of prediction tasks.
</p></li>
</ul>

<h3>Title: Learning Energy Decompositions for Partial Inference of GFlowNets. (arXiv:2310.03301v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.03301">http://arxiv.org/abs/2310.03301</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.03301]] Learning Energy Decompositions for Partial Inference of GFlowNets(http://arxiv.org/abs/2310.03301)</code></li>
<li>Summary: <p>This paper studies generative flow networks (GFlowNets) to sample objects
from the Boltzmann energy distribution via a sequence of actions. In
particular, we focus on improving GFlowNet with partial inference: training
flow functions with the evaluation of the intermediate states or transitions.
To this end, the recently developed forward-looking GFlowNet reparameterizes
the flow functions based on evaluating the energy of intermediate states.
However, such an evaluation of intermediate energies may (i) be too expensive
or impossible to evaluate and (ii) even provide misleading training signals
under large energy fluctuations along the sequence of actions. To resolve this
issue, we propose learning energy decompositions for GFlowNets (LED-GFN). Our
main idea is to (i) decompose the energy of an object into learnable potential
functions defined on state transitions and (ii) reparameterize the flow
functions using the potential functions. In particular, to produce informative
local credits, we propose to regularize the potential to change smoothly over
the sequence of actions. It is also noteworthy that training GFlowNet with our
learned potential can preserve the optimal policy. We empirically verify the
superiority of LED-GFN in five problems including the generation of
unstructured and maximum independent sets, molecular graphs, and RNA sequences.
</p></li>
</ul>

<h3>Title: Deep Variational Multivariate Information Bottleneck -- A Framework for Variational Losses. (arXiv:2310.03311v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.03311">http://arxiv.org/abs/2310.03311</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.03311]] Deep Variational Multivariate Information Bottleneck -- A Framework for Variational Losses(http://arxiv.org/abs/2310.03311)</code></li>
<li>Summary: <p>Variational dimensionality reduction methods are known for their high
accuracy, generative abilities, and robustness. These methods have many
theoretical justifications. Here we introduce a unifying principle rooted in
information theory to rederive and generalize existing variational methods and
design new ones. We base our framework on an interpretation of the multivariate
information bottleneck, in which two Bayesian networks are traded off against
one another. We interpret the first network as an encoder graph, which
specifies what information to keep when compressing the data. We interpret the
second network as a decoder graph, which specifies a generative model for the
data. Using this framework, we rederive existing dimensionality reduction
methods such as the deep variational information bottleneck (DVIB), beta
variational auto-encoders (beta-VAE), and deep variational canonical
correlation analysis (DVCCA). The framework naturally introduces a trade-off
parameter between compression and reconstruction in the DVCCA family of
algorithms, resulting in the new beta-DVCCA family. In addition, we derive a
new variational dimensionality reduction method, deep variational symmetric
informational bottleneck (DVSIB), which simultaneously compresses two variables
to preserve information between their compressed representations. We implement
all of these algorithms and evaluate their ability to produce shared low
dimensional latent spaces on a modified noisy MNIST dataset. We show that
algorithms that are better matched to the structure of the data (beta-DVCCA and
DVSIB) produce better latent spaces as measured by classification accuracy and
the dimensionality of the latent variables. We believe that this framework can
be used to unify other multi-view representation learning algorithms.
Additionally, it provides a straightforward framework for deriving
problem-specific loss functions.
</p></li>
</ul>

<h3>Title: Pre-Training and Fine-Tuning Generative Flow Networks. (arXiv:2310.03419v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.03419">http://arxiv.org/abs/2310.03419</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.03419]] Pre-Training and Fine-Tuning Generative Flow Networks(http://arxiv.org/abs/2310.03419)</code></li>
<li>Summary: <p>Generative Flow Networks (GFlowNets) are amortized samplers that learn
stochastic policies to sequentially generate compositional objects from a given
unnormalized reward distribution. They can generate diverse sets of high-reward
objects, which is an important consideration in scientific discovery tasks.
However, as they are typically trained from a given extrinsic reward function,
it remains an important open challenge about how to leverage the power of
pre-training and train GFlowNets in an unsupervised fashion for efficient
adaptation to downstream tasks. Inspired by recent successes of unsupervised
pre-training in various domains, we introduce a novel approach for reward-free
pre-training of GFlowNets. By framing the training as a self-supervised
problem, we propose an outcome-conditioned GFlowNet (OC-GFN) that learns to
explore the candidate space. Specifically, OC-GFN learns to reach any targeted
outcomes, akin to goal-conditioned policies in reinforcement learning. We show
that the pre-trained OC-GFN model can allow for a direct extraction of a policy
capable of sampling from any new reward functions in downstream tasks.
Nonetheless, adapting OC-GFN on a downstream task-specific reward involves an
intractable marginalization over possible outcomes. We propose a novel way to
approximate this marginalization by learning an amortized predictor enabling
efficient fine-tuning. Extensive experimental results validate the efficacy of
our approach, demonstrating the effectiveness of pre-training the OC-GFN, and
its ability to swiftly adapt to downstream tasks and discover modes more
efficiently. This work may serve as a foundation for further exploration of
pre-training strategies in the context of GFlowNets.
</p></li>
</ul>

<h3>Title: Multimarginal generative modeling with stochastic interpolants. (arXiv:2310.03695v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.03695">http://arxiv.org/abs/2310.03695</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.03695]] Multimarginal generative modeling with stochastic interpolants(http://arxiv.org/abs/2310.03695)</code></li>
<li>Summary: <p>Given a set of $K$ probability densities, we consider the multimarginal
generative modeling problem of learning a joint distribution that recovers
these densities as marginals. The structure of this joint distribution should
identify multi-way correspondences among the prescribed marginals. We formalize
an approach to this task within a generalization of the stochastic interpolant
framework, leading to efficient learning algorithms built upon dynamical
transport of measure. Our generative models are defined by velocity and score
fields that can be characterized as the minimizers of simple quadratic
objectives, and they are defined on a simplex that generalizes the time
variable in the usual dynamical transport framework. The resulting transport on
the simplex is influenced by all marginals, and we show that multi-way
correspondences can be extracted. The identification of such correspondences
has applications to style transfer, algorithmic fairness, and data
decorruption. In addition, the multimarginal perspective enables an efficient
algorithm for reducing the dynamical transport cost in the ordinary
two-marginal setting. We demonstrate these capacities with several numerical
examples.
</p></li>
</ul>

<h2>anomaly</h2>
<h2>in-context</h2>
<h3>Title: How FaR Are Large Language Models From Agents with Theory-of-Mind?. (arXiv:2310.03051v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.03051">http://arxiv.org/abs/2310.03051</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.03051]] How FaR Are Large Language Models From Agents with Theory-of-Mind?(http://arxiv.org/abs/2310.03051)</code></li>
<li>Summary: <p>"Thinking is for Doing." Humans can infer other people's mental states from
observations--an ability called Theory-of-Mind (ToM)--and subsequently act
pragmatically on those inferences. Existing question answering benchmarks such
as ToMi ask models questions to make inferences about beliefs of characters in
a story, but do not test whether models can then use these inferences to guide
their actions. We propose a new evaluation paradigm for large language models
(LLMs): Thinking for Doing (T4D), which requires models to connect inferences
about others' mental states to actions in social scenarios. Experiments on T4D
demonstrate that LLMs such as GPT-4 and PaLM 2 seemingly excel at tracking
characters' beliefs in stories, but they struggle to translate this capability
into strategic action. Our analysis reveals the core challenge for LLMs lies in
identifying the implicit inferences about mental states without being
explicitly asked about as in ToMi, that lead to choosing the correct action in
T4D. To bridge this gap, we introduce a zero-shot prompting framework, Foresee
and Reflect (FaR), which provides a reasoning structure that encourages LLMs to
anticipate future challenges and reason about potential actions. FaR boosts
GPT-4's performance from 50% to 71% on T4D, outperforming other prompting
methods such as Chain-of-Thought and Self-Ask. Moreover, FaR generalizes to
diverse out-of-distribution story structures and scenarios that also require
ToM inferences to choose an action, consistently outperforming other methods
including few-shot in-context learning.
</p></li>
</ul>

<h3>Title: Fine-tune Language Models to Approximate Unbiased In-context Learning. (arXiv:2310.03331v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.03331">http://arxiv.org/abs/2310.03331</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.03331]] Fine-tune Language Models to Approximate Unbiased In-context Learning(http://arxiv.org/abs/2310.03331)</code></li>
<li>Summary: <p>In-context learning (ICL) is an astonishing emergent ability of large
language models (LLMs). By presenting a prompt that includes multiple
input-output pairs as examples and introducing a new query input, models can
generate the corresponding output. However, the performance of models heavily
relies on the quality of the input prompt when implementing in-context
learning. Biased or imbalanced input prompts can significantly degrade the
performance of language models. To address this issue, we introduce a
reweighted algorithm called RICL (Reweighted In-context Learning). This
algorithm fine-tunes language models using an unbiased validation set to
determine the optimal weight for each input-output example to approximate
unbiased in-context learning. Furthermore, we also introduce a low-cost
reweighted algorithm, a linear optimal weight approximation algorithm called
LARICL (Linear Approximation of Reweighted In-context Learning). This algorithm
requires minimal training cost while providing effective results. We prove the
convergence of our algorithm and validate its performance through experiments
conducted on a numerical dataset. The experimental findings reveal a
substantial improvement in comparison to benchmarks including the performance
of casual prompt-based in-context learning and the performance of a classic
fine-tuning method.
</p></li>
</ul>

<button id="copy">Copy All</button>
</article>
<script src="https://cdn.staticfile.org/clipboard.js/2.0.4/clipboard.min.js"></script>
<script src="../../javascript/clipboard.js"></script>
