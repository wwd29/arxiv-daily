<link rel="stylesheet" href="../../css/markdown.css" />
<article class="markdown-body">
<h2>diffusion</h2>
<h3>Title: Post-training Quantization with Progressive Calibration and Activation Relaxing for Text-to-Image Diffusion Models. (arXiv:2311.06322v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2311.06322">http://arxiv.org/abs/2311.06322</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2311.06322]] Post-training Quantization with Progressive Calibration and Activation Relaxing for Text-to-Image Diffusion Models(http://arxiv.org/abs/2311.06322)</code></li>
<li>Summary: <p>Diffusion models have achieved great success due to their remarkable
generation ability. However, their high computational overhead is still a
troublesome problem. Recent studies have leveraged post-training quantization
(PTQ) to compress diffusion models. However, most of them only focus on
unconditional models, leaving the quantization of widely used large pretrained
text-to-image models, e.g., Stable Diffusion, largely unexplored. In this
paper, we propose a novel post-training quantization method PCR (Progressive
Calibration and Relaxing) for text-to-image diffusion models, which consists of
a progressive calibration strategy that considers the accumulated quantization
error across timesteps, and an activation relaxing strategy that improves the
performance with negligible cost. Additionally, we demonstrate the previous
metrics for text-to-image diffusion model quantization are not accurate due to
the distribution gap. To tackle the problem, we propose a novel QDiffBench
benchmark, which utilizes data in the same domain for more accurate evaluation.
Besides, QDiffBench also considers the generalization performance of the
quantized model outside the calibration dataset. Extensive experiments on
Stable Diffusion and Stable Diffusion XL demonstrate the superiority of our
method and benchmark. Moreover, we are the first to achieve quantization for
Stable Diffusion XL while maintaining the performance.
</p></li>
</ul>

<h3>Title: ShipGen: A Diffusion Model for Parametric Ship Hull Generation with Multiple Objectives and Constraints. (arXiv:2311.06315v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2311.06315">http://arxiv.org/abs/2311.06315</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2311.06315]] ShipGen: A Diffusion Model for Parametric Ship Hull Generation with Multiple Objectives and Constraints(http://arxiv.org/abs/2311.06315)</code></li>
<li>Summary: <p>Ship design is a years-long process that requires balancing complex design
trade-offs to create a ship that is efficient and effective. Finding new ways
to improve the ship design process can lead to significant cost savings for
ship building and operation. One promising technology is generative artificial
intelligence, which has been shown to reduce design cycle time and create
novel, high-performing designs. In literature review, generative artificial
intelligence has been shown to generate ship hulls; however, ship design is
particularly difficult as the hull of a ship requires the consideration of many
objectives. This paper presents a study on the generation of parametric ship
hull designs using a parametric diffusion model that considers multiple
objectives and constraints for the hulls. This denoising diffusion
probabilistic model (DDPM) generates the tabular parametric design vectors of a
ship hull for evaluation. In addition to a tabular DDPM, this paper details
adding guidance to improve the quality of generated ship hull designs. By
leveraging classifier guidance, the DDPM produced feasible parametric ship
hulls that maintain the coverage of the initial training dataset of ship hulls
with a 99.5% rate, a 149x improvement over random sampling of the design vector
parameters across the design space. Parametric ship hulls produced with
performance guidance saw an average of 91.4% reduction in wave drag
coefficients and an average of a 47.9x relative increase in the total displaced
volume of the hulls compared to the mean performance of the hulls in the
training dataset. The use of a DDPM to generate parametric ship hulls can
reduce design time by generating high-performing hull designs for future
analysis. These generated hulls have low drag and high volume, which can reduce
the cost of operating a ship and increase its potential to generate revenue.
</p></li>
</ul>

<h2>self-supervised</h2>
<h3>Title: Self-supervised Context Learning for Visual Inspection of Industrial Defects. (arXiv:2311.06504v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2311.06504">http://arxiv.org/abs/2311.06504</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2311.06504]] Self-supervised Context Learning for Visual Inspection of Industrial Defects(http://arxiv.org/abs/2311.06504)</code></li>
<li>Summary: <p>The unsupervised visual inspection of defects in industrial products poses a
significant challenge due to substantial variations in product surfaces.
Current unsupervised models struggle to strike a balance between detecting
texture and object defects, lacking the capacity to discern latent
representations and intricate features. In this paper, we present a novel
self-supervised learning algorithm designed to derive an optimal encoder by
tackling the renowned jigsaw puzzle. Our approach involves dividing the target
image into nine patches, tasking the encoder with predicting the relative
position relationships between any two patches to extract rich semantics.
Subsequently, we introduce an affinity-augmentation method to accentuate
differences between normal and abnormal latent representations. Leveraging the
classic support vector data description algorithm yields final detection
results. Experimental outcomes demonstrate that our proposed method achieves
outstanding detection and segmentation performance on the widely used MVTec AD
dataset, with rates of 95.8% and 96.8%, respectively, establishing a
state-of-the-art benchmark for both texture and object defects. Comprehensive
experimentation underscores the effectiveness of our approach in diverse
industrial applications.
</p></li>
</ul>

<h3>Title: SCADI: Self-supervised Causal Disentanglement in Latent Variable Models. (arXiv:2311.06567v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2311.06567">http://arxiv.org/abs/2311.06567</a></li>
<li>Code URL: https://github.com/hazel-heejeong-nam/self-supervised-causal-disentanglement</li>
<li>Copy Paste: <code><input type="checkbox">[[2311.06567]] SCADI: Self-supervised Causal Disentanglement in Latent Variable Models(http://arxiv.org/abs/2311.06567)</code></li>
<li>Summary: <p>Causal disentanglement has great potential for capturing complex situations.
However, there is a lack of practical and efficient approaches. It is already
known that most unsupervised disentangling methods are unable to produce
identifiable results without additional information, often leading to randomly
disentangled output. Therefore, most existing models for disentangling are
weakly supervised, providing information about intrinsic factors, which incurs
excessive costs. Therefore, we propose a novel model, SCADI(SElf-supervised
CAusal DIsentanglement), that enables the model to discover semantic factors
and learn their causal relationships without any supervision. This model
combines a masked structural causal model (SCM) with a pseudo-label generator
for causal disentanglement, aiming to provide a new direction for
self-supervised causal disentanglement models.
</p></li>
</ul>

<h2>foundation model</h2>
<h2>generative</h2>
<h3>Title: Word Definitions from Large Language Models. (arXiv:2311.06362v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2311.06362">http://arxiv.org/abs/2311.06362</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2311.06362]] Word Definitions from Large Language Models(http://arxiv.org/abs/2311.06362)</code></li>
<li>Summary: <p>Dictionary definitions are historically the arbitrator of what words mean,
but this primacy has come under threat by recent progress in NLP, including
word embeddings and generative models like ChatGPT. We present an exploratory
study of the degree of alignment between word definitions from classical
dictionaries and these newer computational artifacts. Specifically, we compare
definitions from three published dictionaries to those generated from variants
of ChatGPT. We show that (i) definitions from different traditional
dictionaries exhibit more surface form similarity than do model-generated
definitions, (ii) that the ChatGPT definitions are highly accurate, comparable
to traditional dictionaries, and (iii) ChatGPT-based embedding definitions
retain their accuracy even on low frequency words, much better than GloVE and
FastText word embeddings.
</p></li>
</ul>

<h3>Title: Relation Extraction in underexplored biomedical domains: A diversity-optimised sampling and synthetic data generation approach. (arXiv:2311.06364v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2311.06364">http://arxiv.org/abs/2311.06364</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2311.06364]] Relation Extraction in underexplored biomedical domains: A diversity-optimised sampling and synthetic data generation approach(http://arxiv.org/abs/2311.06364)</code></li>
<li>Summary: <p>The sparsity of labelled data is an obstacle to the development of Relation
Extraction models and the completion of databases in various biomedical areas.
While being of high interest in drug-discovery, the natural-products
literature, reporting the identification of potential bioactive compounds from
organisms, is a concrete example of such an overlooked topic. To mark the start
of this new task, we created the first curated evaluation dataset and extracted
literature items from the LOTUS database to build training sets. To this end,
we developed a new sampler inspired by diversity metrics in ecology, named
Greedy Maximum Entropy sampler, or GME-sampler
(https://github.com/idiap/gme-sampler). The strategic optimization of both
balance and diversity of the selected items in the evaluation set is important
given the resource-intensive nature of manual curation. After quantifying the
noise in the training set, in the form of discrepancies between the input
abstracts text and the expected output labels, we explored different strategies
accordingly. Framing the task as an end-to-end Relation Extraction, we
evaluated the performance of standard fine-tuning as a generative task and
few-shot learning with open Large Language Models (LLaMA 7B-65B). In addition
to their evaluation in few-shot settings, we explore the potential of open
Large Language Models (Vicuna-13B) as synthetic data generator and propose a
new workflow for this purpose. All evaluated models exhibited substantial
improvements when fine-tuned on synthetic abstracts rather than the original
noisy data. We provide our best performing (f1-score=59.0) BioGPT-Large model
for end-to-end RE of natural-products relationships along with all the
generated synthetic data and the evaluation dataset. See more details at
https://github.com/idiap/abroad-re.
</p></li>
</ul>

<h3>Title: Convolve and Conquer: Data Comparison with Wiener Filters. (arXiv:2311.06558v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2311.06558">http://arxiv.org/abs/2311.06558</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2311.06558]] Convolve and Conquer: Data Comparison with Wiener Filters(http://arxiv.org/abs/2311.06558)</code></li>
<li>Summary: <p>Quantitative evaluations of differences and/or similarities between data
samples define and shape optimisation problems associated with learning data
distributions. Current methods to compare data often suffer from limitations in
capturing such distributions or lack desirable mathematical properties for
optimisation (e.g. smoothness, differentiability, or convexity). In this paper,
we introduce a new method to measure (dis)similarities between paired samples
inspired by Wiener-filter theory. The convolutional nature of Wiener filters
allows us to comprehensively compare data samples in a globally correlated way.
We validate our approach in four machine learning applications: data
compression, medical imaging imputation, translated classification, and
non-parametric generative modelling. Our results demonstrate increased
resolution in reconstructed images with better perceptual quality and higher
data fidelity, as well as robustness against translations, compared to
conventional mean-squared-error analogue implementations.
</p></li>
</ul>

<h2>anomaly</h2>
<h3>Title: VT-Former: A Transformer-based Vehicle Trajectory Prediction Approach For Intelligent Highway Transportation Systems. (arXiv:2311.06623v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2311.06623">http://arxiv.org/abs/2311.06623</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2311.06623]] VT-Former: A Transformer-based Vehicle Trajectory Prediction Approach For Intelligent Highway Transportation Systems(http://arxiv.org/abs/2311.06623)</code></li>
<li>Summary: <p>Enhancing roadway safety and traffic management has become an essential focus
area for a broad range of modern cyber-physical systems and intelligent
transportation systems. Vehicle Trajectory Prediction is a pivotal element
within numerous applications for highway and road safety. These applications
encompass a wide range of use cases, spanning from traffic management and
accident prevention to enhancing work-zone safety and optimizing energy
conservation. The ability to implement intelligent management in this context
has been greatly advanced by the developments in the field of Artificial
Intelligence (AI), alongside the increasing deployment of surveillance cameras
across road networks. In this paper, we introduce a novel transformer-based
approach for vehicle trajectory prediction for highway safety and surveillance,
denoted as VT-Former. In addition to utilizing transformers to capture
long-range temporal patterns, a new Graph Attentive Tokenization (GAT) module
has been proposed to capture intricate social interactions among vehicles.
Combining these two core components culminates in a precise approach for
vehicle trajectory prediction. Our study on three benchmark datasets with three
different viewpoints demonstrates the State-of-The-Art (SoTA) performance of
VT-Former in vehicle trajectory prediction and its generalizability and
robustness. We also evaluate VT-Former's efficiency on embedded boards and
explore its potential for vehicle anomaly detection as a sample application,
showcasing its broad applicability.
</p></li>
</ul>

<h2>in-context</h2>
<h3>Title: LayoutPrompter: Awaken the Design Ability of Large Language Models. (arXiv:2311.06495v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2311.06495">http://arxiv.org/abs/2311.06495</a></li>
<li>Code URL: https://github.com/microsoft/layoutgeneration</li>
<li>Copy Paste: <code><input type="checkbox">[[2311.06495]] LayoutPrompter: Awaken the Design Ability of Large Language Models(http://arxiv.org/abs/2311.06495)</code></li>
<li>Summary: <p>Conditional graphic layout generation, which automatically maps user
constraints to high-quality layouts, has attracted widespread attention today.
Although recent works have achieved promising performance, the lack of
versatility and data efficiency hinders their practical applications. In this
work, we propose LayoutPrompter, which leverages large language models (LLMs)
to address the above problems through in-context learning. LayoutPrompter is
made up of three key components, namely input-output serialization, dynamic
exemplar selection and layout ranking. Specifically, the input-output
serialization component meticulously designs the input and output formats for
each layout generation task. Dynamic exemplar selection is responsible for
selecting the most helpful prompting exemplars for a given input. And a layout
ranker is used to pick the highest quality layout from multiple outputs of
LLMs. We conduct experiments on all existing layout generation tasks using four
public datasets. Despite the simplicity of our approach, experimental results
show that LayoutPrompter can compete with or even outperform state-of-the-art
approaches on these tasks without any model training or fine-tuning. This
demonstrates the effectiveness of this versatile and training-free approach. In
addition, the ablation studies show that LayoutPrompter is significantly
superior to the training-based baseline in a low-data regime, further
indicating the data efficiency of LayoutPrompter. Our project is available at
https://github.com/microsoft/LayoutGeneration/tree/main/LayoutPrompter.
</p></li>
</ul>

<h3>Title: Heuristics-Driven Link-of-Analogy Prompting: Enhancing Large Language Models for Document-Level Event Argument Extraction. (arXiv:2311.06555v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2311.06555">http://arxiv.org/abs/2311.06555</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2311.06555]] Heuristics-Driven Link-of-Analogy Prompting: Enhancing Large Language Models for Document-Level Event Argument Extraction(http://arxiv.org/abs/2311.06555)</code></li>
<li>Summary: <p>In this study, we investigate in-context learning (ICL) in document-level
event argument extraction (EAE). The paper identifies key challenges in this
problem, including example selection, context length limitation, abundance of
event types, and the limitation of Chain-of-Thought (CoT) prompting in
non-reasoning tasks. To address these challenges, we introduce the
Heuristic-Driven Link-of-Analogy (HD-LoA) prompting method. Specifically, we
hypothesize and validate that LLMs learn task-specific heuristics from
demonstrations via ICL. Building upon this hypothesis, we introduce an explicit
heuristic-driven demonstration construction approach, which transforms the
haphazard example selection process into a methodical method that emphasizes
task heuristics. Additionally, inspired by the analogical reasoning of human,
we propose the link-of-analogy prompting, which enables LLMs to process new
situations by drawing analogies to known situations, enhancing their
adaptability. Extensive experiments show that our method outperforms the
existing prompting methods and few-shot supervised learning methods, exhibiting
F1 score improvements of 4.53% and 9.38% on the document-level EAE dataset.
Furthermore, when applied to sentiment analysis and natural language inference
tasks, the HD-LoA prompting achieves accuracy gains of 2.87% and 2.63%,
indicating its effectiveness across different tasks.
</p></li>
</ul>

<h3>Title: From Classification to Generation: Insights into Crosslingual Retrieval Augmented ICL. (arXiv:2311.06595v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2311.06595">http://arxiv.org/abs/2311.06595</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2311.06595]] From Classification to Generation: Insights into Crosslingual Retrieval Augmented ICL(http://arxiv.org/abs/2311.06595)</code></li>
<li>Summary: <p>The remarkable ability of Large Language Models (LLMs) to understand and
follow instructions has sometimes been limited by their in-context learning
(ICL) performance in low-resource languages. To address this, we introduce a
novel approach that leverages cross-lingual retrieval-augmented in-context
learning (CREA-ICL). By extracting semantically similar prompts from
high-resource languages, we aim to improve the zero-shot performance of
multilingual pre-trained language models (MPLMs) across diverse tasks. Though
our approach yields steady improvements in classification tasks, it faces
challenges in generation tasks. Our evaluation offers insights into the
performance dynamics of retrieval-augmented in-context learning across both
classification and generation domains.
</p></li>
</ul>

<button id="copy">Copy All</button>
</article>
<script src="https://cdn.staticfile.org/clipboard.js/2.0.4/clipboard.min.js"></script>
<script src="../../javascript/clipboard.js"></script>
