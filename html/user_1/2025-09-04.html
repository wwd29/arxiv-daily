<link rel="stylesheet" href="../../css/markdown.css" />
<article class="markdown-body">
<h1>2025-09-04</h1>
<h3>Title: Mentality: A Mamba-based Approach towards Foundation Models for EEG</h3>
<ul>
<li><strong>Authors: </strong>Saarang Panchavati, Corey Arnold, William Speier</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, q-bio.NC</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2509.02746">https://arxiv.org/abs/2509.02746</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2509.02746">https://arxiv.org/pdf/2509.02746</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2509.02746]] Mentality: A Mamba-based Approach towards Foundation Models for EEG(https://arxiv.org/abs/2509.02746)</code><input type="text"></li>
<li><strong>Keywords: </strong>self-supervised, foundation model</a></li>
<li><strong>Abstract: </strong>This work explores the potential of foundation models, specifically a Mamba-based selective state space model, for enhancing EEG analysis in neurological disorder diagnosis. EEG, crucial for diagnosing conditions like epilepsy, presents significant challenges due to its noisy, high-dimensional, and nonlinear nature. Traditional machine learning methods have made advances in automating EEG analysis but often fail to capture its complex spatio-temporal dynamics. Recent advances in deep learning, particularly in sequence modeling, offer new avenues for creating more generalized and expressive models capable of handling such complexities. By training a Mamba-based model on a large dataset containing seizure and non-seizure EEG recordings through a self-supervised reconstruction task followed by a seizure detection task, we demonstrate the model's effectiveness, achieving an AUROC of 0.72 on a held-out test set. This approach marks a significant step toward developing large-scale, clinically applicable foundation models for EEG data analysis.</li>
</ul>

<h3>Title: The Transparent Earth: A Multimodal Foundation Model for the Earth's Subsurface</h3>
<ul>
<li><strong>Authors: </strong>Arnab Mazumder, Javier E. Santos, Noah Hobbs, Mohamed Mehana, Daniel O'Malley</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, physics.geo-ph</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2509.02783">https://arxiv.org/abs/2509.02783</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2509.02783">https://arxiv.org/pdf/2509.02783</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2509.02783]] The Transparent Earth: A Multimodal Foundation Model for the Earth's Subsurface(https://arxiv.org/abs/2509.02783)</code><input type="text"></li>
<li><strong>Keywords: </strong>foundation model, in-context</a></li>
<li><strong>Abstract: </strong>We present the Transparent Earth, a transformer-based architecture for reconstructing subsurface properties from heterogeneous datasets that vary in sparsity, resolution, and modality, where each modality represents a distinct type of observation (e.g., stress angle, mantle temperature, tectonic plate type). The model incorporates positional encodings of observations together with modality encodings, derived from a text embedding model applied to a description of each modality. This design enables the model to scale to an arbitrary number of modalities, making it straightforward to add new ones not considered in the initial design. We currently include eight modalities spanning directional angles, categorical classes, and continuous properties such as temperature and thickness. These capabilities support in-context learning, enabling the model to generate predictions either with no inputs or with an arbitrary number of additional observations from any subset of modalities. On validation data, this reduces errors in predicting stress angle by more than a factor of three. The proposed architecture is scalable and demonstrates improved performance with increased parameters. Together, these advances make the Transparent Earth an initial foundation model for the Earth's subsurface that ultimately aims to predict any subsurface property anywhere on Earth.</li>
</ul>

<h3>Title: DrDiff: Dynamic Routing Diffusion with Hierarchical Attention for Breaking the Efficiency-Quality Trade-off</h3>
<ul>
<li><strong>Authors: </strong>Jusheng Zhang, Yijia Fan, Kaitong Cai, Zimeng Huang, Xiaofei Sun, Jian Wang, Chengpei Tang, Keze Wang</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2509.02785">https://arxiv.org/abs/2509.02785</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2509.02785">https://arxiv.org/pdf/2509.02785</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2509.02785]] DrDiff: Dynamic Routing Diffusion with Hierarchical Attention for Breaking the Efficiency-Quality Trade-off(https://arxiv.org/abs/2509.02785)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>This paper introduces DrDiff, a novel framework for long-text generation that overcomes the efficiency-quality trade-off through three core technologies. First, we design a dynamic expert scheduling mechanism that intelligently allocates computational resources during the diffusion process based on text complexity, enabling more efficient handling of text generation tasks of varying difficulty. Second, we introduce a Hierarchical Sparse Attention (HSA) mechanism that adaptively adjusts attention patterns according to a variety of input lengths, reducing computational complexity from O($n^2$) to O($n$) while maintaining model performance. Finally, we propose a soft absorption guidance optimization strategy that combines with DPM-solver++ to reduce diffusion steps, significantly improving generation speed. Comprehensive experiments on various long-text generation benchmarks demonstrate the superiority of our DrDiff over the existing SOTA methods.</li>
</ul>

<h3>Title: Learning Laplacian Eigenvectors: a Pre-training Method for Graph Neural Networks</h3>
<ul>
<li><strong>Authors: </strong>Howard Dai, Nyambura Njenga, Benjamin Whitsett, Catherine Ma, Darwin Deng, Sara de Ángel, Alexandre Van Tassel, Siddharth Viswanath, Ryan Pellico, Ian Adelstein, Smita Krishnaswamy</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2509.02803">https://arxiv.org/abs/2509.02803</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2509.02803">https://arxiv.org/pdf/2509.02803</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2509.02803]] Learning Laplacian Eigenvectors: a Pre-training Method for Graph Neural Networks(https://arxiv.org/abs/2509.02803)</code><input type="text"></li>
<li><strong>Keywords: </strong>self-supervised</a></li>
<li><strong>Abstract: </strong>We propose a novel framework for pre-training Graph Neural Networks (GNNs) by inductively learning Laplacian eigenvectors. Traditional Message Passing Neural Networks (MPNNs) often struggle to capture global and regional graph structure due to over-smoothing risk as network depth increases. Because the low-frequency eigenvectors of the graph Laplacian matrix encode global information, pre-training GNNs to predict these eigenvectors encourages the network to naturally learn large-scale structural patterns over each graph. Empirically, we show that models pre-trained via our framework outperform baseline models on a variety of graph structure-based tasks. While most existing pre-training methods focus on domain-specific tasks like node or edge feature reconstruction, our self-supervised pre-training framework is structure-based and highly flexible. Eigenvector-learning can be applied to all graph-based datasets, and can be used with synthetic features when task-specific data is sparse.</li>
</ul>

<h3>Title: SSVD: Structured SVD for Parameter-Efficient Fine-Tuning and Benchmarking under Domain Shift in ASR</h3>
<ul>
<li><strong>Authors: </strong>Pu Wang, Shinji Watanabe, Hugo Van hamme</a></li>
<li><strong>Subjects: </strong>cs.CL, eess.AS</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2509.02830">https://arxiv.org/abs/2509.02830</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2509.02830">https://arxiv.org/pdf/2509.02830</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2509.02830]] SSVD: Structured SVD for Parameter-Efficient Fine-Tuning and Benchmarking under Domain Shift in ASR(https://arxiv.org/abs/2509.02830)</code><input type="text"></li>
<li><strong>Keywords: </strong>foundation model</a></li>
<li><strong>Abstract: </strong>Parameter-efficient fine-tuning (PEFT) has emerged as a scalable solution for adapting large foundation models. While low-rank adaptation (LoRA) is widely used in speech applications, its state-of-the-art variants, e.g., VeRA, DoRA, PiSSA, and SVFT, are developed mainly for language and vision tasks, with limited validation in speech. This work presents the first comprehensive integration and benchmarking of these PEFT methods within ESPnet. We further introduce structured SVD-guided (SSVD) fine-tuning, which selectively rotates input-associated right singular vectors while keeping output-associated vectors fixed to preserve semantic mappings. This design enables robust domain adaptation with minimal trainable parameters and improved efficiency. We evaluate all methods on domain-shifted speech recognition tasks, including child speech and dialectal variation, across model scales from 0.1B to 2B. All implementations are released in ESPnet to support reproducibility and future work.</li>
</ul>

<h3>Title: Towards Reasoning for PDE Foundation Models: A Reward-Model-Driven Inference-Time-Scaling Algorithm</h3>
<ul>
<li><strong>Authors: </strong>Siddharth Mansingh, James Amarel, Ragib Arnab, Arvind Mohan, Kamaljeet Singh, Gerd J. Kunde, Nicolas Hengartner, Benjamin Migliori, Emily Casleton, Nathan A. Debarledeben, Ayan Biswas, Diane Oyen, Earl Lawrence</a></li>
<li><strong>Subjects: </strong>cs.LG, physics.comp-ph</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2509.02846">https://arxiv.org/abs/2509.02846</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2509.02846">https://arxiv.org/pdf/2509.02846</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2509.02846]] Towards Reasoning for PDE Foundation Models: A Reward-Model-Driven Inference-Time-Scaling Algorithm(https://arxiv.org/abs/2509.02846)</code><input type="text"></li>
<li><strong>Keywords: </strong>foundation model</a></li>
<li><strong>Abstract: </strong>Partial Differential Equations (PDEs) are the bedrock for modern computational sciences and engineering, and inherently computationally expensive. While PDE foundation models have shown much promise for simulating such complex spatio-temporal phenomena, existing models remain constrained by the pretraining datasets and struggle with auto-regressive rollout performance, especially in out-of-distribution (OOD) cases. Furthermore, they have significant compute and training data requirements which hamper their use in many critical applications. Inspired by recent advances in ``thinking" strategies used in large language models (LLMs), we introduce the first test-time computing (TTC) strategy for PDEs that utilizes computational resources during inference to achieve more accurate predictions with fewer training samples and smaller models. We accomplish this with two types of reward models that evaluate predictions of a stochastic based model for spatio-temporal consistency. We demonstrate this method on compressible Euler-equation simulations from the PDEGym benchmark and show that TTC captures improved predictions relative to standard non-adaptive auto-regressive inference. This TTC framework marks a foundational step towards more advanced reasoning algorithms or PDE modeling, inluding building reinforcement-learning-based approaches, potentially transforming computational workflows in physics and engineering.</li>
</ul>

<h3>Title: Multi-Scale Deep Learning for Colon Histopathology: A Hybrid Graph-Transformer Approach</h3>
<ul>
<li><strong>Authors: </strong>Sadra Saremi, Amirhossein Ahmadkhan Kordbacheh</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2509.02851">https://arxiv.org/abs/2509.02851</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2509.02851">https://arxiv.org/pdf/2509.02851</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2509.02851]] Multi-Scale Deep Learning for Colon Histopathology: A Hybrid Graph-Transformer Approach(https://arxiv.org/abs/2509.02851)</code><input type="text"></li>
<li><strong>Keywords: </strong>self-supervised</a></li>
<li><strong>Abstract: </strong>Colon cancer also known as Colorectal cancer, is one of the most malignant types of cancer worldwide. Early-stage detection of colon cancer is highly crucial to prevent its deterioration. This research presents a hybrid multi-scale deep learning architecture that synergizes capsule networks, graph attention mechanisms, transformer modules, and residual learning to advance colon cancer classification on the Lung and Colon Cancer Histopathological Image Dataset (LC25000) dataset. The proposed model in this paper utilizes the HG-TNet model that introduces a hybrid architecture that joins strength points in transformers and convolutional neural networks to capture multi-scale features in histopathological images. Mainly, a transformer branch extracts global contextual bonds by partitioning the image into patches by convolution-based patch embedding and then processing these patches through a transformer encoder. Analogously, a dedicated CNN branch captures fine-grained, local details through successive Incorporation these diverse features, combined with a self-supervised rotation prediction objective, produce a robust diagnostic representation that surpasses standard architectures in performance. Results show better performance not only in accuracy or loss function but also in these algorithms by utilizing capsule networks to preserve spatial orders and realize how each element individually combines and forms whole structures.</li>
</ul>

<h3>Title: Improving Generative Methods for Causal Evaluation via Simulation-Based Inference</h3>
<ul>
<li><strong>Authors: </strong>Pracheta Amaranath, Vinitra Muralikrishnan, Amit Sharma, David D. Jensen</a></li>
<li><strong>Subjects: </strong>cs.LG, stat.ME</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2509.02892">https://arxiv.org/abs/2509.02892</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2509.02892">https://arxiv.org/pdf/2509.02892</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2509.02892]] Improving Generative Methods for Causal Evaluation via Simulation-Based Inference(https://arxiv.org/abs/2509.02892)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>Generating synthetic datasets that accurately reflect real-world observational data is critical for evaluating causal estimators, but remains a challenging task. Existing generative methods offer a solution by producing synthetic datasets anchored in the observed data (source data) while allowing variation in key parameters such as the treatment effect and amount of confounding bias. However, existing methods typically require users to provide point estimates of such parameters (rather than distributions) and fixed estimates (rather than estimates that can be improved with reference to the source data). This denies users the ability to express uncertainty over parameter values and removes the potential for posterior inference, potentially leading to unreliable estimator comparisons. We introduce simulation-based inference for causal evaluation (SBICE), a framework that models generative parameters as uncertain and infers their posterior distribution given a source dataset. Leveraging techniques in simulation-based inference, SBICE identifies parameter configurations that produce synthetic datasets closely aligned with the source data distribution. Empirical results demonstrate that SBICE improves the reliability of estimator evaluations by generating more realistic datasets, which supports a robust and data-consistent approach to causal benchmarking under uncertainty.</li>
</ul>

<h3>Title: A Narrative Review of Clinical Decision Support Systems in Offloading Footwear for Diabetes-Related Foot Ulcers</h3>
<ul>
<li><strong>Authors: </strong>Kunal Kumar, Muhammad Ashad Kabir, Luke Donnan, Sayed Ahmed</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2509.02923">https://arxiv.org/abs/2509.02923</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2509.02923">https://arxiv.org/pdf/2509.02923</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2509.02923]] A Narrative Review of Clinical Decision Support Systems in Offloading Footwear for Diabetes-Related Foot Ulcers(https://arxiv.org/abs/2509.02923)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>Offloading footwear helps prevent and treat diabetic foot ulcers (DFUs) by lowering plantar pressure (PP), yet prescription decisions remain fragmented: feature selection varies, personalization is limited, and evaluation practices differ. We performed a narrative review of 45 studies (12 guidelines/protocols, 25 knowledge-based systems, 8 machine-learning applications) published to Aug 2025. We thematically analyzed knowledge type, decision logic, evaluation methods, and enabling technologies. Guidelines emphasize PP thresholds (<=200 kPa or >=25--30\% reduction) but rarely yield actionable, feature-level outputs. Knowledge-based systems use rule- and sensor-driven logic, integrating PP monitoring, adherence tracking, and usability testing. ML work introduces predictive, optimization, and generative models with high computational accuracy but limited explainability and clinical validation. Evaluation remains fragmented: protocols prioritize biomechanical tests; knowledge-based systems assess usability/adherence; ML studies focus on technical accuracy with weak linkage to long-term outcomes. From this synthesis we propose a five-part CDSS framework: (1) a minimum viable dataset; (2) a hybrid architecture combining rules, optimization, and explainable ML; (3) structured feature-level outputs; (4) continuous validation and evaluation; and (5) integration with clinical and telehealth workflows. This framework aims to enable scalable, patient-centered CDSSs for DFU care; prioritizing interoperable datasets, explainable models, and outcome-focused evaluation will be key to clinical adoption.</li>
</ul>

<h3>Title: VendiRL: A Framework for Self-Supervised Reinforcement Learning of Diversely Diverse Skills</h3>
<ul>
<li><strong>Authors: </strong>Erik M. Lintunen</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.RO</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2509.02930">https://arxiv.org/abs/2509.02930</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2509.02930">https://arxiv.org/pdf/2509.02930</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2509.02930]] VendiRL: A Framework for Self-Supervised Reinforcement Learning of Diversely Diverse Skills(https://arxiv.org/abs/2509.02930)</code><input type="text"></li>
<li><strong>Keywords: </strong>self-supervised</a></li>
<li><strong>Abstract: </strong>In self-supervised reinforcement learning (RL), one of the key challenges is learning a diverse set of skills to prepare agents for unknown future tasks. Despite impressive advances, scalability and evaluation remain prevalent issues. Regarding scalability, the search for meaningful skills can be obscured by high-dimensional feature spaces, where relevant features may vary across downstream task domains. For evaluating skill diversity, defining what constitutes "diversity" typically requires a hard commitment to a specific notion of what it means for skills to be diverse, potentially leading to inconsistencies in how skill diversity is understood, making results across different approaches hard to compare, and leaving many forms of diversity unexplored. To address these issues, we adopt a measure of sample diversity that translates ideas from ecology to machine learning -- the Vendi Score -- allowing the user to specify and evaluate any desired form of diversity. We demonstrate how this metric facilitates skill evaluation and introduce VendiRL, a unified framework for learning diversely diverse sets of skills. Given distinct similarity functions, VendiRL motivates distinct forms of diversity, which could support skill-diversity pretraining in new and richly interactive environments where optimising for various forms of diversity may be desirable.</li>
</ul>

<h3>Title: KEPT: Knowledge-Enhanced Prediction of Trajectories from Consecutive Driving Frames with Vision-Language Models</h3>
<ul>
<li><strong>Authors: </strong>Yujin Wang, Tianyi Wang, Quanfeng Liu, Wenxian Fan, Junfeng Jiao, Christian Claudel, Yunbing Yan, Bingzhao Gao, Jianqiang Wang, Hong Chen</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2509.02966">https://arxiv.org/abs/2509.02966</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2509.02966">https://arxiv.org/pdf/2509.02966</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2509.02966]] KEPT: Knowledge-Enhanced Prediction of Trajectories from Consecutive Driving Frames with Vision-Language Models(https://arxiv.org/abs/2509.02966)</code><input type="text"></li>
<li><strong>Keywords: </strong>self-supervised</a></li>
<li><strong>Abstract: </strong>Accurate short-horizon trajectory prediction is pivotal for safe and reliable autonomous driving, yet existing vision-language models (VLMs) often fail to effectively ground their reasoning in scene dynamics and domain knowledge. To address this challenge, this paper introduces KEPT, a knowledge-enhanced VLM framework that predicts ego trajectories directly from consecutive front-view driving frames. KEPT couples a temporal frequency-spatial fusion (TFSF) video encoder, trained via self-supervised learning with hard-negative mining, with a scalable k-means + HNSW retrieval stack that supplies scene-aligned exemplars. Retrieved priors are embedded into chain-of-thought (CoT) prompts with explicit planning constraints, while a triple-stage fine-tuning schedule incrementally aligns the language head to metric spatial cues, physically feasible motion, and temporally conditioned front-view planning. Evaluated on nuScenes dataset, KEPT achieves state-of-the-art performance across open-loop protocols: under NoAvg, it achieves 0.70m average L2 with a 0.21\% collision rate; under TemAvg with lightweight ego status, it attains 0.31m average L2 and a 0.07\% collision rate. Ablation studies show that all three fine-tuning stages contribute complementary benefits, and that using Top-2 retrieved exemplars yields the best accuracy-safety trade-off. The k-means-clustered HNSW index delivers sub-millisecond retrieval latency, supporting practical deployment. These results indicate that retrieval-augmented, CoT-guided VLMs offer a promising, data-efficient pathway toward interpretable and trustworthy autonomous driving.</li>
</ul>

<h3>Title: InstaDA: Augmenting Instance Segmentation Data with Dual-Agent System</h3>
<ul>
<li><strong>Authors: </strong>Xianbao Hou, Yonghao He, Zeyd Boukhers, John See, Hu Su, Wei Sui, Cong Yang</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2509.02973">https://arxiv.org/abs/2509.02973</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2509.02973">https://arxiv.org/pdf/2509.02973</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2509.02973]] InstaDA: Augmenting Instance Segmentation Data with Dual-Agent System(https://arxiv.org/abs/2509.02973)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>Acquiring high-quality instance segmentation data is challenging due to the labor-intensive nature of the annotation process and significant class imbalances within datasets. Recent studies have utilized the integration of Copy-Paste and diffusion models to create more diverse datasets. However, these studies often lack deep collaboration between large language models (LLMs) and diffusion models, and underutilize the rich information within the existing training data. To address these limitations, we propose InstaDA, a novel, training-free Dual-Agent system designed to augment instance segmentation datasets. First, we introduce a Text-Agent (T-Agent) that enhances data diversity through collaboration between LLMs and diffusion models. This agent features a novel Prompt Rethink mechanism, which iteratively refines prompts based on the generated images. This process not only fosters collaboration but also increases image utilization and optimizes the prompts themselves. Additionally, we present an Image-Agent (I-Agent) aimed at enriching the overall data distribution. This agent augments the training set by generating new instances conditioned on the training images. To ensure practicality and efficiency, both agents operate as independent and automated workflows, enhancing usability. Experiments conducted on the LVIS 1.0 validation set indicate that InstaDA achieves significant improvements, with an increase of +4.0 in box average precision (AP) and +3.3 in mask AP compared to the baseline. Furthermore, it outperforms the leading model, DiverGen, by +0.3 in box AP and +0.1 in mask AP, with a notable +0.7 gain in box AP on common categories and mask AP gains of +0.2 on common categories and +0.5 on frequent categories.</li>
</ul>

<h3>Title: Enhancing Robustness in Post-Processing Watermarking: An Ensemble Attack Network Using CNNs and Transformers</h3>
<ul>
<li><strong>Authors: </strong>Tzuhsuan Huang, Cheng Yu Yeo, Tsai-Ling Huang, Hong-Han Shuai, Wen-Huang Cheng, Jun-Cheng Chen</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2509.03006">https://arxiv.org/abs/2509.03006</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2509.03006">https://arxiv.org/pdf/2509.03006</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2509.03006]] Enhancing Robustness in Post-Processing Watermarking: An Ensemble Attack Network Using CNNs and Transformers(https://arxiv.org/abs/2509.03006)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, generative</a></li>
<li><strong>Abstract: </strong>Recent studies on deep watermarking have predominantly focused on in-processing watermarking, which integrates the watermarking process into image generation. However, post-processing watermarking, which embeds watermarks after image generation, offers more flexibility. It can be applied to outputs from any generative model (e.g. GANs, diffusion models) without needing access to the model's internal structure. It also allows users to embed unique watermarks into individual images. Therefore, this study focuses on post-processing watermarking and enhances its robustness by incorporating an ensemble attack network during training. We construct various versions of attack networks using CNN and Transformer in both spatial and frequency domains to investigate how each combination influences the robustness of the watermarking model. Our results demonstrate that combining a CNN-based attack network in the spatial domain with a Transformer-based attack network in the frequency domain yields the highest robustness in watermarking models. Extensive evaluation on the WAVES benchmark, using average bit accuracy as the metric, demonstrates that our ensemble attack network significantly enhances the robustness of baseline watermarking methods under various stress tests. In particular, for the Regeneration Attack defined in WAVES, our method improves StegaStamp by 18.743%. The code is released at:this https URL.</li>
</ul>

<h3>Title: Training LLMs to be Better Text Embedders through Bidirectional Reconstruction</h3>
<ul>
<li><strong>Authors: </strong>Chang Su, Dengliang Shi, Siyuan Huang, Jintao Du, Changhua Meng, Yu Cheng, Weiqiang Wang, Zhouhan Lin</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.IR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2509.03020">https://arxiv.org/abs/2509.03020</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2509.03020">https://arxiv.org/pdf/2509.03020</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2509.03020]] Training LLMs to be Better Text Embedders through Bidirectional Reconstruction(https://arxiv.org/abs/2509.03020)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>Large language models (LLMs) have increasingly been explored as powerful text embedders. Existing LLM-based text embedding approaches often leverage the embedding of the final token, typically a reserved special token such as [EOS]. However, these tokens have not been intentionally trained to capture the semantics of the whole context, limiting their capacity as text embeddings, especially for retrieval and re-ranking tasks. We propose to add a new training stage before contrastive learning to enrich the semantics of the final token embedding. This stage employs bidirectional generative reconstruction tasks, namely EBQ2D (Embedding-Based Query-to-Document) and EBD2Q (Embedding-Based Document-to-Query), which interleave to anchor the [EOS] embedding and reconstruct either side of Query-Document pairs. Experimental results demonstrate that our additional training stage significantly improves LLM performance on the Massive Text Embedding Benchmark (MTEB), achieving new state-of-the-art results across different LLM base models and scales.</li>
</ul>

<h3>Title: TraceLLM: Security Diagnosis Through Traces and Smart Contracts in Ethereum</h3>
<ul>
<li><strong>Authors: </strong>Shuzheng Wang, Yue Huang, Zhuoer Xu, Yuming Huang, Jing Tang</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.ET, cs.SE</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2509.03037">https://arxiv.org/abs/2509.03037</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2509.03037">https://arxiv.org/pdf/2509.03037</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2509.03037]] TraceLLM: Security Diagnosis Through Traces and Smart Contracts in Ethereum(https://arxiv.org/abs/2509.03037)</code><input type="text"></li>
<li><strong>Keywords: </strong>anomaly</a></li>
<li><strong>Abstract: </strong>Ethereum smart contracts hold tens of billions of USD in DeFi and NFTs, yet comprehensive security analysis remains difficult due to unverified code, proxy-based architectures, and the reliance on manual inspection of complex execution traces. Existing approaches fall into two main categories: anomaly transaction detection, which flags suspicious transactions but offers limited insight into specific attack strategies hidden in execution traces inside transactions, and code vulnerability detection, which cannot analyze unverified contracts and struggles to show how identified flaws are exploited in real incidents. As a result, analysts must still manually align transaction traces with contract code to reconstruct attack scenarios and conduct forensics. To address this gap, TraceLLM is proposed as a framework that leverages LLMs to integrate execution trace-level detection with decompiled contract code. We introduce a new anomaly execution path identification algorithm and an LLM-refined decompile tool to identify vulnerable functions and provide explicit attack paths to LLM. TraceLLM establishes the first benchmark for joint trace and contract code-driven security analysis. For comparison, proxy baselines are created by jointly transmitting the results of three representative code analysis along with raw traces to LLM. TraceLLM identifies attacker and victim addresses with 85.19\% precision and produces automated reports with 70.37\% factual precision across 27 cases with ground truth expert reports, achieving 25.93\% higher accuracy than the best baseline. Moreover, across 148 real-world Ethereum incidents, TraceLLM automatically generates reports with 66.22\% expert-verified accuracy, demonstrating strong generalizability.</li>
</ul>

<h3>Title: DCDB: Dynamic Conditional Dual Diffusion Bridge for Ill-posed Multi-Tasks</h3>
<ul>
<li><strong>Authors: </strong>Chengjie Huang, Jiafeng Yan, Jing Li, Lu Bai</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2509.03044">https://arxiv.org/abs/2509.03044</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2509.03044">https://arxiv.org/pdf/2509.03044</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2509.03044]] DCDB: Dynamic Conditional Dual Diffusion Bridge for Ill-posed Multi-Tasks(https://arxiv.org/abs/2509.03044)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>Conditional diffusion models have made impressive progress in the field of image processing, but the characteristics of constructing data distribution pathways make it difficult to exploit the intrinsic correlation between tasks in multi-task scenarios, which is even worse in ill-posed tasks with a lack of training data. In addition, traditional static condition control makes it difficult for networks to learn in multi-task scenarios with its dynamically evolving characteristics. To address these challenges, we propose a dynamic conditional double diffusion bridge training paradigm to build a general framework for ill-posed multi-tasks. Firstly, this paradigm decouples the diffusion and condition generation processes, avoiding the dependence of the diffusion model on supervised data in ill-posed tasks. Secondly, generated by the same noise schedule, dynamic conditions are used to gradually adjust their statistical characteristics, naturally embed time-related information, and reduce the difficulty of network learning. We analyze the learning objectives of the network under different conditional forms in the single-step denoising process and compare the changes in its attention weights in the network, demonstrating the superiority of our dynamic conditions. Taking dehazing and visible-infrared fusion as typical ill-posed multi-task scenarios, we achieve the best performance in multiple indicators on public datasets. The code has been publicly released at: this https URL.</li>
</ul>

<h3>Title: High Cursive Complex Character Recognition using GAN External Classifier</h3>
<ul>
<li><strong>Authors: </strong>S M Rafiuddin</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2509.03062">https://arxiv.org/abs/2509.03062</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2509.03062">https://arxiv.org/pdf/2509.03062</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2509.03062]] High Cursive Complex Character Recognition using GAN External Classifier(https://arxiv.org/abs/2509.03062)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>Handwritten characters can be trickier to classify due to their complex and cursive nature compared to simple and non-cursive characters. We present an external classifier along with a Generative Adversarial Network that can classify highly cursive and complex characters. The generator network produces fake handwritten character images, which are then used to augment the training data after adding adversarially perturbed noise and achieving a confidence score above a threshold with the discriminator network. The results show that the accuracy of convolutional neural networks decreases as character complexity increases, but our proposed model, ADA-GAN, remains more robust and effective for both cursive and complex characters.</li>
</ul>

<h3>Title: TRELLIS-Enhanced Surface Features for Comprehensive Intracranial Aneurysm Analysis</h3>
<ul>
<li><strong>Authors: </strong>Clément Hervé, Paul Garnier, Jonathan Viquerat, Elie Hachem</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2509.03095">https://arxiv.org/abs/2509.03095</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2509.03095">https://arxiv.org/pdf/2509.03095</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2509.03095]] TRELLIS-Enhanced Surface Features for Comprehensive Intracranial Aneurysm Analysis(https://arxiv.org/abs/2509.03095)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>Intracranial aneurysms pose a significant clinical risk yet are difficult to detect, delineate and model due to limited annotated 3D data. We propose a cross-domain feature-transfer approach that leverages the latent geometric embeddings learned by TRELLIS, a generative model trained on large-scale non-medical 3D datasets, to augment neural networks for aneurysm analysis. By replacing conventional point normals or mesh descriptors with TRELLIS surface features, we systematically enhance three downstream tasks: (i) classifying aneurysms versus healthy vessels in the Intra3D dataset, (ii) segmenting aneurysm and vessel regions on 3D meshes, and (iii) predicting time-evolving blood-flow fields using a graph neural network on the AnXplore dataset. Our experiments show that the inclusion of these features yields strong gains in accuracy, F1-score and segmentation quality over state-of-the-art baselines, and reduces simulation error by 15\%. These results illustrate the broader potential of transferring 3D representations from general-purpose generative models to specialized medical tasks.</li>
</ul>

<h3>Title: Towards Realistic Hand-Object Interaction with Gravity-Field Based Diffusion Bridge</h3>
<ul>
<li><strong>Authors: </strong>Miao Xu, Xiangyu Zhu, Xusheng Liang, Zidu Wang, Jinlin Wu, Zhen Lei</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2509.03114">https://arxiv.org/abs/2509.03114</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2509.03114">https://arxiv.org/pdf/2509.03114</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2509.03114]] Towards Realistic Hand-Object Interaction with Gravity-Field Based Diffusion Bridge(https://arxiv.org/abs/2509.03114)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>Existing reconstruction or hand-object pose estimation methods are capable of producing coarse interaction states. However, due to the complex and diverse geometry of both human hands and objects, these approaches often suffer from interpenetration or leave noticeable gaps in regions that are supposed to be in contact. Moreover, the surface of a real human hand undergoes non-negligible deformations during interaction, which are difficult to capture and represent with previous methods. To tackle these challenges, we formulate hand-object interaction as an attraction-driven process and propose a Gravity-Field Based Diffusion Bridge (GravityDB) to simulate interactions between a deformable hand surface and rigid objects. Our approach effectively resolves the aforementioned issues by generating physically plausible interactions that are free of interpenetration, ensure stable grasping, and capture realistic hand deformations. Furthermore, we incorporate semantic information from textual descriptions to guide the construction of the gravitational field, enabling more semantically meaningful interaction regions. Extensive qualitative and quantitative experiments on multiple datasets demonstrate the effectiveness of our method.</li>
</ul>

<h3>Title: Temporally-Aware Diffusion Model for Brain Progression Modelling with Bidirectional Temporal Regularisation</h3>
<ul>
<li><strong>Authors: </strong>Mattia Litrico, Francesco Guarnera, Mario Valerio Giuffrida, Daniele Ravì, Sebastiano Battiato</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2509.03141">https://arxiv.org/abs/2509.03141</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2509.03141">https://arxiv.org/pdf/2509.03141</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2509.03141]] Temporally-Aware Diffusion Model for Brain Progression Modelling with Bidirectional Temporal Regularisation(https://arxiv.org/abs/2509.03141)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>Generating realistic MRIs to accurately predict future changes in the structure of brain is an invaluable tool for clinicians in assessing clinical outcomes and analysing the disease progression at the patient level. However, current existing methods present some limitations: (i) some approaches fail to explicitly capture the relationship between structural changes and time intervals, especially when trained on age-imbalanced datasets; (ii) others rely only on scan interpolation, which lack clinical utility, as they generate intermediate images between timepoints rather than future pathological progression; and (iii) most approaches rely on 2D slice-based architectures, thereby disregarding full 3D anatomical context, which is essential for accurate longitudinal predictions. We propose a 3D Temporally-Aware Diffusion Model (TADM-3D), which accurately predicts brain progression on MRI volumes. To better model the relationship between time interval and brain changes, TADM-3D uses a pre-trained Brain-Age Estimator (BAE) that guides the diffusion model in the generation of MRIs that accurately reflect the expected age difference between baseline and generated follow-up scans. Additionally, to further improve the temporal awareness of TADM-3D, we propose the Back-In-Time Regularisation (BITR), by training TADM-3D to predict bidirectionally from the baseline to follow-up (forward), as well as from the follow-up to baseline (backward). Although predicting past scans has limited clinical applications, this regularisation helps the model generate temporally more accurate scans. We train and evaluate TADM-3D on the OASIS-3 dataset, and we validate the generalisation performance on an external test set from the NACC dataset. The code will be available upon acceptance.</li>
</ul>

<h3>Title: Count2Density: Crowd Density Estimation without Location-level Annotations</h3>
<ul>
<li><strong>Authors: </strong>Mattia Litrico, Feng Chen, Michael Pound, Sotirios A Tsaftaris, Sebastiano Battiato, Mario Valerio Giuffrida</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2509.03170">https://arxiv.org/abs/2509.03170</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2509.03170">https://arxiv.org/pdf/2509.03170</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2509.03170]] Count2Density: Crowd Density Estimation without Location-level Annotations(https://arxiv.org/abs/2509.03170)</code><input type="text"></li>
<li><strong>Keywords: </strong>self-supervised</a></li>
<li><strong>Abstract: </strong>Crowd density estimation is a well-known computer vision task aimed at estimating the density distribution of people in an image. The main challenge in this domain is the reliance on fine-grained location-level annotations, (i.e. points placed on top of each individual) to train deep networks. Collecting such detailed annotations is both tedious, time-consuming, and poses a significant barrier to scalability for real-world applications. To alleviate this burden, we present Count2Density: a novel pipeline designed to predict meaningful density maps containing quantitative spatial information using only count-level annotations (i.e., total number of people) during training. To achieve this, Count2Density generates pseudo-density maps leveraging past predictions stored in a Historical Map Bank, thereby reducing confirmation bias. This bank is initialised using an unsupervised saliency estimator to provide an initial spatial prior and is iteratively updated with an EMA of predicted density maps. These pseudo-density maps are obtained by sampling locations from estimated crowd areas using a hypergeometric distribution, with the number of samplings determined by the count-level annotations. To further enhance the spatial awareness of the model, we add a self-supervised contrastive spatial regulariser to encourage similar feature representations within crowded regions while maximising dissimilarity with background regions. Experimental results demonstrate that our approach significantly outperforms cross-domain adaptation methods and achieves better results than recent state-of-the-art approaches in semi-supervised settings across several datasets. Additional analyses validate the effectiveness of each individual component of our pipeline, confirming the ability of Count2Density to effectively retrieve spatial information from count-level annotations and enabling accurate subregion counting.</li>
</ul>

<h3>Title: AutoDetect: Designing an Autoencoder-based Detection Method for Poisoning Attacks on Object Detection Applications in the Military Domain</h3>
<ul>
<li><strong>Authors: </strong>Alma M. Liezenga, Stefan Wijnja, Puck de Haan, Niels W. T. Brink, Jip J. van Stijn, Yori Kamphuis, Klamer Schutte</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2509.03179">https://arxiv.org/abs/2509.03179</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2509.03179">https://arxiv.org/pdf/2509.03179</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2509.03179]] AutoDetect: Designing an Autoencoder-based Detection Method for Poisoning Attacks on Object Detection Applications in the Military Domain(https://arxiv.org/abs/2509.03179)</code><input type="text"></li>
<li><strong>Keywords: </strong>anomaly</a></li>
<li><strong>Abstract: </strong>Poisoning attacks pose an increasing threat to the security and robustness of Artificial Intelligence systems in the military domain. The widespread use of open-source datasets and pretrained models exacerbates this risk. Despite the severity of this threat, there is limited research on the application and detection of poisoning attacks on object detection systems. This is especially problematic in the military domain, where attacks can have grave consequences. In this work, we both investigate the effect of poisoning attacks on military object detectors in practice, and the best approach to detect these attacks. To support this research, we create a small, custom dataset featuring military vehicles: MilCivVeh. We explore the vulnerability of military object detectors for poisoning attacks by implementing a modified version of the BadDet attack: a patch-based poisoning attack. We then assess its impact, finding that while a positive attack success rate is achievable, it requires a substantial portion of the data to be poisoned -- raising questions about its practical applicability. To address the detection challenge, we test both specialized poisoning detection methods and anomaly detection methods from the visual industrial inspection domain. Since our research shows that both classes of methods are lacking, we introduce our own patch detection method: AutoDetect, a simple, fast, and lightweight autoencoder-based method. Our method shows promising results in separating clean from poisoned samples using the reconstruction error of image slices, outperforming existing methods, while being less time- and memory-intensive. We urge that the availability of large, representative datasets in the military domain is a prerequisite to further evaluate risks of poisoning attacks and opportunities patch detection.</li>
</ul>

<h3>Title: Tabular foundation model for GEOAI benchmark problems BM/AirportSoilProperties/2/2025</h3>
<ul>
<li><strong>Authors: </strong>Taiga Saito, Yu Otake, Stephen Wu</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2509.03191">https://arxiv.org/abs/2509.03191</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2509.03191">https://arxiv.org/pdf/2509.03191</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2509.03191]] Tabular foundation model for GEOAI benchmark problems BM/AirportSoilProperties/2/2025(https://arxiv.org/abs/2509.03191)</code><input type="text"></li>
<li><strong>Keywords: </strong>foundation model, in-context</a></li>
<li><strong>Abstract: </strong>This paper presents a novel application of the Tabular Prior-Data Fitted Network (TabPFN) - a transformer-based foundation model for tabular data - to geotechnical site characterization problems defined in the GEOAI benchmark BM/AirportSoilProperties/2/2025. Two tasks are addressed: (1) predicting the spatial variation of undrained shear strength (su) across borehole depth profiles, and (2) imputing missing mechanical parameters in a dense-site dataset. We apply TabPFN in a zero-training, few-shot, in-context learning setting - without hyper-parameter tuning - and provide it with additional context from the big indirect database (BID). The study demonstrates that TabPFN, as a general-purpose foundation model, achieved superior accuracy and well-calibrated predictive distributions compared to a conventional hierarchical Bayesian model (HBM) baseline, while also offering significant gains in inference efficiency. In Benchmark Problem #1 (spatial su prediction), TabPFN outperformed the HBM in prediction accuracy and delivered an order-of-magnitude faster runtime. In Benchmark Problem #2 (missing mechanical parameter imputation), TabPFN likewise achieved lower RMSE for all target parameters with well-quantified uncertainties, though its cumulative computation cost was higher than HBM's due to its one-variable-at-a-time inference. These results mark the first successful use of a tabular foundation model in geotechnical modeling, suggesting a potential paradigm shift in probabilistic site characterization.</li>
</ul>

<h3>Title: FoMEMO: Towards Foundation Models for Expensive Multi-objective Optimization</h3>
<ul>
<li><strong>Authors: </strong>Yiming Yao, Fei Liu, Liang Zhao, Xi Lin, Qingfu Zhang</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2509.03244">https://arxiv.org/abs/2509.03244</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2509.03244">https://arxiv.org/pdf/2509.03244</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2509.03244]] FoMEMO: Towards Foundation Models for Expensive Multi-objective Optimization(https://arxiv.org/abs/2509.03244)</code><input type="text"></li>
<li><strong>Keywords: </strong>foundation model, in-context</a></li>
<li><strong>Abstract: </strong>Expensive multi-objective optimization is a prevalent and crucial concern in many real-world scenarios, where sample-efficiency is vital due to the limited evaluations to recover the true Pareto front for decision making. Existing works either involve rebuilding Gaussian process surrogates from scratch for each objective in each new problem encountered, or rely on extensive past domain experiments for pre-training deep learning models, making them hard to generalize and impractical to cope with various emerging applications in the real world. To address this issue, we propose a new paradigm named FoMEMO (Foundation Models for Expensive Multi-objective Optimization), which enables the establishment of a foundation model conditioned on any domain trajectory and user preference, and facilitates fast in-context optimization based on the predicted preference-wise aggregation posteriors. Rather than accessing extensive domain experiments in the real world, we demonstrate that pre-training the foundation model with a diverse set of hundreds of millions of synthetic data can lead to superior adaptability to unknown problems, without necessitating any subsequent model training or updates in the optimization process. We evaluate our method across a variety of synthetic benchmarks and real-word applications, and demonstrate its superior generality and competitive performance compared to existing methods.</li>
</ul>

<h3>Title: HyPV-LEAD: Proactive Early-Warning of Cryptocurrency Anomalies through Data-Driven Structural-Temporal Modeling</h3>
<ul>
<li><strong>Authors: </strong>Minjung Park, Gyuyeon Na, Soyoun Kim, Sunyoung Moon, HyeonJeong Cha, Sangmi Chai</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, q-fin.RM</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2509.03260">https://arxiv.org/abs/2509.03260</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2509.03260">https://arxiv.org/pdf/2509.03260</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2509.03260]] HyPV-LEAD: Proactive Early-Warning of Cryptocurrency Anomalies through Data-Driven Structural-Temporal Modeling(https://arxiv.org/abs/2509.03260)</code><input type="text"></li>
<li><strong>Keywords: </strong>anomaly</a></li>
<li><strong>Abstract: </strong>Abnormal cryptocurrency transactions - such as mixing services, fraudulent transfers, and pump-and-dump operations -- pose escalating risks to financial integrity but remain notoriously difficult to detect due to class imbalance, temporal volatility, and complex network dependencies. Existing approaches are predominantly model-centric and post hoc, flagging anomalies only after they occur and thus offering limited preventive value. This paper introduces HyPV-LEAD (Hyperbolic Peak-Valley Lead-time Enabled Anomaly Detection), a data-driven early-warning framework that explicitly incorporates lead time into anomaly detection. Unlike prior methods, HyPV-LEAD integrates three innovations: (1) window-horizon modeling to guarantee actionable lead-time alerts, (2) Peak-Valley (PV) sampling to mitigate class imbalance while preserving temporal continuity, and (3) hyperbolic embedding to capture the hierarchical and scale-free properties of blockchain transaction networks. Empirical evaluation on large-scale Bitcoin transaction data demonstrates that HyPV-LEAD consistently outperforms state-of-the-art baselines, achieving a PR-AUC of 0.9624 with significant gains in precision and recall. Ablation studies further confirm that each component - PV sampling, hyperbolic embedding, and structural-temporal modeling - provides complementary benefits, with the full framework delivering the highest performance. By shifting anomaly detection from reactive classification to proactive early-warning, HyPV-LEAD establishes a robust foundation for real-time risk management, anti-money laundering (AML) compliance, and financial security in dynamic blockchain environments.</li>
</ul>

<h3>Title: Estudio de la eficiencia en la escalabilidad de GPUs para el entrenamiento de Inteligencia Artificial</h3>
<ul>
<li><strong>Authors: </strong>David Cortes, Carlos Juiz, Belen Bermejo</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.PF</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2509.03263">https://arxiv.org/abs/2509.03263</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2509.03263">https://arxiv.org/pdf/2509.03263</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2509.03263]] Estudio de la eficiencia en la escalabilidad de GPUs para el entrenamiento de Inteligencia Artificial(https://arxiv.org/abs/2509.03263)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>Training large-scale deep learning models has become a key challenge for the scientific community and industry. While the massive use of GPUs can significantly speed up training times, this approach has a negative impact on efficiency. In this article, we present a detailed analysis of the times reported by MLPerf Training v4.1 on four workloads: BERT, Llama2 LoRA, RetinaNet, and Stable Diffusion, showing that there are configurations that optimise the relationship between performance, GPU usage, and efficiency. The results point to a break-even point that allows training times to be reduced while maximising efficiency.</li>
</ul>

<h3>Title: SynBT: High-quality Tumor Synthesis for Breast Tumor Segmentation by 3D Diffusion Model</h3>
<ul>
<li><strong>Authors: </strong>Hongxu Yang, Edina Timko, Levente Lippenszky, Vanda Czipczer, Lehel Ferenczi</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2509.03267">https://arxiv.org/abs/2509.03267</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2509.03267">https://arxiv.org/pdf/2509.03267</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2509.03267]] SynBT: High-quality Tumor Synthesis for Breast Tumor Segmentation by 3D Diffusion Model(https://arxiv.org/abs/2509.03267)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>Synthetic tumors in medical images offer controllable characteristics that facilitate the training of machine learning models, leading to an improved segmentation performance. However, the existing methods of tumor synthesis yield suboptimal performances when tumor occupies a large spatial volume, such as breast tumor segmentation in MRI with a large field-of-view (FOV), while commonly used tumor generation methods are based on small patches. In this paper, we propose a 3D medical diffusion model, called SynBT, to generate high-quality breast tumor (BT) in contrast-enhanced MRI images. The proposed model consists of a patch-to-volume autoencoder, which is able to compress the high-resolution MRIs into compact latent space, while preserving the resolution of volumes with large FOV. Using the obtained latent space feature vector, a mask-conditioned diffusion model is used to synthesize breast tumors within selected regions of breast tissue, resulting in realistic tumor appearances. We evaluated the proposed method for a tumor segmentation task, which demonstrated the proposed high-quality tumor synthesis method can facilitate the common segmentation models with performance improvement of 2-3% Dice Score on a large public dataset, and therefore provides benefits for tumor segmentation in MRI images.</li>
</ul>

<h3>Title: PointAD+: Learning Hierarchical Representations for Zero-shot 3D Anomaly Detection</h3>
<ul>
<li><strong>Authors: </strong>Qihang Zhou, Shibo He, Jiangtao Yan, Wenchao Meng, Jiming Chen</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2509.03277">https://arxiv.org/abs/2509.03277</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2509.03277">https://arxiv.org/pdf/2509.03277</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2509.03277]] PointAD+: Learning Hierarchical Representations for Zero-shot 3D Anomaly Detection(https://arxiv.org/abs/2509.03277)</code><input type="text"></li>
<li><strong>Keywords: </strong>anomaly</a></li>
<li><strong>Abstract: </strong>In this paper, we aim to transfer CLIP's robust 2D generalization capabilities to identify 3D anomalies across unseen objects of highly diverse class semantics. To this end, we propose a unified framework to comprehensively detect and segment 3D anomalies by leveraging both point- and pixel-level information. We first design PointAD, which leverages point-pixel correspondence to represent 3D anomalies through their associated rendering pixel representations. This approach is referred to as implicit 3D representation, as it focuses solely on rendering pixel anomalies but neglects the inherent spatial relationships within point clouds. Then, we propose PointAD+ to further broaden the interpretation of 3D anomalies by introducing explicit 3D representation, emphasizing spatial abnormality to uncover abnormal spatial relationships. Hence, we propose G-aggregation to involve geometry information to enable the aggregated point representations spatially aware. To simultaneously capture rendering and spatial abnormality, PointAD+ proposes hierarchical representation learning, incorporating implicit and explicit anomaly semantics into hierarchical text prompts: rendering prompts for the rendering layer and geometry prompts for the geometry layer. A cross-hierarchy contrastive alignment is further introduced to promote the interaction between the rendering and geometry layers, facilitating mutual anomaly learning. Finally, PointAD+ integrates anomaly semantics from both layers to capture the generalized anomaly semantics. During the test, PointAD+ can integrate RGB information in a plug-and-play manner and further improve its detection performance. Extensive experiments demonstrate the superiority of PointAD+ in ZS 3D anomaly detection across unseen objects with highly diverse class semantics, achieving a holistic understanding of abnormality.</li>
</ul>

<h3>Title: InfraDiffusion: zero-shot depth map restoration with diffusion models and prompted segmentation from sparse infrastructure point clouds</h3>
<ul>
<li><strong>Authors: </strong>Yixiong Jing, Cheng Zhang, Haibing Wu, Guangming Wang, Olaf Wysocki, Brian Sheil</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2509.03324">https://arxiv.org/abs/2509.03324</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2509.03324">https://arxiv.org/pdf/2509.03324</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2509.03324]] InfraDiffusion: zero-shot depth map restoration with diffusion models and prompted segmentation from sparse infrastructure point clouds(https://arxiv.org/abs/2509.03324)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>Point clouds are widely used for infrastructure monitoring by providing geometric information, where segmentation is required for downstream tasks such as defect detection. Existing research has automated semantic segmentation of structural components, while brick-level segmentation (identifying defects such as spalling and mortar loss) has been primarily conducted from RGB images. However, acquiring high-resolution images is impractical in low-light environments like masonry tunnels. Point clouds, though robust to dim lighting, are typically unstructured, sparse, and noisy, limiting fine-grained segmentation. We present InfraDiffusion, a zero-shot framework that projects masonry point clouds into depth maps using virtual cameras and restores them by adapting the Denoising Diffusion Null-space Model (DDNM). Without task-specific training, InfraDiffusion enhances visual clarity and geometric consistency of depth maps. Experiments on masonry bridge and tunnel point cloud datasets show significant improvements in brick-level segmentation using the Segment Anything Model (SAM), underscoring its potential for automated inspection of masonry assets. Our code and data is available at this https URL.</li>
</ul>

<h3>Title: Equivariant Flow Matching for Symmetry-Breaking Bifurcation Problems</h3>
<ul>
<li><strong>Authors: </strong>Fleur Hendriks, Ondřej Rokoš, Martin Doškář, Marc G.D. Geers, Vlado Menkovski</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CE, physics.comp-ph</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2509.03340">https://arxiv.org/abs/2509.03340</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2509.03340">https://arxiv.org/pdf/2509.03340</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2509.03340]] Equivariant Flow Matching for Symmetry-Breaking Bifurcation Problems(https://arxiv.org/abs/2509.03340)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>Bifurcation phenomena in nonlinear dynamical systems often lead to multiple coexisting stable solutions, particularly in the presence of symmetry breaking. Deterministic machine learning models struggle to capture this multiplicity, averaging over solutions and failing to represent lower-symmetry outcomes. In this work, we propose a generative framework based on flow matching to model the full probability distribution over bifurcation outcomes. Our method enables direct sampling of multiple valid solutions while preserving system symmetries through equivariant modeling. We introduce a symmetric matching strategy that aligns predicted and target outputs under group actions, allowing accurate learning in equivariant settings. We validate our approach on a range of systems, from toy models to complex physical problems such as buckling beams and the Allen-Cahn equation. Our results demonstrate that flow matching significantly outperforms non-probabilistic and variational methods in capturing multimodal distributions and symmetry-breaking bifurcations, offering a principled and scalable solution for modeling multistability in high-dimensional systems.</li>
</ul>

<h3>Title: On the MIA Vulnerability Gap Between Private GANs and Diffusion Models</h3>
<ul>
<li><strong>Authors: </strong>Ilana Sebag, Jean-Yves Franceschi, Alain Rakotomamonjy, Alexandre Allauzen, Jamal Atif</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2509.03341">https://arxiv.org/abs/2509.03341</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2509.03341">https://arxiv.org/pdf/2509.03341</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2509.03341]] On the MIA Vulnerability Gap Between Private GANs and Diffusion Models(https://arxiv.org/abs/2509.03341)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, generative</a></li>
<li><strong>Abstract: </strong>Generative Adversarial Networks (GANs) and diffusion models have emerged as leading approaches for high-quality image synthesis. While both can be trained under differential privacy (DP) to protect sensitive data, their sensitivity to membership inference attacks (MIAs), a key threat to data confidentiality, remains poorly understood. In this work, we present the first unified theoretical and empirical analysis of the privacy risks faced by differentially private generative models. We begin by showing, through a stability-based analysis, that GANs exhibit fundamentally lower sensitivity to data perturbations than diffusion models, suggesting a structural advantage in resisting MIAs. We then validate this insight with a comprehensive empirical study using a standardized MIA pipeline to evaluate privacy leakage across datasets and privacy budgets. Our results consistently reveal a marked privacy robustness gap in favor of GANs, even in strong DP regimes, highlighting that model type alone can critically shape privacy leakage.</li>
</ul>

<h3>Title: epiGPTope: A machine learning-based epitope generator and classifier</h3>
<ul>
<li><strong>Authors: </strong>Natalia Flechas Manrique, Alberto Martínez, Elena López-Martínez, Luc Andrea, Román Orus, Aitor Manteca, Aitziber L. Cortajarena, Llorenç Espinosa-Portalés</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, q-bio.QM</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2509.03351">https://arxiv.org/abs/2509.03351</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2509.03351">https://arxiv.org/pdf/2509.03351</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2509.03351]] epiGPTope: A machine learning-based epitope generator and classifier(https://arxiv.org/abs/2509.03351)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>Epitopes are short antigenic peptide sequences which are recognized by antibodies or immune cell receptors. These are central to the development of immunotherapies, vaccines, and diagnostics. However, the rational design of synthetic epitope libraries is challenging due to the large combinatorial sequence space, $20^n$ combinations for linear epitopes of n amino acids, making screening and testing unfeasible, even with high throughput experimental techniques. In this study, we present a large language model, epiGPTope, pre-trained on protein data and specifically fine-tuned on linear epitopes, which for the first time can directly generate novel epitope-like sequences, which are found to possess statistical properties analogous to the ones of known epitopes. This generative approach can be used to prepare libraries of epitope candidate sequences. We further train statistical classifiers to predict whether an epitope sequence is of bacterial or viral origin, thus narrowing the candidate library and increasing the likelihood of identifying specific epitopes. We propose that such combination of generative and predictive models can be of assistance in epitope discovery. The approach uses only primary amino acid sequences of linear epitopes, bypassing the need for a geometric framework or hand-crafted features of the sequences. By developing a method to create biologically feasible sequences, we anticipate faster and more cost-effective generation and screening of synthetic epitopes, with relevant applications in the development of new biotechnologies.</li>
</ul>

<h3>Title: Human Preference-Aligned Concept Customization Benchmark via Decomposed Evaluation</h3>
<ul>
<li><strong>Authors: </strong>Reina Ishikawa, Ryo Fujii, Hideo Saito, Ryo Hachiuma</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2509.03385">https://arxiv.org/abs/2509.03385</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2509.03385">https://arxiv.org/pdf/2509.03385</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2509.03385]] Human Preference-Aligned Concept Customization Benchmark via Decomposed Evaluation(https://arxiv.org/abs/2509.03385)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>Evaluating concept customization is challenging, as it requires a comprehensive assessment of fidelity to generative prompts and concept images. Moreover, evaluating multiple concepts is considerably more difficult than evaluating a single concept, as it demands detailed assessment not only for each individual concept but also for the interactions among concepts. While humans can intuitively assess generated images, existing metrics often provide either overly narrow or overly generalized evaluations, resulting in misalignment with human preference. To address this, we propose Decomposed GPT Score (D-GPTScore), a novel human-aligned evaluation method that decomposes evaluation criteria into finer aspects and incorporates aspect-wise assessments using Multimodal Large Language Model (MLLM). Additionally, we release Human Preference-Aligned Concept Customization Benchmark (CC-AlignBench), a benchmark dataset containing both single- and multi-concept tasks, enabling stage-wise evaluation across a wide difficulty range -- from individual actions to multi-person interactions. Our method significantly outperforms existing approaches on this benchmark, exhibiting higher correlation with human preferences. This work establishes a new standard for evaluating concept customization and highlights key challenges for future research. The benchmark and associated materials are available at this https URL.</li>
</ul>

<h3>Title: Joint Training of Image Generator and Detector for Road Defect Detection</h3>
<ul>
<li><strong>Authors: </strong>Kuan-Chuan Peng</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2509.03465">https://arxiv.org/abs/2509.03465</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2509.03465">https://arxiv.org/pdf/2509.03465</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2509.03465]] Joint Training of Image Generator and Detector for Road Defect Detection(https://arxiv.org/abs/2509.03465)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>Road defect detection is important for road authorities to reduce the vehicle damage caused by road defects. Considering the practical scenarios where the defect detectors are typically deployed on edge devices with limited memory and computational resource, we aim at performing road defect detection without using ensemble-based methods or test-time augmentation (TTA). To this end, we propose to Jointly Train the image Generator and Detector for road defect detection (dubbed as JTGD). We design the dual discriminators for the generative model to enforce both the synthesized defect patches and overall images to look plausible. The synthesized image quality is improved by our proposed CLIP-based Fréchet Inception Distance loss. The generative model in JTGD is trained jointly with the detector to encourage the generative model to synthesize harder examples for the detector. Since harder synthesized images of better quality caused by the aforesaid design are used in the data augmentation, JTGD outperforms the state-of-the-art method in the RDD2022 road defect detection benchmark across various countries under the condition of no ensemble and TTA. JTGD only uses less than 20% of the number of parameters compared with the competing baseline, which makes it more suitable for deployment on edge devices in practice.</li>
</ul>

<h3>Title: SafeProtein: Red-Teaming Framework and Benchmark for Protein Foundation Models</h3>
<ul>
<li><strong>Authors: </strong>Jigang Fan, Zhenghong Zhou, Ruofan Jin, Le Cong, Mengdi Wang, Zaixi Zhang</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CR, q-bio.BM, q-bio.QM</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2509.03487">https://arxiv.org/abs/2509.03487</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2509.03487">https://arxiv.org/pdf/2509.03487</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2509.03487]] SafeProtein: Red-Teaming Framework and Benchmark for Protein Foundation Models(https://arxiv.org/abs/2509.03487)</code><input type="text"></li>
<li><strong>Keywords: </strong>foundation model</a></li>
<li><strong>Abstract: </strong>Proteins play crucial roles in almost all biological processes. The advancement of deep learning has greatly accelerated the development of protein foundation models, leading to significant successes in protein understanding and design. However, the lack of systematic red-teaming for these models has raised serious concerns about their potential misuse, such as generating proteins with biological safety risks. This paper introduces SafeProtein, the first red-teaming framework designed for protein foundation models to the best of our knowledge. SafeProtein combines multimodal prompt engineering and heuristic beam search to systematically design red-teaming methods and conduct tests on protein foundation models. We also curated SafeProtein-Bench, which includes a manually constructed red-teaming benchmark dataset and a comprehensive evaluation protocol. SafeProtein achieved continuous jailbreaks on state-of-the-art protein foundation models (up to 70% attack success rate for ESM3), revealing potential biological safety risks in current protein foundation models and providing insights for the development of robust security protection technologies for frontier models. The codes will be made publicly available at this https URL.</li>
</ul>

<h3>Title: OneCAT: Decoder-Only Auto-Regressive Model for Unified Understanding and Generation</h3>
<ul>
<li><strong>Authors: </strong>Han Li, Xinyu Peng, Yaoming Wang, Zelin Peng, Xin Chen, Rongxiang Weng, Jingang Wang, Xunliang Cai, Wenrui Dai, Hongkai Xiong</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2509.03498">https://arxiv.org/abs/2509.03498</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2509.03498">https://arxiv.org/pdf/2509.03498</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2509.03498]] OneCAT: Decoder-Only Auto-Regressive Model for Unified Understanding and Generation(https://arxiv.org/abs/2509.03498)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>We introduce OneCAT, a unified multimodal model that seamlessly integrates understanding, generation, and editing within a novel, pure decoder-only transformer architecture. Our framework uniquely eliminates the need for external components such as Vision Transformers (ViT) or vision tokenizer during inference, leading to significant efficiency gains, especially for high-resolution inputs. This is achieved through a modality-specific Mixture-of-Experts (MoE) structure trained with a single autoregressive (AR) objective, which also natively supports dynamic resolutions. Furthermore, we pioneer a multi-scale visual autoregressive mechanism within the Large Language Model (LLM) that drastically reduces decoding steps compared to diffusion-based methods while maintaining state-of-the-art performance. Our findings demonstrate the powerful potential of pure autoregressive modeling as a sufficient and elegant foundation for unified multimodal intelligence. As a result, OneCAT sets a new performance standard, outperforming existing open-source unified multimodal models across benchmarks for multimodal generation, editing, and understanding.</li>
</ul>

<h3>Title: LimiX: Unleashing Structured-Data Modeling Capability for Generalist Intelligence</h3>
<ul>
<li><strong>Authors: </strong>Xingxuan Zhang, Gang Ren, Han Yu, Hao Yuan, Hui Wang, Jiansheng Li, Jiayun Wu, Lang Mo, Li Mao, Mingchao Hao, Ningbo Dai, Renzhe Xu, Shuyang Li, Tianyang Zhang, Yue He, Yuanrui Wang, Yunjia Zhang, Zijing Xu, Dongzhe Li, Fang Gao, Hao Zou, Jiandong Liu, Jiashuo Liu, Jiawei Xu, Kaijie Cheng, Kehan Li, Linjun Zhou, Qing Li, Shaohua Fan, Xiaoyu Lin, Xinyan Han, Xuanyue Li, Yan Lu, Yuan Xue, Yuanyuan Jiang, Zimu Wang, Zhenlei Wang, Peng Cui</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2509.03505">https://arxiv.org/abs/2509.03505</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2509.03505">https://arxiv.org/pdf/2509.03505</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2509.03505]] LimiX: Unleashing Structured-Data Modeling Capability for Generalist Intelligence(https://arxiv.org/abs/2509.03505)</code><input type="text"></li>
<li><strong>Keywords: </strong>foundation model</a></li>
<li><strong>Abstract: </strong>We argue that progress toward general intelligence requires complementary foundation models grounded in language, the physical world, and structured data. This report presents LimiX, the first installment of our large structured-data models (LDMs). LimiX treats structured data as a joint distribution over variables and missingness, thus capable of addressing a wide range of tabular tasks through query-based conditional prediction via a single model. LimiX is pretrained using masked joint-distribution modeling with an episodic, context-conditional objective, where the model predicts for query subsets conditioned on dataset-specific contexts, supporting rapid, training-free adaptation at inference. We evaluate LimiX across 10 large structured-data benchmarks with broad regimes of sample size, feature dimensionality, class number, categorical-to-numerical feature ratio, missingness, and sample-to-feature ratios. With a single model and a unified interface, LimiX consistently surpasses strong baselines including gradient-boosting trees, deep tabular networks, recent tabular foundation models, and automated ensembles, as shown in Figure 1 and Figure 2. The superiority holds across a wide range of tasks, such as classification, regression, missing value imputation, and data generation, often by substantial margins, while avoiding task-specific architectures or bespoke training per task. All LimiX models are publicly accessible under Apache 2.0.</li>
</ul>

<button id="copy">Copy All</button>
</article>
<script src="../../javascript/clipboard.min.js"></script>
<script src="../../javascript/clipboard.js"></script>
