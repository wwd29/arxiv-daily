<link rel="stylesheet" href="../../css/markdown.css" />
<article class="markdown-body">
<h2>diffusion</h2>
<h3>Title: DF-3DFace: One-to-Many Speech Synchronized 3D Face Animation with Diffusion. (arXiv:2310.05934v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.05934">http://arxiv.org/abs/2310.05934</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.05934]] DF-3DFace: One-to-Many Speech Synchronized 3D Face Animation with Diffusion(http://arxiv.org/abs/2310.05934)</code></li>
<li>Summary: <p>Speech-driven 3D facial animation has gained significant attention for its
ability to create realistic and expressive facial animations in 3D space based
on speech. Learning-based methods have shown promising progress in achieving
accurate facial motion synchronized with speech. However, one-to-many nature of
speech-to-3D facial synthesis has not been fully explored: while the lip
accurately synchronizes with the speech content, other facial attributes beyond
speech-related motions are variable with respect to the speech. To account for
the potential variance in the facial attributes within a single speech, we
propose DF-3DFace, a diffusion-driven speech-to-3D face mesh synthesis.
DF-3DFace captures the complex one-to-many relationships between speech and 3D
face based on diffusion. It concurrently achieves aligned lip motion by
exploiting audio-mesh synchronization and masked conditioning. Furthermore, the
proposed method jointly models identity and pose in addition to facial motions
so that it can generate 3D face animation without requiring a reference
identity mesh and produce natural head poses. We contribute a new large-scale
3D facial mesh dataset, 3D-HDTF to enable the synthesis of variations in
identities, poses, and facial motions of 3D face mesh. Extensive experiments
demonstrate that our method successfully generates highly variable facial
shapes and motions from speech and simultaneously achieves more realistic
facial animation than the state-of-the-art methods.
</p></li>
</ul>

<h3>Title: Layout Sequence Prediction From Noisy Mobile Modality. (arXiv:2310.06138v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.06138">http://arxiv.org/abs/2310.06138</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.06138]] Layout Sequence Prediction From Noisy Mobile Modality(http://arxiv.org/abs/2310.06138)</code></li>
<li>Summary: <p>Trajectory prediction plays a vital role in understanding pedestrian movement
for applications such as autonomous driving and robotics. Current trajectory
prediction models depend on long, complete, and accurately observed sequences
from visual modalities. Nevertheless, real-world situations often involve
obstructed cameras, missed objects, or objects out of sight due to
environmental factors, leading to incomplete or noisy trajectories. To overcome
these limitations, we propose LTrajDiff, a novel approach that treats objects
obstructed or out of sight as equally important as those with fully visible
trajectories. LTrajDiff utilizes sensor data from mobile phones to surmount
out-of-sight constraints, albeit introducing new challenges such as modality
fusion, noisy data, and the absence of spatial layout and object size
information. We employ a denoising diffusion model to predict precise layout
sequences from noisy mobile data using a coarse-to-fine diffusion strategy,
incorporating the RMS, Siamese Masked Encoding Module, and MFM. Our model
predicts layout sequences by implicitly inferring object size and projection
status from a single reference timestamp or significantly obstructed sequences.
Achieving SOTA results in randomly obstructed experiments and extremely short
input experiments, our model illustrates the effectiveness of leveraging noisy
mobile data. In summary, our approach offers a promising solution to the
challenges faced by layout sequence and trajectory prediction models in
real-world settings, paving the way for utilizing sensor data from mobile
phones to accurately predict pedestrian bounding box trajectories. To the best
of our knowledge, this is the first work that addresses severely obstructed and
extremely short layout sequences by combining vision with noisy mobile
modality, making it the pioneering work in the field of layout sequence
trajectory prediction.
</p></li>
</ul>

<h3>Title: Improving Compositional Text-to-image Generation with Large Vision-Language Models. (arXiv:2310.06311v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.06311">http://arxiv.org/abs/2310.06311</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.06311]] Improving Compositional Text-to-image Generation with Large Vision-Language Models(http://arxiv.org/abs/2310.06311)</code></li>
<li>Summary: <p>Recent advancements in text-to-image models, particularly diffusion models,
have shown significant promise. However, compositional text-to-image models
frequently encounter difficulties in generating high-quality images that
accurately align with input texts describing multiple objects, variable
attributes, and intricate spatial relationships. To address this limitation, we
employ large vision-language models (LVLMs) for multi-dimensional assessment of
the alignment between generated images and their corresponding input texts.
Utilizing this assessment, we fine-tune the diffusion model to enhance its
alignment capabilities. During the inference phase, an initial image is
produced using the fine-tuned diffusion model. The LVLM is then employed to
pinpoint areas of misalignment in the initial image, which are subsequently
corrected using the image editing algorithm until no further misalignments are
detected by the LVLM. The resultant image is consequently more closely aligned
with the input text. Our experimental results validate that the proposed
methodology significantly improves text-image alignment in compositional image
generation, particularly with respect to object number, attribute binding,
spatial relationships, and aesthetic quality.
</p></li>
</ul>

<h3>Title: Advancing Pose-Guided Image Synthesis with Progressive Conditional Diffusion Models. (arXiv:2310.06313v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.06313">http://arxiv.org/abs/2310.06313</a></li>
<li>Code URL: https://github.com/muzishen/pcdms</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.06313]] Advancing Pose-Guided Image Synthesis with Progressive Conditional Diffusion Models(http://arxiv.org/abs/2310.06313)</code></li>
<li>Summary: <p>Recent work has showcased the significant potential of diffusion models in
pose-guided person image synthesis. However, owing to the inconsistency in pose
between the source and target images, synthesizing an image with a distinct
pose, relying exclusively on the source image and target pose information,
remains a formidable challenge. This paper presents Progressive Conditional
Diffusion Models (PCDMs) that incrementally bridge the gap between person
images under the target and source poses through three stages. Specifically, in
the first stage, we design a simple prior conditional diffusion model that
predicts the global features of the target image by mining the global alignment
relationship between pose coordinates and image appearance. Then, the second
stage establishes a dense correspondence between the source and target images
using the global features from the previous stage, and an inpainting
conditional diffusion model is proposed to further align and enhance the
contextual features, generating a coarse-grained person image. In the third
stage, we propose a refining conditional diffusion model to utilize the
coarsely generated image from the previous stage as a condition, achieving
texture restoration and enhancing fine-detail consistency. The three-stage
PCDMs work progressively to generate the final high-quality and high-fidelity
synthesized image. Both qualitative and quantitative results demonstrate the
consistency and photorealism of our proposed PCDMs under challenging
scenarios.The code and model will be available at
https://github.com/muzishen/PCDMs.
</p></li>
</ul>

<h3>Title: JointNet: Extending Text-to-Image Diffusion for Dense Distribution Modeling. (arXiv:2310.06347v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.06347">http://arxiv.org/abs/2310.06347</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.06347]] JointNet: Extending Text-to-Image Diffusion for Dense Distribution Modeling(http://arxiv.org/abs/2310.06347)</code></li>
<li>Summary: <p>We introduce JointNet, a novel neural network architecture for modeling the
joint distribution of images and an additional dense modality (e.g., depth
maps). JointNet is extended from a pre-trained text-to-image diffusion model,
where a copy of the original network is created for the new dense modality
branch and is densely connected with the RGB branch. The RGB branch is locked
during network fine-tuning, which enables efficient learning of the new
modality distribution while maintaining the strong generalization ability of
the large-scale pre-trained diffusion model. We demonstrate the effectiveness
of JointNet by using RGBD diffusion as an example and through extensive
experiments, showcasing its applicability in a variety of applications,
including joint RGBD generation, dense depth prediction, depth-conditioned
image generation, and coherent tile-based 3D panorama generation.
</p></li>
</ul>

<h3>Title: Leveraging Diffusion-Based Image Variations for Robust Training on Poisoned Data. (arXiv:2310.06372v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.06372">http://arxiv.org/abs/2310.06372</a></li>
<li>Code URL: https://github.com/lukasstruppek/robust_training_on_poisoned_samples</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.06372]] Leveraging Diffusion-Based Image Variations for Robust Training on Poisoned Data(http://arxiv.org/abs/2310.06372)</code></li>
<li>Summary: <p>Backdoor attacks pose a serious security threat for training neural networks
as they surreptitiously introduce hidden functionalities into a model. Such
backdoors remain silent during inference on clean inputs, evading detection due
to inconspicuous behavior. However, once a specific trigger pattern appears in
the input data, the backdoor activates, causing the model to execute its
concealed function. Detecting such poisoned samples within vast datasets is
virtually impossible through manual inspection. To address this challenge, we
propose a novel approach that enables model training on potentially poisoned
datasets by utilizing the power of recent diffusion models. Specifically, we
create synthetic variations of all training samples, leveraging the inherent
resilience of diffusion models to potential trigger patterns in the data. By
combining this generative approach with knowledge distillation, we produce
student models that maintain their general performance on the task while
exhibiting robust resistance to backdoor triggers.
</p></li>
</ul>

<h3>Title: Learning Stackable and Skippable LEGO Bricks for Efficient, Reconfigurable, and Variable-Resolution Diffusion Modeling. (arXiv:2310.06389v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.06389">http://arxiv.org/abs/2310.06389</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.06389]] Learning Stackable and Skippable LEGO Bricks for Efficient, Reconfigurable, and Variable-Resolution Diffusion Modeling(http://arxiv.org/abs/2310.06389)</code></li>
<li>Summary: <p>Diffusion models excel at generating photo-realistic images but come with
significant computational costs in both training and sampling. While various
techniques address these computational challenges, a less-explored issue is
designing an efficient and adaptable network backbone for iterative refinement.
Current options like U-Net and Vision Transformer often rely on
resource-intensive deep networks and lack the flexibility needed for generating
images at variable resolutions or with a smaller network than used in training.
This study introduces LEGO bricks, which seamlessly integrate Local-feature
Enrichment and Global-content Orchestration. These bricks can be stacked to
create a test-time reconfigurable diffusion backbone, allowing selective
skipping of bricks to reduce sampling costs and generate higher-resolution
images than the training data. LEGO bricks enrich local regions with an MLP and
transform them using a Transformer block while maintaining a consistent
full-resolution image across all bricks. Experimental results demonstrate that
LEGO bricks enhance training efficiency, expedite convergence, and facilitate
variable-resolution image generation while maintaining strong generative
performance. Moreover, LEGO significantly reduces sampling time compared to
other methods, establishing it as a valuable enhancement for diffusion models.
</p></li>
</ul>

<h3>Title: AnoDODE: Anomaly Detection with Diffusion ODE. (arXiv:2310.06420v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.06420">http://arxiv.org/abs/2310.06420</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.06420]] AnoDODE: Anomaly Detection with Diffusion ODE(http://arxiv.org/abs/2310.06420)</code></li>
<li>Summary: <p>Anomaly detection is the process of identifying atypical data samples that
significantly deviate from the majority of the dataset. In the realm of
clinical screening and diagnosis, detecting abnormalities in medical images
holds great importance. Typically, clinical practice provides access to a vast
collection of normal images, while abnormal images are relatively scarce. We
hypothesize that abnormal images and their associated features tend to manifest
in low-density regions of the data distribution. Following this assumption, we
turn to diffusion ODEs for unsupervised anomaly detection, given their
tractability and superior performance in density estimation tasks. More
precisely, we propose a new anomaly detection method based on diffusion ODEs by
estimating the density of features extracted from multi-scale medical images.
Our anomaly scoring mechanism depends on computing the negative log-likelihood
of features extracted from medical images at different scales, quantified in
bits per dimension. Furthermore, we propose a reconstruction-based anomaly
localization suitable for our method. Our proposed method not only identifie
anomalies but also provides interpretability at both the image and pixel
levels. Through experiments on the BraTS2021 medical dataset, our proposed
method outperforms existing methods. These results confirm the effectiveness
and robustness of our method.
</p></li>
</ul>

<h3>Title: Latent Diffusion Model for DNA Sequence Generation. (arXiv:2310.06150v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.06150">http://arxiv.org/abs/2310.06150</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.06150]] Latent Diffusion Model for DNA Sequence Generation(http://arxiv.org/abs/2310.06150)</code></li>
<li>Summary: <p>The harnessing of machine learning, especially deep generative models, has
opened up promising avenues in the field of synthetic DNA sequence generation.
Whilst Generative Adversarial Networks (GANs) have gained traction for this
application, they often face issues such as limited sample diversity and mode
collapse. On the other hand, Diffusion Models are a promising new class of
generative models that are not burdened with these problems, enabling them to
reach the state-of-the-art in domains such as image generation. In light of
this, we propose a novel latent diffusion model, DiscDiff, tailored for
discrete DNA sequence generation. By simply embedding discrete DNA sequences
into a continuous latent space using an autoencoder, we are able to leverage
the powerful generative abilities of continuous diffusion models for the
generation of discrete data. Additionally, we introduce Fr\'echet
Reconstruction Distance (FReD) as a new metric to measure the sample quality of
DNA sequence generations. Our DiscDiff model demonstrates an ability to
generate synthetic DNA sequences that align closely with real DNA in terms of
Motif Distribution, Latent Embedding Distribution (FReD), and Chromatin
Profiles. Additionally, we contribute a comprehensive cross-species dataset of
150K unique promoter-gene sequences from 15 species, enriching resources for
future generative modelling in genomics. We will make our code public upon
publication.
</p></li>
</ul>

<h3>Title: Memory-Consistent Neural Networks for Imitation Learning. (arXiv:2310.06171v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.06171">http://arxiv.org/abs/2310.06171</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.06171]] Memory-Consistent Neural Networks for Imitation Learning(http://arxiv.org/abs/2310.06171)</code></li>
<li>Summary: <p>Imitation learning considerably simplifies policy synthesis compared to
alternative approaches by exploiting access to expert demonstrations. For such
imitation policies, errors away from the training samples are particularly
critical. Even rare slip-ups in the policy action outputs can compound quickly
over time, since they lead to unfamiliar future states where the policy is
still more likely to err, eventually causing task failures. We revisit simple
supervised ``behavior cloning'' for conveniently training the policy from
nothing more than pre-recorded demonstrations, but carefully design the model
class to counter the compounding error phenomenon. Our ``memory-consistent
neural network'' (MCNN) outputs are hard-constrained to stay within clearly
specified permissible regions anchored to prototypical ``memory'' training
samples. We provide a guaranteed upper bound for the sub-optimality gap induced
by MCNN policies. Using MCNNs on 9 imitation learning tasks, with MLP,
Transformer, and Diffusion backbones, spanning dexterous robotic manipulation
and driving, proprioceptive inputs and visual inputs, and varying sizes and
types of demonstration data, we find large and consistent gains in performance,
validating that MCNNs are better-suited than vanilla deep neural networks for
imitation learning applications. Website:
https://sites.google.com/view/mcnn-imitation
</p></li>
</ul>

<h3>Title: DockGame: Cooperative Games for Multimeric Rigid Protein Docking. (arXiv:2310.06177v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.06177">http://arxiv.org/abs/2310.06177</a></li>
<li>Code URL: https://github.com/vsomnath/dockgame</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.06177]] DockGame: Cooperative Games for Multimeric Rigid Protein Docking(http://arxiv.org/abs/2310.06177)</code></li>
<li>Summary: <p>Protein interactions and assembly formation are fundamental to most
biological processes. Predicting the assembly structure from constituent
proteins -- referred to as the protein docking task -- is thus a crucial step
in protein design applications. Most traditional and deep learning methods for
docking have focused mainly on binary docking, following either a search-based,
regression-based, or generative modeling paradigm. In this paper, we focus on
the less-studied multimeric (i.e., two or more proteins) docking problem. We
introduce DockGame, a novel game-theoretic framework for docking -- we view
protein docking as a cooperative game between proteins, where the final
assembly structure(s) constitute stable equilibria w.r.t. the underlying game
potential. Since we do not have access to the true potential, we consider two
approaches - i) learning a surrogate game potential guided by physics-based
energy functions and computing equilibria by simultaneous gradient updates, and
ii) sampling from the Gibbs distribution of the true potential by learning a
diffusion generative model over the action spaces (rotations and translations)
of all proteins. Empirically, on the Docking Benchmark 5.5 (DB5.5) dataset,
DockGame has much faster runtimes than traditional docking methods, can
generate multiple plausible assembly structures, and achieves comparable
performance to existing binary docking baselines, despite solving the harder
task of coordinating multiple protein chains.
</p></li>
</ul>

<h3>Title: Boosting Continuous Control with Consistency Policy. (arXiv:2310.06343v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.06343">http://arxiv.org/abs/2310.06343</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.06343]] Boosting Continuous Control with Consistency Policy(http://arxiv.org/abs/2310.06343)</code></li>
<li>Summary: <p>Due to its training stability and strong expression, the diffusion model has
attracted considerable attention in offline reinforcement learning. However,
several challenges have also come with it: 1) The demand for a large number of
diffusion steps makes the diffusion-model-based methods time inefficient and
limits their applications in real-time control; 2) How to achieve policy
improvement with accurate guidance for diffusion model-based policy is still an
open problem. Inspired by the consistency model, we propose a novel
time-efficiency method named Consistency Policy with Q-Learning (CPQL), which
derives action from noise by a single step. By establishing a mapping from the
reverse diffusion trajectories to the desired policy, we simultaneously address
the issues of time efficiency and inaccurate guidance when updating diffusion
model-based policy with the learned Q-function. We demonstrate that CPQL can
achieve policy improvement with accurate guidance for offline reinforcement
learning, and can be seamlessly extended for online RL tasks. Experimental
results indicate that CPQL achieves new state-of-the-art performance on 11
offline and 21 online tasks, significantly improving inference speed by nearly
45 times compared to Diffusion-QL. We will release our code later.
</p></li>
</ul>

<h3>Title: Advective Diffusion Transformers for Topological Generalization in Graph Learning. (arXiv:2310.06417v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.06417">http://arxiv.org/abs/2310.06417</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.06417]] Advective Diffusion Transformers for Topological Generalization in Graph Learning(http://arxiv.org/abs/2310.06417)</code></li>
<li>Summary: <p>Graph diffusion equations are intimately related to graph neural networks
(GNNs) and have recently attracted attention as a principled framework for
analyzing GNN dynamics, formalizing their expressive power, and justifying
architectural choices. One key open questions in graph learning is the
generalization capabilities of GNNs. A major limitation of current approaches
hinges on the assumption that the graph topologies in the training and test
sets come from the same distribution. In this paper, we make steps towards
understanding the generalization of GNNs by exploring how graph diffusion
equations extrapolate and generalize in the presence of varying graph
topologies. We first show deficiencies in the generalization capability of
existing models built upon local diffusion on graphs, stemming from the
exponential sensitivity to topology variation. Our subsequent analysis reveals
the promise of non-local diffusion, which advocates for feature propagation
over fully-connected latent graphs, under the assumption of a specific
data-generating condition. In addition to these findings, we propose a novel
graph encoder backbone, Advective Diffusion Transformer (ADiT), inspired by
advective graph diffusion equations that have a closed-form solution backed up
with theoretical guarantees of desired generalization under topological
distribution shifts. The new model, functioning as a versatile graph
Transformer, demonstrates superior performance across a wide range of graph
learning tasks.
</p></li>
</ul>

<h2>self-supervised</h2>
<h3>Title: Quantile-based Maximum Likelihood Training for Outlier Detection. (arXiv:2310.06085v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.06085">http://arxiv.org/abs/2310.06085</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.06085]] Quantile-based Maximum Likelihood Training for Outlier Detection(http://arxiv.org/abs/2310.06085)</code></li>
<li>Summary: <p>Discriminative learning effectively predicts true object class for image
classification. However, it often results in false positives for outliers,
posing critical concerns in applications like autonomous driving and video
surveillance systems. Previous attempts to address this challenge involved
training image classifiers through contrastive learning using actual outlier
data or synthesizing outliers for self-supervised learning. Furthermore,
unsupervised generative modeling of inliers in pixel space has shown limited
success for outlier detection. In this work, we introduce a quantile-based
maximum likelihood objective for learning the inlier distribution to improve
the outlier separation during inference. Our approach fits a normalizing flow
to pre-trained discriminative features and detects the outliers according to
the evaluated log-likelihood. The experimental evaluation demonstrates the
effectiveness of our method as it surpasses the performance of the
state-of-the-art unsupervised methods for outlier detection. The results are
also competitive compared with a recent self-supervised approach for outlier
detection. Our work allows to reduce dependency on well-sampled negative
training data, which is especially important for domains like medical
diagnostics or remote sensing.
</p></li>
</ul>

<h3>Title: DiPS: Discriminative Pseudo-Label Sampling with Self-Supervised Transformers for Weakly Supervised Object Localization. (arXiv:2310.06196v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.06196">http://arxiv.org/abs/2310.06196</a></li>
<li>Code URL: https://github.com/shakeebmurtaza/dips</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.06196]] DiPS: Discriminative Pseudo-Label Sampling with Self-Supervised Transformers for Weakly Supervised Object Localization(http://arxiv.org/abs/2310.06196)</code></li>
<li>Summary: <p>Self-supervised vision transformers (SSTs) have shown great potential to
yield rich localization maps that highlight different objects in an image.
However, these maps remain class-agnostic since the model is unsupervised. They
often tend to decompose the image into multiple maps containing different
objects while being unable to distinguish the object of interest from
background noise objects. In this paper, Discriminative Pseudo-label Sampling
(DiPS) is introduced to leverage these class-agnostic maps for
weakly-supervised object localization (WSOL), where only image-class labels are
available. Given multiple attention maps, DiPS relies on a pre-trained
classifier to identify the most discriminative regions of each attention map.
This ensures that the selected ROIs cover the correct image object while
discarding the background ones, and, as such, provides a rich pool of diverse
and discriminative proposals to cover different parts of the object.
Subsequently, these proposals are used as pseudo-labels to train our new
transformer-based WSOL model designed to perform classification and
localization tasks. Unlike standard WSOL methods, DiPS optimizes performance in
both tasks by using a transformer encoder and a dedicated output head for each
task, each trained using dedicated loss functions. To avoid overfitting a
single proposal and promote better object coverage, a single proposal is
randomly selected among the top ones for a training image at each training
step. Experimental results on the challenging CUB, ILSVRC, OpenImages, and
TelDrone datasets indicate that our architecture, in combination with our
transformer-based proposals, can yield better localization performance than
state-of-the-art methods.
</p></li>
</ul>

<h3>Title: Local Style Awareness of Font Images. (arXiv:2310.06337v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.06337">http://arxiv.org/abs/2310.06337</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.06337]] Local Style Awareness of Font Images(http://arxiv.org/abs/2310.06337)</code></li>
<li>Summary: <p>When we compare fonts, we often pay attention to styles of local parts, such
as serifs and curvatures. This paper proposes an attention mechanism to find
important local parts. The local parts with larger attention are then
considered important. The proposed mechanism can be trained in a
quasi-self-supervised manner that requires no manual annotation other than
knowing that a set of character images is from the same font, such as
Helvetica. After confirming that the trained attention mechanism can find
style-relevant local parts, we utilize the resulting attention for local
style-aware font generation. Specifically, we design a new reconstruction loss
function to put more weight on the local parts with larger attention for
generating character images with more accurate style realization. This loss
function has the merit of applicability to various font generation models. Our
experimental results show that the proposed loss function improves the quality
of generated character images by several few-shot font generation models.
</p></li>
</ul>

<h3>Title: Leveraging Multilingual Self-Supervised Pretrained Models for Sequence-to-Sequence End-to-End Spoken Language Understanding. (arXiv:2310.06103v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.06103">http://arxiv.org/abs/2310.06103</a></li>
<li>Code URL: https://github.com/digitalphonetics/multilingual-seq2seq-slu</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.06103]] Leveraging Multilingual Self-Supervised Pretrained Models for Sequence-to-Sequence End-to-End Spoken Language Understanding(http://arxiv.org/abs/2310.06103)</code></li>
<li>Summary: <p>A number of methods have been proposed for End-to-End Spoken Language
Understanding (E2E-SLU) using pretrained models, however their evaluation often
lacks multilingual setup and tasks that require prediction of lexical fillers,
such as slot filling. In this work, we propose a unified method that integrates
multilingual pretrained speech and text models and performs E2E-SLU on six
datasets in four languages in a generative manner, including the prediction of
lexical fillers. We investigate how the proposed method can be improved by
pretraining on widely available speech recognition data using several training
objectives. Pretraining on 7000 hours of multilingual data allows us to
outperform the state-of-the-art ultimately on two SLU datasets and partly on
two more SLU datasets. Finally, we examine the cross-lingual capabilities of
the proposed model and improve on the best known result on the
PortMEDIA-Language dataset by almost half, achieving a Concept/Value Error Rate
of 23.65%.
</p></li>
</ul>

<h3>Title: Exploit the antenna response consistency to define the alignment criteria for CSI data. (arXiv:2310.06328v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.06328">http://arxiv.org/abs/2310.06328</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.06328]] Exploit the antenna response consistency to define the alignment criteria for CSI data(http://arxiv.org/abs/2310.06328)</code></li>
<li>Summary: <p>Self-supervised learning (SSL) for WiFi-based human activity recognition
(HAR) holds great promise due to its ability to address the challenge of
insufficient labeled data. However, directly transplanting SSL algorithms,
especially contrastive learning, originally designed for other domains to CSI
data, often fails to achieve the expected performance. We attribute this issue
to the inappropriate alignment criteria, which disrupt the semantic distance
consistency between the feature space and the input space. To address this
challenge, we introduce \textbf{A}netenna \textbf{R}esponse
\textbf{C}onsistency (ARC) as a solution to define proper alignment criteria.
ARC is designed to retain semantic information from the input space while
introducing robustness to real-world noise. We analyze ARC from the perspective
of CSI data structure, demonstrating that its optimal solution leads to a
direct mapping from input CSI data to action vectors in the feature map.
Furthermore, we provide extensive experimental evidence to validate the
effectiveness of ARC in improving the performance of self-supervised learning
for WiFi-based HAR.
</p></li>
</ul>

<h3>Title: TANGO: Time-Reversal Latent GraphODE for Multi-Agent Dynamical Systems. (arXiv:2310.06427v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.06427">http://arxiv.org/abs/2310.06427</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.06427]] TANGO: Time-Reversal Latent GraphODE for Multi-Agent Dynamical Systems(http://arxiv.org/abs/2310.06427)</code></li>
<li>Summary: <p>Learning complex multi-agent system dynamics from data is crucial across many
domains, such as in physical simulations and material modeling. Extended from
purely data-driven approaches, existing physics-informed approaches such as
Hamiltonian Neural Network strictly follow energy conservation law to introduce
inductive bias, making their learning more sample efficiently. However, many
real-world systems do not strictly conserve energy, such as spring systems with
frictions. Recognizing this, we turn our attention to a broader physical
principle: Time-Reversal Symmetry, which depicts that the dynamics of a system
shall remain invariant when traversed back over time. It still helps to
preserve energies for conservative systems and in the meanwhile, serves as a
strong inductive bias for non-conservative, reversible systems. To inject such
inductive bias, in this paper, we propose a simple-yet-effective
self-supervised regularization term as a soft constraint that aligns the
forward and backward trajectories predicted by a continuous graph neural
network-based ordinary differential equation (GraphODE). It effectively imposes
time-reversal symmetry to enable more accurate model predictions across a wider
range of dynamical systems under classical mechanics. In addition, we further
provide theoretical analysis to show that our regularization essentially
minimizes higher-order Taylor expansion terms during the ODE integration steps,
which enables our model to be more noise-tolerant and even applicable to
irreversible systems. Experimental results on a variety of physical systems
demonstrate the effectiveness of our proposed method. Particularly, it achieves
an MSE improvement of 11.5 % on a challenging chaotic triple-pendulum systems.
</p></li>
</ul>

<h2>foundation model</h2>
<h2>generative</h2>
<h3>Title: LLM for SoC Security: A Paradigm Shift. (arXiv:2310.06046v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.06046">http://arxiv.org/abs/2310.06046</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.06046]] LLM for SoC Security: A Paradigm Shift(http://arxiv.org/abs/2310.06046)</code></li>
<li>Summary: <p>As the ubiquity and complexity of system-on-chip (SoC) designs increase
across electronic devices, the task of incorporating security into an SoC
design flow poses significant challenges. Existing security solutions are
inadequate to provide effective verification of modern SoC designs due to their
limitations in scalability, comprehensiveness, and adaptability. On the other
hand, Large Language Models (LLMs) are celebrated for their remarkable success
in natural language understanding, advanced reasoning, and program synthesis
tasks. Recognizing an opportunity, our research delves into leveraging the
emergent capabilities of Generative Pre-trained Transformers (GPTs) to address
the existing gaps in SoC security, aiming for a more efficient, scalable, and
adaptable methodology. By integrating LLMs into the SoC security verification
paradigm, we open a new frontier of possibilities and challenges to ensure the
security of increasingly complex SoCs. This paper offers an in-depth analysis
of existing works, showcases practical case studies, demonstrates comprehensive
experiments, and provides useful promoting guidelines. We also present the
achievements, prospects, and challenges of employing LLM in different SoC
security verification tasks.
</p></li>
</ul>

<h3>Title: Get the gist? Using large language models for few-shot decontextualization. (arXiv:2310.06254v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.06254">http://arxiv.org/abs/2310.06254</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.06254]] Get the gist? Using large language models for few-shot decontextualization(http://arxiv.org/abs/2310.06254)</code></li>
<li>Summary: <p>In many NLP applications that involve interpreting sentences within a rich
context -- for instance, information retrieval systems or dialogue systems --
it is desirable to be able to preserve the sentence in a form that can be
readily understood without context, for later reuse -- a process known as
``decontextualization''. While previous work demonstrated that generative
Seq2Seq models could effectively perform decontextualization after being
fine-tuned on a specific dataset, this approach requires expensive human
annotations and may not transfer to other domains. We propose a few-shot method
of decontextualization using a large language model, and present preliminary
results showing that this method achieves viable performance on multiple
domains using only a small set of examples.
</p></li>
</ul>

<h3>Title: Towards Mitigating Hallucination in Large Language Models via Self-Reflection. (arXiv:2310.06271v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.06271">http://arxiv.org/abs/2310.06271</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.06271]] Towards Mitigating Hallucination in Large Language Models via Self-Reflection(http://arxiv.org/abs/2310.06271)</code></li>
<li>Summary: <p>Large language models (LLMs) have shown promise for generative and
knowledge-intensive tasks including question-answering (QA) tasks. However, the
practical deployment still faces challenges, notably the issue of
"hallucination", where models generate plausible-sounding but unfaithful or
nonsensical information. This issue becomes particularly critical in the
medical domain due to the uncommon professional concepts and potential social
risks involved. This paper analyses the phenomenon of hallucination in medical
generative QA systems using widely adopted LLMs and datasets. Our investigation
centers on the identification and comprehension of common problematic answers,
with a specific emphasis on hallucination. To tackle this challenge, we present
an interactive self-reflection methodology that incorporates knowledge
acquisition and answer generation. Through this feedback process, our approach
steadily enhances the factuality, consistency, and entailment of the generated
answers. Consequently, we harness the interactivity and multitasking ability of
LLMs and produce progressively more precise and accurate answers. Experimental
results on both automatic and human evaluation demonstrate the superiority of
our approach in hallucination reduction compared to baselines.
</p></li>
</ul>

<h3>Title: Hexa: Self-Improving for Knowledge-Grounded Dialogue System. (arXiv:2310.06404v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.06404">http://arxiv.org/abs/2310.06404</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.06404]] Hexa: Self-Improving for Knowledge-Grounded Dialogue System(http://arxiv.org/abs/2310.06404)</code></li>
<li>Summary: <p>A common practice in knowledge-grounded dialogue generation is to explicitly
utilize intermediate steps (e.g., web-search, memory retrieval) with modular
approaches. However, data for such steps are often inaccessible compared to
those of dialogue responses as they are unobservable in an ordinary dialogue.
To fill in the absence of these data, we develop a self-improving method to
improve the generative performances of intermediate steps without the ground
truth data. In particular, we propose a novel bootstrapping scheme with a
guided prompt and a modified loss function to enhance the diversity of
appropriate self-generated responses. Through experiments on various benchmark
datasets, we empirically demonstrate that our method successfully leverages a
self-improving mechanism in generating intermediate and final responses and
improves the performances on the task of knowledge-grounded dialogue
generation.
</p></li>
</ul>

<h3>Title: Whispering LLaMA: A Cross-Modal Generative Error Correction Framework for Speech Recognition. (arXiv:2310.06434v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.06434">http://arxiv.org/abs/2310.06434</a></li>
<li>Code URL: https://github.com/srijith-rkr/whispering-llama</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.06434]] Whispering LLaMA: A Cross-Modal Generative Error Correction Framework for Speech Recognition(http://arxiv.org/abs/2310.06434)</code></li>
<li>Summary: <p>We introduce a new cross-modal fusion technique designed for generative error
correction in automatic speech recognition (ASR). Our methodology leverages
both acoustic information and external linguistic representations to generate
accurate speech transcription contexts. This marks a step towards a fresh
paradigm in generative error correction within the realm of n-best hypotheses.
Unlike the existing ranking-based rescoring methods, our approach adeptly uses
distinct initialization techniques and parameter-efficient algorithms to boost
ASR performance derived from pre-trained speech and text models. Through
evaluation across diverse ASR datasets, we evaluate the stability and
reproducibility of our fusion technique, demonstrating its improved word error
rate relative (WERR) performance in comparison to n-best hypotheses by
relatively 37.66%. To encourage future research, we have made our code and
pre-trained models open source at
https://github.com/Srijith-rkr/Whispering-LLaMA.
</p></li>
</ul>

<h3>Title: Generative ensemble deep learning severe weather prediction from a deterministic convection-allowing model. (arXiv:2310.06045v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.06045">http://arxiv.org/abs/2310.06045</a></li>
<li>Code URL: https://github.com/yingkaisha/severe_weather_cgan</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.06045]] Generative ensemble deep learning severe weather prediction from a deterministic convection-allowing model(http://arxiv.org/abs/2310.06045)</code></li>
<li>Summary: <p>An ensemble post-processing method is developed for the probabilistic
prediction of severe weather (tornadoes, hail, and wind gusts) over the
conterminous United States (CONUS). The method combines conditional generative
adversarial networks (CGANs), a type of deep generative model, with a
convolutional neural network (CNN) to post-process convection-allowing model
(CAM) forecasts. The CGANs are designed to create synthetic ensemble members
from deterministic CAM forecasts, and their outputs are processed by the CNN to
estimate the probability of severe weather. The method is tested using
High-Resolution Rapid Refresh (HRRR) 1--24 hr forecasts as inputs and Storm
Prediction Center (SPC) severe weather reports as targets. The method produced
skillful predictions with up to 20% Brier Skill Score (BSS) increases compared
to other neural-network-based reference methods using a testing dataset of HRRR
forecasts in 2021. For the evaluation of uncertainty quantification, the method
is overconfident but produces meaningful ensemble spreads that can distinguish
good and bad forecasts. The quality of CGAN outputs is also evaluated. Results
show that the CGAN outputs behave similarly to a numerical ensemble; they
preserved the inter-variable correlations and the contribution of influential
predictors as in the original HRRR forecasts. This work provides a novel
approach to post-process CAM output using neural networks that can be applied
to severe weather prediction.
</p></li>
</ul>

<h3>Title: When is Agnostic Reinforcement Learning Statistically Tractable?. (arXiv:2310.06113v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.06113">http://arxiv.org/abs/2310.06113</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.06113]] When is Agnostic Reinforcement Learning Statistically Tractable?(http://arxiv.org/abs/2310.06113)</code></li>
<li>Summary: <p>We study the problem of agnostic PAC reinforcement learning (RL): given a
policy class $\Pi$, how many rounds of interaction with an unknown MDP (with a
potentially large state and action space) are required to learn an
$\epsilon$-suboptimal policy with respect to $\Pi$? Towards that end, we
introduce a new complexity measure, called the \emph{spanning capacity}, that
depends solely on the set $\Pi$ and is independent of the MDP dynamics. With a
generative model, we show that for any policy class $\Pi$, bounded spanning
capacity characterizes PAC learnability. However, for online RL, the situation
is more subtle. We show there exists a policy class $\Pi$ with a bounded
spanning capacity that requires a superpolynomial number of samples to learn.
This reveals a surprising separation for agnostic learnability between
generative access and online access models (as well as between
deterministic/stochastic MDPs under online access). On the positive side, we
identify an additional \emph{sunflower} structure, which in conjunction with
bounded spanning capacity enables statistically efficient online RL via a new
algorithm called POPLER, which takes inspiration from classical importance
sampling methods as well as techniques for reachable-state identification and
policy evaluation in reward-free exploration.
</p></li>
</ul>

<h2>anomaly</h2>
<h3>Title: Knowledge Distillation for Anomaly Detection. (arXiv:2310.06047v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.06047">http://arxiv.org/abs/2310.06047</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.06047]] Knowledge Distillation for Anomaly Detection(http://arxiv.org/abs/2310.06047)</code></li>
<li>Summary: <p>Unsupervised deep learning techniques are widely used to identify anomalous
behaviour. The performance of such methods is a product of the amount of
training data and the model size. However, the size is often a limiting factor
for the deployment on resource-constrained devices. We present a novel
procedure based on knowledge distillation for compressing an unsupervised
anomaly detection model into a supervised deployable one and we suggest a set
of techniques to improve the detection sensitivity. Compressed models perform
comparably to their larger counterparts while significantly reducing the size
and memory footprint.
</p></li>
</ul>

<h3>Title: Self-Discriminative Modeling for Anomalous Graph Detection. (arXiv:2310.06261v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.06261">http://arxiv.org/abs/2310.06261</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.06261]] Self-Discriminative Modeling for Anomalous Graph Detection(http://arxiv.org/abs/2310.06261)</code></li>
<li>Summary: <p>This paper studies the problem of detecting anomalous graphs using a machine
learning model trained on only normal graphs, which has many applications in
molecule, biology, and social network data analysis. We present a
self-discriminative modeling framework for anomalous graph detection. The key
idea, mathematically and numerically illustrated, is to learn a discriminator
(classifier) from the given normal graphs together with pseudo-anomalous graphs
generated by a model jointly trained, where we never use any true anomalous
graphs and we hope that the generated pseudo-anomalous graphs interpolate
between normal ones and (real) anomalous ones. Under the framework, we provide
three algorithms with different computational efficiencies and stabilities for
anomalous graph detection. The three algorithms are compared with several
state-of-the-art graph-level anomaly detection baselines on nine popular graph
datasets (four with small size and five with moderate size) and show
significant improvement in terms of AUC. The success of our algorithms stems
from the integration of the discriminative classifier and the well-posed
pseudo-anomalous graphs, which provide new insights for anomaly detection.
Moreover, we investigate our algorithms for large-scale imbalanced graph
datasets. Surprisingly, our algorithms, though fully unsupervised, are able to
significantly outperform supervised learning algorithms of anomalous graph
detection. The corresponding reason is also analyzed.
</p></li>
</ul>

<h2>in-context</h2>
<h3>Title: Selective Demonstrations for Cross-domain Text-to-SQL. (arXiv:2310.06302v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.06302">http://arxiv.org/abs/2310.06302</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.06302]] Selective Demonstrations for Cross-domain Text-to-SQL(http://arxiv.org/abs/2310.06302)</code></li>
<li>Summary: <p>Large language models (LLMs) with in-context learning have demonstrated
impressive generalization capabilities in the cross-domain text-to-SQL task,
without the use of in-domain annotations. However, incorporating in-domain
demonstration examples has been found to greatly enhance LLMs' performance. In
this paper, we delve into the key factors within in-domain examples that
contribute to the improvement and explore whether we can harness these benefits
without relying on in-domain annotations. Based on our findings, we propose a
demonstration selection framework ODIS which utilizes both out-of-domain
examples and synthetically generated in-domain examples to construct
demonstrations. By retrieving demonstrations from hybrid sources, ODIS
leverages the advantages of both, showcasing its effectiveness compared to
baseline methods that rely on a single data source. Furthermore, ODIS
outperforms state-of-the-art approaches on two cross-domain text-to-SQL
datasets, with improvements of 1.1 and 11.8 points in execution accuracy,
respectively.
</p></li>
</ul>

<h3>Title: Jailbreak and Guard Aligned Language Models with Only Few In-Context Demonstrations. (arXiv:2310.06387v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.06387">http://arxiv.org/abs/2310.06387</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.06387]] Jailbreak and Guard Aligned Language Models with Only Few In-Context Demonstrations(http://arxiv.org/abs/2310.06387)</code></li>
<li>Summary: <p>Large Language Models (LLMs) have shown remarkable success in various tasks,
but concerns about their safety and the potential for generating malicious
content have emerged. In this paper, we explore the power of In-Context
Learning (ICL) in manipulating the alignment ability of LLMs. We find that by
providing just few in-context demonstrations without fine-tuning, LLMs can be
manipulated to increase or decrease the probability of jailbreaking, i.e.
answering malicious prompts. Based on these observations, we propose In-Context
Attack (ICA) and In-Context Defense (ICD) methods for jailbreaking and guarding
aligned language model purposes. ICA crafts malicious contexts to guide models
in generating harmful outputs, while ICD enhances model robustness by
demonstrations of rejecting to answer harmful prompts. Our experiments show the
effectiveness of ICA and ICD in increasing or reducing the success rate of
adversarial jailbreaking attacks. Overall, we shed light on the potential of
ICL to influence LLM behavior and provide a new perspective for enhancing the
safety and alignment of LLMs.
</p></li>
</ul>

<h3>Title: Humans and language models diverge when predicting repeating text. (arXiv:2310.06408v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.06408">http://arxiv.org/abs/2310.06408</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.06408]] Humans and language models diverge when predicting repeating text(http://arxiv.org/abs/2310.06408)</code></li>
<li>Summary: <p>Language models that are trained on the next-word prediction task have been
shown to accurately model human behavior in word prediction and reading speed.
In contrast with these findings, we present a scenario in which the performance
of humans and LMs diverges. We collected a dataset of human next-word
predictions for five stimuli that are formed by repeating spans of text. Human
and GPT-2 LM predictions are strongly aligned in the first presentation of a
text span, but their performance quickly diverges when memory (or in-context
learning) begins to play a role. We traced the cause of this divergence to
specific attention heads in a middle layer. Adding a power-law recency bias to
these attention heads yielded a model that performs much more similarly to
humans. We hope that this scenario will spur future work in bringing LMs closer
to human behavior.
</p></li>
</ul>

<button id="copy">Copy All</button>
</article>
<script src="../../javascript/clipboard.min.js"></script>
<script src="../../javascript/clipboard.js"></script>
