<link rel="stylesheet" href="../../css/markdown.css" />
<article class="markdown-body">
<h1>2025-11-06</h1>
<h3>Title: Generative Hints</h3>
<ul>
<li><strong>Authors: </strong>Andy Dimnaku, Abdullah Yusuf Kavranoğlu, Yaser Abu-Mostafa</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.02933">https://arxiv.org/abs/2511.02933</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.02933">https://arxiv.org/pdf/2511.02933</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.02933]] Generative Hints(https://arxiv.org/abs/2511.02933)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>Data augmentation is widely used in vision to introduce variation and mitigate overfitting, through enabling models to learn invariant properties, such as spatial invariance. However, these properties are not fully captured by data augmentation alone, since it attempts to learn the property on transformations of the training data only. We propose generative hints, a training methodology that directly enforces known invariances in the entire input space. Our approach leverages a generative model trained on the training set to approximate the input distribution and generate unlabeled images, which we refer to as virtual examples. These virtual examples are used to enforce functional properties known as hints. In generative hints, although the training dataset is fully labeled, the model is trained in a semi-supervised manner on both the classification and hint objectives, using the unlabeled virtual examples to guide the model in learning the desired hint. Across datasets, architectures, and loss functions, generative hints consistently outperform standard data augmentation when learning the same property. On popular fine-grained visual classification benchmarks, we achieved up to 1.78% top-1 accuracy improvement (0.63% on average) over fine-tuned models with data augmentation and an average performance boost of 1.286% on the CheXpert X-ray dataset.</li>
</ul>

<h3>Title: EvtSlowTV - A Large and Diverse Dataset for Event-Based Depth Estimation</h3>
<ul>
<li><strong>Authors: </strong>Sadiq Layi Macaulay, Nimet Kaygusuz, Simon Hadfield</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI, cs.LG, cs.RO</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.02953">https://arxiv.org/abs/2511.02953</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.02953">https://arxiv.org/pdf/2511.02953</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.02953]] EvtSlowTV - A Large and Diverse Dataset for Event-Based Depth Estimation(https://arxiv.org/abs/2511.02953)</code><input type="text"></li>
<li><strong>Keywords: </strong>self-supervised</a></li>
<li><strong>Abstract: </strong>Event cameras, with their high dynamic range (HDR) and low latency, offer a promising alternative for robust depth estimation in challenging environments. However, many event-based depth estimation approaches are constrained by small-scale annotated datasets, limiting their generalizability to real-world scenarios. To bridge this gap, we introduce EvtSlowTV, a large-scale event camera dataset curated from publicly available YouTube footage, which contains more than 13B events across various environmental conditions and motions, including seasonal hiking, flying, scenic driving, and underwater exploration. EvtSlowTV is an order of magnitude larger than existing event datasets, providing an unconstrained, naturalistic setting for event-based depth learning. This work shows the suitability of EvtSlowTV for a self-supervised learning framework to capitalise on the HDR potential of raw event streams. We further demonstrate that training with EvtSlowTV enhances the model's ability to generalise to complex scenes and motions. Our approach removes the need for frame-based annotations and preserves the asynchronous nature of event data.</li>
</ul>

<h3>Title: Inference-Time Personalized Alignment with a Few User Preference Queries</h3>
<ul>
<li><strong>Authors: </strong>Victor-Alexandru Pădurean, Parameswaran Kamalaruban, Nachiket Kotalwar, Alkis Gotovos, Adish Singla</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.02966">https://arxiv.org/abs/2511.02966</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.02966">https://arxiv.org/pdf/2511.02966</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.02966]] Inference-Time Personalized Alignment with a Few User Preference Queries(https://arxiv.org/abs/2511.02966)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>We study the problem of aligning a generative model's response with a user's preferences. Recent works have proposed several different formulations for personalized alignment; however, they either require a large amount of user preference queries or require that the preference be explicitly specified as a text input. In this paper, we propose a novel inference-time personalized alignment method, UserAlign, that elicits the user's preferences with a few queries as pairwise response comparisons. In particular, UserAlign builds on the theoretical framework of best-arm identification in logistic bandits and selects a personalized response from a fixed pool of the model's generated responses. The key idea is to consider the user's feedback consistent and noise-free, and incorporate it into the theoretical framework to identify the best response quickly. Experimental results across several tasks, involving personalized text and image generation, showcase the effectiveness of UserAlign in achieving personalized alignment.</li>
</ul>

<h3>Title: Learning with less: label-efficient land cover classification at very high spatial resolution using self-supervised deep learning</h3>
<ul>
<li><strong>Authors: </strong>Dakota Hester, Vitor S. Martins, Lucas B. Ferreira, Thainara M. A. Lima</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.03004">https://arxiv.org/abs/2511.03004</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.03004">https://arxiv.org/pdf/2511.03004</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.03004]] Learning with less: label-efficient land cover classification at very high spatial resolution using self-supervised deep learning(https://arxiv.org/abs/2511.03004)</code><input type="text"></li>
<li><strong>Keywords: </strong>self-supervised</a></li>
<li><strong>Abstract: </strong>Deep learning semantic segmentation methods have shown promising performance for very high 1-m resolution land cover classification, but the challenge of collecting large volumes of representative training data creates a significant barrier to widespread adoption of such models for meter-scale land cover mapping over large areas. In this study, we present a novel label-efficient approach for statewide 1-m land cover classification using only 1,000 annotated reference image patches with self-supervised deep learning. We use the "Bootstrap Your Own Latent" pre-training strategy with a large amount of unlabeled color-infrared aerial images (377,921 256x256 1-m pixel patches) to pre-train a ResNet-101 convolutional encoder. The learned encoder weights were subsequently transferred into multiple deep semantic segmentation architectures (FCN, U-Net, Attention U-Net, DeepLabV3+, UPerNet, PAN), which were then fine-tuned using very small training dataset sizes with cross-validation (250, 500, 750 patches). Among the fine-tuned models, we obtained the 87.14% overall accuracy and 75.58% macro F1 score using an ensemble of the best performing U-Net models for comprehensive 1-m, 8-class land cover mapping, covering more than 123 billion pixels over the state of Mississippi, USA. Detailed qualitative and quantitative analysis revealed accurate mapping of open water and forested areas, while highlighting challenges in accurate delineation between cropland, herbaceous, and barren land cover types. These results show that self-supervised learning is an effective strategy for reducing the need for large volumes of manually annotated data, directly addressing a major limitation to high spatial resolution land cover mapping at scale.</li>
</ul>

<h3>Title: A Foundation Model for Brain MRI with Dynamic Modality Integration</h3>
<ul>
<li><strong>Authors: </strong>Minh Sao Khue Luu, Bair N. Tuchinov</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.03014">https://arxiv.org/abs/2511.03014</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.03014">https://arxiv.org/pdf/2511.03014</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.03014]] A Foundation Model for Brain MRI with Dynamic Modality Integration(https://arxiv.org/abs/2511.03014)</code><input type="text"></li>
<li><strong>Keywords: </strong>self-supervised, foundation model</a></li>
<li><strong>Abstract: </strong>We present a foundation model for brain MRI that can work with different combinations of imaging sequences. The model uses one encoder with learnable modality embeddings, conditional layer normalization, and a masked autoencoding objective that accounts for missing modalities. A variance-covariance regularizer is applied to stabilize feature learning and improve representation diversity. This design removes the need for separate models for each modality and allows the network to adapt when some sequences are missing or unseen. It is trained on about 60,000 multi-center MRIs using self-supervised reconstruction and modality imputation to learn flexible representations. A learnable modality embedding guides feature extraction so the encoder can adjust to different inputs. We describe our planned evaluation on brain tumor and multiple sclerosis segmentation, as well as lesion classification, under various modality settings. Preliminary results show that the method works feasibly, and further experiments are planned to study its performance in more detail. All code and pretrained models are available at this https URL</li>
</ul>

<h3>Title: Discrete Bayesian Sample Inference for Graph Generation</h3>
<ul>
<li><strong>Authors: </strong>Ole Petersen, Marcel Kollovieh, Marten Lienen, Stephan Günnemann</a></li>
<li><strong>Subjects: </strong>cs.LG, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.03015">https://arxiv.org/abs/2511.03015</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.03015">https://arxiv.org/pdf/2511.03015</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.03015]] Discrete Bayesian Sample Inference for Graph Generation(https://arxiv.org/abs/2511.03015)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, generative</a></li>
<li><strong>Abstract: </strong>Generating graph-structured data is crucial in applications such as molecular generation, knowledge graphs, and network analysis. However, their discrete, unordered nature makes them difficult for traditional generative models, leading to the rise of discrete diffusion and flow matching models. In this work, we introduce GraphBSI, a novel one-shot graph generative model based on Bayesian Sample Inference (BSI). Instead of evolving samples directly, GraphBSI iteratively refines a belief over graphs in the continuous space of distribution parameters, naturally handling discrete structures. Further, we state BSI as a stochastic differential equation (SDE) and derive a noise-controlled family of SDEs that preserves the marginal distributions via an approximation of the score function. Our theoretical analysis further reveals the connection to Bayesian Flow Networks and Diffusion models. Finally, in our empirical evaluation, we demonstrate state-of-the-art performance on molecular and synthetic graph generation, outperforming existing one-shot graph generative models on the standard benchmarks Moses and GuacaMol.</li>
</ul>

<h3>Title: Leveraging Discrete Function Decomposability for Scientific Design</h3>
<ul>
<li><strong>Authors: </strong>James C. Bowden, Sergey Levine, Jennifer Listgarten</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.03032">https://arxiv.org/abs/2511.03032</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.03032">https://arxiv.org/pdf/2511.03032</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.03032]] Leveraging Discrete Function Decomposability for Scientific Design(https://arxiv.org/abs/2511.03032)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>In the era of AI-driven science and engineering, we often want to design discrete objects in silico according to user-specified properties. For example, we may wish to design a protein to bind its target, arrange components within a circuit to minimize latency, or find materials with certain properties. Given a property predictive model, in silico design typically involves training a generative model over the design space (e.g., protein sequence space) to concentrate on designs with the desired properties. Distributional optimization -- which can be formalized as an estimation of distribution algorithm or as reinforcement learning policy optimization -- finds the generative model that maximizes an objective function in expectation. Optimizing a distribution over discrete-valued designs is in general challenging because of the combinatorial nature of the design space. However, many property predictors in scientific applications are decomposable in the sense that they can be factorized over design variables in a way that could in principle enable more effective optimization. For example, amino acids at a catalytic site of a protein may only loosely interact with amino acids of the rest of the protein to achieve maximal catalytic activity. Current distributional optimization algorithms are unable to make use of such decomposability structure. Herein, we propose and demonstrate use of a new distributional optimization algorithm, Decomposition-Aware Distributional Optimization (DADO), that can leverage any decomposability defined by a junction tree on the design variables, to make optimization more efficient. At its core, DADO employs a soft-factorized "search distribution" -- a learned generative model -- for efficient navigation of the search space, invoking graph message-passing to coordinate optimization across linked factors.</li>
</ul>

<h3>Title: Data-Efficient Adaptation and a Novel Evaluation Method for Aspect-based Sentiment Analysis</h3>
<ul>
<li><strong>Authors: </strong>Yan Cathy Hua, Paul Denny, Jörg Wicker, Katerina Taškova</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.03034">https://arxiv.org/abs/2511.03034</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.03034">https://arxiv.org/pdf/2511.03034</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.03034]] Data-Efficient Adaptation and a Novel Evaluation Method for Aspect-based Sentiment Analysis(https://arxiv.org/abs/2511.03034)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative, in-context</a></li>
<li><strong>Abstract: </strong>Aspect-based Sentiment Analysis (ABSA) is a fine-grained opinion mining approach that identifies and classifies opinions associated with specific entities (aspects) or their categories within a sentence. Despite its rapid growth and broad potential, ABSA research and resources remain concentrated in commercial domains, leaving analytical needs unmet in high-demand yet low-resource areas such as education and healthcare. Domain adaptation challenges and most existing methods' reliance on resource-intensive in-training knowledge injection further hinder progress in these areas. Moreover, traditional evaluation methods based on exact matches are overly rigid for ABSA tasks, penalising any boundary variations which may misrepresent the performance of generative models. This work addresses these gaps through three contributions: 1) We propose a novel evaluation method, Flexible Text Similarity Matching and Optimal Bipartite Pairing (FTS-OBP), which accommodates realistic extraction boundary variations while maintaining strong correlation with traditional metrics and offering fine-grained diagnostics. 2) We present the first ABSA study of small decoder-only generative language models (SLMs; <7B parameters), examining resource lower bounds via a case study in education review ABSA. We systematically explore data-free (in-context learning and weight merging) and data-light fine-tuning methods, and propose a multitask fine-tuning strategy that significantly enhances SLM performance, enabling 1.5-3.8 B models to surpass proprietary large models and approach benchmark results with only 200-1,000 examples on a single GPU. 3) We release the first public set of education review ABSA resources to support future research in low-resource domains.</li>
</ul>

<h3>Title: Sparse, self-organizing ensembles of local kernels detect rare statistical anomalies</h3>
<ul>
<li><strong>Authors: </strong>Gaia Grosso, Sai Sumedh R. Hindupur, Thomas Fel, Samuel Bright-Thonney, Philip Harris, Demba Ba</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.03095">https://arxiv.org/abs/2511.03095</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.03095">https://arxiv.org/pdf/2511.03095</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.03095]] Sparse, self-organizing ensembles of local kernels detect rare statistical anomalies(https://arxiv.org/abs/2511.03095)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative, anomaly</a></li>
<li><strong>Abstract: </strong>Modern artificial intelligence has revolutionized our ability to extract rich and versatile data representations across scientific disciplines. Yet, the statistical properties of these representations remain poorly controlled, causing misspecified anomaly detection (AD) methods to falter. Weak or rare signals can remain hidden within the apparent regularity of normal data, creating a gap in our ability to detect and interpret anomalies. We examine this gap and identify a set of structural desiderata for detection methods operating under minimal prior information: sparsity, to enforce parsimony; locality, to preserve geometric sensitivity; and competition, to promote efficient allocation of model capacity. These principles define a class of self-organizing local kernels that adaptively partition the representation space around regions of statistical imbalance. As an instantiation of these principles, we introduce SparKer, a sparse ensemble of Gaussian kernels trained within a semi-supervised Neyman--Pearson framework to locally model the likelihood ratio between a sample that may contain anomalies and a nominal, anomaly-free reference. We provide theoretical insights into the mechanisms that drive detection and self-organization in the proposed model, and demonstrate the effectiveness of this approach on realistic high-dimensional problems of scientific discovery, open-world novelty detection, intrusion detection, and generative-model validation. Our applications span both the natural- and computer-science domains. We demonstrate that ensembles containing only a handful of kernels can identify statistically significant anomalous locations within representation spaces of thousands of dimensions, underscoring both the interpretability, efficiency and scalability of the proposed approach.</li>
</ul>

<h3>Title: Scaling Multi-Agent Environment Co-Design with Diffusion Models</h3>
<ul>
<li><strong>Authors: </strong>Hao Xiang Li, Michael Amir, Amanda Prorok</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.MA</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.03100">https://arxiv.org/abs/2511.03100</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.03100">https://arxiv.org/pdf/2511.03100</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.03100]] Scaling Multi-Agent Environment Co-Design with Diffusion Models(https://arxiv.org/abs/2511.03100)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>The agent-environment co-design paradigm jointly optimises agent policies and environment configurations in search of improved system performance. With application domains ranging from warehouse logistics to windfarm management, co-design promises to fundamentally change how we deploy multi-agent systems. However, current co-design methods struggle to scale. They collapse under high-dimensional environment design spaces and suffer from sample inefficiency when addressing moving targets inherent to joint optimisation. We address these challenges by developing Diffusion Co-Design (DiCoDe), a scalable and sample-efficient co-design framework pushing co-design towards practically relevant settings. DiCoDe incorporates two core innovations. First, we introduce Projected Universal Guidance (PUG), a sampling technique that enables DiCoDe to explore a distribution of reward-maximising environments while satisfying hard constraints such as spatial separation between obstacles. Second, we devise a critic distillation mechanism to share knowledge from the reinforcement learning critic, ensuring that the guided diffusion model adapts to evolving agent policies using a dense and up-to-date learning signal. Together, these improvements lead to superior environment-policy pairs when validated on challenging multi-agent environment co-design benchmarks including warehouse automation, multi-agent pathfinding and wind farm optimisation. Our method consistently exceeds the state-of-the-art, achieving, for example, 39% higher rewards in the warehouse setting with 66% fewer simulation samples. This sets a new standard in agent-environment co-design, and is a stepping stone towards reaping the rewards of co-design in real world domains.</li>
</ul>

<h3>Title: FP-AbDiff: Improving Score-based Antibody Design by Capturing Nonequilibrium Dynamics through the Underlying Fokker-Planck Equation</h3>
<ul>
<li><strong>Authors: </strong>Jiameng Chen, Yida Xiong, Kun Li, Hongzhi Zhang, Xiantao Cai, Wenbin Hu, Jia Wu</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, q-bio.QM</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.03113">https://arxiv.org/abs/2511.03113</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.03113">https://arxiv.org/pdf/2511.03113</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.03113]] FP-AbDiff: Improving Score-based Antibody Design by Capturing Nonequilibrium Dynamics through the Underlying Fokker-Planck Equation(https://arxiv.org/abs/2511.03113)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, generative</a></li>
<li><strong>Abstract: </strong>Computational antibody design holds immense promise for therapeutic discovery, yet existing generative models are fundamentally limited by two core challenges: (i) a lack of dynamical consistency, which yields physically implausible structures, and (ii) poor generalization due to data scarcity and structural bias. We introduce FP-AbDiff, the first antibody generator to enforce Fokker-Planck Equation (FPE) physics along the entire generative trajectory. Our method minimizes a novel FPE residual loss over the mixed manifold of CDR geometries (R^3 x SO(3)), compelling locally-learned denoising scores to assemble into a globally coherent probability flow. This physics-informed regularizer is synergistically integrated with deep biological priors within a state-of-the-art SE(3)-equivariant diffusion framework. Rigorous evaluation on the RAbD benchmark confirms that FP-AbDiff establishes a new state-of-the-art. In de novo CDR-H3 design, it achieves a mean Root Mean Square Deviation of 0.99 Å when superposing on the variable region, a 25% improvement over the previous state-of-the-art model, AbX, and the highest reported Contact Amino Acid Recovery of 39.91%. This superiority is underscored in the more challenging six-CDR co-design task, where our model delivers consistently superior geometric precision, cutting the average full-chain Root Mean Square Deviation by ~15%, and crucially, achieves the highest full-chain Amino Acid Recovery on the functionally dominant CDR-H3 loop (45.67%). By aligning generative dynamics with physical laws, FP-AbDiff enhances robustness and generalizability, establishing a principled approach for physically faithful and functionally viable antibody design.</li>
</ul>

<h3>Title: An Augmentation Overlap Theory of Contrastive Learning</h3>
<ul>
<li><strong>Authors: </strong>Qi Zhang, Yifei Wang, Yisen Wang</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.03114">https://arxiv.org/abs/2511.03114</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.03114">https://arxiv.org/pdf/2511.03114</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.03114]] An Augmentation Overlap Theory of Contrastive Learning(https://arxiv.org/abs/2511.03114)</code><input type="text"></li>
<li><strong>Keywords: </strong>self-supervised</a></li>
<li><strong>Abstract: </strong>Recently, self-supervised contrastive learning has achieved great success on various tasks. However, its underlying working mechanism is yet unclear. In this paper, we first provide the tightest bounds based on the widely adopted assumption of conditional independence. Further, we relax the conditional independence assumption to a more practical assumption of augmentation overlap and derive the asymptotically closed bounds for the downstream performance. Our proposed augmentation overlap theory hinges on the insight that the support of different intra-class samples will become more overlapped under aggressive data augmentations, thus simply aligning the positive samples (augmented views of the same sample) could make contrastive learning cluster intra-class samples together. Moreover, from the newly derived augmentation overlap perspective, we develop an unsupervised metric for the representation evaluation of contrastive learning, which aligns well with the downstream performance almost without relying on additional modules. Code is available at this https URL.</li>
</ul>

<h3>Title: Image-Intrinsic Priors for Integrated Circuit Defect Detection and Novel Class Discovery via Self-Supervised Learning</h3>
<ul>
<li><strong>Authors: </strong>Botong.Zhao, Xubin.Wang, Shujing.Lyu, Yue.Lu</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.03120">https://arxiv.org/abs/2511.03120</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.03120">https://arxiv.org/pdf/2511.03120</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.03120]] Image-Intrinsic Priors for Integrated Circuit Defect Detection and Novel Class Discovery via Self-Supervised Learning(https://arxiv.org/abs/2511.03120)</code><input type="text"></li>
<li><strong>Keywords: </strong>self-supervised</a></li>
<li><strong>Abstract: </strong>Integrated circuit manufacturing is highly complex, comprising hundreds of process steps. Defects can arise at any stage, causing yield loss and ultimately degrading product reliability. Supervised methods require extensive human annotation and struggle with emergent categories and rare, data scarce defects. Clustering-based unsupervised methods often exhibit unstable performance due to missing priors. We propose IC DefectNCD, a support set free framework that leverages Image Intrinsic Priors in IC SEM images for defect detection and novel class discovery. We first develop Self Normal Information Guided IC Defect Detection, aggregating representative normal features via a learnable normal information extractor and using reconstruction residuals to coarsely localize defect regions. To handle saliency variations across defects, we introduce an adaptive binarization strategy that produces stable subimages focused on core defective areas. Finally, we design Self Defect Information Guided IC Defect Classification, which incorporates a soft mask guided attention mechanism to inject spatial defect priors into the teacher student model. This enhances sensitivity to defective regions, suppresses background interference, and enables recognition and classification of unseen defects. We validate the approach on a real world dataset spanning three key fabrication stages and covering 15 defect types. Experiments demonstrate robust performance on both defect detection and unseen defect classification.</li>
</ul>

<h3>Title: Forecast2Anomaly (F2A): Adapting Multivariate Time Series Foundation Models for Anomaly Prediction</h3>
<ul>
<li><strong>Authors: </strong>Atif Hassan, Tarun Kumar, Ashish Mishra, Sergey Serebryakov, Satish Kumar Mopur, Phanidhar Koganti, Murthy Chelankuri, Ramanagopal Vogety, Suparna Bhattacharya, Martin Foltin</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.03149">https://arxiv.org/abs/2511.03149</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.03149">https://arxiv.org/pdf/2511.03149</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.03149]] Forecast2Anomaly (F2A): Adapting Multivariate Time Series Foundation Models for Anomaly Prediction(https://arxiv.org/abs/2511.03149)</code><input type="text"></li>
<li><strong>Keywords: </strong>foundation model, anomaly</a></li>
<li><strong>Abstract: </strong>Forecasting anomalies (anomaly prediction) in multivariate time series from different real-world, dynamic, and complex systems is vital for preempting critical failures, leading to a substantial minimization in operational costs and human labor. Yet, existing methods are limited to specific systems while failing to generalize to evolving anomaly patterns over time. In contrast, pretrained Time Series Foundation Models (TSFMs) have recently demonstrated strong generalization and zero-shot forecasting capabilities. However, their potential remains untapped for anomaly prediction, a task fundamentally different from forecasting normal behavior. Thus, we present Forecast2Anomaly (F2A), a novel framework that empowers TSFMs with anomaly prediction abilities through two key innovations. First, we propose a joint forecast-anomaly loss that fine-tunes TSFMs to accurately forecast future signals even at anomalous time points. Second, we introduce a Retrieval-Augmented Generation (RAG) module that retrieves historically relevant horizons and conditions predictions on them. This component dynamically adapts to distributional shifts at inference time, enabling F2A to track evolving anomalies without requiring model updates. By combining targeted fine-tuning with dynamic retrieval, F2A bridges the gap between robust TSFM zero-shot forecasting and zero-shot anomaly prediction. Extensive experiments across 16 diverse datasets and multiple TSFM backbones show that F2A consistently outperforms state-of-the-art methods, offering a scalable, zero-shot anomaly prediction solution for real-world applications.</li>
</ul>

<h3>Title: Finetuning-Free Personalization of Text to Image Generation via Hypernetworks</h3>
<ul>
<li><strong>Authors: </strong>Sagar Shrestha, Gopal Sharma, Luowei Zhou, Suren Kumar</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.03156">https://arxiv.org/abs/2511.03156</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.03156">https://arxiv.org/pdf/2511.03156</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.03156]] Finetuning-Free Personalization of Text to Image Generation via Hypernetworks(https://arxiv.org/abs/2511.03156)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>Personalizing text-to-image diffusion models has traditionally relied on subject-specific fine-tuning approaches such as DreamBooth~\cite{ruiz2023dreambooth}, which are computationally expensive and slow at inference. Recent adapter- and encoder-based methods attempt to reduce this overhead but still depend on additional fine-tuning or large backbone models for satisfactory results. In this work, we revisit an orthogonal direction: fine-tuning-free personalization via Hypernetworks that predict LoRA-adapted weights directly from subject images. Prior hypernetwork-based approaches, however, suffer from costly data generation or unstable attempts to mimic base model optimization trajectories. We address these limitations with an end-to-end training objective, stabilized by a simple output regularization, yielding reliable and effective hypernetworks. Our method removes the need for per-subject optimization at test time while preserving both subject fidelity and prompt alignment. To further enhance compositional generalization at inference time, we introduce Hybrid-Model Classifier-Free Guidance (HM-CFG), which combines the compositional strengths of the base diffusion model with the subject fidelity of personalized models during sampling. Extensive experiments on CelebA-HQ, AFHQ-v2, and DreamBench demonstrate that our approach achieves strong personalization performance and highlights the promise of hypernetworks as a scalable and effective direction for open-category personalization.</li>
</ul>

<h3>Title: Subsampled Randomized Fourier GaLore for Adapting Foundation Models in Depth-Driven Liver Landmark Segmentation</h3>
<ul>
<li><strong>Authors: </strong>Yun-Chen Lin, Jiayuan Huang, Hanyuan Zhang, Sergi Kavtaradze, Matthew J. Clarkson, Mobarak I. Hoque</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.03163">https://arxiv.org/abs/2511.03163</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.03163">https://arxiv.org/pdf/2511.03163</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.03163]] Subsampled Randomized Fourier GaLore for Adapting Foundation Models in Depth-Driven Liver Landmark Segmentation(https://arxiv.org/abs/2511.03163)</code><input type="text"></li>
<li><strong>Keywords: </strong>foundation model</a></li>
<li><strong>Abstract: </strong>Accurate detection and delineation of anatomical structures in medical imaging are critical for computer-assisted interventions, particularly in laparoscopic liver surgery where 2D video streams limit depth perception and complicate landmark localization. While recent works have leveraged monocular depth cues for enhanced landmark detection, challenges remain in fusing RGB and depth features and in efficiently adapting large-scale vision models to surgical domains. We propose a depth-guided liver landmark segmentation framework integrating semantic and geometric cues via vision foundation encoders. We employ Segment Anything Model V2 (SAM2) encoder to extract RGB features and Depth Anything V2 (DA2) encoder to extract depth-aware features. To efficiently adapt SAM2, we introduce SRFT-GaLore, a novel low-rank gradient projection method that replaces the computationally expensive SVD with a Subsampled Randomized Fourier Transform (SRFT). This enables efficient fine-tuning of high-dimensional attention layers without sacrificing representational power. A cross-attention fusion module further integrates RGB and depth cues. To assess cross-dataset generalization, we also construct a new Laparoscopic Liver Surgical Dataset (LLSD) as an external validation benchmark. On the public L3D dataset, our method achieves a 4.85% improvement in Dice Similarity Coefficient and a 11.78-point reduction in Average Symmetric Surface Distance compared to the D2GPLand. To further assess generalization capability, we evaluate our model on LLSD dataset. Our model maintains competitive performance and significantly outperforms SAM-based baselines, demonstrating strong cross-dataset robustness and adaptability to unseen surgical environments. These results demonstrate that our SRFT-GaLore-enhanced dual-encoder framework enables scalable and precise segmentation under real-time, depth-constrained surgical settings.</li>
</ul>

<h3>Title: Diffusion-Guided Mask-Consistent Paired Mixing for Endoscopic Image Segmentation</h3>
<ul>
<li><strong>Authors: </strong>Pengyu Jie, Wanquan Liu, Rui He, Yihui Wen, Deyu Meng, Chenqiang Gao</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.03219">https://arxiv.org/abs/2511.03219</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.03219">https://arxiv.org/pdf/2511.03219</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.03219]] Diffusion-Guided Mask-Consistent Paired Mixing for Endoscopic Image Segmentation(https://arxiv.org/abs/2511.03219)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, generative</a></li>
<li><strong>Abstract: </strong>Augmentation for dense prediction typically relies on either sample mixing or generative synthesis. Mixing improves robustness but misaligned masks yield soft label ambiguity. Diffusion synthesis increases apparent diversity but, when trained as common samples, overlooks the structural benefit of mask conditioning and introduces synthetic-real domain shift. We propose a paired, diffusion-guided paradigm that fuses the strengths of both. For each real image, a synthetic counterpart is generated under the same mask and the pair is used as a controllable input for Mask-Consistent Paired Mixing (MCPMix), which mixes only image appearance while supervision always uses the original hard mask. This produces a continuous family of intermediate samples that smoothly bridges synthetic and real appearances under shared geometry, enlarging diversity without compromising pixel-level semantics. To keep learning aligned with real data, Real-Anchored Learnable Annealing (RLA) adaptively adjusts the mixing strength and the loss weight of mixed samples over training, gradually re-anchoring optimization to real data and mitigating distributional bias. Across Kvasir-SEG, PICCOLO, CVC-ClinicDB, a private NPC-LES cohort, and ISIC 2017, the approach achieves state-of-the-art segmentation performance and consistent gains over baselines. The results show that combining label-preserving mixing with diffusion-driven diversity, together with adaptive re-anchoring, yields robust and generalizable endoscopic segmentation.</li>
</ul>

<h3>Title: A unified physics-informed generative operator framework for general inverse problems</h3>
<ul>
<li><strong>Authors: </strong>Gang Bao, Yaohua Zang</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.03241">https://arxiv.org/abs/2511.03241</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.03241">https://arxiv.org/pdf/2511.03241</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.03241]] A unified physics-informed generative operator framework for general inverse problems(https://arxiv.org/abs/2511.03241)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>Solving inverse problems governed by partial differential equations (PDEs) is central to science and engineering, yet remains challenging when measurements are sparse, noisy, or when the underlying coefficients are high-dimensional or discontinuous. Existing deep learning approaches either require extensive labeled datasets or are limited to specific measurement types, often leading to failure in such regimes and restricting their practical applicability. Here, a novel generative neural operator framework, IGNO, is introduced to overcome these limitations. IGNO unifies the solution of inverse problems from both point measurements and operator-valued data without labeled training pairs. This framework encodes high-dimensional, potentially discontinuous coefficient fields into a low-dimensional latent space, which drives neural operator decoders to reconstruct both coefficients and PDE solutions. Training relies purely on physics constraints through PDE residuals, while inversion proceeds via efficient gradient-based optimization in latent space, accelerated by an a priori normalizing flow model. Across a diverse set of challenging inverse problems, including recovery of discontinuous coefficients from solution-based measurements and the EIT problem with operator-based measurements, IGNO consistently achieves accurate, stable, and scalable inversion even under severe noise. It consistently outperforms the state-of-the-art method under varying noise levels and demonstrates strong generalization to out-of-distribution targets. These results establish IGNO as a unified and powerful framework for tackling challenging inverse problems across computational science domains.</li>
</ul>

<h3>Title: GMoPE:A Prompt-Expert Mixture Framework for Graph Foundation Models</h3>
<ul>
<li><strong>Authors: </strong>Zhibin Wang, Zhixing Zhang, Shuqi Wang, Xuanting Xie, Zhao Kang</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.SI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.03251">https://arxiv.org/abs/2511.03251</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.03251">https://arxiv.org/pdf/2511.03251</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.03251]] GMoPE:A Prompt-Expert Mixture Framework for Graph Foundation Models(https://arxiv.org/abs/2511.03251)</code><input type="text"></li>
<li><strong>Keywords: </strong>foundation model</a></li>
<li><strong>Abstract: </strong>Graph Neural Networks (GNNs) have demonstrated impressive performance on task-specific benchmarks, yet their ability to generalize across diverse domains and tasks remains limited. Existing approaches often struggle with negative transfer, scalability issues, and high adaptation costs. To address these challenges, we propose GMoPE (Graph Mixture of Prompt-Experts), a novel framework that seamlessly integrates the Mixture-of-Experts (MoE) architecture with prompt-based learning for graphs. GMoPE leverages expert-specific prompt vectors and structure-aware MoE routing to enable each expert to specialize in distinct subdomains and dynamically contribute to predictions. To promote diversity and prevent expert collapse, we introduce a soft orthogonality constraint across prompt vectors, encouraging expert specialization and facilitating a more balanced expert utilization. Additionally, we adopt a prompt-only fine-tuning strategy that significantly reduces spatiotemporal complexity during transfer. We validate GMoPE through extensive experiments under various pretraining strategies and multiple downstream tasks. Results show that GMoPE consistently outperforms state-of-the-art baselines and achieves performance comparable to full parameter fine-tuning-while requiring only a fraction of the adaptation overhead. Our work provides a principled and scalable framework for advancing generalizable and efficient graph foundation models.</li>
</ul>

<h3>Title: Generative deep learning for foundational video translation in ultrasound</h3>
<ul>
<li><strong>Authors: </strong>Nikolina Tomic Roshni Bhatnagar, Sarthak Jain, Connor Lau, Tien-Yu Liu, Laura Gambini, Rima Arnaout</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.03255">https://arxiv.org/abs/2511.03255</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.03255">https://arxiv.org/pdf/2511.03255</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.03255]] Generative deep learning for foundational video translation in ultrasound(https://arxiv.org/abs/2511.03255)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>Deep learning (DL) has the potential to revolutionize image acquisition and interpretation across medicine, however, attention to data imbalance and missingness is required. Ultrasound data presents a particular challenge because in addition to different views and structures, it includes several sub-modalities-such as greyscale and color flow doppler (CFD)-that are often imbalanced in clinical studies. Image translation can help balance datasets but is challenging for ultrasound sub-modalities to date. Here, we present a generative method for ultrasound CFD-greyscale video translation, trained on 54,975 videos and tested on 8,368. The method developed leveraged pixel-wise, adversarial, and perceptual loses and utilized two networks: one for reconstructing anatomic structures and one for denoising to achieve realistic ultrasound imaging. Average pairwise SSIM between synthetic videos and ground truth was 0.91+/-0.04. Synthetic videos performed indistinguishably from real ones in DL classification and segmentation tasks and when evaluated by blinded clinical experts: F1 score was 0.9 for real and 0.89 for synthetic videos; Dice score between real and synthetic segmentation was 0.97. Overall clinician accuracy in distinguishing real vs synthetic videos was 54+/-6% (42-61%), indicating realistic synthetic videos. Although trained only on heart videos, the model worked well on ultrasound spanning several clinical domains (average SSIM 0.91+/-0.05), demonstrating foundational abilities. Together, these data expand the utility of retrospectively collected imaging and augment the dataset design toolbox for medical imaging.</li>
</ul>

<h3>Title: Enhancing Medical Image Segmentation via Heat Conduction Equation</h3>
<ul>
<li><strong>Authors: </strong>Rong Wu, Yim-Sang Yu</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.03260">https://arxiv.org/abs/2511.03260</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.03260">https://arxiv.org/pdf/2511.03260</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.03260]] Enhancing Medical Image Segmentation via Heat Conduction Equation(https://arxiv.org/abs/2511.03260)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>Medical image segmentation has been significantly advanced by deep learning architectures, notably U-Net variants. However, existing models struggle to achieve efficient global context modeling and long-range dependency reasoning under practical computational budgets simultaneously. In this work, we propose a novel hybrid architecture utilizing U-Mamba with Heat Conduction Equation. Our model combines Mamba-based state-space modules for efficient long-range reasoning with Heat Conduction Operators (HCOs) in the bottleneck layers, simulating frequency-domain thermal diffusion for enhanced semantic abstraction. Experimental results on multimodal abdominal CT and MRI datasets demonstrate that the proposed model consistently outperforms strong baselines, validating its effectiveness and generalizability. It suggest that blending state-space dynamics with heat-based global diffusion offers a scalable and interpretable solution for medical segmentation tasks.</li>
</ul>

<h3>Title: Comparing the Performance of LLMs in RAG-based Question-Answering: A Case Study in Computer Science Literature</h3>
<ul>
<li><strong>Authors: </strong>Ranul Dayarathne, Uvini Ranaweera, Upeksha Ganegoda</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.03261">https://arxiv.org/abs/2511.03261</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.03261">https://arxiv.org/pdf/2511.03261</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.03261]] Comparing the Performance of LLMs in RAG-based Question-Answering: A Case Study in Computer Science Literature(https://arxiv.org/abs/2511.03261)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>Retrieval Augmented Generation (RAG) is emerging as a powerful technique to enhance the capabilities of Generative AI models by reducing hallucination. Thus, the increasing prominence of RAG alongside Large Language Models (LLMs) has sparked interest in comparing the performance of different LLMs in question-answering (QA) in diverse domains. This study compares the performance of four open-source LLMs, Mistral-7b-instruct, LLaMa2-7b-chat, Falcon-7b-instruct and Orca-mini-v3-7b, and OpenAI's trending GPT-3.5 over QA tasks within the computer science literature leveraging RAG support. Evaluation metrics employed in the study include accuracy and precision for binary questions and ranking by a human expert, ranking by Google's AI model Gemini, alongside cosine similarity for long-answer questions. GPT-3.5, when paired with RAG, effectively answers binary and long-answer questions, reaffirming its status as an advanced LLM. Regarding open-source LLMs, Mistral AI's Mistral-7b-instruct paired with RAG surpasses the rest in answering both binary and long-answer questions. However, among the open-source LLMs, Orca-mini-v3-7b reports the shortest average latency in generating responses, whereas LLaMa2-7b-chat by Meta reports the highest average latency. This research underscores the fact that open-source LLMs, too, can go hand in hand with proprietary models like GPT-3.5 with better infrastructure.</li>
</ul>

<h3>Title: IEC3D-AD: A 3D Dataset of Industrial Equipment Components for Unsupervised Point Cloud Anomaly Detection</h3>
<ul>
<li><strong>Authors: </strong>Bingyang Guo, Hongjie Li, Ruiyun Yu, Hanzhe Liang, Jinbao Wang</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.03267">https://arxiv.org/abs/2511.03267</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.03267">https://arxiv.org/pdf/2511.03267</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.03267]] IEC3D-AD: A 3D Dataset of Industrial Equipment Components for Unsupervised Point Cloud Anomaly Detection(https://arxiv.org/abs/2511.03267)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative, anomaly</a></li>
<li><strong>Abstract: </strong>3D anomaly detection (3D-AD) plays a critical role in industrial manufacturing, particularly in ensuring the reliability and safety of core equipment components. Although existing 3D datasets like Real3D-AD and MVTec 3D-AD offer broad application support, they fall short in capturing the complexities and subtle defects found in real industrial environments. This limitation hampers precise anomaly detection research, especially for industrial equipment components (IEC) such as bearings, rings, and bolts. To address this challenge, we have developed a point cloud anomaly detection dataset (IEC3D-AD) specific to real industrial scenarios. This dataset is directly collected from actual production lines, ensuring high fidelity and relevance. Compared to existing datasets, IEC3D-AD features significantly improved point cloud resolution and defect annotation granularity, facilitating more demanding anomaly detection tasks. Furthermore, inspired by generative 2D-AD methods, we introduce a novel 3D-AD paradigm (GMANet) on IEC3D-AD. This paradigm generates synthetic point cloud samples based on geometric morphological analysis, then reduces the margin and increases the overlap between normal and abnormal point-level features through spatial discrepancy optimization. Extensive experiments demonstrate the effectiveness of our method on both IEC3D-AD and other datasets.</li>
</ul>

<h3>Title: Unified Long Video Inpainting and Outpainting via Overlapping High-Order Co-Denoising</h3>
<ul>
<li><strong>Authors: </strong>Shuangquan Lyu, Steven Mao, Yue Ma</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.03272">https://arxiv.org/abs/2511.03272</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.03272">https://arxiv.org/pdf/2511.03272</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.03272]] Unified Long Video Inpainting and Outpainting via Overlapping High-Order Co-Denoising(https://arxiv.org/abs/2511.03272)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>Generating long videos remains a fundamental challenge, and achieving high controllability in video inpainting and outpainting is particularly demanding. To address both of these challenges simultaneously and achieve controllable video inpainting and outpainting for long video clips, we introduce a novel and unified approach for long video inpainting and outpainting that extends text-to-video diffusion models to generate arbitrarily long, spatially edited videos with high fidelity. Our method leverages LoRA to efficiently fine-tune a large pre-trained video diffusion model like Alibaba's Wan 2.1 for masked region video synthesis, and employs an overlap-and-blend temporal co-denoising strategy with high-order solvers to maintain consistency across long sequences. In contrast to prior work that struggles with fixed-length clips or exhibits stitching artifacts, our system enables arbitrarily long video generation and editing without noticeable seams or drift. We validate our approach on challenging inpainting/outpainting tasks including editing or adding objects over hundreds of frames and demonstrate superior performance to baseline methods like Wan 2.1 model and VACE in terms of quality (PSNR/SSIM), and perceptual realism (LPIPS). Our method enables practical long-range video editing with minimal overhead, achieved a balance between parameter efficient and superior performance.</li>
</ul>

<h3>Title: Diffusion Language Models are Super Data Learners</h3>
<ul>
<li><strong>Authors: </strong>Jinjie Ni, Qian Liu, Longxu Dou, Chao Du, Zili Wang, Hang Yan, Tianyu Pang, Michael Qizhe Shieh</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.03276">https://arxiv.org/abs/2511.03276</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.03276">https://arxiv.org/pdf/2511.03276</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.03276]] Diffusion Language Models are Super Data Learners(https://arxiv.org/abs/2511.03276)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>Under strictly controlled pre-training settings, we observe a Crossover: when unique data is limited, diffusion language models (DLMs) consistently surpass autoregressive (AR) models by training for more epochs. The crossover shifts later with more or higher-quality data, earlier with larger models, and persists across dense and sparse architectures. We attribute the gains to three compounding factors: (1) any-order modeling, (2) super-dense compute from iterative bidirectional denoising, and (3) built-in Monte Carlo augmentation; input or parameter noise improves AR under data constraint but cannot close the gap. At scale, a 1.7B DLM trained with a ~1.5T-token compute budget on 10B unique Python tokens overtakes an AR coder trained with strictly matched settings. In addition, a 1B-parameter DLM achieves > 56% accuracy on HellaSwag and > 33% on MMLU using only 1B tokens, without any special tricks, just by repeating standard pre-training data. We also show that rising validation cross-entropy does not imply degraded downstream performance in this regime.</li>
</ul>

<h3>Title: Graph Neural AI with Temporal Dynamics for Comprehensive Anomaly Detection in Microservices</h3>
<ul>
<li><strong>Authors: </strong>Qingyuan Zhang, Ning Lyu, Le Liu, Yuxi Wang, Ziyu Cheng, Cancan Hua</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.03285">https://arxiv.org/abs/2511.03285</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.03285">https://arxiv.org/pdf/2511.03285</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.03285]] Graph Neural AI with Temporal Dynamics for Comprehensive Anomaly Detection in Microservices(https://arxiv.org/abs/2511.03285)</code><input type="text"></li>
<li><strong>Keywords: </strong>anomaly</a></li>
<li><strong>Abstract: </strong>This study addresses the problem of anomaly detection and root cause tracing in microservice architectures and proposes a unified framework that combines graph neural networks with temporal modeling. The microservice call chain is abstracted as a directed graph, where multidimensional features of nodes and edges are used to construct a service topology representation, and graph convolution is applied to aggregate features across nodes and model dependencies, capturing complex structural relationships among services. On this basis, gated recurrent units are introduced to model the temporal evolution of call chains, and multi-layer stacking and concatenation operations are used to jointly obtain structural and temporal representations, improving the ability to identify anomaly patterns. Furthermore, anomaly scoring functions at both the node and path levels are defined to achieve unified modeling from local anomaly detection to global call chain tracing, which enables the identification of abnormal service nodes and the reconstruction of potential anomaly propagation paths. Sensitivity experiments are then designed from multiple dimensions, including hyperparameters, environmental disturbances, and data distribution, to evaluate the framework, and results show that it outperforms baseline methods in key metrics such as AUC, ACC, Recall, and F1-Score, maintaining high accuracy and stability under dynamic topologies and complex environments. This research not only provides a new technical path for anomaly detection in microservices but also lays a methodological foundation for intelligent operations in distributed systems.</li>
</ul>

<h3>Title: Diffusion-SDPO: Safeguarded Direct Preference Optimization for Diffusion Models</h3>
<ul>
<li><strong>Authors: </strong>Minghao Fu, Guo-Hua Wang, Tianyu Cui, Qing-Guo Chen, Zhao Xu, Weihua Luo, Kaifu Zhang</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.03317">https://arxiv.org/abs/2511.03317</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.03317">https://arxiv.org/pdf/2511.03317</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.03317]] Diffusion-SDPO: Safeguarded Direct Preference Optimization for Diffusion Models(https://arxiv.org/abs/2511.03317)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>Text-to-image diffusion models deliver high-quality images, yet aligning them with human preferences remains challenging. We revisit diffusion-based Direct Preference Optimization (DPO) for these models and identify a critical pathology: enlarging the preference margin does not necessarily improve generation quality. In particular, the standard Diffusion-DPO objective can increase the reconstruction error of both winner and loser branches. Consequently, degradation of the less-preferred outputs can become sufficiently severe that the preferred branch is also adversely affected even as the margin grows. To address this, we introduce Diffusion-SDPO, a safeguarded update rule that preserves the winner by adaptively scaling the loser gradient according to its alignment with the winner gradient. A first-order analysis yields a closed-form scaling coefficient that guarantees the error of the preferred output is non-increasing at each optimization step. Our method is simple, model-agnostic, broadly compatible with existing DPO-style alignment frameworks and adds only marginal computational overhead. Across standard text-to-image benchmarks, Diffusion-SDPO delivers consistent gains over preference-learning baselines on automated preference, aesthetic, and prompt alignment metrics. Code is publicly available at this https URL.</li>
</ul>

<h3>Title: UniAVGen: Unified Audio and Video Generation with Asymmetric Cross-Modal Interactions</h3>
<ul>
<li><strong>Authors: </strong>Guozhen Zhang, Zixiang Zhou, Teng Hu, Ziqiao Peng, Youliang Zhang, Yi Chen, Yuan Zhou, Qinglin Lu, Limin Wang</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.03334">https://arxiv.org/abs/2511.03334</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.03334">https://arxiv.org/pdf/2511.03334</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.03334]] UniAVGen: Unified Audio and Video Generation with Asymmetric Cross-Modal Interactions(https://arxiv.org/abs/2511.03334)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, generative</a></li>
<li><strong>Abstract: </strong>Due to the lack of effective cross-modal modeling, existing open-source audio-video generation methods often exhibit compromised lip synchronization and insufficient semantic consistency. To mitigate these drawbacks, we propose UniAVGen, a unified framework for joint audio and video generation. UniAVGen is anchored in a dual-branch joint synthesis architecture, incorporating two parallel Diffusion Transformers (DiTs) to build a cohesive cross-modal latent space. At its heart lies an Asymmetric Cross-Modal Interaction mechanism, which enables bidirectional, temporally aligned cross-attention, thus ensuring precise spatiotemporal synchronization and semantic consistency. Furthermore, this cross-modal interaction is augmented by a Face-Aware Modulation module, which dynamically prioritizes salient regions in the interaction process. To enhance generative fidelity during inference, we additionally introduce Modality-Aware Classifier-Free Guidance, a novel strategy that explicitly amplifies cross-modal correlation signals. Notably, UniAVGen's robust joint synthesis design enables seamless unification of pivotal audio-video tasks within a single model, such as joint audio-video generation and continuation, video-to-audio dubbing, and audio-driven video synthesis. Comprehensive experiments validate that, with far fewer training samples (1.3M vs. 30.1M), UniAVGen delivers overall advantages in audio-video synchronization, timbre consistency, and emotion consistency.</li>
</ul>

<h3>Title: Generative Artificial Intelligence in Bioinformatics: A Systematic Review of Models, Applications, and Methodological Advances</h3>
<ul>
<li><strong>Authors: </strong>Riasad Alvi, Sayeem Been Zaman, Wasimul Karim, Arefin Ittesafun Abian, Mohaimenul Azam Khan Raiaan, Saddam Mukta, Md Rafi Ur Rashid, Md Rafiqul Islam, Yakub Sebastian, Sami Azam</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.03354">https://arxiv.org/abs/2511.03354</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.03354">https://arxiv.org/pdf/2511.03354</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.03354]] Generative Artificial Intelligence in Bioinformatics: A Systematic Review of Models, Applications, and Methodological Advances(https://arxiv.org/abs/2511.03354)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>Generative artificial intelligence (GenAI) has become a transformative approach in bioinformatics that often enables advancements in genomics, proteomics, transcriptomics, structural biology, and drug discovery. To systematically identify and evaluate these growing developments, this review proposed six research questions (RQs), according to the preferred reporting items for systematic reviews and meta-analysis methods. The objective is to evaluate impactful GenAI strategies in methodological advancement, predictive performance, and specialization, and to identify promising approaches for advanced modeling, data-intensive discovery, and integrative biological analysis. RQ1 highlights diverse applications across multiple bioinformatics subfields (sequence analysis, molecular design, and integrative data modeling), which demonstrate superior performance over traditional methods through pattern recognition and output generation. RQ2 reveals that adapted specialized model architectures outperformed general-purpose models, an advantage attributed to targeted pretraining and context-aware strategies. RQ3 identifies significant benefits in the bioinformatics domains, focusing on molecular analysis and data integration, which improves accuracy and reduces errors in complex analysis. RQ4 indicates improvements in structural modeling, functional prediction, and synthetic data generation, validated by established benchmarks. RQ5 suggests the main constraints, such as the lack of scalability and biases in data that impact generalizability, and proposes future directions focused on robust evaluation and biologically grounded modeling. RQ6 examines that molecular datasets (such as UniProtKB and ProteinNet12), cellular datasets (such as CELLxGENE and GTEx) and textual resources (such as PubMedQA and OMIM) broadly support the training and generalization of GenAI models.</li>
</ul>

<h3>Title: POEMS: Product of Experts for Interpretable Multi-omic Integration using Sparse Decoding</h3>
<ul>
<li><strong>Authors: </strong>Mihriban Kocak Balik, Pekka Marttinen, Negar Safinianaini</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.03464">https://arxiv.org/abs/2511.03464</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.03464">https://arxiv.org/pdf/2511.03464</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.03464]] POEMS: Product of Experts for Interpretable Multi-omic Integration using Sparse Decoding(https://arxiv.org/abs/2511.03464)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>Integrating different molecular layers, i.e., multiomics data, is crucial for unraveling the complexity of diseases; yet, most deep generative models either prioritize predictive performance at the expense of interpretability or enforce interpretability by linearizing the decoder, thereby weakening the network's nonlinear expressiveness. To overcome this tradeoff, we introduce POEMS: Product Of Experts for Interpretable Multiomics Integration using Sparse Decoding, an unsupervised probabilistic framework that preserves predictive performance while providing interpretability. POEMS provides interpretability without linearizing any part of the network by 1) mapping features to latent factors using sparse connections, which directly translates to biomarker discovery, 2) allowing for cross-omic associations through a shared latent space using product of experts model, and 3) reporting contributions of each omic by a gating network that adaptively computes their influence in the representation learning. Additionally, we present an efficient sparse decoder. In a cancer subtyping case study, POEMS achieves competitive clustering and classification performance while offering our novel set of interpretations, demonstrating that biomarker based insight and predictive accuracy can coexist in multiomics representation learning.</li>
</ul>

<h3>Title: TabGemma: Text-Based Tabular ICL via LLM using Continued Pretraining and Retrieval</h3>
<ul>
<li><strong>Authors: </strong>Günther Schindler, Maximilian Schambach, Michael Medek, Sam Thelin</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.03570">https://arxiv.org/abs/2511.03570</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.03570">https://arxiv.org/pdf/2511.03570</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.03570]] TabGemma: Text-Based Tabular ICL via LLM using Continued Pretraining and Retrieval(https://arxiv.org/abs/2511.03570)</code><input type="text"></li>
<li><strong>Keywords: </strong>in-context</a></li>
<li><strong>Abstract: </strong>We study LLMs for tabular prediction with mixed text, numeric, and categorical fields. We introduce TabGemma, a schema-agnostic in-context learner that treats rows as sequences and tackles two practical hurdles when adapting pretrained LLMs for tabular predictions: unstable numeric tokenization and limited context size. We propose to canonicalize numbers via signed scientific notation and continue pretraining of a 12B Gemma 3 model with a target imputation objective using a large-scale real world dataset. For inference, we use a compact n-gram-based retrieval to select informative exemplars that fit within a 128k-token window. On semantically rich benchmarks, TabGemma establishes a new state of the art on classification across low- and high-data regimes and improves monotonically with more context rows. For regression, it is competitive at small sample sizes but trails conventional approaches as data grows. Our results show that LLMs can be effective tabular in-context learners on highly semantic tasks when paired with dedicated numeric handling and context retrieval, while motivating further advances in numeric modeling and long-context scaling.</li>
</ul>

<h3>Title: nanoTabPFN: A Lightweight and Educational Reimplementation of TabPFN</h3>
<ul>
<li><strong>Authors: </strong>Alexander Pfefferle, Johannes Hog, Lennart Purucker, Frank Hutter</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.03634">https://arxiv.org/abs/2511.03634</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.03634">https://arxiv.org/pdf/2511.03634</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.03634]] nanoTabPFN: A Lightweight and Educational Reimplementation of TabPFN(https://arxiv.org/abs/2511.03634)</code><input type="text"></li>
<li><strong>Keywords: </strong>foundation model</a></li>
<li><strong>Abstract: </strong>Tabular foundation models such as TabPFN have revolutionized predictive machine learning for tabular data. At the same time, the driving factors of this revolution are hard to understand. Existing open-source tabular foundation models are implemented in complicated pipelines boasting over 10,000 lines of code, lack architecture documentation or code quality. In short, the implementations are hard to understand, not beginner-friendly, and complicated to adapt for new experiments. We introduce nanoTabPFN, a simplified and lightweight implementation of the TabPFN v2 architecture and a corresponding training loop that uses pre-generated training data. nanoTabPFN makes tabular foundation models more accessible to students and researchers alike. For example, restricted to a small data setting it achieves a performance comparable to traditional machine learning baselines within one minute of pre-training on a single GPU (160,000x faster than TabPFN v2 pretraining). This eliminated requirement of large computational resources makes pre-training tabular foundation models accessible for educational purposes. Our code is available at this https URL.</li>
</ul>

<h3>Title: SHIELD: Securing Healthcare IoT with Efficient Machine Learning Techniques for Anomaly Detection</h3>
<ul>
<li><strong>Authors: </strong>Mahek Desai, Apoorva Rumale, Marjan Asadinia</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.03661">https://arxiv.org/abs/2511.03661</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.03661">https://arxiv.org/pdf/2511.03661</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.03661]] SHIELD: Securing Healthcare IoT with Efficient Machine Learning Techniques for Anomaly Detection(https://arxiv.org/abs/2511.03661)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative, anomaly</a></li>
<li><strong>Abstract: </strong>The integration of IoT devices in healthcare introduces significant security and reliability challenges, increasing susceptibility to cyber threats and operational anomalies. This study proposes a machine learning-driven framework for (1) detecting malicious cyberattacks and (2) identifying faulty device anomalies, leveraging a dataset of 200,000 records. Eight machine learning models are evaluated across three learning approaches: supervised learning (XGBoost, K-Nearest Neighbors (K- NN)), semi-supervised learning (Generative Adversarial Networks (GAN), Variational Autoencoders (VAE)), and unsupervised learning (One-Class Support Vector Machine (SVM), Isolation Forest, Graph Neural Networks (GNN), and Long Short-Term Memory (LSTM) Autoencoders). The comprehensive evaluation was conducted across multiple metrics like F1-score, precision, recall, accuracy, ROC-AUC, computational efficiency. XGBoost achieved 99\% accuracy with minimal computational overhead (0.04s) for anomaly detection, while Isolation Forest balanced precision and recall effectively. LSTM Autoencoders underperformed with lower accuracy and higher latency. For attack detection, KNN achieved near-perfect precision, recall, and F1-score with the lowest computational cost (0.05s), followed by VAE at 97% accuracy. GAN showed the highest computational cost with lowest accuracy and ROC-AUC. These findings enhance IoT-enabled healthcare security through effective anomaly detection strategies. By improving early detection of cyber threats and device failures, this framework has the potential to prevent data breaches, minimize system downtime, and ensure the continuous and safe operation of medical devices, ultimately safeguarding patient health and trust in IoT-driven healthcare solutions.</li>
</ul>

<h3>Title: AnaFlow: Agentic LLM-based Workflow for Reasoning-Driven Explainable and Sample-Efficient Analog Circuit Sizing</h3>
<ul>
<li><strong>Authors: </strong>Mohsen Ahmadzadeh, Kaichang Chen, Georges Gielen</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.AR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.03697">https://arxiv.org/abs/2511.03697</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.03697">https://arxiv.org/pdf/2511.03697</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.03697]] AnaFlow: Agentic LLM-based Workflow for Reasoning-Driven Explainable and Sample-Efficient Analog Circuit Sizing(https://arxiv.org/abs/2511.03697)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>Analog/mixed-signal circuits are key for interfacing electronics with the physical world. Their design, however, remains a largely handcrafted process, resulting in long and error-prone design cycles. While the recent rise of AI-based reinforcement learning and generative AI has created new techniques to automate this task, the need for many time-consuming simulations is a critical bottleneck hindering the overall efficiency. Furthermore, the lack of explainability of the resulting design solutions hampers widespread adoption of the tools. To address these issues, a novel agentic AI framework for sample-efficient and explainable analog circuit sizing is presented. It employs a multi-agent workflow where specialized Large Language Model (LLM)-based agents collaborate to interpret the circuit topology, to understand the design goals, and to iteratively refine the circuit's design parameters towards the target goals with human-interpretable reasoning. The adaptive simulation strategy creates an intelligent control that yields a high sample efficiency. The AnaFlow framework is demonstrated for two circuits of varying complexity and is able to complete the sizing task fully automatically, differently from pure Bayesian optimization and reinforcement learning approaches. The system learns from its optimization history to avoid past mistakes and to accelerate convergence. The inherent explainability makes this a powerful tool for analog design space exploration and a new paradigm in analog EDA, where AI agents serve as transparent design assistants.</li>
</ul>

<button id="copy">Copy All</button>
</article>
<script src="../../javascript/clipboard.min.js"></script>
<script src="../../javascript/clipboard.js"></script>
