<link rel="stylesheet" href="../../css/markdown.css" />
<article class="markdown-body">
<h1>2024-11-05</h1>
<h3>Title: IDEATOR: Jailbreaking VLMs Using VLMs</h3>
<ul>
<li><strong>Authors: </strong>Ruofan Wang, Bo Wang, Xingjun Ma, Yu-Gang Jiang</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.00827">https://arxiv.org/abs/2411.00827</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.00827">https://arxiv.org/pdf/2411.00827</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.00827]] IDEATOR: Jailbreaking VLMs Using VLMs(https://arxiv.org/abs/2411.00827)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>As large Vision-Language Models (VLMs) continue to gain prominence, ensuring their safety deployment in real-world applications has become a critical concern. Recently, significant research efforts have focused on evaluating the robustness of VLMs against jailbreak attacks. Due to challenges in obtaining multi-modal data, current studies often assess VLM robustness by generating adversarial or query-relevant images based on harmful text datasets. However, the jailbreak images generated this way exhibit certain limitations. Adversarial images require white-box access to the target VLM and are relatively easy to defend against, while query-relevant images must be linked to the target harmful content, limiting their diversity and effectiveness. In this paper, we propose a novel jailbreak method named IDEATOR, which autonomously generates malicious image-text pairs for black-box jailbreak attacks. IDEATOR is a VLM-based approach inspired by our conjecture that a VLM itself might be a powerful red team model for generating jailbreak prompts. Specifically, IDEATOR employs a VLM to generate jailbreak texts while leveraging a state-of-the-art diffusion model to create corresponding jailbreak images. Extensive experiments demonstrate the high effectiveness and transferability of IDEATOR. It successfully jailbreaks MiniGPT-4 with a 94% success rate and transfers seamlessly to LLaVA and InstructBLIP, achieving high success rates of 82% and 88%, respectively. IDEATOR uncovers previously unrecognized vulnerabilities in VLMs, calling for advanced safety mechanisms.</li>
</ul>

<h3>Title: Accelerated AI Inference via Dynamic Execution Methods</h3>
<ul>
<li><strong>Authors: </strong>Haim Barad, Jascha Achterberg, Tien Pei Chou, Jean Yu</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.00853">https://arxiv.org/abs/2411.00853</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.00853">https://arxiv.org/pdf/2411.00853</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.00853]] Accelerated AI Inference via Dynamic Execution Methods(https://arxiv.org/abs/2411.00853)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, generative</a></li>
<li><strong>Abstract: </strong>In this paper, we focus on Dynamic Execution techniques that optimize the computation flow based on input. This aims to identify simpler problems that can be solved using fewer resources, similar to human cognition. The techniques discussed include early exit from deep networks, speculative sampling for language models, and adaptive steps for diffusion models. Experimental results demonstrate that these dynamic approaches can significantly improve latency and throughput without compromising quality. When combined with model-based optimizations, such as quantization, dynamic execution provides a powerful multi-pronged strategy to optimize AI inference. Generative AI requires a large amount of compute resources. This is expected to grow, and demand for resources in data centers through to the edge is expected to continue to increase at high rates. We take advantage of existing research and provide additional innovations for some generative optimizations. In the case of LLMs, we provide more efficient sampling methods that depend on the complexity of the data. In the case of diffusion model generation, we provide a new method that also leverages the difficulty of the input prompt to predict an optimal early stopping point. Therefore, dynamic execution methods are relevant because they add another dimension of performance optimizations. Performance is critical from a competitive point of view, but increasing capacity can result in significant power savings and cost savings. We have provided several integrations of these techniques into several Intel performance libraries and Huggingface Optimum. These integrations will make them easier to use and increase the adoption of these techniques.</li>
</ul>

<h3>Title: Profiling AI Models: Towards Efficient Computation Offloading in Heterogeneous Edge AI Systems</h3>
<ul>
<li><strong>Authors: </strong>Juan Marcelo Parra-Ullauri, Oscar Dilley, Hari Madhukumar, Dimitra Simeonidou</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.DC, cs.ET, cs.NI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.00859">https://arxiv.org/abs/2411.00859</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.00859">https://arxiv.org/pdf/2411.00859</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.00859]] Profiling AI Models: Towards Efficient Computation Offloading in Heterogeneous Edge AI Systems(https://arxiv.org/abs/2411.00859)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>The rapid growth of end-user AI applications, such as computer vision and generative AI, has led to immense data and processing demands often exceeding user devices' capabilities. Edge AI addresses this by offloading computation to the network edge, crucial for future services in 6G networks. However, it faces challenges such as limited resources during simultaneous offloads and the unrealistic assumption of homogeneous system architecture. To address these, we propose a research roadmap focused on profiling AI models, capturing data about model types, hyperparameters, and underlying hardware to predict resource utilisation and task completion time. Initial experiments with over 3,000 runs show promise in optimising resource allocation and enhancing Edge AI performance.</li>
</ul>

<h3>Title: AAD-LLM: Adaptive Anomaly Detection Using Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Alicia Russell-Gilbert, Alexander Sommers, Andrew Thompson, Logan Cummins, Sudip Mittal, Shahram Rahimi, Maria Seale, Joseph Jaboure, Thomas Arnold, Joshua Church</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CE</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.00914">https://arxiv.org/abs/2411.00914</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.00914">https://arxiv.org/pdf/2411.00914</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.00914]] AAD-LLM: Adaptive Anomaly Detection Using Large Language Models(https://arxiv.org/abs/2411.00914)</code><input type="text"></li>
<li><strong>Keywords: </strong>anomaly</a></li>
<li><strong>Abstract: </strong>For data-constrained, complex and dynamic industrial environments, there is a critical need for transferable and multimodal methodologies to enhance anomaly detection and therefore, prevent costs associated with system failures. Typically, traditional PdM approaches are not transferable or multimodal. This work examines the use of Large Language Models (LLMs) for anomaly detection in complex and dynamic manufacturing systems. The research aims to improve the transferability of anomaly detection models by leveraging Large Language Models (LLMs) and seeks to validate the enhanced effectiveness of the proposed approach in data-sparse industrial applications. The research also seeks to enable more collaborative decision-making between the model and plant operators by allowing for the enriching of input series data with semantics. Additionally, the research aims to address the issue of concept drift in dynamic industrial settings by integrating an adaptability mechanism. The literature review examines the latest developments in LLM time series tasks alongside associated adaptive anomaly detection methods to establish a robust theoretical framework for the proposed architecture. This paper presents a novel model framework (AAD-LLM) that doesn't require any training or finetuning on the dataset it is applied to and is multimodal. Results suggest that anomaly detection can be converted into a "language" task to deliver effective, context-aware detection in data-constrained industrial applications. This work, therefore, contributes significantly to advancements in anomaly detection methodologies.</li>
</ul>

<h3>Title: Scalable AI Framework for Defect Detection in Metal Additive Manufacturing</h3>
<ul>
<li><strong>Authors: </strong>Duy Nhat Phan, Sushant Jha, James P. Mavo, Erin L. Lanigan, Linh Nguyen, Lokendra Poudel, Rahul Bhowmik</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI, cs.LG, eess.SP</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.00960">https://arxiv.org/abs/2411.00960</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.00960">https://arxiv.org/pdf/2411.00960</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.00960]] Scalable AI Framework for Defect Detection in Metal Additive Manufacturing(https://arxiv.org/abs/2411.00960)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>Additive Manufacturing (AM) is transforming the manufacturing sector by enabling efficient production of intricately designed products and small-batch components. However, metal parts produced via AM can include flaws that cause inferior mechanical properties, including reduced fatigue response, yield strength, and fracture toughness. To address this issue, we leverage convolutional neural networks (CNN) to analyze thermal images of printed layers, automatically identifying anomalies that impact these properties. We also investigate various synthetic data generation techniques to address limited and imbalanced AM training data. Our models' defect detection capabilities were assessed using images of Nickel alloy 718 layers produced on a laser powder bed fusion AM machine and synthetic datasets with and without added noise. Our results show significant accuracy improvements with synthetic data, emphasizing the importance of expanding training sets for reliable defect detection. Specifically, Generative Adversarial Networks (GAN)-generated datasets streamlined data preparation by eliminating human intervention while maintaining high performance, thereby enhancing defect detection capabilities. Additionally, our denoising approach effectively improves image quality, ensuring reliable defect detection. Finally, our work integrates these models in the CLoud ADditive MAnufacturing (CLADMA) module, a user-friendly interface, to enhance their accessibility and practicality for AM applications. This integration supports broader adoption and practical implementation of advanced defect detection in AM processes.</li>
</ul>

<h3>Title: Enhancing AAC Software for Dysarthric Speakers in e-Health Settings: An Evaluation Using TORGO</h3>
<ul>
<li><strong>Authors: </strong>Macarious Hui, Jinda Zhang, Aanchan Mohan</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.HC, cs.SD, eess.AS</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.00980">https://arxiv.org/abs/2411.00980</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.00980">https://arxiv.org/pdf/2411.00980</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.00980]] Enhancing AAC Software for Dysarthric Speakers in e-Health Settings: An Evaluation Using TORGO(https://arxiv.org/abs/2411.00980)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>Individuals with cerebral palsy (CP) and amyotrophic lateral sclerosis (ALS) frequently face challenges with articulation, leading to dysarthria and resulting in atypical speech patterns. In healthcare settings, coomunication breakdowns reduce the quality of care. While building an augmentative and alternative communication (AAC) tool to enable fluid communication we found that state-of-the-art (SOTA) automatic speech recognition (ASR) technology like Whisper and Wav2vec2.0 marginalizes atypical speakers largely due to the lack of training data. Our work looks to leverage SOTA ASR followed by domain specific error-correction. English dysarthric ASR performance is often evaluated on the TORGO dataset. Prompt-overlap is a well-known issue with this dataset where phrases overlap between training and test speakers. Our work proposes an algorithm to break this prompt-overlap. After reducing prompt-overlap, results with SOTA ASR models produce extremely high word error rates for speakers with mild and severe dysarthria. Furthermore, to improve ASR, our work looks at the impact of n-gram language models and large-language model (LLM) based multi-modal generative error-correction algorithms like Whispering-LLaMA for a second pass ASR. Our work highlights how much more needs to be done to improve ASR for atypical speakers to enable equitable healthcare access both in-person and in e-health settings.</li>
</ul>

<h3>Title: FedDTPT: Federated Discrete and Transferable Prompt Tuning for Black-Box Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Jiaqi Wu, Simin Chen, Yuzhe Yang, Yijiang Li, Shiyue Hou, Rui Jing, Zehua Wang, Wei Chen, Zijian Tian</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.00985">https://arxiv.org/abs/2411.00985</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.00985">https://arxiv.org/pdf/2411.00985</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.00985]] FedDTPT: Federated Discrete and Transferable Prompt Tuning for Black-Box Large Language Models(https://arxiv.org/abs/2411.00985)</code><input type="text"></li>
<li><strong>Keywords: </strong>foundation model</a></li>
<li><strong>Abstract: </strong>In recent years, large language models (LLMs) have significantly advanced the field of natural language processing (NLP). By fine-tuning LLMs with data from specific scenarios, these foundation models can better adapt to various downstream tasks. However, the fine-tuning process poses privacy leakage risks, particularly in centralized data processing scenarios. To address user privacy concerns, federated learning (FL) has been introduced to mitigate the risks associated with centralized data collection from multiple sources. Nevertheless, the privacy of LLMs themselves is equally critical, as potential malicious attacks challenge their security, an issue that has received limited attention in current research. Consequently, establishing a trusted multi-party model fine-tuning environment is essential. Additionally, the local deployment of large LLMs incurs significant storage costs and high computational demands. To address these challenges, we propose for the first time a federated discrete and transferable prompt tuning, namely FedDTPT, for black-box large language models. In the client optimization phase, we adopt a token-level discrete prompt optimization method that leverages a feedback loop based on prediction accuracy to drive gradient-free prompt optimization through the MLM API. For server optimization, we employ an attention mechanism based on semantic similarity to filter all local prompt tokens, along with an embedding distance elbow detection and DBSCAN clustering strategy to enhance the filtering process. Experimental results demonstrate that, compared to state-of-the-art methods, our approach achieves higher accuracy, reduced communication overhead, and robustness to non-iid data in a black-box setting. Moreover, the optimized prompts are transferable.</li>
</ul>

<h3>Title: Abstracted Shapes as Tokens -- A Generalizable and Interpretable Model for Time-series Classification</h3>
<ul>
<li><strong>Authors: </strong>Yunshi Wen, Tengfei Ma, Tsui-Wei Weng, Lam M. Nguyen, Anak Agung Julius</a></li>
<li><strong>Subjects: </strong>cs.LG, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.01006">https://arxiv.org/abs/2411.01006</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.01006">https://arxiv.org/pdf/2411.01006</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.01006]] Abstracted Shapes as Tokens -- A Generalizable and Interpretable Model for Time-series Classification(https://arxiv.org/abs/2411.01006)</code><input type="text"></li>
<li><strong>Keywords: </strong>foundation model</a></li>
<li><strong>Abstract: </strong>In time-series analysis, many recent works seek to provide a unified view and representation for time-series across multiple domains, leading to the development of foundation models for time-series data. Despite diverse modeling techniques, existing models are black boxes and fail to provide insights and explanations about their representations. In this paper, we present VQShape, a pre-trained, generalizable, and interpretable model for time-series representation learning and classification. By introducing a novel representation for time-series data, we forge a connection between the latent space of VQShape and shape-level features. Using vector quantization, we show that time-series from different domains can be described using a unified set of low-dimensional codes, where each code can be represented as an abstracted shape in the time domain. On classification tasks, we show that the representations of VQShape can be utilized to build interpretable classifiers, achieving comparable performance to specialist models. Additionally, in zero-shot learning, VQShape and its codebook can generalize to previously unseen datasets and domains that are not included in the pre-training process. The code and pre-trained weights are available at this https URL.</li>
</ul>

<h3>Title: Birdie: Advancing State Space Models with Reward-Driven Objectives and Curricula</h3>
<ul>
<li><strong>Authors: </strong>Sam Blouir, Jimmy Smith, Antonios Anastasopoulos, Amarda Shehu</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.01030">https://arxiv.org/abs/2411.01030</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.01030">https://arxiv.org/pdf/2411.01030</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.01030]] Birdie: Advancing State Space Models with Reward-Driven Objectives and Curricula(https://arxiv.org/abs/2411.01030)</code><input type="text"></li>
<li><strong>Keywords: </strong>in-context</a></li>
<li><strong>Abstract: </strong>Efficient state space models (SSMs), including linear recurrent neural networks and linear attention variants, have emerged as potential alternative language models to Transformers. While efficient, SSMs struggle with tasks requiring in-context retrieval, such as text copying and associative recall, limiting their usefulness in practical settings. Prior work on how to meet this challenge has focused on the internal model architecture and not investigated the role of the training procedure. This paper proposes a new training procedure that strongly improves the performance of SSMs on retrieval-intensive tasks. This novel pre-training procedure combines a bidirectional processing of the input with dynamic mixtures of pre-training objectives to improve the utilization of the SSM's fixed-size state. Our experimental evaluations show that Birdie significantly improves performance on retrieval-intensive tasks that challenge current SSMs, such as phone book lookup, long paragraph question-answering, and infilling tasks. Our findings offer insights into a new direction to advance the training of SSMs to close the performance gap with Transformers.</li>
</ul>

<h3>Title: Identify Backdoored Model in Federated Learning via Individual Unlearning</h3>
<ul>
<li><strong>Authors: </strong>Jiahao Xu, Zikai Zhang, Rui Hu</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CR, cs.DC</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.01040">https://arxiv.org/abs/2411.01040</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.01040">https://arxiv.org/pdf/2411.01040</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.01040]] Identify Backdoored Model in Federated Learning via Individual Unlearning(https://arxiv.org/abs/2411.01040)</code><input type="text"></li>
<li><strong>Keywords: </strong>anomaly</a></li>
<li><strong>Abstract: </strong>Backdoor attacks present a significant threat to the robustness of Federated Learning (FL) due to their stealth and effectiveness. They maintain both the main task of the FL system and the backdoor task simultaneously, causing malicious models to appear statistically similar to benign ones, which enables them to evade detection by existing defense methods. We find that malicious parameters in backdoored models are inactive on the main task, resulting in a significantly large empirical loss during the machine unlearning process on clean inputs. Inspired by this, we propose MASA, a method that utilizes individual unlearning on local models to identify malicious models in FL. To improve the performance of MASA in challenging non-independent and identically distributed (non-IID) settings, we design pre-unlearning model fusion that integrates local models with knowledge learned from other datasets to mitigate the divergence in their unlearning behaviors caused by the non-IID data distributions of clients. Additionally, we propose a new anomaly detection metric with minimal hyperparameters to filter out malicious models efficiently. Extensive experiments on IID and non-IID datasets across six different attacks validate the effectiveness of MASA. To the best of our knowledge, this is the first work to leverage machine unlearning to identify malicious models in FL. Code is available at \url{this https URL}.</li>
</ul>

<h3>Title: X-Drive: Cross-modality consistent multi-sensor data synthesis for driving scenarios</h3>
<ul>
<li><strong>Authors: </strong>Yichen Xie, Chenfeng Xu, Chensheng Peng, Shuqi Zhao, Nhat Ho, Alexander T. Pham, Mingyu Ding, Masayoshi Tomizuka, Wei Zhan</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.01123">https://arxiv.org/abs/2411.01123</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.01123">https://arxiv.org/pdf/2411.01123</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.01123]] X-Drive: Cross-modality consistent multi-sensor data synthesis for driving scenarios(https://arxiv.org/abs/2411.01123)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>Recent advancements have exploited diffusion models for the synthesis of either LiDAR point clouds or camera image data in driving scenarios. Despite their success in modeling single-modality data marginal distribution, there is an under-exploration in the mutual reliance between different modalities to describe complex driving scenes. To fill in this gap, we propose a novel framework, X-DRIVE, to model the joint distribution of point clouds and multi-view images via a dual-branch latent diffusion model architecture. Considering the distinct geometrical spaces of the two modalities, X-DRIVE conditions the synthesis of each modality on the corresponding local regions from the other modality, ensuring better alignment and realism. To further handle the spatial ambiguity during denoising, we design the cross-modality condition module based on epipolar lines to adaptively learn the cross-modality local correspondence. Besides, X-DRIVE allows for controllable generation through multi-level input conditions, including text, bounding box, image, and point clouds. Extensive results demonstrate the high-fidelity synthetic results of X-DRIVE for both point clouds and multi-view images, adhering to input conditions while ensuring reliable cross-modality consistency. Our code will be made publicly available at this https URL.</li>
</ul>

<h3>Title: HG-Adapter: Improving Pre-Trained Heterogeneous Graph Neural Networks with Dual Adapters</h3>
<ul>
<li><strong>Authors: </strong>Yujie Mo, Runpeng Yu, Xiaofeng Zhu, Xinchao Wang</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.01155">https://arxiv.org/abs/2411.01155</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.01155">https://arxiv.org/pdf/2411.01155</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.01155]] HG-Adapter: Improving Pre-Trained Heterogeneous Graph Neural Networks with Dual Adapters(https://arxiv.org/abs/2411.01155)</code><input type="text"></li>
<li><strong>Keywords: </strong>self-supervised</a></li>
<li><strong>Abstract: </strong>The "pre-train, prompt-tuning'' paradigm has demonstrated impressive performance for tuning pre-trained heterogeneous graph neural networks (HGNNs) by mitigating the gap between pre-trained models and downstream tasks. However, most prompt-tuning-based works may face at least two limitations: (i) the model may be insufficient to fit the graph structures well as they are generally ignored in the prompt-tuning stage, increasing the training error to decrease the generalization ability; and (ii) the model may suffer from the limited labeled data during the prompt-tuning stage, leading to a large generalization gap between the training error and the test error to further affect the model generalization. To alleviate the above limitations, we first derive the generalization error bound for existing prompt-tuning-based methods, and then propose a unified framework that combines two new adapters with potential labeled data extension to improve the generalization of pre-trained HGNN models. Specifically, we design dual structure-aware adapters to adaptively fit task-related homogeneous and heterogeneous structural information. We further design a label-propagated contrastive loss and two self-supervised losses to optimize dual adapters and incorporate unlabeled nodes as potential labeled data. Theoretical analysis indicates that the proposed method achieves a lower generalization error bound than existing methods, thus obtaining superior generalization ability. Comprehensive experiments demonstrate the effectiveness and generalization of the proposed method on different downstream tasks.</li>
</ul>

<h3>Title: Negative-Free Self-Supervised Gaussian Embedding of Graphs</h3>
<ul>
<li><strong>Authors: </strong>Yunhui Liu, Tieke He, Tao Zheng, Jianhua Zhao</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.01157">https://arxiv.org/abs/2411.01157</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.01157">https://arxiv.org/pdf/2411.01157</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.01157]] Negative-Free Self-Supervised Gaussian Embedding of Graphs(https://arxiv.org/abs/2411.01157)</code><input type="text"></li>
<li><strong>Keywords: </strong>self-supervised</a></li>
<li><strong>Abstract: </strong>Graph Contrastive Learning (GCL) has recently emerged as a promising graph self-supervised learning framework for learning discriminative node representations without labels. The widely adopted objective function of GCL benefits from two key properties: \emph{alignment} and \emph{uniformity}, which align representations of positive node pairs while uniformly distributing all representations on the hypersphere. The uniformity property plays a critical role in preventing representation collapse and is achieved by pushing apart augmented views of different nodes (negative pairs). As such, existing GCL methods inherently rely on increasing the quantity and quality of negative samples, resulting in heavy computational demands, memory overhead, and potential class collision issues. In this study, we propose a negative-free objective to achieve uniformity, inspired by the fact that points distributed according to a normalized isotropic Gaussian are uniformly spread across the unit hypersphere. Therefore, we can minimize the distance between the distribution of learned representations and the isotropic Gaussian distribution to promote the uniformity of node representations. Our method also distinguishes itself from other approaches by eliminating the need for a parameterized mutual information estimator, an additional projector, asymmetric structures, and, crucially, negative samples. Extensive experiments over seven graph benchmarks demonstrate that our proposal achieves competitive performance with fewer parameters, shorter training times, and lower memory consumption compared to existing GCL methods.</li>
</ul>

<h3>Title: Pin-Tuning: Parameter-Efficient In-Context Tuning for Few-Shot Molecular Property Prediction</h3>
<ul>
<li><strong>Authors: </strong>Liang Wang, Qiang Liu, Shaozhen Liu, Xin Sun, Shu Wu, Liang Wang</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, q-bio.MN</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.01158">https://arxiv.org/abs/2411.01158</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.01158">https://arxiv.org/pdf/2411.01158</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.01158]] Pin-Tuning: Parameter-Efficient In-Context Tuning for Few-Shot Molecular Property Prediction(https://arxiv.org/abs/2411.01158)</code><input type="text"></li>
<li><strong>Keywords: </strong>in-context</a></li>
<li><strong>Abstract: </strong>Molecular property prediction (MPP) is integral to drug discovery and material science, but often faces the challenge of data scarcity in real-world scenarios. Addressing this, few-shot molecular property prediction (FSMPP) has been developed. Unlike other few-shot tasks, FSMPP typically employs a pre-trained molecular encoder and a context-aware classifier, benefiting from molecular pre-training and molecular context information. Despite these advancements, existing methods struggle with the ineffective fine-tuning of pre-trained encoders. We attribute this issue to the imbalance between the abundance of tunable parameters and the scarcity of labeled molecules, and the lack of contextual perceptiveness in the encoders. To overcome this hurdle, we propose a parameter-efficient in-context tuning method, named Pin-Tuning. Specifically, we propose a lightweight adapter for pre-trained message passing layers (MP-Adapter) and Bayesian weight consolidation for pre-trained atom/bond embedding layers (Emb-BWC), to achieve parameter-efficient tuning while preventing over-fitting and catastrophic forgetting. Additionally, we enhance the MP-Adapters with contextual perceptiveness. This innovation allows for in-context tuning of the pre-trained encoder, thereby improving its adaptability for specific FSMPP tasks. When evaluated on public datasets, our method demonstrates superior tuning with fewer trainable parameters, improving few-shot predictive performance.</li>
</ul>

<h3>Title: Supervised Score-Based Modeling by Gradient Boosting</h3>
<ul>
<li><strong>Authors: </strong>Changyuan Zhao, Hongyang Du, Guangyuan Liu, Dusit Niyato</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.01159">https://arxiv.org/abs/2411.01159</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.01159">https://arxiv.org/pdf/2411.01159</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.01159]] Supervised Score-Based Modeling by Gradient Boosting(https://arxiv.org/abs/2411.01159)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, generative</a></li>
<li><strong>Abstract: </strong>Score-based generative models can effectively learn the distribution of data by estimating the gradient of the distribution. Due to the multi-step denoising characteristic, researchers have recently considered combining score-based generative models with the gradient boosting algorithm, a multi-step supervised learning algorithm, to solve supervised learning tasks. However, existing generative model algorithms are often limited by the stochastic nature of the models and the long inference time, impacting prediction performances. Therefore, we propose a Supervised Score-based Model (SSM), which can be viewed as a gradient boosting algorithm combining score matching. We provide a theoretical analysis of learning and sampling for SSM to balance inference time and prediction accuracy. Via the ablation experiment in selected examples, we demonstrate the outstanding performances of the proposed techniques. Additionally, we compare our model with other probabilistic models, including Natural Gradient Boosting (NGboost), Classification and Regression Diffusion Models (CARD), Diffusion Boosted Trees (DBT), and Bayesian neural network-based models. The experimental results show that our model outperforms existing models in both accuracy and inference time.</li>
</ul>

<h3>Title: Prompt Tuning with Diffusion for Few-Shot Pre-trained Policy Generalization</h3>
<ul>
<li><strong>Authors: </strong>Shengchao Hu, Wanru Zhao, Weixiong Lin, Li Shen, Ya Zhang, Dacheng Tao</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.01168">https://arxiv.org/abs/2411.01168</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.01168">https://arxiv.org/pdf/2411.01168</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.01168]] Prompt Tuning with Diffusion for Few-Shot Pre-trained Policy Generalization(https://arxiv.org/abs/2411.01168)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, generative</a></li>
<li><strong>Abstract: </strong>Offline reinforcement learning (RL) methods harness previous experiences to derive an optimal policy, forming the foundation for pre-trained large-scale models (PLMs). When encountering tasks not seen before, PLMs often utilize several expert trajectories as prompts to expedite their adaptation to new requirements. Though a range of prompt-tuning methods have been proposed to enhance the quality of prompts, these methods often face optimization restrictions due to prompt initialization, which can significantly constrain the exploration domain and potentially lead to suboptimal solutions. To eliminate the reliance on the initial prompt, we shift our perspective towards the generative model, framing the prompt-tuning process as a form of conditional generative modeling, where prompts are generated from random noise. Our innovation, the Prompt Diffuser, leverages a conditional diffusion model to produce prompts of exceptional quality. Central to our framework is the approach to trajectory reconstruction and the meticulous integration of downstream task guidance during the training phase. Further experimental results underscore the potency of the Prompt Diffuser as a robust and effective tool for the prompt-tuning process, demonstrating strong performance in the meta-RL tasks.</li>
</ul>

<h3>Title: Fast and Memory-Efficient Video Diffusion Using Streamlined Inference</h3>
<ul>
<li><strong>Authors: </strong>Zheng Zhan, Yushu Wu, Yifan Gong, Zichong Meng, Zhenglun Kong, Changdi Yang, Geng Yuan, Pu Zhao, Wei Niu, Yanzhi Wang</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.01171">https://arxiv.org/abs/2411.01171</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.01171">https://arxiv.org/pdf/2411.01171</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.01171]] Fast and Memory-Efficient Video Diffusion Using Streamlined Inference(https://arxiv.org/abs/2411.01171)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>The rapid progress in artificial intelligence-generated content (AIGC), especially with diffusion models, has significantly advanced development of high-quality video generation. However, current video diffusion models exhibit demanding computational requirements and high peak memory usage, especially for generating longer and higher-resolution videos. These limitations greatly hinder the practical application of video diffusion models on standard hardware platforms. To tackle this issue, we present a novel, training-free framework named Streamlined Inference, which leverages the temporal and spatial properties of video diffusion models. Our approach integrates three core components: Feature Slicer, Operator Grouping, and Step Rehash. Specifically, Feature Slicer effectively partitions input features into sub-features and Operator Grouping processes each sub-feature with a group of consecutive operators, resulting in significant memory reduction without sacrificing the quality or speed. Step Rehash further exploits the similarity between adjacent steps in diffusion, and accelerates inference through skipping unnecessary steps. Extensive experiments demonstrate that our approach significantly reduces peak memory and computational overhead, making it feasible to generate high-quality videos on a single consumer GPU (e.g., reducing peak memory of AnimateDiff from 42GB to 11GB, featuring faster inference on 2080Ti).</li>
</ul>

<h3>Title: Hollowed Net for On-Device Personalization of Text-to-Image Diffusion Models</h3>
<ul>
<li><strong>Authors: </strong>Wonguk Cho, Seokeon Choi, Debasmit Das, Matthias Reisser, Taesup Kim, Sungrack Yun, Fatih Porikli</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI, cs.GR, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.01179">https://arxiv.org/abs/2411.01179</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.01179">https://arxiv.org/pdf/2411.01179</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.01179]] Hollowed Net for On-Device Personalization of Text-to-Image Diffusion Models(https://arxiv.org/abs/2411.01179)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>Recent advancements in text-to-image diffusion models have enabled the personalization of these models to generate custom images from textual prompts. This paper presents an efficient LoRA-based personalization approach for on-device subject-driven generation, where pre-trained diffusion models are fine-tuned with user-specific data on resource-constrained devices. Our method, termed Hollowed Net, enhances memory efficiency during fine-tuning by modifying the architecture of a diffusion U-Net to temporarily remove a fraction of its deep layers, creating a hollowed structure. This approach directly addresses on-device memory constraints and substantially reduces GPU memory requirements for training, in contrast to previous methods that primarily focus on minimizing training steps and reducing the number of parameters to update. Additionally, the personalized Hollowed Net can be transferred back into the original U-Net, enabling inference without additional memory overhead. Quantitative and qualitative analyses demonstrate that our approach not only reduces training memory to levels as low as those required for inference but also maintains or improves personalization performance compared to existing methods.</li>
</ul>

<h3>Title: Infinite-Resolution Integral Noise Warping for Diffusion Models</h3>
<ul>
<li><strong>Authors: </strong>Yitong Deng, Winnie Lin, Lingxiao Li, Dmitriy Smirnov, Ryan Burgert, Ning Yu, Vincent Dedun, Mohammad H. Taghavi</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI, cs.GR, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.01212">https://arxiv.org/abs/2411.01212</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.01212">https://arxiv.org/pdf/2411.01212</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.01212]] Infinite-Resolution Integral Noise Warping for Diffusion Models(https://arxiv.org/abs/2411.01212)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, generative</a></li>
<li><strong>Abstract: </strong>Adapting pretrained image-based diffusion models to generate temporally consistent videos has become an impactful generative modeling research direction. Training-free noise-space manipulation has proven to be an effective technique, where the challenge is to preserve the Gaussian white noise distribution while adding in temporal consistency. Recently, Chang et al. (2024) formulated this problem using an integral noise representation with distribution-preserving guarantees, and proposed an upsampling-based algorithm to compute it. However, while their mathematical formulation is advantageous, the algorithm incurs a high computational cost. Through analyzing the limiting-case behavior of their algorithm as the upsampling resolution goes to infinity, we develop an alternative algorithm that, by gathering increments of multiple Brownian bridges, achieves their infinite-resolution accuracy while simultaneously reducing the computational cost by orders of magnitude. We prove and experimentally validate our theoretical claims, and demonstrate our method's effectiveness in real-world applications. We further show that our method readily extends to the 3-dimensional space.</li>
</ul>

<h3>Title: Diversidade lingu\'istica e inclus\~ao digital: desafios para uma ia brasileira</h3>
<ul>
<li><strong>Authors: </strong>Raquel Meister Ko Freitag</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.CY</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.01259">https://arxiv.org/abs/2411.01259</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.01259">https://arxiv.org/pdf/2411.01259</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.01259]] Diversidade lingu\'istica e inclus\~ao digital: desafios para uma ia brasileira(https://arxiv.org/abs/2411.01259)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>Linguistic diversity is a human attribute which, with the advance of generative AIs, is coming under threat. This paper, based on the contributions of sociolinguistics, examines the consequences of the variety selection bias imposed by technological applications and the vicious circle of preserving a variety that becomes dominant and standardized because it has linguistic documentation to feed the large language models for machine learning.</li>
</ul>

<h3>Title: ProGen: Revisiting Probabilistic Spatial-Temporal Time Series Forecasting from a Continuous Generative Perspective Using Stochastic Differential Equations</h3>
<ul>
<li><strong>Authors: </strong>Mingze Gong, Lei Chen, Jia Li</a></li>
<li><strong>Subjects: </strong>cs.LG, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.01267">https://arxiv.org/abs/2411.01267</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.01267">https://arxiv.org/pdf/2411.01267</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.01267]] ProGen: Revisiting Probabilistic Spatial-Temporal Time Series Forecasting from a Continuous Generative Perspective Using Stochastic Differential Equations(https://arxiv.org/abs/2411.01267)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, generative</a></li>
<li><strong>Abstract: </strong>Accurate forecasting of spatiotemporal data remains challenging due to complex spatial dependencies and temporal dynamics. The inherent uncertainty and variability in such data often render deterministic models insufficient, prompting a shift towards probabilistic approaches, where diffusion-based generative models have emerged as effective solutions. In this paper, we present ProGen, a novel framework for probabilistic spatiotemporal time series forecasting that leverages Stochastic Differential Equations (SDEs) and diffusion-based generative modeling techniques in the continuous domain. By integrating a novel denoising score model, graph neural networks, and a tailored SDE, ProGen provides a robust solution that effectively captures spatiotemporal dependencies while managing uncertainty. Our extensive experiments on four benchmark traffic datasets demonstrate that ProGen outperforms state-of-the-art deterministic and probabilistic models. This work contributes a continuous, diffusion-based generative approach to spatiotemporal forecasting, paving the way for future research in probabilistic modeling and stochastic processes.</li>
</ul>

<h3>Title: Diffusion Models as Cartoonists! The Curious Case of High Density Regions</h3>
<ul>
<li><strong>Authors: </strong>Rafa≈Ç Karczewski, Markus Heinonen, Vikas Garg</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.01293">https://arxiv.org/abs/2411.01293</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.01293">https://arxiv.org/pdf/2411.01293</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.01293]] Diffusion Models as Cartoonists! The Curious Case of High Density Regions(https://arxiv.org/abs/2411.01293)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>We investigate what kind of images lie in the high-density regions of diffusion models. We introduce a theoretical mode-tracking process capable of pinpointing the exact mode of the denoising distribution, and we propose a practical high-probability sampler that consistently generates images of higher likelihood than usual samplers. Our empirical findings reveal the existence of significantly higher likelihood samples that typical samplers do not produce, often manifesting as cartoon-like drawings or blurry images depending on the noise level. Curiously, these patterns emerge in datasets devoid of such examples. We also present a novel approach to track sample likelihoods in diffusion SDEs, which remarkably incurs no additional computational cost.</li>
</ul>

<h3>Title: Marginal Causal Flows for Validation and Inference</h3>
<ul>
<li><strong>Authors: </strong>Daniel de Vassimon Manela, Laura Battaglia, Robin J. Evans</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, stat.ME, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.01295">https://arxiv.org/abs/2411.01295</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.01295">https://arxiv.org/pdf/2411.01295</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.01295]] Marginal Causal Flows for Validation and Inference(https://arxiv.org/abs/2411.01295)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>Investigating the marginal causal effect of an intervention on an outcome from complex data remains challenging due to the inflexibility of employed models and the lack of complexity in causal benchmark datasets, which often fail to reproduce intricate real-world data patterns. In this paper we introduce Frugal Flows, a novel likelihood-based machine learning model that uses normalising flows to flexibly learn the data-generating process, while also directly inferring the marginal causal quantities from observational data. We propose that these models are exceptionally well suited for generating synthetic data to validate causal methods. They can create synthetic datasets that closely resemble the empirical dataset, while automatically and exactly satisfying a user-defined average treatment effect. To our knowledge, Frugal Flows are the first generative model to both learn flexible data representations and also exactly parameterise quantities such as the average treatment effect and the degree of unobserved confounding. We demonstrate the above with experiments on both simulated and real-world datasets.</li>
</ul>

<h3>Title: Regret of exploratory policy improvement and $q$-learning</h3>
<ul>
<li><strong>Authors: </strong>Wenpin Tang, Xun Yu Zhou</a></li>
<li><strong>Subjects: </strong>cs.LG, math.OC, math.PR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.01302">https://arxiv.org/abs/2411.01302</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.01302">https://arxiv.org/pdf/2411.01302</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.01302]] Regret of exploratory policy improvement and $q$-learning(https://arxiv.org/abs/2411.01302)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>We study the convergence of $q$-learning and related algorithms introduced by Jia and Zhou (J. Mach. Learn. Res., 24 (2023), 161) for controlled diffusion processes. Under suitable conditions on the growth and regularity of the model parameters, we provide a quantitative error and regret analysis of both the exploratory policy improvement algorithm and the $q$-learning algorithm.</li>
</ul>

<h3>Title: FEET: A Framework for Evaluating Embedding Techniques</h3>
<ul>
<li><strong>Authors: </strong>Simon A. Lee, John Lee, Jeffrey N. Chiang</a></li>
<li><strong>Subjects: </strong>cs.LG, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.01322">https://arxiv.org/abs/2411.01322</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.01322">https://arxiv.org/pdf/2411.01322</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.01322]] FEET: A Framework for Evaluating Embedding Techniques(https://arxiv.org/abs/2411.01322)</code><input type="text"></li>
<li><strong>Keywords: </strong>foundation model</a></li>
<li><strong>Abstract: </strong>In this study, we introduce FEET, a standardized protocol designed to guide the development and benchmarking of foundation models. While numerous benchmark datasets exist for evaluating these models, we propose a structured evaluation protocol across three distinct scenarios to gain a comprehensive understanding of their practical performance. We define three primary use cases: frozen embeddings, few-shot embeddings, and fully fine-tuned embeddings. Each scenario is detailed and illustrated through two case studies: one in sentiment analysis and another in the medical domain, demonstrating how these evaluations provide a thorough assessment of foundation models' effectiveness in research applications. We recommend this protocol as a standard for future research aimed at advancing representation learning models.</li>
</ul>

<h3>Title: Generalized Eigenvalue Problems with Generative Priors</h3>
<ul>
<li><strong>Authors: </strong>Zhaoqiang Liu, Wen Li, Junren Chen</a></li>
<li><strong>Subjects: </strong>cs.LG, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.01326">https://arxiv.org/abs/2411.01326</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.01326">https://arxiv.org/pdf/2411.01326</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.01326]] Generalized Eigenvalue Problems with Generative Priors(https://arxiv.org/abs/2411.01326)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>Generalized eigenvalue problems (GEPs) find applications in various fields of science and engineering. For example, principal component analysis, Fisher's discriminant analysis, and canonical correlation analysis are specific instances of GEPs and are widely used in statistical data processing. In this work, we study GEPs under generative priors, assuming that the underlying leading generalized eigenvector lies within the range of a Lipschitz continuous generative model. Under appropriate conditions, we show that any optimal solution to the corresponding optimization problems attains the optimal statistical rate. Moreover, from a computational perspective, we propose an iterative algorithm called the Projected Rayleigh Flow Method (PRFM) to approximate the optimal solution. We theoretically demonstrate that under suitable assumptions, PRFM converges linearly to an estimated vector that achieves the optimal statistical rate. Numerical results are provided to demonstrate the effectiveness of the proposed method.</li>
</ul>

<h3>Title: Guided Synthesis of Labeled Brain MRI Data Using Latent Diffusion Models for Segmentation of Enlarged Ventricles</h3>
<ul>
<li><strong>Authors: </strong>Tim Ruschke, Jonathan Frederik Carlsen, Adam Espe Hansen, Ulrich Lindberg, Amalie Monberg Hindsholm, Martin Norgaard, Claes N√∏hr Ladefoged</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.01351">https://arxiv.org/abs/2411.01351</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.01351">https://arxiv.org/pdf/2411.01351</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.01351]] Guided Synthesis of Labeled Brain MRI Data Using Latent Diffusion Models for Segmentation of Enlarged Ventricles(https://arxiv.org/abs/2411.01351)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>Deep learning models in medical contexts face challenges like data scarcity, inhomogeneity, and privacy concerns. This study focuses on improving ventricular segmentation in brain MRI images using synthetic data. We employed two latent diffusion models (LDMs): a mask generator trained using 10,000 masks, and a corresponding SPADE image generator optimized using 6,881 scans to create an MRI conditioned on a 3D brain mask. Conditioning the mask generator on ventricular volume in combination with classifier-free guidance enabled the control of the ventricular volume distribution of the generated synthetic images. Next, the performance of the synthetic data was tested using three nnU-Net segmentation models trained on a real, augmented and entirely synthetic data, respectively. The resulting models were tested on a completely independent hold-out dataset of patients with enlarged ventricles, with manual delineation of the ventricles used as ground truth. The model trained on real data showed a mean absolute error (MAE) of 9.09 \pm 12.18 mL in predicted ventricular volume, while the models trained on synthetic and augmented data showed MAEs of 7.52 \pm 4.81 mL and 6.23 \pm 4.33 mL, respectively. Both the synthetic and augmented model also outperformed the state-of-the-art model SynthSeg, which due to limited performance in cases of large ventricular volumes, showed an MAE of 7.73 \pm 12.12 mL with a factor of 3 higher standard deviation. The model trained on augmented data showed the highest Dice score of 0.892 \pm 0.05, slightly outperforming SynthSeg and on par with the model trained on real data. The synthetic model performed similar to SynthSeg. In summary, we provide evidence that guided synthesis of labeled brain MRI data using LDMs improves the segmentation of enlarged ventricles and outperforms existing state-of-the-art segmentation models.</li>
</ul>

<h3>Title: Privacy-Preserving Customer Churn Prediction Model in the Context of Telecommunication Industry</h3>
<ul>
<li><strong>Authors: </strong>Joydeb Kumar Sana, M Sohel Rahman, M Saifur Rahman</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.01447">https://arxiv.org/abs/2411.01447</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.01447">https://arxiv.org/pdf/2411.01447</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.01447]] Privacy-Preserving Customer Churn Prediction Model in the Context of Telecommunication Industry(https://arxiv.org/abs/2411.01447)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>Data is the main fuel of a successful machine learning model. A dataset may contain sensitive individual records e.g. personal health records, financial data, industrial information, etc. Training a model using this sensitive data has become a new privacy concern when someone uses third-party cloud computing. Trained models also suffer privacy attacks which leads to the leaking of sensitive information of the training data. This study is conducted to preserve the privacy of training data in the context of customer churn prediction modeling for the telecommunications industry (TCI). In this work, we propose a framework for privacy-preserving customer churn prediction (PPCCP) model in the cloud environment. We have proposed a novel approach which is a combination of Generative Adversarial Networks (GANs) and adaptive Weight-of-Evidence (aWOE). Synthetic data is generated from GANs, and aWOE is applied on the synthetic training dataset before feeding the data to the classification algorithms. Our experiments were carried out using eight different machine learning (ML) classifiers on three openly accessible datasets from the telecommunication sector. We then evaluated the performance using six commonly employed evaluation metrics. In addition to presenting a data privacy analysis, we also performed a statistical significance test. The training and prediction processes achieve data privacy and the prediction classifiers achieve high prediction performance (87.1\% in terms of F-Measure for GANs-aWOE based Na\"ƒ±ve Bayes model). In contrast to earlier studies, our suggested approach demonstrates a prediction enhancement of up to 28.9\% and 27.9\% in terms of accuracy and F-measure, respectively.</li>
</ul>

<h3>Title: Two-Timescale Model Caching and Resource Allocation for Edge-Enabled AI-Generated Content Services</h3>
<ul>
<li><strong>Authors: </strong>Zhang Liu, Hongyang Du, Xiangwang Hou, Lianfen Huang, Seyyedali Hosseinalipour, Dusit Niyato, Khaled Ben Letaief</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.DC</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.01458">https://arxiv.org/abs/2411.01458</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.01458">https://arxiv.org/pdf/2411.01458</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.01458]] Two-Timescale Model Caching and Resource Allocation for Edge-Enabled AI-Generated Content Services(https://arxiv.org/abs/2411.01458)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, generative</a></li>
<li><strong>Abstract: </strong>Generative AI (GenAI) has emerged as a transformative technology, enabling customized and personalized AI-generated content (AIGC) services. In this paper, we address challenges of edge-enabled AIGC service provisioning, which remain underexplored in the literature. These services require executing GenAI models with billions of parameters, posing significant obstacles to resource-limited wireless edge. We subsequently introduce the formulation of joint model caching and resource allocation for AIGC services to balance a trade-off between AIGC quality and latency metrics. We obtain mathematical relationships of these metrics with the computational resources required by GenAI models via experimentation. Afterward, we decompose the formulation into a model caching subproblem on a long-timescale and a resource allocation subproblem on a short-timescale. Since the variables to be solved are discrete and continuous, respectively, we leverage a double deep Q-network (DDQN) algorithm to solve the former subproblem and propose a diffusion-based deep deterministic policy gradient (D3PG) algorithm to solve the latter. The proposed D3PG algorithm makes an innovative use of diffusion models as the actor network to determine optimal resource allocation decisions. Consequently, we integrate these two learning methods within the overarching two-timescale deep reinforcement learning (T2DRL) algorithm, the performance of which is studied through comparative numerical simulations.</li>
</ul>

<h3>Title: DPCL-Diff: The Temporal Knowledge Graph Reasoning based on Graph Node Diffusion Model with Dual-Domain Periodic Contrastive Learning</h3>
<ul>
<li><strong>Authors: </strong>Yukun Cao, Lisheng Wang, Luobing Huang</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.01477">https://arxiv.org/abs/2411.01477</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.01477">https://arxiv.org/pdf/2411.01477</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.01477]] DPCL-Diff: The Temporal Knowledge Graph Reasoning based on Graph Node Diffusion Model with Dual-Domain Periodic Contrastive Learning(https://arxiv.org/abs/2411.01477)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, generative</a></li>
<li><strong>Abstract: </strong>Temporal knowledge graph (TKG) reasoning that infers future missing facts is an essential and challenging task. Predicting future events typically relies on closely related historical facts, yielding more accurate results for repetitive or periodic events. However, for future events with sparse historical interactions, the effectiveness of this method, which focuses on leveraging high-frequency historical information, diminishes. Recently, the capabilities of diffusion models in image generation have opened new opportunities for TKG reasoning. Therefore, we propose a graph node diffusion model with dual-domain periodic contrastive learning (DPCL-Diff). Graph node diffusion model (GNDiff) introduces noise into sparsely related events to simulate new events, generating high-quality data that better conforms to the actual distribution. This generative mechanism significantly enhances the model's ability to reason about new events. Additionally, the dual-domain periodic contrastive learning (DPCL) maps periodic and non-periodic event entities to Poincar√© and Euclidean spaces, leveraging their characteristics to distinguish similar periodic events effectively. Experimental results on four public datasets demonstrate that DPCL-Diff significantly outperforms state-of-the-art TKG models in event prediction, demonstrating our approach's effectiveness. This study also investigates the combined effectiveness of GNDiff and DPCL in TKG tasks.</li>
</ul>

<h3>Title: Anomalous Client Detection in Federated Learning</h3>
<ul>
<li><strong>Authors: </strong>Dipanwita Thakur, Antonella Guzzo, Giancarlo Fortino</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CR, cs.DC</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.01490">https://arxiv.org/abs/2411.01490</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.01490">https://arxiv.org/pdf/2411.01490</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.01490]] Anomalous Client Detection in Federated Learning(https://arxiv.org/abs/2411.01490)</code><input type="text"></li>
<li><strong>Keywords: </strong>anomaly</a></li>
<li><strong>Abstract: </strong>Federated learning (FL), with the growing IoT and edge computing, is seen as a promising solution for applications that are latency- and privacy-aware. However, due to the widespread dispersion of data across many clients, it is challenging to monitor client anomalies caused by malfunctioning devices or unexpected events. The majority of FL solutions now in use concentrate on the classification problem, ignoring situations in which anomaly detection may also necessitate privacy preservation and effectiveness. The system in federated learning is unable to manage the potentially flawed behavior of its clients completely. These behaviors include sharing arbitrary parameter values and causing a delay in convergence since clients are chosen at random without knowing the malfunctioning behavior of the client. Client selection is crucial in terms of the efficiency of the federated learning framework. The challenges such as client drift and handling slow clients with low computational capability are well-studied in FL. However, the detection of anomalous clients either for security or for overall performance in the FL frameworks is hardly studied in the literature. In this paper, we propose an anomaly client detection algorithm to overcome malicious client attacks and client drift in FL frameworks. Instead of random client selection, our proposed method utilizes anomaly client detection to remove clients from the FL framework, thereby enhancing the security and efficiency of the overall system. This proposed method improves the global model convergence in almost 50\% fewer communication rounds compared with widely used random client selection using the MNIST dataset.</li>
</ul>

<h3>Title: EEE-Bench: A Comprehensive Multimodal Electrical And Electronics Engineering Benchmark</h3>
<ul>
<li><strong>Authors: </strong>Ming Li, Jike Zhong, Tianle Chen, Yuxiang Lai, Konstantinos Psounis</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.01492">https://arxiv.org/abs/2411.01492</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.01492">https://arxiv.org/pdf/2411.01492</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.01492]] EEE-Bench: A Comprehensive Multimodal Electrical And Electronics Engineering Benchmark(https://arxiv.org/abs/2411.01492)</code><input type="text"></li>
<li><strong>Keywords: </strong>foundation model</a></li>
<li><strong>Abstract: </strong>Recent studies on large language models (LLMs) and large multimodal models (LMMs) have demonstrated promising skills in various domains including science and mathematics. However, their capability in more challenging and real-world related scenarios like engineering has not been systematically studied. To bridge this gap, we propose EEE-Bench, a multimodal benchmark aimed at assessing LMMs' capabilities in solving practical engineering tasks, using electrical and electronics engineering (EEE) as the testbed. Our benchmark consists of 2860 carefully curated problems spanning 10 essential subdomains such as analog circuits, control systems, etc. Compared to benchmarks in other domains, engineering problems are intrinsically 1) more visually complex and versatile and 2) less deterministic in solutions. Successful solutions to these problems often demand more-than-usual rigorous integration of visual and textual information as models need to understand intricate images like abstract circuits and system diagrams while taking professional instructions, making them excellent candidates for LMM evaluations. Alongside EEE-Bench, we provide extensive quantitative evaluations and fine-grained analysis of 17 widely-used open and closed-sourced LLMs and LMMs. Our results demonstrate notable deficiencies of current foundation models in EEE, with an average performance ranging from 19.48% to 46.78%. Finally, we reveal and explore a critical shortcoming in LMMs which we term laziness: the tendency to take shortcuts by relying on the text while overlooking the visual context when reasoning for technical image problems. In summary, we believe EEE-Bench not only reveals some noteworthy limitations of LMMs but also provides a valuable resource for advancing research on their application in practical engineering tasks, driving future improvements in their capability to handle complex, real-world scenarios.</li>
</ul>

<h3>Title: Towards Small Object Editing: A Benchmark Dataset and A Training-Free Approach</h3>
<ul>
<li><strong>Authors: </strong>Qihe Pan, Zhen Zhao, Zicheng Wang, Sifan Long, Yiming Wu, Wei Ji, Haoran Liang, Ronghua Liang</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.01545">https://arxiv.org/abs/2411.01545</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.01545">https://arxiv.org/pdf/2411.01545</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.01545]] Towards Small Object Editing: A Benchmark Dataset and A Training-Free Approach(https://arxiv.org/abs/2411.01545)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, generative</a></li>
<li><strong>Abstract: </strong>A plethora of text-guided image editing methods has recently been developed by leveraging the impressive capabilities of large-scale diffusion-based generative models especially Stable Diffusion. Despite the success of diffusion models in producing high-quality images, their application to small object generation has been limited due to difficulties in aligning cross-modal attention maps between text and these objects. Our approach offers a training-free method that significantly mitigates this alignment issue with local and global attention guidance , enhancing the model's ability to accurately render small objects in accordance with textual descriptions. We detail the methodology in our approach, emphasizing its divergence from traditional generation techniques and highlighting its advantages. What's more important is that we also provide~\textit{SOEBench} (Small Object Editing), a standardized benchmark for quantitatively evaluating text-based small object generation collected from \textit{MSCOCO} and \textit{OpenImage}. Preliminary results demonstrate the effectiveness of our method, showing marked improvements in the fidelity and accuracy of small object generation compared to existing models. This advancement not only contributes to the field of AI and computer vision but also opens up new possibilities for applications in various industries where precise image generation is critical. We will release our dataset on our project page: \href{this https URL}{this https URL}.</li>
</ul>

<h3>Title: Conditional Controllable Image Fusion</h3>
<ul>
<li><strong>Authors: </strong>Bing Cao, Xingxin Xu, Pengfei Zhu, Qilong Wang, Qinghua Hu</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.LG, eess.IV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.01573">https://arxiv.org/abs/2411.01573</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.01573">https://arxiv.org/pdf/2411.01573</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.01573]] Conditional Controllable Image Fusion(https://arxiv.org/abs/2411.01573)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, generative</a></li>
<li><strong>Abstract: </strong>Image fusion aims to integrate complementary information from multiple input images acquired through various sources to synthesize a new fused image. Existing methods usually employ distinct constraint designs tailored to specific scenes, forming fixed fusion paradigms. However, this data-driven fusion approach is challenging to deploy in varying scenarios, especially in rapidly changing environments. To address this issue, we propose a conditional controllable fusion (CCF) framework for general image fusion tasks without specific training. Due to the dynamic differences of different samples, our CCF employs specific fusion constraints for each individual in practice. Given the powerful generative capabilities of the denoising diffusion model, we first inject the specific constraints into the pre-trained DDPM as adaptive fusion conditions. The appropriate conditions are dynamically selected to ensure the fusion process remains responsive to the specific requirements in each reverse diffusion stage. Thus, CCF enables conditionally calibrating the fused images step by step. Extensive experiments validate our effectiveness in general fusion tasks across diverse scenarios against the competing methods without additional training.</li>
</ul>

<h3>Title: DreamPolish: Domain Score Distillation With Progressive Geometry Generation</h3>
<ul>
<li><strong>Authors: </strong>Yean Cheng, Ziqi Cai, Ming Ding, Wendi Zheng, Shiyu Huang, Yuxiao Dong, Jie Tang, Boxin Shi</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.01602">https://arxiv.org/abs/2411.01602</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.01602">https://arxiv.org/pdf/2411.01602</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.01602]] DreamPolish: Domain Score Distillation With Progressive Geometry Generation(https://arxiv.org/abs/2411.01602)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>We introduce DreamPolish, a text-to-3D generation model that excels in producing refined geometry and high-quality textures. In the geometry construction phase, our approach leverages multiple neural representations to enhance the stability of the synthesis process. Instead of relying solely on a view-conditioned diffusion prior in the novel sampled views, which often leads to undesired artifacts in the geometric surface, we incorporate an additional normal estimator to polish the geometry details, conditioned on viewpoints with varying field-of-views. We propose to add a surface polishing stage with only a few training steps, which can effectively refine the artifacts attributed to limited guidance from previous stages and produce 3D objects with more desirable geometry. The key topic of texture generation using pretrained text-to-image models is to find a suitable domain in the vast latent distribution of these models that contains photorealistic and consistent renderings. In the texture generation phase, we introduce a novel score distillation objective, namely domain score distillation (DSD), to guide neural representations toward such a domain. We draw inspiration from the classifier-free guidance (CFG) in textconditioned image generation tasks and show that CFG and variational distribution guidance represent distinct aspects in gradient guidance and are both imperative domains for the enhancement of texture quality. Extensive experiments show our proposed model can produce 3D assets with polished surfaces and photorealistic textures, outperforming existing state-of-the-art methods.</li>
</ul>

<h3>Title: VQ-Map: Bird's-Eye-View Map Layout Estimation in Tokenized Discrete Space via Vector Quantization</h3>
<ul>
<li><strong>Authors: </strong>Yiwei Zhang, Jin Gao, Fudong Ge, Guan Luo, Bing Li, Zhaoxiang Zhang, Haibin Ling, Weiming Hu</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.01618">https://arxiv.org/abs/2411.01618</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.01618">https://arxiv.org/pdf/2411.01618</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.01618]] VQ-Map: Bird's-Eye-View Map Layout Estimation in Tokenized Discrete Space via Vector Quantization(https://arxiv.org/abs/2411.01618)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>Bird's-eye-view (BEV) map layout estimation requires an accurate and full understanding of the semantics for the environmental elements around the ego car to make the results coherent and realistic. Due to the challenges posed by occlusion, unfavourable imaging conditions and low resolution, \emph{generating} the BEV semantic maps corresponding to corrupted or invalid areas in the perspective view (PV) is appealing very recently. \emph{The question is how to align the PV features with the generative models to facilitate the map estimation}. In this paper, we propose to utilize a generative model similar to the Vector Quantized-Variational AutoEncoder (VQ-VAE) to acquire prior knowledge for the high-level BEV semantics in the tokenized discrete space. Thanks to the obtained BEV tokens accompanied with a codebook embedding encapsulating the semantics for different BEV elements in the groundtruth maps, we are able to directly align the sparse backbone image features with the obtained BEV tokens from the discrete representation learning based on a specialized token decoder module, and finally generate high-quality BEV maps with the BEV codebook embedding serving as a bridge between PV and BEV. We evaluate the BEV map layout estimation performance of our model, termed VQ-Map, on both the nuScenes and Argoverse benchmarks, achieving 62.2/47.6 mean IoU for surround-view/monocular evaluation on nuScenes, as well as 73.4 IoU for monocular evaluation on Argoverse, which all set a new record for this map layout estimation task. The code and models are available on \url{this https URL}.</li>
</ul>

<h3>Title: Optical Flow Representation Alignment Mamba Diffusion Model for Medical Video Generation</h3>
<ul>
<li><strong>Authors: </strong>Zhenbin Wang, Lei Zhang, Lituan Wang, Minjuan Zhu, Zhenwei Zhang</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.01647">https://arxiv.org/abs/2411.01647</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.01647">https://arxiv.org/pdf/2411.01647</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.01647]] Optical Flow Representation Alignment Mamba Diffusion Model for Medical Video Generation(https://arxiv.org/abs/2411.01647)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>Medical video generation models are expected to have a profound impact on the healthcare industry, including but not limited to medical education and training, surgical planning, and simulation. Current video diffusion models typically build on image diffusion architecture by incorporating temporal operations (such as 3D convolution and temporal attention). Although this approach is effective, its oversimplification limits spatio-temporal performance and consumes substantial computational resources. To counter this, we propose Medical Simulation Video Generator (MedSora), which incorporates three key elements: i) a video diffusion framework integrates the advantages of attention and Mamba, balancing low computational load with high-quality video generation, ii) an optical flow representation alignment method that implicitly enhances attention to inter-frame pixels, and iii) a video variational autoencoder (VAE) with frequency compensation addresses the information loss of medical features that occurs when transforming pixel space into latent features and then back to pixel frames. Extensive experiments and applications demonstrate that MedSora exhibits superior visual quality in generating medical videos, outperforming the most advanced baseline methods. Further results and code are available at this https URL</li>
</ul>

<h3>Title: GraphXForm: Graph transformer for computer-aided molecular design with application to extraction</h3>
<ul>
<li><strong>Authors: </strong>Jonathan Pirnay, Jan G. Rittig, Alexander B. Wolf, Martin Grohe, Jakob Burger, Alexander Mitsos, Dominik G. Grimm</a></li>
<li><strong>Subjects: </strong>cs.LG, physics.chem-ph, q-bio.BM</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.01667">https://arxiv.org/abs/2411.01667</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.01667">https://arxiv.org/pdf/2411.01667</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.01667]] GraphXForm: Graph transformer for computer-aided molecular design with application to extraction(https://arxiv.org/abs/2411.01667)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>Generative deep learning has become pivotal in molecular design for drug discovery and materials science. A widely used paradigm is to pretrain neural networks on string representations of molecules and fine-tune them using reinforcement learning on specific objectives. However, string-based models face challenges in ensuring chemical validity and enforcing structural constraints like the presence of specific substructures. We propose to instead combine graph-based molecular representations, which can naturally ensure chemical validity, with transformer architectures, which are highly expressive and capable of modeling long-range dependencies between atoms. Our approach iteratively modifies a molecular graph by adding atoms and bonds, which ensures chemical validity and facilitates the incorporation of structural constraints. We present GraphXForm, a decoder-only graph transformer architecture, which is pretrained on existing compounds and then fine-tuned using a new training algorithm that combines elements of the deep cross-entropy method with self-improvement learning from language modeling, allowing stable fine-tuning of deep transformers with many layers. We evaluate GraphXForm on two solvent design tasks for liquid-liquid extraction, showing that it outperforms four state-of-the-art molecular design techniques, while it can flexibly enforce structural constraints or initiate the design from existing molecular structures.</li>
</ul>

<h3>Title: Robust Neural Processes for Noisy Data</h3>
<ul>
<li><strong>Authors: </strong>Chen Shapira, Dan Rosenbaum</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.01670">https://arxiv.org/abs/2411.01670</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.01670">https://arxiv.org/pdf/2411.01670</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.01670]] Robust Neural Processes for Noisy Data(https://arxiv.org/abs/2411.01670)</code><input type="text"></li>
<li><strong>Keywords: </strong>in-context</a></li>
<li><strong>Abstract: </strong>Models that adapt their predictions based on some given contexts, also known as in-context learning, have become ubiquitous in recent years. We propose to study the behavior of such models when data is contaminated by noise. Towards this goal we use the Neural Processes (NP) framework, as a simple and rigorous way to learn a distribution over functions, where predictions are based on a set of context points. Using this framework, we find that the models that perform best on clean data, are different than the models that perform best on noisy data. Specifically, models that process the context using attention, are more severely affected by noise, leading to in-context overfitting. We propose a simple method to train NP models that makes them more robust to noisy data. Experiments on 1D functions and 2D image datasets demonstrate that our method leads to models that outperform all other NP models for all noise levels.</li>
</ul>

<h3>Title: Rethinking Weight Decay for Robust Fine-Tuning of Foundation Models</h3>
<ul>
<li><strong>Authors: </strong>Junjiao Tian, Chengyue Huang, Zsolt Kira</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CL, cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.01713">https://arxiv.org/abs/2411.01713</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.01713">https://arxiv.org/pdf/2411.01713</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.01713]] Rethinking Weight Decay for Robust Fine-Tuning of Foundation Models(https://arxiv.org/abs/2411.01713)</code><input type="text"></li>
<li><strong>Keywords: </strong>foundation model</a></li>
<li><strong>Abstract: </strong>Modern optimizers such as AdamW, equipped with momentum and adaptive learning rate, are designed to escape local minima and explore the vast parameter space. This exploration is beneficial for finding good loss basins when training from scratch. It is not necessarily ideal when resuming from a powerful foundation model because it can lead to large deviations from the pre-trained initialization and, consequently, worse robustness and generalization. At the same time, strong regularization on all parameters can lead to under-fitting. We hypothesize that selectively regularizing the parameter space is the key to fitting and retraining the pre-trained knowledge. This paper proposes a new weight decay technique, Selective Projection Decay (SPD), that selectively imposes a strong penalty on certain layers while allowing others to change freely. Intuitively, SPD expands and contracts the parameter search space for layers with consistent and inconsistent loss reduction, respectively. Experimentally, when equipped with SPD, Adam consistently provides better in-distribution generalization and out-of-distribution robustness performance on multiple popular vision and language benchmarks. Code available at~\url{this https URL}</li>
</ul>

<h3>Title: Data Augmentations Go Beyond Encoding Invariances: A Theoretical Study on Self-Supervised Learning</h3>
<ul>
<li><strong>Authors: </strong>Shlomo Libo Feigin, Maximilian Fleissner, Debarghya Ghoshdastidar</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.01767">https://arxiv.org/abs/2411.01767</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.01767">https://arxiv.org/pdf/2411.01767</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.01767]] Data Augmentations Go Beyond Encoding Invariances: A Theoretical Study on Self-Supervised Learning(https://arxiv.org/abs/2411.01767)</code><input type="text"></li>
<li><strong>Keywords: </strong>self-supervised</a></li>
<li><strong>Abstract: </strong>Understanding the role of data augmentations is critical for applying Self-Supervised Learning (SSL) methods in new domains. Data augmentations are commonly understood as encoding invariances into the learned representations. This interpretation suggests that SSL would require diverse augmentations that resemble the original data. However, in practice, augmentations do not need to be similar to the original data nor be diverse, and can be neither at the same time. We provide a theoretical insight into this phenomenon. We show that for different SSL losses, any non-redundant representation can be learned with a single suitable augmentation. We provide an algorithm to reconstruct such augmentations and give insights into augmentation choices in SSL.</li>
</ul>

<h3>Title: Learning predictable and robust neural representations by straightening image sequences</h3>
<ul>
<li><strong>Authors: </strong>Xueyan Niu, Cristina Savin, Eero P. Simoncelli</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.01777">https://arxiv.org/abs/2411.01777</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.01777">https://arxiv.org/pdf/2411.01777</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.01777]] Learning predictable and robust neural representations by straightening image sequences(https://arxiv.org/abs/2411.01777)</code><input type="text"></li>
<li><strong>Keywords: </strong>self-supervised</a></li>
<li><strong>Abstract: </strong>Prediction is a fundamental capability of all living organisms, and has been proposed as an objective for learning sensory representations. Recent work demonstrates that in primate visual systems, prediction is facilitated by neural representations that follow straighter temporal trajectories than their initial photoreceptor encoding, which allows for prediction by linear extrapolation. Inspired by these experimental findings, we develop a self-supervised learning (SSL) objective that explicitly quantifies and promotes straightening. We demonstrate the power of this objective in training deep feedforward neural networks on smoothly-rendered synthetic image sequences that mimic commonly-occurring properties of natural videos. The learned model contains neural embeddings that are predictive, but also factorize the geometric, photometric, and semantic attributes of objects. The representations also prove more robust to noise and adversarial attacks compared to previous SSL methods that optimize for invariance to random augmentations. Moreover, these beneficial properties can be transferred to other training procedures by using the straightening objective as a regularizer, suggesting a broader utility for straightening as a principle for robust unsupervised learning.</li>
</ul>

<h3>Title: High-Pass Graph Convolutional Network for Enhanced Anomaly Detection: A Novel Approach</h3>
<ul>
<li><strong>Authors: </strong>Shelei Li, Yong Chai Tan, Tai Vincent</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.01817">https://arxiv.org/abs/2411.01817</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.01817">https://arxiv.org/pdf/2411.01817</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.01817]] High-Pass Graph Convolutional Network for Enhanced Anomaly Detection: A Novel Approach(https://arxiv.org/abs/2411.01817)</code><input type="text"></li>
<li><strong>Keywords: </strong>anomaly</a></li>
<li><strong>Abstract: </strong>Graph Convolutional Network (GCN) are widely used in Graph Anomaly Detection (GAD) due to their natural compatibility with graph structures, resulting in significant performance improvements. However, most researchers approach GAD as a graph node classification task and often rely on low-pass filters or feature aggregation from neighboring nodes. This paper proposes a novel approach by introducing a High-Pass Graph Convolution Network (HP-GCN) for GAD. The proposed HP-GCN leverages high-frequency components to detect anomalies, as anomalies tend to increase high-frequency signals within the network of normal nodes. Additionally, isolated nodes, which lack interactions with other nodes, present a challenge for Graph Neural Network (GNN). To address this, the model segments the graph into isolated nodes and nodes within connected subgraphs. Isolated nodes learn their features through Multi-Layer Perceptron (MLP), enhancing detection accuracy. The model is evaluated and validated on YelpChi, Amazon, T-Finance, and T-Social datasets. The results showed that the proposed HP-GCN can achieve anomaly detection accuracy of 96.10%, 98.16%, 96.46%, and 98.94%, respectively. The findings demonstrate that the HP-GCN outperforms existing GAD methods based on spatial domain GNN as well as those using low-pass and band-pass filters in spectral domain GCN. The findings underscore the effectiveness of this method in improving anomaly detection performance. Source code can be found at: this https URL.</li>
</ul>

<h3>Title: DiffuMask-Editor: A Novel Paradigm of Integration Between the Segmentation Diffusion Model and Image Editing to Improve Segmentation Ability</h3>
<ul>
<li><strong>Authors: </strong>Bo Gao, Fangxu Xing, Daniel Tang</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.01819">https://arxiv.org/abs/2411.01819</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.01819">https://arxiv.org/pdf/2411.01819</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.01819]] DiffuMask-Editor: A Novel Paradigm of Integration Between the Segmentation Diffusion Model and Image Editing to Improve Segmentation Ability(https://arxiv.org/abs/2411.01819)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>Semantic segmentation models, like mask2former, often demand a substantial amount of manually annotated data, which is time-consuming and inefficient to acquire. Leveraging state-of-the-art text-to-image models like Midjourney and Stable Diffusion has emerged as an effective strategy for automatically generating synthetic data instead of human annotations. However, prior approaches have been constrained to synthesizing single-instance images due to the instability inherent in generating multiple instances with Stable Diffusion. To expand the domains and diversity of synthetic datasets, this paper introduces a novel paradigm named DiffuMask-Editor, which combines the Diffusion Model for Segmentation with Image Editing. By integrating multiple objects into images using Text2Image models, our method facilitates the creation of more realistic datasets that closely resemble open-world settings while simultaneously generating accurate masks. Our approach significantly reduces the laborious effort associated with manual annotation while ensuring precise mask generation. Experimental results demonstrate that synthetic data generated by DiffuMask-Editor enable segmentation methods to achieve superior performance compared to real data. Particularly in zero-shot backgrounds, DiffuMask-Editor achieves new state-of-the-art results on Unseen classes of VOC 2012. The code and models will be publicly available soon.</li>
</ul>

<h3>Title: OwMatch: Conditional Self-Labeling with Consistency for Open-World Semi-Supervised Learning</h3>
<ul>
<li><strong>Authors: </strong>Shengjie Niu, Lifan Lin, Jian Huang, Chao Wang</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CV, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.01833">https://arxiv.org/abs/2411.01833</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.01833">https://arxiv.org/pdf/2411.01833</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.01833]] OwMatch: Conditional Self-Labeling with Consistency for Open-World Semi-Supervised Learning(https://arxiv.org/abs/2411.01833)</code><input type="text"></li>
<li><strong>Keywords: </strong>self-supervised</a></li>
<li><strong>Abstract: </strong>Semi-supervised learning (SSL) offers a robust framework for harnessing the potential of unannotated data. Traditionally, SSL mandates that all classes possess labeled instances. However, the emergence of open-world SSL (OwSSL) introduces a more practical challenge, wherein unlabeled data may encompass samples from unseen classes. This scenario leads to misclassification of unseen classes as known ones, consequently undermining classification accuracy. To overcome this challenge, this study revisits two methodologies from self-supervised and semi-supervised learning, self-labeling and consistency, tailoring them to address the OwSSL problem. Specifically, we propose an effective framework called OwMatch, combining conditional self-labeling and open-world hierarchical thresholding. Theoretically, we analyze the estimation of class distribution on unlabeled data through rigorous statistical analysis, thus demonstrating that OwMatch can ensure the unbiasedness of the self-label assignment estimator with reliability. Comprehensive empirical analyses demonstrate that our method yields substantial performance enhancements across both known and unknown classes in comparison to previous studies. Code is available at this https URL.</li>
</ul>

<h3>Title: ElasTST: Towards Robust Varied-Horizon Forecasting with Elastic Time-Series Transformer</h3>
<ul>
<li><strong>Authors: </strong>Jiawen Zhang, Shun Zheng, Xumeng Wen, Xiaofang Zhou, Jiang Bian, Jia Li</a></li>
<li><strong>Subjects: </strong>cs.LG, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.01842">https://arxiv.org/abs/2411.01842</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.01842">https://arxiv.org/pdf/2411.01842</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.01842]] ElasTST: Towards Robust Varied-Horizon Forecasting with Elastic Time-Series Transformer(https://arxiv.org/abs/2411.01842)</code><input type="text"></li>
<li><strong>Keywords: </strong>foundation model</a></li>
<li><strong>Abstract: </strong>Numerous industrial sectors necessitate models capable of providing robust forecasts across various horizons. Despite the recent strides in crafting specific architectures for time-series forecasting and developing pre-trained universal models, a comprehensive examination of their capability in accommodating varied-horizon forecasting during inference is still lacking. This paper bridges this gap through the design and evaluation of the Elastic Time-Series Transformer (ElasTST). The ElasTST model incorporates a non-autoregressive design with placeholders and structured self-attention masks, warranting future outputs that are invariant to adjustments in inference horizons. A tunable version of rotary position embedding is also integrated into ElasTST to capture time-series-specific periods and enhance adaptability to different horizons. Additionally, ElasTST employs a multi-scale patch design, effectively integrating both fine-grained and coarse-grained information. During the training phase, ElasTST uses a horizon reweighting strategy that approximates the effect of random sampling across multiple horizons with a single fixed horizon setting. Through comprehensive experiments and comparisons with state-of-the-art time-series architectures and contemporary foundation models, we demonstrate the efficacy of ElasTST's unique design elements. Our findings position ElasTST as a robust solution for the practical necessity of varied-horizon forecasting.</li>
</ul>

<h3>Title: Masked Autoencoders are Parameter-Efficient Federated Continual Learners</h3>
<ul>
<li><strong>Authors: </strong>Yuchen He, Xiangfeng Wang</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.01916">https://arxiv.org/abs/2411.01916</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.01916">https://arxiv.org/pdf/2411.01916</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.01916]] Masked Autoencoders are Parameter-Efficient Federated Continual Learners(https://arxiv.org/abs/2411.01916)</code><input type="text"></li>
<li><strong>Keywords: </strong>self-supervised</a></li>
<li><strong>Abstract: </strong>Federated learning is a specific distributed learning paradigm in which a central server aggregates updates from multiple clients' local models, thereby enabling the server to learn without requiring clients to upload their private data, maintaining data privacy. While existing federated learning methods are primarily designed for static data, real-world applications often require clients to learn new categories over time. This challenge necessitates the integration of continual learning techniques, resulting in federated continual learning (FCL). Although advanced prompt-based continual learning methods leverage pre-trained transformers to mitigate catastrophic forgetting, they do not adequately address the non-IID challenges in federated learning. To address both catastrophic forgetting and non-IID issues, we propose to use masked autoencoders (MAEs) as parameter-efficient federated continual learners, called pMAE. pMAE learns reconstructive prompt on the client side through image reconstruction using MAEs. On the server side, it reconstructs the uploaded restore information to capture the data distribution across previous tasks and different clients, using these reconstructed images to finetune discriminative prompt and classifier parameters designed for classification, thereby alleviating catastrophic forgetting and non-IID challenges on a global scale. Experimental results demonstrate that pMAE achieves performance comparable to existing prompt-based methods and can enhance their effectiveness, particularly when using self-supervised pre-trained transformers as the backbone. Code is available at: this https URL.</li>
</ul>

<h3>Title: Exploring the Landscape for Generative Sequence Models for Specialized Data Synthesis</h3>
<ul>
<li><strong>Authors: </strong>Mohammad Zbeeb, Mohammad Ghorayeb, Mariam Salman</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.01929">https://arxiv.org/abs/2411.01929</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.01929">https://arxiv.org/pdf/2411.01929</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.01929]] Exploring the Landscape for Generative Sequence Models for Specialized Data Synthesis(https://arxiv.org/abs/2411.01929)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>Artificial Intelligence (AI) research often aims to develop models that generalize reliably across complex datasets, yet this remains challenging in fields where data is scarce, intricate, or inaccessible. This paper introduces a novel approach leveraging three generative models of varying complexity to synthesize one of the most demanding structured datasets: Malicious Network Traffic. Our approach transforms numerical data into text, reframing data generation as a language modeling task, which enhances data regularization and significantly improves generalization and the quality of the synthetic data. Extensive statistical analyses demonstrate that our method surpasses state-of-the-art generative models in producing high-fidelity synthetic data. Additionally, we conduct a comprehensive study on synthetic data applications, effectiveness, and evaluation strategies, offering valuable insights into its role across various domains. Our code and pre-trained models are openly accessible at this https URL, enabling further exploration and application of our methodology. Index Terms: Data synthesis, machine learning, traffic generation, privacy-preserving data, generative models.</li>
</ul>

<h3>Title: N-Gram Induction Heads for In-Context RL: Improving Stability and Reducing Data Needs</h3>
<ul>
<li><strong>Authors: </strong>Ilya Zisman, Alexander Nikulin, Andrei Polubarov, Nikita Lyubaykin, Vladislav Kurenkov</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.01958">https://arxiv.org/abs/2411.01958</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.01958">https://arxiv.org/pdf/2411.01958</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.01958]] N-Gram Induction Heads for In-Context RL: Improving Stability and Reducing Data Needs(https://arxiv.org/abs/2411.01958)</code><input type="text"></li>
<li><strong>Keywords: </strong>in-context</a></li>
<li><strong>Abstract: </strong>In-context learning allows models like transformers to adapt to new tasks from a few examples without updating their weights, a desirable trait for reinforcement learning (RL). However, existing in-context RL methods, such as Algorithm Distillation (AD), demand large, carefully curated datasets and can be unstable and costly to train due to the transient nature of in-context learning abilities. In this work we integrated the n-gram induction heads into transformers for in-context RL. By incorporating these n-gram attention patterns, we significantly reduced the data required for generalization - up to 27 times fewer transitions in the Key-to-Door environment - and eased the training process by making models less sensitive to hyperparameters. Our approach not only matches but often surpasses the performance of AD, demonstrating the potential of n-gram induction heads to enhance the efficiency of in-context RL.</li>
</ul>

<h3>Title: Active Gaze Behavior Boosts Self-Supervised Object Learning</h3>
<ul>
<li><strong>Authors: </strong>Zhengyang Yu, Arthur Aubret, Marcel C. Raabe, Jane Yang, Chen Yu, Jochen Triesch</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.01969">https://arxiv.org/abs/2411.01969</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.01969">https://arxiv.org/pdf/2411.01969</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.01969]] Active Gaze Behavior Boosts Self-Supervised Object Learning(https://arxiv.org/abs/2411.01969)</code><input type="text"></li>
<li><strong>Keywords: </strong>self-supervised</a></li>
<li><strong>Abstract: </strong>Due to significant variations in the projection of the same object from different viewpoints, machine learning algorithms struggle to recognize the same object across various perspectives. In contrast, toddlers quickly learn to recognize objects from different viewpoints with almost no supervision. Recent works argue that toddlers develop this ability by mapping close-in-time visual inputs to similar representations while interacting with objects. High acuity vision is only available in the central visual field, which may explain why toddlers (much like adults) constantly move their gaze around during such interactions. It is unclear whether/how much toddlers curate their visual experience through these eye movements to support learning object representations. In this work, we explore whether a bio inspired visual learning model can harness toddlers' gaze behavior during a play session to develop view-invariant object recognition. Exploiting head-mounted eye tracking during dyadic play, we simulate toddlers' central visual field experience by cropping image regions centered on the gaze location. This visual stream feeds a time-based self-supervised learning algorithm. Our experiments demonstrate that toddlers' gaze strategy supports the learning of invariant object representations. Our analysis also reveals that the limited size of the central visual field where acuity is high is crucial for this. We further find that toddlers' visual experience elicits more robust representations compared to adults' mostly because toddlers look at objects they hold themselves for longer bouts. Overall, our work reveals how toddlers' gaze behavior supports self-supervised learning of view-invariant object recognition.</li>
</ul>

<h3>Title: Understanding Variational Autoencoders with Intrinsic Dimension and Information Imbalance</h3>
<ul>
<li><strong>Authors: </strong>Charles Camboulin, Diego Doimo, Aldo Glielmo</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.01978">https://arxiv.org/abs/2411.01978</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.01978">https://arxiv.org/pdf/2411.01978</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.01978]] Understanding Variational Autoencoders with Intrinsic Dimension and Information Imbalance(https://arxiv.org/abs/2411.01978)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>This work presents an analysis of the hidden representations of Variational Autoencoders (VAEs) using the Intrinsic Dimension (ID) and the Information Imbalance (II). We show that VAEs undergo a transition in behaviour once the bottleneck size is larger than the ID of the data, manifesting in a double hunchback ID profile and a qualitative shift in information processing as captured by the II. Our results also highlight two distinct training phases for architectures with sufficiently large bottleneck sizes, consisting of a rapid fit and a slower generalisation, as assessed by a differentiated behaviour of ID, II, and KL loss. These insights demonstrate that II and ID could be valuable tools for aiding architecture search, for diagnosing underfitting in VAEs, and, more broadly, they contribute to advancing a unified understanding of deep generative models through geometric analysis.</li>
</ul>

<h3>Title: Culinary Class Wars: Evaluating LLMs using ASH in Cuisine Transfer Task</h3>
<ul>
<li><strong>Authors: </strong>Hoonick Lee, Mogan Gim, Donghyeon Park, Donghee Choi, Jaewoo Kang</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.01996">https://arxiv.org/abs/2411.01996</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.01996">https://arxiv.org/pdf/2411.01996</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.01996]] Culinary Class Wars: Evaluating LLMs using ASH in Cuisine Transfer Task(https://arxiv.org/abs/2411.01996)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>The advent of Large Language Models (LLMs) have shown promise in various creative domains, including culinary arts. However, many LLMs still struggle to deliver the desired level of culinary creativity, especially when tasked with adapting recipes to meet specific cultural requirements. This study focuses on cuisine transfer-applying elements of one cuisine to another-to assess LLMs' culinary creativity. We employ a diverse set of LLMs to generate and evaluate culturally adapted recipes, comparing their evaluations against LLM and human judgments. We introduce the ASH (authenticity, sensitivity, harmony) benchmark to evaluate LLMs' recipe generation abilities in the cuisine transfer task, assessing their cultural accuracy and creativity in the culinary domain. Our findings reveal crucial insights into both generative and evaluative capabilities of LLMs in the culinary domain, highlighting strengths and limitations in understanding and applying cultural nuances in recipe creation. The code and dataset used in this project will be openly available in \url{this http URL}.</li>
</ul>

<h3>Title: Shortcut Learning in In-Context Learning: A Survey</h3>
<ul>
<li><strong>Authors: </strong>Rui Song, Yingji Li, Fausto Giunchiglia, Hao Xu</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.02018">https://arxiv.org/abs/2411.02018</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.02018">https://arxiv.org/pdf/2411.02018</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.02018]] Shortcut Learning in In-Context Learning: A Survey(https://arxiv.org/abs/2411.02018)</code><input type="text"></li>
<li><strong>Keywords: </strong>in-context</a></li>
<li><strong>Abstract: </strong>Shortcut learning refers to the phenomenon where models employ simple, non-robust decision rules in practical tasks, which hinders their generalization and robustness. With the rapid development of large language models (LLMs) in recent years, an increasing number of studies have shown the impact of shortcut learning on LLMs. This paper provides a novel perspective to review relevant research on shortcut learning in In-Context Learning (ICL). It conducts a detailed exploration of the types of shortcuts in ICL tasks, their causes, available benchmarks, and strategies for mitigating shortcuts. Based on corresponding observations, it summarizes the unresolved issues in existing research and attempts to outline the future research landscape of shortcut learning.</li>
</ul>

<h3>Title: Addressing Representation Collapse in Vector Quantized Models with One Linear Layer</h3>
<ul>
<li><strong>Authors: </strong>Yongxin Zhu, Bocheng Li, Yifei Xin, Linli Xu</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CV, cs.SD, eess.AS</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.02038">https://arxiv.org/abs/2411.02038</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.02038">https://arxiv.org/pdf/2411.02038</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.02038]] Addressing Representation Collapse in Vector Quantized Models with One Linear Layer(https://arxiv.org/abs/2411.02038)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>Vector Quantization (VQ) is a widely used method for converting continuous representations into discrete codes, which has become fundamental in unsupervised representation learning and latent generative models. However, VQ models are often hindered by the problem of representation collapse in the latent space, which leads to low codebook utilization and limits the scalability of the codebook for large-scale training. Existing methods designed to mitigate representation collapse typically reduce the dimensionality of latent space at the expense of model capacity, which do not fully resolve the core issue. In this study, we conduct a theoretical analysis of representation collapse in VQ models and identify its primary cause as the disjoint optimization of the codebook, where only a small subset of code vectors are updated through gradient descent. To address this issue, we propose \textbf{SimVQ}, a novel method which reparameterizes the code vectors through a linear transformation layer based on a learnable latent basis. This transformation optimizes the \textit{entire linear space} spanned by the codebook, rather than merely updating \textit{the code vector} selected by the nearest-neighbor search in vanilla VQ models. Although it is commonly understood that the multiplication of two linear matrices is equivalent to applying a single linear layer, our approach works surprisingly well in resolving the collapse issue in VQ models with just one linear layer. We validate the efficacy of SimVQ through extensive experiments across various modalities, including image and audio data with different model architectures. Our code is available at \url{this https URL}.</li>
</ul>

<h3>Title: AM Flow: Adapters for Temporal Processing in Action Recognition</h3>
<ul>
<li><strong>Authors: </strong>Tanay Agrawal, Abid Ali, Antitza Dantcheva, Francois Bremond</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.02065">https://arxiv.org/abs/2411.02065</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.02065">https://arxiv.org/pdf/2411.02065</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.02065]] AM Flow: Adapters for Temporal Processing in Action Recognition(https://arxiv.org/abs/2411.02065)</code><input type="text"></li>
<li><strong>Keywords: </strong>foundation model</a></li>
<li><strong>Abstract: </strong>Deep learning models, in particular \textit{image} models, have recently gained generalisability and robustness. %are becoming more general and robust by the day. In this work, we propose to exploit such advances in the realm of \textit{video} classification. Video foundation models suffer from the requirement of extensive pretraining and a large training time. Towards mitigating such limitations, we propose "\textit{Attention Map (AM) Flow}" for image models, a method for identifying pixels relevant to motion in each input video frame. In this context, we propose two methods to compute AM flow, depending on camera motion. AM flow allows the separation of spatial and temporal processing, while providing improved results over combined spatio-temporal processing (as in video models). Adapters, one of the popular techniques in parameter efficient transfer learning, facilitate the incorporation of AM flow into pretrained image models, mitigating the need for full-finetuning. We extend adapters to "\textit{temporal processing adapters}" by incorporating a temporal processing unit into the adapters. Our work achieves faster convergence, therefore reducing the number of epochs needed for training. Moreover, we endow an image model with the ability to achieve state-of-the-art results on popular action recognition datasets. This reduces training time and simplifies pretraining. We present experiments on Kinetics-400, Something-Something v2, and Toyota Smarthome datasets, showcasing state-of-the-art or comparable results.</li>
</ul>

<h3>Title: Model Integrity when Unlearning with T2I Diffusion Models</h3>
<ul>
<li><strong>Authors: </strong>Andrea Schioppa, Emiel Hoogeboom, Jonathan Heek</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.02068">https://arxiv.org/abs/2411.02068</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.02068">https://arxiv.org/pdf/2411.02068</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.02068]] Model Integrity when Unlearning with T2I Diffusion Models(https://arxiv.org/abs/2411.02068)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>The rapid advancement of text-to-image Diffusion Models has led to their widespread public accessibility. However these models, trained on large internet datasets, can sometimes generate undesirable outputs. To mitigate this, approximate Machine Unlearning algorithms have been proposed to modify model weights to reduce the generation of specific types of images, characterized by samples from a ``forget distribution'', while preserving the model's ability to generate other images, characterized by samples from a ``retain distribution''. While these methods aim to minimize the influence of training data in the forget distribution without extensive additional computation, we point out that they can compromise the model's integrity by inadvertently affecting generation for images in the retain distribution. Recognizing the limitations of FID and CLIPScore in capturing these effects, we introduce a novel retention metric that directly assesses the perceptual difference between outputs generated by the original and the unlearned models. We then propose unlearning algorithms that demonstrate superior effectiveness in preserving model integrity compared to existing baselines. Given their straightforward implementation, these algorithms serve as valuable benchmarks for future advancements in approximate Machine Unlearning for Diffusion Models.</li>
</ul>

<h3>Title: Training on test proteins improves fitness, structure, and function prediction</h3>
<ul>
<li><strong>Authors: </strong>Anton Bushuiev, Roman Bushuiev, Nikola Zadorozhny, Raman Samusevich, Hannes St√§rk, Jiri Sedlar, Tom√°≈° Pluskal, Josef Sivic</a></li>
<li><strong>Subjects: </strong>cs.LG, q-bio.BM</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.02109">https://arxiv.org/abs/2411.02109</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.02109">https://arxiv.org/pdf/2411.02109</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.02109]] Training on test proteins improves fitness, structure, and function prediction(https://arxiv.org/abs/2411.02109)</code><input type="text"></li>
<li><strong>Keywords: </strong>self-supervised</a></li>
<li><strong>Abstract: </strong>Data scarcity and distribution shifts often hinder the ability of machine learning models to generalize when applied to proteins and other biological data. Self-supervised pre-training on large datasets is a common method to enhance generalization. However, striving to perform well on all possible proteins can limit model's capacity to excel on any specific one, even though practitioners are often most interested in accurate predictions for the individual protein they study. To address this limitation, we propose an orthogonal approach to achieve generalization. Building on the prevalence of self-supervised pre-training, we introduce a method for self-supervised fine-tuning at test time, allowing models to adapt to the test protein of interest on the fly and without requiring any additional data. We study our test-time training (TTT) method through the lens of perplexity minimization and show that it consistently enhances generalization across different models, their scales, and datasets. Notably, our method leads to new state-of-the-art results on the standard benchmark for protein fitness prediction, improves protein structure prediction for challenging targets, and enhances function prediction accuracy.</li>
</ul>

<h3>Title: Bridge-IF: Learning Inverse Protein Folding with Markov Bridges</h3>
<ul>
<li><strong>Authors: </strong>Yiheng Zhu, Jialu Wu, Qiuyi Li, Jiahuan Yan, Mingze Yin, Wei Wu, Mingyang Li, Jieping Ye, Zheng Wang, Jian Wu</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, q-bio.BM</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.02120">https://arxiv.org/abs/2411.02120</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.02120">https://arxiv.org/pdf/2411.02120</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.02120]] Bridge-IF: Learning Inverse Protein Folding with Markov Bridges(https://arxiv.org/abs/2411.02120)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, generative</a></li>
<li><strong>Abstract: </strong>Inverse protein folding is a fundamental task in computational protein design, which aims to design protein sequences that fold into the desired backbone structures. While the development of machine learning algorithms for this task has seen significant success, the prevailing approaches, which predominantly employ a discriminative formulation, frequently encounter the error accumulation issue and often fail to capture the extensive variety of plausible sequences. To fill these gaps, we propose Bridge-IF, a generative diffusion bridge model for inverse folding, which is designed to learn the probabilistic dependency between the distributions of backbone structures and protein sequences. Specifically, we harness an expressive structure encoder to propose a discrete, informative prior derived from structures, and establish a Markov bridge to connect this prior with native sequences. During the inference stage, Bridge-IF progressively refines the prior sequence, culminating in a more plausible design. Moreover, we introduce a reparameterization perspective on Markov bridge models, from which we derive a simplified loss function that facilitates more effective training. We also modulate protein language models (PLMs) with structural conditions to precisely approximate the Markov bridge process, thereby significantly enhancing generation performance while maintaining parameter-efficient training. Extensive experiments on well-established benchmarks demonstrate that Bridge-IF predominantly surpasses existing baselines in sequence recovery and excels in the design of plausible proteins with high foldability. The code is available at this https URL.</li>
</ul>

<h3>Title: Adaptive Sparse Allocation with Mutual Choice & Feature Choice Sparse Autoencoders</h3>
<ul>
<li><strong>Authors: </strong>Kola Ayonrinde</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.02124">https://arxiv.org/abs/2411.02124</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.02124">https://arxiv.org/pdf/2411.02124</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.02124]] Adaptive Sparse Allocation with Mutual Choice & Feature Choice Sparse Autoencoders(https://arxiv.org/abs/2411.02124)</code><input type="text"></li>
<li><strong>Keywords: </strong>foundation model</a></li>
<li><strong>Abstract: </strong>Sparse autoencoders (SAEs) are a promising approach to extracting features from neural networks, enabling model interpretability as well as causal interventions on model internals. SAEs generate sparse feature representations using a sparsifying activation function that implicitly defines a set of token-feature matches. We frame the token-feature matching as a resource allocation problem constrained by a total sparsity upper bound. For example, TopK SAEs solve this allocation problem with the additional constraint that each token matches with at most $k$ features. In TopK SAEs, the $k$ active features per token constraint is the same across tokens, despite some tokens being more difficult to reconstruct than others. To address this limitation, we propose two novel SAE variants, Feature Choice SAEs and Mutual Choice SAEs, which each allow for a variable number of active features per token. Feature Choice SAEs solve the sparsity allocation problem under the additional constraint that each feature matches with at most $m$ tokens. Mutual Choice SAEs solve the unrestricted allocation problem where the total sparsity budget can be allocated freely between tokens and features. Additionally, we introduce a new auxiliary loss function, $\mathtt{aux\_zipf\_loss}$, which generalises the $\mathtt{aux\_k\_loss}$ to mitigate dead and underutilised features. Our methods result in SAEs with fewer dead features and improved reconstruction loss at equivalent sparsity levels as a result of the inherent adaptive computation. More accurate and scalable feature extraction methods provide a path towards better understanding and more precise control of foundation models.</li>
</ul>

<h3>Title: Revisiting K-mer Profile for Effective and Scalable Genome Representation Learning</h3>
<ul>
<li><strong>Authors: </strong>Abdulkadir Celikkanat, Andres R. Masegosa, Thomas D. Nielsen</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CE, q-bio.GN</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.02125">https://arxiv.org/abs/2411.02125</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.02125">https://arxiv.org/pdf/2411.02125</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.02125]] Revisiting K-mer Profile for Effective and Scalable Genome Representation Learning(https://arxiv.org/abs/2411.02125)</code><input type="text"></li>
<li><strong>Keywords: </strong>foundation model</a></li>
<li><strong>Abstract: </strong>Obtaining effective representations of DNA sequences is crucial for genome analysis. Metagenomic binning, for instance, relies on genome representations to cluster complex mixtures of DNA fragments from biological samples with the aim of determining their microbial compositions. In this paper, we revisit k-mer-based representations of genomes and provide a theoretical analysis of their use in representation learning. Based on the analysis, we propose a lightweight and scalable model for performing metagenomic binning at the genome read level, relying only on the k-mer compositions of the DNA fragments. We compare the model to recent genome foundation models and demonstrate that while the models are comparable in performance, the proposed model is significantly more effective in terms of scalability, a crucial aspect for performing metagenomic binning of real-world datasets.</li>
</ul>

<h3>Title: Supervised Transfer Learning Framework for Fault Diagnosis in Wind Turbines</h3>
<ul>
<li><strong>Authors: </strong>Kenan Weber, Christine Preisach</a></li>
<li><strong>Subjects: </strong>cs.LG, eess.SP</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.02127">https://arxiv.org/abs/2411.02127</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.02127">https://arxiv.org/pdf/2411.02127</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.02127]] Supervised Transfer Learning Framework for Fault Diagnosis in Wind Turbines(https://arxiv.org/abs/2411.02127)</code><input type="text"></li>
<li><strong>Keywords: </strong>anomaly</a></li>
<li><strong>Abstract: </strong>Common challenges in fault diagnosis include the lack of labeled data and the need to build models for each domain, resulting in many models that require supervision. Transfer learning can help tackle these challenges by learning cross-domain knowledge. Many approaches still require at least some labeled data in the target domain, and often provide unexplainable results. To this end, we propose a supervised transfer learning framework for fault diagnosis in wind turbines that operates in an Anomaly-Space. This space was created using SCADA data and vibration data and was built and provided to us by our research partner. Data within the Anomaly-Space can be interpreted as anomaly scores for each component in the wind turbine, making each value intuitive to understand. We conducted cross-domain evaluation on the train set using popular supervised classifiers like Random Forest, Light-Gradient-Boosting-Machines and Multilayer Perceptron as metamodels for the diagnosis of bearing and sensor faults. The Multilayer Perceptron achieved the highest classification performance. This model was then used for a final evaluation in our test set. The results show, that the proposed framework is able to detect cross-domain faults in the test set with a high degree of accuracy by using one single classifier, which is a significant asset to the diagnostic team.</li>
</ul>

<h3>Title: Improving Domain Generalization in Self-supervised Monocular Depth Estimation via Stabilized Adversarial Training</h3>
<ul>
<li><strong>Authors: </strong>Yuanqi Yao, Gang Wu, Kui Jiang, Siao Liu, Jian Kuai, Xianming Liu, Junjun Jiang</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.02149">https://arxiv.org/abs/2411.02149</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.02149">https://arxiv.org/pdf/2411.02149</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.02149]] Improving Domain Generalization in Self-supervised Monocular Depth Estimation via Stabilized Adversarial Training(https://arxiv.org/abs/2411.02149)</code><input type="text"></li>
<li><strong>Keywords: </strong>self-supervised</a></li>
<li><strong>Abstract: </strong>Learning a self-supervised Monocular Depth Estimation (MDE) model with great generalization remains significantly challenging. Despite the success of adversarial augmentation in the supervised learning generalization, naively incorporating it into self-supervised MDE models potentially causes over-regularization, suffering from severe performance degradation. In this paper, we conduct qualitative analysis and illuminate the main causes: (i) inherent sensitivity in the UNet-alike depth network and (ii) dual optimization conflict caused by over-regularization. To tackle these issues, we propose a general adversarial training framework, named Stabilized Conflict-optimization Adversarial Training (SCAT), integrating adversarial data augmentation into self-supervised MDE methods to achieve a balance between stability and generalization. Specifically, we devise an effective scaling depth network that tunes the coefficients of long skip connection and effectively stabilizes the training process. Then, we propose a conflict gradient surgery strategy, which progressively integrates the adversarial gradient and optimizes the model toward a conflict-free direction. Extensive experiments on five benchmarks demonstrate that SCAT can achieve state-of-the-art performance and significantly improve the generalization capability of existing self-supervised MDE methods.</li>
</ul>

<h3>Title: SAFE: Slow and Fast Parameter-Efficient Tuning for Continual Learning with Pre-Trained Models</h3>
<ul>
<li><strong>Authors: </strong>Linglan Zhao, Xuerui Zhang, Ke Yan, Shouhong Ding, Weiran Huang</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.02175">https://arxiv.org/abs/2411.02175</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.02175">https://arxiv.org/pdf/2411.02175</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.02175]] SAFE: Slow and Fast Parameter-Efficient Tuning for Continual Learning with Pre-Trained Models(https://arxiv.org/abs/2411.02175)</code><input type="text"></li>
<li><strong>Keywords: </strong>foundation model</a></li>
<li><strong>Abstract: </strong>Continual learning aims to incrementally acquire new concepts in data streams while resisting forgetting previous knowledge. With the rise of powerful pre-trained models (PTMs), there is a growing interest in training incremental learning systems using these foundation models, rather than learning from scratch. Existing works often view PTMs as a strong initial point and directly apply parameter-efficient tuning (PET) in the first session for adapting to downstream tasks. In the following sessions, most methods freeze model parameters for tackling forgetting issues. However, applying PET directly to downstream data cannot fully explore the inherent knowledge in PTMs. Additionally, freezing the parameters in incremental sessions hinders models' plasticity to novel concepts not covered in the first session. To solve the above issues, we propose a Slow And Fast parameter-Efficient tuning (SAFE) framework. In particular, to inherit general knowledge from foundation models, we include a transfer loss function by measuring the correlation between the PTM and the PET-applied model. After calibrating in the first session, the slow efficient tuning parameters can capture more informative features, improving generalization to incoming classes. Moreover, to further incorporate novel concepts, we strike a balance between stability and plasticity by fixing slow efficient tuning parameters and continuously updating the fast ones. Specifically, a cross-classification loss with feature alignment is proposed to circumvent catastrophic forgetting. During inference, we introduce an entropy-based aggregation strategy to dynamically utilize the complementarity in the slow and fast learners. Extensive experiments on seven benchmark datasets verify the effectiveness of our method by significantly surpassing the state-of-the-art.</li>
</ul>

<h3>Title: CleAR: Robust Context-Guided Generative Lighting Estimation for Mobile Augmented Reality</h3>
<ul>
<li><strong>Authors: </strong>Yiqin Zhao, Mallesham Dasari, Tian Guo</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.GR, cs.HC</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.02179">https://arxiv.org/abs/2411.02179</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.02179">https://arxiv.org/pdf/2411.02179</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.02179]] CleAR: Robust Context-Guided Generative Lighting Estimation for Mobile Augmented Reality(https://arxiv.org/abs/2411.02179)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, generative</a></li>
<li><strong>Abstract: </strong>High-quality environment lighting is the foundation of creating immersive user experiences in mobile augmented reality (AR) applications. However, achieving visually coherent environment lighting estimation for Mobile AR is challenging due to several key limitations associated with AR device sensing capabilities, including limitations in device camera FoV and pixel dynamic ranges. Recent advancements in generative AI, which can generate high-quality images from different types of prompts, including texts and images, present a potential solution for high-quality lighting estimation. Still, to effectively use generative image diffusion models, we must address their key limitations of generation hallucination and slow inference process. To do so, in this work, we design and implement a generative lighting estimation system called CleAR that can produce high-quality and diverse environment maps in the format of 360$^\circ$ images. Specifically, we design a two-step generation pipeline guided by AR environment context data to ensure the results follow physical environment visual context and color appearances. To improve the estimation robustness under different lighting conditions, we design a real-time refinement component to adjust lighting estimation results on AR devices. To train and test our generative models, we curate a large-scale environment lighting estimation dataset with diverse lighting conditions. Through quantitative evaluation and user study, we show that CleAR outperforms state-of-the-art lighting estimation methods on both estimation accuracy and robustness. Moreover, CleAR supports real-time refinement of lighting estimation results, ensuring robust and timely environment lighting updates for AR applications. Our end-to-end generative estimation takes as fast as 3.2 seconds, outperforming state-of-the-art methods by 110x.</li>
</ul>

<h3>Title: Digi2Real: Bridging the Realism Gap in Synthetic Data Face Recognition via Foundation Models</h3>
<ul>
<li><strong>Authors: </strong>Anjith George, Sebastien Marcel</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.02188">https://arxiv.org/abs/2411.02188</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.02188">https://arxiv.org/pdf/2411.02188</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.02188]] Digi2Real: Bridging the Realism Gap in Synthetic Data Face Recognition via Foundation Models(https://arxiv.org/abs/2411.02188)</code><input type="text"></li>
<li><strong>Keywords: </strong>foundation model, generative</a></li>
<li><strong>Abstract: </strong>The accuracy of face recognition systems has improved significantly in the past few years, thanks to the large amount of data collected and the advancement in neural network architectures. However, these large-scale datasets are often collected without explicit consent, raising ethical and privacy concerns. To address this, there have been proposals to use synthetic datasets for training face recognition models. Yet, such models still rely on real data to train the generative models and generally exhibit inferior performance compared to those trained on real datasets. One of these datasets, DigiFace, uses a graphics pipeline to generate different identities and different intra-class variations without using real data in training the models. However, the performance of this approach is poor on face recognition benchmarks, possibly due to the lack of realism in the images generated from the graphics pipeline. In this work, we introduce a novel framework for realism transfer aimed at enhancing the realism of synthetically generated face images. Our method leverages the large-scale face foundation model, and we adapt the pipeline for realism enhancement. By integrating the controllable aspects of the graphics pipeline with our realism enhancement technique, we generate a large amount of realistic variations-combining the advantages of both approaches. Our empirical evaluations demonstrate that models trained using our enhanced dataset significantly improve the performance of face recognition systems over the baseline. The source code and datasets will be made available publicly.</li>
</ul>

<h3>Title: Provably Transformers Harness Multi-Concept Word Semantics for Efficient In-Context Learning</h3>
<ul>
<li><strong>Authors: </strong>Dake Bu, Wei Huang, Andi Han, Atsushi Nitanda, Taiji Suzuki, Qingfu Zhang, Hau-San Wong</a></li>
<li><strong>Subjects: </strong>cs.LG, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.02199">https://arxiv.org/abs/2411.02199</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.02199">https://arxiv.org/pdf/2411.02199</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.02199]] Provably Transformers Harness Multi-Concept Word Semantics for Efficient In-Context Learning(https://arxiv.org/abs/2411.02199)</code><input type="text"></li>
<li><strong>Keywords: </strong>in-context</a></li>
<li><strong>Abstract: </strong>Transformer-based large language models (LLMs) have displayed remarkable creative prowess and emergence capabilities. Existing empirical studies have revealed a strong connection between these LLMs' impressive emergence abilities and their in-context learning (ICL) capacity, allowing them to solve new tasks using only task-specific prompts without further fine-tuning. On the other hand, existing empirical and theoretical studies also show that there is a linear regularity of the multi-concept encoded semantic representation behind transformer-based LLMs. However, existing theoretical work fail to build up an understanding of the connection between this regularity and the innovative power of ICL. Additionally, prior work often focuses on simplified, unrealistic scenarios involving linear transformers or unrealistic loss functions, and they achieve only linear or sub-linear convergence rates. In contrast, this work provides a fine-grained mathematical analysis to show how transformers leverage the multi-concept semantics of words to enable powerful ICL and excellent out-of-distribution ICL abilities, offering insights into how transformers innovate solutions for certain unseen tasks encoded with multiple cross-concept semantics. Inspired by empirical studies on the linear latent geometry of LLMs, the analysis is based on a concept-based low-noise sparse coding prompt model. Leveraging advanced techniques, this work showcases the exponential 0-1 loss convergence over the highly non-convex training dynamics, which pioneeringly incorporates the challenges of softmax self-attention, ReLU-activated MLPs, and cross-entropy loss. Empirical simulations corroborate the theoretical findings.</li>
</ul>

<h3>Title: FewViewGS: Gaussian Splatting with Few View Matching and Multi-stage Training</h3>
<ul>
<li><strong>Authors: </strong>Ruihong Yin, Vladimir Yugay, Yue Li, Sezer Karaoglu, Theo Gevers</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.02229">https://arxiv.org/abs/2411.02229</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.02229">https://arxiv.org/pdf/2411.02229</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.02229]] FewViewGS: Gaussian Splatting with Few View Matching and Multi-stage Training(https://arxiv.org/abs/2411.02229)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>The field of novel view synthesis from images has seen rapid advancements with the introduction of Neural Radiance Fields (NeRF) and more recently with 3D Gaussian Splatting. Gaussian Splatting became widely adopted due to its efficiency and ability to render novel views accurately. While Gaussian Splatting performs well when a sufficient amount of training images are available, its unstructured explicit representation tends to overfit in scenarios with sparse input images, resulting in poor rendering performance. To address this, we present a 3D Gaussian-based novel view synthesis method using sparse input images that can accurately render the scene from the viewpoints not covered by the training images. We propose a multi-stage training scheme with matching-based consistency constraints imposed on the novel views without relying on pre-trained depth estimation or diffusion models. This is achieved by using the matches of the available training images to supervise the generation of the novel views sampled between the training frames with color, geometry, and semantic losses. In addition, we introduce a locality preserving regularization for 3D Gaussians which removes rendering artifacts by preserving the local color structure of the scene. Evaluation on synthetic and real-world datasets demonstrates competitive or superior performance of our method in few-shot novel view synthesis compared to existing state-of-the-art methods.</li>
</ul>

<h3>Title: 3D Audio-Visual Segmentation</h3>
<ul>
<li><strong>Authors: </strong>Artem Sokolov, Swapnil Bhosale, Xiatian Zhu</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.MM, cs.SD, eess.AS</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.02236">https://arxiv.org/abs/2411.02236</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.02236">https://arxiv.org/pdf/2411.02236</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.02236]] 3D Audio-Visual Segmentation(https://arxiv.org/abs/2411.02236)</code><input type="text"></li>
<li><strong>Keywords: </strong>foundation model</a></li>
<li><strong>Abstract: </strong>Recognizing the sounding objects in scenes is a longstanding objective in embodied AI, with diverse applications in robotics and AR/VR/MR. To that end, Audio-Visual Segmentation (AVS), taking as condition an audio signal to identify the masks of the target sounding objects in an input image with synchronous camera and microphone sensors, has been recently advanced. However, this paradigm is still insufficient for real-world operation, as the mapping from 2D images to 3D scenes is missing. To address this fundamental limitation, we introduce a novel research problem, 3D Audio-Visual Segmentation, extending the existing AVS to the 3D output space. This problem poses more challenges due to variations in camera extrinsics, audio scattering, occlusions, and diverse acoustics across sounding object categories. To facilitate this research, we create the very first simulation based benchmark, 3DAVS-S34-O7, providing photorealistic 3D scene environments with grounded spatial audio under single-instance and multi-instance settings, across 34 scenes and 7 object categories. This is made possible by re-purposing the Habitat simulator to generate comprehensive annotations of sounding object locations and corresponding 3D masks. Subsequently, we propose a new approach, EchoSegnet, characterized by integrating the ready-to-use knowledge from pretrained 2D audio-visual foundation models synergistically with 3D visual scene representation through spatial audio-aware mask alignment and refinement. Extensive experiments demonstrate that EchoSegnet can effectively segment sounding objects in 3D space on our new benchmark, representing a significant advancement in the field of embodied AI. Project page: this https URL</li>
</ul>

<h3>Title: Unified Speech Recognition: A Single Model for Auditory, Visual, and Audiovisual Inputs</h3>
<ul>
<li><strong>Authors: </strong>Alexandros Haliassos, Rodrigo Mira, Honglie Chen, Zoe Landgraf, Stavros Petridis, Maja Pantic</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.02256">https://arxiv.org/abs/2411.02256</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.02256">https://arxiv.org/pdf/2411.02256</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.02256]] Unified Speech Recognition: A Single Model for Auditory, Visual, and Audiovisual Inputs(https://arxiv.org/abs/2411.02256)</code><input type="text"></li>
<li><strong>Keywords: </strong>self-supervised</a></li>
<li><strong>Abstract: </strong>Research in auditory, visual, and audiovisual speech recognition (ASR, VSR, and AVSR, respectively) has traditionally been conducted independently. Even recent self-supervised studies addressing two or all three tasks simultaneously tend to yield separate models, leading to disjoint inference pipelines with increased memory requirements and redundancies. This paper proposes unified training strategies for these systems. We demonstrate that training a single model for all three tasks enhances VSR and AVSR performance, overcoming typical optimisation challenges when training from scratch. Moreover, we introduce a greedy pseudo-labelling approach to more effectively leverage unlabelled samples, addressing shortcomings in related self-supervised methods. Finally, we develop a self-supervised pre-training method within our framework, proving its effectiveness alongside our semi-supervised approach. Despite using a single model for all tasks, our unified approach achieves state-of-the-art performance compared to recent methods on LRS3 and LRS2 for ASR, VSR, and AVSR, as well as on the newly released WildVSR dataset. Code and models are available at this https URL.</li>
</ul>

<h3>Title: Counterfactual Explanations via Riemannian Latent Space Traversal</h3>
<ul>
<li><strong>Authors: </strong>Paraskevas Pegios, Aasa Feragen, Andreas Abildtrup Hansen, Georgios Arvanitidis</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.02259">https://arxiv.org/abs/2411.02259</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.02259">https://arxiv.org/pdf/2411.02259</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.02259]] Counterfactual Explanations via Riemannian Latent Space Traversal(https://arxiv.org/abs/2411.02259)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>The adoption of increasingly complex deep models has fueled an urgent need for insight into how these models make predictions. Counterfactual explanations form a powerful tool for providing actionable explanations to practitioners. Previously, counterfactual explanation methods have been designed by traversing the latent space of generative models. Yet, these latent spaces are usually greatly simplified, with most of the data distribution complexity contained in the decoder rather than the latent embedding. Thus, traversing the latent space naively without taking the nonlinear decoder into account can lead to unnatural counterfactual trajectories. We introduce counterfactual explanations obtained using a Riemannian metric pulled back via the decoder and the classifier under scrutiny. This metric encodes information about the complex geometric structure of the data and the learned representation, enabling us to obtain robust counterfactual trajectories with high fidelity, as demonstrated by our experiments in real-world tabular datasets.</li>
</ul>

<h3>Title: Hunyuan3D-1.0: A Unified Framework for Text-to-3D and Image-to-3D Generation</h3>
<ul>
<li><strong>Authors: </strong>Xianghui Yang, Huiwen Shi, Bowen Zhang, Fan Yang, Jiacheng Wang, Hongxu Zhao, Xinhai Liu, Xinzhou Wang, Qingxiang Lin, Jiaao Yu, Lifu Wang, Zhuo Chen, Sicong Liu, Yuhong Liu, Yong Yang, Di Wang, Jie Jiang, Chunchao Guo</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.02293">https://arxiv.org/abs/2411.02293</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.02293">https://arxiv.org/pdf/2411.02293</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.02293]] Hunyuan3D-1.0: A Unified Framework for Text-to-3D and Image-to-3D Generation(https://arxiv.org/abs/2411.02293)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, generative</a></li>
<li><strong>Abstract: </strong>While 3D generative models have greatly improved artists' workflows, the existing diffusion models for 3D generation suffer from slow generation and poor generalization. To address this issue, we propose a two-stage approach named Hunyuan3D-1.0 including a lite version and a standard version, that both support text- and image-conditioned generation. In the first stage, we employ a multi-view diffusion model that efficiently generates multi-view RGB in approximately 4 seconds. These multi-view images capture rich details of the 3D asset from different viewpoints, relaxing the tasks from single-view to multi-view reconstruction. In the second stage, we introduce a feed-forward reconstruction model that rapidly and faithfully reconstructs the 3D asset given the generated multi-view images in approximately 7 seconds. The reconstruction network learns to handle noises and in-consistency introduced by the multi-view diffusion and leverages the available information from the condition image to efficiently recover the 3D structure. % Extensive experimental results demonstrate the effectiveness of Hunyuan3D-1.0 in generating high-quality 3D assets. Our framework involves the text-to-image model ~\ie, Hunyuan-DiT, making it a unified framework to support both text- and image-conditioned 3D generation. Our standard version has $10\times$ more parameters than our lite and other existing model. Our Hunyuan3D-1.0 achieves an impressive balance between speed and quality, significantly reducing generation time while maintaining the quality and diversity of the produced assets.</li>
</ul>

<h3>Title: Grouped Discrete Representation for Object-Centric Learning</h3>
<ul>
<li><strong>Authors: </strong>Rongzhen Zhao, Vivienne Wang, Juho Kannala, Joni Pajarinen</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.02299">https://arxiv.org/abs/2411.02299</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.02299">https://arxiv.org/pdf/2411.02299</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.02299]] Grouped Discrete Representation for Object-Centric Learning(https://arxiv.org/abs/2411.02299)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>Object-Centric Learning (OCL) can discover objects in images or videos by simply reconstructing the input. For better object discovery, representative OCL methods reconstruct the input as its Variational Autoencoder (VAE) intermediate representation, which suppresses pixel noises and promotes object separability by discretizing continuous super-pixels with template features. However, treating features as units overlooks their composing attributes, thus impeding model generalization; indexing features with scalar numbers loses attribute-level similarities and differences, thus hindering model convergence. We propose \textit{Grouped Discrete Representation} (GDR) for OCL. We decompose features into combinatorial attributes via organized channel grouping, and compose these attributes into discrete representation via tuple indexes. Experiments show that our GDR improves both Transformer- and Diffusion-based OCL methods consistently on various datasets. Visualizations show that our GDR captures better object separability.</li>
</ul>

<h3>Title: Defining and Evaluating Physical Safety for Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Yung-Chen Tang, Pin-Yu Chen, Tsung-Yi Ho</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CY</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.02317">https://arxiv.org/abs/2411.02317</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.02317">https://arxiv.org/pdf/2411.02317</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.02317]] Defining and Evaluating Physical Safety for Large Language Models(https://arxiv.org/abs/2411.02317)</code><input type="text"></li>
<li><strong>Keywords: </strong>in-context</a></li>
<li><strong>Abstract: </strong>Large Language Models (LLMs) are increasingly used to control robotic systems such as drones, but their risks of causing physical threats and harm in real-world applications remain unexplored. Our study addresses the critical gap in evaluating LLM physical safety by developing a comprehensive benchmark for drone control. We classify the physical safety risks of drones into four categories: (1) human-targeted threats, (2) object-targeted threats, (3) infrastructure attacks, and (4) regulatory violations. Our evaluation of mainstream LLMs reveals an undesirable trade-off between utility and safety, with models that excel in code generation often performing poorly in crucial safety aspects. Furthermore, while incorporating advanced prompt engineering techniques such as In-Context Learning and Chain-of-Thought can improve safety, these methods still struggle to identify unintentional attacks. In addition, larger models demonstrate better safety capabilities, particularly in refusing dangerous commands. Our findings and benchmark can facilitate the design and evaluation of physical safety for LLMs. The project page is available at this http URL.</li>
</ul>

<h3>Title: LayerDAG: A Layerwise Autoregressive Diffusion Model for Directed Acyclic Graph Generation</h3>
<ul>
<li><strong>Authors: </strong>Mufei Li, Viraj Shitole, Eli Chien, Changhai Man, Zhaodong Wang, Srinivas Sridharan, Ying Zhang, Tushar Krishna, Pan Li</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AR, cs.DC</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.02322">https://arxiv.org/abs/2411.02322</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.02322">https://arxiv.org/pdf/2411.02322</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.02322]] LayerDAG: A Layerwise Autoregressive Diffusion Model for Directed Acyclic Graph Generation(https://arxiv.org/abs/2411.02322)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, generative</a></li>
<li><strong>Abstract: </strong>Directed acyclic graphs (DAGs) serve as crucial data representations in domains such as hardware synthesis and compiler/program optimization for computing systems. DAG generative models facilitate the creation of synthetic DAGs, which can be used for benchmarking computing systems while preserving intellectual property. However, generating realistic DAGs is challenging due to their inherent directional and logical dependencies. This paper introduces LayerDAG, an autoregressive diffusion model, to address these challenges. LayerDAG decouples the strong node dependencies into manageable units that can be processed sequentially. By interpreting the partial order of nodes as a sequence of bipartite graphs, LayerDAG leverages autoregressive generation to model directional dependencies and employs diffusion models to capture logical dependencies within each bipartite graph. Comparative analyses demonstrate that LayerDAG outperforms existing DAG generative models in both expressiveness and generalization, particularly for generating large-scale DAGs with up to 400 nodes-a critical scenario for system benchmarking. Extensive experiments on both synthetic and real-world flow graphs from various computing platforms show that LayerDAG generates valid DAGs with superior statistical properties and benchmarking performance. The synthetic DAGs generated by LayerDAG enhance the training of ML-based surrogate models, resulting in improved accuracy in predicting performance metrics of real-world DAGs across diverse computing platforms.</li>
</ul>

<h3>Title: MVPaint: Synchronized Multi-View Diffusion for Painting Anything 3D</h3>
<ul>
<li><strong>Authors: </strong>Wei Cheng, Juncheng Mu, Xianfang Zeng, Xin Chen, Anqi Pang, Chi Zhang, Zhibin Wang, Bin Fu, Gang Yu, Ziwei Liu, Liang Pan</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.02336">https://arxiv.org/abs/2411.02336</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.02336">https://arxiv.org/pdf/2411.02336</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.02336]] MVPaint: Synchronized Multi-View Diffusion for Painting Anything 3D(https://arxiv.org/abs/2411.02336)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>Texturing is a crucial step in the 3D asset production workflow, which enhances the visual appeal and diversity of 3D assets. Despite recent advancements in Text-to-Texture (T2T) generation, existing methods often yield subpar results, primarily due to local discontinuities, inconsistencies across multiple views, and their heavy dependence on UV unwrapping outcomes. To tackle these challenges, we propose a novel generation-refinement 3D texturing framework called MVPaint, which can generate high-resolution, seamless textures while emphasizing multi-view consistency. MVPaint mainly consists of three key modules. 1) Synchronized Multi-view Generation (SMG). Given a 3D mesh model, MVPaint first simultaneously generates multi-view images by employing an SMG model, which leads to coarse texturing results with unpainted parts due to missing observations. 2) Spatial-aware 3D Inpainting (S3I). To ensure complete 3D texturing, we introduce the S3I method, specifically designed to effectively texture previously unobserved areas. 3) UV Refinement (UVR). Furthermore, MVPaint employs a UVR module to improve the texture quality in the UV space, which first performs a UV-space Super-Resolution, followed by a Spatial-aware Seam-Smoothing algorithm for revising spatial texturing discontinuities caused by UV unwrapping. Moreover, we establish two T2T evaluation benchmarks: the Objaverse T2T benchmark and the GSO T2T benchmark, based on selected high-quality 3D meshes from the Objaverse dataset and the entire GSO dataset, respectively. Extensive experimental results demonstrate that MVPaint surpasses existing state-of-the-art methods. Notably, MVPaint could generate high-fidelity textures with minimal Janus issues and highly enhanced cross-view consistency.</li>
</ul>

<h3>Title: Machine learning identification of maternal inflammatory response and histologic choroamnionitis from placental membrane whole slide images</h3>
<ul>
<li><strong>Authors: </strong>Abhishek Sharma, Ramin Nateghi, Marina Ayad, Lee A.D. Cooper, Jeffery A. Goldstein</a></li>
<li><strong>Subjects: </strong>cs.CV, q-bio.QM</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.02354">https://arxiv.org/abs/2411.02354</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.02354">https://arxiv.org/pdf/2411.02354</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.02354]] Machine learning identification of maternal inflammatory response and histologic choroamnionitis from placental membrane whole slide images(https://arxiv.org/abs/2411.02354)</code><input type="text"></li>
<li><strong>Keywords: </strong>foundation model</a></li>
<li><strong>Abstract: </strong>The placenta forms a critical barrier to infection through pregnancy, labor and, delivery. Inflammatory processes in the placenta have short-term, and long-term consequences for offspring health. Digital pathology and machine learning can play an important role in understanding placental inflammation, and there have been very few investigations into methods for predicting and understanding Maternal Inflammatory Response (MIR). This work intends to investigate the potential of using machine learning to understand MIR based on whole slide images (WSI), and establish early benchmarks. To that end, we use Multiple Instance Learning framework with 3 feature extractors: ImageNet-based EfficientNet-v2s, and 2 histopathology foundation models, UNI and Phikon to investigate predictability of MIR stage from histopathology WSIs. We also interpret predictions from these models using the learned attention maps from these models. We also use the MIL framework for predicting white blood cells count (WBC) and maximum fever temperature ($T_{max}$). Attention-based MIL models are able to classify MIR with a balanced accuracy of up to 88.5% with a Cohen's Kappa ($\kappa$) of up to 0.772. Furthermore, we found that the pathology foundation models (UNI and Phikon) are both able to achieve higher performance with balanced accuracy and $\kappa$, compared to ImageNet-based feature extractor (EfficientNet-v2s). For WBC and $T_{max}$ prediction, we found mild correlation between actual values and those predicted from histopathology WSIs. We used MIL framework for predicting MIR stage from WSIs, and compared effectiveness of foundation models as feature extractors, with that of an ImageNet-based model. We further investigated model failure cases and found them to be either edge cases prone to interobserver variability, examples of pathologist's overreach, or mislabeled due to processing errors.</li>
</ul>

<h3>Title: Learning General-Purpose Biomedical Volume Representations using Randomized Synthesis</h3>
<ul>
<li><strong>Authors: </strong>Neel Dey, Benjamin Billot, Hallee E. Wong, Clinton J. Wang, Mengwei Ren, P. Ellen Grant, Adrian V. Dalca, Polina Golland</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.02372">https://arxiv.org/abs/2411.02372</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.02372">https://arxiv.org/pdf/2411.02372</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.02372]] Learning General-Purpose Biomedical Volume Representations using Randomized Synthesis(https://arxiv.org/abs/2411.02372)</code><input type="text"></li>
<li><strong>Keywords: </strong>foundation model</a></li>
<li><strong>Abstract: </strong>Current volumetric biomedical foundation models struggle to generalize as public 3D datasets are small and do not cover the broad diversity of medical procedures, conditions, anatomical regions, and imaging protocols. We address this by creating a representation learning method that instead anticipates strong domain shifts at training time itself. We first propose a data engine that synthesizes highly variable training samples that enable generalization to new biomedical contexts. To then train a single 3D network for any voxel-level task, we develop a contrastive learning method that pretrains the network to be stable against nuisance imaging variation simulated by the data engine, a key inductive bias for generalization. This network's features can be used as robust representations of input images for downstream tasks and its weights provide a strong, dataset-agnostic initialization for finetuning on new datasets. As a result, we set new standards across both multimodality registration and few-shot segmentation, a first for any 3D biomedical vision model, all without (pre-)training on any existing dataset of real images.</li>
</ul>

<h3>Title: How Far is Video Generation from World Model: A Physical Law Perspective</h3>
<ul>
<li><strong>Authors: </strong>Bingyi Kang, Yang Yue, Rui Lu, Zhijie Lin, Yang Zhao, Kaixin Wang, Gao Huang, Jiashi Feng</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.02385">https://arxiv.org/abs/2411.02385</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.02385">https://arxiv.org/pdf/2411.02385</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.02385]] How Far is Video Generation from World Model: A Physical Law Perspective(https://arxiv.org/abs/2411.02385)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>OpenAI's Sora highlights the potential of video generation for developing world models that adhere to fundamental physical laws. However, the ability of video generation models to discover such laws purely from visual data without human priors can be questioned. A world model learning the true law should give predictions robust to nuances and correctly extrapolate on unseen scenarios. In this work, we evaluate across three key scenarios: in-distribution, out-of-distribution, and combinatorial generalization. We developed a 2D simulation testbed for object movement and collisions to generate videos deterministically governed by one or more classical mechanics laws. This provides an unlimited supply of data for large-scale experimentation and enables quantitative evaluation of whether the generated videos adhere to physical laws. We trained diffusion-based video generation models to predict object movements based on initial frames. Our scaling experiments show perfect generalization within the distribution, measurable scaling behavior for combinatorial generalization, but failure in out-of-distribution scenarios. Further experiments reveal two key insights about the generalization mechanisms of these models: (1) the models fail to abstract general physical rules and instead exhibit "case-based" generalization behavior, i.e., mimicking the closest training example; (2) when generalizing to new cases, models are observed to prioritize different factors when referencing training data: color > size > velocity > shape. Our study suggests that scaling alone is insufficient for video generation models to uncover fundamental physical laws, despite its role in Sora's broader success. See our project page at this https URL</li>
</ul>

<h3>Title: AutoVFX: Physically Realistic Video Editing from Natural Language Instructions</h3>
<ul>
<li><strong>Authors: </strong>Hao-Yu Hsu, Zhi-Hao Lin, Albert Zhai, Hongchi Xia, Shenlong Wang</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.02394">https://arxiv.org/abs/2411.02394</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.02394">https://arxiv.org/pdf/2411.02394</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.02394]] AutoVFX: Physically Realistic Video Editing from Natural Language Instructions(https://arxiv.org/abs/2411.02394)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>Modern visual effects (VFX) software has made it possible for skilled artists to create imagery of virtually anything. However, the creation process remains laborious, complex, and largely inaccessible to everyday users. In this work, we present AutoVFX, a framework that automatically creates realistic and dynamic VFX videos from a single video and natural language instructions. By carefully integrating neural scene modeling, LLM-based code generation, and physical simulation, AutoVFX is able to provide physically-grounded, photorealistic editing effects that can be controlled directly using natural language instructions. We conduct extensive experiments to validate AutoVFX's efficacy across a diverse spectrum of videos and instructions. Quantitative and qualitative results suggest that AutoVFX outperforms all competing methods by a large margin in generative quality, instruction alignment, editing versatility, and physical plausibility.</li>
</ul>

<h3>Title: Training-free Regional Prompting for Diffusion Transformers</h3>
<ul>
<li><strong>Authors: </strong>Anthony Chen, Jianjin Xu, Wenzhao Zheng, Gaole Dai, Yida Wang, Renrui Zhang, Haofan Wang, Shanghang Zhang</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.02395">https://arxiv.org/abs/2411.02395</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.02395">https://arxiv.org/pdf/2411.02395</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.02395]] Training-free Regional Prompting for Diffusion Transformers(https://arxiv.org/abs/2411.02395)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>Diffusion models have demonstrated excellent capabilities in text-to-image generation. Their semantic understanding (i.e., prompt following) ability has also been greatly improved with large language models (e.g., T5, Llama). However, existing models cannot perfectly handle long and complex text prompts, especially when the text prompts contain various objects with numerous attributes and interrelated spatial relationships. While many regional prompting methods have been proposed for UNet-based models (SD1.5, SDXL), but there are still no implementations based on the recent Diffusion Transformer (DiT) architecture, such as SD3 and this http URL this report, we propose and implement regional prompting for FLUX.1 based on attention manipulation, which enables DiT with fined-grained compositional text-to-image generation capability in a training-free manner. Code is available at this https URL.</li>
</ul>

<h3>Title: Adaptive Caching for Faster Video Generation with Diffusion Transformers</h3>
<ul>
<li><strong>Authors: </strong>Kumara Kahatapitiya, Haozhe Liu, Sen He, Ding Liu, Menglin Jia, Michael S. Ryoo, Tian Xie</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.02397">https://arxiv.org/abs/2411.02397</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.02397">https://arxiv.org/pdf/2411.02397</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.02397]] Adaptive Caching for Faster Video Generation with Diffusion Transformers(https://arxiv.org/abs/2411.02397)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>Generating temporally-consistent high-fidelity videos can be computationally expensive, especially over longer temporal spans. More-recent Diffusion Transformers (DiTs) -- despite making significant headway in this context -- have only heightened such challenges as they rely on larger models and heavier attention mechanisms, resulting in slower inference speeds. In this paper, we introduce a training-free method to accelerate video DiTs, termed Adaptive Caching (AdaCache), which is motivated by the fact that "not all videos are created equal": meaning, some videos require fewer denoising steps to attain a reasonable quality than others. Building on this, we not only cache computations through the diffusion process, but also devise a caching schedule tailored to each video generation, maximizing the quality-latency trade-off. We further introduce a Motion Regularization (MoReg) scheme to utilize video information within AdaCache, essentially controlling the compute allocation based on motion content. Altogether, our plug-and-play contributions grant significant inference speedups (e.g. up to 4.7x on Open-Sora 720p - 2s video generation) without sacrificing the generation quality, across multiple video DiT baselines.</li>
</ul>

<h3>Title: Prompting with Phonemes: Enhancing LLM Multilinguality for non-Latin Script Languages</h3>
<ul>
<li><strong>Authors: </strong>Hoang Nguyen, Khyati Mahajan, Vikas Yadav, Philip S. Yu, Masoud Hashemi, Rishabh Maheshwary</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.02398">https://arxiv.org/abs/2411.02398</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.02398">https://arxiv.org/pdf/2411.02398</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.02398]] Prompting with Phonemes: Enhancing LLM Multilinguality for non-Latin Script Languages(https://arxiv.org/abs/2411.02398)</code><input type="text"></li>
<li><strong>Keywords: </strong>in-context</a></li>
<li><strong>Abstract: </strong>Multilingual LLMs have achieved remarkable benchmark performance, but we find they continue to underperform on non-Latin script languages across contemporary LLM families. This discrepancy arises from the fact that LLMs are pretrained with orthographic scripts, which are dominated by Latin characters that obscure their shared phonology with non-Latin scripts. We propose leveraging phonemic transcriptions as complementary signals to induce script-invariant representations. Our study demonstrates that integrating phonemic signals improves performance across both non-Latin and Latin languages, with a particularly significant impact on closing the performance gap between the two. Through detailed experiments, we show that phonemic and orthographic scripts retrieve distinct examples for in-context learning (ICL). This motivates our proposed Mixed-ICL retrieval strategy, where further aggregation leads to our significant performance improvements for both Latin script languages (up to 12.6%) and non-Latin script languages (up to 15.1%) compared to randomized ICL retrieval.</li>
</ul>

<button id="copy">Copy All</button>
</article>
<script src="../../javascript/clipboard.min.js"></script>
<script src="../../javascript/clipboard.js"></script>
