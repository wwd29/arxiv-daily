<link rel="stylesheet" href="../../css/markdown.css" />
<article class="markdown-body">
<h1>2024-12-23</h1>
<h3>Title: Modeling Story Expectations to Understand Engagement: A Generative Framework Using LLMs</h3>
<ul>
<li><strong>Authors: </strong>Hortense Fong, George Gui</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, econ.GN, stat.ME</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2412.15239">https://arxiv.org/abs/2412.15239</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2412.15239">https://arxiv.org/pdf/2412.15239</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2412.15239]] Modeling Story Expectations to Understand Engagement: A Generative Framework Using LLMs(https://arxiv.org/abs/2412.15239)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>Understanding when and why consumers engage with stories is crucial for content creators and platforms. While existing theories suggest that audience beliefs of what is going to happen should play an important role in engagement decisions, empirical work has mostly focused on developing techniques to directly extract features from actual content, rather than capturing forward-looking beliefs, due to the lack of a principled way to model such beliefs in unstructured narrative data. To complement existing feature extraction techniques, this paper introduces a novel framework that leverages large language models to model audience forward-looking beliefs about how stories might unfold. Our method generates multiple potential continuations for each story and extracts features related to expectations, uncertainty, and surprise using established content analysis techniques. Applying our method to over 30,000 book chapters from Wattpad, we demonstrate that our framework complements existing feature engineering techniques by amplifying their marginal explanatory power on average by 31%. The results reveal that different types of engagement-continuing to read, commenting, and voting-are driven by distinct combinations of current and anticipated content features. Our framework provides a novel way to study and explore how audience forward-looking beliefs shape their engagement with narrative media, with implications for marketing strategy in content-focused industries.</li>
</ul>

<h3>Title: ChainStream: An LLM-based Framework for Unified Synthetic Sensing</h3>
<ul>
<li><strong>Authors: </strong>Jiacheng Liu, Yuanchun Li, Liangyan Li, Yi Sun, Hao Wen, Xiangyu Li, Yao Guo, Yunxin Liu</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.SE</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2412.15240">https://arxiv.org/abs/2412.15240</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2412.15240">https://arxiv.org/pdf/2412.15240</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2412.15240]] ChainStream: An LLM-based Framework for Unified Synthetic Sensing(https://arxiv.org/abs/2412.15240)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>Many applications demand context sensing to offer personalized and timely services. Yet, developing sensing programs can be challenging for developers and using them is privacy-concerning for end-users. In this paper, we propose to use natural language as the unified interface to process personal data and sense user context, which can effectively ease app development and make the data pipeline more transparent. Our work is inspired by large language models (LLMs) and other generative models, while directly applying them does not solve the problem - letting the model directly process the data cannot handle complex sensing requests and letting the model write the data processing program suffers error-prone code generation. We address the problem with 1) a unified data processing framework that makes context-sensing programs simpler and 2) a feedback-guided query optimizer that makes data query more informative. To evaluate the performance of natural language-based context sensing, we create a benchmark that contains 133 context sensing tasks. Extensive evaluation has shown that our approach is able to automatically solve the context-sensing tasks efficiently and precisely. The code is opensourced at this https URL.</li>
</ul>

<h3>Title: Accelerating Retrieval-Augmented Generation</h3>
<ul>
<li><strong>Authors: </strong>Derrick Quinn, Mohammad Nouri, Neel Patel, John Salihu, Alireza Salemi, Sukhan Lee, Hamed Zamani, Mohammad Alian</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.AR, cs.DC, cs.IR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2412.15246">https://arxiv.org/abs/2412.15246</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2412.15246">https://arxiv.org/pdf/2412.15246</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2412.15246]] Accelerating Retrieval-Augmented Generation(https://arxiv.org/abs/2412.15246)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>An evolving solution to address hallucination and enhance accuracy in large language models (LLMs) is Retrieval-Augmented Generation (RAG), which involves augmenting LLMs with information retrieved from an external knowledge source, such as the web. This paper profiles several RAG execution pipelines and demystifies the complex interplay between their retrieval and generation phases. We demonstrate that while exact retrieval schemes are expensive, they can reduce inference time compared to approximate retrieval variants because an exact retrieval model can send a smaller but more accurate list of documents to the generative model while maintaining the same end-to-end accuracy. This observation motivates the acceleration of the exact nearest neighbor search for RAG. In this work, we design Intelligent Knowledge Store (IKS), a type-2 CXL device that implements a scale-out near-memory acceleration architecture with a novel cache-coherent interface between the host CPU and near-memory accelerators. IKS offers 13.4-27.9x faster exact nearest neighbor search over a 512GB vector database compared with executing the search on Intel Sapphire Rapids CPUs. This higher search performance translates to 1.7-26.3x lower end-to-end inference time for representative RAG applications. IKS is inherently a memory expander; its internal DRAM can be disaggregated and used for other applications running on the server to prevent DRAM, which is the most expensive component in today's servers, from being stranded.</li>
</ul>

<h3>Title: NER- RoBERTa: Fine-Tuning RoBERTa for Named Entity Recognition (NER) within low-resource languages</h3>
<ul>
<li><strong>Authors: </strong>Abdulhady Abas Abdullah, Srwa Hasan Abdulla, Dalia Mohammad Toufiq, Halgurd S. Maghdid, Tarik A. Rashid, Pakshan F. Farho, Shadan Sh. Sabr, Akar H. Taher, Darya S. Hamad, Hadi Veisi, Aras T. Asaad</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2412.15252">https://arxiv.org/abs/2412.15252</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2412.15252">https://arxiv.org/pdf/2412.15252</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2412.15252]] NER- RoBERTa: Fine-Tuning RoBERTa for Named Entity Recognition (NER) within low-resource languages(https://arxiv.org/abs/2412.15252)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>Nowadays, Natural Language Processing (NLP) is an important tool for most people's daily life routines, ranging from understanding speech, translation, named entity recognition (NER), and text categorization, to generative text models such as ChatGPT. Due to the existence of big data and consequently large corpora for widely used languages like English, Spanish, Turkish, Persian, and many more, these applications have been developed accurately. However, the Kurdish language still requires more corpora and large datasets to be included in NLP applications. This is because Kurdish has a rich linguistic structure, varied dialects, and a limited dataset, which poses unique challenges for Kurdish NLP (KNLP) application development. While several studies have been conducted in KNLP for various applications, Kurdish NER (KNER) remains a challenge for many KNLP tasks, including text analysis and classification. In this work, we address this limitation by proposing a methodology for fine-tuning the pre-trained RoBERTa model for KNER. To this end, we first create a Kurdish corpus, followed by designing a modified model architecture and implementing the training procedures. To evaluate the trained model, a set of experiments is conducted to demonstrate the performance of the KNER model using different tokenization methods and trained models. The experimental results show that fine-tuned RoBERTa with the SentencePiece tokenization method substantially improves KNER performance, achieving a 12.8% improvement in F1-score compared to traditional models, and consequently establishes a new benchmark for KNLP.</li>
</ul>

<h3>Title: Using Machine Learning to Distinguish Human-written from Machine-generated Creative Fiction</h3>
<ul>
<li><strong>Authors: </strong>Andrea Cristina McGlinchey, Peter J Barclay</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2412.15253">https://arxiv.org/abs/2412.15253</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2412.15253">https://arxiv.org/pdf/2412.15253</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2412.15253]] Using Machine Learning to Distinguish Human-written from Machine-generated Creative Fiction(https://arxiv.org/abs/2412.15253)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>Following the universal availability of generative AI systems with the release of ChatGPT, automatic detection of deceptive text created by Large Language Models has focused on domains such as academic plagiarism and "fake news". However, generative AI also poses a threat to the livelihood of creative writers, and perhaps to literary culture in general, through reduction in quality of published material. Training a Large Language Model on writers' output to generate "sham books" in a particular style seems to constitute a new form of plagiarism. This problem has been little researched. In this study, we trained Machine Learning classifier models to distinguish short samples of human-written from machine-generated creative fiction, focusing on classic detective novels. Our results show that a Naive Bayes and a Multi-Layer Perceptron classifier achieved a high degree of success (accuracy > 95%), significantly outperforming human judges (accuracy < 55%). This approach worked well with short text samples (around 100 words), which previous research has shown to be difficult to classify. We have deployed an online proof-of-concept classifier tool, AI Detective, as a first step towards developing lightweight and reliable applications for use by editors and publishers, with the aim of protecting the economic and cultural contribution of human authors.</li>
</ul>

<h3>Title: Context-DPO: Aligning Language Models for Context-Faithfulness</h3>
<ul>
<li><strong>Authors: </strong>Baolong Bi, Shaohan Huang, Yiwei Wang, Tianchi Yang, Zihan Zhang, Haizhen Huang, Lingrui Mei, Junfeng Fang, Zehao Li, Furu Wei, Weiwei Deng, Feng Sun, Qi Zhang, Shenghua Liu</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.IR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2412.15280">https://arxiv.org/abs/2412.15280</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2412.15280">https://arxiv.org/pdf/2412.15280</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2412.15280]] Context-DPO: Aligning Language Models for Context-Faithfulness(https://arxiv.org/abs/2412.15280)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>Reliable responses from large language models (LLMs) require adherence to user instructions and retrieved information. While alignment techniques help LLMs align with human intentions and values, improving context-faithfulness through alignment remains underexplored. To address this, we propose $\textbf{Context-DPO}$, the first alignment method specifically designed to enhance LLMs' context-faithfulness. We introduce $\textbf{ConFiQA}$, a benchmark that simulates Retrieval-Augmented Generation (RAG) scenarios with knowledge conflicts to evaluate context-faithfulness. By leveraging faithful and stubborn responses to questions with provided context from ConFiQA, our Context-DPO aligns LLMs through direct preference optimization. Extensive experiments demonstrate that our Context-DPO significantly improves context-faithfulness, achieving 35% to 280% improvements on popular open-source models. Further analysis demonstrates that Context-DPO preserves LLMs' generative capabilities while providing interpretable insights into context utilization. Our code and data are released at this https URL</li>
</ul>

<h3>Title: A Universal Model for Human Mobility Prediction</h3>
<ul>
<li><strong>Authors: </strong>Qingyue Long, Yuan Yuan, Yong Li</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2412.15294">https://arxiv.org/abs/2412.15294</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2412.15294">https://arxiv.org/pdf/2412.15294</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2412.15294]] A Universal Model for Human Mobility Prediction(https://arxiv.org/abs/2412.15294)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>Predicting human mobility is crucial for urban planning, traffic control, and emergency response. Mobility behaviors can be categorized into individual and collective, and these behaviors are recorded by diverse mobility data, such as individual trajectory and crowd flow. As different modalities of mobility data, individual trajectory and crowd flow have a close coupling relationship. Crowd flows originate from the bottom-up aggregation of individual trajectories, while the constraints imposed by crowd flows shape these individual trajectories. Existing mobility prediction methods are limited to single tasks due to modal gaps between individual trajectory and crowd flow. In this work, we aim to unify mobility prediction to break through the limitations of task-specific models. We propose a universal human mobility prediction model (named UniMob), which can be applied to both individual trajectory and crowd flow. UniMob leverages a multi-view mobility tokenizer that transforms both trajectory and flow data into spatiotemporal tokens, facilitating unified sequential modeling through a diffusion transformer architecture. To bridge the gap between the different characteristics of these two data modalities, we implement a novel bidirectional individual and collective alignment mechanism. This mechanism enables learning common spatiotemporal patterns from different mobility data, facilitating mutual enhancement of both trajectory and flow predictions. Extensive experiments on real-world datasets validate the superiority of our model over state-of-the-art baselines in trajectory and flow prediction. Especially in noisy and scarce data scenarios, our model achieves the highest performance improvement of more than 14% and 25% in MAPE and Accuracy@5.</li>
</ul>

<h3>Title: Tokenphormer: Structure-aware Multi-token Graph Transformer for Node Classification</h3>
<ul>
<li><strong>Authors: </strong>Zijie Zhou, Zhaoqi Lu, Xuekai Wei, Rongqin Chen, Shenghui Zhang, Pak Lon Ip, Leong Hou U</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2412.15302">https://arxiv.org/abs/2412.15302</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2412.15302">https://arxiv.org/pdf/2412.15302</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2412.15302]] Tokenphormer: Structure-aware Multi-token Graph Transformer for Node Classification(https://arxiv.org/abs/2412.15302)</code><input type="text"></li>
<li><strong>Keywords: </strong>self-supervised</a></li>
<li><strong>Abstract: </strong>Graph Neural Networks (GNNs) are widely used in graph data mining tasks. Traditional GNNs follow a message passing scheme that can effectively utilize local and structural information. However, the phenomena of over-smoothing and over-squashing limit the receptive field in message passing processes. Graph Transformers were introduced to address these issues, achieving a global receptive field but suffering from the noise of irrelevant nodes and loss of structural information. Therefore, drawing inspiration from fine-grained token-based representation learning in Natural Language Processing (NLP), we propose the Structure-aware Multi-token Graph Transformer (Tokenphormer), which generates multiple tokens to effectively capture local and structural information and explore global information at different levels of granularity. Specifically, we first introduce the walk-token generated by mixed walks consisting of four walk types to explore the graph and capture structure and contextual information flexibly. To ensure local and global information coverage, we also introduce the SGPM-token (obtained through the Self-supervised Graph Pre-train Model, SGPM) and the hop-token, extending the length and density limit of the walk-token, respectively. Finally, these expressive tokens are fed into the Transformer model to learn node representations collaboratively. Experimental results demonstrate that the capability of the proposed Tokenphormer can achieve state-of-the-art performance on node classification tasks.</li>
</ul>

<h3>Title: MIETT: Multi-Instance Encrypted Traffic Transformer for Encrypted Traffic Classification</h3>
<ul>
<li><strong>Authors: </strong>Xu-Yang Chen, Lu Han, De-Chuan Zhan, Han-Jia Ye</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2412.15306">https://arxiv.org/abs/2412.15306</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2412.15306">https://arxiv.org/pdf/2412.15306</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2412.15306]] MIETT: Multi-Instance Encrypted Traffic Transformer for Encrypted Traffic Classification(https://arxiv.org/abs/2412.15306)</code><input type="text"></li>
<li><strong>Keywords: </strong>foundation model</a></li>
<li><strong>Abstract: </strong>Network traffic includes data transmitted across a network, such as web browsing and file transfers, and is organized into packets (small units of data) and flows (sequences of packets exchanged between two endpoints). Classifying encrypted traffic is essential for detecting security threats and optimizing network management. Recent advancements have highlighted the superiority of foundation models in this task, particularly for their ability to leverage large amounts of unlabeled data and demonstrate strong generalization to unseen data. However, existing methods that focus on token-level relationships fail to capture broader flow patterns, as tokens, defined as sequences of hexadecimal digits, typically carry limited semantic information in encrypted traffic. These flow patterns, which are crucial for traffic classification, arise from the interactions between packets within a flow, not just their internal structure. To address this limitation, we propose a Multi-Instance Encrypted Traffic Transformer (MIETT), which adopts a multi-instance approach where each packet is treated as a distinct instance within a larger bag representing the entire flow. This enables the model to capture both token-level and packet-level relationships more effectively through Two-Level Attention (TLA) layers, improving the model's ability to learn complex packet dynamics and flow patterns. We further enhance the model's understanding of temporal and flow-specific dynamics by introducing two novel pre-training tasks: Packet Relative Position Prediction (PRPP) and Flow Contrastive Learning (FCL). After fine-tuning, MIETT achieves state-of-the-art (SOTA) results across five datasets, demonstrating its effectiveness in classifying encrypted traffic and understanding complex network behaviors. Code is available at \url{this https URL}.</li>
</ul>

<h3>Title: Conceptual In-Context Learning and Chain of Concepts: Solving Complex Conceptual Problems Using Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Nishtha N. Vaidya, Thomas Runkler, Thomas Hubauer, Veronika Haderlein-Hoegberg, Maja Mlicic Brandt</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2412.15309">https://arxiv.org/abs/2412.15309</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2412.15309">https://arxiv.org/pdf/2412.15309</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2412.15309]] Conceptual In-Context Learning and Chain of Concepts: Solving Complex Conceptual Problems Using Large Language Models(https://arxiv.org/abs/2412.15309)</code><input type="text"></li>
<li><strong>Keywords: </strong>in-context</a></li>
<li><strong>Abstract: </strong>Science and engineering problems fall in the category of complex conceptual problems that require specific conceptual information (CI) like math/logic -related know-how, process information, or engineering guidelines to solve them. Large Language Models (LLMs) are promising agents to solve such complex conceptual problems due to their implications in advancing engineering and science tasks like assisted problem-solving. But vanilla LLMs, trained on open-world data, lack the necessary CI. In this work, we specifically explore shallow customization methods (SCMs) of LLMs for solving complex conceptual problems. We propose two novel SCM algorithms for LLM, to augment LLMs with CI and enable LLMs to solve complex conceptual problems: Conceptual In-Context Learning (C-ICL) and Chain of Concepts (CoC). The problem tackled in this paper is generation of proprietary data models in the engineering/industry domain based on conceptual information in data modelling guidelines. We evaluate our algorithms on varied sizes of the OpenAI LLMs against four evaluation metrics related to syntactic and semantic correctness, time and cost incurred. The proposed algorithms perform better than currently popular LLM SCMs like In-context Learning (ICL) and Chain of Thoughts (CoT). It was observed that as compared to CoT, response correctness increased by 30.6% and 29.88% for the new SCMs C-ICL and CoC respectively. Qualitative analysis suggests that the proposed new SCMs activate emergent capabilities in LLMs, previously unobserved in the existing SCMs. They make problem-solving processes more transparent and reduce hallucinations and the tendency of model responses to copy examples from prompts (parroting).</li>
</ul>

<h3>Title: Efficient Fine-Tuning and Concept Suppression for Pruned Diffusion Models</h3>
<ul>
<li><strong>Authors: </strong>Reza Shirkavand, Peiran Yu, Shangqian Gao, Gowthami Somepalli, Tom Goldstein, Heng Huang</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2412.15341">https://arxiv.org/abs/2412.15341</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2412.15341">https://arxiv.org/pdf/2412.15341</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2412.15341]] Efficient Fine-Tuning and Concept Suppression for Pruned Diffusion Models(https://arxiv.org/abs/2412.15341)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, generative</a></li>
<li><strong>Abstract: </strong>Recent advances in diffusion generative models have yielded remarkable progress. While the quality of generated content continues to improve, these models have grown considerably in size and complexity. This increasing computational burden poses significant challenges, particularly in resource-constrained deployment scenarios such as mobile devices. The combination of model pruning and knowledge distillation has emerged as a promising solution to reduce computational demands while preserving generation quality. However, this technique inadvertently propagates undesirable behaviors, including the generation of copyrighted content and unsafe concepts, even when such instances are absent from the fine-tuning dataset. In this paper, we propose a novel bilevel optimization framework for pruned diffusion models that consolidates the fine-tuning and unlearning processes into a unified phase. Our approach maintains the principal advantages of distillation-namely, efficient convergence and style transfer capabilities-while selectively suppressing the generation of unwanted content. This plug-in framework is compatible with various pruning and concept unlearning methods, facilitating efficient, safe deployment of diffusion models in controlled environments.</li>
</ul>

<h3>Title: Large Language Models on Small Resource-Constrained Systems: Performance Characterization, Analysis and Trade-offs</h3>
<ul>
<li><strong>Authors: </strong>Liam Seymour, Basar Kutukcu, Sabur Baidya</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CC</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2412.15352">https://arxiv.org/abs/2412.15352</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2412.15352">https://arxiv.org/pdf/2412.15352</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2412.15352]] Large Language Models on Small Resource-Constrained Systems: Performance Characterization, Analysis and Trade-offs(https://arxiv.org/abs/2412.15352)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>Generative AI like the Large Language Models (LLMs) has become more available for the general consumer in recent years. Publicly available services, e.g., ChatGPT, perform token generation on networked cloud server hardware, effectively removing the hardware entry cost for end users. However, the reliance on network access for these services, privacy and security risks involved, and sometimes the needs of the application make it necessary to run LLMs locally on edge devices. A significant amount of research has been done on optimization of LLMs and other transformer-based models on non-networked, resource-constrained devices, but they typically target older hardware. Our research intends to provide a 'baseline' characterization of more recent commercially available embedded hardware for LLMs, and to provide a simple utility to facilitate batch testing LLMs on recent Jetson hardware. We focus on the latest line of NVIDIA Jetson devices (Jetson Orin), and a set of publicly available LLMs (Pythia) ranging between 70 million and 1.4 billion parameters. Through detailed experimental evaluation with varying software and hardware parameters, we showcase trade-off spaces and optimization choices. Additionally, we design our testing structure to facilitate further research that involves performing batch LLM testing on Jetson hardware.</li>
</ul>

<h3>Title: Dataset Augmentation by Mixing Visual Concepts</h3>
<ul>
<li><strong>Authors: </strong>Abdullah Al Rahat, Hemanth Venkateswara</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2412.15358">https://arxiv.org/abs/2412.15358</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2412.15358">https://arxiv.org/pdf/2412.15358</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2412.15358]] Dataset Augmentation by Mixing Visual Concepts(https://arxiv.org/abs/2412.15358)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>This paper proposes a dataset augmentation method by fine-tuning pre-trained diffusion models. Generating images using a pre-trained diffusion model with textual conditioning often results in domain discrepancy between real data and generated images. We propose a fine-tuning approach where we adapt the diffusion model by conditioning it with real images and novel text embeddings. We introduce a unique procedure called Mixing Visual Concepts (MVC) where we create novel text embeddings from image captions. The MVC enables us to generate multiple images which are diverse and yet similar to the real data enabling us to perform effective dataset augmentation. We perform comprehensive qualitative and quantitative evaluations with the proposed dataset augmentation approach showcasing both coarse-grained and finegrained changes in generated images. Our approach outperforms state-of-the-art augmentation techniques on benchmark classification tasks.</li>
</ul>

<h3>Title: Spatiotemporally Coherent Probabilistic Generation of Weather from Climate</h3>
<ul>
<li><strong>Authors: </strong>Jonathan Schmidt, Luca Schmidt, Felix Strnad, Nicole Ludwig, Philipp Hennig</a></li>
<li><strong>Subjects: </strong>cs.LG, physics.ao-ph</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2412.15361">https://arxiv.org/abs/2412.15361</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2412.15361">https://arxiv.org/pdf/2412.15361</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2412.15361]] Spatiotemporally Coherent Probabilistic Generation of Weather from Climate(https://arxiv.org/abs/2412.15361)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, generative</a></li>
<li><strong>Abstract: </strong>Local climate information is crucial for impact assessment and decision-making, yet coarse global climate simulations cannot capture small-scale phenomena. Current statistical downscaling methods infer these phenomena as temporally decoupled spatial patches. However, to preserve physical properties, estimating spatio-temporally coherent high-resolution weather dynamics for multiple variables across long time horizons is crucial. We present a novel generative approach that uses a score-based diffusion model trained on high-resolution reanalysis data to capture the statistical properties of local weather dynamics. After training, we condition on coarse climate model data to generate weather patterns consistent with the aggregate information. As this inference task is inherently uncertain, we leverage the probabilistic nature of diffusion models and sample multiple trajectories. We evaluate our approach with high-resolution reanalysis information before applying it to the climate model downscaling task. We then demonstrate that the model generates spatially and temporally coherent weather dynamics that align with global climate output.</li>
</ul>

<h3>Title: Maximising Histopathology Segmentation using Minimal Labels via Self-Supervision</h3>
<ul>
<li><strong>Authors: </strong>Zeeshan Nisar, Thomas Lampert</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2412.15389">https://arxiv.org/abs/2412.15389</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2412.15389">https://arxiv.org/pdf/2412.15389</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2412.15389]] Maximising Histopathology Segmentation using Minimal Labels via Self-Supervision(https://arxiv.org/abs/2412.15389)</code><input type="text"></li>
<li><strong>Keywords: </strong>self-supervised</a></li>
<li><strong>Abstract: </strong>Histopathology, the microscopic examination of tissue samples, is essential for disease diagnosis and prognosis. Accurate segmentation and identification of key regions in histopathology images are crucial for developing automated solutions. However, state-of-art deep learning segmentation methods like UNet require extensive labels, which is both costly and time-consuming, particularly when dealing with multiple stainings. To mitigate this, multi-stain segmentation methods such as MDS1 and UDAGAN have been developed, which reduce the need for labels by requiring only one (source) stain to be labelled. Nonetheless, obtaining source stain labels can still be challenging, and segmentation models fail when they are unavailable. This article shows that through self-supervised pre-training, including SimCLR, BYOL, and a novel approach, HR-CS-CO, the performance of these segmentation methods (UNet, MDS1, and UDAGAN) can be retained even with 95% fewer labels. Notably, with self-supervised pre-training and using only 5% labels, the performance drops are minimal: 5.9% for UNet, 4.5% for MDS1, and 6.2% for UDAGAN, compared to their respective fully supervised counterparts (without pre-training, using 100% labels). The code is available from this https URL [to be made public upon acceptance].</li>
</ul>

<h3>Title: GCA-3D: Towards Generalized and Consistent Domain Adaptation of 3D Generators</h3>
<ul>
<li><strong>Authors: </strong>Hengjia Li, Yang Liu, Yibo Zhao, Haoran Cheng, Yang Yang, Linxuan Xia, Zekai Luo, Qibo Qiu, Boxi Wu, Tu Zheng, Zheng Yang, Deng Cai</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2412.15491">https://arxiv.org/abs/2412.15491</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2412.15491">https://arxiv.org/pdf/2412.15491</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2412.15491]] GCA-3D: Towards Generalized and Consistent Domain Adaptation of 3D Generators(https://arxiv.org/abs/2412.15491)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, generative</a></li>
<li><strong>Abstract: </strong>Recently, 3D generative domain adaptation has emerged to adapt the pre-trained generator to other domains without collecting massive datasets and camera pose distributions. Typically, they leverage large-scale pre-trained text-to-image diffusion models to synthesize images for the target domain and then fine-tune the 3D model. However, they suffer from the tedious pipeline of data generation, which inevitably introduces pose bias between the source domain and synthetic dataset. Furthermore, they are not generalized to support one-shot image-guided domain adaptation, which is more challenging due to the more severe pose bias and additional identity bias introduced by the single image reference. To address these issues, we propose GCA-3D, a generalized and consistent 3D domain adaptation method without the intricate pipeline of data generation. Different from previous pipeline methods, we introduce multi-modal depth-aware score distillation sampling loss to efficiently adapt 3D generative models in a non-adversarial manner. This multi-modal loss enables GCA-3D in both text prompt and one-shot image prompt adaptation. Besides, it leverages per-instance depth maps from the volume rendering module to mitigate the overfitting problem and retain the diversity of results. To enhance the pose and identity consistency, we further propose a hierarchical spatial consistency loss to align the spatial structure between the generated images in the source and target domain. Experiments demonstrate that GCA-3D outperforms previous methods in terms of efficiency, generalization, pose accuracy, and identity consistency.</li>
</ul>

<h3>Title: Stylish and Functional: Guided Interpolation Subject to Physical Constraints</h3>
<ul>
<li><strong>Authors: </strong>Yan-Ying Chen, Nikos Arechiga, Chenyang Yuan, Matthew Hong, Matt Klenk, Charlene Wu</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2412.15507">https://arxiv.org/abs/2412.15507</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2412.15507">https://arxiv.org/pdf/2412.15507</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2412.15507]] Stylish and Functional: Guided Interpolation Subject to Physical Constraints(https://arxiv.org/abs/2412.15507)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, foundation model, generative</a></li>
<li><strong>Abstract: </strong>Generative AI is revolutionizing engineering design practices by enabling rapid prototyping and manipulation of designs. One example of design manipulation involves taking two reference design images and using them as prompts to generate a design image that combines aspects of both. Real engineering designs have physical constraints and functional requirements in addition to aesthetic design considerations. Internet-scale foundation models commonly used for image generation, however, are unable to take these physical constraints and functional requirements into consideration as part of the generation process. We consider the problem of generating a design inspired by two input designs, and propose a zero-shot framework toward enforcing physical, functional requirements over the generation process by leveraging a pretrained diffusion model as the backbone. As a case study, we consider the example of rotational symmetry in generation of wheel designs. Automotive wheels are required to be rotationally symmetric for physical stability. We formulate the requirement of rotational symmetry by the use of a symmetrizer, and we use this symmetrizer to guide the diffusion process towards symmetric wheel generations. Our experimental results find that the proposed approach makes generated interpolations with higher realism than methods in related work, as evaluated by Fréchet inception distance (FID). We also find that our approach generates designs that more closely satisfy physical and functional requirements than generating without the symmetry guidance.</li>
</ul>

<h3>Title: XRAG: eXamining the Core -- Benchmarking Foundational Components in Advanced Retrieval-Augmented Generation</h3>
<ul>
<li><strong>Authors: </strong>Qianren Mao, Yangyifei Luo, Jinlong Zhang, Hanwen Hao, Zhilong Cao, Xiaolong Wang, Xiao Guan, Zhenting Huang, Weifeng Jiang, Shuyu Guo, Zhentao Han, Qili Zhang, Siyuan Tao, Yujie Liu, Junnan Liu, Zhixing Tan, Jie Sun, Bo Li, Xudong Liu, Richong Zhang, Jianxin Li</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2412.15529">https://arxiv.org/abs/2412.15529</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2412.15529">https://arxiv.org/pdf/2412.15529</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2412.15529]] XRAG: eXamining the Core -- Benchmarking Foundational Components in Advanced Retrieval-Augmented Generation(https://arxiv.org/abs/2412.15529)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>Retrieval-augmented generation (RAG) synergizes the retrieval of pertinent data with the generative capabilities of Large Language Models (LLMs), ensuring that the generated output is not only contextually relevant but also accurate and this http URL introduce XRAG, an open-source, modular codebase that facilitates exhaustive evaluation of the performance of foundational components of advanced RAG modules. These components are systematically categorized into four core phases: pre-retrieval, retrieval, post-retrieval, and generation. We systematically analyse them across reconfigured datasets, providing a comprehensive benchmark for their effectiveness. Given the escalating complexity of RAG systems, we underscore the necessity of identifying potential failure points of RAG modules. We formulate a suite of experimental methodologies and diagnostic testing protocols to dissect the failure points inherent in the engineering of RAG modules. Subsequently, we proffer bespoke solutions that are designed to augment the validation processes and bolster the overall performance of these modules. Our work thoroughly evaluates the performance of core advanced components in RAG systems, providing insights into optimizations for prevalent failure points.</li>
</ul>

<h3>Title: ChangeDiff: A Multi-Temporal Change Detection Data Generator with Flexible Text Prompts via Diffusion Model</h3>
<ul>
<li><strong>Authors: </strong>Qi Zang, Jiayi Yang, Shuang Wang, Dong Zhao, Wenjun Yi, Zhun Zhong</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2412.15541">https://arxiv.org/abs/2412.15541</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2412.15541">https://arxiv.org/pdf/2412.15541</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2412.15541]] ChangeDiff: A Multi-Temporal Change Detection Data Generator with Flexible Text Prompts via Diffusion Model(https://arxiv.org/abs/2412.15541)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, generative</a></li>
<li><strong>Abstract: </strong>Data-driven deep learning models have enabled tremendous progress in change detection (CD) with the support of pixel-level annotations. However, collecting diverse data and manually annotating them is costly, laborious, and knowledge-intensive. Existing generative methods for CD data synthesis show competitive potential in addressing this issue but still face the following limitations: 1) difficulty in flexibly controlling change events, 2) dependence on additional data to train the data generators, 3) focus on specific change detection tasks. To this end, this paper focuses on the semantic CD (SCD) task and develops a multi-temporal SCD data generator ChangeDiff by exploring powerful diffusion models. ChangeDiff innovatively generates change data in two steps: first, it uses text prompts and a text-to-layout (T2L) model to create continuous layouts, and then it employs layout-to-image (L2I) to convert these layouts into images. Specifically, we propose multi-class distribution-guided text prompts (MCDG-TP), allowing for layouts to be generated flexibly through controllable classes and their corresponding ratios. Subsequently, to generalize the T2L model to the proposed MCDG-TP, a class distribution refinement loss is further designed as training supervision. %For the former, a multi-classdistribution-guided text prompt (MCDG-TP) is proposed to complement via controllable classes and ratios. To generalize the text-to-image diffusion model to the proposed MCDG-TP, a class distribution refinement loss is designed as training supervision. For the latter, MCDG-TP in three modes is proposed to synthesize new layout masks from various texts. Our generated data shows significant progress in temporal continuity, spatial diversity, and quality realism, empowering change detectors with accuracy and transferability. The code is available at this https URL</li>
</ul>

<h3>Title: In-context Continual Learning Assisted by an External Continual Learner</h3>
<ul>
<li><strong>Authors: </strong>Saleh Momeni, Sahisnu Mazumder, Zixuan Ke, Bing Liu</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2412.15563">https://arxiv.org/abs/2412.15563</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2412.15563">https://arxiv.org/pdf/2412.15563</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2412.15563]] In-context Continual Learning Assisted by an External Continual Learner(https://arxiv.org/abs/2412.15563)</code><input type="text"></li>
<li><strong>Keywords: </strong>in-context</a></li>
<li><strong>Abstract: </strong>Existing continual learning (CL) methods mainly rely on fine-tuning or adapting large language models (LLMs). They still suffer from catastrophic forgetting (CF). Little work has been done to exploit in-context learning (ICL) to leverage the extensive knowledge within LLMs for CL without updating any parameters. However, incrementally learning each new task in ICL necessitates adding training examples from each class of the task to the prompt, which hampers scalability as the prompt length increases. This issue not only leads to excessively long prompts that exceed the input token limit of the underlying LLM but also degrades the model's performance due to the overextended context. To address this, we introduce InCA, a novel approach that integrates an external continual learner (ECL) with ICL to enable scalable CL without CF. The ECL is built incrementally to pre-select a small subset of likely classes for each test instance. By restricting the ICL prompt to only these selected classes, InCA prevents prompt lengths from becoming excessively long, while maintaining high performance. Experimental results demonstrate that InCA significantly outperforms existing CL baselines, achieving substantial performance gains.</li>
</ul>

<h3>Title: DefFiller: Mask-Conditioned Diffusion for Salient Steel Surface Defect Generation</h3>
<ul>
<li><strong>Authors: </strong>Yichun Tai, Zhenzhen Huang, Tao Peng, Zhijiang Zhang</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2412.15570">https://arxiv.org/abs/2412.15570</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2412.15570">https://arxiv.org/pdf/2412.15570</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2412.15570]] DefFiller: Mask-Conditioned Diffusion for Salient Steel Surface Defect Generation(https://arxiv.org/abs/2412.15570)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, generative</a></li>
<li><strong>Abstract: </strong>Current saliency-based defect detection methods show promise in industrial settings, but the unpredictability of defects in steel production environments complicates dataset creation, hampering model performance. Existing data augmentation approaches using generative models often require pixel-level annotations, which are time-consuming and resource-intensive. To address this, we introduce DefFiller, a mask-conditioned defect generation method that leverages a layout-to-image diffusion model. DefFiller generates defect samples paired with mask conditions, eliminating the need for pixel-level annotations and enabling direct use in model training. We also develop an evaluation framework to assess the quality of generated samples and their impact on detection performance. Experimental results on the SD-Saliency-900 dataset demonstrate that DefFiller produces high-quality defect images that accurately match the provided mask conditions, significantly enhancing the performance of saliency-based defect detection models trained on the augmented dataset.</li>
</ul>

<h3>Title: Continual Learning Using a Kernel-Based Method Over Foundation Models</h3>
<ul>
<li><strong>Authors: </strong>Saleh Momeni, Sahisnu Mazumder, Bing Liu</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CL, cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2412.15571">https://arxiv.org/abs/2412.15571</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2412.15571">https://arxiv.org/pdf/2412.15571</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2412.15571]] Continual Learning Using a Kernel-Based Method Over Foundation Models(https://arxiv.org/abs/2412.15571)</code><input type="text"></li>
<li><strong>Keywords: </strong>foundation model</a></li>
<li><strong>Abstract: </strong>Continual learning (CL) learns a sequence of tasks incrementally. This paper studies the challenging CL setting of class-incremental learning (CIL). CIL has two key challenges: catastrophic forgetting (CF) and inter-task class separation (ICS). Despite numerous proposed methods, these issues remain persistent obstacles. This paper proposes a novel CIL method, called Kernel Linear Discriminant Analysis (KLDA), that can effectively avoid CF and ICS problems. It leverages only the powerful features learned in a foundation model (FM). However, directly using these features proves suboptimal. To address this, KLDA incorporates the Radial Basis Function (RBF) kernel and its Random Fourier Features (RFF) to enhance the feature representations from the FM, leading to improved performance. When a new task arrives, KLDA computes only the mean for each class in the task and updates a shared covariance matrix for all learned classes based on the kernelized features. Classification is performed using Linear Discriminant Analysis. Our empirical evaluation using text and image classification datasets demonstrates that KLDA significantly outperforms baselines. Remarkably, without relying on replay data, KLDA achieves accuracy comparable to joint training of all classes, which is considered the upper bound for CIL performance. The KLDA code is available at this https URL.</li>
</ul>

<h3>Title: A Deep Probabilistic Framework for Continuous Time Dynamic Graph Generation</h3>
<ul>
<li><strong>Authors: </strong>Ryien Hosseini, Filippo Simini, Venkatram Vishwanath, Henry Hoffmann</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2412.15582">https://arxiv.org/abs/2412.15582</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2412.15582">https://arxiv.org/pdf/2412.15582</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2412.15582]] A Deep Probabilistic Framework for Continuous Time Dynamic Graph Generation(https://arxiv.org/abs/2412.15582)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative, anomaly</a></li>
<li><strong>Abstract: </strong>Recent advancements in graph representation learning have shifted attention towards dynamic graphs, which exhibit evolving topologies and features over time. The increased use of such graphs creates a paramount need for generative models suitable for applications such as data augmentation, obfuscation, and anomaly detection. However, there are few generative techniques that handle continuously changing temporal graph data; existing work largely relies on augmenting static graphs with additional temporal information to model dynamic interactions between nodes. In this work, we propose a fundamentally different approach: We instead directly model interactions as a joint probability of an edge forming between two nodes at a given time. This allows us to autoregressively generate new synthetic dynamic graphs in a largely assumption free, scalable, and inductive manner. We formalize this approach as DG-Gen, a generative framework for continuous time dynamic graphs, and demonstrate its effectiveness over five datasets. Our experiments demonstrate that DG-Gen not only generates higher fidelity graphs compared to traditional methods but also significantly advances link prediction tasks.</li>
</ul>

<h3>Title: Pre-training Graph Neural Networks on Molecules by Using Subgraph-Conditioned Graph Information Bottleneck</h3>
<ul>
<li><strong>Authors: </strong>Van Thuy Hoang, O-Joun Lee</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2412.15589">https://arxiv.org/abs/2412.15589</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2412.15589">https://arxiv.org/pdf/2412.15589</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2412.15589]] Pre-training Graph Neural Networks on Molecules by Using Subgraph-Conditioned Graph Information Bottleneck(https://arxiv.org/abs/2412.15589)</code><input type="text"></li>
<li><strong>Keywords: </strong>self-supervised</a></li>
<li><strong>Abstract: </strong>This study aims to build a pre-trained Graph Neural Network (GNN) model on molecules without human annotations or prior knowledge. Although various attempts have been proposed to overcome limitations in acquiring labeled molecules, the previous pre-training methods still rely on semantic subgraphs, i.e., functional groups. Only focusing on the functional groups could overlook the graph-level distinctions. The key challenge to build a pre-trained GNN on molecules is how to (1) generate well-distinguished graph-level representations and (2) automatically discover the functional groups without prior knowledge. To solve it, we propose a novel Subgraph-conditioned Graph Information Bottleneck, named S-CGIB, for pre-training GNNs to recognize core subgraphs (graph cores) and significant subgraphs. The main idea is that the graph cores contain compressed and sufficient information that could generate well-distinguished graph-level representations and reconstruct the input graph conditioned on significant subgraphs across molecules under the S-CGIB principle. To discover significant subgraphs without prior knowledge about functional groups, we propose generating a set of functional group candidates, i.e., ego networks, and using an attention-based interaction between the graph core and the candidates. Despite being identified from self-supervised learning, our learned subgraphs match the real-world functional groups. Extensive experiments on molecule datasets across various domains demonstrate the superiority of S-CGIB.</li>
</ul>

<h3>Title: Dynamic Label Name Refinement for Few-Shot Dialogue Intent Classification</h3>
<ul>
<li><strong>Authors: </strong>Gyutae Park, Ingeol Baek, ByeongJeong Kim, Joongbo Shin, Hwanhee Lee</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2412.15603">https://arxiv.org/abs/2412.15603</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2412.15603">https://arxiv.org/pdf/2412.15603</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2412.15603]] Dynamic Label Name Refinement for Few-Shot Dialogue Intent Classification(https://arxiv.org/abs/2412.15603)</code><input type="text"></li>
<li><strong>Keywords: </strong>in-context</a></li>
<li><strong>Abstract: </strong>Dialogue intent classification aims to identify the underlying purpose or intent of a user's input in a conversation. Current intent classification systems encounter considerable challenges, primarily due to the vast number of possible intents and the significant semantic overlap among similar intent classes. In this paper, we propose a novel approach to few-shot dialogue intent classification through in-context learning, incorporating dynamic label refinement to address these challenges. Our method retrieves relevant examples for a test input from the training set and leverages a large language model to dynamically refine intent labels based on semantic understanding, ensuring that intents are clearly distinguishable from one another. Experimental results demonstrate that our approach effectively resolves confusion between semantically similar intents, resulting in significantly enhanced performance across multiple datasets compared to baselines. We also show that our method generates more interpretable intent labels, and has a better semantic coherence in capturing underlying user intents compared to baselines.</li>
</ul>

<h3>Title: Can Input Attributions Interpret the Inductive Reasoning Process Elicited in In-Context Learning?</h3>
<ul>
<li><strong>Authors: </strong>Mengyu Ye, Tatsuki Kuribayashi, Goro Kobayashi, Jun Suzuki</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2412.15628">https://arxiv.org/abs/2412.15628</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2412.15628">https://arxiv.org/pdf/2412.15628</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2412.15628]] Can Input Attributions Interpret the Inductive Reasoning Process Elicited in In-Context Learning?(https://arxiv.org/abs/2412.15628)</code><input type="text"></li>
<li><strong>Keywords: </strong>in-context</a></li>
<li><strong>Abstract: </strong>Elucidating the rationale behind neural models' outputs has been challenging in the machine learning field, which is indeed applicable in this age of large language models (LLMs) and in-context learning (ICL). When it comes to estimating input attributions (IA), ICL poses a new issue of interpreting which example in the prompt, consisting of a set of examples, contributed to identifying the task/rule to be solved. To this end, in this paper, we introduce synthetic diagnostic tasks inspired by the poverty of the stimulus design in inductive reasoning; here, most in-context examples are ambiguous w.r.t. their underlying rule, and one critical example disambiguates the task demonstrated. The question is whether conventional IA methods can identify such an example in interpreting the inductive reasoning process in ICL. Our experiments provide several practical findings; for example, a certain simple IA method works the best, and the larger the model, the generally harder it is to interpret the ICL with gradient-based IA methods.</li>
</ul>

<h3>Title: CustomTTT: Motion and Appearance Customized Video Generation via Test-Time Training</h3>
<ul>
<li><strong>Authors: </strong>Xiuli Bi, Jian Lu, Bo Liu, Xiaodong Cun, Yong Zhang, Weisheng Li, Bin Xiao</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2412.15646">https://arxiv.org/abs/2412.15646</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2412.15646">https://arxiv.org/pdf/2412.15646</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2412.15646]] CustomTTT: Motion and Appearance Customized Video Generation via Test-Time Training(https://arxiv.org/abs/2412.15646)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>Benefiting from large-scale pre-training of text-video pairs, current text-to-video (T2V) diffusion models can generate high-quality videos from the text description. Besides, given some reference images or videos, the parameter-efficient fine-tuning method, i.e. LoRA, can generate high-quality customized concepts, e.g., the specific subject or the motions from a reference video. However, combining the trained multiple concepts from different references into a single network shows obvious artifacts. To this end, we propose CustomTTT, where we can joint custom the appearance and the motion of the given video easily. In detail, we first analyze the prompt influence in the current video diffusion model and find the LoRAs are only needed for the specific layers for appearance and motion customization. Besides, since each LoRA is trained individually, we propose a novel test-time training technique to update parameters after combination utilizing the trained customized models. We conduct detailed experiments to verify the effectiveness of the proposed methods. Our method outperforms several state-of-the-art works in both qualitative and quantitative evaluations.</li>
</ul>

<h3>Title: Synthetic Tabular Data Generation for Imbalanced Classification: The Surprising Effectiveness of an Overlap Class</h3>
<ul>
<li><strong>Authors: </strong>Annie D'souza, Swetha M, Sunita Sarawagi</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2412.15657">https://arxiv.org/abs/2412.15657</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2412.15657">https://arxiv.org/pdf/2412.15657</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2412.15657]] Synthetic Tabular Data Generation for Imbalanced Classification: The Surprising Effectiveness of an Overlap Class(https://arxiv.org/abs/2412.15657)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, generative</a></li>
<li><strong>Abstract: </strong>Handling imbalance in class distribution when building a classifier over tabular data has been a problem of long-standing interest. One popular approach is augmenting the training dataset with synthetically generated data. While classical augmentation techniques were limited to linear interpolation of existing minority class examples, recently higher capacity deep generative models are providing greater promise. However, handling of imbalance in class distribution when building a deep generative model is also a challenging problem, that has not been studied as extensively as imbalanced classifier model training. We show that state-of-the-art deep generative models yield significantly lower-quality minority examples than majority examples. %In this paper, we start with the observation that imbalanced data training of generative models trained imbalanced dataset which under-represent the minority class. We propose a novel technique of converting the binary class labels to ternary class labels by introducing a class for the region where minority and majority distributions overlap. We show that just this pre-processing of the training set, significantly improves the quality of data generated spanning several state-of-the-art diffusion and GAN-based models. While training the classifier using synthetic data, we remove the overlap class from the training data and justify the reasons behind the enhanced accuracy. We perform extensive experiments on four real-life datasets, five different classifiers, and five generative models demonstrating that our method enhances not only the synthesizer performance of state-of-the-art models but also the classifier performance.</li>
</ul>

<h3>Title: SCENIC: Scene-aware Semantic Navigation with Instruction-guided Control</h3>
<ul>
<li><strong>Authors: </strong>Xiaohan Zhang, Sebastian Starke, Vladimir Guzov, Zhensong Zhang, Eduardo Pérez Pellitero, Gerard Pons-Moll</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2412.15664">https://arxiv.org/abs/2412.15664</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2412.15664">https://arxiv.org/pdf/2412.15664</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2412.15664]] SCENIC: Scene-aware Semantic Navigation with Instruction-guided Control(https://arxiv.org/abs/2412.15664)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>Synthesizing natural human motion that adapts to complex environments while allowing creative control remains a fundamental challenge in motion synthesis. Existing models often fall short, either by assuming flat terrain or lacking the ability to control motion semantics through text. To address these limitations, we introduce SCENIC, a diffusion model designed to generate human motion that adapts to dynamic terrains within virtual scenes while enabling semantic control through natural language. The key technical challenge lies in simultaneously reasoning about complex scene geometry while maintaining text control. This requires understanding both high-level navigation goals and fine-grained environmental constraints. The model must ensure physical plausibility and precise navigation across varied terrain, while also preserving user-specified text control, such as ``carefully stepping over obstacles" or ``walking upstairs like a zombie." Our solution introduces a hierarchical scene reasoning approach. At its core is a novel scene-dependent, goal-centric canonicalization that handles high-level goal constraint, and is complemented by an ego-centric distance field that captures local geometric details. This dual representation enables our model to generate physically plausible motion across diverse 3D scenes. By implementing frame-wise text alignment, our system achieves seamless transitions between different motion styles while maintaining scene constraints. Experiments demonstrate our novel diffusion model generates arbitrarily long human motions that both adapt to complex scenes with varying terrain surfaces and respond to textual prompts. Additionally, we show SCENIC can generalize to four real-scene datasets. Our code, dataset, and models will be released at \url{this https URL}.</li>
</ul>

<h3>Title: Learning Group Interactions and Semantic Intentions for Multi-Object Trajectory Prediction</h3>
<ul>
<li><strong>Authors: </strong>Mengshi Qi, Yuxin Yang, Huadong Ma</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2412.15673">https://arxiv.org/abs/2412.15673</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2412.15673">https://arxiv.org/pdf/2412.15673</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2412.15673]] Learning Group Interactions and Semantic Intentions for Multi-Object Trajectory Prediction(https://arxiv.org/abs/2412.15673)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>Effective modeling of group interactions and dynamic semantic intentions is crucial for forecasting behaviors like trajectories or movements. In complex scenarios like sports, agents' trajectories are influenced by group interactions and intentions, including team strategies and opponent actions. To this end, we propose a novel diffusion-based trajectory prediction framework that integrates group-level interactions into a conditional diffusion model, enabling the generation of diverse trajectories aligned with specific group activity. To capture dynamic semantic intentions, we frame group interaction prediction as a cooperative game, using Banzhaf interaction to model cooperation trends. We then fuse semantic intentions with enhanced agent embeddings, which are refined through both global and local aggregation. Furthermore, we expand the NBA SportVU dataset by adding human annotations of team-level tactics for trajectory and tactic prediction tasks. Extensive experiments on three widely-adopted datasets demonstrate that our model outperforms state-of-the-art methods. Our source code and data are available at this https URL.</li>
</ul>

<h3>Title: PersonaMagic: Stage-Regulated High-Fidelity Face Customization with Tandem Equilibrium</h3>
<ul>
<li><strong>Authors: </strong>Xinzhe Li, Jiahui Zhan, Shengfeng He, Yangyang Xu, Junyu Dong, Huaidong Zhang, Yong Du</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2412.15674">https://arxiv.org/abs/2412.15674</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2412.15674">https://arxiv.org/pdf/2412.15674</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2412.15674]] PersonaMagic: Stage-Regulated High-Fidelity Face Customization with Tandem Equilibrium(https://arxiv.org/abs/2412.15674)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>Personalized image generation has made significant strides in adapting content to novel concepts. However, a persistent challenge remains: balancing the accurate reconstruction of unseen concepts with the need for editability according to the prompt, especially when dealing with the complex nuances of facial features. In this study, we delve into the temporal dynamics of the text-to-image conditioning process, emphasizing the crucial role of stage partitioning in introducing new concepts. We present PersonaMagic, a stage-regulated generative technique designed for high-fidelity face customization. Using a simple MLP network, our method learns a series of embeddings within a specific timestep interval to capture face concepts. Additionally, we develop a Tandem Equilibrium mechanism that adjusts self-attention responses in the text encoder, balancing text description and identity preservation, improving both areas. Extensive experiments confirm the superiority of PersonaMagic over state-of-the-art methods in both qualitative and quantitative evaluations. Moreover, its robustness and flexibility are validated in non-facial domains, and it can also serve as a valuable plug-in for enhancing the performance of pretrained personalization models.</li>
</ul>

<h3>Title: Multi-Pair Temporal Sentence Grounding via Multi-Thread Knowledge Transfer Network</h3>
<ul>
<li><strong>Authors: </strong>Xiang Fang, Wanlong Fang, Changshuo Wang, Daizong Liu, Keke Tang, Jianfeng Dong, Pan Zhou, Beibei Li</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2412.15678">https://arxiv.org/abs/2412.15678</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2412.15678">https://arxiv.org/pdf/2412.15678</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2412.15678]] Multi-Pair Temporal Sentence Grounding via Multi-Thread Knowledge Transfer Network(https://arxiv.org/abs/2412.15678)</code><input type="text"></li>
<li><strong>Keywords: </strong>self-supervised</a></li>
<li><strong>Abstract: </strong>Given some video-query pairs with untrimmed videos and sentence queries, temporal sentence grounding (TSG) aims to locate query-relevant segments in these videos. Although previous respectable TSG methods have achieved remarkable success, they train each video-query pair separately and ignore the relationship between different pairs. We observe that the similar video/query content not only helps the TSG model better understand and generalize the cross-modal representation but also assists the model in locating some complex video-query pairs. Previous methods follow a single-thread framework that cannot co-train different pairs and usually spends much time re-obtaining redundant knowledge, limiting their real-world applications. To this end, in this paper, we pose a brand-new setting: Multi-Pair TSG, which aims to co-train these pairs. In particular, we propose a novel video-query co-training approach, Multi-Thread Knowledge Transfer Network, to locate a variety of video-query pairs effectively and efficiently. Firstly, we mine the spatial and temporal semantics across different queries to cooperate with each other. To learn intra- and inter-modal representations simultaneously, we design a cross-modal contrast module to explore the semantic consistency by a self-supervised strategy. To fully align visual and textual representations between different pairs, we design a prototype alignment strategy to 1) match object prototypes and phrase prototypes for spatial alignment, and 2) align activity prototypes and sentence prototypes for temporal alignment. Finally, we develop an adaptive negative selection module to adaptively generate a threshold for cross-modal matching. Extensive experiments show the effectiveness and efficiency of our proposed method.</li>
</ul>

<h3>Title: DOLLAR: Few-Step Video Generation via Distillation and Latent Reward Optimization</h3>
<ul>
<li><strong>Authors: </strong>Zihan Ding, Chi Jin, Difan Liu, Haitian Zheng, Krishna Kumar Singh, Qiang Zhang, Yan Kang, Zhe Lin, Yuchen Liu</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2412.15689">https://arxiv.org/abs/2412.15689</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2412.15689">https://arxiv.org/pdf/2412.15689</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2412.15689]] DOLLAR: Few-Step Video Generation via Distillation and Latent Reward Optimization(https://arxiv.org/abs/2412.15689)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>Diffusion probabilistic models have shown significant progress in video generation; however, their computational efficiency is limited by the large number of sampling steps required. Reducing sampling steps often compromises video quality or generation diversity. In this work, we introduce a distillation method that combines variational score distillation and consistency distillation to achieve few-step video generation, maintaining both high quality and diversity. We also propose a latent reward model fine-tuning approach to further enhance video generation performance according to any specified reward metric. This approach reduces memory usage and does not require the reward to be differentiable. Our method demonstrates state-of-the-art performance in few-step generation for 10-second videos (128 frames at 12 FPS). The distilled student model achieves a score of 82.57 on VBench, surpassing the teacher model as well as baseline models Gen-3, T2V-Turbo, and Kling. One-step distillation accelerates the teacher model's diffusion sampling by up to 278.6 times, enabling near real-time generation. Human evaluations further validate the superior performance of our 4-step student models compared to teacher model using 50-step DDIM sampling.</li>
</ul>

<h3>Title: Diffusion-Based Conditional Image Editing through Optimized Inference with Guidance</h3>
<ul>
<li><strong>Authors: </strong>Hyunsoo Lee, Minsoo Kang, Bohyung Han</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2412.15798">https://arxiv.org/abs/2412.15798</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2412.15798">https://arxiv.org/pdf/2412.15798</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2412.15798]] Diffusion-Based Conditional Image Editing through Optimized Inference with Guidance(https://arxiv.org/abs/2412.15798)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>We present a simple but effective training-free approach for text-driven image-to-image translation based on a pretrained text-to-image diffusion model. Our goal is to generate an image that aligns with the target task while preserving the structure and background of a source image. To this end, we derive the representation guidance with a combination of two objectives: maximizing the similarity to the target prompt based on the CLIP score and minimizing the structural distance to the source latent variable. This guidance improves the fidelity of the generated target image to the given target prompt while maintaining the structure integrity of the source image. To incorporate the representation guidance component, we optimize the target latent variable of diffusion model's reverse process with the guidance. Experimental results demonstrate that our method achieves outstanding image-to-image translation performance on various tasks when combined with the pretrained Stable Diffusion model.</li>
</ul>

<h3>Title: Robustness-enhanced Myoelectric Control with GAN-based Open-set Recognition</h3>
<ul>
<li><strong>Authors: </strong>Cheng Wang, Ziyang Feng, Pin Zhang, Manjiang Cao, Yiming Yuan, Tengfei Chang</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.HC, eess.SP</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2412.15819">https://arxiv.org/abs/2412.15819</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2412.15819">https://arxiv.org/pdf/2412.15819</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2412.15819]] Robustness-enhanced Myoelectric Control with GAN-based Open-set Recognition(https://arxiv.org/abs/2412.15819)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>Electromyography (EMG) signals are widely used in human motion recognition and medical rehabilitation, yet their variability and susceptibility to noise significantly limit the reliability of myoelectric control systems. Existing recognition algorithms often fail to handle unfamiliar actions effectively, leading to system instability and errors. This paper proposes a novel framework based on Generative Adversarial Networks (GANs) to enhance the robustness and usability of myoelectric control systems by enabling open-set recognition. The method incorporates a GAN-based discriminator to identify and reject unknown actions, maintaining system stability by preventing misclassifications. Experimental evaluations on publicly available and self-collected datasets demonstrate a recognition accuracy of 97.6\% for known actions and a 23.6\% improvement in Active Error Rate (AER) after rejecting unknown actions. The proposed approach is computationally efficient and suitable for deployment on edge devices, making it practical for real-world applications.</li>
</ul>

<h3>Title: Semi-Supervised Adaptation of Diffusion Models for Handwritten Text Generation</h3>
<ul>
<li><strong>Authors: </strong>Kai Brandenbusch</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2412.15853">https://arxiv.org/abs/2412.15853</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2412.15853">https://arxiv.org/pdf/2412.15853</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2412.15853]] Semi-Supervised Adaptation of Diffusion Models for Handwritten Text Generation(https://arxiv.org/abs/2412.15853)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>The generation of images of realistic looking, readable handwritten text is a challenging task which is referred to as handwritten text generation (HTG). Given a string and examples from a writer, the goal is to synthesize an image depicting the correctly spelled word in handwriting with the calligraphic style of the desired writer. An important application of HTG is the generation of training images in order to adapt downstream models for new data sets. With their success in natural image generation, diffusion models (DMs) have become the state-of-the-art approach in HTG. In this work, we present an extension of a latent DM for HTG to enable generation of writing styles not seen during training by learning style conditioning with a masked auto encoder. Our proposed content encoder allows for different ways of conditioning the DM on textual and calligraphic features. Additionally, we employ classifier-free guidance and explore the influence on the quality of the generated training images. For adapting the model to a new unlabeled data set, we propose a semi-supervised training scheme. We evaluate our approach on the IAM-database and use the RIMES-database to examine the generation of data not seen during training achieving improvements in this particularly promising application of DMs for HTG.</li>
</ul>

<h3>Title: NeuroPump: Simultaneous Geometric and Color Rectification for Underwater Images</h3>
<ul>
<li><strong>Authors: </strong>Yue Guo, Haoxiang Liao, Haibin Ling, Bingyao Huang</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2412.15890">https://arxiv.org/abs/2412.15890</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2412.15890">https://arxiv.org/pdf/2412.15890</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2412.15890]] NeuroPump: Simultaneous Geometric and Color Rectification for Underwater Images(https://arxiv.org/abs/2412.15890)</code><input type="text"></li>
<li><strong>Keywords: </strong>self-supervised</a></li>
<li><strong>Abstract: </strong>Underwater image restoration aims to remove geometric and color distortions due to water refraction, absorption and scattering. Previous studies focus on restoring either color or the geometry, but to our best knowledge, not both. However, in practice it may be cumbersome to address the two rectifications one-by-one. In this paper, we propose NeuroPump, a self-supervised method to simultaneously optimize and rectify underwater geometry and color as if water were pumped out. The key idea is to explicitly model refraction, absorption and scattering in Neural Radiance Field (NeRF) pipeline, such that it not only performs simultaneous geometric and color rectification, but also enables to synthesize novel views and optical effects by controlling the decoupled parameters. In addition, to address issue of lack of real paired ground truth images, we propose an underwater 360 benchmark dataset that has real paired (i.e., with and without water) images. Our method clearly outperforms other baselines both quantitatively and qualitatively.</li>
</ul>

<h3>Title: A Thorough Investigation into the Application of Deep CNN for Enhancing Natural Language Processing Capabilities</h3>
<ul>
<li><strong>Authors: </strong>Chang Weng, Scott Rood, Mehdi Ali Ramezani, Amir Aslani, Reza Zarrab, Wang Zwuo, Sanjeev Salimans, Tim Satheesh</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2412.15900">https://arxiv.org/abs/2412.15900</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2412.15900">https://arxiv.org/pdf/2412.15900</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2412.15900]] A Thorough Investigation into the Application of Deep CNN for Enhancing Natural Language Processing Capabilities(https://arxiv.org/abs/2412.15900)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>Natural Language Processing (NLP) is widely used in fields like machine translation and sentiment analysis. However, traditional NLP models struggle with accuracy and efficiency. This paper introduces Deep Convolutional Neural Networks (DCNN) into NLP to address these issues. By integrating DCNN, machine learning (ML) algorithms, and generative adversarial networks (GAN), the study improves language understanding, reduces ambiguity, and enhances task performance. The high-performance NLP model shows a 10% improvement in segmentation accuracy and a 4% increase in recall rate compared to traditional models. This integrated approach excels in tasks such as word segmentation, part-of-speech tagging, machine translation, and text classification, offering better recognition accuracy and processing efficiency.</li>
</ul>

<h3>Title: Self-supervised Spatial-Temporal Learner for Precipitation Nowcasting</h3>
<ul>
<li><strong>Authors: </strong>Haotian Li, Arno Siebes, Siamak Mehrkanoon</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2412.15917">https://arxiv.org/abs/2412.15917</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2412.15917">https://arxiv.org/pdf/2412.15917</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2412.15917]] Self-supervised Spatial-Temporal Learner for Precipitation Nowcasting(https://arxiv.org/abs/2412.15917)</code><input type="text"></li>
<li><strong>Keywords: </strong>self-supervised</a></li>
<li><strong>Abstract: </strong>Nowcasting, the short-term prediction of weather, is essential for making timely and weather-dependent decisions. Specifically, precipitation nowcasting aims to predict precipitation at a local level within a 6-hour time frame. This task can be framed as a spatial-temporal sequence forecasting problem, where deep learning methods have been particularly effective. However, despite advancements in self-supervised learning, most successful methods for nowcasting remain fully supervised. Self-supervised learning is advantageous for pretraining models to learn representations without requiring extensive labeled data. In this work, we leverage the benefits of self-supervised learning and integrate it with spatial-temporal learning to develop a novel model, SpaT-SparK. SpaT-SparK comprises a CNN-based encoder-decoder structure pretrained with a masked image modeling (MIM) task and a translation network that captures temporal relationships among past and future precipitation maps in downstream tasks. We conducted experiments on the NL-50 dataset to evaluate the performance of SpaT-SparK. The results demonstrate that SpaT-SparK outperforms existing baseline supervised models, such as SmaAt-UNet, providing more accurate nowcasting predictions.</li>
</ul>

<h3>Title: Reframing Image Difference Captioning with BLIP2IDC and Synthetic Augmentation</h3>
<ul>
<li><strong>Authors: </strong>Gautier Evennou, Antoine Chaffin, Vivien Chappelier, Ewa Kijak</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2412.15939">https://arxiv.org/abs/2412.15939</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2412.15939">https://arxiv.org/pdf/2412.15939</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2412.15939]] Reframing Image Difference Captioning with BLIP2IDC and Synthetic Augmentation(https://arxiv.org/abs/2412.15939)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>The rise of the generative models quality during the past years enabled the generation of edited variations of images at an important scale. To counter the harmful effects of such technology, the Image Difference Captioning (IDC) task aims to describe the differences between two images. While this task is successfully handled for simple 3D rendered images, it struggles on real-world images. The reason is twofold: the training data-scarcity, and the difficulty to capture fine-grained differences between complex images. To address those issues, we propose in this paper a simple yet effective framework to both adapt existing image captioning models to the IDC task and augment IDC datasets. We introduce BLIP2IDC, an adaptation of BLIP2 to the IDC task at low computational cost, and show it outperforms two-streams approaches by a significant margin on real-world IDC datasets. We also propose to use synthetic augmentation to improve the performance of IDC models in an agnostic fashion. We show that our synthetic augmentation strategy provides high quality data, leading to a challenging new dataset well-suited for IDC named Syned1.</li>
</ul>

<h3>Title: Self-Supervised Radiograph Anatomical Region Classification -- How Clean Is Your Real-World Data?</h3>
<ul>
<li><strong>Authors: </strong>Simon Langer, Jessica Ritter, Rickmer Braren, Daniel Rueckert, Paul Hager</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2412.15967">https://arxiv.org/abs/2412.15967</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2412.15967">https://arxiv.org/pdf/2412.15967</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2412.15967]] Self-Supervised Radiograph Anatomical Region Classification -- How Clean Is Your Real-World Data?(https://arxiv.org/abs/2412.15967)</code><input type="text"></li>
<li><strong>Keywords: </strong>self-supervised</a></li>
<li><strong>Abstract: </strong>Modern deep learning-based clinical imaging workflows rely on accurate labels of the examined anatomical region. Knowing the anatomical region is required to select applicable downstream models and to effectively generate cohorts of high quality data for future medical and machine learning research efforts. However, this information may not be available in externally sourced data or generally contain data entry errors. To address this problem, we show the effectiveness of self-supervised methods such as SimCLR and BYOL as well as supervised contrastive deep learning methods in assigning one of 14 anatomical region classes in our in-house dataset of 48,434 skeletal radiographs. We achieve a strong linear evaluation accuracy of 96.6% with a single model and 97.7% using an ensemble approach. Furthermore, only a few labeled instances (1% of the training set) suffice to achieve an accuracy of 92.2%, enabling usage in low-label and thus low-resource scenarios. Our model can be used to correct data entry mistakes: a follow-up analysis of the test set errors of our best-performing single model by an expert radiologist identified 35% incorrect labels and 11% out-of-domain images. When accounted for, the radiograph anatomical region labelling performance increased -- without and with an ensemble, respectively -- to a theoretical accuracy of 98.0% and 98.8%.</li>
</ul>

<h3>Title: Detection of Aerial Spoofing Attacks to LEO Satellite Systems via Deep Learning</h3>
<ul>
<li><strong>Authors: </strong>Jos Wigchert, Savio Sciancalepore, Gabriele Oligeri</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2412.16008">https://arxiv.org/abs/2412.16008</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2412.16008">https://arxiv.org/pdf/2412.16008</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2412.16008]] Detection of Aerial Spoofing Attacks to LEO Satellite Systems via Deep Learning(https://arxiv.org/abs/2412.16008)</code><input type="text"></li>
<li><strong>Keywords: </strong>anomaly</a></li>
<li><strong>Abstract: </strong>Detecting spoofing attacks to Low-Earth-Orbit (LEO) satellite systems is a cornerstone to assessing the authenticity of the received information and guaranteeing robust service delivery in several application domains. The solutions available today for spoofing detection either rely on additional communication systems, receivers, and antennas, or require mobile deployments. Detection systems working at the Physical (PHY) layer of the satellite communication link also require time-consuming and energy-hungry training processes on all satellites of the constellation, and rely on the availability of spoofed data, which are often challenging to collect. Moreover, none of such contributions investigate the feasibility of aerial spoofing attacks launched via drones operating at various altitudes. In this paper, we propose a new spoofing detection technique for LEO satellite constellation systems, applying anomaly detection on the received PHY signal via autoencoders. We validate our solution through an extensive measurement campaign involving the deployment of an actual spoofer (Software-Defined Radio) installed on a drone and injecting rogue IRIDIUM messages while flying at different altitudes with various movement patterns. Our results demonstrate that the proposed technique can reliably detect LEO spoofing attacks launched at different altitudes, while state-of-the-art competing approaches simply fail. We also release the collected data as open source, fostering further research on satellite security.</li>
</ul>

<h3>Title: SafeCFG: Redirecting Harmful Classifier-Free Guidance for Safe Generation</h3>
<ul>
<li><strong>Authors: </strong>Jiadong Pan, Hongcheng Gao, Liang Li, Zheng-Jun Zha, Qingming Huang, Jiebo Luo</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2412.16039">https://arxiv.org/abs/2412.16039</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2412.16039">https://arxiv.org/pdf/2412.16039</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2412.16039]] SafeCFG: Redirecting Harmful Classifier-Free Guidance for Safe Generation(https://arxiv.org/abs/2412.16039)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>Diffusion models (DMs) have demonstrated exceptional performance in text-to-image (T2I) tasks, leading to their widespread use. With the introduction of classifier-free guidance (CFG), the quality of images generated by DMs is improved. However, DMs can generate more harmful images by maliciously guiding the image generation process through CFG. Some safe guidance methods aim to mitigate the risk of generating harmful images but often reduce the quality of clean image generation. To address this issue, we introduce the Harmful Guidance Redirector (HGR), which redirects harmful CFG direction while preserving clean CFG direction during image generation, transforming CFG into SafeCFG and achieving high safety and quality generation. We train HGR to redirect multiple harmful CFG directions simultaneously, demonstrating its ability to eliminate various harmful elements while preserving high-quality generation. Additionally, we find that HGR can detect image harmfulness, allowing for unsupervised fine-tuning of safe diffusion models without pre-defined clean or harmful labels. Experimental results show that by incorporating HGR, images generated by diffusion models achieve both high quality and strong safety, and safe DMs trained through unsupervised methods according to the harmfulness detected by HGR also exhibit good safety performance. The codes will be publicly available.</li>
</ul>

<h3>Title: Label-Efficient Data Augmentation with Video Diffusion Models for Guidewire Segmentation in Cardiac Fluoroscopy</h3>
<ul>
<li><strong>Authors: </strong>Shaoyan Pan, Yikang Liu, Lin Zhao, Eric Z. Chen, Xiao Chen, Terrence Chen, Shanhui Sun</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2412.16050">https://arxiv.org/abs/2412.16050</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2412.16050">https://arxiv.org/pdf/2412.16050</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2412.16050]] Label-Efficient Data Augmentation with Video Diffusion Models for Guidewire Segmentation in Cardiac Fluoroscopy(https://arxiv.org/abs/2412.16050)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>The accurate segmentation of guidewires in interventional cardiac fluoroscopy videos is crucial for computer-aided navigation tasks. Although deep learning methods have demonstrated high accuracy and robustness in wire segmentation, they require substantial annotated datasets for generalizability, underscoring the need for extensive labeled data to enhance model performance. To address this challenge, we propose the Segmentation-guided Frame-consistency Video Diffusion Model (SF-VD) to generate large collections of labeled fluoroscopy videos, augmenting the training data for wire segmentation networks. SF-VD leverages videos with limited annotations by independently modeling scene distribution and motion distribution. It first samples the scene distribution by generating 2D fluoroscopy images with wires positioned according to a specified input mask, and then samples the motion distribution by progressively generating subsequent frames, ensuring frame-to-frame coherence through a frame-consistency strategy. A segmentation-guided mechanism further refines the process by adjusting wire contrast, ensuring a diverse range of visibility in the synthesized image. Evaluation on a fluoroscopy dataset confirms the superior quality of the generated videos and shows significant improvements in guidewire segmentation.</li>
</ul>

<h3>Title: Differentially Private Federated Learning of Diffusion Models for Synthetic Tabular Data Generation</h3>
<ul>
<li><strong>Authors: </strong>Timur Sattarov, Marco Schreyer, Damian Borth</a></li>
<li><strong>Subjects: </strong>cs.LG, q-fin.ST</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2412.16083">https://arxiv.org/abs/2412.16083</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2412.16083">https://arxiv.org/pdf/2412.16083</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2412.16083]] Differentially Private Federated Learning of Diffusion Models for Synthetic Tabular Data Generation(https://arxiv.org/abs/2412.16083)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>The increasing demand for privacy-preserving data analytics in finance necessitates solutions for synthetic data generation that rigorously uphold privacy standards. We introduce DP-Fed-FinDiff framework, a novel integration of Differential Privacy, Federated Learning and Denoising Diffusion Probabilistic Models designed to generate high-fidelity synthetic tabular data. This framework ensures compliance with stringent privacy regulations while maintaining data utility. We demonstrate the effectiveness of DP-Fed-FinDiff on multiple real-world financial datasets, achieving significant improvements in privacy guarantees without compromising data quality. Our empirical evaluations reveal the optimal trade-offs between privacy budgets, client configurations, and federated optimization strategies. The results affirm the potential of DP-Fed-FinDiff to enable secure data sharing and robust analytics in highly regulated domains, paving the way for further advances in federated learning and privacy-preserving data synthesis.</li>
</ul>

<h3>Title: Explainable AI for Multivariate Time Series Pattern Exploration: Latent Space Visual Analytics with Time Fusion Transformer and Variational Autoencoders in Power Grid Event Diagnosis</h3>
<ul>
<li><strong>Authors: </strong>Haowen Xu, Ali Boyaci, Jianming Lian, Aaron Wilson</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2412.16098">https://arxiv.org/abs/2412.16098</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2412.16098">https://arxiv.org/pdf/2412.16098</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2412.16098]] Explainable AI for Multivariate Time Series Pattern Exploration: Latent Space Visual Analytics with Time Fusion Transformer and Variational Autoencoders in Power Grid Event Diagnosis(https://arxiv.org/abs/2412.16098)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>Detecting and analyzing complex patterns in multivariate time-series data is crucial for decision-making in urban and environmental system operations. However, challenges arise from the high dimensionality, intricate complexity, and interconnected nature of complex patterns, which hinder the understanding of their underlying physical processes. Existing AI methods often face limitations in interpretability, computational efficiency, and scalability, reducing their applicability in real-world scenarios. This paper proposes a novel visual analytics framework that integrates two generative AI models, Time Fusion Transformer (TFT) and Variational Autoencoders (VAEs), to reduce complex patterns into lower-dimensional latent spaces and visualize them in 2D using dimensionality reduction techniques such as PCA, t-SNE, and UMAP with DBSCAN. These visualizations, presented through coordinated and interactive views and tailored glyphs, enable intuitive exploration of complex multivariate temporal patterns, identifying patterns' similarities and uncover their potential correlations for a better interpretability of the AI outputs. The framework is demonstrated through a case study on power grid signal data, where it identifies multi-label grid event signatures, including faults and anomalies with diverse root causes. Additionally, novel metrics and visualizations are introduced to validate the models and evaluate the performance, efficiency, and consistency of latent maps generated by TFT and VAE under different configurations. These analyses provide actionable insights for model parameter tuning and reliability improvements. Comparative results highlight that TFT achieves shorter run times and superior scalability to diverse time-series data shapes compared to VAE. This work advances fault diagnosis in multivariate time series, fostering explainable AI to support critical system operations.</li>
</ul>

<h3>Title: CLEAR: Conv-Like Linearization Revs Pre-Trained Diffusion Transformers Up</h3>
<ul>
<li><strong>Authors: </strong>Songhua Liu, Zhenxiong Tan, Xinchao Wang</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2412.16112">https://arxiv.org/abs/2412.16112</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2412.16112">https://arxiv.org/pdf/2412.16112</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2412.16112]] CLEAR: Conv-Like Linearization Revs Pre-Trained Diffusion Transformers Up(https://arxiv.org/abs/2412.16112)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>Diffusion Transformers (DiT) have become a leading architecture in image generation. However, the quadratic complexity of attention mechanisms, which are responsible for modeling token-wise relationships, results in significant latency when generating high-resolution images. To address this issue, we aim at a linear attention mechanism in this paper that reduces the complexity of pre-trained DiTs to linear. We begin our exploration with a comprehensive summary of existing efficient attention mechanisms and identify four key factors crucial for successful linearization of pre-trained DiTs: locality, formulation consistency, high-rank attention maps, and feature integrity. Based on these insights, we introduce a convolution-like local attention strategy termed CLEAR, which limits feature interactions to a local window around each query token, and thus achieves linear complexity. Our experiments indicate that, by fine-tuning the attention layer on merely 10K self-generated samples for 10K iterations, we can effectively transfer knowledge from a pre-trained DiT to a student model with linear complexity, yielding results comparable to the teacher model. Simultaneously, it reduces attention computations by 99.5% and accelerates generation by 6.3 times for generating 8K-resolution images. Furthermore, we investigate favorable properties in the distilled attention layers, such as zero-shot generalization cross various models and plugins, and improved support for multi-GPU parallel inference. Models and codes are available here: this https URL.</li>
</ul>

<h3>Title: Can Generative Video Models Help Pose Estimation?</h3>
<ul>
<li><strong>Authors: </strong>Ruojin Cai, Jason Y. Zhang, Philipp Henzler, Zhengqi Li, Noah Snavely, Ricardo Martin-Brualla</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2412.16155">https://arxiv.org/abs/2412.16155</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2412.16155">https://arxiv.org/pdf/2412.16155</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2412.16155]] Can Generative Video Models Help Pose Estimation?(https://arxiv.org/abs/2412.16155)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>Pairwise pose estimation from images with little or no overlap is an open challenge in computer vision. Existing methods, even those trained on large-scale datasets, struggle in these scenarios due to the lack of identifiable correspondences or visual overlap. Inspired by the human ability to infer spatial relationships from diverse scenes, we propose a novel approach, InterPose, that leverages the rich priors encoded within pre-trained generative video models. We propose to use a video model to hallucinate intermediate frames between two input images, effectively creating a dense, visual transition, which significantly simplifies the problem of pose estimation. Since current video models can still produce implausible motion or inconsistent geometry, we introduce a self-consistency score that evaluates the consistency of pose predictions from sampled videos. We demonstrate that our approach generalizes among three state-of-the-art video models and show consistent improvements over the state-of-the-art DUSt3R on four diverse datasets encompassing indoor, outdoor, and object-centric scenes. Our findings suggest a promising avenue for improving pose estimation models by leveraging large generative models trained on vast amounts of video data, which is more readily available than 3D data. See our project page for results: this https URL.</li>
</ul>

<h3>Title: Personalized Representation from Personalized Generation</h3>
<ul>
<li><strong>Authors: </strong>Shobhita Sundaram, Julia Chae, Yonglong Tian, Sara Beery, Phillip Isola</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2412.16156">https://arxiv.org/abs/2412.16156</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2412.16156">https://arxiv.org/pdf/2412.16156</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2412.16156]] Personalized Representation from Personalized Generation(https://arxiv.org/abs/2412.16156)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>Modern vision models excel at general purpose downstream tasks. It is unclear, however, how they may be used for personalized vision tasks, which are both fine-grained and data-scarce. Recent works have successfully applied synthetic data to general-purpose representation learning, while advances in T2I diffusion models have enabled the generation of personalized images from just a few real examples. Here, we explore a potential connection between these ideas, and formalize the challenge of using personalized synthetic data to learn personalized representations, which encode knowledge about an object of interest and may be flexibly applied to any downstream task relating to the target object. We introduce an evaluation suite for this challenge, including reformulations of two existing datasets and a novel dataset explicitly constructed for this purpose, and propose a contrastive learning approach that makes creative use of image generators. We show that our method improves personalized representation learning for diverse downstream tasks, from recognition to segmentation, and analyze characteristics of image generation approaches that are key to this gain.</li>
</ul>

<button id="copy">Copy All</button>
</article>
<script src="../../javascript/clipboard.min.js"></script>
<script src="../../javascript/clipboard.js"></script>
