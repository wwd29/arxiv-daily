<link rel="stylesheet" href="../../css/markdown.css" />
<article class="markdown-body">
<h2>diffusion</h2>
<h3>Title: GenEval: An Object-Focused Framework for Evaluating Text-to-Image Alignment. (arXiv:2310.11513v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.11513">http://arxiv.org/abs/2310.11513</a></li>
<li>Code URL: https://github.com/djghosh13/geneval</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.11513]] GenEval: An Object-Focused Framework for Evaluating Text-to-Image Alignment(http://arxiv.org/abs/2310.11513)</code></li>
<li>Summary: <p>Recent breakthroughs in diffusion models, multimodal pretraining, and
efficient finetuning have led to an explosion of text-to-image generative
models. Given human evaluation is expensive and difficult to scale, automated
methods are critical for evaluating the increasingly large number of new
models. However, most current automated evaluation metrics like FID or
CLIPScore only offer a holistic measure of image quality or image-text
alignment, and are unsuited for fine-grained or instance-level analysis. In
this paper, we introduce GenEval, an object-focused framework to evaluate
compositional image properties such as object co-occurrence, position, count,
and color. We show that current object detection models can be leveraged to
evaluate text-to-image models on a variety of generation tasks with strong
human agreement, and that other discriminative vision models can be linked to
this pipeline to further verify properties like object color. We then evaluate
several open-source text-to-image models and analyze their relative generative
capabilities on our benchmark. We find that recent models demonstrate
significant improvement on these tasks, though they are still lacking in
complex capabilities such as spatial relations and attribute binding. Finally,
we demonstrate how GenEval might be used to help discover existing failure
modes, in order to inform development of the next generation of text-to-image
models. Our code to run the GenEval framework is publicly available at
https://github.com/djghosh13/geneval.
</p></li>
</ul>

<h3>Title: Progressive3D: Progressively Local Editing for Text-to-3D Content Creation with Complex Semantic Prompts. (arXiv:2310.11784v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.11784">http://arxiv.org/abs/2310.11784</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.11784]] Progressive3D: Progressively Local Editing for Text-to-3D Content Creation with Complex Semantic Prompts(http://arxiv.org/abs/2310.11784)</code></li>
<li>Summary: <p>Recent text-to-3D generation methods achieve impressive 3D content creation
capacity thanks to the advances in image diffusion models and optimizing
strategies. However, current methods struggle to generate correct 3D content
for a complex prompt in semantics, i.e., a prompt describing multiple
interacted objects binding with different attributes. In this work, we propose
a general framework named Progressive3D, which decomposes the entire generation
into a series of locally progressive editing steps to create precise 3D content
for complex prompts, and we constrain the content change to only occur in
regions determined by user-defined region prompts in each editing step.
Furthermore, we propose an overlapped semantic component suppression technique
to encourage the optimization process to focus more on the semantic differences
between prompts. Extensive experiments demonstrate that the proposed
Progressive3D framework generates precise 3D content for prompts with complex
semantics and is general for various text-to-3D methods driven by different 3D
representations.
</p></li>
</ul>

<h3>Title: To Generate or Not? Safety-Driven Unlearned Diffusion Models Are Still Easy To Generate Unsafe Images ... For Now. (arXiv:2310.11868v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.11868">http://arxiv.org/abs/2310.11868</a></li>
<li>Code URL: https://github.com/optml-group/diffusion-mu-attack</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.11868]] To Generate or Not? Safety-Driven Unlearned Diffusion Models Are Still Easy To Generate Unsafe Images (http://arxiv.org/abs/2310.11868)</code></li>
<li>Summary: <p>The recent advances in diffusion models (DMs) have revolutionized the
generation of complex and diverse images. However, these models also introduce
potential safety hazards, such as the production of harmful content and
infringement of data copyrights. Although there have been efforts to create
safety-driven unlearning methods to counteract these challenges, doubts remain
about their capabilities. To bridge this uncertainty, we propose an evaluation
framework built upon adversarial attacks (also referred to as adversarial
prompts), in order to discern the trustworthiness of these safety-driven
unlearned DMs. Specifically, our research explores the (worst-case) robustness
of unlearned DMs in eradicating unwanted concepts, styles, and objects,
assessed by the generation of adversarial prompts. We develop a novel
adversarial learning approach called UnlearnDiff that leverages the inherent
classification capabilities of DMs to streamline the generation of adversarial
prompts, making it as simple for DMs as it is for image classification attacks.
This technique streamlines the creation of adversarial prompts, making the
process as intuitive for generative modeling as it is for image classification
assaults. Through comprehensive benchmarking, we assess the unlearning
robustness of five prevalent unlearned DMs across multiple tasks. Our results
underscore the effectiveness and efficiency of UnlearnDiff when compared to
state-of-the-art adversarial prompting methods. Codes are available at
https://github.com/OPTML-Group/Diffusion-MU-Attack. WARNING: This paper
contains model outputs that may be offensive in nature.
</p></li>
</ul>

<h3>Title: IRAD: Implicit Representation-driven Image Resampling against Adversarial Attacks. (arXiv:2310.11890v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.11890">http://arxiv.org/abs/2310.11890</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.11890]] IRAD: Implicit Representation-driven Image Resampling against Adversarial Attacks(http://arxiv.org/abs/2310.11890)</code></li>
<li>Summary: <p>We introduce a novel approach to counter adversarial attacks, namely, image
resampling. Image resampling transforms a discrete image into a new one,
simulating the process of scene recapturing or rerendering as specified by a
geometrical transformation. The underlying rationale behind our idea is that
image resampling can alleviate the influence of adversarial perturbations while
preserving essential semantic information, thereby conferring an inherent
advantage in defending against adversarial attacks. To validate this concept,
we present a comprehensive study on leveraging image resampling to defend
against adversarial attacks. We have developed basic resampling methods that
employ interpolation strategies and coordinate shifting magnitudes. Our
analysis reveals that these basic methods can partially mitigate adversarial
attacks. However, they come with apparent limitations: the accuracy of clean
images noticeably decreases, while the improvement in accuracy on adversarial
examples is not substantial. We propose implicit representation-driven image
resampling (IRAD) to overcome these limitations. First, we construct an
implicit continuous representation that enables us to represent any input image
within a continuous coordinate space. Second, we introduce SampleNet, which
automatically generates pixel-wise shifts for resampling in response to
different inputs. Furthermore, we can extend our approach to the
state-of-the-art diffusion-based method, accelerating it with fewer time steps
while preserving its defense capability. Extensive experiments demonstrate that
our method significantly enhances the adversarial robustness of diverse deep
models against various attacks while maintaining high accuracy on clean images.
</p></li>
</ul>

<h3>Title: Image Super-resolution Via Latent Diffusion: A Sampling-space Mixture Of Experts And Frequency-augmented Decoder Approach. (arXiv:2310.12004v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.12004">http://arxiv.org/abs/2310.12004</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.12004]] Image Super-resolution Via Latent Diffusion: A Sampling-space Mixture Of Experts And Frequency-augmented Decoder Approach(http://arxiv.org/abs/2310.12004)</code></li>
<li>Summary: <p>The recent use of diffusion prior, enhanced by pre-trained text-image models,
has markedly elevated the performance of image super-resolution (SR). To
alleviate the huge computational cost required by pixel-based diffusion SR,
latent-based methods utilize a feature encoder to transform the image and then
implement the SR image generation in a compact latent space. Nevertheless,
there are two major issues that limit the performance of latent-based
diffusion. First, the compression of latent space usually causes reconstruction
distortion. Second, huge computational cost constrains the parameter scale of
the diffusion model. To counteract these issues, we first propose a frequency
compensation module that enhances the frequency components from latent space to
pixel space. The reconstruction distortion (especially for high-frequency
information) can be significantly decreased. Then, we propose to use
Sample-Space Mixture of Experts (SS-MoE) to achieve more powerful latent-based
SR, which steadily improves the capacity of the model without a significant
increase in inference costs. These carefully crafted designs contribute to
performance improvements in largely explored 4x blind super-resolution
benchmarks and extend to large magnification factors, i.e., 8x image SR
benchmarks. The code is available at https://github.com/amandaluof/moe_sr.
</p></li>
</ul>

<h3>Title: InfoDiffusion: Information Entropy Aware Diffusion Process for Non-Autoregressive Text Generation. (arXiv:2310.11976v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.11976">http://arxiv.org/abs/2310.11976</a></li>
<li>Code URL: https://github.com/rzhwang/infodiffusion</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.11976]] InfoDiffusion: Information Entropy Aware Diffusion Process for Non-Autoregressive Text Generation(http://arxiv.org/abs/2310.11976)</code></li>
<li>Summary: <p>Diffusion models have garnered considerable interest in the field of text
generation. Several studies have explored text diffusion models with different
structures and applied them to various tasks, including named entity
recognition and summarization. However, there exists a notable disparity
between the "easy-first" text generation process of current diffusion models
and the "keyword-first" natural text generation process of humans, which has
received limited attention. To bridge this gap, we propose InfoDiffusion, a
non-autoregressive text diffusion model. Our approach introduces a
"keyinfo-first" generation strategy and incorporates a noise schedule based on
the amount of text information. In addition, InfoDiffusion combines
self-conditioning with a newly proposed partially noising model structure.
Experimental results show that InfoDiffusion outperforms the baseline model in
terms of generation quality and diversity, as well as exhibiting higher
sampling efficiency.
</p></li>
</ul>

<h3>Title: Reflection-Equivariant Diffusion for 3D Structure Determination from Isotopologue Rotational Spectra in Natural Abundance. (arXiv:2310.11609v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.11609">http://arxiv.org/abs/2310.11609</a></li>
<li>Code URL: https://github.com/aspuru-guzik-group/kreed</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.11609]] Reflection-Equivariant Diffusion for 3D Structure Determination from Isotopologue Rotational Spectra in Natural Abundance(http://arxiv.org/abs/2310.11609)</code></li>
<li>Summary: <p>Structure determination is necessary to identify unknown organic molecules,
such as those in natural products, forensic samples, the interstellar medium,
and laboratory syntheses. Rotational spectroscopy enables structure
determination by providing accurate 3D information about small organic
molecules via their moments of inertia. Using these moments, Kraitchman
analysis determines isotopic substitution coordinates, which are the unsigned
$|x|,|y|,|z|$ coordinates of all atoms with natural isotopic abundance,
including carbon, nitrogen, and oxygen. While unsigned substitution coordinates
can verify guesses of structures, the missing $+/-$ signs make it challenging
to determine the actual structure from the substitution coordinates alone. To
tackle this inverse problem, we develop KREED (Kraitchman
REflection-Equivariant Diffusion), a generative diffusion model that infers a
molecule's complete 3D structure from its molecular formula, moments of
inertia, and unsigned substitution coordinates of heavy atoms. KREED's top-1
predictions identify the correct 3D structure with &gt;98% accuracy on the QM9 and
GEOM datasets when provided with substitution coordinates of all heavy atoms
with natural isotopic abundance. When substitution coordinates are restricted
to only a subset of carbons, accuracy is retained at 91% on QM9 and 32% on
GEOM. On a test set of experimentally measured substitution coordinates
gathered from the literature, KREED predicts the correct all-atom 3D structure
in 25 of 33 cases, demonstrating experimental applicability for context-free 3D
structure determination with rotational spectroscopy.
</p></li>
</ul>

<h2>self-supervised</h2>
<h3>Title: What is a good question? Task-oriented asking with fact-level masking. (arXiv:2310.11571v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.11571">http://arxiv.org/abs/2310.11571</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.11571]] What is a good question? Task-oriented asking with fact-level masking(http://arxiv.org/abs/2310.11571)</code></li>
<li>Summary: <p>Asking questions is an important element of real-life collaboration on
reasoning tasks like question answering. For example, a legal assistant chatbot
may be unable to make accurate recommendations without specific information on
the user's circumstances. However, large language models are usually deployed
to solve reasoning tasks directly without asking follow-up questions to the
user or third parties. We term this problem task-oriented asking (TOA).
Zero-shot chat models can perform TOA, but their training is primarily based on
next-token prediction rather than whether questions contribute to successful
collaboration. To enable the training and evaluation of TOA models, we present
a definition and framework for natural language task-oriented asking, the
problem of generating questions that result in answers useful for a reasoning
task. We also present fact-level masking (FLM), a procedure for converting
natural language datasets into self-supervised TOA datasets by omitting
particular critical facts. Finally, we generate a TOA dataset from the HotpotQA
dataset using FLM and evaluate several zero-shot language models on it. Our
experiments show that current zero-shot models struggle to ask questions that
retrieve useful information, as compared to human annotators. These results
demonstrate an opportunity to use FLM datasets and the TOA framework to train
and evaluate better TOA models.
</p></li>
</ul>

<h3>Title: Learning under Label Proportions for Text Classification. (arXiv:2310.11707v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.11707">http://arxiv.org/abs/2310.11707</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.11707]] Learning under Label Proportions for Text Classification(http://arxiv.org/abs/2310.11707)</code></li>
<li>Summary: <p>We present one of the preliminary NLP works under the challenging setup of
Learning from Label Proportions (LLP), where the data is provided in an
aggregate form called bags and only the proportion of samples in each class as
the ground truth. This setup is inline with the desired characteristics of
training models under Privacy settings and Weakly supervision. By
characterizing some irregularities of the most widely used baseline technique
DLLP, we propose a novel formulation that is also robust. This is accompanied
with a learnability result that provides a generalization bound under LLP.
Combining this formulation with a self-supervised objective, our method
achieves better results as compared to the baselines in almost 87% of the
experimental configurations which include large scale models for both long and
short range texts across multiple metrics.
</p></li>
</ul>

<h2>foundation model</h2>
<h3>Title: Evaluating the Fairness of Discriminative Foundation Models in Computer Vision. (arXiv:2310.11867v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.11867">http://arxiv.org/abs/2310.11867</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.11867]] Evaluating the Fairness of Discriminative Foundation Models in Computer Vision(http://arxiv.org/abs/2310.11867)</code></li>
<li>Summary: <p>We propose a novel taxonomy for bias evaluation of discriminative foundation
models, such as Contrastive Language-Pretraining (CLIP), that are used for
labeling tasks. We then systematically evaluate existing methods for mitigating
bias in these models with respect to our taxonomy. Specifically, we evaluate
OpenAI's CLIP and OpenCLIP models for key applications, such as zero-shot
classification, image retrieval and image captioning. We categorize desired
behaviors based around three axes: (i) if the task concerns humans; (ii) how
subjective the task is (i.e., how likely it is that people from a diverse range
of backgrounds would agree on a labeling); and (iii) the intended purpose of
the task and if fairness is better served by impartiality (i.e., making
decisions independent of the protected attributes) or representation (i.e.,
making decisions to maximize diversity). Finally, we provide quantitative
fairness evaluations for both binary-valued and multi-valued protected
attributes over ten diverse datasets. We find that fair PCA, a post-processing
method for fair representations, works very well for debiasing in most of the
aforementioned tasks while incurring only minor loss of performance. However,
different debiasing approaches vary in their effectiveness depending on the
task. Hence, one should choose the debiasing approach depending on the specific
use case.
</p></li>
</ul>

<h3>Title: On the Benefit of Generative Foundation Models for Human Activity Recognition. (arXiv:2310.12085v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.12085">http://arxiv.org/abs/2310.12085</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.12085]] On the Benefit of Generative Foundation Models for Human Activity Recognition(http://arxiv.org/abs/2310.12085)</code></li>
<li>Summary: <p>In human activity recognition (HAR), the limited availability of annotated
data presents a significant challenge. Drawing inspiration from the latest
advancements in generative AI, including Large Language Models (LLMs) and
motion synthesis models, we believe that generative AI can address this data
scarcity by autonomously generating virtual IMU data from text descriptions.
Beyond this, we spotlight several promising research pathways that could
benefit from generative AI for the community, including the generating
benchmark datasets, the development of foundational models specific to HAR, the
exploration of hierarchical structures within HAR, breaking down complex
activities, and applications in health sensing and activity summarization.
</p></li>
</ul>

<h3>Title: SPEED: Speculative Pipelined Execution for Efficient Decoding. (arXiv:2310.12072v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.12072">http://arxiv.org/abs/2310.12072</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.12072]] SPEED: Speculative Pipelined Execution for Efficient Decoding(http://arxiv.org/abs/2310.12072)</code></li>
<li>Summary: <p>Generative Large Language Models (LLMs) based on the Transformer architecture
have recently emerged as a dominant foundation model for a wide range of
Natural Language Processing tasks. Nevertheless, their application in real-time
scenarios has been highly restricted due to the significant inference latency
associated with these models. This is particularly pronounced due to the
autoregressive nature of generative LLM inference, where tokens are generated
sequentially since each token depends on all previous output tokens. It is
therefore challenging to achieve any token-level parallelism, making inference
extremely memory-bound. In this work, we propose SPEED, which improves
inference efficiency by speculatively executing multiple future tokens in
parallel with the current token using predicted values based on early-layer
hidden states. For Transformer decoders that employ parameter sharing, the
memory operations for the tokens executing in parallel can be amortized, which
allows us to accelerate generative LLM inference. We demonstrate the efficiency
of our method in terms of latency reduction relative to model accuracy and
demonstrate how speculation allows for training deeper decoders with parameter
sharing with minimal runtime overhead.
</p></li>
</ul>

<h3>Title: Towards Graph Foundation Models: A Survey and Beyond. (arXiv:2310.11829v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.11829">http://arxiv.org/abs/2310.11829</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.11829]] Towards Graph Foundation Models: A Survey and Beyond(http://arxiv.org/abs/2310.11829)</code></li>
<li>Summary: <p>Emerging as fundamental building blocks for diverse artificial intelligence
applications, foundation models have achieved notable success across natural
language processing and many other domains. Parallelly, graph machine learning
has witnessed a transformative shift, with shallow methods giving way to deep
learning approaches. The emergence and homogenization capabilities of
foundation models have piqued the interest of graph machine learning
researchers, sparking discussions about developing the next graph learning
paradigm that is pre-trained on broad graph data and can be adapted to a wide
range of downstream graph tasks. However, there is currently no clear
definition and systematic analysis for this type of work. In this article, we
propose the concept of graph foundation models (GFMs), and provide the first
comprehensive elucidation on their key characteristics and technologies.
Following that, we categorize existing works towards GFMs into three categories
based on their reliance on graph neural networks and large language models.
Beyond providing a comprehensive overview of the current landscape of graph
foundation models, this article also discusses potential research directions
for this evolving field.
</p></li>
</ul>

<h2>generative</h2>
<h3>Title: Bayesian Flow Networks in Continual Learning. (arXiv:2310.12001v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.12001">http://arxiv.org/abs/2310.12001</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.12001]] Bayesian Flow Networks in Continual Learning(http://arxiv.org/abs/2310.12001)</code></li>
<li>Summary: <p>Bayesian Flow Networks (BFNs) has been recently proposed as one of the most
promising direction to universal generative modelling, having ability to learn
any of the data type. Their power comes from the expressiveness of neural
networks and Bayesian inference which make them suitable in the context of
continual learning. We delve into the mechanics behind BFNs and conduct the
experiments to empirically verify the generative capabilities on non-stationary
data.
</p></li>
</ul>

<h3>Title: Eliciting Human Preferences with Language Models. (arXiv:2310.11589v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.11589">http://arxiv.org/abs/2310.11589</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.11589]] Eliciting Human Preferences with Language Models(http://arxiv.org/abs/2310.11589)</code></li>
<li>Summary: <p>Language models (LMs) can be directed to perform target tasks by using
labeled examples or natural language prompts. But selecting examples or writing
prompts for can be challenging--especially in tasks that involve unusual edge
cases, demand precise articulation of nebulous preferences, or require an
accurate mental model of LM behavior. We propose to use *LMs themselves* to
guide the task specification process. In this paper, we introduce **Generative
Active Task Elicitation (GATE)**: a learning framework in which models elicit
and infer intended behavior through free-form, language-based interaction with
users. We study GATE in three domains: email validation, content
recommendation, and moral reasoning. In preregistered experiments, we show that
LMs prompted to perform GATE (e.g., by generating open-ended questions or
synthesizing informative edge cases) elicit responses that are often more
informative than user-written prompts or labels. Users report that interactive
task elicitation requires less effort than prompting or example labeling and
surfaces novel considerations not initially anticipated by users. Our findings
suggest that LM-driven elicitation can be a powerful tool for aligning models
to complex human preferences and values.
</p></li>
</ul>

<h3>Title: Concept-Guided Chain-of-Thought Prompting for Pairwise Comparison Scaling of Texts with Large Language Models. (arXiv:2310.12049v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.12049">http://arxiv.org/abs/2310.12049</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.12049]] Concept-Guided Chain-of-Thought Prompting for Pairwise Comparison Scaling of Texts with Large Language Models(http://arxiv.org/abs/2310.12049)</code></li>
<li>Summary: <p>Existing text scaling methods often require a large corpus, struggle with
short texts, or require labeled data. We develop a text scaling method that
leverages the pattern recognition capabilities of generative large language
models (LLMs). Specifically, we propose concept-guided chain-of-thought
(CGCoT), which uses prompts designed to summarize ideas and identify target
parties in texts to generate concept-specific breakdowns, in many ways similar
to guidance for human coder content analysis. CGCoT effectively shifts pairwise
text comparisons from a reasoning problem to a pattern recognition problem. We
then pairwise compare concept-specific breakdowns using an LLM. We use the
results of these pairwise comparisons to estimate a scale using the
Bradley-Terry model. We use this approach to scale affective speech on Twitter.
Our measures correlate more strongly with human judgments than alternative
approaches like Wordfish. Besides a small set of pilot data to develop the
CGCoT prompts, our measures require no additional labeled data and produce
binary predictions comparable to a RoBERTa-Large model fine-tuned on thousands
of human-labeled tweets. We demonstrate how combining substantive knowledge
with LLMs can create state-of-the-art measures of abstract concepts.
</p></li>
</ul>

<h3>Title: On the Evaluation of Generative Models in Distributed Learning Tasks. (arXiv:2310.11714v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.11714">http://arxiv.org/abs/2310.11714</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.11714]] On the Evaluation of Generative Models in Distributed Learning Tasks(http://arxiv.org/abs/2310.11714)</code></li>
<li>Summary: <p>The evaluation of deep generative models including generative adversarial
networks (GANs) and diffusion models has been extensively studied in the
literature. While the existing evaluation methods mainly target a centralized
learning problem with training data stored by a single client, many
applications of generative models concern distributed learning settings, e.g.
the federated learning scenario, where training data are collected by and
distributed among several clients. In this paper, we study the evaluation of
generative models in distributed learning tasks with heterogeneous data
distributions. First, we focus on the Fr\'echet inception distance (FID) and
consider the following FID-based aggregate scores over the clients: 1) FID-avg
as the mean of clients' individual FID scores, 2) FID-all as the FID distance
of the trained model to the collective dataset containing all clients' data. We
prove that the model rankings according to the FID-all and FID-avg scores could
be inconsistent, which can lead to different optimal generative models
according to the two aggregate scores. Next, we consider the kernel inception
distance (KID) and similarly define the KID-avg and KID-all aggregations.
Unlike the FID case, we prove that KID-all and KID-avg result in the same
rankings of generative models. We perform several numerical experiments on
standard image datasets and training schemes to support our theoretical
findings on the evaluation of generative models in distributed learning
problems.
</p></li>
</ul>

<h3>Title: Black-Box Training Data Identification in GANs via Detector Networks. (arXiv:2310.12063v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.12063">http://arxiv.org/abs/2310.12063</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.12063]] Black-Box Training Data Identification in GANs via Detector Networks(http://arxiv.org/abs/2310.12063)</code></li>
<li>Summary: <p>Since their inception Generative Adversarial Networks (GANs) have been
popular generative models across images, audio, video, and tabular data. In
this paper we study whether given access to a trained GAN, as well as fresh
samples from the underlying distribution, if it is possible for an attacker to
efficiently identify if a given point is a member of the GAN's training data.
This is of interest for both reasons related to copyright, where a user may
want to determine if their copyrighted data has been used to train a GAN, and
in the study of data privacy, where the ability to detect training set
membership is known as a membership inference attack. Unlike the majority of
prior work this paper investigates the privacy implications of using GANs in
black-box settings, where the attack only has access to samples from the
generator, rather than access to the discriminator as well. We introduce a
suite of membership inference attacks against GANs in the black-box setting and
evaluate our attacks on image GANs trained on the CIFAR10 dataset and tabular
GANs trained on genomic data. Our most successful attack, called The Detector,
involve training a second network to score samples based on their likelihood of
being generated by the GAN, as opposed to a fresh sample from the distribution.
We prove under a simple model of the generator that the detector is an
approximately optimal membership inference attack. Across a wide range of
tabular and image datasets, attacks, and GAN architectures, we find that
adversaries can orchestrate non-trivial privacy attacks when provided with
access to samples from the generator. At the same time, the attack success
achievable against GANs still appears to be lower compared to other generative
and discriminative models; this leaves the intriguing open question of whether
GANs are in fact more private, or if it is a matter of developing stronger
attacks.
</p></li>
</ul>

<h2>anomaly</h2>
<h3>Title: Malicious Agent Detection for Robust Multi-Agent Collaborative Perception. (arXiv:2310.11901v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.11901">http://arxiv.org/abs/2310.11901</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.11901]] Malicious Agent Detection for Robust Multi-Agent Collaborative Perception(http://arxiv.org/abs/2310.11901)</code></li>
<li>Summary: <p>Recently, multi-agent collaborative (MAC) perception has been proposed and
outperformed the traditional single-agent perception in many applications, such
as autonomous driving. However, MAC perception is more vulnerable to
adversarial attacks than single-agent perception due to the information
exchange. The attacker can easily degrade the performance of a victim agent by
sending harmful information from a malicious agent nearby. In this paper, we
extend adversarial attacks to an important perception task -- MAC object
detection, where generic defenses such as adversarial training are no longer
effective against these attacks. More importantly, we propose Malicious Agent
Detection (MADE), a reactive defense specific to MAC perception that can be
deployed by each agent to accurately detect and then remove any potential
malicious agent in its local collaboration network. In particular, MADE
inspects each agent in the network independently using a semi-supervised
anomaly detector based on a double-hypothesis test with the Benjamini-Hochberg
procedure to control the false positive rate of the inference. For the two
hypothesis tests, we propose a match loss statistic and a collaborative
reconstruction loss statistic, respectively, both based on the consistency
between the agent to be inspected and the ego agent where our detector is
deployed. We conduct comprehensive evaluations on a benchmark 3D dataset
V2X-sim and a real-road dataset DAIR-V2X and show that with the protection of
MADE, the drops in the average precision compared with the best-case "oracle"
defender against our attack are merely 1.28% and 0.34%, respectively, much
lower than 8.92% and 10.00% for adversarial training, respectively.
</p></li>
</ul>

<h3>Title: PREM: A Simple Yet Effective Approach for Node-Level Graph Anomaly Detection. (arXiv:2310.11676v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.11676">http://arxiv.org/abs/2310.11676</a></li>
<li>Code URL: https://github.com/campanulabells/prem-gad</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.11676]] PREM: A Simple Yet Effective Approach for Node-Level Graph Anomaly Detection(http://arxiv.org/abs/2310.11676)</code></li>
<li>Summary: <p>Node-level graph anomaly detection (GAD) plays a critical role in identifying
anomalous nodes from graph-structured data in various domains such as medicine,
social networks, and e-commerce. However, challenges have arisen due to the
diversity of anomalies and the dearth of labeled data. Existing methodologies -
reconstruction-based and contrastive learning - while effective, often suffer
from efficiency issues, stemming from their complex objectives and elaborate
modules. To improve the efficiency of GAD, we introduce a simple method termed
PREprocessing and Matching (PREM for short). Our approach streamlines GAD,
reducing time and memory consumption while maintaining powerful anomaly
detection capabilities. Comprising two modules - a pre-processing module and an
ego-neighbor matching module - PREM eliminates the necessity for
message-passing propagation during training, and employs a simple contrastive
loss, leading to considerable reductions in training time and memory usage.
Moreover, through rigorous evaluations of five real-world datasets, our method
demonstrated robustness and effectiveness. Notably, when validated on the ACM
dataset, PREM achieved a 5% improvement in AUC, a 9-fold increase in training
speed, and sharply reduce memory usage compared to the most efficient baseline.
</p></li>
</ul>

<h3>Title: A Multi-Scale Decomposition MLP-Mixer for Time Series Analysis. (arXiv:2310.11959v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.11959">http://arxiv.org/abs/2310.11959</a></li>
<li>Code URL: https://github.com/zshhans/msd-mixer</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.11959]] A Multi-Scale Decomposition MLP-Mixer for Time Series Analysis(http://arxiv.org/abs/2310.11959)</code></li>
<li>Summary: <p>Time series data, often characterized by unique composition and complex
multi-scale temporal variations, requires special consideration of
decomposition and multi-scale modeling in its analysis. Existing deep learning
methods on this best fit to only univariate time series, and have not
sufficiently accounted for sub-series level modeling and decomposition
completeness. To address this, we propose MSD-Mixer, a Multi-Scale
Decomposition MLP-Mixer which learns to explicitly decompose the input time
series into different components, and represents the components in different
layers. To handle multi-scale temporal patterns and inter-channel dependencies,
we propose a novel temporal patching approach to model the time series as
multi-scale sub-series, i.e., patches, and employ MLPs to mix intra- and
inter-patch variations and channel-wise correlations. In addition, we propose a
loss function to constrain both the magnitude and autocorrelation of the
decomposition residual for decomposition completeness. Through extensive
experiments on various real-world datasets for five common time series analysis
tasks (long- and short-term forecasting, imputation, anomaly detection, and
classification), we demonstrate that MSD-Mixer consistently achieves
significantly better performance in comparison with other state-of-the-art
task-general and task-specific approaches.
</p></li>
</ul>

<h2>in-context</h2>
<h3>Title: Group Preference Optimization: Few-Shot Alignment of Large Language Models. (arXiv:2310.11523v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.11523">http://arxiv.org/abs/2310.11523</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.11523]] Group Preference Optimization: Few-Shot Alignment of Large Language Models(http://arxiv.org/abs/2310.11523)</code></li>
<li>Summary: <p>Many applications of large language models (LLMs), ranging from chatbots to
creative writing, require nuanced subjective judgments that can differ
significantly across different groups. Existing alignment algorithms can be
expensive to align for each group, requiring prohibitive amounts of
group-specific preference data and computation for real-world use cases. We
introduce Group Preference Optimization (GPO), an alignment framework that
steers language models to preferences of individual groups in a few-shot
manner. In GPO, we augment the base LLM with an independent transformer module
trained to predict the preferences of a group for the LLM generations. For
few-shot learning, we parameterize this module as an in-context autoregressive
transformer and train it via meta-learning on several groups. We empirically
validate the efficacy of GPO through rigorous evaluations using LLMs with
varied sizes on three human opinion adaptation tasks. These tasks involve
adapting to the preferences of US demographic groups, global countries, and
individual users. Our results demonstrate that GPO not only aligns models more
accurately but also requires fewer group-specific preferences, and less
training and inference computing resources, outperforming existing strategies
such as in-context steering and fine-tuning methods.
</p></li>
</ul>

<h3>Title: MAGNIFICo: Evaluating the In-Context Learning Ability of Large Language Models to Generalize to Novel Interpretations. (arXiv:2310.11634v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.11634">http://arxiv.org/abs/2310.11634</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.11634]] MAGNIFICo: Evaluating the In-Context Learning Ability of Large Language Models to Generalize to Novel Interpretations(http://arxiv.org/abs/2310.11634)</code></li>
<li>Summary: <p>Humans possess a remarkable ability to assign novel interpretations to
linguistic expressions, enabling them to learn new words and understand
community-specific connotations. However, Large Language Models (LLMs) have a
knowledge cutoff and are costly to finetune repeatedly. Therefore, it is
crucial for LLMs to learn novel interpretations in-context. In this paper, we
systematically analyse the ability of LLMs to acquire novel interpretations
using in-context learning. To facilitate our study, we introduce MAGNIFICo, an
evaluation suite implemented within a text-to-SQL semantic parsing framework
that incorporates diverse tokens and prompt settings to simulate real-world
complexity. Experimental results on MAGNIFICo demonstrate that LLMs exhibit a
surprisingly robust capacity for comprehending novel interpretations from
natural language descriptions as well as from discussions within long
conversations. Nevertheless, our findings also highlight the need for further
improvements, particularly when interpreting unfamiliar words or when composing
multiple novel interpretations simultaneously in the same example.
Additionally, our analysis uncovers the semantic predispositions in LLMs and
reveals the impact of recency bias for information presented in long contexts.
</p></li>
</ul>

<h3>Title: Understanding Retrieval Augmentation for Long-Form Question Answering. (arXiv:2310.12150v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.12150">http://arxiv.org/abs/2310.12150</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.12150]] Understanding Retrieval Augmentation for Long-Form Question Answering(http://arxiv.org/abs/2310.12150)</code></li>
<li>Summary: <p>We present a study of retrieval-augmented language models (LMs) on long-form
question answering. We analyze how retrieval augmentation impacts different
LMs, by comparing answers generated from models while using the same evidence
documents, and how differing quality of retrieval document set impacts the
answers generated from the same LM. We study various attributes of generated
answers (e.g., fluency, length, variance) with an emphasis on the attribution
of generated long-form answers to in-context evidence documents. We collect
human annotations of answer attribution and evaluate methods for automatically
judging attribution. Our study provides new insights on how retrieval
augmentation impacts long, knowledge-rich text generation of LMs. We further
identify attribution patterns for long text generation and analyze the main
culprits of attribution errors. Together, our analysis reveals how retrieval
augmentation impacts long knowledge-rich text generation and provide directions
for future work.
</p></li>
</ul>

<button id="copy">Copy All</button>
</article>
<script src="https://cdn.staticfile.org/clipboard.js/2.0.4/clipboard.min.js"></script>
<script src="../../javascript/clipboard.js"></script>
