<link rel="stylesheet" href="../../css/markdown.css" />
<article class="markdown-body">
<h2>secure</h2>
<h2>security</h2>
<h3>Title: Detecting and Characterizing Propagation of Security Weaknesses in Puppet-based Infrastructure Management. (arXiv:2208.01242v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2208.01242">http://arxiv.org/abs/2208.01242</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2208.01242] Detecting and Characterizing Propagation of Security Weaknesses in Puppet-based Infrastructure Management](http://arxiv.org/abs/2208.01242)</code></li>
<li>Summary: <p>Despite being beneficial for managing computing infrastructure automatically,
Puppet manifests are susceptible to security weaknesses, e.g., hard-coded
secrets and use of weak cryptography algorithms. Adequate mitigation of
security weaknesses in Puppet manifests is thus necessary to secure computing
infrastructure that are managed with Puppet manifests. A characterization of
how security weaknesses propagate and affect Puppet-based infrastructure
management, can inform practitioners on the relevance of the detected security
weaknesses, as well as help them take necessary actions for mitigation. To that
end, we conduct an empirical study with 17,629 Puppet manifests mined from 336
open source repositories. We construct Taint Tracker for Puppet Manifests
(TaintPup), for which we observe 2.4 times more precision compared to that of a
state-of-the-art security static analysis tool. TaintPup leverages
Puppet-specific information flow analysis using which we characterize
propagation of security weaknesses. From our empirical study, we observe
security weaknesses to propagate into 4,457 resources, i.e, Puppet-specific
code elements used to manage infrastructure. A single instance of a security
weakness can propagate into as many as 35 distinct resources. We observe
security weaknesses to propagate into 7 categories of resources, which include
resources used to manage continuous integration servers and network
controllers. According to our survey with 24 practitioners, propagation of
security weaknesses into data storage-related resources is rated to have the
most severe impact for Puppet-based infrastructure management.
</p></li>
</ul>

<h3>Title: Security Requirement Analysis of Blockchain-based E-Voting Systems. (arXiv:2208.01277v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2208.01277">http://arxiv.org/abs/2208.01277</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2208.01277] Security Requirement Analysis of Blockchain-based E-Voting Systems](http://arxiv.org/abs/2208.01277)</code></li>
<li>Summary: <p>In democratic countries such as India, voting is a fundamental right given to
citizens of their countries. Citizens need to physically present and cast their
vote in ballot-paper-based voting systems. Most of the citizens fail to fulfill
this constraint and have stayed away from their fundamental duty.
Electronic-voting systems are often considered one efficient alternative in
such situations. Blockchain Technology is an emerging technology that can
provide a real solution as it is characterized by immutable, transparent,
anonymous, and decentralized properties. This paper presents a security
requirement analysis for e-voting systems and evaluates blockchain technology
against these requirements.
</p></li>
</ul>

<h3>Title: A replication of a controlled experiment with two STRIDE variants. (arXiv:2208.01524v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2208.01524">http://arxiv.org/abs/2208.01524</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2208.01524] A replication of a controlled experiment with two STRIDE variants](http://arxiv.org/abs/2208.01524)</code></li>
<li>Summary: <p>To avoid costly security patching after software deployment,
security-by-design techniques (e.g., STRIDE threat analysis) are adopted in
organizations to root out security issues before the system is ever
implemented. Despite the global gap in cybersecurity workforce and the high
manual effort required for performing threat analysis, organizations are
ramping up threat analysis activities. However, past experimental results were
inconclusive regarding some performance indicators of threat analysis
techniques thus practitioners have little evidence for choosing the technique
to adopt. To address this issue, we replicated a controlled experiment with
STRIDE. Our study was aimed at measuring and comparing the performance
indicators (productivity and precision) of two STRIDE variants (element and
interaction). We conclude the paper by comparing our results to the original
study.
</p></li>
</ul>

<h2>privacy</h2>
<h3>Title: Dyadic Movement Synchrony Estimation Under Privacy-preserving Conditions. (arXiv:2208.01100v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2208.01100">http://arxiv.org/abs/2208.01100</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2208.01100] Dyadic Movement Synchrony Estimation Under Privacy-preserving Conditions](http://arxiv.org/abs/2208.01100)</code></li>
<li>Summary: <p>Movement synchrony refers to the dynamic temporal connection between the
motions of interacting people. The applications of movement synchrony are wide
and broad. For example, as a measure of coordination between teammates,
synchrony scores are often reported in sports. The autism community also
identifies movement synchrony as a key indicator of children's social and
developmental achievements. In general, raw video recordings are often used for
movement synchrony estimation, with the drawback that they may reveal people's
identities. Furthermore, such privacy concern also hinders data sharing, one
major roadblock to a fair comparison between different approaches in autism
research. To address the issue, this paper proposes an ensemble method for
movement synchrony estimation, one of the first deep-learning-based methods for
automatic movement synchrony assessment under privacy-preserving conditions.
Our method relies entirely on publicly shareable, identity-agnostic secondary
data, such as skeleton data and optical flow. We validate our method on two
datasets: (1) PT13 dataset collected from autism therapy interventions and (2)
TASD-2 dataset collected from synchronized diving competitions. In this
context, our method outperforms its counterpart approaches, both deep neural
networks and alternatives.
</p></li>
</ul>

<h3>Title: A Feasibility Study on Image Inpainting for Non-cleft Lip Generation from Patients with Cleft Lip. (arXiv:2208.01149v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2208.01149">http://arxiv.org/abs/2208.01149</a></li>
<li>Code URL: <a href="https://github.com/chrischen1023/nclg-mt">https://github.com/chrischen1023/nclg-mt</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2208.01149] A Feasibility Study on Image Inpainting for Non-cleft Lip Generation from Patients with Cleft Lip](http://arxiv.org/abs/2208.01149)</code></li>
<li>Summary: <p>A Cleft lip is a congenital abnormality requiring surgical repair by a
specialist. The surgeon must have extensive experience and theoretical
knowledge to perform surgery, and Artificial Intelligence (AI) method has been
proposed to guide surgeons in improving surgical outcomes. If AI can be used to
predict what a repaired cleft lip would look like, surgeons could use it as an
adjunct to adjust their surgical technique and improve results. To explore the
feasibility of this idea while protecting patient privacy, we propose a deep
learning-based image inpainting method that is capable of covering a cleft lip
and generating a lip and nose without a cleft. Our experiments are conducted on
two real-world cleft lip datasets and are assessed by expert cleft lip surgeons
to demonstrate the feasibility of the proposed method.
</p></li>
</ul>

<h3>Title: Pose Uncertainty Aware Movement Synchrony Estimation via Spatial-Temporal Graph Transformer. (arXiv:2208.01161v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2208.01161">http://arxiv.org/abs/2208.01161</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2208.01161] Pose Uncertainty Aware Movement Synchrony Estimation via Spatial-Temporal Graph Transformer](http://arxiv.org/abs/2208.01161)</code></li>
<li>Summary: <p>Movement synchrony reflects the coordination of body movements between
interacting dyads. The estimation of movement synchrony has been automated by
powerful deep learning models such as transformer networks. However, instead of
designing a specialized network for movement synchrony estimation, previous
transformer-based works broadly adopted architectures from other tasks such as
human activity recognition. Therefore, this paper proposed a skeleton-based
graph transformer for movement synchrony estimation. The proposed model applied
ST-GCN, a spatial-temporal graph convolutional neural network for skeleton
feature extraction, followed by a spatial transformer for spatial feature
generation. The spatial transformer is guided by a uniquely designed joint
position embedding shared between the same joints of interacting individuals.
Besides, we incorporated a temporal similarity matrix in temporal attention
computation considering the periodic intrinsic of body movements. In addition,
the confidence score associated with each joint reflects the uncertainty of a
pose, while previous works on movement synchrony estimation have not
sufficiently emphasized this point. Since transformer networks demand a
significant amount of data to train, we constructed a dataset for movement
synchrony estimation using Human3.6M, a benchmark dataset for human activity
recognition, and pretrained our model on it using contrastive learning. We
further applied knowledge distillation to alleviate information loss introduced
by pose detector failure in a privacy-preserving way. We compared our method
with representative approaches on PT13, a dataset collected from autism therapy
interventions. Our method achieved an overall accuracy of 88.98% and surpassed
its counterparts by a wide margin while maintaining data privacy.
</p></li>
</ul>

<h3>Title: On the Evaluation of User Privacy in Deep Neural Networks using Timing Side Channel. (arXiv:2208.01113v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2208.01113">http://arxiv.org/abs/2208.01113</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2208.01113] On the Evaluation of User Privacy in Deep Neural Networks using Timing Side Channel](http://arxiv.org/abs/2208.01113)</code></li>
<li>Summary: <p>Recent Deep Learning (DL) advancements in solving complex real-world tasks
have led to its widespread adoption in practical applications. However, this
opportunity comes with significant underlying risks, as many of these models
rely on privacy-sensitive data for training in a variety of applications,
making them an overly-exposed threat surface for privacy violations.
Furthermore, the widespread use of cloud-based Machine-Learning-as-a-Service
(MLaaS) for its robust infrastructure support has broadened the threat surface
to include a variety of remote side-channel attacks. In this paper, we first
identify and report a novel data-dependent timing side-channel leakage (termed
Class Leakage) in DL implementations originating from non-constant time
branching operation in a widely used DL framework PyTorch. We further
demonstrate a practical inference-time attack where an adversary with user
privilege and hard-label black-box access to an MLaaS can exploit Class Leakage
to compromise the privacy of MLaaS users. DL models are vulnerable to
Membership Inference Attack (MIA), where an adversary's objective is to deduce
whether any particular data has been used while training the model. In this
paper, as a separate case study, we demonstrate that a DL model secured with
differential privacy (a popular countermeasure against MIA) is still vulnerable
to MIA against an adversary exploiting Class Leakage. We develop an
easy-to-implement countermeasure by making a constant-time branching operation
that alleviates the Class Leakage and also aids in mitigating MIA. We have
chosen two standard benchmarking image classification datasets, CIFAR-10 and
CIFAR-100 to train five state-of-the-art pre-trained DL models, over two
different computing environments having Intel Xeon and Intel i7 processors to
validate our approach.
</p></li>
</ul>

<h3>Title: A ZK-SNARK based Proof of Assets Protocol for Bitcoin Exchanges. (arXiv:2208.01263v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2208.01263">http://arxiv.org/abs/2208.01263</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2208.01263] A ZK-SNARK based Proof of Assets Protocol for Bitcoin Exchanges](http://arxiv.org/abs/2208.01263)</code></li>
<li>Summary: <p>This paper proposes a protocol for Proof of Assets of a bitcoin exchange
using the Zero-Knowledge Succinct Non-Interactive Argument of Knowledge
(ZK-SNARK) without revealing either the bitcoin addresses of the exchange or
balances associated with those addresses. The proof of assets is a mechanism to
prove the total value of bitcoins the exchange has authority to spend using its
private keys. We construct a privacy-preserving ZK-SNARK proof system to prove
the knowledge of the private keys corresponding to the bitcoin assets of an
exchange. The ZK-SNARK tool-chain helps to convert an NP-Statement for proving
the knowledge of the private keys (known to the exchange) into a circuit
satisfiability problem. In this protocol, the exchange creates a Pedersen
commitment to the value of bitcoins associated with each address without
revealing the balance. The simulation results show that the proof generation
time, size, and verification time are efficient in practice.
</p></li>
</ul>

<h3>Title: Efficient Personalized Learning for Wearable Health Applications using HyperDimensional Computing. (arXiv:2208.01095v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2208.01095">http://arxiv.org/abs/2208.01095</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2208.01095] Efficient Personalized Learning for Wearable Health Applications using HyperDimensional Computing](http://arxiv.org/abs/2208.01095)</code></li>
<li>Summary: <p>Health monitoring applications increasingly rely on machine learning
techniques to learn end-user physiological and behavioral patterns in everyday
settings. Considering the significant role of wearable devices in monitoring
human body parameters, on-device learning can be utilized to build personalized
models for behavioral and physiological patterns, and provide data privacy for
users at the same time. However, resource constraints on most of these wearable
devices prevent the ability to perform online learning on them. To address this
issue, it is required to rethink the machine learning models from the
algorithmic perspective to be suitable to run on wearable devices.
Hyperdimensional computing (HDC) offers a well-suited on-device learning
solution for resource-constrained devices and provides support for
privacy-preserving personalization. Our HDC-based method offers flexibility,
high efficiency, resilience, and performance while enabling on-device
personalization and privacy protection. We evaluate the efficacy of our
approach using three case studies and show that our system improves the energy
efficiency of training by up to $45.8\times$ compared with the state-of-the-art
Deep Neural Network (DNN) algorithms while offering a comparable accuracy.
</p></li>
</ul>

<h3>Title: A Multifaceted Benchmarking of Synthetic Electronic Health Record Generation Models. (arXiv:2208.01230v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2208.01230">http://arxiv.org/abs/2208.01230</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2208.01230] A Multifaceted Benchmarking of Synthetic Electronic Health Record Generation Models](http://arxiv.org/abs/2208.01230)</code></li>
<li>Summary: <p>Synthetic health data have the potential to mitigate privacy concerns when
sharing data to support biomedical research and the development of innovative
healthcare applications. Modern approaches for data generation based on machine
learning, generative adversarial networks (GAN) methods in particular, continue
to evolve and demonstrate remarkable potential. Yet there is a lack of a
systematic assessment framework to benchmark methods as they emerge and
determine which methods are most appropriate for which use cases. In this work,
we introduce a generalizable benchmarking framework to appraise key
characteristics of synthetic health data with respect to utility and privacy
metrics. We apply the framework to evaluate synthetic data generation methods
for electronic health records (EHRs) data from two large academic medical
centers with respect to several use cases. The results illustrate that there is
a utility-privacy tradeoff for sharing synthetic EHR data. The results further
indicate that no method is unequivocally the best on all criteria in each use
case, which makes it evident why synthetic data generation methods need to be
assessed in context.
</p></li>
</ul>

<h3>Title: Short-term Load Forecasting with Distributed Long Short-Term Memory. (arXiv:2208.01147v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2208.01147">http://arxiv.org/abs/2208.01147</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2208.01147] Short-term Load Forecasting with Distributed Long Short-Term Memory](http://arxiv.org/abs/2208.01147)</code></li>
<li>Summary: <p>With the employment of smart meters, massive data on consumer behaviour can
be collected by retailers. From the collected data, the retailers may obtain
the household profile information and implement demand response. While
retailers prefer to acquire a model as accurate as possible among different
customers, there are two major challenges. First, different retailers in the
retail market do not share their consumer's electricity consumption data as
these data are regarded as their assets, which has led to the problem of data
island. Second, the electricity load data are highly heterogeneous since
different retailers may serve various consumers. To this end, a fully
distributed short-term load forecasting framework based on a consensus
algorithm and Long Short-Term Memory (LSTM) is proposed, which may protect the
customer's privacy and satisfy the accurate load forecasting requirement.
Specifically, a fully distributed learning framework is exploited for
distributed training, and a consensus technique is applied to meet confidential
privacy. Case studies show that the proposed method has comparable performance
with centralised methods regarding the accuracy, but the proposed method shows
advantages in training speed and data privacy.
</p></li>
</ul>

<h2>protect</h2>
<h3>Title: A Turning Point for Verified Spectre Sandboxing. (arXiv:2208.01548v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2208.01548">http://arxiv.org/abs/2208.01548</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2208.01548] A Turning Point for Verified Spectre Sandboxing](http://arxiv.org/abs/2208.01548)</code></li>
<li>Summary: <p>Spectre attacks enable an attacker to access restricted data in an
application's memory. Both the academic community and industry veterans have
developed several mitigations to block Spectre attacks, but to date, very few
have been formally vetted; most are "best effort" strategies. Formal guarantees
are particularly crucial for protecting isolated environments like sandboxing
against Spectre attacks. In such environments, a subtle flaw in the mitigation
would allow untrusted code to break out of the sandbox and access trusted
memory regions.
</p></li>
</ul>

<p>In our work, we develop principled foundations to build isolated environments
resistant against Spectre attacks. We propose a formal framework for reasoning
about sandbox execution and Spectre attacks. We formalize properties that sound
mitigation strategies must fulfill and we show how various existing mitigations
satisfy (or fail to satisfy!) these properties.
</p>

<h2>defense</h2>
<h2>attack</h2>
<h3>Title: SCFI: State Machine Control-Flow Hardening Against Fault Attacks. (arXiv:2208.01356v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2208.01356">http://arxiv.org/abs/2208.01356</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2208.01356] SCFI: State Machine Control-Flow Hardening Against Fault Attacks](http://arxiv.org/abs/2208.01356)</code></li>
<li>Summary: <p>Fault injection (FI) is a powerful attack methodology allowing an adversary
to entirely break the security of a target device. As finite-state machines
(FSMs) are fundamental hardware building blocks responsible for controlling
systems, inducing faults into these controllers enables an adversary to hijack
the execution of the integrated circuit. A common defense strategy mitigating
these attacks is to manually instantiate FSMs multiple times and detect faults
using a majority voting logic. However, as each additional FSM instance only
provides security against one additional induced fault, this approach scales
poorly in a multi-fault attack scenario.
</p></li>
</ul>

<p>In this paper, we present SCFI: a strong, probabilistic FSM protection
mechanism ensuring that control-flow deviations from the intended control-flow
are detected even in the presence of multiple faults. At its core, SCFI
consists of a hardened next-state function absorbing the execution history as
well as the FSM's control signals to derive the next state. When either the
absorbed inputs, the state registers, or the function itself are affected by
faults, SCFI triggers an error with no detection latency. We integrate SCFI
into a synthesis tool capable of automatically hardening arbitrary unprotected
FSMs without user interaction and open-source the tool. Our evaluation shows
that SCFI provides strong protection guarantees with a better area-time product
than FSMs protected using classical redundancy-based approaches. Finally, we
formally verify the resilience of the protected state machines using a
pre-silicon fault analysis tool.
</p>

<h3>Title: Improvement of algebraic attacks for solving superdetermined MinRank instances. (arXiv:2208.01442v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2208.01442">http://arxiv.org/abs/2208.01442</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2208.01442] Improvement of algebraic attacks for solving superdetermined MinRank instances](http://arxiv.org/abs/2208.01442)</code></li>
<li>Summary: <p>The MinRank (MR) problem is a computational problem that arises in many
cryptographic applications. In Verbel et al. (PQCrypto 2019), the authors
introduced a new way to solve superdetermined instances of the MinRank problem,
starting from the bilinear Kipnis-Shamir (KS) modeling. They use linear algebra
on specific Macaulay matrices, considering only multiples of the initial
equations by one block of variables, the so called ''kernel'' variables. Later,
Bardet et al. (Asiacrypt 2020) introduced a new Support Minors modeling (SM),
that consider the Pl{\"u}cker coordinates associated to the kernel variables,
i.e. the maximal minors of the Kernel matrix in the KS modeling. In this paper,
we give a complete algebraic explanation of the link between the (KS) and (SM)
modelings (for any instance). We then show that superdetermined MinRank
instances can be seen as easy instances of the SM modeling. In particular, we
show that performing computation at the smallest possible degree (the ''first
degree fall'') and the smallest possible number of variables is not always the
best strategy. We give complexity estimates of the attack for generic random
instances.We apply those results to the DAGS cryptosystem, that was submitted
to the first round of the NIST standardization process. We show that the
algebraic attack from Barelli and Couvreur (Asiacrypt 2018), improved in Bardet
et al. (CBC 2019), is a particular superdetermined MinRank instance.Here, the
instances are not generic, but we show that it is possible to analyse the
particular instances from DAGS and provide a way toselect the optimal
parameters (number of shortened positions) to solve a particular instance.
</p></li>
</ul>

<h2>robust</h2>
<h3>Title: Ithaca365: Dataset and Driving Perception under Repeated and Challenging Weather Conditions. (arXiv:2208.01166v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2208.01166">http://arxiv.org/abs/2208.01166</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2208.01166] Ithaca365: Dataset and Driving Perception under Repeated and Challenging Weather Conditions](http://arxiv.org/abs/2208.01166)</code></li>
<li>Summary: <p>Advances in perception for self-driving cars have accelerated in recent years
due to the availability of large-scale datasets, typically collected at
specific locations and under nice weather conditions. Yet, to achieve the high
safety requirement, these perceptual systems must operate robustly under a wide
variety of weather conditions including snow and rain. In this paper, we
present a new dataset to enable robust autonomous driving via a novel data
collection process - data is repeatedly recorded along a 15 km route under
diverse scene (urban, highway, rural, campus), weather (snow, rain, sun), time
(day/night), and traffic conditions (pedestrians, cyclists and cars). The
dataset includes images and point clouds from cameras and LiDAR sensors, along
with high-precision GPS/INS to establish correspondence across routes. The
dataset includes road and object annotations using amodal masks to capture
partial occlusions and 3D bounding boxes. We demonstrate the uniqueness of this
dataset by analyzing the performance of baselines in amodal segmentation of
road and objects, depth estimation, and 3D object detection. The repeated
routes opens new research directions in object discovery, continual learning,
and anomaly detection. Link to Ithaca365: https://ithaca365.mae.cornell.edu/
</p></li>
</ul>

<h3>Title: MV6D: Multi-View 6D Pose Estimation on RGB-D Frames Using a Deep Point-wise Voting Network. (arXiv:2208.01172v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2208.01172">http://arxiv.org/abs/2208.01172</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2208.01172] MV6D: Multi-View 6D Pose Estimation on RGB-D Frames Using a Deep Point-wise Voting Network](http://arxiv.org/abs/2208.01172)</code></li>
<li>Summary: <p>Estimating 6D poses of objects is an essential computer vision task. However,
most conventional approaches rely on camera data from a single perspective and
therefore suffer from occlusions. We overcome this issue with our novel
multi-view 6D pose estimation method called MV6D which accurately predicts the
6D poses of all objects in a cluttered scene based on RGB-D images from
multiple perspectives. We base our approach on the PVN3D network that uses a
single RGB-D image to predict keypoints of the target objects. We extend this
approach by using a combined point cloud from multiple views and fusing the
images from each view with a DenseFusion layer. In contrast to current
multi-view pose detection networks such as CosyPose, our MV6D can learn the
fusion of multiple perspectives in an end-to-end manner and does not require
multiple prediction stages or subsequent fine tuning of the prediction.
Furthermore, we present three novel photorealistic datasets of cluttered scenes
with heavy occlusions. All of them contain RGB-D images from multiple
perspectives and the ground truth for instance semantic segmentation and 6D
pose estimation. MV6D significantly outperforms the state-of-the-art in
multi-view 6D pose estimation even in cases where the camera poses are known
inaccurately. Furthermore, we show that our approach is robust towards dynamic
camera setups and that its accuracy increases incrementally with an increasing
number of perspectives.
</p></li>
</ul>

<h3>Title: A Robust Morphological Approach for Semantic Segmentation of Very High Resolution Images. (arXiv:2208.01254v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2208.01254">http://arxiv.org/abs/2208.01254</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2208.01254] A Robust Morphological Approach for Semantic Segmentation of Very High Resolution Images](http://arxiv.org/abs/2208.01254)</code></li>
<li>Summary: <p>State-of-the-art methods for semantic segmentation of images involve
computationally intensive neural network architectures. Most of these methods
are not adaptable to high-resolution image segmentation due to memory and other
computational issues. Typical approaches in literature involve design of neural
network architectures that can fuse global information from low-resolution
images and local information from the high-resolution counterparts. However,
architectures designed for processing high resolution images are unnecessarily
complex and involve a lot of hyper parameters that can be difficult to tune.
Also, most of these architectures require ground truth annotations of the high
resolution images to train, which can be hard to obtain. In this article, we
develop a robust pipeline based on mathematical morphological (MM) operators
that can seamlessly extend any existing semantic segmentation algorithm to high
resolution images. Our method does not require the ground truth annotations of
the high resolution images. It is based on efficiently utilizing information
from the low-resolution counterparts, and gradient information on the
high-resolution images. We obtain high quality seeds from the inferred labels
on low-resolution images using traditional morphological operators and
propagate seed labels using a random walker to refine the semantic labels at
the boundaries. We show that the semantic segmentation results obtained by our
method beat the existing state-of-the-art algorithms on high-resolution images.
We empirically prove the robustness of our approach to the hyper parameters
used in our pipeline. Further, we characterize some necessary conditions under
which our pipeline is applicable and provide an in-depth analysis of the
proposed approach.
</p></li>
</ul>

<h3>Title: Unified Normalization for Accelerating and Stabilizing Transformers. (arXiv:2208.01313v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2208.01313">http://arxiv.org/abs/2208.01313</a></li>
<li>Code URL: <a href="https://github.com/hikvision-research/unified-normalization">https://github.com/hikvision-research/unified-normalization</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2208.01313] Unified Normalization for Accelerating and Stabilizing Transformers](http://arxiv.org/abs/2208.01313)</code></li>
<li>Summary: <p>Solid results from Transformers have made them prevailing architectures in
various natural language and vision tasks. As a default component in
Transformers, Layer Normalization (LN) normalizes activations within each token
to boost the robustness. However, LN requires on-the-fly statistics calculation
in inference as well as division and square root operations, leading to
inefficiency on hardware. What is more, replacing LN with other
hardware-efficient normalization schemes (e.g., Batch Normalization) results in
inferior performance, even collapse in training. We find that this dilemma is
caused by abnormal behaviors of activation statistics, including large
fluctuations over iterations and extreme outliers across layers. To tackle
these issues, we propose Unified Normalization (UN), which can speed up the
inference by being fused with other linear operations and achieve comparable
performance on par with LN. UN strives to boost performance by calibrating the
activation and gradient statistics with a tailored fluctuation smoothing
strategy. Meanwhile, an adaptive outlier filtration strategy is applied to
avoid collapse in training whose effectiveness is theoretically proved and
experimentally verified in this paper. We demonstrate that UN can be an
efficient drop-in alternative to LN by conducting extensive experiments on
language and vision tasks. Besides, we evaluate the efficiency of our method on
GPU. Transformers equipped with UN enjoy about 31% inference speedup and nearly
18% memory reduction. Code will be released at
https://github.com/hikvision-research/Unified-Normalization.
</p></li>
</ul>

<h3>Title: UnrealEgo: A New Dataset for Robust Egocentric 3D Human Motion Capture. (arXiv:2208.01633v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2208.01633">http://arxiv.org/abs/2208.01633</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2208.01633] UnrealEgo: A New Dataset for Robust Egocentric 3D Human Motion Capture](http://arxiv.org/abs/2208.01633)</code></li>
<li>Summary: <p>We present UnrealEgo, i.e., a new large-scale naturalistic dataset for
egocentric 3D human pose estimation. UnrealEgo is based on an advanced concept
of eyeglasses equipped with two fisheye cameras that can be used in
unconstrained environments. We design their virtual prototype and attach them
to 3D human models for stereo view capture. We next generate a large corpus of
human motions. As a consequence, UnrealEgo is the first dataset to provide
in-the-wild stereo images with the largest variety of motions among existing
egocentric datasets. Furthermore, we propose a new benchmark method with a
simple but effective idea of devising a 2D keypoint estimation module for
stereo inputs to improve 3D human pose estimation. The extensive experiments
show that our approach outperforms the previous state-of-the-art methods
qualitatively and quantitatively. UnrealEgo and our source codes are available
on our project web page.
</p></li>
</ul>

<h3>Title: Compound Density Networks for Risk Prediction using Electronic Health Records. (arXiv:2208.01320v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2208.01320">http://arxiv.org/abs/2208.01320</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2208.01320] Compound Density Networks for Risk Prediction using Electronic Health Records](http://arxiv.org/abs/2208.01320)</code></li>
<li>Summary: <p>Electronic Health Records (EHRs) exhibit a high amount of missing data due to
variations of patient conditions and treatment needs. Imputation of missing
values has been considered an effective approach to deal with this challenge.
Existing work separates imputation method and prediction model as two
independent parts of an EHR-based machine learning system. We propose an
integrated end-to-end approach by utilizing a Compound Density Network (CDNet)
that allows the imputation method and prediction model to be tuned together
within a single framework. CDNet consists of a Gated recurrent unit (GRU), a
Mixture Density Network (MDN), and a Regularized Attention Network (RAN). The
GRU is used as a latent variable model to model EHR data. The MDN is designed
to sample latent variables generated by GRU. The RAN serves as a regularizer
for less reliable imputed values. The architecture of CDNet enables GRU and MDN
to iteratively leverage the output of each other to impute missing values,
leading to a more accurate and robust prediction. We validate CDNet on the
mortality prediction task on the MIMIC-III dataset. Our model outperforms
state-of-the-art models by significant margins. We also empirically show that
regularizing imputed values is a key factor for superior prediction
performance. Analysis of prediction uncertainty shows that our model can
capture both aleatoric and epistemic uncertainties, which offers model users a
better understanding of the model results.
</p></li>
</ul>

<h2>biometric</h2>
<h2>steal</h2>
<h2>extraction</h2>
<h3>Title: GaitGL: Learning Discriminative Global-Local Feature Representations for Gait Recognition. (arXiv:2208.01380v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2208.01380">http://arxiv.org/abs/2208.01380</a></li>
<li>Code URL: <a href="https://github.com/bb12346/gaitgl">https://github.com/bb12346/gaitgl</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2208.01380] GaitGL: Learning Discriminative Global-Local Feature Representations for Gait Recognition](http://arxiv.org/abs/2208.01380)</code></li>
<li>Summary: <p>Existing gait recognition methods either directly establish Global Feature
Representation (GFR) from original gait sequences or generate Local Feature
Representation (LFR) from several local parts. However, GFR tends to neglect
local details of human postures as the receptive fields become larger in the
deeper network layers. Although LFR allows the network to focus on the detailed
posture information of each local region, it neglects the relations among
different local parts and thus only exploits limited local information of
several specific regions. To solve these issues, we propose a global-local
based gait recognition network, named GaitGL, to generate more discriminative
feature representations. To be specific, a novel Global and Local Convolutional
Layer (GLCL) is developed to take full advantage of both global visual
information and local region details in each layer. GLCL is a dual-branch
structure that consists of a GFR extractor and a mask-based LFR extractor. GFR
extractor aims to extract contextual information, e.g., the relationship among
various body parts, and the mask-based LFR extractor is presented to exploit
the detailed posture changes of local regions. In addition, we introduce a
novel mask-based strategy to improve the local feature extraction capability.
Specifically, we design pairs of complementary masks to randomly occlude
feature maps, and then train our mask-based LFR extractor on various occluded
feature maps. In this manner, the LFR extractor will learn to fully exploit
local information. Extensive experiments demonstrate that GaitGL achieves
better performance than state-of-the-art gait recognition methods. The average
rank-1 accuracy on CASIA-B, OU-MVLP, GREW and Gait3D is 93.6%, 98.7%, 68.0% and
63.8%, respectively, significantly outperforming the competing methods. The
proposed method has won the first prize in two competitions: HID 2020 and HID
2021.
</p></li>
</ul>

<h3>Title: Joint Learning-based Causal Relation Extraction from Biomedical Literature. (arXiv:2208.01316v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2208.01316">http://arxiv.org/abs/2208.01316</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2208.01316] Joint Learning-based Causal Relation Extraction from Biomedical Literature](http://arxiv.org/abs/2208.01316)</code></li>
<li>Summary: <p>Causal relation extraction of biomedical entities is one of the most complex
tasks in biomedical text mining, which involves two kinds of information:
entity relations and entity functions. One feasible approach is to take
relation extraction and function detection as two independent sub-tasks.
However, this separate learning method ignores the intrinsic correlation
between them and leads to unsatisfactory performance. In this paper, we propose
a joint learning model, which combines entity relation extraction and entity
function detection to exploit their commonality and capture their
inter-relationship, so as to improve the performance of biomedical causal
relation extraction. Meanwhile, during the model training stage, different
function types in the loss function are assigned different weights.
Specifically, the penalty coefficient for negative function instances increases
to effectively improve the precision of function detection. Experimental
results on the BioCreative-V Track 4 corpus show that our joint learning model
outperforms the separate models in BEL statement extraction, achieving the F1
scores of 58.4% and 37.3% on the test set in Stage 2 and Stage 1 evaluations,
respectively. This demonstrates that our joint learning system reaches the
state-of-the-art performance in Stage 2 compared with other systems.
</p></li>
</ul>

<h3>Title: PyABSA: Open Framework for Aspect-based Sentiment Analysis. (arXiv:2208.01368v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2208.01368">http://arxiv.org/abs/2208.01368</a></li>
<li>Code URL: <a href="https://github.com/yangheng95/pyabsa">https://github.com/yangheng95/pyabsa</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2208.01368] PyABSA: Open Framework for Aspect-based Sentiment Analysis](http://arxiv.org/abs/2208.01368)</code></li>
<li>Summary: <p>Aspect-based sentiment analysis (ABSA) has become a prevalent task in recent
years. However, the absence of a unified framework in the present ABSA research
makes it challenging to compare different models' performance fairly.
Therefore, we created an open-source ABSA framework, namely PYABSA. Besides,
previous efforts usually neglect the precursor aspect term extraction (ASC)
subtask and focus on the aspect sentiment classification (ATE) subtask.
Compared to previous works, PYABSA includes the features of aspect term
extraction, aspect sentiment classification, and text classification, while
multiple ABSA subtasks can be adapted to PYABSA owing to its modular
architecture. To facilitate ABSA applications, PYABSAseamless integrates
multilingual modelling, automated dataset annotation, etc., which are helpful
in deploying ABSA services. In ASC and ATE, PYABSA provides up to 33 and 7
built-in models, respectively, while all the models provide quick training and
instant inference. Besides, PYABSA contains 180K+ ABSA instances from 21
augmented ABSA datasets for applications and studies. PyABSA is available at
https://github.com/yangheng95/PyABSA
</p></li>
</ul>

<h3>Title: EBOCA: Evidences for BiOmedical Concepts Association Ontology. (arXiv:2208.01093v1 [cs.AI])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2208.01093">http://arxiv.org/abs/2208.01093</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2208.01093] EBOCA: Evidences for BiOmedical Concepts Association Ontology](http://arxiv.org/abs/2208.01093)</code></li>
<li>Summary: <p>There is a large number of online documents data sources available nowadays.
The lack of structure and the differences between formats are the main
difficulties to automatically extract information from them, which also has a
negative impact on its use and reuse. In the biomedical domain, the DISNET
platform emerged to provide researchers with a resource to obtain information
in the scope of human disease networks by means of large-scale heterogeneous
sources. Specifically in this domain, it is critical to offer not only the
information extracted from different sources, but also the evidence that
supports it. This paper proposes EBOCA, an ontology that describes (i)
biomedical domain concepts and associations between them, and (ii) evidences
supporting these associations; with the objective of providing an schema to
improve the publication and description of evidences and biomedical
associations in this domain. The ontology has been successfully evaluated to
ensure there are no errors, modelling pitfalls and that it meets the previously
defined functional requirements. Test data coming from a subset of DISNET and
automatic association extractions from texts has been transformed according to
the proposed ontology to create a Knowledge Graph that can be used in real
scenarios, and which has also been used for the evaluation of the presented
ontology.
</p></li>
</ul>

<h3>Title: Physics-informed Deep Super-resolution for Spatiotemporal Data. (arXiv:2208.01462v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2208.01462">http://arxiv.org/abs/2208.01462</a></li>
<li>Code URL: <a href="https://github.com/paulpuren/physr">https://github.com/paulpuren/physr</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2208.01462] Physics-informed Deep Super-resolution for Spatiotemporal Data](http://arxiv.org/abs/2208.01462)</code></li>
<li>Summary: <p>High-fidelity simulation of complex physical systems is exorbitantly
expensive and inaccessible across spatiotemporal scales. Recently, there has
been an increasing interest in leveraging deep learning to augment scientific
data based on the coarse-grained simulations, which is of cheap computational
expense and retains satisfactory solution accuracy. However, the major existing
work focuses on data-driven approaches which rely on rich training datasets and
lack sufficient physical constraints. To this end, we propose a novel and
efficient spatiotemporal super-resolution framework via physics-informed
learning, inspired by the independence between temporal and spatial derivatives
in partial differential equations (PDEs). The general principle is to leverage
the temporal interpolation for flow estimation, and then introduce
convolutional-recurrent neural networks for learning temporal refinement.
Furthermore, we employ the stacked residual blocks with wide activation and
sub-pixel layers with pixelshuffle for spatial reconstruction, where feature
extraction is conducted in a low-resolution latent space. Moreover, we consider
hard imposition of boundary conditions in the network to improve reconstruction
accuracy. Results demonstrate the superior effectiveness and efficiency of the
proposed method compared with baseline algorithms through extensive numerical
experiments.
</p></li>
</ul>

<h2>membership infer</h2>
<h2>federate</h2>
<h3>Title: Mitigating Biases in Student Performance Prediction via Attention-Based Personalized Federated Learning. (arXiv:2208.01182v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2208.01182">http://arxiv.org/abs/2208.01182</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2208.01182] Mitigating Biases in Student Performance Prediction via Attention-Based Personalized Federated Learning](http://arxiv.org/abs/2208.01182)</code></li>
<li>Summary: <p>Traditional learning-based approaches to student modeling generalize poorly
to underrepresented student groups due to biases in data availability. In this
paper, we propose a methodology for predicting student performance from their
online learning activities that optimizes inference accuracy over different
demographic groups such as race and gender. Building upon recent foundations in
federated learning, in our approach, personalized models for individual student
subgroups are derived from a global model aggregated across all student models
via meta-gradient updates that account for subgroup heterogeneity. To learn
better representations of student activity, we augment our approach with a
self-supervised behavioral pretraining methodology that leverages multiple
modalities of student behavior (e.g., visits to lecture videos and
participation on forums), and include a neural network attention mechanism in
the model aggregation stage. Through experiments on three real-world datasets
from online courses, we demonstrate that our approach obtains substantial
improvements over existing student modeling baselines in predicting student
learning outcomes for all subgroups. Visual analysis of the resulting student
embeddings confirm that our personalization methodology indeed identifies
different activity patterns within different subgroups, consistent with its
stronger inference ability compared with the baselines.
</p></li>
</ul>

<h2>fair</h2>
<h3>Title: Explicit Use of Fourier Spectrum in Generative Adversarial Networks. (arXiv:2208.01265v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2208.01265">http://arxiv.org/abs/2208.01265</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2208.01265] Explicit Use of Fourier Spectrum in Generative Adversarial Networks](http://arxiv.org/abs/2208.01265)</code></li>
<li>Summary: <p>Generative Adversarial Networks have got the researchers' attention due to
their state-of-the-art performance in generating new images with only a dataset
of the target distribution. It has been shown that there is a dissimilarity
between the spectrum of authentic images and fake ones. Since the Fourier
transform is a bijective mapping, saying that the model has a significant
problem in learning the original distribution is a fair conclusion. In this
work, we investigate the possible reasons for the mentioned drawback in the
architecture and mathematical theory of the current GANs. Then we propose a new
model to reduce the discrepancies between the spectrum of the actual and fake
images. To that end, we design a brand new architecture for the frequency
domain using the blueprint of geometric deep learning. Then, we experimentally
show promising improvements in the quality of the generated images by
considering the Fourier domain representation of the original data as a
principal feature in the training process.
</p></li>
</ul>

<h3>Title: CIPCaD-Bench: Continuous Industrial Process datasets for benchmarking Causal Discovery methods. (arXiv:2208.01529v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2208.01529">http://arxiv.org/abs/2208.01529</a></li>
<li>Code URL: <a href="https://github.com/giovannimen/cpcad-bench">https://github.com/giovannimen/cpcad-bench</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2208.01529] CIPCaD-Bench: Continuous Industrial Process datasets for benchmarking Causal Discovery methods](http://arxiv.org/abs/2208.01529)</code></li>
<li>Summary: <p>Causal relationships are commonly examined in manufacturing processes to
support faults investigations, perform interventions, and make strategic
decisions. Industry 4.0 has made available an increasing amount of data that
enable data-driven Causal Discovery (CD). Considering the growing number of
recently proposed CD methods, it is necessary to introduce strict benchmarking
procedures on publicly available datasets since they represent the foundation
for a fair comparison and validation of different methods. This work introduces
two novel public datasets for CD in continuous manufacturing processes. The
first dataset employs the well-known Tennessee Eastman simulator for fault
detection and process control. The second dataset is extracted from an
ultra-processed food manufacturing plant, and it includes a description of the
plant, as well as multiple ground truths. These datasets are used to propose a
benchmarking procedure based on different metrics and evaluated on a wide
selection of CD algorithms. This work allows testing CD methods in realistic
conditions enabling the selection of the most suitable method for specific
target applications. The datasets are available at the following link:
https://github.com/giovanniMen
</p></li>
</ul>

<h3>Title: The Curse of Low Task Diversity: On the Failure of Transfer Learning to Outperform MAML and Their Empirical Equivalence. (arXiv:2208.01545v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2208.01545">http://arxiv.org/abs/2208.01545</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2208.01545] The Curse of Low Task Diversity: On the Failure of Transfer Learning to Outperform MAML and Their Empirical Equivalence](http://arxiv.org/abs/2208.01545)</code></li>
<li>Summary: <p>Recently, it has been observed that a transfer learning solution might be all
we need to solve many few-shot learning benchmarks -- thus raising important
questions about when and how meta-learning algorithms should be deployed. In
this paper, we seek to clarify these questions by 1. proposing a novel metric
-- the diversity coefficient -- to measure the diversity of tasks in a few-shot
learning benchmark and 2. by comparing Model-Agnostic Meta-Learning (MAML) and
transfer learning under fair conditions (same architecture, same optimizer, and
all models trained to convergence). Using the diversity coefficient, we show
that the popular MiniImageNet and CIFAR-FS few-shot learning benchmarks have
low diversity. This novel insight contextualizes claims that transfer learning
solutions are better than meta-learned solutions in the regime of low diversity
under a fair comparison. Specifically, we empirically find that a low diversity
coefficient correlates with a high similarity between transfer learning and
MAML learned solutions in terms of accuracy at meta-test time and
classification layer similarity (using feature based distance metrics like
SVCCA, PWCCA, CKA, and OPD). To further support our claim, we find this
meta-test accuracy holds even as the model size changes. Therefore, we conclude
that in the low diversity regime, MAML and transfer learning have equivalent
meta-test performance when both are compared fairly. We also hope our work
inspires more thoughtful constructions and quantitative evaluations of
meta-learning benchmarks in the future.
</p></li>
</ul>

<h2>interpretability</h2>
<h3>Title: ferret: a Framework for Benchmarking Explainers on Transformers. (arXiv:2208.01575v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2208.01575">http://arxiv.org/abs/2208.01575</a></li>
<li>Code URL: <a href="https://github.com/g8a9/ferret">https://github.com/g8a9/ferret</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2208.01575] ferret: a Framework for Benchmarking Explainers on Transformers](http://arxiv.org/abs/2208.01575)</code></li>
<li>Summary: <p>Many interpretability tools allow practitioners and researchers to explain
Natural Language Processing systems. However, each tool requires different
configurations and provides explanations in different forms, hindering the
possibility of assessing and comparing them. A principled, unified evaluation
benchmark will guide the users through the central question: which explanation
method is more reliable for my use case? We introduce ferret, an easy-to-use,
extensible Python library to explain Transformer-based models integrated with
the Hugging Face Hub. It offers a unified benchmarking suite to test and
compare a wide range of state-of-the-art explainers on any text or
interpretability corpora. In addition, ferret provides convenient programming
abstractions to foster the introduction of new explanation methods, datasets,
or evaluation metrics.
</p></li>
</ul>

<h3>Title: Interpretable Time Series Clustering Using Local Explanations. (arXiv:2208.01152v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2208.01152">http://arxiv.org/abs/2208.01152</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2208.01152] Interpretable Time Series Clustering Using Local Explanations](http://arxiv.org/abs/2208.01152)</code></li>
<li>Summary: <p>This study focuses on exploring the use of local interpretability methods for
explaining time series clustering models. Many of the state-of-the-art
clustering models are not directly explainable. To provide explanations for
these clustering algorithms, we train classification models to estimate the
cluster labels. Then, we use interpretability methods to explain the decisions
of the classification models. The explanations are used to obtain insights into
the clustering models. We perform a detailed numerical study to test the
proposed approach on multiple datasets, clustering models, and classification
models. The analysis of the results shows that the proposed approach can be
used to explain time series clustering models, specifically when the underlying
classification model is accurate. Lastly, we provide a detailed analysis of the
results, discussing how our approach can be used in a real-life scenario.
</p></li>
</ul>

<h2>exlainability</h2>
<h2>watermark</h2>
<button id="copy">Copy All</button>
</article>
<script src="../../javascript/clipboard.min.js"></script>
<script src="../../javascript/clipboard.js"></script>
