<link rel="stylesheet" href="../../css/markdown.css" />
<article class="markdown-body">
<h1>2025-08-27</h1>
<h3>Title: Reasoning Steps as Curriculum: Using Depth of Thought as a Difficulty Signal for Tuning LLMs</h3>
<ul>
<li><strong>Authors: </strong>Jeesu Jung, Sangkeun Jung</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.18279">https://arxiv.org/abs/2508.18279</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.18279">https://arxiv.org/pdf/2508.18279</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.18279]] Reasoning Steps as Curriculum: Using Depth of Thought as a Difficulty Signal for Tuning LLMs(https://arxiv.org/abs/2508.18279)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Curriculum learning for training LLMs requires a difficulty signal that aligns with reasoning while remaining scalable and interpretable. We propose a simple premise: tasks that demand deeper depth of thought for humans should also be harder for models. Accordingly, we define difficulty as depth of thought (DoT) and operationalize it by counting the discrete steps in a teacher model's reasoning trace (e.g., Chain-of-Thought). We then train with a shallow to deep curriculum ordered by this DoT and outline how to derive, validate, and schedule it at scale. Our position yields three testable hypotheses: (i) DoT correlates with conventional difficulty on reasoning benchmarks, (ii) DoT-ordered curricula outperform length- or judge-scored curricula under matched budgets, and (iii) the difficulty is robust across teacher models given light formatting controls. We propose an evaluation framework and discuss threats to validity (teacher style, length confounds) alongside practical mitigations. Taken together, we aim to move toward cognitively grounded, interpretable curricula for reasoning-centric training.</li>
</ul>

<h3>Title: Multi-Modal Drift Forecasting of Leeway Objects via Navier-Stokes-Guided CNN and Sequence-to-Sequence Attention-Based Models</h3>
<ul>
<li><strong>Authors: </strong>Rahmat K. Adesunkanmi, Alexander W. Brandt, Masoud Deylami, Gustavo A. Giraldo Echeverri, Hamidreza Karbasian, Adel Alaeddini</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, eess.SY</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.18284">https://arxiv.org/abs/2508.18284</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.18284">https://arxiv.org/pdf/2508.18284</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.18284]] Multi-Modal Drift Forecasting of Leeway Objects via Navier-Stokes-Guided CNN and Sequence-to-Sequence Attention-Based Models(https://arxiv.org/abs/2508.18284)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Accurately predicting the drift (displacement) of leeway objects in maritime environments remains a critical challenge, particularly in time-sensitive scenarios such as search and rescue operations. In this study, we propose a multi-modal machine learning framework that integrates Sentence Transformer embeddings with attention-based sequence-to-sequence architectures to predict the drift of leeway objects in water. We begin by experimentally collecting environmental and physical data, including water current and wind velocities, object mass, and surface area, for five distinct leeway objects. Using simulated data from a Navier-Stokes-based model to train a convolutional neural network on geometrical image representations, we estimate drag and lift coefficients of the leeway objects. These coefficients are then used to derive the net forces responsible for driving the objects' motion. The resulting time series, comprising physical forces, environmental velocities, and object-specific features, combined with textual descriptions encoded via a language model, are inputs to attention-based sequence-to-sequence long-short-term memory and Transformer models, to predict future drift trajectories. We evaluate the framework across multiple time horizons ($1$, $3$, $5$, and $10$ seconds) and assess its generalization across different objects. We compare our approach against a fitted physics-based model and traditional machine learning methods, including recurrent neural networks and temporal convolutional neural networks. Our results show that these multi-modal models perform comparably to traditional models while also enabling longer-term forecasting in place of single-step prediction. Overall, our findings demonstrate the ability of a multi-modal modeling strategy to provide accurate and adaptable predictions of leeway object drift in dynamic maritime conditions.</li>
</ul>

<h3>Title: Semantic Attractors and the Emergence of Meaning: Towards a Teleological Model of AGI</h3>
<ul>
<li><strong>Authors: </strong>Hans-Joachim Rudolph</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.18290">https://arxiv.org/abs/2508.18290</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.18290">https://arxiv.org/pdf/2508.18290</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.18290]] Semantic Attractors and the Emergence of Meaning: Towards a Teleological Model of AGI(https://arxiv.org/abs/2508.18290)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>This essay develops a theoretical framework for a semantic Artificial General Intelligence (AGI) based on the notion of semantic attractors in complex-valued meaning spaces. Departing from current transformer-based language models, which operate on statistical next-token prediction, we explore a model in which meaning is not inferred probabilistically but formed through recursive tensorial transformation. Using cyclic operations involving the imaginary unit \emph{i}, we describe a rotational semantic structure capable of modeling irony, homonymy, and ambiguity. At the center of this model, however, is a semantic attractor -- a teleological operator that, unlike statistical computation, acts as an intentional agent (Microvitum), guiding meaning toward stability, clarity, and expressive depth. Conceived in terms of gradient flows, tensor deformations, and iterative matrix dynamics, the attractor offers a model of semantic transformation that is not only mathematically suggestive, but also philosophically significant. We argue that true meaning emerges not from simulation, but from recursive convergence toward semantic coherence, and that this requires a fundamentally new kind of cognitive architecture -- one designed to shape language, not just predict it.</li>
</ul>

<h3>Title: Towards Training-Free Underwater 3D Object Detection from Sonar Point Clouds: A Comparison of Traditional and Deep Learning Approaches</h3>
<ul>
<li><strong>Authors: </strong>M. Salman Shaukat, Yannik KÃ¤ckenmeister, Sebastian Bader, Thomas Kirste</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI, cs.LG, cs.RO</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.18293">https://arxiv.org/abs/2508.18293</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.18293">https://arxiv.org/pdf/2508.18293</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.18293]] Towards Training-Free Underwater 3D Object Detection from Sonar Point Clouds: A Comparison of Traditional and Deep Learning Approaches(https://arxiv.org/abs/2508.18293)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Underwater 3D object detection remains one of the most challenging frontiers in computer vision, where traditional approaches struggle with the harsh acoustic environment and scarcity of training data. While deep learning has revolutionized terrestrial 3D detection, its application underwater faces a critical bottleneck: obtaining sufficient annotated sonar data is prohibitively expensive and logistically complex, often requiring specialized vessels, expert surveyors, and favorable weather conditions. This work addresses a fundamental question: Can we achieve reliable underwater 3D object detection without real-world training data? We tackle this challenge by developing and comparing two paradigms for training-free detection of artificial structures in multibeam echo-sounder point clouds. Our dual approach combines a physics-based sonar simulation pipeline that generates synthetic training data for state-of-the-art neural networks, with a robust model-based template matching system that leverages geometric priors of target objects. Evaluation on real bathymetry surveys from the Baltic Sea reveals surprising insights: while neural networks trained on synthetic data achieve 98% mean Average Precision (mAP) on simulated scenes, they drop to 40% mAP on real sonar data due to domain shift. Conversely, our template matching approach maintains 83% mAP on real data without requiring any training, demonstrating remarkable robustness to acoustic noise and environmental variations. Our findings challenge conventional wisdom about data-hungry deep learning in underwater domains and establish the first large-scale benchmark for training-free underwater 3D detection. This work opens new possibilities for autonomous underwater vehicle navigation, marine archaeology, and offshore infrastructure monitoring in data-scarce environments where traditional machine learning approaches fail.</li>
</ul>

<h3>Title: MobileDenseAttn:A Dual-Stream Architecture for Accurate and Interpretable Brain Tumor Detection</h3>
<ul>
<li><strong>Authors: </strong>Shudipta Banik, Muna Das, Trapa Banik, Md. Ehsanul Haque</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.18294">https://arxiv.org/abs/2508.18294</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.18294">https://arxiv.org/pdf/2508.18294</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.18294]] MobileDenseAttn:A Dual-Stream Architecture for Accurate and Interpretable Brain Tumor Detection(https://arxiv.org/abs/2508.18294)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability</a></li>
<li><strong>Abstract: </strong>The detection of brain tumor in MRI is an important aspect of ensuring timely diagnostics and treatment; however, manual analysis is commonly long and error-prone. Current approaches are not universal because they have limited generalization to heterogeneous tumors, are computationally inefficient, are not interpretable, and lack transparency, thus limiting trustworthiness. To overcome these issues, we introduce MobileDenseAttn, a fusion model of dual streams of MobileNetV2 and DenseNet201 that can help gradually improve the feature representation scale, computing efficiency, and visual explanations via GradCAM. Our model uses feature level fusion and is trained on an augmented dataset of 6,020 MRI scans representing glioma, meningioma, pituitary tumors, and normal samples. Measured under strict 5-fold cross-validation protocols, MobileDenseAttn provides a training accuracy of 99.75%, a testing accuracy of 98.35%, and a stable F1 score of 0.9835 (95% CI: 0.9743 to 0.9920). The extensive validation shows the stability of the model, and the comparative analysis proves that it is a great advancement over the baseline models (VGG19, DenseNet201, MobileNetV2) with a +3.67% accuracy increase and a 39.3% decrease in training time compared to VGG19. The GradCAM heatmaps clearly show tumor-affected areas, offering clinically significant localization and improving interpretability. These findings position MobileDenseAttn as an efficient, high performance, interpretable model with a high probability of becoming a clinically practical tool in identifying brain tumors in the real world.</li>
</ul>

<h3>Title: Federative ischemic stroke segmentation as alternative to overcome domain-shift multi-institution challenges</h3>
<ul>
<li><strong>Authors: </strong>Edgar Rangel, Fabio Martinez</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI, cs.ET</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.18296">https://arxiv.org/abs/2508.18296</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.18296">https://arxiv.org/pdf/2508.18296</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.18296]] Federative ischemic stroke segmentation as alternative to overcome domain-shift multi-institution challenges(https://arxiv.org/abs/2508.18296)</code><input type="text"></li>
<li><strong>Keywords: </strong>federate, diffusion, segmentation</a></li>
<li><strong>Abstract: </strong>Stroke is the second leading cause of death and the third leading cause of disability worldwide. Clinical guidelines establish diffusion resonance imaging (DWI, ADC) as the standard for localizing, characterizing, and measuring infarct volume, enabling treatment support and prognosis. Nonetheless, such lesion analysis is highly variable due to different patient demographics, scanner vendors, and expert annotations. Computational support approaches have been key to helping with the localization and segmentation of lesions. However, these strategies are dedicated solutions that learn patterns from only one institution, lacking the variability to generalize geometrical lesions shape models. Even worse, many clinical centers lack sufficient labeled samples to adjust these dedicated solutions. This work developed a collaborative framework for segmenting ischemic stroke lesions in DWI sequences by sharing knowledge from deep center-independent representations. From 14 emulated healthcare centers with 2031 studies, the FedAvg model achieved a general DSC of $0.71 \pm 0.24$, AVD of $5.29 \pm 22.74$, ALD of $2.16 \pm 3.60$ and LF1 of $0.70 \pm 0.26$ over all centers, outperforming both the centralized and other federated rules. Interestingly, the model demonstrated strong generalization properties, showing uniform performance across different lesion categories and reliable performance in out-of-distribution centers (with DSC of $0.64 \pm 0.29$ and AVD of $4.44 \pm 8.74$ without any additional training).</li>
</ul>

<h3>Title: A Fast and Minimal System to Identify Depression Using Smartphones: Explainable Machine Learning-Based Approach</h3>
<ul>
<li><strong>Authors: </strong>Md Sabbir Ahmed, Nova Ahmed</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CY, cs.HC</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.18301">https://arxiv.org/abs/2508.18301</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.18301">https://arxiv.org/pdf/2508.18301</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.18301]] A Fast and Minimal System to Identify Depression Using Smartphones: Explainable Machine Learning-Based Approach(https://arxiv.org/abs/2508.18301)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Background: Existing robust, pervasive device-based systems developed in recent years to detect depression require data collected over a long period and may not be effective in cases where early detection is crucial. Objective: Our main objective was to develop a minimalistic system to identify depression using data retrieved in the fastest possible time. Methods: We developed a fast tool that retrieves the past 7 days' app usage data in 1 second (mean 0.31, SD 1.10 seconds). A total of 100 students from Bangladesh participated in our study, and our tool collected their app usage data. To identify depressed and nondepressed students, we developed a diverse set of ML models. We selected important features using the stable approach, along with 3 main types of feature selection (FS) approaches. Results: Leveraging only the app usage data retrieved in 1 second, our light gradient boosting machine model used the important features selected by the stable FS approach and correctly identified 82.4% (n=42) of depressed students (precision=75%, F1-score=78.5%). Moreover, after comprehensive exploration, we presented a parsimonious stacking model where around 5 features selected by the all-relevant FS approach Boruta were used in each iteration of validation and showed a maximum precision of 77.4% (balanced accuracy=77.9%). A SHAP analysis of our best models presented behavioral markers that were related to depression. Conclusions: Due to our system's fast and minimalistic nature, it may make a worthwhile contribution to identifying depression in underdeveloped and developing regions. In addition, our detailed discussion about the implication of our findings can facilitate the development of less resource-intensive systems to better understand students who are depressed.</li>
</ul>

<h3>Title: Learning Explainable Imaging-Genetics Associations Related to a Neurological Disorder</h3>
<ul>
<li><strong>Authors: </strong>Jueqi Wang, Zachary Jacokes, John Darrell Van Horn, Michael C. Schatz, Kevin A. Pelphrey, Archana Venkataraman</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, q-bio.QM</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.18303">https://arxiv.org/abs/2508.18303</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.18303">https://arxiv.org/pdf/2508.18303</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.18303]] Learning Explainable Imaging-Genetics Associations Related to a Neurological Disorder(https://arxiv.org/abs/2508.18303)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, interpretability</a></li>
<li><strong>Abstract: </strong>While imaging-genetics holds great promise for unraveling the complex interplay between brain structure and genetic variation in neurological disorders, traditional methods are limited to simplistic linear models or to black-box techniques that lack interpretability. In this paper, we present NeuroPathX, an explainable deep learning framework that uses an early fusion strategy powered by cross-attention mechanisms to capture meaningful interactions between structural variations in the brain derived from MRI and established biological pathways derived from genetics data. To enhance interpretability and robustness, we introduce two loss functions over the attention matrix - a sparsity loss that focuses on the most salient interactions and a pathway similarity loss that enforces consistent representations across the cohort. We validate NeuroPathX on both autism spectrum disorder and Alzheimer's disease. Our results demonstrate that NeuroPathX outperforms competing baseline approaches and reveals biologically plausible associations linked to the disorder. These findings underscore the potential of NeuroPathX to advance our understanding of complex brain disorders. Code is available at this https URL .</li>
</ul>

<h3>Title: SALMAN: Stability Analysis of Language Models Through the Maps Between Graph-based Manifolds</h3>
<ul>
<li><strong>Authors: </strong>Wuxinlin Cheng, Yupeng Cao, Jinwen Wu, Koduvayur Subbalakshmi, Tian Han, Zhuo Feng</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.18306">https://arxiv.org/abs/2508.18306</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.18306">https://arxiv.org/pdf/2508.18306</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.18306]] SALMAN: Stability Analysis of Language Models Through the Maps Between Graph-based Manifolds(https://arxiv.org/abs/2508.18306)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack, robust, transformer</a></li>
<li><strong>Abstract: </strong>Recent strides in pretrained transformer-based language models have propelled state-of-the-art performance in numerous NLP tasks. Yet, as these models grow in size and deployment, their robustness under input perturbations becomes an increasingly urgent question. Existing robustness methods often diverge between small-parameter and large-scale models (LLMs), and they typically rely on labor-intensive, sample-specific adversarial designs. In this paper, we propose a unified, local (sample-level) robustness framework (SALMAN) that evaluates model stability without modifying internal parameters or resorting to complex perturbation heuristics. Central to our approach is a novel Distance Mapping Distortion (DMD) measure, which ranks each sample's susceptibility by comparing input-to-output distance mappings in a near-linear complexity manner. By demonstrating significant gains in attack efficiency and robust training, we position our framework as a practical, model-agnostic tool for advancing the reliability of transformer-based NLP systems.</li>
</ul>

<h3>Title: CoPE: A Lightweight Complex Positional Encoding</h3>
<ul>
<li><strong>Authors: </strong>Avinash Amballa</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.18308">https://arxiv.org/abs/2508.18308</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.18308">https://arxiv.org/pdf/2508.18308</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.18308]] CoPE: A Lightweight Complex Positional Encoding(https://arxiv.org/abs/2508.18308)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Recent studies have demonstrated the effectiveness of position encoding in transformer architectures. By incorporating positional information, this approach provides essential guidance for modeling dependencies between elements across different sequence positions. We introduce CoPE (a lightweight Complex Positional Encoding), a novel architecture that leverages complex-valued encoding to encode both content and positional information. Our approach replaces traditional positional encodings with complex embeddings where the real part captures semantic content and the imaginary part encodes positional information. We introduce phase-aware attention in the first layer of the transformer model to capture position-dependent patterns, followed by standard attention layers for higher-levels. We show that CoPE doesn't exhibit long term decay and is compatible with linear attention. Experimental evaluation on the GLUE benchmark suggest that our approach achieves superior performance with less computational complexity, compared to RoPE, Sinusoidal and Learned positional encodings.</li>
</ul>

<h3>Title: What Matters in Data for DPO?</h3>
<ul>
<li><strong>Authors: </strong>Yu Pan, Zhongze Cai, Guanting Chen, Huaiyang Zhong, Chonghuan Wang</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.18312">https://arxiv.org/abs/2508.18312</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.18312">https://arxiv.org/pdf/2508.18312</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.18312]] What Matters in Data for DPO?(https://arxiv.org/abs/2508.18312)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Direct Preference Optimization (DPO) has emerged as a simple and effective approach for aligning large language models (LLMs) with human preferences, bypassing the need for a learned reward model. Despite its growing adoption, a fundamental question remains open: what characteristics of preference data are most critical for DPO performance? In this work, we provide a systematic study of how preference data distribution influences DPO, from both theoretical and empirical perspectives. We show that the quality of chosen responses plays a dominant role in optimizing the DPO objective, while the quality of rejected responses may have relatively limited impact. Our theoretical analysis characterizes the optimal response distribution under DPO and reveals how contrastiveness between responses helps primarily by improving the chosen samples. We further study an online DPO setting and show it effectively reduces to supervised fine-tuning on the chosen responses. Extensive experiments across diverse tasks confirm our findings: improving the quality of chosen responses consistently boosts performance regardless of the quality of the rejected responses. We also investigate the benefit of mixing the on-policy data. Our results interpret the mechanism behind some widely adopted strategies and offer practical insights for constructing high-impact preference datasets for LLM alignment.</li>
</ul>

<h3>Title: ProtoEHR: Hierarchical Prototype Learning for EHR-based Healthcare Predictions</h3>
<ul>
<li><strong>Authors: </strong>Zi Cai, Yu Liu, Zhiyao Luo, Tingting Zhu</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.18313">https://arxiv.org/abs/2508.18313</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.18313">https://arxiv.org/pdf/2508.18313</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.18313]] ProtoEHR: Hierarchical Prototype Learning for EHR-based Healthcare Predictions(https://arxiv.org/abs/2508.18313)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, interpretability, large language model</a></li>
<li><strong>Abstract: </strong>Digital healthcare systems have enabled the collection of mass healthcare data in electronic healthcare records (EHRs), allowing artificial intelligence solutions for various healthcare prediction tasks. However, existing studies often focus on isolated components of EHR data, limiting their predictive performance and interpretability. To address this gap, we propose ProtoEHR, an interpretable hierarchical prototype learning framework that fully exploits the rich, multi-level structure of EHR data to enhance healthcare predictions. More specifically, ProtoEHR models relationships within and across three hierarchical levels of EHRs: medical codes, hospital visits, and patients. We first leverage large language models to extract semantic relationships among medical codes and construct a medical knowledge graph as the knowledge source. Building on this, we design a hierarchical representation learning framework that captures contextualized representations across three levels, while incorporating prototype information within each level to capture intrinsic similarities and improve generalization. To perform a comprehensive assessment, we evaluate ProtoEHR in two public datasets on five clinically significant tasks, including prediction of mortality, prediction of readmission, prediction of length of stay, drug recommendation, and prediction of phenotype. The results demonstrate the ability of ProtoEHR to make accurate, robust, and interpretable predictions compared to baselines in the literature. Furthermore, ProtoEHR offers interpretable insights on code, visit, and patient levels to aid in healthcare prediction.</li>
</ul>

<h3>Title: Automated Landfill Detection Using Deep Learning: A Comparative Study of Lightweight and Custom Architectures with the AerialWaste Dataset</h3>
<ul>
<li><strong>Authors: </strong>Nowshin Sharmily, Rusab Sarmun, Muhammad E. H. Chowdhury, Mir Hamidul Hussain, Saad Bin Abul Kashem, Molla E Majid, Amith Khandakar</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.18315">https://arxiv.org/abs/2508.18315</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.18315">https://arxiv.org/pdf/2508.18315</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.18315]] Automated Landfill Detection Using Deep Learning: A Comparative Study of Lightweight and Custom Architectures with the AerialWaste Dataset(https://arxiv.org/abs/2508.18315)</code><input type="text"></li>
<li><strong>Keywords: </strong>security</a></li>
<li><strong>Abstract: </strong>Illegal landfills are posing as a hazardous threat to people all over the world. Due to the arduous nature of manually identifying the location of landfill, many landfills go unnoticed by authorities and later cause dangerous harm to people and environment. Deep learning can play a significant role in identifying these landfills while saving valuable time, manpower and resources. Despite being a burning concern, good quality publicly released datasets for illegal landfill detection are hard to find due to security concerns. However, AerialWaste Dataset is a large collection of 10434 images of Lombardy region of Italy. The images are of varying qualities, collected from three different sources: AGEA Orthophotos, WorldView-3, and Google Earth. The dataset contains professionally curated, diverse and high-quality images which makes it particularly suitable for scalable and impactful research. As we trained several models to compare results, we found complex and heavy models to be prone to overfitting and memorizing training data instead of learning patterns. Therefore, we chose lightweight simpler models which could leverage general features from the dataset. In this study, Mobilenetv2, Googlenet, Densenet, MobileVit and other lightweight deep learning models were used to train and validate the dataset as they achieved significant success with less overfitting. As we saw substantial improvement in the performance using some of these models, we combined the best performing models and came up with an ensemble model. With the help of ensemble and fusion technique, binary classification could be performed on this dataset with 92.33% accuracy, 92.67% precision, 92.33% sensitivity, 92.41% F1 score and 92.71% specificity.</li>
</ul>

<h3>Title: Evaluating Federated Learning for At-Risk Student Prediction: A Comparative Analysis of Model Complexity and Data Balancing</h3>
<ul>
<li><strong>Authors: </strong>Rodrigo Tertulino</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CY</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.18316">https://arxiv.org/abs/2508.18316</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.18316">https://arxiv.org/pdf/2508.18316</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.18316]] Evaluating Federated Learning for At-Risk Student Prediction: A Comparative Analysis of Model Complexity and Data Balancing(https://arxiv.org/abs/2508.18316)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, federate</a></li>
<li><strong>Abstract: </strong>High dropout and failure rates in distance education pose a significant challenge for academic institutions, making the proactive identification of at-risk students crucial for providing timely support. This study develops and evaluates a machine learning model based on early academic performance and digital engagement patterns from the large-scale OULAD dataset to predict student risk at a UK university. To address the practical challenges of data privacy and institutional silos that often hinder such initiatives, we implement the model using a Federated Learning (FL) framework. We compare model complexity (Logistic Regression vs. a Deep Neural Network) and data balancing. The final federated model demonstrates strong predictive capability, achieving an ROC AUC score of approximately 85% in identifying at-risk students. Our findings show that this federated approach provides a practical and scalable solution for institutions to build effective early-warning systems, enabling proactive student support while inherently respecting data privacy.</li>
</ul>

<h3>Title: ZTFed-MAS2S: A Zero-Trust Federated Learning Framework with Verifiable Privacy and Trust-Aware Aggregation for Wind Power Data Imputation</h3>
<ul>
<li><strong>Authors: </strong>Yang Li, Hanjie Wang, Yuanzheng Li, Jiazheng Li, Zhaoyang Dong</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CR, eess.SY</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.18318">https://arxiv.org/abs/2508.18318</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.18318">https://arxiv.org/pdf/2508.18318</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.18318]] ZTFed-MAS2S: A Zero-Trust Federated Learning Framework with Verifiable Privacy and Trust-Aware Aggregation for Wind Power Data Imputation(https://arxiv.org/abs/2508.18318)</code><input type="text"></li>
<li><strong>Keywords: </strong>secure, privacy, robust, federate</a></li>
<li><strong>Abstract: </strong>Wind power data often suffers from missing values due to sensor faults and unstable transmission at edge sites. While federated learning enables privacy-preserving collaboration without sharing raw data, it remains vulnerable to anomalous updates and privacy leakage during parameter exchange. These challenges are amplified in open industrial environments, necessitating zero-trust mechanisms where no participant is inherently trusted. To address these challenges, this work proposes ZTFed-MAS2S, a zero-trust federated learning framework that integrates a multi-head attention-based sequence-to-sequence imputation model. ZTFed integrates verifiable differential privacy with non-interactive zero-knowledge proofs and a confidentiality and integrity verification mechanism to ensure verifiable privacy preservation and secure model parameters transmission. A dynamic trust-aware aggregation mechanism is employed, where trust is propagated over similarity graphs to enhance robustness, and communication overhead is reduced via sparsity- and quantization-based compression. MAS2S captures long-term dependencies in wind power data for accurate imputation. Extensive experiments on real-world wind farm datasets validate the superiority of ZTFed-MAS2S in both federated learning performance and missing data imputation, demonstrating its effectiveness as a secure and efficient solution for practical applications in the energy sector.</li>
</ul>

<h3>Title: LLMs Can't Handle Peer Pressure: Crumbling under Multi-Agent Social Interactions</h3>
<ul>
<li><strong>Authors: </strong>Maojia Song, Tej Deep Pala, Weisheng Jin, Amir Zadeh, Chuan Li, Dorien Herremans, Soujanya Poria</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.18321">https://arxiv.org/abs/2508.18321</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.18321">https://arxiv.org/pdf/2508.18321</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.18321]] LLMs Can't Handle Peer Pressure: Crumbling under Multi-Agent Social Interactions(https://arxiv.org/abs/2508.18321)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, large language model</a></li>
<li><strong>Abstract: </strong>Large language models (LLMs) are increasingly deployed in multi-agent systems (MAS) as components of collaborative intelligence, where peer interactions dynamically shape individual decision-making. Although prior work has focused on conformity bias, we extend the analysis to examine how LLMs form trust from previous impressions, resist misinformation, and integrate peer input during interaction, key factors for achieving collective intelligence under complex social dynamics. We present KAIROS, a benchmark simulating quiz contests with peer agents of varying reliability, offering fine-grained control over conditions such as expert-novice roles, noisy crowds, and adversarial peers. LLMs receive both historical interactions and current peer responses, allowing systematic investigation into how trust, peer action, and self-confidence influence decisions. As for mitigation strategies, we evaluate prompting, supervised fine-tuning, and reinforcement learning, Group Relative Policy Optimisation (GRPO), across multiple models. Our results reveal that GRPO with multi-agent context combined with outcome-based rewards and unconstrained reasoning achieves the best overall performance, but also decreases the robustness to social influence compared to Base models. The code and datasets are available at: this https URL.</li>
</ul>

<h3>Title: Structures Meet Semantics: Multimodal Fusion via Graph Contrastive Learning</h3>
<ul>
<li><strong>Authors: </strong>Jiangfeng Sun, Sihao He, Zhonghong Ou, Meina Song</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.18322">https://arxiv.org/abs/2508.18322</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.18322">https://arxiv.org/pdf/2508.18322</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.18322]] Structures Meet Semantics: Multimodal Fusion via Graph Contrastive Learning(https://arxiv.org/abs/2508.18322)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, interpretability</a></li>
<li><strong>Abstract: </strong>Multimodal sentiment analysis (MSA) aims to infer emotional states by effectively integrating textual, acoustic, and visual modalities. Despite notable progress, existing multimodal fusion methods often neglect modality-specific structural dependencies and semantic misalignment, limiting their quality, interpretability, and robustness. To address these challenges, we propose a novel framework called the Structural-Semantic Unifier (SSU), which systematically integrates modality-specific structural information and cross-modal semantic grounding for enhanced multimodal representations. Specifically, SSU dynamically constructs modality-specific graphs by leveraging linguistic syntax for text and a lightweight, text-guided attention mechanism for acoustic and visual modalities, thus capturing detailed intra-modal relationships and semantic interactions. We further introduce a semantic anchor, derived from global textual semantics, that serves as a cross-modal alignment hub, effectively harmonizing heterogeneous semantic spaces across modalities. Additionally, we develop a multiview contrastive learning objective that promotes discriminability, semantic consistency, and structural coherence across intra- and inter-modal views. Extensive evaluations on two widely used benchmark datasets, CMU-MOSI and CMU-MOSEI, demonstrate that SSU consistently achieves state-of-the-art performance while significantly reducing computational overhead compared to prior methods. Comprehensive qualitative analyses further validate SSU's interpretability and its ability to capture nuanced emotional patterns through semantically grounded interactions.</li>
</ul>

<h3>Title: Not All Visitors are Bilingual: A Measurement Study of the Multilingual Web from an Accessibility Perspective</h3>
<ul>
<li><strong>Authors: </strong>Masudul Hasan Masud Bhuiyan, Matteo Varvello, Yasir Zaki, Cristian-Alexandru Staicu</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.CY, cs.NI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.18328">https://arxiv.org/abs/2508.18328</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.18328">https://arxiv.org/pdf/2508.18328</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.18328]] Not All Visitors are Bilingual: A Measurement Study of the Multilingual Web from an Accessibility Perspective(https://arxiv.org/abs/2508.18328)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>English is the predominant language on the web, powering nearly half of the world's top ten million websites. Support for multilingual content is nevertheless growing, with many websites increasingly combining English with regional or native languages in both visible content and hidden metadata. This multilingualism introduces significant barriers for users with visual impairments, as assistive technologies like screen readers frequently lack robust support for non-Latin scripts and misrender or mispronounce non-English text, compounding accessibility challenges across diverse linguistic contexts. Yet, large-scale studies of this issue have been limited by the lack of comprehensive datasets on multilingual web content. To address this gap, we introduce LangCrUX, the first large-scale dataset of 120,000 popular websites across 12 languages that primarily use non-Latin scripts. Leveraging this dataset, we conduct a systematic analysis of multilingual web accessibility and uncover widespread neglect of accessibility hints. We find that these hints often fail to reflect the language diversity of visible content, reducing the effectiveness of screen readers and limiting web accessibility. We finally propose Kizuki, a language-aware automated accessibility testing extension to account for the limited utility of language-inconsistent accessibility hints.</li>
</ul>

<h3>Title: DualSparse-MoE: Coordinating Tensor/Neuron-Level Sparsity with Expert Partition and Reconstruction</h3>
<ul>
<li><strong>Authors: </strong>Weilin Cai, Le Qin, Shwai He, Junwei Cui, Ang Li, Jiayi Huang</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.DC</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.18376">https://arxiv.org/abs/2508.18376</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.18376">https://arxiv.org/pdf/2508.18376</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.18376]] DualSparse-MoE: Coordinating Tensor/Neuron-Level Sparsity with Expert Partition and Reconstruction(https://arxiv.org/abs/2508.18376)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Mixture of Experts (MoE) has become a mainstream architecture for building Large Language Models (LLMs) by reducing per-token computation while enabling model scaling. It can be viewed as partitioning a large Feed-Forward Network (FFN) at the tensor level into fine-grained sub-FFNs, or experts, and activating only a sparse subset for each input. While this sparsity improves efficiency, MoE still faces substantial challenges due to their massive computational scale and unpredictable activation patterns. To enable efficient MoE deployment, we identify dual sparsity at the tensor and neuron levels in pre-trained MoE modules as a key factor for both accuracy and efficiency. Unlike prior work that increases tensor-level sparsity through finer-grained expert design during pre-training, we introduce post-training expert partitioning to induce such sparsity without retraining. This preserves the mathematical consistency of model transformations and enhances both efficiency and accuracy in subsequent fine-tuning and inference. Building upon this, we propose DualSparse-MoE, an inference system that integrates dynamic tensor-level computation dropping with static neuron-level reconstruction to deliver significant efficiency gains with minimal accuracy loss. Experimental results show that enforcing an approximate 25% drop rate with our approach reduces average accuracy by only 0.08%-0.28% across three prevailing MoE models, while nearly all degrees of computation dropping consistently yield proportional computational speedups. Furthermore, incorporating load-imbalance awareness into expert parallelism achieves a 1.41x MoE module speedup with just 0.5% average accuracy degradation.</li>
</ul>

<h3>Title: Backprompting: Leveraging Synthetic Production Data for Health Advice Guardrails</h3>
<ul>
<li><strong>Authors: </strong>Kellen Tan Cheng, Anna Lisa Gentile, Chad DeLuca, Guang-Jie Ren</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.18384">https://arxiv.org/abs/2508.18384</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.18384">https://arxiv.org/pdf/2508.18384</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.18384]] Backprompting: Leveraging Synthetic Production Data for Health Advice Guardrails(https://arxiv.org/abs/2508.18384)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, large language model</a></li>
<li><strong>Abstract: </strong>The pervasiveness of large language models (LLMs) in enterprise settings has also brought forth a significant amount of risks associated with their usage. Guardrails technologies aim to mitigate this risk by filtering LLMs' input/output text through various detectors. However, developing and maintaining robust detectors faces many challenges, one of which is the difficulty in acquiring production-quality labeled data on real LLM outputs prior to deployment. In this work, we propose backprompting, a simple yet intuitive solution to generate production-like labeled data for health advice guardrails development. Furthermore, we pair our backprompting method with a sparse human-in-the-loop clustering technique to label the generated data. Our aim is to construct a parallel corpus roughly representative of the original dataset yet resembling real LLM output. We then infuse existing datasets with our synthetic examples to produce robust training data for our detector. We test our technique in one of the most difficult and nuanced guardrails: the identification of health advice in LLM output, and demonstrate improvement versus other solutions. Our detector is able to outperform GPT-4o by up to 3.73%, despite having 400x less parameters.</li>
</ul>

<h3>Title: Integral Transformer: Denoising Attention, Not Too Much Not Too Little</h3>
<ul>
<li><strong>Authors: </strong>Ivan Kobyzev, Abbas Ghaddar, Dingtao Hu, Boxing Chen</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.18387">https://arxiv.org/abs/2508.18387</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.18387">https://arxiv.org/pdf/2508.18387</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.18387]] Integral Transformer: Denoising Attention, Not Too Much Not Too Little(https://arxiv.org/abs/2508.18387)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Softmax self-attention often assigns disproportionate weight to semantically uninformative tokens such as special tokens and punctuation, a phenomenon known as attention noise. While recent methods like Cog Attention and the Differential Transformer have addressed this by introducing negative attention scores, they risk discarding useful information. In this paper, we propose the Integral Transformer, a novel self-attention mechanism that denoises attention by integrating signals sampled from the logit distribution. Our approach mitigates noise while preserving the contributions of special tokens critical for model performance. Extensive experiments demonstrate that our model outperforms vanilla, Cog, and Differential attention variants on well-established knowledge and reasoning language benchmarks. Moreover, our analysis reveals that employing vanilla self-attention in the lower Transformer layers enhances performance and that the Integral Transformer effectively balances attention distributions and reduces rank collapse in upper layers.</li>
</ul>

<h3>Title: FastAvatar: Instant 3D Gaussian Splatting for Faces from Single Unconstrained Poses</h3>
<ul>
<li><strong>Authors: </strong>Hao Liang, Zhixuan Ge, Ashish Tiwari, Soumendu Majee, G.M. Dilshan Godaliyadda, Ashok Veeraraghavan, Guha Balakrishnan</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.18389">https://arxiv.org/abs/2508.18389</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.18389">https://arxiv.org/pdf/2508.18389</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.18389]] FastAvatar: Instant 3D Gaussian Splatting for Faces from Single Unconstrained Poses(https://arxiv.org/abs/2508.18389)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>We present FastAvatar, a pose-invariant, feed-forward framework that can generate a 3D Gaussian Splatting (3DGS) model from a single face image from an arbitrary pose in near-instant time (<10ms). FastAvatar uses a novel encoder-decoder neural network design to achieve both fast fitting and identity preservation regardless of input pose. First, FastAvatar constructs a 3DGS face ``template'' model from a training dataset of faces with multi-view captures. Second, FastAvatar encodes the input face image into an identity-specific and pose-invariant latent embedding, and decodes this embedding to predict residuals to the structural and appearance parameters of each Gaussian in the template 3DGS model. By only inferring residuals in a feed-forward fashion, model inference is fast and robust. FastAvatar significantly outperforms existing feed-forward face 3DGS methods (e.g., GAGAvatar) in reconstruction quality, and runs 1000x faster than per-face optimization methods (e.g., FlashAvatar, GaussianAvatars and GASP). In addition, FastAvatar's novel latent space design supports real-time identity interpolation and attribute editing which is not possible with any existing feed-forward 3DGS face generation framework. FastAvatar's combination of excellent reconstruction quality and speed expands the scope of 3DGS for photorealistic avatar applications in consumer and interactive systems.</li>
</ul>

<h3>Title: Latent Self-Consistency for Reliable Majority-Set Selection in Short- and Long-Answer Reasoning</h3>
<ul>
<li><strong>Authors: </strong>Jeong-seok Oh, Jay-yoon Lee</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.18395">https://arxiv.org/abs/2508.18395</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.18395">https://arxiv.org/pdf/2508.18395</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.18395]] Latent Self-Consistency for Reliable Majority-Set Selection in Short- and Long-Answer Reasoning(https://arxiv.org/abs/2508.18395)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Probabilistic decoding in Large Language Models (LLMs) often yields inconsistent outputs, particularly on complex or long-form questions. Self-Consistency (SC) mitigates this for short-form QA by majority voting over exact strings, whereas Universal Self-Consistency (USC) and Weighted Unigram Consistency Score (WUCS) extend to long-form responses but lose accuracy on short-form benchmarks. We introduce Latent Self-Consistency (LSC), which selects the most semantically consistent response using learnable token embeddings. A lightweight forward generation of summary tokens increases inference time by less than 1% and requires no changes to the model architecture. Across 6 short-form and 5 long-form reasoning benchmarks (e.g., MATH, MMLU, TruthfulQA), LSC surpasses SC, USC and WUCS on all short-form and long-form ones on average, while maintaining negligible computational overhead. These results position LSC as a practical consistency-selection method that works reliably across answer formats. Additionally, LSC provides well-calibrated confidence estimates, maintaining low Expected Calibration Error across both answer formats.</li>
</ul>

<h3>Title: Can Out-of-Distribution Evaluations Uncover Reliance on Shortcuts? A Case Study in Question Answering</h3>
<ul>
<li><strong>Authors: </strong>Michal Å tefÃ¡nik, Timothee Mickus, Marek KadlÄÃ­k, Michal Spiegel, Josef KuchaÅ</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.18407">https://arxiv.org/abs/2508.18407</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.18407">https://arxiv.org/pdf/2508.18407</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.18407]] Can Out-of-Distribution Evaluations Uncover Reliance on Shortcuts? A Case Study in Question Answering(https://arxiv.org/abs/2508.18407)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>A majority of recent work in AI assesses models' generalization capabilities through the lens of performance on out-of-distribution (OOD) datasets. Despite their practicality, such evaluations build upon a strong assumption: that OOD evaluations can capture and reflect upon possible failures in a real-world deployment. In this work, we challenge this assumption and confront the results obtained from OOD evaluations with a set of specific failure modes documented in existing question-answering (QA) models, referred to as a reliance on spurious features or prediction shortcuts. We find that different datasets used for OOD evaluations in QA provide an estimate of models' robustness to shortcuts that have a vastly different quality, some largely under-performing even a simple, in-distribution evaluation. We partially attribute this to the observation that spurious shortcuts are shared across ID+OOD datasets, but also find cases where a dataset's quality for training and evaluation is largely disconnected. Our work underlines limitations of commonly-used OOD-based evaluations of generalization, and provides methodology and recommendations for evaluating generalization within and beyond QA more robustly.</li>
</ul>

<h3>Title: Securing Face and Fingerprint Templates in Humanitarian Biometric Systems</h3>
<ul>
<li><strong>Authors: </strong>Giuseppe Stragapede, Sam Merrick, Vedrana KrivokuÄa Hahn, Justin Sukaitis, Vincent Graf Narbel</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.18415">https://arxiv.org/abs/2508.18415</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.18415">https://arxiv.org/pdf/2508.18415</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.18415]] Securing Face and Fingerprint Templates in Humanitarian Biometric Systems(https://arxiv.org/abs/2508.18415)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, privacy, protect, biometric</a></li>
<li><strong>Abstract: </strong>In humanitarian and emergency scenarios, the use of biometrics can dramatically improve the efficiency of operations, but it poses risks for the data subjects, which are exacerbated in contexts of vulnerability. To address this, we present a mobile biometric system implementing a biometric template protection (BTP) scheme suitable for these scenarios. After rigorously formulating the functional, operational, and security and privacy requirements of these contexts, we perform a broad comparative analysis of the BTP landscape. PolyProtect, a method designed to operate on neural network face embeddings, is identified as the most suitable method due to its effectiveness, modularity, and lightweight computational burden. We evaluate PolyProtect in terms of verification and identification accuracy, irreversibility, and unlinkability, when this BTP method is applied to face embeddings extracted using EdgeFace, a novel state-of-the-art efficient feature extractor, on a real-world face dataset from a humanitarian field project in Ethiopia. Moreover, as PolyProtect promises to be modality-independent, we extend its evaluation to fingerprints. To the best of our knowledge, this is the first time that PolyProtect has been evaluated for the identification scenario and for fingerprint biometrics. Our experimental results are promising, and we plan to release our code</li>
</ul>

<h3>Title: LLM-Driven Intrinsic Motivation for Sparse Reward Reinforcement Learning</h3>
<ul>
<li><strong>Authors: </strong>AndrÃ© Quadros, Cassio Silva, Ronnie Alves</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.18420">https://arxiv.org/abs/2508.18420</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.18420">https://arxiv.org/pdf/2508.18420</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.18420]] LLM-Driven Intrinsic Motivation for Sparse Reward Reinforcement Learning(https://arxiv.org/abs/2508.18420)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>This paper explores the combination of two intrinsic motivation strategies to improve the efficiency of reinforcement learning (RL) agents in environments with extreme sparse rewards, where traditional learning struggles due to infrequent positive feedback. We propose integrating Variational State as Intrinsic Reward (VSIMR), which uses Variational AutoEncoders (VAEs) to reward state novelty, with an intrinsic reward approach derived from Large Language Models (LLMs). The LLMs leverage their pre-trained knowledge to generate reward signals based on environment and goal descriptions, guiding the agent. We implemented this combined approach with an Actor-Critic (A2C) agent in the MiniGrid DoorKey environment, a benchmark for sparse rewards. Our empirical results show that this combined strategy significantly increases agent performance and sampling efficiency compared to using each strategy individually or a standard A2C agent, which failed to learn. Analysis of learning curves indicates that the combination effectively complements different aspects of the environment and task: VSIMR drives exploration of new states, while the LLM-derived rewards facilitate progressive exploitation towards goals.</li>
</ul>

<h3>Title: Why Relational Graphs Will Save the Next Generation of Vision Foundation Models?</h3>
<ul>
<li><strong>Authors: </strong>Fatemeh Ziaeetabar</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.18421">https://arxiv.org/abs/2508.18421</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.18421">https://arxiv.org/pdf/2508.18421</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.18421]] Why Relational Graphs Will Save the Next Generation of Vision Foundation Models?(https://arxiv.org/abs/2508.18421)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, interpretability, segmentation</a></li>
<li><strong>Abstract: </strong>Vision foundation models (FMs) have become the predominant architecture in computer vision, providing highly transferable representations learned from large-scale, multimodal corpora. Nonetheless, they exhibit persistent limitations on tasks that require explicit reasoning over entities, roles, and spatio-temporal relations. Such relational competence is indispensable for fine-grained human activity recognition, egocentric video understanding, and multimodal medical image analysis, where spatial, temporal, and semantic dependencies are decisive for performance. We advance the position that next-generation FMs should incorporate explicit relational interfaces, instantiated as dynamic relational graphs (graphs whose topology and edge semantics are inferred from the input and task context). We illustrate this position with cross-domain evidence from recent systems in human manipulation action recognition and brain tumor segmentation, showing that augmenting FMs with lightweight, context-adaptive graph-reasoning modules improves fine-grained semantic fidelity, out of distribution robustness, interpretability, and computational efficiency relative to FM only baselines. Importantly, by reasoning sparsely over semantic nodes, such hybrids also achieve favorable memory and hardware efficiency, enabling deployment under practical resource constraints. We conclude with a targeted research agenda for FM graph hybrids, prioritizing learned dynamic graph construction, multi-level relational reasoning (e.g., part object scene in activity understanding, or region organ in medical imaging), cross-modal fusion, and evaluation protocols that directly probe relational competence in structured vision tasks.</li>
</ul>

<h3>Title: A Systematic Approach to Predict the Impact of Cybersecurity Vulnerabilities Using LLMs</h3>
<ul>
<li><strong>Authors: </strong>Anders MÃ¸lmen HÃ¸st, Pierre Lison, Leon Moonen</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.AI, cs.CL, cs.SE</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.18439">https://arxiv.org/abs/2508.18439</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.18439">https://arxiv.org/pdf/2508.18439</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.18439]] A Systematic Approach to Predict the Impact of Cybersecurity Vulnerabilities Using LLMs(https://arxiv.org/abs/2508.18439)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, large language model</a></li>
<li><strong>Abstract: </strong>Vulnerability databases, such as the National Vulnerability Database (NVD), offer detailed descriptions of Common Vulnerabilities and Exposures (CVEs), but often lack information on their real-world impact, such as the tactics, techniques, and procedures (TTPs) that adversaries may use to exploit the vulnerability. However, manually linking CVEs to their corresponding TTPs is a challenging and time-consuming task, and the high volume of new vulnerabilities published annually makes automated support desirable. This paper introduces TRIAGE, a two-pronged automated approach that uses Large Language Models (LLMs) to map CVEs to relevant techniques from the ATT&CK knowledge base. We first prompt an LLM with instructions based on MITRE's CVE Mapping Methodology to predict an initial list of techniques. This list is then combined with the results from a second LLM-based module that uses in-context learning to map a CVE to relevant techniques. This hybrid approach strategically combines rule-based reasoning with data-driven inference. Our evaluation reveals that in-context learning outperforms the individual mapping methods, and the hybrid approach improves recall of exploitation techniques. We also find that GPT-4o-mini performs better than Llama3.3-70B on this task. Overall, our results show that LLMs can be used to automatically predict the impact of cybersecurity vulnerabilities and TRIAGE makes the process of mapping CVEs to ATT&CK more efficient. Keywords: vulnerability impact, CVE, ATT&CK techniques, large language models, automated mapping.</li>
</ul>

<h3>Title: How Reliable are LLMs for Reasoning on the Re-ranking task?</h3>
<ul>
<li><strong>Authors: </strong>Nafis Tanveer Islam, Zhiming Zhao</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.18444">https://arxiv.org/abs/2508.18444</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.18444">https://arxiv.org/pdf/2508.18444</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.18444]] How Reliable are LLMs for Reasoning on the Re-ranking task?(https://arxiv.org/abs/2508.18444)</code><input type="text"></li>
<li><strong>Keywords: </strong>explainability, large language model</a></li>
<li><strong>Abstract: </strong>With the improving semantic understanding capability of Large Language Models (LLMs), they exhibit a greater awareness and alignment with human values, but this comes at the cost of transparency. Although promising results are achieved via experimental analysis, an in-depth understanding of the LLM's internal workings is unavoidable to comprehend the reasoning behind the re-ranking, which provides end users with an explanation that enables them to make an informed decision. Moreover, in newly developed systems with limited user engagement and insufficient ranking data, accurately re-ranking content remains a significant challenge. While various training methods affect the training of LLMs and generate inference, our analysis has found that some training methods exhibit better explainability than others, implying that an accurate semantic understanding has not been learned through all training methods; instead, abstract knowledge has been gained to optimize evaluation, which raises questions about the true reliability of LLMs. Therefore, in this work, we analyze how different training methods affect the semantic understanding of the re-ranking task in LLMs and investigate whether these models can generate more informed textual reasoning to overcome the challenges of transparency or LLMs and limited training data. To analyze the LLMs for re-ranking tasks, we utilize a relatively small ranking dataset from the environment and the Earth science domain to re-rank retrieved content. Furthermore, we also analyze the explainable information to see if the re-ranking can be reasoned using explainability.</li>
</ul>

<h3>Title: Privacy-Preserving Federated Learning Framework for Risk-Based Adaptive Authentication</h3>
<ul>
<li><strong>Authors: </strong>Yaser Baseri, Abdelhakim Senhaji Hafid, Dimitrios Makrakis, Hamidreza Fereidouni</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.18453">https://arxiv.org/abs/2508.18453</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.18453">https://arxiv.org/pdf/2508.18453</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.18453]] Privacy-Preserving Federated Learning Framework for Risk-Based Adaptive Authentication(https://arxiv.org/abs/2508.18453)</code><input type="text"></li>
<li><strong>Keywords: </strong>secure, security, privacy, attack, robust, biometric, federate</a></li>
<li><strong>Abstract: </strong>Balancing robust security with strong privacy guarantees is critical for Risk-Based Adaptive Authentication (RBA), particularly in decentralized settings. Federated Learning (FL) offers a promising solution by enabling collaborative risk assessment without centralizing user data. However, existing FL approaches struggle with Non-Independent and Identically Distributed (Non-IID) user features, resulting in biased, unstable, and poorly generalized global models. This paper introduces FL-RBA2, a novel Federated Learning framework for Risk-Based Adaptive Authentication that addresses Non-IID challenges through a mathematically grounded similarity transformation. By converting heterogeneous user features (including behavioral, biometric, contextual, interaction-based, and knowledge-based modalities) into IID similarity vectors, FL-RBA2 supports unbiased aggregation and personalized risk modeling across distributed clients. The framework mitigates cold-start limitations via clustering-based risk labeling, incorporates Differential Privacy (DP) to safeguard sensitive information, and employs Message Authentication Codes (MACs) to ensure model integrity and authenticity. Federated updates are securely aggregated into a global model, achieving strong balance between user privacy, scalability, and adaptive authentication robustness. Rigorous game-based security proofs in the Random Oracle Model formally establish privacy, correctness, and adaptive security guarantees. Extensive experiments on keystroke, mouse, and contextual datasets validate FL-RBA2's effectiveness in high-risk user detection and its resilience to model inversion and inference attacks, even under strong DP constraints.</li>
</ul>

<h3>Title: VERIRL: Boosting the LLM-based Verilog Code Generation via Reinforcement Learning</h3>
<ul>
<li><strong>Authors: </strong>Fu Teng, Miao Pan, Xuhong Zhang, Zhezhi He, Yiyao Yang, Xinyi Chai, Mengnan Qi, Liqiang Lu, Jianwei Yin</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.18462">https://arxiv.org/abs/2508.18462</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.18462">https://arxiv.org/pdf/2508.18462</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.18462]] VERIRL: Boosting the LLM-based Verilog Code Generation via Reinforcement Learning(https://arxiv.org/abs/2508.18462)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Recent advancements in code generation have shown remarkable success across software domains, yet hardware description languages (HDLs) such as Verilog remain underexplored due to their concurrency semantics, syntactic rigidity, and simulation complexity. In this work, we address these challenges by introducing a reinforcement learning (RL) framework tailored for Verilog code generation. We first construct Veribench-53K, a high-quality dataset curated from over 700K Verilog problems, enriched with structured prompts, complexity labels, and diverse testbenches. To tackle the problem of sparse and noisy reward signals, we propose a Trace-back based Rescore mechanism that leverages reasoning paths and iterative refinement to enhance feedback reliability and support reward model training. Furthermore, to mitigate catastrophic forgetting and overfitting during RL fine-tuning, we introduce a sample-balanced weighting strategy that adaptively balances learning dynamics based on reward-probability distributions. These innovations are integrated into an iterative RL pipeline that co-evolves the policy and reward models. In contrast to recent work such as CraftRTL, which relies on large-scale closed-source model distillation, and DeepSeek-style approaches that struggle with sparse feedback, our method demonstrates superior performance using a smaller but high-quality dataset combined with RL optimization. Experiments on Verilog generation tasks demonstrate state-of-the-art performance, with substantial gains in test pass rate, functional correctness, and compilation robustness. Our findings highlight the potential of RL-driven approaches for structured code generation in hardware-centric domains. VERIRL is publicly available at this https URL.</li>
</ul>

<h3>Title: Integrating gender inclusivity into large language models via instruction tuning</h3>
<ul>
<li><strong>Authors: </strong>Alina WrÃ³blewska, Bartosz Å»uk</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.18466">https://arxiv.org/abs/2508.18466</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.18466">https://arxiv.org/pdf/2508.18466</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.18466]] Integrating gender inclusivity into large language models via instruction tuning(https://arxiv.org/abs/2508.18466)</code><input type="text"></li>
<li><strong>Keywords: </strong>fair, large language model</a></li>
<li><strong>Abstract: </strong>Imagine a language with masculine, feminine, and neuter grammatical genders, yet, due to historical and political conventions, masculine forms are predominantly used to refer to men, women and mixed-gender groups. This is the reality of contemporary Polish. A social consequence of this unfair linguistic system is that large language models (LLMs) trained on Polish texts inherit and reinforce this masculine bias, generating gender-imbalanced outputs. This study addresses this issue by tuning LLMs using the IPIS dataset, a collection of human-crafted gender-inclusive proofreading in Polish and Polish-to-English translation instructions. Grounded in a theoretical linguistic framework, we design a system prompt with explicit gender-inclusive guidelines for Polish. In our experiments, we IPIS-tune multilingual LLMs (Llama-8B, Mistral-7B and Mistral-Nemo) and Polish-specific LLMs (Bielik and PLLuM). Our approach aims to integrate gender inclusivity as an inherent feature of these models, offering a systematic solution to mitigate gender bias in Polish language generation.</li>
</ul>

<h3>Title: Principled Detection of Hallucinations in Large Language Models via Multiple Testing</h3>
<ul>
<li><strong>Authors: </strong>Jiawei Li, Akshayaa Magesh, Venugopal V. Veeravalli</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.18473">https://arxiv.org/abs/2508.18473</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.18473">https://arxiv.org/pdf/2508.18473</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.18473]] Principled Detection of Hallucinations in Large Language Models via Multiple Testing(https://arxiv.org/abs/2508.18473)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, large language model</a></li>
<li><strong>Abstract: </strong>While Large Language Models (LLMs) have emerged as powerful foundational models to solve a variety of tasks, they have also been shown to be prone to hallucinations, i.e., generating responses that sound confident but are actually incorrect or even nonsensical. In this work, we formulate the problem of detecting hallucinations as a hypothesis testing problem and draw parallels to the problem of out-of-distribution detection in machine learning models. We propose a multiple-testing-inspired method to solve the hallucination detection problem, and provide extensive experimental results to validate the robustness of our approach against state-of-the-art methods.</li>
</ul>

<h3>Title: Collaborative Intelligence: Topic Modelling of Large Language Model use in Live Cybersecurity Operations</h3>
<ul>
<li><strong>Authors: </strong>Martin Lochner, Keegan Keplinger</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.18488">https://arxiv.org/abs/2508.18488</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.18488">https://arxiv.org/pdf/2508.18488</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.18488]] Collaborative Intelligence: Topic Modelling of Large Language Model use in Live Cybersecurity Operations(https://arxiv.org/abs/2508.18488)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, transformer, large language model</a></li>
<li><strong>Abstract: </strong>Objective: This work describes the topic modelling of Security Operations Centre (SOC) use of a large language model (LLM), during live security operations. The goal is to better understand how these specialists voluntarily use this tool. Background: Human-automation teams have been extensively studied, but transformer-based language models have sparked a new wave of collaboration. SOC personnel at a major cybersecurity provider used an LLM to support live security operations. This study examines how these specialists incorporated the LLM into their work. Method: Our data set is the result of 10 months of SOC operators accessing GPT-4 over an internally deployed HTTP-based chat application. We performed two topic modelling exercises, first using the established BERTopic model (Grootendorst, 2022), and second, using a novel topic modeling workflow. Results: Both the BERTopic analysis and novel modelling approach revealed that SOC operators primarily used the LLM to facilitate their understanding of complex text strings. Variations on this use-case accounted for ~40% of SOC LLM usage. Conclusion: SOC operators are required to rapidly interpret complex commands and similar information. Their natural tendency to leverage LLMs to support this activity indicates that their workflow can be supported and augmented by designing collaborative LLM tools for use in the SOC. Application: This work can aid in creating next-generation tools for Security Operations Centres. By understanding common use-cases, we can develop workflows supporting SOC task flow. One example is a right-click context menu for executing a command line analysis LLM call directly in the SOC environment.</li>
</ul>

<h3>Title: Data Augmentation Improves Machine Unlearning</h3>
<ul>
<li><strong>Authors: </strong>Andreza M. C. Falcao, Filipe R. Cordeiro</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.18502">https://arxiv.org/abs/2508.18502</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.18502">https://arxiv.org/pdf/2508.18502</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.18502]] Data Augmentation Improves Machine Unlearning(https://arxiv.org/abs/2508.18502)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy</a></li>
<li><strong>Abstract: </strong>Machine Unlearning (MU) aims to remove the influence of specific data from a trained model while preserving its performance on the remaining data. Although a few works suggest connections between memorisation and augmentation, the role of systematic augmentation design in MU remains under-investigated. In this work, we investigate the impact of different data augmentation strategies on the performance of unlearning methods, including SalUn, Random Label, and Fine-Tuning. Experiments conducted on CIFAR-10 and CIFAR-100, under varying forget rates, show that proper augmentation design can significantly improve unlearning effectiveness, reducing the performance gap to retrained models. Results showed a reduction of up to 40.12% of the Average Gap unlearning Metric, when using TrivialAug augmentation. Our results suggest that augmentation not only helps reduce memorization but also plays a crucial role in achieving privacy-preserving and efficient unlearning.</li>
</ul>

<h3>Title: DoGFlow: Self-Supervised LiDAR Scene Flow via Cross-Modal Doppler Guidance</h3>
<ul>
<li><strong>Authors: </strong>Ajinkya Khoche, Qingwen Zhang, Yixi Cai, Sina Sharif Mansouri, Patric Jensfelt</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.18506">https://arxiv.org/abs/2508.18506</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.18506">https://arxiv.org/pdf/2508.18506</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.18506]] DoGFlow: Self-Supervised LiDAR Scene Flow via Cross-Modal Doppler Guidance(https://arxiv.org/abs/2508.18506)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Accurate 3D scene flow estimation is critical for autonomous systems to navigate dynamic environments safely, but creating the necessary large-scale, manually annotated datasets remains a significant bottleneck for developing robust perception models. Current self-supervised methods struggle to match the performance of fully supervised approaches, especially in challenging long-range and adverse weather scenarios, while supervised methods are not scalable due to their reliance on expensive human labeling. We introduce DoGFlow, a novel self-supervised framework that recovers full 3D object motions for LiDAR scene flow estimation without requiring any manual ground truth annotations. This paper presents our cross-modal label transfer approach, where DoGFlow computes motion pseudo-labels in real-time directly from 4D radar Doppler measurements and transfers them to the LiDAR domain using dynamic-aware association and ambiguity-resolved propagation. On the challenging MAN TruckScenes dataset, DoGFlow substantially outperforms existing self-supervised methods and improves label efficiency by enabling LiDAR backbones to achieve over 90% of fully supervised performance with only 10% of the ground truth data. For more details, please visit this https URL</li>
</ul>

<h3>Title: Analise de Desaprendizado de Maquina em Modelos de Classificacao de Imagens Medicas</h3>
<ul>
<li><strong>Authors: </strong>Andreza M. C. Falcao, Filipe R. Cordeiro</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.18509">https://arxiv.org/abs/2508.18509</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.18509">https://arxiv.org/pdf/2508.18509</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.18509]] Analise de Desaprendizado de Maquina em Modelos de Classificacao de Imagens Medicas(https://arxiv.org/abs/2508.18509)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Machine unlearning aims to remove private or sensitive data from a pre-trained model while preserving the model's robustness. Despite recent advances, this technique has not been explored in medical image classification. This work evaluates the SalUn unlearning model by conducting experiments on the PathMNIST, OrganAMNIST, and BloodMNIST datasets. We also analyse the impact of data augmentation on the quality of unlearning. Results show that SalUn achieves performance close to full retraining, indicating an efficient solution for use in medical applications.</li>
</ul>

<h3>Title: Breaking Through Barren Plateaus: Reinforcement Learning Initializations for Deep Variational Quantum Circuits</h3>
<ul>
<li><strong>Authors: </strong>Yifeng Peng, Xinyi Li, Zhemin Zhang, Samuel Yen-Chi Chen, Zhiding Liang, Ying Wang</a></li>
<li><strong>Subjects: </strong>cs.LG, quant-ph</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.18514">https://arxiv.org/abs/2508.18514</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.18514">https://arxiv.org/pdf/2508.18514</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.18514]] Breaking Through Barren Plateaus: Reinforcement Learning Initializations for Deep Variational Quantum Circuits(https://arxiv.org/abs/2508.18514)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Variational Quantum Algorithms (VQAs) have gained prominence as a viable framework for exploiting near-term quantum devices in applications ranging from optimization and chemistry simulation to machine learning. However, the effectiveness of VQAs is often constrained by the so-called barren plateau problem, wherein gradients diminish exponentially as system size or circuit depth increases, thereby hindering training. In this work, we propose a reinforcement learning (RL)-based initialization strategy to alleviate the barren plateau issue by reshaping the initial parameter landscape to avoid regions prone to vanishing gradients. In particular, we explore several RL algorithms (Deterministic Policy Gradient, Soft Actor-Critic, and Proximal Policy Optimization, etc.) to generate the circuit parameters (treated as actions) that minimize the VQAs cost function before standard gradient-based optimization. By pre-training with RL in this manner, subsequent optimization using methods such as gradient descent or Adam proceeds from a more favorable initial state. Extensive numerical experiments under various noise conditions and tasks consistently demonstrate that the RL-based initialization method significantly enhances both convergence speed and final solution quality. Moreover, comparisons among different RL algorithms highlight that multiple approaches can achieve comparable performance gains, underscoring the flexibility and robustness of our method. These findings shed light on a promising avenue for integrating machine learning techniques into quantum algorithm design, offering insights into how RL-driven parameter initialization can accelerate the scalability and practical deployment of VQAs. Opening up a promising path for the research community in machine learning for quantum, especially barren plateau problems in VQAs.</li>
</ul>

<h3>Title: Adaptive Visual Navigation Assistant in 3D RPGs</h3>
<ul>
<li><strong>Authors: </strong>Kaijie Xu, Clark Verbrugge</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.18539">https://arxiv.org/abs/2508.18539</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.18539">https://arxiv.org/pdf/2508.18539</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.18539]] Adaptive Visual Navigation Assistant in 3D RPGs(https://arxiv.org/abs/2508.18539)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>In complex 3D game environments, players rely on visual affordances to spot map transition points. Efficient identification of such points is important to client-side auto-mapping, and provides an objective basis for evaluating map cue presentation. In this work, we formalize the task of detecting traversable Spatial Transition Points (STPs)-connectors between two sub regions-and selecting the singular Main STP (MSTP), the unique STP that lies on the designer-intended critical path toward the player's current macro-objective, from a single game frame, proposing this as a new research focus. We introduce a two-stage deep-learning pipeline that first detects potential STPs using Faster R-CNN and then ranks them with a lightweight MSTP selector that fuses local and global visual features. Both stages benefit from parameter-efficient adapters, and we further introduce an optional retrieval-augmented fusion step. Our primary goal is to establish the feasibility of this problem and set baseline performance metrics. We validate our approach on a custom-built, diverse dataset collected from five Action RPG titles. Our experiments reveal a key trade-off: while full-network fine-tuning produces superior STP detection with sufficient data, adapter-only transfer is significantly more robust and effective in low-data scenarios and for the MSTP selection task. By defining this novel problem, providing a baseline pipeline and dataset, and offering initial insights into efficient model adaptation, we aim to contribute to future AI-driven navigation aids and data-informed level-design tools.</li>
</ul>

<h3>Title: Enhancing Chemical Explainability Through Counterfactual Masking</h3>
<ul>
<li><strong>Authors: </strong>Åukasz JanisiÃ³w, Marek KochaÅczyk, Bartosz ZieliÅski, Tomasz Danel</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.18561">https://arxiv.org/abs/2508.18561</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.18561">https://arxiv.org/pdf/2508.18561</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.18561]] Enhancing Chemical Explainability Through Counterfactual Masking(https://arxiv.org/abs/2508.18561)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, explainability, generative</a></li>
<li><strong>Abstract: </strong>Molecular property prediction is a crucial task that guides the design of new compounds, including drugs and materials. While explainable artificial intelligence methods aim to scrutinize model predictions by identifying influential molecular substructures, many existing approaches rely on masking strategies that remove either atoms or atom-level features to assess importance via fidelity metrics. These methods, however, often fail to adhere to the underlying molecular distribution and thus yield unintuitive explanations. In this work, we propose counterfactual masking, a novel framework that replaces masked substructures with chemically reasonable fragments sampled from generative models trained to complete molecular graphs. Rather than evaluating masked predictions against implausible zeroed-out baselines, we assess them relative to counterfactual molecules drawn from the data distribution. Our method offers two key benefits: (1) molecular realism underpinning robust and distribution-consistent explanations, and (2) meaningful counterfactuals that directly indicate how structural modifications may affect predicted properties. We demonstrate that counterfactual masking is well-suited for benchmarking model explainers and yields more actionable insights across multiple datasets and property prediction tasks. Our approach bridges the gap between explainability and molecular design, offering a principled and generative path toward explainable machine learning in chemistry.</li>
</ul>

<h3>Title: A Note on Graphon-Signal Analysis of Graph Neural Networks</h3>
<ul>
<li><strong>Authors: </strong>Levi Rauchwerger, Ron Levie</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.18564">https://arxiv.org/abs/2508.18564</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.18564">https://arxiv.org/pdf/2508.18564</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.18564]] A Note on Graphon-Signal Analysis of Graph Neural Networks(https://arxiv.org/abs/2508.18564)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>A recent paper, ``A Graphon-Signal Analysis of Graph Neural Networks'', by Levie, analyzed message passing graph neural networks (MPNNs) by embedding the input space of MPNNs, i.e., attributed graphs (graph-signals), to a space of attributed graphons (graphon-signals). Based on extensions of standard results in graphon analysis to graphon-signals, the paper proved a generalization bound and a sampling lemma for MPNNs. However, there are some missing ingredients in that paper, limiting its applicability in practical settings of graph machine learning. In the current paper, we introduce several refinements and extensions to existing results that address these shortcomings. In detail, 1) we extend the main results in the paper to graphon-signals with multidimensional signals (rather than 1D signals), 2) we extend the Lipschitz continuity to MPNNs with readout with respect to cut distance (rather than MPNNs without readout with respect to cut metric), 3) we improve the generalization bound by utilizing robustness-type generalization bounds, and 4) we extend the analysis to non-symmetric graphons and kernels.</li>
</ul>

<h3>Title: DrugReasoner: Interpretable Drug Approval Prediction with a Reasoning-augmented Language Model</h3>
<ul>
<li><strong>Authors: </strong>Mohammadreza Ghaffarzadeh-Esfahani, Ali Motahharynia, Nahid Yousefian, Navid Mazrouei, Jafar Ghaisari, Yousof Gheisari</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, q-bio.QM</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.18579">https://arxiv.org/abs/2508.18579</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.18579">https://arxiv.org/pdf/2508.18579</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.18579]] DrugReasoner: Interpretable Drug Approval Prediction with a Reasoning-augmented Language Model(https://arxiv.org/abs/2508.18579)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, interpretability, large language model</a></li>
<li><strong>Abstract: </strong>Drug discovery is a complex and resource-intensive process, making early prediction of approval outcomes critical for optimizing research investments. While classical machine learning and deep learning methods have shown promise in drug approval prediction, their limited interpretability constraints their impact. Here, we present DrugReasoner, a reasoning-based large language model (LLM) built on the LLaMA architecture and fine-tuned with group relative policy optimization (GRPO) to predict the likelihood of small-molecule approval. DrugReasoner integrates molecular descriptors with comparative reasoning against structurally similar approved and unapproved compounds, generating predictions alongside step-by-step rationales and confidence scores. DrugReasoner achieved robust performance with an AUC of 0.732 and an F1 score of 0.729 on the validation set and 0.725 and 0.718 on the test set, respectively. These results outperformed conventional baselines, including logistic regression, support vector machine, and k-nearest neighbors and had competitive performance relative to XGBoost. On an external independent dataset, DrugReasoner outperformed both baseline and the recently developed ChemAP model, achieving an AUC of 0.728 and an F1-score of 0.774, while maintaining high precision and balanced sensitivity, demonstrating robustness in real-world scenarios. These findings demonstrate that DrugReasoner not only delivers competitive predictive accuracy but also enhances transparency through its reasoning outputs, thereby addressing a key bottleneck in AI-assisted drug discovery. This study highlights the potential of reasoning-augmented LLMs as interpretable and effective tools for pharmaceutical decision-making.</li>
</ul>

<h3>Title: History Rhymes: Accelerating LLM Reinforcement Learning with RhymeRL</h3>
<ul>
<li><strong>Authors: </strong>Jingkai He, Tianjian Li, Erhu Feng, Dong Du, Qian Liu, Tao Liu, Yubin Xia, Haibo Chen</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.DC</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.18588">https://arxiv.org/abs/2508.18588</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.18588">https://arxiv.org/pdf/2508.18588</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.18588]] History Rhymes: Accelerating LLM Reinforcement Learning with RhymeRL(https://arxiv.org/abs/2508.18588)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>With the rapid advancement of large language models (LLMs), reinforcement learning (RL) has emerged as a pivotal methodology for enhancing the reasoning capabilities of LLMs. Unlike traditional pre-training approaches, RL encompasses multiple stages: rollout, reward, and training, which necessitates collaboration among various worker types. However, current RL systems continue to grapple with substantial GPU underutilization, due to two primary factors: (1) The rollout stage dominates the overall RL process due to test-time scaling; (2) Imbalances in rollout lengths (within the same batch) result in GPU bubbles. While prior solutions like asynchronous execution and truncation offer partial relief, they may compromise training accuracy for efficiency. Our key insight stems from a previously overlooked observation: rollout responses exhibit remarkable similarity across adjacent training epochs. Based on the insight, we introduce RhymeRL, an LLM RL system designed to accelerate RL training with two key innovations. First, to enhance rollout generation, we present HistoSpec, a speculative decoding inference engine that utilizes the similarity of historical rollout token sequences to obtain accurate drafts. Second, to tackle rollout bubbles, we introduce HistoPipe, a two-tier scheduling strategy that leverages the similarity of historical rollout distributions to balance workload among rollout workers. We have evaluated RhymeRL within a real production environment, demonstrating scalability from dozens to thousands of GPUs. Experimental results demonstrate that RhymeRL achieves a 2.6x performance improvement over existing methods, without compromising accuracy or modifying the RL paradigm.</li>
</ul>

<h3>Title: Linear Trading Position with Sparse Spectrum</h3>
<ul>
<li><strong>Authors: </strong>Zhao-Rong Lai, Haisheng Yang</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.18596">https://arxiv.org/abs/2508.18596</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.18596">https://arxiv.org/pdf/2508.18596</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.18596]] Linear Trading Position with Sparse Spectrum(https://arxiv.org/abs/2508.18596)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>The principal portfolio approach is an emerging method in signal-based trading. However, these principal portfolios may not be diversified to explore the key features of the prediction matrix or robust to different situations. To address this problem, we propose a novel linear trading position with sparse spectrum that can explore a larger spectral region of the prediction matrix. We also develop a Krasnosel'ski\u Ä±-Mann fixed-point algorithm to optimize this trading position, which possesses the descent property and achieves a linear convergence rate in the objective value. This is a new theoretical result for this type of algorithms. Extensive experiments show that the proposed method achieves good and robust performance in various situations.</li>
</ul>

<h3>Title: What do language models model? Transformers, automata, and the format of thought</h3>
<ul>
<li><strong>Authors: </strong>Colin Klein</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.18598">https://arxiv.org/abs/2508.18598</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.18598">https://arxiv.org/pdf/2508.18598</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.18598]] What do language models model? Transformers, automata, and the format of thought(https://arxiv.org/abs/2508.18598)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer, large language model</a></li>
<li><strong>Abstract: </strong>What do large language models actually model? Do they tell us something about human capacities, or are they models of the corpus we've trained them on? I give a non-deflationary defence of the latter position. Cognitive science tells us that linguistic capabilities in humans rely supralinear formats for computation. The transformer architecture, by contrast, supports at best a linear formats for processing. This argument will rely primarily on certain invariants of the computational architecture of transformers. I then suggest a positive story about what transformers are doing, focusing on Liu et al. (2022)'s intriguing speculations about shortcut automata. I conclude with why I don't think this is a terribly deflationary story. Language is not (just) a means for expressing inner state but also a kind of 'discourse machine' that lets us make new language given appropriate context. We have learned to use this technology in one way; LLMs have also learned to use it too, but via very different means.</li>
</ul>

<h3>Title: Scaling Laws for Task-Stratified Knowledge in Post-Training Quantized Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Chenxi Zhou, Pengfei Cao, Jiang Li, Jun Zhao, Kang Liu</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.18609">https://arxiv.org/abs/2508.18609</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.18609">https://arxiv.org/pdf/2508.18609</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.18609]] Scaling Laws for Task-Stratified Knowledge in Post-Training Quantized Large Language Models(https://arxiv.org/abs/2508.18609)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, large language model</a></li>
<li><strong>Abstract: </strong>Large language models (LLMs) present significant deployment challenges due to their scale, with post-training quantization (PTQ) emerging as a practical compression solution. However, a comprehensive understanding of how PTQ precisely impacts diverse LLM knowledge capabilities remains elusive, and existing scaling laws for quantized models often overlook crucial PTQ-specific parameters and task-specific sensitivities. This paper addresses these gaps by conducting an extensive empirical investigation to establish task-stratified scaling laws. We disentangle LLM knowledge into memorization and utilization capabilities and develop a unified quantitative framework that incorporates model size, effective bit-width, calibration set size, and group size. Our central finding reveals that knowledge memorization exhibits markedly greater sensitivity to variations in effective bit-width, calibration set size, and model size compared to the more robust knowledge utilization. These findings offer a fine-grained understanding of PTQ's impact and provide guidance for developing knowledge-aware quantization strategies that can better preserve targeted cognitive functions.</li>
</ul>

<h3>Title: Uncertainty Awareness on Unsupervised Domain Adaptation for Time Series Data</h3>
<ul>
<li><strong>Authors: </strong>Weide Liu, Xiaoyang Zhong, Lu Wang, Jingwen Hou, Yuemei Luo, Jiebin Yan, Yuming Fang</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.18630">https://arxiv.org/abs/2508.18630</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.18630">https://arxiv.org/pdf/2508.18630</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.18630]] Uncertainty Awareness on Unsupervised Domain Adaptation for Time Series Data(https://arxiv.org/abs/2508.18630)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, extraction</a></li>
<li><strong>Abstract: </strong>Unsupervised domain adaptation methods seek to generalize effectively on unlabeled test data, especially when encountering the common challenge in time series data that distribution shifts occur between training and testing datasets. In this paper, we propose incorporating multi-scale feature extraction and uncertainty estimation to improve the model's generalization and robustness across domains. Our approach begins with a multi-scale mixed input architecture that captures features at different scales, increasing training diversity and reducing feature discrepancies between the training and testing domains. Based on the mixed input architecture, we further introduce an uncertainty awareness mechanism based on evidential learning by imposing a Dirichlet prior on the labels to facilitate both target prediction and uncertainty estimation. The uncertainty awareness mechanism enhances domain adaptation by aligning features with the same labels across different domains, which leads to significant performance improvements in the target domain. Additionally, our uncertainty-aware model demonstrates a much lower Expected Calibration Error (ECE), indicating better-calibrated prediction confidence. Our experimental results show that this combined approach of mixed input architecture with the uncertainty awareness mechanism achieves state-of-the-art performance across multiple benchmark datasets, underscoring its effectiveness in unsupervised domain adaptation for time series data.</li>
</ul>

<h3>Title: ROSE: Remove Objects with Side Effects in Videos</h3>
<ul>
<li><strong>Authors: </strong>Chenxuan Miao, Yutong Feng, Jianshu Zeng, Zixiang Gao, Hantang Liu, Yunfeng Yan, Donglian Qi, Xi Chen, Bin Wang, Hengshuang Zhao</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.18633">https://arxiv.org/abs/2508.18633</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.18633">https://arxiv.org/pdf/2508.18633</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.18633]] ROSE: Remove Objects with Side Effects in Videos(https://arxiv.org/abs/2508.18633)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, transformer, generative</a></li>
<li><strong>Abstract: </strong>Video object removal has achieved advanced performance due to the recent success of video generative models. However, when addressing the side effects of objects, e.g., their shadows and reflections, existing works struggle to eliminate these effects for the scarcity of paired video data as supervision. This paper presents ROSE, termed Remove Objects with Side Effects, a framework that systematically studies the object's effects on environment, which can be categorized into five common cases: shadows, reflections, light, translucency and mirror. Given the challenges of curating paired videos exhibiting the aforementioned effects, we leverage a 3D rendering engine for synthetic data generation. We carefully construct a fully-automatic pipeline for data preparation, which simulates a large-scale paired dataset with diverse scenes, objects, shooting angles, and camera trajectories. ROSE is implemented as an video inpainting model built on diffusion transformer. To localize all object-correlated areas, the entire video is fed into the model for reference-based erasing. Moreover, additional supervision is introduced to explicitly predict the areas affected by side effects, which can be revealed through the differential mask between the paired videos. To fully investigate the model performance on various side effect removal, we presents a new benchmark, dubbed ROSE-Bench, incorporating both common scenarios and the five special side effects for comprehensive evaluation. Experimental results demonstrate that ROSE achieves superior performance compared to existing video object erasing models and generalizes well to real-world video scenarios. The project page is this https URL.</li>
</ul>

<h3>Title: OwlCap: Harmonizing Motion-Detail for Video Captioning via HMD-270K and Caption Set Equivalence Reward</h3>
<ul>
<li><strong>Authors: </strong>Chunlin Zhong, Qiuxia Hou, Zhangjun Zhou, Shuang Hao, Haonan Lu, Yanhao Zhang, He Tang, Xiang Bai</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.18634">https://arxiv.org/abs/2508.18634</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.18634">https://arxiv.org/pdf/2508.18634</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.18634]] OwlCap: Harmonizing Motion-Detail for Video Captioning via HMD-270K and Caption Set Equivalence Reward(https://arxiv.org/abs/2508.18634)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Video captioning aims to generate comprehensive and coherent descriptions of the video content, contributing to the advancement of both video understanding and generation. However, existing methods often suffer from motion-detail imbalance, as models tend to overemphasize one aspect while neglecting the other. This imbalance results in incomplete captions, which in turn leads to a lack of consistency in video understanding and generation. To address this issue, we propose solutions from two aspects: 1) Data aspect: We constructed the Harmonizing Motion-Detail 270K (HMD-270K) dataset through a two-stage pipeline: Motion-Detail Fusion (MDF) and Fine-Grained Examination (FGE). 2) Optimization aspect: We introduce the Caption Set Equivalence Reward (CSER) based on Group Relative Policy Optimization (GRPO). CSER enhances completeness and accuracy in capturing both motion and details through unit-to-set matching and bidirectional validation. Based on the HMD-270K supervised fine-tuning and GRPO post-training with CSER, we developed OwlCap, a powerful video captioning multi-modal large language model (MLLM) with motion-detail balance. Experimental results demonstrate that OwlCap achieves significant improvements compared to baseline models on two benchmarks: the detail-focused VDC (+4.2 Acc) and the motion-focused DREAM-1K (+4.6 F1). The HMD-270K dataset and OwlCap model will be publicly released to facilitate video captioning research community advancements.</li>
</ul>

<h3>Title: Biologically Disentangled Multi-Omic Modeling Reveals Mechanistic Insights into Pan-Cancer Immunotherapy Resistance</h3>
<ul>
<li><strong>Authors: </strong>Ifrah Tariq, Ernest Fraenkel</a></li>
<li><strong>Subjects: </strong>cs.LG, q-bio.QM</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.18638">https://arxiv.org/abs/2508.18638</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.18638">https://arxiv.org/pdf/2508.18638</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.18638]] Biologically Disentangled Multi-Omic Modeling Reveals Mechanistic Insights into Pan-Cancer Immunotherapy Resistance(https://arxiv.org/abs/2508.18638)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability, generative</a></li>
<li><strong>Abstract: </strong>Immune checkpoint inhibitors (ICIs) have transformed cancer treatment, yet patient responses remain highly variable, and the biological mechanisms underlying resistance are poorly understood. While machine learning models hold promise for predicting responses to ICIs, most existing methods lack interpretability and do not effectively leverage the biological structure inherent to multi-omics data. Here, we introduce the Biologically Disentangled Variational Autoencoder (BDVAE), a deep generative model that integrates transcriptomic and genomic data through modality- and pathway-specific encoders. Unlike existing rigid, pathway-informed models, BDVAE employs a modular encoder architecture combined with variational inference to learn biologically meaningful latent features associated with immune, genomic, and metabolic processes. Applied to a pan-cancer cohort of 366 patients across four cancer types treated with ICIs, BDVAE accurately predicts treatment response (AUC-ROC = 0.94 on unseen test data) and uncovers critical resistance mechanisms, including immune suppression, metabolic shifts, and neuronal signaling. Importantly, BDVAE reveals that resistance spans a continuous biological spectrum rather than strictly binary states, reflecting gradations of tumor dysfunction. Several latent features correlate with survival outcomes and known clinical subtypes, demonstrating BDVAE's capability to generate interpretable, clinically relevant insights. These findings underscore the value of biologically structured machine learning in elucidating complex resistance patterns and guiding precision immunotherapy strategies.</li>
</ul>

<h3>Title: Clustering-based Feature Representation Learning for Oracle Bone Inscriptions Detection</h3>
<ul>
<li><strong>Authors: </strong>Ye Tao, Xinran Fu, Honglin Pang, Xi Yang, Chuntao Li</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.18641">https://arxiv.org/abs/2508.18641</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.18641">https://arxiv.org/pdf/2508.18641</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.18641]] Clustering-based Feature Representation Learning for Oracle Bone Inscriptions Detection(https://arxiv.org/abs/2508.18641)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction</a></li>
<li><strong>Abstract: </strong>Oracle Bone Inscriptions (OBIs), play a crucial role in understanding ancient Chinese civilization. The automated detection of OBIs from rubbing images represents a fundamental yet challenging task in digital archaeology, primarily due to various degradation factors including noise and cracks that limit the effectiveness of conventional detection networks. To address these challenges, we propose a novel clustering-based feature space representation learning method. Our approach uniquely leverages the Oracle Bones Character (OBC) font library dataset as prior knowledge to enhance feature extraction in the detection network through clustering-based representation learning. The method incorporates a specialized loss function derived from clustering results to optimize feature representation, which is then integrated into the total network loss. We validate the effectiveness of our method by conducting experiments on two OBIs detection dataset using three mainstream detection frameworks: Faster R-CNN, DETR, and Sparse R-CNN. Through extensive experimentation, all frameworks demonstrate significant performance improvements.</li>
</ul>

<h3>Title: Thinking Before You Speak: A Proactive Test-time Scaling Approach</h3>
<ul>
<li><strong>Authors: </strong>Cong Li, Wenchang Chai, Hejun Wu, Yan Pan, Pengxu Wei, Liang Lin</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.18648">https://arxiv.org/abs/2508.18648</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.18648">https://arxiv.org/pdf/2508.18648</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.18648]] Thinking Before You Speak: A Proactive Test-time Scaling Approach(https://arxiv.org/abs/2508.18648)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large Language Models (LLMs) often exhibit deficiencies with complex reasoning tasks, such as maths, which we attribute to the discrepancy between human reasoning patterns and those presented in the LLMs' training data. When dealing with complex problems, humans tend to think carefully before expressing solutions. However, they often do not articulate their inner thoughts, including their intentions and chosen methodologies. Consequently, critical insights essential for bridging reasoning steps may be absent in training data collected from human sources. To bridge this gap, we proposes inserting \emph{insight}s between consecutive reasoning steps, which review the status and initiate the next reasoning steps. Unlike prior prompting strategies that rely on a single or a workflow of static prompts to facilitate reasoning, \emph{insight}s are \emph{proactively} generated to guide reasoning processes. We implement our idea as a reasoning framework, named \emph{Thinking Before You Speak} (TBYS), and design a pipeline for automatically collecting and filtering in-context examples for the generation of \emph{insight}s, which alleviates human labeling efforts and fine-tuning overheads. Experiments on challenging mathematical datasets verify the effectiveness of TBYS. Project website: this https URL</li>
</ul>

<h3>Title: PRISM: Robust VLM Alignment with Principled Reasoning for Integrated Safety in Multimodality</h3>
<ul>
<li><strong>Authors: </strong>Nanxi Li, Zhengyue Zhao, Chaowei Xiao</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.18649">https://arxiv.org/abs/2508.18649</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.18649">https://arxiv.org/pdf/2508.18649</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.18649]] PRISM: Robust VLM Alignment with Principled Reasoning for Integrated Safety in Multimodality(https://arxiv.org/abs/2508.18649)</code><input type="text"></li>
<li><strong>Keywords: </strong>defense, attack, robust</a></li>
<li><strong>Abstract: </strong>Safeguarding vision-language models (VLMs) is a critical challenge, as existing methods often suffer from over-defense, which harms utility, or rely on shallow alignment, failing to detect complex threats that require deep reasoning. To this end, we introduce PRISM (Principled Reasoning for Integrated Safety in Multimodality), a system2-like framework that aligns VLMs by embedding a structured, safety-aware reasoning process. Our framework consists of two key components: PRISM-CoT, a dataset that teaches safety-aware chain-of-thought reasoning, and PRISM-DPO, generated via Monte Carlo Tree Search (MCTS) to further refine this reasoning through Direct Preference Optimization to help obtain a delicate safety boundary. Comprehensive evaluations demonstrate PRISM's effectiveness, achieving remarkably low attack success rates including 0.15% on JailbreakV-28K for Qwen2-VL and 90% improvement over the previous best method on VLBreak for LLaVA-1.5. PRISM also exhibits strong robustness against adaptive attacks, significantly increasing computational costs for adversaries, and generalizes effectively to out-of-distribution challenges, reducing attack success rates to just 8.70% on the challenging multi-image MIS benchmark. Remarkably, this robust defense is achieved while preserving, and in some cases enhancing, model utility. To promote reproducibility, we have made our code, data, and model weights available at this https URL.</li>
</ul>

<h3>Title: Breaking the Trade-Off Between Faithfulness and Expressiveness for Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Chenxu Yang, Qingyi Si, Zheng Lin</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.18651">https://arxiv.org/abs/2508.18651</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.18651">https://arxiv.org/pdf/2508.18651</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.18651]] Breaking the Trade-Off Between Faithfulness and Expressiveness for Large Language Models(https://arxiv.org/abs/2508.18651)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Grounding responses in external knowledge represents an effective strategy for mitigating hallucinations in Large Language Models (LLMs). However, current LLMs struggle to seamlessly integrate knowledge while simultaneously maintaining faithfulness (or fidelity) and expressiveness, capabilities that humans naturally possess. This limitation results in outputs that either lack support from external knowledge, thereby compromising faithfulness, or appear overly verbose and unnatural, thus sacrificing expressiveness. In this work, to break the trade-off between faithfulness and expressiveness, we propose Collaborative Decoding (CoDe), a novel approach that dynamically integrates output probabilities generated with and without external knowledge. This integration is guided by distribution divergence and model confidence, enabling the selective activation of relevant and reliable expressions from the model's internal parameters. Furthermore, we introduce a knowledge-aware reranking mechanism that prevents over-reliance on prior parametric knowledge while ensuring proper utilization of provided external information. Through comprehensive experiments, our plug-and-play CoDe framework demonstrates superior performance in enhancing faithfulness without compromising expressiveness across diverse LLMs and evaluation metrics, validating both its effectiveness and generalizability.</li>
</ul>

<h3>Title: UniC-RAG: Universal Knowledge Corruption Attacks to Retrieval-Augmented Generation</h3>
<ul>
<li><strong>Authors: </strong>Runpeng Geng, Yanting Wang, Ying Chen, Jinyuan Jia</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.18652">https://arxiv.org/abs/2508.18652</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.18652">https://arxiv.org/pdf/2508.18652</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.18652]] UniC-RAG: Universal Knowledge Corruption Attacks to Retrieval-Augmented Generation(https://arxiv.org/abs/2508.18652)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, defense, attack</a></li>
<li><strong>Abstract: </strong>Retrieval-augmented generation (RAG) systems are widely deployed in real-world applications in diverse domains such as finance, healthcare, and cybersecurity. However, many studies showed that they are vulnerable to knowledge corruption attacks, where an attacker can inject adversarial texts into the knowledge database of a RAG system to induce the LLM to generate attacker-desired outputs. Existing studies mainly focus on attacking specific queries or queries with similar topics (or keywords). In this work, we propose UniC-RAG, a universal knowledge corruption attack against RAG systems. Unlike prior work, UniC-RAG jointly optimizes a small number of adversarial texts that can simultaneously attack a large number of user queries with diverse topics and domains, enabling an attacker to achieve various malicious objectives, such as directing users to malicious websites, triggering harmful command execution, or launching denial-of-service attacks. We formulate UniC-RAG as an optimization problem and further design an effective solution to solve it, including a balanced similarity-based clustering method to enhance the attack's effectiveness. Our extensive evaluations demonstrate that UniC-RAG is highly effective and significantly outperforms baselines. For instance, UniC-RAG could achieve over 90% attack success rate by injecting 100 adversarial texts into a knowledge database with millions of texts to simultaneously attack a large set of user queries (e.g., 2,000). Additionally, we evaluate existing defenses and show that they are insufficient to defend against UniC-RAG, highlighting the need for new defense mechanisms in RAG systems.</li>
</ul>

<h3>Title: The Sound of Risk: A Multimodal Physics-Informed Acoustic Model for Forecasting Market Volatility and Enhancing Market Interpretability</h3>
<ul>
<li><strong>Authors: </strong>Xiaoliang Chen, Xin Yu, Le Chang, Teng Jing, Jiashuai He, Ze Wang, Yangjun Luo, Xingyu Chen, Jiayue Liang, Yuchen Wang, Jiaying Xie</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.SD</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.18653">https://arxiv.org/abs/2508.18653</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.18653">https://arxiv.org/pdf/2508.18653</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.18653]] The Sound of Risk: A Multimodal Physics-Informed Acoustic Model for Forecasting Market Volatility and Enhancing Market Interpretability(https://arxiv.org/abs/2508.18653)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, biometric, interpretability</a></li>
<li><strong>Abstract: </strong>Information asymmetry in financial markets, often amplified by strategically crafted corporate narratives, undermines the effectiveness of conventional textual analysis. We propose a novel multimodal framework for financial risk assessment that integrates textual sentiment with paralinguistic cues derived from executive vocal tract dynamics in earnings calls. Central to this framework is the Physics-Informed Acoustic Model (PIAM), which applies nonlinear acoustics to robustly extract emotional signatures from raw teleconference sound subject to distortions such as signal clipping. Both acoustic and textual emotional states are projected onto an interpretable three-dimensional Affective State Label (ASL) space-Tension, Stability, and Arousal. Using a dataset of 1,795 earnings calls (approximately 1,800 hours), we construct features capturing dynamic shifts in executive affect between scripted presentation and spontaneous Q&A exchanges. Our key finding reveals a pronounced divergence in predictive capacity: while multimodal features do not forecast directional stock returns, they explain up to 43.8% of the out-of-sample variance in 30-day realized volatility. Importantly, volatility predictions are strongly driven by emotional dynamics during executive transitions from scripted to spontaneous speech, particularly reduced textual stability and heightened acoustic instability from CFOs, and significant arousal variability from CEOs. An ablation study confirms that our multimodal approach substantially outperforms a financials-only baseline, underscoring the complementary contributions of acoustic and textual modalities. By decoding latent markers of uncertainty from verifiable biometric signals, our methodology provides investors and regulators a powerful tool for enhancing market interpretability and identifying hidden corporate uncertainty.</li>
</ul>

<h3>Title: Emotion Omni: Enabling Empathetic Speech Response Generation through Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Haoyu Wang, Guangyan Zhang, Jiale Chen, Jingyu Li, Yuehai Wang, Yiwen Guo</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.SD</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.18655">https://arxiv.org/abs/2508.18655</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.18655">https://arxiv.org/pdf/2508.18655</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.18655]] Emotion Omni: Enabling Empathetic Speech Response Generation through Large Language Models(https://arxiv.org/abs/2508.18655)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>With the development of speech large language models (speech LLMs), users can now interact directly with assistants via speech. However, most existing models simply convert the response content into speech without fully understanding the rich emotional and paralinguistic cues embedded in the user's query. In many cases, the same sentence can have different meanings depending on the emotional expression. Furthermore, emotional understanding is essential for improving user experience in human-machine interaction. Currently, most speech LLMs with empathetic capabilities are trained on massive datasets. This approach requires vast amounts of data and significant computational resources. Therefore, a key challenge lies in how to develop a speech LLM capable of generating empathetic responses with limited data and without the need for large-scale training. To address this challenge, we propose Emotion Omni, a novel model architecture designed to understand the emotional content of user speech input and generate empathetic speech responses. Additionally, we developed a data generation pipeline based on an open-source TTS framework to construct a 200k emotional dialogue dataset, which supports the construction of an empathetic speech assistant. The demos are available at this https URL</li>
</ul>

<h3>Title: FFT-MoE: Efficient Federated Fine-Tuning for Foundation Models via Large-scale Sparse MoE under Heterogeneous Edge</h3>
<ul>
<li><strong>Authors: </strong>Gang Hu, Yinglei Teng, Pengfei Wu, Nan Wang</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.18663">https://arxiv.org/abs/2508.18663</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.18663">https://arxiv.org/pdf/2508.18663</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.18663]] FFT-MoE: Efficient Federated Fine-Tuning for Foundation Models via Large-scale Sparse MoE under Heterogeneous Edge(https://arxiv.org/abs/2508.18663)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, federate</a></li>
<li><strong>Abstract: </strong>As FMs drive progress toward Artificial General Intelligence (AGI), fine-tuning them under privacy and resource constraints has become increasingly critical particularly when highquality training data resides on distributed edge devices. Federated Learning (FL) offers a compelling solution through Federated Fine-Tuning (FFT), which enables collaborative model adaptation without sharing raw data. Recent approaches incorporate Parameter-Efficient Fine-Tuning (PEFT) techniques such as Low Rank Adaptation (LoRA) to reduce computational overhead. However, LoRA-based FFT faces two major limitations in heterogeneous FL environments: structural incompatibility across clients with varying LoRA configurations and limited adaptability to non-IID data distributions, which hinders convergence and generalization. To address these challenges, we propose FFT MoE, a novel FFT framework that replaces LoRA with sparse Mixture of Experts (MoE) adapters. Each client trains a lightweight gating network to selectively activate a personalized subset of experts, enabling fine-grained adaptation to local resource budgets while preserving aggregation compatibility. To further combat the expert load imbalance caused by device and data heterogeneity, we introduce a heterogeneity-aware auxiliary loss that dynamically regularizes the routing distribution to ensure expert diversity and balanced utilization. Extensive experiments spanning both IID and non-IID conditions demonstrate that FFT MoE consistently outperforms state of the art FFT baselines in generalization performance and training efficiency.</li>
</ul>

<h3>Title: SFormer: SNR-guided Transformer for Underwater Image Enhancement from the Frequency Domain</h3>
<ul>
<li><strong>Authors: </strong>Xin Tian, Yingtie Lei, Xiujun Zhang, Zimeng Li, Chi-Man Pun, Xuhang Chen</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.18664">https://arxiv.org/abs/2508.18664</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.18664">https://arxiv.org/pdf/2508.18664</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.18664]] SFormer: SNR-guided Transformer for Underwater Image Enhancement from the Frequency Domain(https://arxiv.org/abs/2508.18664)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Recent learning-based underwater image enhancement (UIE) methods have advanced by incorporating physical priors into deep neural networks, particularly using the signal-to-noise ratio (SNR) prior to reduce wavelength-dependent attenuation. However, spatial domain SNR priors have two limitations: (i) they cannot effectively separate cross-channel interference, and (ii) they provide limited help in amplifying informative structures while suppressing noise. To overcome these, we propose using the SNR prior in the frequency domain, decomposing features into amplitude and phase spectra for better channel modulation. We introduce the Fourier Attention SNR-prior Transformer (FAST), combining spectral interactions with SNR cues to highlight key spectral components. Additionally, the Frequency Adaptive Transformer (FAT) bottleneck merges low- and high-frequency branches using a gated attention mechanism to enhance perceptual quality. Embedded in a unified U-shaped architecture, these modules integrate a conventional RGB stream with an SNR-guided branch, forming SFormer. Trained on 4,800 paired images from UIEB, EUVP, and LSUI, SFormer surpasses recent methods with a 3.1 dB gain in PSNR and 0.08 in SSIM, successfully restoring colors, textures, and contrast in underwater scenes.</li>
</ul>

<h3>Title: Auditing Approximate Machine Unlearning for Differentially Private Models</h3>
<ul>
<li><strong>Authors: </strong>Yuechun Gu, Jiajie He, Keke Chen</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.18671">https://arxiv.org/abs/2508.18671</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.18671">https://arxiv.org/pdf/2508.18671</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.18671]] Auditing Approximate Machine Unlearning for Differentially Private Models(https://arxiv.org/abs/2508.18671)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, attack, membership infer</a></li>
<li><strong>Abstract: </strong>Approximate machine unlearning aims to remove the effect of specific data from trained models to ensure individuals' privacy. Existing methods focus on the removed records and assume the retained ones are unaffected. However, recent studies on the \emph{privacy onion effect} indicate this assumption might be incorrect. Especially when the model is differentially private, no study has explored whether the retained ones still meet the differential privacy (DP) criterion under existing machine unlearning methods. This paper takes a holistic approach to auditing both unlearned and retained samples' privacy risks after applying approximate unlearning algorithms. We propose the privacy criteria for unlearned and retained samples, respectively, based on the perspectives of DP and membership inference attacks (MIAs). To make the auditing process more practical, we also develop an efficient MIA, A-LiRA, utilizing data augmentation to reduce the cost of shadow model training. Our experimental findings indicate that existing approximate machine unlearning algorithms may inadvertently compromise the privacy of retained samples for differentially private models, and we need differentially private unlearning algorithms. For reproducibility, we have pubished our code: this https URL</li>
</ul>

<h3>Title: Optimal Sparsity of Mixture-of-Experts Language Models for Reasoning Tasks</h3>
<ul>
<li><strong>Authors: </strong>Taishi Nakamura, Satoki Ishikawa, Masaki Kawamura, Takumi Okamoto, Daisuke Nohara, Jun Suzuki, Rio Yokota</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.18672">https://arxiv.org/abs/2508.18672</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.18672">https://arxiv.org/pdf/2508.18672</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.18672]] Optimal Sparsity of Mixture-of-Experts Language Models for Reasoning Tasks(https://arxiv.org/abs/2508.18672)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer, large language model</a></li>
<li><strong>Abstract: </strong>Empirical scaling laws have driven the evolution of large language models (LLMs), yet their coefficients shift whenever the model architecture or data pipeline changes. Mixture-of-Experts (MoE) models, now standard in state-of-the-art systems, introduce a new sparsity dimension that current dense-model frontiers overlook. We investigate how MoE sparsity influences two distinct capability regimes: memorization and reasoning. We train families of MoE Transformers that systematically vary total parameters, active parameters, and top-$k$ routing while holding the compute budget fixed. For every model we record pre-training loss, downstream task loss, and task accuracy, allowing us to separate the train-test generalization gap from the loss-accuracy gap. Memorization benchmarks improve monotonically with total parameters, mirroring training loss. By contrast, reasoning performance saturates and can even regress despite continued gains in both total parameters and training loss. Altering top-$k$ alone has little effect when active parameters are constant, and classic hyperparameters such as learning rate and initialization modulate the generalization gap in the same direction as sparsity. Neither post-training reinforcement learning (GRPO) nor extra test-time compute rescues the reasoning deficit of overly sparse models. Our model checkpoints, code and logs are open-source at this https URL.</li>
</ul>

<h3>Title: Tailored Teaching with Balanced Difficulty: Elevating Reasoning in Multimodal Chain-of-Thought via Prompt Curriculum</h3>
<ul>
<li><strong>Authors: </strong>Xinglong Yang, Quan Feng, Zhongying Pan, Xiang Chen, Yu Tian, Wentong Li, Shuofei Qiao, Yuxia Geng, Xingyu Zhao, Sheng-Jun Huang</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.MM</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.18673">https://arxiv.org/abs/2508.18673</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.18673">https://arxiv.org/pdf/2508.18673</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.18673]] Tailored Teaching with Balanced Difficulty: Elevating Reasoning in Multimodal Chain-of-Thought via Prompt Curriculum(https://arxiv.org/abs/2508.18673)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, large language model</a></li>
<li><strong>Abstract: </strong>The effectiveness of Multimodal Chain-of-Thought (MCoT) prompting is often limited by the use of randomly or manually selected examples. These examples fail to account for both model-specific knowledge distributions and the intrinsic complexity of the tasks, resulting in suboptimal and unstable model performance. To address this, we propose a novel framework inspired by the pedagogical principle of "tailored teaching with balanced difficulty". We reframe prompt selection as a prompt curriculum design problem: constructing a well ordered set of training examples that align with the model's current capabilities. Our approach integrates two complementary signals: (1) model-perceived difficulty, quantified through prediction disagreement in an active learning setup, capturing what the model itself finds challenging; and (2) intrinsic sample complexity, which measures the inherent difficulty of each question-image pair independently of any model. By jointly analyzing these signals, we develop a difficulty-balanced sampling strategy that ensures the selected prompt examples are diverse across both dimensions. Extensive experiments conducted on five challenging benchmarks and multiple popular Multimodal Large Language Models (MLLMs) demonstrate that our method yields substantial and consistent improvements and greatly reduces performance discrepancies caused by random sampling, providing a principled and robust approach for enhancing multimodal reasoning.</li>
</ul>

<h3>Title: Utilizing Training Data to Improve LLM Reasoning for Tabular Understanding</h3>
<ul>
<li><strong>Authors: </strong>Chufan Gao, Jintai Chen, Jimeng Sun</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.18676">https://arxiv.org/abs/2508.18676</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.18676">https://arxiv.org/pdf/2508.18676</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.18676]] Utilizing Training Data to Improve LLM Reasoning for Tabular Understanding(https://arxiv.org/abs/2508.18676)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Automated tabular understanding and reasoning are essential tasks for data scientists. Recently, Large language models (LLMs) have become increasingly prevalent in tabular reasoning tasks. Previous work focuses on (1) finetuning LLMs using labeled data or (2) Training-free prompting LLM agents using chain-of-thought (CoT). Finetuning offers dataset-specific learning at the cost of generalizability. Training-free prompting is highly generalizable but does not take full advantage of training data. In this paper, we propose a novel prompting-based reasoning approach, Learn then Retrieve: LRTab, which integrates the benefits of both by retrieving relevant information learned from training data. We first use prompting to obtain CoT responses over the training data. For incorrect CoTs, we prompt the LLM to predict Prompt Conditions to avoid the error, learning insights from the data. We validate the effectiveness of Prompt Conditions using validation data. Finally, at inference time, we retrieve the most relevant Prompt Conditions for additional context for table understanding. We provide comprehensive experiments on WikiTQ and Tabfact, showing that LRTab is interpretable, cost-efficient, and can outperform previous baselines in tabular reasoning.</li>
</ul>

<h3>Title: Hierarchical Spatio-temporal Segmentation Network for Ejection Fraction Estimation in Echocardiography Videos</h3>
<ul>
<li><strong>Authors: </strong>Dongfang Wang, Jian Yang, Yizhe Zhang, Tao Zhou</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.18681">https://arxiv.org/abs/2508.18681</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.18681">https://arxiv.org/pdf/2508.18681</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.18681]] Hierarchical Spatio-temporal Segmentation Network for Ejection Fraction Estimation in Echocardiography Videos(https://arxiv.org/abs/2508.18681)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>Automated segmentation of the left ventricular endocardium in echocardiography videos is a key research area in cardiology. It aims to provide accurate assessment of cardiac structure and function through Ejection Fraction (EF) estimation. Although existing studies have achieved good segmentation performance, their results do not perform well in EF estimation. In this paper, we propose a Hierarchical Spatio-temporal Segmentation Network (\ourmodel) for echocardiography video, aiming to improve EF estimation accuracy by synergizing local detail modeling with global dynamic perception. The network employs a hierarchical design, with low-level stages using convolutional networks to process single-frame images and preserve details, while high-level stages utilize the Mamba architecture to capture spatio-temporal relationships. The hierarchical design balances single-frame and multi-frame processing, avoiding issues such as local error accumulation when relying solely on single frames or neglecting details when using only multi-frame data. To overcome local spatio-temporal limitations, we propose the Spatio-temporal Cross Scan (STCS) module, which integrates long-range context through skip scanning across frames and positions. This approach helps mitigate EF calculation biases caused by ultrasound image noise and other factors.</li>
</ul>

<h3>Title: FALCON: Autonomous Cyber Threat Intelligence Mining with LLMs for IDS Rule Generation</h3>
<ul>
<li><strong>Authors: </strong>Shaswata Mitra, Azim Bazarov, Martin Duclos, Sudip Mittal, Aritran Piplai, Md Rayhanur Rahman, Edward Zieglar, Shahram Rahimi</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.AI, cs.CL, cs.LG, eess.SY</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.18684">https://arxiv.org/abs/2508.18684</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.18684">https://arxiv.org/pdf/2508.18684</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.18684]] FALCON: Autonomous Cyber Threat Intelligence Mining with LLMs for IDS Rule Generation(https://arxiv.org/abs/2508.18684)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, attack, large language model</a></li>
<li><strong>Abstract: </strong>Signature-based Intrusion Detection Systems (IDS) detect malicious activities by matching network or host activity against predefined rules. These rules are derived from extensive Cyber Threat Intelligence (CTI), which includes attack signatures and behavioral patterns obtained through automated tools and manual threat analysis, such as sandboxing. The CTI is then transformed into actionable rules for the IDS engine, enabling real-time detection and prevention. However, the constant evolution of cyber threats necessitates frequent rule updates, which delay deployment time and weaken overall security readiness. Recent advancements in agentic systems powered by Large Language Models (LLMs) offer the potential for autonomous IDS rule generation with internal evaluation. We introduce FALCON, an autonomous agentic framework that generates deployable IDS rules from CTI data in real-time and evaluates them using built-in multi-phased validators. To demonstrate versatility, we target both network (Snort) and host-based (YARA) mediums and construct a comprehensive dataset of IDS rules with their corresponding CTIs. Our evaluations indicate FALCON excels in automatic rule generation, with an average of 95% accuracy validated by qualitative evaluation with 84% inter-rater agreement among multiple cybersecurity analysts across all metrics. These results underscore the feasibility and effectiveness of LLM-driven data mining for real-time cyber threat mitigation.</li>
</ul>

<h3>Title: Knowing or Guessing? Robust Medical Visual Question Answering via Joint Consistency and Contrastive Learning</h3>
<ul>
<li><strong>Authors: </strong>Songtao Jiang, Yuxi Chen, Sibo Song, Yan Zhang, Yeying Jin, Yang Feng, Jian Wu, Zuozhu Liu</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.18687">https://arxiv.org/abs/2508.18687</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.18687">https://arxiv.org/pdf/2508.18687</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.18687]] Knowing or Guessing? Robust Medical Visual Question Answering via Joint Consistency and Contrastive Learning(https://arxiv.org/abs/2508.18687)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>In high-stakes medical applications, consistent answering across diverse question phrasings is essential for reliable diagnosis. However, we reveal that current Medical Vision-Language Models (Med-VLMs) exhibit concerning fragility in Medical Visual Question Answering, as their answers fluctuate significantly when faced with semantically equivalent rephrasings of medical questions. We attribute this to two limitations: (1) insufficient alignment of medical concepts, leading to divergent reasoning patterns, and (2) hidden biases in training data that prioritize syntactic shortcuts over semantic understanding. To address these challenges, we construct RoMed, a dataset built upon original VQA datasets containing 144k questions with variations spanning word-level, sentence-level, and semantic-level perturbations. When evaluating state-of-the-art (SOTA) models like LLaVA-Med on RoMed, we observe alarming performance drops (e.g., a 40\% decline in Recall) compared to original VQA benchmarks, exposing critical robustness gaps. To bridge this gap, we propose Consistency and Contrastive Learning (CCL), which integrates two key components: (1) knowledge-anchored consistency learning, aligning Med-VLMs with medical knowledge rather than shallow feature patterns, and (2) bias-aware contrastive learning, mitigating data-specific priors through discriminative representation refinement. CCL achieves SOTA performance on three popular VQA benchmarks and notably improves answer consistency by 50\% on the challenging RoMed test set, demonstrating significantly enhanced robustness. Code will be released.</li>
</ul>

<h3>Title: End to End Autoencoder MLP Framework for Sepsis Prediction</h3>
<ul>
<li><strong>Authors: </strong>Hejiang Cai, Di Wu, Ji Xu, Xiang Liu, Yiziting Zhu, Xin Shu, Yujie Li, Bin Yi</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.18688">https://arxiv.org/abs/2508.18688</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.18688">https://arxiv.org/pdf/2508.18688</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.18688]] End to End Autoencoder MLP Framework for Sepsis Prediction(https://arxiv.org/abs/2508.18688)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, extraction</a></li>
<li><strong>Abstract: </strong>Sepsis is a life threatening condition that requires timely detection in intensive care settings. Traditional machine learning approaches, including Naive Bayes, Support Vector Machine (SVM), Random Forest, and XGBoost, often rely on manual feature engineering and struggle with irregular, incomplete time-series data commonly present in electronic health records. We introduce an end-to-end deep learning framework integrating an unsupervised autoencoder for automatic feature extraction with a multilayer perceptron classifier for binary sepsis risk prediction. To enhance clinical applicability, we implement a customized down sampling strategy that extracts high information density segments during training and a non-overlapping dynamic sliding window mechanism for real-time inference. Preprocessed time series data are represented as fixed dimension vectors with explicit missingness indicators, mitigating bias and noise. We validate our approach on three ICU cohorts. Our end-to-end model achieves accuracies of 74.6 percent, 80.6 percent, and 93.5 percent, respectively, consistently outperforming traditional machine learning baselines. These results demonstrate the framework's superior robustness, generalizability, and clinical utility for early sepsis detection across heterogeneous ICU environments.</li>
</ul>

<h3>Title: Feature-Space Planes Searcher: A Universal Domain Adaptation Framework for Interpretability and Computational Efficiency</h3>
<ul>
<li><strong>Authors: </strong>Zhitong Cheng, Yiran Jiang, Yulong Ge, Yufeng Li, Zhongheng Qin, Rongzhi Lin, Jianwei Ma</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.18693">https://arxiv.org/abs/2508.18693</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.18693">https://arxiv.org/pdf/2508.18693</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.18693]] Feature-Space Planes Searcher: A Universal Domain Adaptation Framework for Interpretability and Computational Efficiency(https://arxiv.org/abs/2508.18693)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction, interpretability</a></li>
<li><strong>Abstract: </strong>Domain shift, characterized by degraded model performance during transition from labeled source domains to unlabeled target domains, poses a persistent challenge for deploying deep learning systems. Current unsupervised domain adaptation (UDA) methods predominantly rely on fine-tuning feature extractors - an approach limited by inefficiency, reduced interpretability, and poor scalability to modern architectures. Our analysis reveals that models pretrained on large-scale data exhibit domain-invariant geometric patterns in their feature space, characterized by intra-class clustering and inter-class separation, thereby preserving transferable discriminative structures. These findings indicate that domain shifts primarily manifest as boundary misalignment rather than feature degradation. Unlike fine-tuning entire pre-trained models - which risks introducing unpredictable feature distortions - we propose the Feature-space Planes Searcher (FPS): a novel domain adaptation framework that optimizes decision boundaries by leveraging these geometric patterns while keeping the feature encoder frozen. This streamlined approach enables interpretative analysis of adaptation while substantially reducing memory and computational costs through offline feature extraction, permitting full-dataset optimization in a single computation cycle. Evaluations on public benchmarks demonstrate that FPS achieves competitive or superior performance to state-of-the-art methods. FPS scales efficiently with multimodal large models and shows versatility across diverse domains including protein structure prediction, remote sensing classification, and earthquake detection. We anticipate FPS will provide a simple, effective, and generalizable paradigm for transfer learning, particularly in domain adaptation tasks. .</li>
</ul>

<h3>Title: A Novel Deep Hybrid Framework with Ensemble-Based Feature Optimization for Robust Real-Time Human Activity Recognition</h3>
<ul>
<li><strong>Authors: </strong>Wasi Ullah, Yasir Noman Khalid, Saddam Hussain Khan</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.18695">https://arxiv.org/abs/2508.18695</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.18695">https://arxiv.org/pdf/2508.18695</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.18695]] A Novel Deep Hybrid Framework with Ensemble-Based Feature Optimization for Robust Real-Time Human Activity Recognition(https://arxiv.org/abs/2508.18695)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Human Activity Recognition (HAR) plays a pivotal role in various applications, including smart surveillance, healthcare, assistive technologies, sports analytics, etc. However, HAR systems still face critical challenges, including high computational costs, redundant features, and limited scalability in real-time scenarios. An optimized hybrid deep learning framework is introduced that integrates a customized InceptionV3, an LSTM architecture, and a novel ensemble-based feature selection strategy. The proposed framework first extracts spatial descriptors using the customized InceptionV3 model, which captures multilevel contextual patterns, region homogeneity, and fine-grained localization cues. The temporal dependencies across frames are then modeled using LSTMs to effectively encode motion dynamics. Finally, an ensemble-based genetic algorithm with Adaptive Dynamic Fitness Sharing and Attention (ADFSA) is employed to select a compact and optimized feature set by dynamically balancing objectives such as accuracy, redundancy, uniqueness, and complexity reduction. Consequently, the selected feature subsets, which are both diverse and discriminative, enable various lightweight machine learning classifiers to achieve accurate and robust HAR in heterogeneous environments. Experimental results on the robust UCF-YouTube dataset, which presents challenges such as occlusion, cluttered backgrounds, motion dynamics, and poor illumination, demonstrate good performance. The proposed approach achieves 99.65% recognition accuracy, reduces features to as few as 7, and enhances inference time. The lightweight and scalable nature of the HAR system supports real-time deployment on edge devices such as Raspberry Pi, enabling practical applications in intelligent, resource-aware environments, including public safety, assistive technology, and autonomous monitoring systems.</li>
</ul>

<h3>Title: Attention2Probability: Attention-Driven Terminology Probability Estimation for Robust Speech-to-Text System</h3>
<ul>
<li><strong>Authors: </strong>Yanfan Du, Jun Zhang, Bin Wang, Jin Qiu, Lu Huang, Yuan Ge, Xiaoqian Liu, Tong Xiao, Jingbo Zhu</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.18701">https://arxiv.org/abs/2508.18701</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.18701">https://arxiv.org/pdf/2508.18701</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.18701]] Attention2Probability: Attention-Driven Terminology Probability Estimation for Robust Speech-to-Text System(https://arxiv.org/abs/2508.18701)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, large language model</a></li>
<li><strong>Abstract: </strong>Recent advances in speech large language models (SLMs) have improved speech recognition and translation in general domains, but accurately generating domain-specific terms or neologisms remains challenging. To address this, we propose Attention2Probability: attention-driven terminology probability estimation for robust speech-to-text system, which is lightweight, flexible, and accurate. Attention2Probability converts cross-attention weights between speech and terminology into presence probabilities, and it further employs curriculum learning to enhance retrieval accuracy. Furthermore, to tackle the lack of data for speech-to-text tasks with terminology intervention, we create and release a new speech dataset with terminology to support future research in this area. Experimental results show that Attention2Probability significantly outperforms the VectorDB method on our test set. Specifically, its maximum recall rates reach 92.57% for Chinese and 86.83% for English. This high recall is achieved with a latency of only 8.71ms per query. Intervening in SLMs' recognition and translation tasks using Attention2Probability-retrieved terms improves terminology accuracy by 6-17%, while revealing that the current utilization of terminology by SLMs has limitations.</li>
</ul>

<h3>Title: Filtering for Creativity: Adaptive Prompting for Multilingual Riddle Generation in LLMs</h3>
<ul>
<li><strong>Authors: </strong>Duy Le, Kent Ziti, Evan Girard-Sun, Sean O'Brien, Vasu Sharma, Kevin Zhu</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.18709">https://arxiv.org/abs/2508.18709</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.18709">https://arxiv.org/pdf/2508.18709</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.18709]] Filtering for Creativity: Adaptive Prompting for Multilingual Riddle Generation in LLMs(https://arxiv.org/abs/2508.18709)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Multilingual riddle generation challenges large language models (LLMs) to balance cultural fluency with creative abstraction. Standard prompting strategies -- zero-shot, few-shot, chain-of-thought -- tend to reuse memorized riddles or perform shallow paraphrasing. We introduce Adaptive Originality Filtering (AOF), a prompting framework that filters redundant generations using cosine-based similarity rejection, while enforcing lexical novelty and cross-lingual fidelity. Evaluated across three LLMs and four language pairs, AOF-enhanced GPT-4o achieves \texttt{0.177} Self-BLEU and \texttt{0.915} Distinct-2 in Japanese, signaling improved lexical diversity and reduced redundancy compared to other prompting methods and language pairs. Our findings show that semantic rejection can guide culturally grounded, creative generation without task-specific fine-tuning.</li>
</ul>

<h3>Title: EMMM, Explain Me My Model! Explainable Machine Generated Text Detection in Dialogues</h3>
<ul>
<li><strong>Authors: </strong>Angela Yifei Yuan, Haoyi Li, Soyeon Caren Han, Christopher Leckie</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.18715">https://arxiv.org/abs/2508.18715</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.18715">https://arxiv.org/pdf/2508.18715</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.18715]] EMMM, Explain Me My Model! Explainable Machine Generated Text Detection in Dialogues(https://arxiv.org/abs/2508.18715)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability, large language model</a></li>
<li><strong>Abstract: </strong>The rapid adoption of large language models (LLMs) in customer service introduces new risks, as malicious actors can exploit them to conduct large-scale user impersonation through machine-generated text (MGT). Current MGT detection methods often struggle in online conversational settings, reducing the reliability and interpretability essential for trustworthy AI deployment. In customer service scenarios where operators are typically non-expert users, explanation become crucial for trustworthy MGT detection. In this paper, we propose EMMM, an explanation-then-detection framework that balances latency, accuracy, and non-expert-oriented interpretability. Experimental results demonstrate that EMMM provides explanations accessible to non-expert users, with 70\% of human evaluators preferring its outputs, while achieving competitive accuracy compared to state-of-the-art models and maintaining low latency, generating outputs within 1 second. Our code and dataset are open-sourced at this https URL.</li>
</ul>

<h3>Title: Flatness-aware Curriculum Learning via Adversarial Difficulty</h3>
<ul>
<li><strong>Authors: </strong>Hiroaki Aizawa, Yoshikazu Hayashi</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.18726">https://arxiv.org/abs/2508.18726</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.18726">https://arxiv.org/pdf/2508.18726</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.18726]] Flatness-aware Curriculum Learning via Adversarial Difficulty(https://arxiv.org/abs/2508.18726)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Neural networks trained by empirical risk minimization often suffer from overfitting, especially to specific samples or domains, which leads to poor generalization. Curriculum Learning (CL) addresses this issue by selecting training samples based on the difficulty. From the optimization perspective, methods such as Sharpness-Aware Minimization (SAM) improve robustness and generalization by seeking flat minima. However, combining CL with SAM is not straightforward. In flat regions, both the loss values and the gradient norms tend to become uniformly small, which makes it difficult to evaluate sample difficulty and design an effective curriculum. To overcome this problem, we propose the Adversarial Difficulty Measure (ADM), which quantifies adversarial vulnerability by leveraging the robustness properties of models trained toward flat minima. Unlike loss- or gradient-based measures, which become ineffective as training progresses into flatter regions, ADM remains informative by measuring the normalized loss gap between original and adversarial examples. We incorporate ADM into CL-based training with SAM to dynamically assess sample difficulty. We evaluated our approach on image classification tasks, fine-grained recognition, and domain generalization. The results demonstrate that our method preserves the strengths of both CL and SAM while outperforming existing curriculum-based and flatness-aware training strategies.</li>
</ul>

<h3>Title: Beyond Tokens: Enhancing RTL Quality Estimation via Structural Graph Learning</h3>
<ul>
<li><strong>Authors: </strong>Yi Liu, Hongji Zhang, Yiwen Wang, Dimitris Tsaras, Lei Chen, Mingxuan Yuan, Qiang Xu</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.18730">https://arxiv.org/abs/2508.18730</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.18730">https://arxiv.org/pdf/2508.18730</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.18730]] Beyond Tokens: Enhancing RTL Quality Estimation via Structural Graph Learning(https://arxiv.org/abs/2508.18730)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Estimating the quality of register transfer level (RTL) designs is crucial in the electronic design automation (EDA) workflow, as it enables instant feedback on key metrics like area and delay without the need for time-consuming logic synthesis. While recent approaches have leveraged large language models (LLMs) to derive embeddings from RTL code and achieved promising results, they overlook the structural semantics essential for accurate quality estimation. In contrast, the control data flow graph (CDFG) view exposes the design's structural characteristics more explicitly, offering richer cues for representation learning. In this work, we introduce a novel structure-aware graph self-supervised learning framework, StructRTL, for improved RTL design quality estimation. By learning structure-informed representations from CDFGs, our method significantly outperforms prior art on various quality estimation tasks. To further boost performance, we incorporate a knowledge distillation strategy that transfers low-level insights from post-mapping netlists into the CDFG predictor. Experiments show that our approach establishes new state-of-the-art results, demonstrating the effectiveness of combining structural learning with cross-stage supervision.</li>
</ul>

<h3>Title: Drawing2CAD: Sequence-to-Sequence Learning for CAD Generation from Vectorized Drawings</h3>
<ul>
<li><strong>Authors: </strong>Feiwei Qin, Shichao Lu, Junhao Hou, Changmiao Wang, Meie Fang, Ligang Liu</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.18733">https://arxiv.org/abs/2508.18733</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.18733">https://arxiv.org/pdf/2508.18733</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.18733]] Drawing2CAD: Sequence-to-Sequence Learning for CAD Generation from Vectorized Drawings(https://arxiv.org/abs/2508.18733)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer, generative</a></li>
<li><strong>Abstract: </strong>Computer-Aided Design (CAD) generative modeling is driving significant innovations across industrial applications. Recent works have shown remarkable progress in creating solid models from various inputs such as point clouds, meshes, and text descriptions. However, these methods fundamentally diverge from traditional industrial workflows that begin with 2D engineering drawings. The automatic generation of parametric CAD models from these 2D vector drawings remains underexplored despite being a critical step in engineering design. To address this gap, our key insight is to reframe CAD generation as a sequence-to-sequence learning problem where vector drawing primitives directly inform the generation of parametric CAD operations, preserving geometric precision and design intent throughout the transformation process. We propose Drawing2CAD, a framework with three key technical components: a network-friendly vector primitive representation that preserves precise geometric information, a dual-decoder transformer architecture that decouples command type and parameter generation while maintaining precise correspondence, and a soft target distribution loss function accommodating inherent flexibility in CAD parameters. To train and evaluate Drawing2CAD, we create CAD-VGDrawing, a dataset of paired engineering drawings and parametric CAD models, and conduct thorough experiments to demonstrate the effectiveness of our method. Code and dataset are available at this https URL.</li>
</ul>

<h3>Title: Improving Noise Robust Audio-Visual Speech Recognition via Router-Gated Cross-Modal Feature Fusion</h3>
<ul>
<li><strong>Authors: </strong>DongHoon Lim, YoungChae Kim, Dong-Hyun Kim, Da-Hee Yang, Joon-Hyuk Chang</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI, cs.MM, eess.AS, eess.SP</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.18734">https://arxiv.org/abs/2508.18734</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.18734">https://arxiv.org/pdf/2508.18734</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.18734]] Improving Noise Robust Audio-Visual Speech Recognition via Router-Gated Cross-Modal Feature Fusion(https://arxiv.org/abs/2508.18734)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Robust audio-visual speech recognition (AVSR) in noisy environments remains challenging, as existing systems struggle to estimate audio reliability and dynamically adjust modality reliance. We propose router-gated cross-modal feature fusion, a novel AVSR framework that adaptively reweights audio and visual features based on token-level acoustic corruption scores. Using an audio-visual feature fusion-based router, our method down-weights unreliable audio tokens and reinforces visual cues through gated cross-attention in each decoder layer. This enables the model to pivot toward the visual modality when audio quality deteriorates. Experiments on LRS3 demonstrate that our approach achieves an 16.51-42.67% relative reduction in word error rate compared to AV-HuBERT. Ablation studies confirm that both the router and gating mechanism contribute to improved robustness under real-world acoustic noise.</li>
</ul>

<h3>Title: FLAegis: A Two-Layer Defense Framework for Federated Learning Against Poisoning Attacks</h3>
<ul>
<li><strong>Authors: </strong>Enrique MÃ¡rmol Campos, Aurora GonzÃ¡lez Vidal, JosÃ© Luis HernÃ¡ndez Ramos, Antonio Skarmeta</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.18737">https://arxiv.org/abs/2508.18737</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.18737">https://arxiv.org/pdf/2508.18737</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.18737]] FLAegis: A Two-Layer Defense Framework for Federated Learning Against Poisoning Attacks(https://arxiv.org/abs/2508.18737)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, defense, attack, robust, federate</a></li>
<li><strong>Abstract: </strong>Federated Learning (FL) has become a powerful technique for training Machine Learning (ML) models in a decentralized manner, preserving the privacy of the training datasets involved. However, the decentralized nature of FL limits the visibility of the training process, relying heavily on the honesty of participating clients. This assumption opens the door to malicious third parties, known as Byzantine clients, which can poison the training process by submitting false model updates. Such malicious clients may engage in poisoning attacks, manipulating either the dataset or the model parameters to induce misclassification. In response, this study introduces FLAegis, a two-stage defensive framework designed to identify Byzantine clients and improve the robustness of FL systems. Our approach leverages symbolic time series transformation (SAX) to amplify the differences between benign and malicious models, and spectral clustering, which enables accurate detection of adversarial behavior. Furthermore, we incorporate a robust FFT-based aggregation function as a final layer to mitigate the impact of those Byzantine clients that manage to evade prior defenses. We rigorously evaluate our method against five poisoning attacks, ranging from simple label flipping to adaptive optimization-based strategies. Notably, our approach outperforms state-of-the-art defenses in both detection precision and final model accuracy, maintaining consistently high performance even under strong adversarial conditions.</li>
</ul>

<h3>Title: Beyond Quality: Unlocking Diversity in Ad Headline Generation with Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Chang Wang, Siyu Yan, Depeng Yuan, Yuqi Chen, Yanhua Huang, Yuanhang Zheng, Shuhao Li, Yinqi Zhang, Kedi Chen, Mingrui Zhu, Ruiwen Xu</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.18739">https://arxiv.org/abs/2508.18739</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.18739">https://arxiv.org/pdf/2508.18739</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.18739]] Beyond Quality: Unlocking Diversity in Ad Headline Generation with Large Language Models(https://arxiv.org/abs/2508.18739)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>The generation of ad headlines plays a vital role in modern advertising, where both quality and diversity are essential to engage a broad range of audience segments. Current approaches primarily optimize language models for headline quality or click-through rates (CTR), often overlooking the need for diversity and resulting in homogeneous outputs. To address this limitation, we propose DIVER, a novel framework based on large language models (LLMs) that are jointly optimized for both diversity and quality. We first design a semantic- and stylistic-aware data generation pipeline that automatically produces high-quality training pairs with ad content and multiple diverse headlines. To achieve the goal of generating high-quality and diversified ad headlines within a single forward pass, we propose a multi-stage multi-objective optimization framework with supervised fine-tuning (SFT) and reinforcement learning (RL). Experiments on real-world industrial datasets demonstrate that DIVER effectively balances quality and diversity. Deployed on a large-scale content-sharing platform serving hundreds of millions of users, our framework improves advertiser value (ADVV) and CTR by 4.0% and 1.4%.</li>
</ul>

<h3>Title: M3HG: Multimodal, Multi-scale, and Multi-type Node Heterogeneous Graph for Emotion Cause Triplet Extraction in Conversations</h3>
<ul>
<li><strong>Authors: </strong>Qiao Liang, Ying Shen, Tiantian Chen, Lin Zhang</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.18740">https://arxiv.org/abs/2508.18740</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.18740">https://arxiv.org/pdf/2508.18740</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.18740]] M3HG: Multimodal, Multi-scale, and Multi-type Node Heterogeneous Graph for Emotion Cause Triplet Extraction in Conversations(https://arxiv.org/abs/2508.18740)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction</a></li>
<li><strong>Abstract: </strong>Emotion Cause Triplet Extraction in Multimodal Conversations (MECTEC) has recently gained significant attention in social media analysis, aiming to extract emotion utterances, cause utterances, and emotion categories simultaneously. However, the scarcity of related datasets, with only one published dataset featuring highly uniform dialogue scenarios, hinders model development in this field. To address this, we introduce MECAD, the first multimodal, multi-scenario MECTEC dataset, comprising 989 conversations from 56 TV series spanning a wide range of dialogue contexts. In addition, existing MECTEC methods fail to explicitly model emotional and causal contexts and neglect the fusion of semantic information at different levels, leading to performance degradation. In this paper, we propose M3HG, a novel model that explicitly captures emotional and causal contexts and effectively fuses contextual information at both inter- and intra-utterance levels via a multimodal heterogeneous graph. Extensive experiments demonstrate the effectiveness of M3HG compared with existing state-of-the-art methods. The codes and dataset are available at this https URL.</li>
</ul>

<h3>Title: Immutable Digital Recognition via Blockchain</h3>
<ul>
<li><strong>Authors: </strong>Zeng Zhang, Xiaoqi Li</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.18750">https://arxiv.org/abs/2508.18750</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.18750">https://arxiv.org/pdf/2508.18750</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.18750]] Immutable Digital Recognition via Blockchain(https://arxiv.org/abs/2508.18750)</code><input type="text"></li>
<li><strong>Keywords: </strong>secure</a></li>
<li><strong>Abstract: </strong>The process integrates the decentralised management and centralised operation models, aligning them with the national policy directives. The developed solution enables the full utilisation of blockchain technology's advantages while also fostering community participation. Consequently, it establishes a secure, legal, reliable, and dynamic electronic certification system.</li>
</ul>

<h3>Title: Rethinking Human-Object Interaction Evaluation for both Vision-Language Models and HOI-Specific Methods</h3>
<ul>
<li><strong>Authors: </strong>Qinqian Lei, Bo Wang, Robby T. Tan</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.18753">https://arxiv.org/abs/2508.18753</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.18753">https://arxiv.org/pdf/2508.18753</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.18753]] Rethinking Human-Object Interaction Evaluation for both Vision-Language Models and HOI-Specific Methods(https://arxiv.org/abs/2508.18753)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>Prior human-object interaction (HOI) detection methods have integrated early vision-language models (VLMs) such as CLIP, but only as supporting components within their frameworks. In contrast, recent advances in large, generative VLMs suggest that these models may already possess strong ability to understand images involving HOI. This naturally raises an important question: can general-purpose standalone VLMs effectively solve HOI detection, and how do they compare with specialized HOI methods? Answering this requires a benchmark that can accommodate both paradigms. However, existing HOI benchmarks such as HICO-DET were developed before the emergence of modern VLMs, and their evaluation protocols require exact matches to annotated HOI classes. This is poorly aligned with the generative nature of VLMs, which often yield multiple valid interpretations in ambiguous cases. For example, a static image may capture a person mid-motion with a frisbee, which can plausibly be interpreted as either "throwing" or "catching". When only "catching" is annotated, the other, though equally plausible for the image, is marked incorrect when exact matching is used. As a result, correct predictions might be penalized, affecting both VLMs and HOI-specific methods. To avoid penalizing valid predictions, we introduce a new benchmark that reformulates HOI detection as a multiple-answer multiple-choice task, where each question includes only ground-truth positive options and a curated set of negatives that are constructed to reduce ambiguity (e.g., when "catching" is annotated, "throwing" is not selected as a negative to avoid penalizing valid predictions). The proposed evaluation protocol is the first of its kind for both VLMs and HOI methods, enabling direct comparison and offering new insight into the current state of progress in HOI understanding.</li>
</ul>

<h3>Title: UltraMemV2: Memory Networks Scaling to 120B Parameters with Superior Long-Context Learning</h3>
<ul>
<li><strong>Authors: </strong>Zihao Huang, Yu Bao, Qiyang Min, Siyan Chen, Ran Guo, Hongzhi Huang, Defa Zhu, Yutao Zeng, Banggu Wu, Xun Zhou, Siyuan Qiao</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.18756">https://arxiv.org/abs/2508.18756</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.18756">https://arxiv.org/pdf/2508.18756</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.18756]] UltraMemV2: Memory Networks Scaling to 120B Parameters with Superior Long-Context Learning(https://arxiv.org/abs/2508.18756)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>While Mixture of Experts (MoE) models achieve remarkable efficiency by activating only subsets of parameters, they suffer from high memory access costs during inference. Memory-layer architectures offer an appealing alternative with very few memory access, but previous attempts like UltraMem have only matched the performance of 2-expert MoE models, falling significantly short of state-of-the-art 8-expert configurations. We present UltraMemV2, a redesigned memory-layer architecture that closes this performance gap. Our approach introduces five key improvements: integrating memory layers into every transformer block, simplifying value expansion with single linear projections, adopting FFN-based value processing from PEER, implementing principled parameter initialization, and rebalancing memory-to-FFN computation ratios. Through extensive evaluation, we demonstrate that UltraMemV2 achieves performance parity with 8-expert MoE models under same computation and parameters but significantly low memory access. Notably, UltraMemV2 shows superior performance on memory-intensive tasks, with improvements of +1.6 points on long-context memorization, +6.2 points on multi-round memorization, and +7.9 points on in-context learning. We validate our approach at scale with models up to 2.5B activated parameters from 120B total parameters, and establish that activation density has greater impact on performance than total sparse parameter count. Our work brings memory-layer architectures to performance parity with state-of-the-art MoE models, presenting a compelling alternative for efficient sparse computation.</li>
</ul>

<h3>Title: Governance-as-a-Service: A Multi-Agent Framework for AI System Compliance and Policy Enforcement</h3>
<ul>
<li><strong>Authors: </strong>Helen Pervez, Suyash Gaurav, Jukka Heikkonen, Jatin Chaudhary</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.18765">https://arxiv.org/abs/2508.18765</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.18765">https://arxiv.org/pdf/2508.18765</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.18765]] Governance-as-a-Service: A Multi-Agent Framework for AI System Compliance and Policy Enforcement(https://arxiv.org/abs/2508.18765)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>As AI systems evolve into distributed ecosystems with autonomous execution, asynchronous reasoning, and multi-agent coordination, the absence of scalable, decoupled governance poses a structural risk. Existing oversight mechanisms are reactive, brittle, and embedded within agent architectures, making them non-auditable and hard to generalize across heterogeneous deployments. We introduce Governance-as-a-Service (GaaS): a modular, policy-driven enforcement layer that regulates agent outputs at runtime without altering model internals or requiring agent cooperation. GaaS employs declarative rules and a Trust Factor mechanism that scores agents based on compliance and severity-weighted violations. It enables coercive, normative, and adaptive interventions, supporting graduated enforcement and dynamic trust modulation. To evaluate GaaS, we conduct three simulation regimes with open-source models (LLaMA3, Qwen3, DeepSeek-R1) across content generation and financial decision-making. In the baseline, agents act without governance; in the second, GaaS enforces policies; in the third, adversarial agents probe robustness. All actions are intercepted, evaluated, and logged for analysis. Results show that GaaS reliably blocks or redirects high-risk behaviors while preserving throughput. Trust scores track rule adherence, isolating and penalizing untrustworthy components in multi-agent systems. By positioning governance as a runtime service akin to compute or storage, GaaS establishes infrastructure-level alignment for interoperable agent ecosystems. It does not teach agents ethics; it enforces them.</li>
</ul>

<h3>Title: Predicting Drug-Drug Interactions Using Heterogeneous Graph Neural Networks: HGNN-DDI</h3>
<ul>
<li><strong>Authors: </strong>Hongbo Liu, Siyi Li, Zheng Yu</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.18766">https://arxiv.org/abs/2508.18766</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.18766">https://arxiv.org/pdf/2508.18766</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.18766]] Predicting Drug-Drug Interactions Using Heterogeneous Graph Neural Networks: HGNN-DDI(https://arxiv.org/abs/2508.18766)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Drug-drug interactions (DDIs) are a major concern in clinical practice, as they can lead to reduced therapeutic efficacy or severe adverse effects. Traditional computational approaches often struggle to capture the complex relationships among drugs, targets, and biological entities. In this work, we propose HGNN-DDI, a heterogeneous graph neural network model designed to predict potential DDIs by integrating multiple drug-related data sources. HGNN-DDI leverages graph representation learning to model heterogeneous biomedical networks, enabling effective information propagation across diverse node and edge types. Experimental results on benchmark DDI datasets demonstrate that HGNN-DDI outperforms state-of-the-art baselines in prediction accuracy and robustness, highlighting its potential to support safer drug development and precision medicine.</li>
</ul>

<h3>Title: ThinkDial: An Open Recipe for Controlling Reasoning Effort in Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Qianyu He, Siyu Yuan, Xuefeng Li, Mingxuan Wang, Jiangjie Chen</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.18773">https://arxiv.org/abs/2508.18773</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.18773">https://arxiv.org/pdf/2508.18773</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.18773]] ThinkDial: An Open Recipe for Controlling Reasoning Effort in Large Language Models(https://arxiv.org/abs/2508.18773)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large language models (LLMs) with chain-of-thought reasoning have demonstrated remarkable problem-solving capabilities, but controlling their computational effort remains a significant challenge for practical deployment. Recent proprietary systems like OpenAI's gpt-oss series have introduced discrete operational modes for intuitive reasoning control, but the open-source community has largely failed to achieve such capabilities. In this paper, we introduce ThinkDial, the first open-recipe end-to-end framework that successfully implements gpt-oss-style controllable reasoning through discrete operational modes. Our system enables seamless switching between three distinct reasoning regimes: High mode (full reasoning capability), Medium mode (50 percent token reduction with <10 percent performance degradation), and Low mode (75 percent token reduction with <15 percent performance degradation). We achieve this through an end-to-end training paradigm that integrates budget-mode control throughout the entire pipeline: budget-mode supervised fine-tuning that embeds controllable reasoning capabilities directly into the learning process, and two-phase budget-aware reinforcement learning with adaptive reward shaping. Extensive experiments demonstrate that ThinkDial achieves target compression-performance trade-offs with clear response length reductions while maintaining performance thresholds. The framework also exhibits strong generalization capabilities on out-of-distribution tasks.</li>
</ul>

<h3>Title: Federated Learning with Heterogeneous and Private Label Sets</h3>
<ul>
<li><strong>Authors: </strong>Adam Breitholtz, Edvin Listo Zec, Fredrik D. Johansson</a></li>
<li><strong>Subjects: </strong>cs.LG, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.18774">https://arxiv.org/abs/2508.18774</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.18774">https://arxiv.org/pdf/2508.18774</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.18774]] Federated Learning with Heterogeneous and Private Label Sets(https://arxiv.org/abs/2508.18774)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, federate</a></li>
<li><strong>Abstract: </strong>Although common in real-world applications, heterogeneous client label sets are rarely investigated in federated learning (FL). Furthermore, in the cases they are, clients are assumed to be willing to share their entire label sets with other clients. Federated learning with private label sets, shared only with the central server, adds further constraints on learning algorithms and is, in general, a more difficult problem to solve. In this work, we study the effects of label set heterogeneity on model performance, comparing the public and private label settings -- when the union of label sets in the federation is known to clients and when it is not. We apply classical methods for the classifier combination problem to FL using centralized tuning, adapt common FL methods to the private label set setting, and discuss the justification of both approaches under practical assumptions. Our experiments show that reducing the number of labels available to each client harms the performance of all methods substantially. Centralized tuning of client models for representational alignment can help remedy this, but often at the cost of higher variance. Throughout, our proposed adaptations of standard FL methods perform well, showing similar performance in the private label setting as the standard methods achieve in the public setting. This shows that clients can enjoy increased privacy at little cost to model accuracy.</li>
</ul>

<h3>Title: Controllable Conversational Theme Detection Track at DSTC 12</h3>
<ul>
<li><strong>Authors: </strong>Igor Shalyminov, Hang Su, Jake Vincent, Siffi Singh, Jason Cai, James Gung, Raphael Shu, Saab Mansour</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.18783">https://arxiv.org/abs/2508.18783</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.18783">https://arxiv.org/pdf/2508.18783</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.18783]] Controllable Conversational Theme Detection Track at DSTC 12(https://arxiv.org/abs/2508.18783)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Conversational analytics has been on the forefront of transformation driven by the advances in Speech and Natural Language Processing techniques. Rapid adoption of Large Language Models (LLMs) in the analytics field has taken the problems that can be automated to a new level of complexity and scale. In this paper, we introduce Theme Detection as a critical task in conversational analytics, aimed at automatically identifying and categorizing topics within conversations. This process can significantly reduce the manual effort involved in analyzing expansive dialogs, particularly in domains like customer support or sales. Unlike traditional dialog intent detection, which often relies on a fixed set of intents for downstream system logic, themes are intended as a direct, user-facing summary of the conversation's core inquiry. This distinction allows for greater flexibility in theme surface forms and user-specific customizations. We pose Controllable Conversational Theme Detection problem as a public competition track at Dialog System Technology Challenge (DSTC) 12 -- it is framed as joint clustering and theme labeling of dialog utterances, with the distinctive aspect being controllability of the resulting theme clusters' granularity achieved via the provided user preference data. We give an overview of the problem, the associated dataset and the evaluation metrics, both automatic and human. Finally, we discuss the participant teams' submissions and provide insights from those. The track materials (data and code) are openly available in the GitHub repository.</li>
</ul>

<h3>Title: Design, Implementation and Evaluation of a Real-Time Remote Photoplethysmography (rPPG) Acquisition System for Non-Invasive Vital Sign Monitoring</h3>
<ul>
<li><strong>Authors: </strong>Constantino Ãlvarez Casado, Sasan Sharifipour, Manuel Lage CaÃ±ellas, Nhi Nguyen, Le Nguyen, Miguel Bordallo LÃ³pez</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.18787">https://arxiv.org/abs/2508.18787</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.18787">https://arxiv.org/pdf/2508.18787</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.18787]] Design, Implementation and Evaluation of a Real-Time Remote Photoplethysmography (rPPG) Acquisition System for Non-Invasive Vital Sign Monitoring(https://arxiv.org/abs/2508.18787)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, extraction</a></li>
<li><strong>Abstract: </strong>The growing integration of smart environments and low-power computing devices, coupled with mass-market sensor technologies, is driving advancements in remote and non-contact physiological monitoring. However, deploying these systems in real-time on resource-constrained platforms introduces significant challenges related to scalability, interoperability, and performance. This paper presents a real-time remote photoplethysmography (rPPG) system optimized for low-power devices, designed to extract physiological signals, such as heart rate (HR), respiratory rate (RR), and oxygen saturation (SpO2), from facial video streams. The system is built on the Face2PPG pipeline, which processes video frames sequentially for rPPG signal extraction and analysis, while leveraging a multithreaded architecture to manage video capture, real-time processing, network communication, and graphical user interface (GUI) updates concurrently. This design ensures continuous, reliable operation at 30 frames per second (fps), with adaptive feedback through a collaborative user interface to guide optimal signal capture conditions. The network interface includes both an HTTP server for continuous video streaming and a RESTful API for on-demand vital sign retrieval. To ensure accurate performance despite the limitations of low-power devices, we use a hybrid programming model combining Functional Reactive Programming (FRP) and the Actor Model, allowing event-driven processing and efficient task parallelization. The system is evaluated under real-time constraints, demonstrating robustness while minimizing computational overhead. Our work addresses key challenges in real-time biosignal monitoring, offering practical solutions for optimizing performance in modern healthcare and human-computer interaction applications.</li>
</ul>

<h3>Title: PseudoMapTrainer: Learning Online Mapping without HD Maps</h3>
<ul>
<li><strong>Authors: </strong>Christian LÃ¶wens, Thorben Funke, Jingchao Xie, Alexandru Paul Condurache</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.LG, cs.RO</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.18788">https://arxiv.org/abs/2508.18788</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.18788">https://arxiv.org/pdf/2508.18788</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.18788]] PseudoMapTrainer: Learning Online Mapping without HD Maps(https://arxiv.org/abs/2508.18788)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>Online mapping models show remarkable results in predicting vectorized maps from multi-view camera images only. However, all existing approaches still rely on ground-truth high-definition maps during training, which are expensive to obtain and often not geographically diverse enough for reliable generalization. In this work, we propose PseudoMapTrainer, a novel approach to online mapping that uses pseudo-labels generated from unlabeled sensor data. We derive those pseudo-labels by reconstructing the road surface from multi-camera imagery using Gaussian splatting and semantics of a pre-trained 2D segmentation network. In addition, we introduce a mask-aware assignment algorithm and loss function to handle partially masked pseudo-labels, allowing for the first time the training of online mapping models without any ground-truth maps. Furthermore, our pseudo-labels can be effectively used to pre-train an online model in a semi-supervised manner to leverage large-scale unlabeled crowdsourced data. The code is available at this http URL.</li>
</ul>

<h3>Title: A Closer Look at Edema Area Segmentation in SD-OCT Images Using Adversarial Framework</h3>
<ul>
<li><strong>Authors: </strong>Yuhui Tao, Yizhe Zhang, Qiang Chen</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.18790">https://arxiv.org/abs/2508.18790</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.18790">https://arxiv.org/pdf/2508.18790</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.18790]] A Closer Look at Edema Area Segmentation in SD-OCT Images Using Adversarial Framework(https://arxiv.org/abs/2508.18790)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, segmentation</a></li>
<li><strong>Abstract: </strong>The development of artificial intelligence models for macular edema (ME) analy-sis always relies on expert-annotated pixel-level image datasets which are expen-sive to collect prospectively. While anomaly-detection-based weakly-supervised methods have shown promise in edema area (EA) segmentation task, their per-formance still lags behind fully-supervised approaches. In this paper, we leverage the strong correlation between EA and retinal layers in spectral-domain optical coherence tomography (SD-OCT) images, along with the update characteristics of weakly-supervised learning, to enhance an off-the-shelf adversarial framework for EA segmentation with a novel layer-structure-guided post-processing step and a test-time-adaptation (TTA) strategy. By incorporating additional retinal lay-er information, our framework reframes the dense EA prediction task as one of confirming intersection points between the EA contour and retinal layers, result-ing in predictions that better align with the shape prior of EA. Besides, the TTA framework further helps address discrepancies in the manifestations and presen-tations of EA between training and test sets. Extensive experiments on two pub-licly available datasets demonstrate that these two proposed ingredients can im-prove the accuracy and robustness of EA segmentation, bridging the gap between weakly-supervised and fully-supervised models.</li>
</ul>

<h3>Title: Robust and Label-Efficient Deep Waste Detection</h3>
<ul>
<li><strong>Authors: </strong>Hassan Abid, Khan Muhammad, Muhammad Haris Khan</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.18799">https://arxiv.org/abs/2508.18799</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.18799">https://arxiv.org/pdf/2508.18799</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.18799]] Robust and Label-Efficient Deep Waste Detection(https://arxiv.org/abs/2508.18799)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, transformer</a></li>
<li><strong>Abstract: </strong>Effective waste sorting is critical for sustainable recycling, yet AI research in this domain continues to lag behind commercial systems due to limited datasets and reliance on legacy object detectors. In this work, we advance AI-driven waste detection by establishing strong baselines and introducing an ensemble-based semi-supervised learning framework. We first benchmark state-of-the-art Open-Vocabulary Object Detection (OVOD) models on the real-world ZeroWaste dataset, demonstrating that while class-only prompts perform poorly, LLM-optimized prompts significantly enhance zero-shot accuracy. Next, to address domain-specific limitations, we fine-tune modern transformer-based detectors, achieving a new baseline of 51.6 mAP. We then propose a soft pseudo-labeling strategy that fuses ensemble predictions using spatial and consensus-aware weighting, enabling robust semi-supervised training. Applied to the unlabeled ZeroWaste-s subset, our pseudo-annotations achieve performance gains that surpass fully supervised training, underscoring the effectiveness of scalable annotation pipelines. Our work contributes to the research community by establishing rigorous baselines, introducing a robust ensemble-based pseudo-labeling pipeline, generating high-quality annotations for the unlabeled ZeroWaste-s subset, and systematically evaluating OVOD models under real-world waste sorting conditions. Our code is available at: this https URL.</li>
</ul>

<h3>Title: Hidden Tail: Adversarial Image Causing Stealthy Resource Consumption in Vision-Language Models</h3>
<ul>
<li><strong>Authors: </strong>Rui Zhang, Zihan Wang, Tianli Yang, Hongwei Li, Wenbo Jiang, Qingchuan Zhao, Yang Liu, Guowen Xu</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.18805">https://arxiv.org/abs/2508.18805</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.18805">https://arxiv.org/pdf/2508.18805</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.18805]] Hidden Tail: Adversarial Image Causing Stealthy Resource Consumption in Vision-Language Models(https://arxiv.org/abs/2508.18805)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack, robust, steal</a></li>
<li><strong>Abstract: </strong>Vision-Language Models (VLMs) are increasingly deployed in real-world applications, but their high inference cost makes them vulnerable to resource consumption attacks. Prior attacks attempt to extend VLM output sequences by optimizing adversarial images, thereby increasing inference costs. However, these extended outputs often introduce irrelevant abnormal content, compromising attack stealthiness. This trade-off between effectiveness and stealthiness poses a major limitation for existing attacks. To address this challenge, we propose \textit{Hidden Tail}, a stealthy resource consumption attack that crafts prompt-agnostic adversarial images, inducing VLMs to generate maximum-length outputs by appending special tokens invisible to users. Our method employs a composite loss function that balances semantic preservation, repetitive special token induction, and suppression of the end-of-sequence (EOS) token, optimized via a dynamic weighting strategy. Extensive experiments show that \textit{Hidden Tail} outperforms existing attacks, increasing output length by up to 19.2$\times$ and reaching the maximum token limit, while preserving attack stealthiness. These results highlight the urgent need to improve the robustness of VLMs against efficiency-oriented adversarial threats. Our code is available at this https URL.</li>
</ul>

<h3>Title: LLM-based Contrastive Self-Supervised AMR Learning with Masked Graph Autoencoders for Fake News Detection</h3>
<ul>
<li><strong>Authors: </strong>Shubham Gupta, Shraban Kumar Chatterjee, Suman Kundu</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.SI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.18819">https://arxiv.org/abs/2508.18819</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.18819">https://arxiv.org/pdf/2508.18819</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.18819]] LLM-based Contrastive Self-Supervised AMR Learning with Masked Graph Autoencoders for Fake News Detection(https://arxiv.org/abs/2508.18819)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>The proliferation of misinformation in the digital age has led to significant societal challenges. Existing approaches often struggle with capturing long-range dependencies, complex semantic relations, and the social dynamics influencing news dissemination. Furthermore, these methods require extensive labelled datasets, making their deployment resource-intensive. In this study, we propose a novel self-supervised misinformation detection framework that integrates both complex semantic relations using Abstract Meaning Representation (AMR) and news propagation dynamics. We introduce an LLM-based graph contrastive loss (LGCL) that utilizes negative anchor points generated by a Large Language Model (LLM) to enhance feature separability in a zero-shot manner. To incorporate social context, we employ a multi view graph masked autoencoder, which learns news propagation features from social context graph. By combining these semantic and propagation-based features, our approach effectively differentiates between fake and real news in a self-supervised manner. Extensive experiments demonstrate that our self-supervised framework achieves superior performance compared to other state-of-the-art methodologies, even with limited labelled datasets while improving generalizability.</li>
</ul>

<h3>Title: Arrows of Math Reasoning Data Synthesis for Large Language Models: Diversity, Complexity and Correctness</h3>
<ul>
<li><strong>Authors: </strong>Sirui Chen, Changxin Tian, Binbin Hu, Kunlong Chen, Ziqi Liu, Zhiqiang Zhang, Jun Zhou</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.18824">https://arxiv.org/abs/2508.18824</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.18824">https://arxiv.org/pdf/2508.18824</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.18824]] Arrows of Math Reasoning Data Synthesis for Large Language Models: Diversity, Complexity and Correctness(https://arxiv.org/abs/2508.18824)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Enhancing the mathematical reasoning of large language models (LLMs) demands high-quality training data, yet conventional methods face critical challenges in scalability, cost, and data reliability. To address these limitations, we propose a novel program-assisted synthesis framework that systematically generates a high-quality mathematical corpus with guaranteed diversity, complexity, and correctness. This framework integrates mathematical knowledge systems and domain-specific tools to create executable programs. These programs are then translated into natural language problem-solution pairs and vetted by a bilateral validation mechanism that verifies solution correctness against program outputs and ensures program-problem consistency. We have generated 12.3 million such problem-solving triples. Experiments demonstrate that models fine-tuned on our data significantly improve their inference capabilities, achieving state-of-the-art performance on several benchmark datasets and showcasing the effectiveness of our synthesis approach.</li>
</ul>

<h3>Title: SWiFT: Soft-Mask Weight Fine-tuning for Bias Mitigation</h3>
<ul>
<li><strong>Authors: </strong>Junyu Yan, Feng Chen, Yuyang Xue, Yuning Du, Konstantinos Vilouras, Sotirios A. Tsaftaris, Steven McDonagh</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.18826">https://arxiv.org/abs/2508.18826</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.18826">https://arxiv.org/pdf/2508.18826</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.18826]] SWiFT: Soft-Mask Weight Fine-tuning for Bias Mitigation(https://arxiv.org/abs/2508.18826)</code><input type="text"></li>
<li><strong>Keywords: </strong>fair</a></li>
<li><strong>Abstract: </strong>Recent studies have shown that Machine Learning (ML) models can exhibit bias in real-world scenarios, posing significant challenges in ethically sensitive domains such as healthcare. Such bias can negatively affect model fairness, model generalization abilities and further risks amplifying social discrimination. There is a need to remove biases from trained models. Existing debiasing approaches often necessitate access to original training data and need extensive model retraining; they also typically exhibit trade-offs between model fairness and discriminative performance. To address these challenges, we propose Soft-Mask Weight Fine-Tuning (SWiFT), a debiasing framework that efficiently improves fairness while preserving discriminative performance with much less debiasing costs. Notably, SWiFT requires only a small external dataset and only a few epochs of model fine-tuning. The idea behind SWiFT is to first find the relative, and yet distinct, contributions of model parameters to both bias and predictive performance. Then, a two-step fine-tuning process updates each parameter with different gradient flows defined by its contribution. Extensive experiments with three bias sensitive attributes (gender, skin tone, and age) across four dermatological and two chest X-ray datasets demonstrate that SWiFT can consistently reduce model bias while achieving competitive or even superior diagnostic accuracy under common fairness and accuracy metrics, compared to the state-of-the-art. Specifically, we demonstrate improved model generalization ability as evidenced by superior performance on several out-of-distribution (OOD) datasets.</li>
</ul>

<h3>Title: Automated Classification of Normal and Atypical Mitotic Figures Using ConvNeXt V2: MIDOG 2025 Track 2</h3>
<ul>
<li><strong>Authors: </strong>Yosuke Yamagishi, Shouhei Hanaoka</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.18831">https://arxiv.org/abs/2508.18831</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.18831">https://arxiv.org/pdf/2508.18831</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.18831]] Automated Classification of Normal and Atypical Mitotic Figures Using ConvNeXt V2: MIDOG 2025 Track 2(https://arxiv.org/abs/2508.18831)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>This paper presents our solution for the MIDOG 2025 Challenge Track 2, which focuses on binary classification of normal mitotic figures (NMFs) versus atypical mitotic figures (AMFs) in histopathological images. Our approach leverages a ConvNeXt V2 base model with center cropping preprocessing and 5-fold cross-validation ensemble strategy. The method addresses key challenges including severe class imbalance, high morphological variability, and domain heterogeneity across different tumor types, species, and scanners. Through strategic preprocessing with 60% center cropping and mixed precision training, our model achieved robust performance on the diverse MIDOG 2025 dataset. The solution demonstrates the effectiveness of modern convolutional architectures for mitotic figure subtyping while maintaining computational efficiency through careful architectural choices and training optimizations.</li>
</ul>

<h3>Title: A Tight Context-aware Privacy Bound for Histogram Publication</h3>
<ul>
<li><strong>Authors: </strong>Sara Saeidian (1 and 2), Ata YavuzyÄ±lmaz, Leonhard Grosse (1), Georg Schuppe (3), Tobias J. Oechtering (1) ((1) KTH Royal Institute of Technology, (2) Inria Saclay, (3) SEBx)</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.IT</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.18832">https://arxiv.org/abs/2508.18832</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.18832">https://arxiv.org/pdf/2508.18832</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.18832]] A Tight Context-aware Privacy Bound for Histogram Publication(https://arxiv.org/abs/2508.18832)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, protect</a></li>
<li><strong>Abstract: </strong>We analyze the privacy guarantees of the Laplace mechanism releasing the histogram of a dataset through the lens of pointwise maximal leakage (PML). While differential privacy is commonly used to quantify the privacy loss, it is a context-free definition that does not depend on the data distribution. In contrast, PML enables a more refined analysis by incorporating assumptions about the data distribution. We show that when the probability of each histogram bin is bounded away from zero, stronger privacy protection can be achieved for a fixed level of noise. Our results demonstrate the advantage of context-aware privacy measures and show that incorporating assumptions about the data can improve privacy-utility tradeoffs.</li>
</ul>

<h3>Title: ConfTuner: Training Large Language Models to Express Their Confidence Verbally</h3>
<ul>
<li><strong>Authors: </strong>Yibo Li, Miao Xiong, Jiaying Wu, Bryan Hooi</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.18847">https://arxiv.org/abs/2508.18847</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.18847">https://arxiv.org/pdf/2508.18847</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.18847]] ConfTuner: Training Large Language Models to Express Their Confidence Verbally(https://arxiv.org/abs/2508.18847)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large Language Models (LLMs) are increasingly deployed in high-stakes domains such as science, law, and healthcare, where accurate expressions of uncertainty are essential for reliability and trust. However, current LLMs are often observed to generate incorrect answers with high confidence, a phenomenon known as "overconfidence". Recent efforts have focused on calibrating LLMs' verbalized confidence: i.e., their expressions of confidence in text form, such as "I am 80% confident that...". Existing approaches either rely on prompt engineering or fine-tuning with heuristically generated uncertainty estimates, both of which have limited effectiveness and generalizability. Motivated by the notion of proper scoring rules for calibration in classical machine learning models, we introduce ConfTuner, a simple and efficient fine-tuning method that introduces minimal overhead and does not require ground-truth confidence scores or proxy confidence estimates. ConfTuner relies on a new loss function, tokenized Brier score, which we theoretically prove to be a proper scoring rule, intuitively meaning that it "correctly incentivizes the model to report its true probability of being correct". ConfTuner improves calibration across diverse reasoning tasks and generalizes to black-box models such as GPT-4o. Our results further show that better-calibrated confidence enables downstream gains in self-correction and model cascade, advancing the development of trustworthy LLM systems. The code is available at this https URL.</li>
</ul>

<h3>Title: Harnessing Meta-Learning for Controllable Full-Frame Video Stabilization</h3>
<ul>
<li><strong>Authors: </strong>Muhammad Kashif Ali, Eun Woo Im, Dongjin Kim, Tae Hyun Kim, Vivek Gupta, Haonan Luo, Tianrui Li</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.18859">https://arxiv.org/abs/2508.18859</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.18859">https://arxiv.org/pdf/2508.18859</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.18859]] Harnessing Meta-Learning for Controllable Full-Frame Video Stabilization(https://arxiv.org/abs/2508.18859)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Video stabilization remains a fundamental problem in computer vision, particularly pixel-level synthesis solutions for video stabilization, which synthesize full-frame outputs, add to the complexity of this task. These methods aim to enhance stability while synthesizing full-frame videos, but the inherent diversity in motion profiles and visual content present in each video sequence makes robust generalization with fixed parameters difficult. To address this, we present a novel method that improves pixel-level synthesis video stabilization methods by rapidly adapting models to each input video at test time. The proposed approach takes advantage of low-level visual cues available during inference to improve both the stability and visual quality of the output. Notably, the proposed rapid adaptation achieves significant performance gains even with a single adaptation pass. We further propose a jerk localization module and a targeted adaptation strategy, which focuses the adaptation on high-jerk segments for maximizing stability with fewer adaptation steps. The proposed methodology enables modern stabilizers to overcome the longstanding SOTA approaches while maintaining the full frame nature of the modern methods, while offering users with control mechanisms akin to classical approaches. Extensive experiments on diverse real-world datasets demonstrate the versatility of the proposed method. Our approach consistently improves the performance of various full-frame synthesis models in both qualitative and quantitative terms, including results on downstream applications.</li>
</ul>

<h3>Title: C-Flat++: Towards a More Efficient and Powerful Framework for Continual Learning</h3>
<ul>
<li><strong>Authors: </strong>Wei Li, Hangjie Yuan, Zixiang Zhao, Yifan Zhu, Aojun Lu, Tao Feng, Yanan Sun</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.18860">https://arxiv.org/abs/2508.18860</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.18860">https://arxiv.org/pdf/2508.18860</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.18860]] C-Flat++: Towards a More Efficient and Powerful Framework for Continual Learning(https://arxiv.org/abs/2508.18860)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Balancing sensitivity to new tasks and stability for retaining past knowledge is crucial in continual learning (CL). Recently, sharpness-aware minimization has proven effective in transfer learning and has also been adopted in continual learning (CL) to improve memory retention and learning efficiency. However, relying on zeroth-order sharpness alone may favor sharper minima over flatter ones in certain settings, leading to less robust and potentially suboptimal solutions. In this paper, we propose \textbf{C}ontinual \textbf{Flat}ness (\textbf{C-Flat}), a method that promotes flatter loss landscapes tailored for CL. C-Flat offers plug-and-play compatibility, enabling easy integration with minimal modifications to the code pipeline. Besides, we present a general framework that integrates C-Flat into all major CL paradigms and conduct comprehensive comparisons with loss-minima optimizers and flat-minima-based CL methods. Our results show that C-Flat consistently improves performance across a wide range of settings. In addition, we introduce C-Flat++, an efficient yet effective framework that leverages selective flatness-driven promotion, significantly reducing the update cost required by C-Flat. Extensive experiments across multiple CL methods, datasets, and scenarios demonstrate the effectiveness and efficiency of our proposed approaches. Code is available at this https URL.</li>
</ul>

<h3>Title: ReflectivePrompt: Reflective evolution in autoprompting algorithms</h3>
<ul>
<li><strong>Authors: </strong>Viktor N. Zhuravlev, Artur R. Khairullin, Ernest A. Dyagin, Alena N. Sitkina, Nikita I. Kulin</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.18870">https://arxiv.org/abs/2508.18870</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.18870">https://arxiv.org/pdf/2508.18870</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.18870]] ReflectivePrompt: Reflective evolution in autoprompting algorithms(https://arxiv.org/abs/2508.18870)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Autoprompting is the process of automatically selecting optimized prompts for language models, which has been gaining popularity with the rapid advancement of prompt engineering, driven by extensive research in the field of large language models (LLMs). This paper presents ReflectivePrompt - a novel autoprompting method based on evolutionary algorithms that employs a reflective evolution approach for more precise and comprehensive search of optimal prompts. ReflectivePrompt utilizes short-term and long-term reflection operations before crossover and elitist mutation to enhance the quality of the modifications they introduce. This method allows for the accumulation of knowledge obtained throughout the evolution process and updates it at each epoch based on the current population. ReflectivePrompt was tested on 33 datasets for classification and text generation tasks using open-access large language models: t-lite-instruct-0.1 and gemma3-27b-it. The method demonstrates, on average, a significant improvement (e.g., 28% on BBH compared to EvoPrompt) in metrics relative to current state-of-the-art approaches, thereby establishing itself as one of the most effective solutions in evolutionary algorithm-based autoprompting.</li>
</ul>

<h3>Title: Empowering Computing Education Researchers Through LLM-Assisted Content Analysis</h3>
<ul>
<li><strong>Authors: </strong>Laurie Gale, Sebastian Mateos Nicolajsen</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.18872">https://arxiv.org/abs/2508.18872</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.18872">https://arxiv.org/pdf/2508.18872</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.18872]] Empowering Computing Education Researchers Through LLM-Assisted Content Analysis(https://arxiv.org/abs/2508.18872)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Computing education research (CER) is often instigated by practitioners wanting to improve both their own and the wider discipline's teaching practice. However, the latter is often difficult as many researchers lack the colleagues, resources, or capacity to conduct research that is generalisable or rigorous enough to advance the discipline. As a result, research methods that enable sense-making with larger volumes of qualitative data, while not increasing the burden on the researcher, have significant potential within CER. In this discussion paper, we propose such a method for conducting rigorous analysis on large volumes of textual data, namely a variation of LLM-assisted content analysis (LACA). This method combines content analysis with the use of large language models, empowering researchers to conduct larger-scale research which they would otherwise not be able to perform. Using a computing education dataset, we illustrate how LACA could be applied in a reproducible and rigorous manner. We believe this method has potential in CER, enabling more generalisable findings from a wider range of research. This, together with the development of similar methods, can help to advance both the practice and research quality of the CER discipline.</li>
</ul>

<h3>Title: HAEPO: History-Aggregated Exploratory Policy Optimization</h3>
<ul>
<li><strong>Authors: </strong>Gaurish Trivedi, Alakh Sharma, Kartikey Singh Bhandari, Dhruv Kumar, Pratik Narang, Jagat Sesh Challa</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.18884">https://arxiv.org/abs/2508.18884</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.18884">https://arxiv.org/pdf/2508.18884</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.18884]] HAEPO: History-Aggregated Exploratory Policy Optimization(https://arxiv.org/abs/2508.18884)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, large language model</a></li>
<li><strong>Abstract: </strong>Exploration is essential in modern learning, from reinforcement learning environments with small neural policies to large language models (LLMs). Existing work, such as DPO, leverages full sequence log-likelihoods to capture an entire trajectory of the model's decisions, while methods like GRPO aggregate per-token ratios into a trajectory-level update. However, both often limit exploration on long-horizon tasks. We introduce History-Aggregated Exploratory Policy Optimization (HAEPO), a history-aware exploratory loss to combat these shortcomings. HAEPO compresses each trajectory into the sum of its logarithmic probabilities (a cumulative logarithmic likelihood), and applies a Plackett-Luce softmax across trajectories to obtain normalized weights proportional to their returns, thus encouraging broader exploration. We add entropy regularization to stabilize the aggressive updates to prevent premature collapse and a soft KL penalty relative to a frozen copy of the previous (reference) policy. Empirically, HAEPO converges fast, explores thoroughly, aligns closely with true rewards, and demonstrates robust learning behavior better or at par with PPO, GRPO, and DPO across diverse tasks. Thus, HAEPO provides a stable and interpretable framework by explicitly leveraging full-trajectory history while balancing exploration and stability.</li>
</ul>

<h3>Title: Toward Robust Medical Fairness: Debiased Dual-Modal Alignment via Text-Guided Attribute-Disentangled Prompt Learning for Vision-Language Models</h3>
<ul>
<li><strong>Authors: </strong>Yuexuan Xia, Benteng Ma, Jiang He, Zhiyong Wang, Qi Dou, Yong Xia</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.18886">https://arxiv.org/abs/2508.18886</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.18886">https://arxiv.org/pdf/2508.18886</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.18886]] Toward Robust Medical Fairness: Debiased Dual-Modal Alignment via Text-Guided Attribute-Disentangled Prompt Learning for Vision-Language Models(https://arxiv.org/abs/2508.18886)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, fair</a></li>
<li><strong>Abstract: </strong>Ensuring fairness across demographic groups in medical diagnosis is essential for equitable healthcare, particularly under distribution shifts caused by variations in imaging equipment and clinical practice. Vision-language models (VLMs) exhibit strong generalization, and text prompts encode identity attributes, enabling explicit identification and removal of sensitive directions. However, existing debiasing approaches typically address vision and text modalities independently, leaving residual cross-modal misalignment and fairness gaps. To address this challenge, we propose DualFairVL, a multimodal prompt-learning framework that jointly debiases and aligns cross-modal representations. DualFairVL employs a parallel dual-branch architecture that separates sensitive and target attributes, enabling disentangled yet aligned representations across modalities. Approximately orthogonal text anchors are constructed via linear projections, guiding cross-attention mechanisms to produce fused features. A hypernetwork further disentangles attribute-related information and generates instance-aware visual prompts, which encode dual-modal cues for fairness and robustness. Prototype-based regularization is applied in the visual branch to enforce separation of sensitive features and strengthen alignment with textual anchors. Extensive experiments on eight medical imaging datasets across four modalities show that DualFairVL achieves state-of-the-art fairness and accuracy under both in- and out-of-distribution settings, outperforming full fine-tuning and parameter-efficient baselines with only 3.6M trainable parameters. Code will be released upon publication.</li>
</ul>

<h3>Title: pyFAST: A Modular PyTorch Framework for Time Series Modeling with Multi-source and Sparse Data</h3>
<ul>
<li><strong>Authors: </strong>Zhijin Wang, Senzhen Wu, Yue Hu, Xiufeng Liu</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.18891">https://arxiv.org/abs/2508.18891</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.18891">https://arxiv.org/pdf/2508.18891</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.18891]] pyFAST: A Modular PyTorch Framework for Time Series Modeling with Multi-source and Sparse Data(https://arxiv.org/abs/2508.18891)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Modern time series analysis demands frameworks that are flexible, efficient, and extensible. However, many existing Python libraries exhibit limitations in modularity and in their native support for irregular, multi-source, or sparse data. We introduce pyFAST, a research-oriented PyTorch framework that explicitly decouples data processing from model computation, fostering a cleaner separation of concerns and facilitating rapid experimentation. Its data engine is engineered for complex scenarios, supporting multi-source loading, protein sequence handling, efficient sequence- and patch-level padding, dynamic normalization, and mask-based modeling for both imputation and forecasting. pyFAST integrates LLM-inspired architectures for the alignment-free fusion of sparse data sources and offers native sparse metrics, specialized loss functions, and flexible exogenous data fusion. Training utilities include batch-based streaming aggregation for evaluation and device synergy to maximize computational efficiency. A comprehensive suite of classical and deep learning models (Linears, CNNs, RNNs, Transformers, and GNNs) is provided within a modular architecture that encourages extension. Released under the MIT license at GitHub, pyFAST provides a compact yet powerful platform for advancing time series research and applications.</li>
</ul>

<h3>Title: Interpretable Decision-Making for End-to-End Autonomous Driving</h3>
<ul>
<li><strong>Authors: </strong>Mona Mirzaie, Bodo Rosenhahn</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI, cs.LG, cs.RO</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.18898">https://arxiv.org/abs/2508.18898</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.18898">https://arxiv.org/pdf/2508.18898</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.18898]] Interpretable Decision-Making for End-to-End Autonomous Driving(https://arxiv.org/abs/2508.18898)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction, interpretability</a></li>
<li><strong>Abstract: </strong>Trustworthy AI is mandatory for the broad deployment of autonomous vehicles. Although end-to-end approaches derive control commands directly from raw data, interpreting these decisions remains challenging, especially in complex urban scenarios. This is mainly attributed to very deep neural networks with non-linear decision boundaries, making it challenging to grasp the logic behind AI-driven decisions. This paper presents a method to enhance interpretability while optimizing control commands in autonomous driving. To address this, we propose loss functions that promote the interpretability of our model by generating sparse and localized feature maps. The feature activations allow us to explain which image regions contribute to the predicted control command. We conduct comprehensive ablation studies on the feature extraction step and validate our method on the CARLA benchmarks. We also demonstrate that our approach improves interpretability, which correlates with reducing infractions, yielding a safer, high-performance driving model. Notably, our monocular, non-ensemble model surpasses the top-performing approaches from the CARLA Leaderboard by achieving lower infraction scores and the highest route completion rate, all while ensuring interpretability.</li>
</ul>

<h3>Title: Event-Enriched Image Analysis Grand Challenge at ACM Multimedia 2025</h3>
<ul>
<li><strong>Authors: </strong>Thien-Phuc Tran, Minh-Quang Nguyen, Minh-Triet Tran, Tam V. Nguyen, Trong-Le Do, Duy-Nam Ly, Viet-Tham Huynh, Khanh-Duy Le, Mai-Khiem Tran, Trung-Nghia Le</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.18904">https://arxiv.org/abs/2508.18904</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.18904">https://arxiv.org/pdf/2508.18904</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.18904]] Event-Enriched Image Analysis Grand Challenge at ACM Multimedia 2025(https://arxiv.org/abs/2508.18904)</code><input type="text"></li>
<li><strong>Keywords: </strong>fair</a></li>
<li><strong>Abstract: </strong>The Event-Enriched Image Analysis (EVENTA) Grand Challenge, hosted at ACM Multimedia 2025, introduces the first large-scale benchmark for event-level multimodal understanding. Traditional captioning and retrieval tasks largely focus on surface-level recognition of people, objects, and scenes, often overlooking the contextual and semantic dimensions that define real-world events. EVENTA addresses this gap by integrating contextual, temporal, and semantic information to capture the who, when, where, what, and why behind an image. Built upon the OpenEvents V1 dataset, the challenge features two tracks: Event-Enriched Image Retrieval and Captioning, and Event-Based Image Retrieval. A total of 45 teams from six countries participated, with evaluation conducted through Public and Private Test phases to ensure fairness and reproducibility. The top three teams were invited to present their solutions at ACM Multimedia 2025. EVENTA establishes a foundation for context-aware, narrative-driven multimedia AI, with applications in journalism, media analysis, cultural archiving, and accessibility. Further details about the challenge are available at the official homepage: this https URL.</li>
</ul>

<h3>Title: Enhancing Model Privacy in Federated Learning with Random Masking and Quantization</h3>
<ul>
<li><strong>Authors: </strong>Zhibo Xu, Jianhao Zhu, Jingwen Xu, Changze Lv, Zisu Huang, Xiaohua Wang, Muling Wu, Qi Qian, Xiaoqing Zheng, Xuanjing Huang</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.18911">https://arxiv.org/abs/2508.18911</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.18911">https://arxiv.org/pdf/2508.18911</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.18911]] Enhancing Model Privacy in Federated Learning with Random Masking and Quantization(https://arxiv.org/abs/2508.18911)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, protect, federate</a></li>
<li><strong>Abstract: </strong>Experimental results across various models and tasks demonstrate that our approach not only maintains strong model performance in federated learning settings but also achieves enhanced protection of model parameters compared to baseline methods.</li>
</ul>

<h3>Title: Diverse And Private Synthetic Datasets Generation for RAG evaluation: A multi-agent framework</h3>
<ul>
<li><strong>Authors: </strong>Ilias Driouich, Hongliu Cao, Eoin Thomas</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.18929">https://arxiv.org/abs/2508.18929</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.18929">https://arxiv.org/pdf/2508.18929</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.18929]] Diverse And Private Synthetic Datasets Generation for RAG evaluation: A multi-agent framework(https://arxiv.org/abs/2508.18929)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, protect, robust, large language model</a></li>
<li><strong>Abstract: </strong>Retrieval-augmented generation (RAG) systems improve large language model outputs by incorporating external knowledge, enabling more informed and context-aware responses. However, the effectiveness and trustworthiness of these systems critically depends on how they are evaluated, particularly on whether the evaluation process captures real-world constraints like protecting sensitive information. While current evaluation efforts for RAG systems have primarily focused on the development of performance metrics, far less attention has been given to the design and quality of the underlying evaluation datasets, despite their pivotal role in enabling meaningful, reliable assessments. In this work, we introduce a novel multi-agent framework for generating synthetic QA datasets for RAG evaluation that prioritize semantic diversity and privacy preservation. Our approach involves: (1) a Diversity agent leveraging clustering techniques to maximize topical coverage and semantic variability, (2) a Privacy Agent that detects and mask sensitive information across multiple domains and (3) a QA curation agent that synthesizes private and diverse QA pairs suitable as ground truth for RAG evaluation. Extensive experiments demonstrate that our evaluation sets outperform baseline methods in diversity and achieve robust privacy masking on domain-specific datasets. This work offers a practical and ethically aligned pathway toward safer, more comprehensive RAG system evaluation, laying the foundation for future enhancements aligned with evolving AI regulations and compliance standards.</li>
</ul>

<h3>Title: Preliminary Study on Space Utilization and Emergent Behaviors of Group vs. Single Pedestrians in Real-World Trajectories</h3>
<ul>
<li><strong>Authors: </strong>Amartaivan Sanjjamts, Morita Hiroshi</a></li>
<li><strong>Subjects: </strong>cs.CV, stat.AP</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.18939">https://arxiv.org/abs/2508.18939</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.18939">https://arxiv.org/pdf/2508.18939</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.18939]] Preliminary Study on Space Utilization and Emergent Behaviors of Group vs. Single Pedestrians in Real-World Trajectories(https://arxiv.org/abs/2508.18939)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>This study presents an initial framework for distinguishing group and single pedestrians based on real-world trajectory data, with the aim of analyzing their differences in space utilization and emergent behavioral patterns. By segmenting pedestrian trajectories into fixed time bins and applying a Transformer-based pair classification model, we identify cohesive groups and isolate single pedestrians over a structured sequence-based filtering process. To prepare for deeper analysis, we establish a comprehensive metric framework incorporating both spatial and behavioral dimensions. Spatial utilization metrics include convex hull area, smallest enclosing circle radius, and heatmap-based spatial densities to characterize how different pedestrian types occupy and interact with space. Behavioral metrics such as velocity change, motion angle deviation, clearance radius, and trajectory straightness are designed to capture local adaptations and responses during interactions. Furthermore, we introduce a typology of encounter types-single-to-single, single-to-group, and group-to-group to categorize and later quantify different interaction scenarios. Although this version focuses primarily on the classification pipeline and dataset structuring, it establishes the groundwork for scalable analysis across different sequence lengths 60, 100, and 200 frames. Future versions will incorporate complete quantitative analysis of the proposed metrics and their implications for pedestrian simulation and space design validation in crowd dynamics research.</li>
</ul>

<h3>Title: EnerSwap: Large-Scale, Privacy-First Automated Market Maker for V2G Energy Trading</h3>
<ul>
<li><strong>Authors: </strong>Ahmed Mounsf Rafik Bendada, Yacine Ghamri-Doudane</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.18942">https://arxiv.org/abs/2508.18942</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.18942">https://arxiv.org/pdf/2508.18942</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.18942]] EnerSwap: Large-Scale, Privacy-First Automated Market Maker for V2G Energy Trading(https://arxiv.org/abs/2508.18942)</code><input type="text"></li>
<li><strong>Keywords: </strong>secure, privacy, protect, attack, fair</a></li>
<li><strong>Abstract: </strong>With the rapid growth of Electric Vehicle (EV) technology, EVs are destined to shape the future of transportation. The large number of EVs facilitates the development of the emerging vehicle-to-grid (V2G) technology, which realizes bidirectional energy exchanges between EVs and the power grid. This has led to the setting up of electricity markets that are usually confined to a small geographical location, often with a small number of participants. Usually, these markets are manipulated by intermediaries responsible for collecting bids from prosumers, determining the market-clearing price, incorporating grid constraints, and accounting for network losses. While centralized models can be highly efficient, they grant excessive power to the intermediary by allowing them to gain exclusive access to prosumers \textquotesingle price preferences. This opens the door to potential market manipulation and raises significant privacy concerns for users, such as the location of energy providers. This lack of protection exposes users to potential risks, as untrustworthy servers and malicious adversaries can exploit this information to infer trading activities and real identities. This work proposes a secure, decentralized exchange market built on blockchain technology, utilizing a privacy-preserving Automated Market Maker (AMM) model to offer open and fair, and equal access to traders, and mitigates the most common trading-manipulation attacks. Additionally, it incorporates a scalable architecture based on geographical dynamic sharding, allowing for efficient resource allocation and improved performance as the market grows.</li>
</ul>

<h3>Title: LLMs in the SOC: An Empirical Study of Human-AI Collaboration in Security Operations Centres</h3>
<ul>
<li><strong>Authors: </strong>Ronal Singh, Shahroz Tariq, Fatemeh Jalalvand, Mohan Baruwal Chhetri, Surya Nepal, Cecile Paris, Martin Lochner</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.18947">https://arxiv.org/abs/2508.18947</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.18947">https://arxiv.org/pdf/2508.18947</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.18947]] LLMs in the SOC: An Empirical Study of Human-AI Collaboration in Security Operations Centres(https://arxiv.org/abs/2508.18947)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, large language model</a></li>
<li><strong>Abstract: </strong>The integration of Large Language Models (LLMs) into Security Operations Centres (SOCs) presents a transformative, yet still evolving, opportunity to reduce analyst workload through human-AI collaboration. However, their real-world application in SOCs remains underexplored. To address this gap, we present a longitudinal study of 3,090 analyst queries from 45 SOC analysts over 10 months. Our analysis reveals that analysts use LLMs as on-demand aids for sensemaking and context-building, rather than for making high-stakes determinations, preserving analyst decision authority. The majority of queries are related to interpreting low-level telemetry (e.g., commands) and refining technical communication through short (1-3 turn) interactions. Notably, 93% of queries align with established cybersecurity competencies (NICE Framework), underscoring the relevance of LLM use for SOC-related tasks. Despite variations in tasks and engagement, usage trends indicate a shift from occasional exploration to routine integration, with growing adoption and sustained use among a subset of analysts. We find that LLMs function as flexible, on-demand cognitive aids that augment, rather than replace, SOC expertise. Our study provides actionable guidance for designing context-aware, human-centred AI assistance in security operations, highlighting the need for further in-the-wild research on real-world analyst-LLM collaboration, challenges, and impacts.</li>
</ul>

<h3>Title: Energy-Based Flow Matching for Generating 3D Molecular Structure</h3>
<ul>
<li><strong>Authors: </strong>Wenyin Zhou, Christopher Iliffe Sprague, Vsevolod Viliuga, Matteo Tadiello, Arne Elofsson, Hossein Azizpour</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.18949">https://arxiv.org/abs/2508.18949</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.18949">https://arxiv.org/pdf/2508.18949</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.18949]] Energy-Based Flow Matching for Generating 3D Molecular Structure(https://arxiv.org/abs/2508.18949)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, generative</a></li>
<li><strong>Abstract: </strong>Molecular structure generation is a fundamental problem that involves determining the 3D positions of molecules' constituents. It has crucial biological applications, such as molecular docking, protein folding, and molecular design. Recent advances in generative modeling, such as diffusion models and flow matching, have made great progress on these tasks by modeling molecular conformations as a distribution. In this work, we focus on flow matching and adopt an energy-based perspective to improve training and inference of structure generation models. Our view results in a mapping function, represented by a deep network, that is directly learned to \textit{iteratively} map random configurations, i.e. samples from the source distribution, to target structures, i.e. points in the data manifold. This yields a conceptually simple and empirically effective flow matching setup that is theoretically justified and has interesting connections to fundamental properties such as idempotency and stability, as well as the empirically useful techniques such as structure refinement in AlphaFold. Experiments on protein docking as well as protein backbone generation consistently demonstrate the method's effectiveness, where it outperforms recent baselines of task-associated flow matching and diffusion models, using a similar computational budget.</li>
</ul>

<h3>Title: On the Generalisation of Koopman Representations for Chaotic System Control</h3>
<ul>
<li><strong>Authors: </strong>Kyriakos Hjikakou (1), Juan Diego Cardenas Cartagena (1), Matthia Sabatelli (1) ((1) University of Groningen, Department of Artificial Intelligence, Groningen, Netherlands)</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.18954">https://arxiv.org/abs/2508.18954</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.18954">https://arxiv.org/pdf/2508.18954</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.18954]] On the Generalisation of Koopman Representations for Chaotic System Control(https://arxiv.org/abs/2508.18954)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>This paper investigates the generalisability of Koopman-based representations for chaotic dynamical systems, focusing on their transferability across prediction and control tasks. Using the Lorenz system as a testbed, we propose a three-stage methodology: learning Koopman embeddings through autoencoding, pre-training a transformer on next-state prediction, and fine-tuning for safety-critical control. Our results show that Koopman embeddings outperform both standard and physics-informed PCA baselines, achieving accurate and data-efficient performance. Notably, fixing the pre-trained transformer weights during fine-tuning leads to no performance degradation, indicating that the learned representations capture reusable dynamical structure rather than task-specific patterns. These findings support the use of Koopman embeddings as a foundation for multi-task learning in physics-informed machine learning. A project page is available at this https URL.</li>
</ul>

<h3>Title: The point is the mask: scaling coral reef segmentation with weak supervision</h3>
<ul>
<li><strong>Authors: </strong>Matteo Contini, Victor Illien, Sylvain Poulain, Serge Bernard, Julien Barde, Sylvain Bonhommeau, Alexis Joly</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.18958">https://arxiv.org/abs/2508.18958</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.18958">https://arxiv.org/pdf/2508.18958</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.18958]] The point is the mask: scaling coral reef segmentation with weak supervision(https://arxiv.org/abs/2508.18958)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>Monitoring coral reefs at large spatial scales remains an open challenge, essential for assessing ecosystem health and informing conservation efforts. While drone-based aerial imagery offers broad spatial coverage, its limited resolution makes it difficult to reliably distinguish fine-scale classes, such as coral morphotypes. At the same time, obtaining pixel-level annotations over large spatial extents is costly and labor-intensive, limiting the scalability of deep learning-based segmentation methods for aerial imagery. We present a multi-scale weakly supervised semantic segmentation framework that addresses this challenge by transferring fine-scale ecological information from underwater imagery to aerial data. Our method enables large-scale coral reef mapping from drone imagery with minimal manual annotation, combining classification-based supervision, spatial interpolation and self-distillation techniques. We demonstrate the efficacy of the approach, enabling large-area segmentation of coral morphotypes and demonstrating flexibility for integrating new classes. This study presents a scalable, cost-effective methodology for high-resolution reef monitoring, combining low-cost data collection, weakly supervised deep learning and multi-scale remote sensing.</li>
</ul>

<h3>Title: Generative AI in Map-Making: A Technical Exploration and Its Implications for Cartographers</h3>
<ul>
<li><strong>Authors: </strong>Claudio Affolter, Sidi Wu, Yizi Chen, Lorenz Hurni</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.18959">https://arxiv.org/abs/2508.18959</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.18959">https://arxiv.org/pdf/2508.18959</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.18959]] Generative AI in Map-Making: A Technical Exploration and Its Implications for Cartographers(https://arxiv.org/abs/2508.18959)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, generative</a></li>
<li><strong>Abstract: </strong>Traditional map-making relies heavily on Geographic Information Systems (GIS), requiring domain expertise and being time-consuming, especially for repetitive tasks. Recent advances in generative AI (GenAI), particularly image diffusion models, offer new opportunities for automating and democratizing the map-making process. However, these models struggle with accurate map creation due to limited control over spatial composition and semantic layout. To address this, we integrate vector data to guide map generation in different styles, specified by the textual prompts. Our model is the first to generate accurate maps in controlled styles, and we have integrated it into a web application to improve its usability and accessibility. We conducted a user study with professional cartographers to assess the fidelity of generated maps, the usability of the web application, and the implications of ever-emerging GenAI in map-making. The findings have suggested the potential of our developed application and, more generally, the GenAI models in helping both non-expert users and professionals in creating maps more efficiently. We have also outlined further technical improvements and emphasized the new role of cartographers to advance the paradigm of AI-assisted map-making.</li>
</ul>

<h3>Title: Enhancing compact convolutional transformers with super attention</h3>
<ul>
<li><strong>Authors: </strong>Simpenzwe Honore Leandre, Natenaile Asmamaw Shiferaw, Dillip Rout</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.18960">https://arxiv.org/abs/2508.18960</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.18960">https://arxiv.org/pdf/2508.18960</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.18960]] Enhancing compact convolutional transformers with super attention(https://arxiv.org/abs/2508.18960)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>In this paper, we propose a vision model that adopts token mixing, sequence-pooling, and convolutional tokenizers to achieve state-of-the-art performance and efficient inference in fixed context-length tasks. In the CIFAR100 benchmark, our model significantly improves the baseline of the top 1% and top 5% validation accuracy from 36.50% to 46.29% and 66.33% to 76.31%, while being more efficient than the Scaled Dot Product Attention (SDPA) transformers when the context length is less than the embedding dimension and only 60% the size. In addition, the architecture demonstrates high training stability and does not rely on techniques such as data augmentation like mixup, positional embeddings, or learning rate scheduling. We make our code available on Github.</li>
</ul>

<h3>Title: Can we make NeRF-based visual localization privacy-preserving?</h3>
<ul>
<li><strong>Authors: </strong>Maxime Pietrantoni, Martin Humenberger, Torsten Sattler, Gabriela Csurka</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.18971">https://arxiv.org/abs/2508.18971</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.18971">https://arxiv.org/pdf/2508.18971</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.18971]] Can we make NeRF-based visual localization privacy-preserving?(https://arxiv.org/abs/2508.18971)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, attack, segmentation</a></li>
<li><strong>Abstract: </strong>Visual localization (VL) is the task of estimating the camera pose in a known scene. VL methods, a.o., can be distinguished based on how they represent the scene, e.g., explicitly through a (sparse) point cloud or a collection of images or implicitly through the weights of a neural network. Recently, NeRF-based methods have become popular for VL. While NeRFs offer high-quality novel view synthesis, they inadvertently encode fine scene details, raising privacy concerns when deployed in cloud-based localization services as sensitive information could be recovered. In this paper, we tackle this challenge on two ends. We first propose a new protocol to assess privacy-preservation of NeRF-based representations. We show that NeRFs trained with photometric losses store fine-grained details in their geometry representations, making them vulnerable to privacy attacks, even if the head that predicts colors is removed. Second, we propose ppNeSF (Privacy-Preserving Neural Segmentation Field), a NeRF variant trained with segmentation supervision instead of RGB images. These segmentation labels are learned in a self-supervised manner, ensuring they are coarse enough to obscure identifiable scene details while remaining discriminativeness in 3D. The segmentation space of ppNeSF can be used for accurate visual localization, yielding state-of-the-art results.</li>
</ul>

<h3>Title: Understanding Benefits and Pitfalls of Current Methods for the Segmentation of Undersampled MRI Data</h3>
<ul>
<li><strong>Authors: </strong>Jan Nikolas Morshuis, Matthias Hein, Christian F. Baumgartner</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.18975">https://arxiv.org/abs/2508.18975</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.18975">https://arxiv.org/pdf/2508.18975</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.18975]] Understanding Benefits and Pitfalls of Current Methods for the Segmentation of Undersampled MRI Data(https://arxiv.org/abs/2508.18975)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>MR imaging is a valuable diagnostic tool allowing to non-invasively visualize patient anatomy and pathology with high soft-tissue contrast. However, MRI acquisition is typically time-consuming, leading to patient discomfort and increased costs to the healthcare system. Recent years have seen substantial research effort into the development of methods that allow for accelerated MRI acquisition while still obtaining a reconstruction that appears similar to the fully-sampled MR image. However, for many applications a perfectly reconstructed MR image may not be necessary, particularly, when the primary goal is a downstream task such as segmentation. This has led to growing interest in methods that aim to perform segmentation directly on accelerated MRI data. Despite recent advances, existing methods have largely been developed in isolation, without direct comparison to one another, often using separate or private datasets, and lacking unified evaluation standards. To date, no high-quality, comprehensive comparison of these methods exists, and the optimal strategy for segmenting accelerated MR data remains unknown. This paper provides the first unified benchmark for the segmentation of undersampled MRI data comparing 7 approaches. A particular focus is placed on comparing \textit{one-stage approaches}, that combine reconstruction and segmentation into a unified model, with \textit{two-stage approaches}, that utilize established MRI reconstruction methods followed by a segmentation network. We test these methods on two MRI datasets that include multi-coil k-space data as well as a human-annotated segmentation ground-truth. We find that simple two-stage methods that consider data-consistency lead to the best segmentation scores, surpassing complex specialized methods that are developed specifically for this task.</li>
</ul>

<h3>Title: The Double-edged Sword of LLM-based Data Reconstruction: Understanding and Mitigating Contextual Vulnerability in Word-level Differential Privacy Text Sanitization</h3>
<ul>
<li><strong>Authors: </strong>Stephen Meisenbacher, Alexandra Klymenko, Andreea-Elena Bodea, Florian Matthes</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.18976">https://arxiv.org/abs/2508.18976</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.18976">https://arxiv.org/pdf/2508.18976</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.18976]] The Double-edged Sword of LLM-based Data Reconstruction: Understanding and Mitigating Contextual Vulnerability in Word-level Differential Privacy Text Sanitization(https://arxiv.org/abs/2508.18976)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, protect, attack, large language model</a></li>
<li><strong>Abstract: </strong>Differentially private text sanitization refers to the process of privatizing texts under the framework of Differential Privacy (DP), providing provable privacy guarantees while also empirically defending against adversaries seeking to harm privacy. Despite their simplicity, DP text sanitization methods operating at the word level exhibit a number of shortcomings, among them the tendency to leave contextual clues from the original texts due to randomization during sanitization $\unicode{x2013}$ this we refer to as $\textit{contextual vulnerability}$. Given the powerful contextual understanding and inference capabilities of Large Language Models (LLMs), we explore to what extent LLMs can be leveraged to exploit the contextual vulnerability of DP-sanitized texts. We expand on previous work not only in the use of advanced LLMs, but also in testing a broader range of sanitization mechanisms at various privacy levels. Our experiments uncover a double-edged sword effect of LLM-based data reconstruction attacks on privacy and utility: while LLMs can indeed infer original semantics and sometimes degrade empirical privacy protections, they can also be used for good, to improve the quality and privacy of DP-sanitized texts. Based on our findings, we propose recommendations for using LLM data reconstruction as a post-processing step, serving to increase privacy protection by thinking adversarially.</li>
</ul>

<h3>Title: PAX-TS: Model-agnostic multi-granular explanations for time series forecasting via localized perturbations</h3>
<ul>
<li><strong>Authors: </strong>Tim Kreuzer, Jelena Zdravkovic, Panagiotis Papapetrou</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.18982">https://arxiv.org/abs/2508.18982</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.18982">https://arxiv.org/pdf/2508.18982</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.18982]] PAX-TS: Model-agnostic multi-granular explanations for time series forecasting via localized perturbations(https://arxiv.org/abs/2508.18982)</code><input type="text"></li>
<li><strong>Keywords: </strong>explainability, transformer, large language model</a></li>
<li><strong>Abstract: </strong>Time series forecasting has seen considerable improvement during the last years, with transformer models and large language models driving advancements of the state of the art. Modern forecasting models are generally opaque and do not provide explanations for their forecasts, while well-known post-hoc explainability methods like LIME are not suitable for the forecasting context. We propose PAX-TS, a model-agnostic post-hoc algorithm to explain time series forecasting models and their forecasts. Our method is based on localized input perturbations and results in multi-granular explanations. Further, it is able to characterize cross-channel correlations for multivariate time series forecasts. We clearly outline the algorithmic procedure behind PAX-TS, demonstrate it on a benchmark with 7 algorithms and 10 diverse datasets, compare it with two other state-of-the-art explanation algorithms, and present the different explanation types of the method. We found that the explanations of high-performing and low-performing algorithms differ on the same datasets, highlighting that the explanations of PAX-TS effectively capture a model's behavior. Based on time step correlation matrices resulting from the benchmark, we identify 6 classes of patterns that repeatedly occur across different datasets and algorithms. We found that the patterns are indicators of performance, with noticeable differences in forecasting error between the classes. Lastly, we outline a multivariate example where PAX-TS demonstrates how the forecasting model takes cross-channel correlations into account. With PAX-TS, time series forecasting models' mechanisms can be illustrated in different levels of detail, and its explanations can be used to answer practical questions on forecasts.</li>
</ul>

<h3>Title: Enhancing Document VQA Models via Retrieval-Augmented Generation</h3>
<ul>
<li><strong>Authors: </strong>Eric LÃ³pez, Artemis LlabrÃ©s, Ernest Valveny</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.18984">https://arxiv.org/abs/2508.18984</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.18984">https://arxiv.org/pdf/2508.18984</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.18984]] Enhancing Document VQA Models via Retrieval-Augmented Generation(https://arxiv.org/abs/2508.18984)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction</a></li>
<li><strong>Abstract: </strong>Document Visual Question Answering (Document VQA) must cope with documents that span dozens of pages, yet leading systems still concatenate every page or rely on very large vision-language models, both of which are memory-hungry. Retrieval-Augmented Generation (RAG) offers an attractive alternative, first retrieving a concise set of relevant segments before generating answers from this selected evidence. In this paper, we systematically evaluate the impact of incorporating RAG into Document VQA through different retrieval variants - text-based retrieval using OCR tokens and purely visual retrieval without OCR - across multiple models and benchmarks. Evaluated on the multi-page datasets MP-DocVQA, DUDE, and InfographicVQA, the text-centric variant improves the "concatenate-all-pages" baseline by up to +22.5 ANLS, while the visual variant achieves +5.0 ANLS improvement without requiring any text extraction. An ablation confirms that retrieval and reranking components drive most of the gain, whereas the layout-guided chunking strategy - proposed in several recent works to leverage page structure - fails to help on these datasets. Our experiments demonstrate that careful evidence selection consistently boosts accuracy across multiple model sizes and multi-page benchmarks, underscoring its practical value for real-world Document VQA.</li>
</ul>

<h3>Title: Interpretable by AI Mother Tongue: Native Symbolic Reasoning in Neural Models</h3>
<ul>
<li><strong>Authors: </strong>Hung Ming Liu</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.18988">https://arxiv.org/abs/2508.18988</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.18988">https://arxiv.org/pdf/2508.18988</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.18988]] Interpretable by AI Mother Tongue: Native Symbolic Reasoning in Neural Models(https://arxiv.org/abs/2508.18988)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability</a></li>
<li><strong>Abstract: </strong>We present a framework where neural models develop an AI Mother Tongue, a native symbolic language that simultaneously supports intuitive reasoning, compositional symbol chains, and inherent interpretability. Unlike post-hoc explanation methods, our approach embeds reasoning directly into the model's representations: symbols capture meaningful semantic patterns, chains trace decision paths, and gated induction mechanisms guide selective focus, yielding transparent yet flexible reasoning. We introduce complementary training objectives to enhance symbol purity and decision sparsity, and employ a sequential specialization strategy to first build broad symbolic competence and then refine intuitive judgments. Experiments on AI tasks demonstrate competitive accuracy alongside verifiable reasoning traces, showing that AI Mother Tongue can serve as a unified mechanism for interpretability, intuition, and symbolic reasoning in neural models.</li>
</ul>

<h3>Title: Automatic Prompt Optimization with Prompt Distillation</h3>
<ul>
<li><strong>Authors: </strong>Viktor N. Zhuravlev, Artur R. Khairullin, Ernest A. Dyagin, Alena N. Sitkina, Nikita I. Kulin</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.18992">https://arxiv.org/abs/2508.18992</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.18992">https://arxiv.org/pdf/2508.18992</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.18992]] Automatic Prompt Optimization with Prompt Distillation(https://arxiv.org/abs/2508.18992)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Autoprompting is the process of automatically selecting optimized prompts for language models, which is gaining popularity due to the rapid development of prompt engineering driven by extensive research in the field of large language models (LLMs). This paper presents DistillPrompt -- a novel autoprompting method based on large language models that employs a multi-stage integration of task-specific information into prompts using training data. DistillPrompt utilizes distillation, compression, and aggregation operations to explore the prompt space more thoroughly. The method was tested on different datasets for text classification and generation tasks using the t-lite-instruct-0.1 language model. The results demonstrate a significant average improvement (e.g., 20.12% across the entire dataset compared to Grips) in key metrics over existing methods in the field, establishing DistillPrompt as one of the most effective non-gradient approaches in autoprompting.</li>
</ul>

<h3>Title: RoofSeg: An edge-aware transformer-based network for end-to-end roof plane segmentation</h3>
<ul>
<li><strong>Authors: </strong>Siyuan You, Guozheng Xu, Pengwei Zhou, Qiwen Jin, Jian Yao, Li Li</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.19003">https://arxiv.org/abs/2508.19003</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.19003">https://arxiv.org/pdf/2508.19003</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.19003]] RoofSeg: An edge-aware transformer-based network for end-to-end roof plane segmentation(https://arxiv.org/abs/2508.19003)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer, segmentation</a></li>
<li><strong>Abstract: </strong>Roof plane segmentation is one of the key procedures for reconstructing three-dimensional (3D) building models at levels of detail (LoD) 2 and 3 from airborne light detection and ranging (LiDAR) point clouds. The majority of current approaches for roof plane segmentation rely on the manually designed or learned features followed by some specifically designed geometric clustering strategies. Because the learned features are more powerful than the manually designed features, the deep learning-based approaches usually perform better than the traditional approaches. However, the current deep learning-based approaches have three unsolved problems. The first is that most of them are not truly end-to-end, the plane segmentation results may be not optimal. The second is that the point feature discriminability near the edges is relatively low, leading to inaccurate planar edges. The third is that the planar geometric characteristics are not sufficiently considered to constrain the network training. To solve these issues, a novel edge-aware transformer-based network, named RoofSeg, is developed for segmenting roof planes from LiDAR point clouds in a truly end-to-end manner. In the RoofSeg, we leverage a transformer encoder-decoder-based framework to hierarchically predict the plane instance masks with the use of a set of learnable plane queries. To further improve the segmentation accuracy of edge regions, we also design an Edge-Aware Mask Module (EAMM) that sufficiently incorporates planar geometric prior of edges to enhance its discriminability for plane instance mask refinement. In addition, we propose an adaptive weighting strategy in the mask loss to reduce the influence of misclassified points, and also propose a new plane geometric loss to constrain the network training.</li>
</ul>

<h3>Title: FedProtoKD: Dual Knowledge Distillation with Adaptive Class-wise Prototype Margin for Heterogeneous Federated Learning</h3>
<ul>
<li><strong>Authors: </strong>Md Anwar Hossen, Fatema Siddika, Wensheng Zhang, Anuj Sharma, Ali Jannesari</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.DC</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.19009">https://arxiv.org/abs/2508.19009</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.19009">https://arxiv.org/pdf/2508.19009</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.19009]] FedProtoKD: Dual Knowledge Distillation with Adaptive Class-wise Prototype Margin for Heterogeneous Federated Learning(https://arxiv.org/abs/2508.19009)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, federate</a></li>
<li><strong>Abstract: </strong>Heterogeneous Federated Learning (HFL) has gained attention for its ability to accommodate diverse models and heterogeneous data across clients. Prototype-based HFL methods emerge as a promising solution to address statistical heterogeneity and privacy challenges, paving the way for new advancements in HFL research. This method focuses on sharing only class-representative prototypes among heterogeneous clients. However, these prototypes are often aggregated on the server using weighted averaging, leading to sub-optimal global knowledge; these cause the shrinking of aggregated prototypes, which negatively affects the model performance in scenarios when models are heterogeneous and data distributions are extremely non-IID. We propose FedProtoKD in a Heterogeneous Federated Learning setting, using an enhanced dual-knowledge distillation mechanism to improve the system performance with clients' logits and prototype feature representation. We aim to resolve the prototype margin-shrinking problem using a contrastive learning-based trainable server prototype by leveraging a class-wise adaptive prototype margin. Furthermore, we assess the importance of public samples using the closeness of the sample's prototype to its class representative prototypes, which enhances learning performance. FedProtoKD achieved average improvements of 1.13% up to 34.13% accuracy across various settings and significantly outperforms existing state-of-the-art HFL methods.</li>
</ul>

<h3>Title: STDiff: A State Transition Diffusion Framework for Time Series Imputation in Industrial Systems</h3>
<ul>
<li><strong>Authors: </strong>Gary Simethy, Daniel Ortiz-Arroyo, Petar Durdevic</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.19011">https://arxiv.org/abs/2508.19011</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.19011">https://arxiv.org/pdf/2508.19011</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.19011]] STDiff: A State Transition Diffusion Framework for Time Series Imputation in Industrial Systems(https://arxiv.org/abs/2508.19011)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, diffusion</a></li>
<li><strong>Abstract: </strong>Most deep learning methods for imputing missing values treat the task as completing patterns within a fixed time window. This assumption often fails in industrial systems, where dynamics are driven by control actions, are highly non-stationary, and can experience long, uninterrupted gaps. We propose STDiff, which reframes imputation as learning how the system evolves from one state to the next. STDiff uses a conditional denoising diffusion model with a causal bias aligned to control theory, generating missing values step-by-step based on the most recent known state and relevant control or environmental inputs. On a public wastewater treatment dataset with simulated missing blocks, STDiff consistently achieves the lowest errors, with its advantage increasing for longer gaps. On a raw industrial dataset with substantial real gaps, it produces trajectories that remain dynamically plausible, in contrast to window-based models that tend to flatten or over-smooth. These results support dynamics-aware, explicitly conditioned imputation as a robust approach for industrial time series, and we discuss computational trade-offs and extensions to broader domains.</li>
</ul>

<h3>Title: Working My Way Back to You: Resource-Centric Next-Activity Prediction</h3>
<ul>
<li><strong>Authors: </strong>Kelly Kurowski, Xixi Lu, Hajo A Reijers</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.19016">https://arxiv.org/abs/2508.19016</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.19016">https://arxiv.org/pdf/2508.19016</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.19016]] Working My Way Back to You: Resource-Centric Next-Activity Prediction(https://arxiv.org/abs/2508.19016)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Predictive Process Monitoring (PPM) aims to train models that forecast upcoming events in process executions. These predictions support early bottleneck detection, improved scheduling, proactive interventions, and timely communication with stakeholders. While existing research adopts a control-flow perspective, we investigate next-activity prediction from a resource-centric viewpoint, which offers additional benefits such as improved work organization, workload balancing, and capacity forecasting. Although resource information has been shown to enhance tasks such as process performance analysis, its role in next-activity prediction remains unexplored. In this study, we evaluate four prediction models and three encoding strategies across four real-life datasets. Compared to the baseline, our results show that LightGBM and Transformer models perform best with an encoding based on 2-gram activity transitions, while Random Forest benefits most from an encoding that combines 2-gram transitions and activity repetition features. This combined encoding also achieves the highest average accuracy. This resource-centric approach could enable smarter resource allocation, strategic workforce planning, and personalized employee support by analyzing individual behavior rather than case-level progression. The findings underscore the potential of resource-centric next-activity prediction, opening up new venues for research on PPM.</li>
</ul>

<h3>Title: Metric Matters: A Formal Evaluation of Similarity Measures in Active Learning for Cyber Threat Intelligence</h3>
<ul>
<li><strong>Authors: </strong>Sidahmed Benabderrahmane, Talal Rahwan</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.NE</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.19019">https://arxiv.org/abs/2508.19019</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.19019">https://arxiv.org/pdf/2508.19019</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.19019]] Metric Matters: A Formal Evaluation of Similarity Measures in Active Learning for Cyber Threat Intelligence(https://arxiv.org/abs/2508.19019)</code><input type="text"></li>
<li><strong>Keywords: </strong>defense, robust, steal</a></li>
<li><strong>Abstract: </strong>Advanced Persistent Threats (APTs) pose a severe challenge to cyber defense due to their stealthy behavior and the extreme class imbalance inherent in detection datasets. To address these issues, we propose a novel active learning-based anomaly detection framework that leverages similarity search to iteratively refine the decision space. Built upon an Attention-Based Autoencoder, our approach uses feature-space similarity to identify normal-like and anomaly-like instances, thereby enhancing model robustness with minimal oracle supervision. Crucially, we perform a formal evaluation of various similarity measures to understand their influence on sample selection and anomaly ranking effectiveness. Through experiments on diverse datasets, including DARPA Transparent Computing APT traces, we demonstrate that the choice of similarity metric significantly impacts model convergence, anomaly detection accuracy, and label efficiency. Our results offer actionable insights for selecting similarity functions in active learning pipelines tailored for threat intelligence and cyber defense.</li>
</ul>

<h3>Title: MicroDetect-Net (MDN): Leveraging Deep Learning to Detect Microplastics in Clam Blood, a Step Towards Human Blood Analysis</h3>
<ul>
<li><strong>Authors: </strong>Riju Marwah, Riya Arora, Navneet Yadav, Himank Arora</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.19021">https://arxiv.org/abs/2508.19021</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.19021">https://arxiv.org/pdf/2508.19021</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.19021]] MicroDetect-Net (MDN): Leveraging Deep Learning to Detect Microplastics in Clam Blood, a Step Towards Human Blood Analysis(https://arxiv.org/abs/2508.19021)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, segmentation</a></li>
<li><strong>Abstract: </strong>With the prevalence of plastics exceeding 368 million tons yearly, microplastic pollution has grown to an extent where air, water, soil, and living organisms have all tested positive for microplastic presence. These particles, which are smaller than 5 millimeters in size, are no less harmful to humans than to the environment. Toxicity research on microplastics has shown that exposure may cause liver infection, intestinal injuries, and gut flora imbalance, leading to numerous potential health hazards. This paper presents a new model, MicroDetect-Net (MDN), which applies fluorescence microscopy with Nile Red dye staining and deep learning to scan blood samples for microplastics. Although clam blood has certain limitations in replicating real human blood, this study opens avenues for applying the approach to human samples, which are more consistent for preliminary data collection. The MDN model integrates dataset preparation, fluorescence imaging, and segmentation using a convolutional neural network to localize and count microplastic fragments. The combination of convolutional networks and Nile Red dye for segmentation produced strong image detection and accuracy. MDN was evaluated on a dataset of 276 Nile Red-stained fluorescent blood images and achieved an accuracy of ninety two percent. Robust performance was observed with an Intersection over Union of 87.4 percent, F1 score of 92.1 percent, Precision of 90.6 percent, and Recall of 93.7 percent. These metrics demonstrate the effectiveness of MDN in the detection of microplastics.</li>
</ul>

<h3>Title: MovieCORE: COgnitive REasoning in Movies</h3>
<ul>
<li><strong>Authors: </strong>Gueter Josmy Faure, Min-Hung Chen, Jia-Fong Yeh, Ying Cheng, Hung-Ting Su, Yung-Hao Tang, Shang-Hong Lai, Winston H. Hsu</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.19026">https://arxiv.org/abs/2508.19026</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.19026">https://arxiv.org/pdf/2508.19026</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.19026]] MovieCORE: COgnitive REasoning in Movies(https://arxiv.org/abs/2508.19026)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>This paper introduces MovieCORE, a novel video question answering (VQA) dataset designed to probe deeper cognitive understanding of movie content. Unlike existing datasets that focus on surface-level comprehension, MovieCORE emphasizes questions that engage System-2 thinking while remaining specific to the video material. We present an innovative agentic brainstorming approach, utilizing multiple large language models (LLMs) as thought agents to generate and refine high-quality question-answer pairs. To evaluate dataset quality, we develop a set of cognitive tests assessing depth, thought-provocation potential, and syntactic complexity. We also propose a comprehensive evaluation scheme for assessing VQA model performance on deeper cognitive tasks. To address the limitations of existing video-language models (VLMs), we introduce an agentic enhancement module, Agentic Choice Enhancement (ACE), which improves model reasoning capabilities post-training by up to 25%. Our work contributes to advancing movie understanding in AI systems and provides valuable insights into the capabilities and limitations of current VQA models when faced with more challenging, nuanced questions about cinematic content. Our project page, dataset and code can be found at this https URL.</li>
</ul>

<h3>Title: When recalling in-context, Transformers are not SSMs</h3>
<ul>
<li><strong>Authors: </strong>Destiny Okpekpe, Antonio Orvieto</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.19029">https://arxiv.org/abs/2508.19029</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.19029">https://arxiv.org/pdf/2508.19029</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.19029]] When recalling in-context, Transformers are not SSMs(https://arxiv.org/abs/2508.19029)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Despite the advantageous subquadratic complexity of modern recurrent deep learning models -- such as state-space models (SSMs) -- recent studies have highlighted their potential shortcomings compared to transformers on reasoning and memorization tasks. In this paper, we dive deeper into one of such benchmarks: associative recall (AR), which has been shown to correlate well with language modeling performance, and inspect in detail the effects of scaling and optimization issues in recently proposed token mixing strategies. We first demonstrate that, unlike standard transformers, the choice of learning rate plays a critical role in the performance of modern recurrent models: an issue that can severely affect reported performance in previous works and suggests further research is needed to stabilize training. Next, we show that recurrent and attention-based models exhibit contrasting benefits when scaling in width as opposed to depth, with attention being notably unable to solve AR when limited to a single layer. We then further inspect 1-layer transformers, revealing that despite their poor performance, their training dynamics surprisingly resemble the formation of induction heads, a phenomenon previously observed only in their 2-layer counterparts. Finally, through architectural ablations, we study how components affects Transformer and Mamba's performance and optimization stability.</li>
</ul>

<h3>Title: GReAT: leveraging geometric artery data to improve wall shear stress assessment</h3>
<ul>
<li><strong>Authors: </strong>Julian Suk, Jolanda J. Wentzel, Patryk Rygiel, Joost Daemen, Daniel Rueckert, Jelmer M. Wolterink</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.19030">https://arxiv.org/abs/2508.19030</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.19030">https://arxiv.org/pdf/2508.19030</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.19030]] GReAT: leveraging geometric artery data to improve wall shear stress assessment(https://arxiv.org/abs/2508.19030)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>Leveraging big data for patient care is promising in many medical fields such as cardiovascular health. For example, hemodynamic biomarkers like wall shear stress could be assessed from patient-specific medical images via machine learning algorithms, bypassing the need for time-intensive computational fluid simulation. However, it is extremely challenging to amass large-enough datasets to effectively train such models. We could address this data scarcity by means of self-supervised pre-training and foundations models given large datasets of geometric artery models. In the context of coronary arteries, leveraging learned representations to improve hemodynamic biomarker assessment has not yet been well studied. In this work, we address this gap by investigating whether a large dataset (8449 shapes) consisting of geometric models of 3D blood vessels can benefit wall shear stress assessment in coronary artery models from a small-scale clinical trial (49 patients). We create a self-supervised target for the 3D blood vessels by computing the heat kernel signature, a quantity obtained via Laplacian eigenvectors, which captures the very essence of the shapes. We show how geometric representations learned from this datasets can boost segmentation of coronary arteries into regions of low, mid and high (time-averaged) wall shear stress even when trained on limited data.</li>
</ul>

<h3>Title: Tackling Federated Unlearning as a Parameter Estimation Problem</h3>
<ul>
<li><strong>Authors: </strong>Antonio Balordi, Lorenzo Manini, Fabio Stella, Alessio Merlo</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.IT</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.19065">https://arxiv.org/abs/2508.19065</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.19065">https://arxiv.org/pdf/2508.19065</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.19065]] Tackling Federated Unlearning as a Parameter Estimation Problem(https://arxiv.org/abs/2508.19065)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, attack, federate</a></li>
<li><strong>Abstract: </strong>Privacy regulations require the erasure of data from deep learning models. This is a significant challenge that is amplified in Federated Learning, where data remains on clients, making full retraining or coordinated updates often infeasible. This work introduces an efficient Federated Unlearning framework based on information theory, modeling leakage as a parameter estimation problem. Our method uses second-order Hessian information to identify and selectively reset only the parameters most sensitive to the data being forgotten, followed by minimal federated retraining. This model-agnostic approach supports categorical and client unlearning without requiring server access to raw client data after initial information aggregation. Evaluations on benchmark datasets demonstrate strong privacy (MIA success near random, categorical knowledge erased) and high performance (Normalized Accuracy against re-trained benchmarks of $\approx$ 0.9), while aiming for increased efficiency over complete retraining. Furthermore, in a targeted backdoor attack scenario, our framework effectively neutralizes the malicious trigger, restoring model integrity. This offers a practical solution for data forgetting in FL.</li>
</ul>

<h3>Title: Attackers Strike Back? Not Anymore - An Ensemble of RL Defenders Awakens for APT Detection</h3>
<ul>
<li><strong>Authors: </strong>Sidahmed Benabderrahmane, Talal Rahwan</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.19072">https://arxiv.org/abs/2508.19072</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.19072">https://arxiv.org/pdf/2508.19072</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.19072]] Attackers Strike Back? Not Anymore - An Ensemble of RL Defenders Awakens for APT Detection(https://arxiv.org/abs/2508.19072)</code><input type="text"></li>
<li><strong>Keywords: </strong>defense, attack, robust, steal</a></li>
<li><strong>Abstract: </strong>Advanced Persistent Threats (APTs) represent a growing menace to modern digital infrastructure. Unlike traditional cyberattacks, APTs are stealthy, adaptive, and long-lasting, often bypassing signature-based detection systems. This paper introduces a novel framework for APT detection that unites deep learning, reinforcement learning (RL), and active learning into a cohesive, adaptive defense system. Our system combines auto-encoders for latent behavioral encoding with a multi-agent ensemble of RL-based defenders, each trained to distinguish between benign and malicious process behaviors. We identify a critical challenge in existing detection systems: their static nature and inability to adapt to evolving attack strategies. To this end, our architecture includes multiple RL agents (Q-Learning, PPO, DQN, adversarial defenders), each analyzing latent vectors generated by an auto-encoder. When any agent is uncertain about its decision, the system triggers an active learning loop to simulate expert feedback, thus refining decision boundaries. An ensemble voting mechanism, weighted by each agent's performance, ensures robust final predictions.</li>
</ul>

<h3>Title: HiPlan: Hierarchical Planning for LLM-Based Agents with Adaptive Global-Local Guidance</h3>
<ul>
<li><strong>Authors: </strong>Ziyue Li, Yuan Chang, Gaihong Yu, Xiaoqiu Le</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.19076">https://arxiv.org/abs/2508.19076</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.19076">https://arxiv.org/pdf/2508.19076</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.19076]] HiPlan: Hierarchical Planning for LLM-Based Agents with Adaptive Global-Local Guidance(https://arxiv.org/abs/2508.19076)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large language model (LLM)-based agents have demonstrated remarkable capabilities in decision-making tasks, but struggle significantly with complex, long-horizon planning scenarios. This arises from their lack of macroscopic guidance, causing disorientation and failures in complex tasks, as well as insufficient continuous oversight during execution, rendering them unresponsive to environmental changes and prone to deviations. To tackle these challenges, we introduce HiPlan, a hierarchical planning framework that provides adaptive global-local guidance to boost LLM-based agents'decision-making. HiPlan decomposes complex tasks into milestone action guides for general direction and step-wise hints for detailed actions. During the offline phase, we construct a milestone library from expert demonstrations, enabling structured experience reuse by retrieving semantically similar tasks and milestones. In the execution phase, trajectory segments from past milestones are dynamically adapted to generate step-wise hints that align current observations with the milestone objectives, bridging gaps and correcting deviations. Extensive experiments across two challenging benchmarks demonstrate that HiPlan substantially outperforms strong baselines, and ablation studies validate the complementary benefits of its hierarchical components.</li>
</ul>

<h3>Title: "Where does it hurt?" - Dataset and Study on Physician Intent Trajectories in Doctor Patient Dialogues</h3>
<ul>
<li><strong>Authors: </strong>Tom RÃ¶hr, Soumyadeep Roy, Fares Al Mohamad, Jens-Michalis Papaioannou, Wolfgang Nejdl, Felix Gers, Alexander LÃ¶ser</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.19077">https://arxiv.org/abs/2508.19077</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.19077">https://arxiv.org/pdf/2508.19077</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.19077]] "Where does it hurt?" - Dataset and Study on Physician Intent Trajectories in Doctor Patient Dialogues(https://arxiv.org/abs/2508.19077)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>In a doctor-patient dialogue, the primary objective of physicians is to diagnose patients and propose a treatment plan. Medical doctors guide these conversations through targeted questioning to efficiently gather the information required to provide the best possible outcomes for patients. To the best of our knowledge, this is the first work that studies physician intent trajectories in doctor-patient dialogues. We use the `Ambient Clinical Intelligence Benchmark' (Aci-bench) dataset for our study. We collaborate with medical professionals to develop a fine-grained taxonomy of physician intents based on the SOAP framework (Subjective, Objective, Assessment, and Plan). We then conduct a large-scale annotation effort to label over 5000 doctor-patient turns with the help of a large number of medical experts recruited using Prolific, a popular crowd-sourcing platform. This large labeled dataset is an important resource contribution that we use for benchmarking the state-of-the-art generative and encoder models for medical intent classification tasks. Our findings show that our models understand the general structure of medical dialogues with high accuracy, but often fail to identify transitions between SOAP categories. We also report for the first time common trajectories in medical dialogue structures that provide valuable insights for designing `differential diagnosis' systems. Finally, we extensively study the impact of intent filtering for medical dialogue summarization and observe a significant boost in performance. We make the codes and data, including annotation guidelines, publicly available at this https URL.</li>
</ul>

<h3>Title: APT-LLM: Exploiting Arbitrary-Precision Tensor Core Computing for LLM Acceleration</h3>
<ul>
<li><strong>Authors: </strong>Shaobo Ma, Chao Fang, Haikuo Shao, Zhongfeng Wang</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.AR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.19087">https://arxiv.org/abs/2508.19087</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.19087">https://arxiv.org/pdf/2508.19087</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.19087]] APT-LLM: Exploiting Arbitrary-Precision Tensor Core Computing for LLM Acceleration(https://arxiv.org/abs/2508.19087)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large language models (LLMs) have revolutionized AI applications, yet their enormous computational demands severely limit deployment and real-time performance. Quantization methods can help reduce computational costs, however, attaining the extreme efficiency associated with ultra-low-bit quantized LLMs at arbitrary precision presents challenges on GPUs. This is primarily due to the limited support for GPU Tensor Cores, inefficient memory management, and inflexible kernel optimizations. To tackle these challenges, we propose a comprehensive acceleration scheme for arbitrary precision LLMs, namely APT-LLM. Firstly, we introduce a novel data format, bipolar-INT, which allows for efficient and lossless conversion with signed INT, while also being more conducive to parallel computation. We also develop a matrix multiplication (MatMul) method allowing for arbitrary precision by dismantling and reassembling matrices at the bit level. This method provides flexible precision and optimizes the utilization of GPU Tensor Cores. In addition, we propose a memory management system focused on data recovery, which strategically employs fast shared memory to substantially increase kernel execution speed and reduce memory access latency. Finally, we develop a kernel mapping method that dynamically selects the optimal configurable hyperparameters of kernels for varying matrix sizes, enabling optimal performance across different LLM architectures and precision settings. In LLM inference, APT-LLM achieves up to a 3.99$\times$ speedup compared to FP16 baselines and a 2.16$\times$ speedup over NVIDIA CUTLASS INT4 acceleration on RTX 3090. On RTX 4090 and H800, APT-LLM achieves up to 2.44$\times$ speedup over FP16 and 1.65$\times$ speedup over CUTLASS integer baselines.</li>
</ul>

<h3>Title: It's All About In-Context Learning! Teaching Extremely Low-Resource Languages to LLMs</h3>
<ul>
<li><strong>Authors: </strong>Yue Li, Zhixue Zhao, Carolina Scarton</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.19089">https://arxiv.org/abs/2508.19089</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.19089">https://arxiv.org/pdf/2508.19089</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.19089]] It's All About In-Context Learning! Teaching Extremely Low-Resource Languages to LLMs(https://arxiv.org/abs/2508.19089)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Extremely low-resource languages, especially those written in rare scripts, as shown in Figure 1, remain largely unsupported by large language models (LLMs). This is due in part to compounding factors such as the lack of training data. This paper delivers the first comprehensive analysis of whether LLMs can acquire such languages purely via in-context learning (ICL), with or without auxiliary alignment signals, and how these methods compare to parameter-efficient fine-tuning (PEFT). We systematically evaluate 20 under-represented languages across three state-of-the-art multilingual LLMs. Our findings highlight the limitation of PEFT when both language and its script are extremely under-represented by the LLM. In contrast, zero-shot ICL with language alignment is impressively effective on extremely low-resource languages, while few-shot ICL or PEFT is more beneficial for languages relatively better represented by LLMs. For LLM practitioners working on extremely low-resource languages, we summarise guidelines grounded by our results on adapting LLMs to low-resource languages, e.g., avoiding fine-tuning a multilingual model on languages of unseen scripts.</li>
</ul>

<h3>Title: Beyond the Black Box: Integrating Lexical and Semantic Methods in Quantitative Discourse Analysis with BERTopic</h3>
<ul>
<li><strong>Authors: </strong>Thomas Compton</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.19099">https://arxiv.org/abs/2508.19099</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.19099">https://arxiv.org/pdf/2508.19099</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.19099]] Beyond the Black Box: Integrating Lexical and Semantic Methods in Quantitative Discourse Analysis with BERTopic(https://arxiv.org/abs/2508.19099)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction, interpretability, transformer, large language model</a></li>
<li><strong>Abstract: </strong>Quantitative Discourse Analysis has seen growing adoption with the rise of Large Language Models and computational tools. However, reliance on black box software such as MAXQDA and NVivo risks undermining methodological transparency and alignment with research goals. This paper presents a hybrid, transparent framework for QDA that combines lexical and semantic methods to enable triangulation, reproducibility, and interpretability. Drawing from a case study in historical political discourse, we demonstrate how custom Python pipelines using NLTK, spaCy, and Sentence Transformers allow fine-grained control over preprocessing, lemmatisation, and embedding generation. We further detail our iterative BERTopic modelling process, incorporating UMAP dimensionality reduction, HDBSCAN clustering, and c-TF-IDF keyword extraction, optimised through parameter tuning and multiple runs to enhance topic coherence and coverage. By juxtaposing precise lexical searches with context-aware semantic clustering, we argue for a multi-layered approach that mitigates the limitations of either method in isolation. Our workflow underscores the importance of code-level transparency, researcher agency, and methodological triangulation in computational discourse studies. Code and supplementary materials are available via GitHub.</li>
</ul>

<h3>Title: Composition and Alignment of Diffusion Models using Constrained Learning</h3>
<ul>
<li><strong>Authors: </strong>Shervin Khalafi, Ignacio Hounie, Dongsheng Ding, Alejandro Ribeiro</a></li>
<li><strong>Subjects: </strong>cs.LG, eess.IV, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.19104">https://arxiv.org/abs/2508.19104</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.19104">https://arxiv.org/pdf/2508.19104</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.19104]] Composition and Alignment of Diffusion Models using Constrained Learning(https://arxiv.org/abs/2508.19104)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, generative</a></li>
<li><strong>Abstract: </strong>Diffusion models have become prevalent in generative modeling due to their ability to sample from complex distributions. To improve the quality of generated samples and their compliance with user requirements, two commonly used methods are: (i) Alignment, which involves fine-tuning a diffusion model to align it with a reward; and (ii) Composition, which combines several pre-trained diffusion models, each emphasizing a desirable attribute in the generated outputs. However, trade-offs often arise when optimizing for multiple rewards or combining multiple models, as they can often represent competing properties. Existing methods cannot guarantee that the resulting model faithfully generates samples with all the desired properties. To address this gap, we propose a constrained optimization framework that unifies alignment and composition of diffusion models by enforcing that the aligned model satisfies reward constraints and/or remains close to (potentially multiple) pre-trained models. We provide a theoretical characterization of the solutions to the constrained alignment and composition problems and develop a Lagrangian-based primal-dual training algorithm to approximate these solutions. Empirically, we demonstrate the effectiveness and merits of our proposed approach in image generation, applying it to alignment and composition, and show that our aligned or composed model satisfies constraints effectively, and improves on the equally-weighted approach. Our implementation can be found at this https URL.</li>
</ul>

<h3>Title: Do LVLMs Know What They Know? A Systematic Study of Knowledge Boundary Perception in LVLMs</h3>
<ul>
<li><strong>Authors: </strong>Zhikai Ding, Shiyu Ni, Keping Bi</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.19111">https://arxiv.org/abs/2508.19111</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.19111">https://arxiv.org/pdf/2508.19111</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.19111]] Do LVLMs Know What They Know? A Systematic Study of Knowledge Boundary Perception in LVLMs(https://arxiv.org/abs/2508.19111)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large vision-language models (LVLMs) demonstrate strong visual question answering (VQA) capabilities but are shown to hallucinate. A reliable model should perceive its knowledge boundaries-knowing what it knows and what it does not. This paper investigates LVLMs' perception of their knowledge boundaries by evaluating three types of confidence signals: probabilistic confidence, answer consistency-based confidence, and verbalized confidence. Experiments on three LVLMs across three VQA datasets show that, although LVLMs possess a reasonable perception level, there is substantial room for improvement. Among the three confidences, probabilistic and consistency-based signals are more reliable indicators, while verbalized confidence often leads to overconfidence. To enhance LVLMs' perception, we adapt several established confidence calibration methods from Large Language Models (LLMs) and propose three effective methods. Additionally, we compare LVLMs with their LLM counterparts, finding that jointly processing visual and textual inputs decreases question-answering performance but reduces confidence, resulting in an improved perception level compared to LLMs.</li>
</ul>

<h3>Title: SecureV2X: An Efficient and Privacy-Preserving System for Vehicle-to-Everything (V2X) Applications</h3>
<ul>
<li><strong>Authors: </strong>Joshua Lee, Ali Arastehfard, Weiran Liu, Xuegang Ban, Yuan Hong</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.19115">https://arxiv.org/abs/2508.19115</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.19115">https://arxiv.org/pdf/2508.19115</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.19115]] SecureV2X: An Efficient and Privacy-Preserving System for Vehicle-to-Everything (V2X) Applications(https://arxiv.org/abs/2508.19115)</code><input type="text"></li>
<li><strong>Keywords: </strong>secure, privacy</a></li>
<li><strong>Abstract: </strong>Autonomous driving and V2X technologies have developed rapidly in the past decade, leading to improved safety and efficiency in modern transportation. These systems interact with extensive networks of vehicles, roadside infrastructure, and cloud resources to support their machine learning capabilities. However, the widespread use of machine learning in V2X systems raises issues over the privacy of the data involved. This is particularly concerning for smart-transit and driver safety applications which can implicitly reveal user locations or explicitly disclose medical data such as EEG signals. To resolve these issues, we propose SecureV2X, a scalable, multi-agent system for secure neural network inferences deployed between the server and each vehicle. Under this setting, we study two multi-agent V2X applications: secure drowsiness detection, and secure red-light violation detection. Our system achieves strong performance relative to baselines, and scales efficiently to support a large number of secure computation interactions simultaneously. For instance, SecureV2X is $9.4 \times$ faster, requires $143\times$ fewer computational rounds, and involves $16.6\times$ less communication on drowsiness detection compared to other secure systems. Moreover, it achieves a runtime nearly $100\times$ faster than state-of-the-art benchmarks in object detection tasks for red light violation detection.</li>
</ul>

<h3>Title: Saddle Hierarchy in Dense Associative Memory</h3>
<ul>
<li><strong>Authors: </strong>Robin ThÃ©riault, Daniele Tantari</a></li>
<li><strong>Subjects: </strong>cs.LG, cond-mat.dis-nn</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.19151">https://arxiv.org/abs/2508.19151</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.19151">https://arxiv.org/pdf/2508.19151</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.19151]] Saddle Hierarchy in Dense Associative Memory(https://arxiv.org/abs/2508.19151)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, diffusion, transformer, generative</a></li>
<li><strong>Abstract: </strong>Dense associative memory (DAM) models have been attracting renewed attention since they were shown to be robust to adversarial examples and closely related to state-of-the-art machine learning paradigms, such as the attention mechanisms in transformers and generative diffusion models. We study a DAM built upon a three-layer Boltzmann machine with Potts hidden units, which represent data clusters and classes. Through a statistical mechanics analysis, we derive saddle-point equations that characterize both the stationary points of DAMs trained on real data and the fixed points of DAMs trained on synthetic data within a teacher-student framework. Based on these results, we propose a novel regularization scheme that makes training significantly more stable. Moreover, we show empirically that our DAM learns interpretable solutions to both supervised and unsupervised classification problems. Pushing our theoretical analysis further, we find that the weights learned by relatively small DAMs correspond to unstable saddle points in larger DAMs. We implement a network-growing algorithm that leverages this saddle-point hierarchy to drastically reduce the computational cost of training dense associative memory.</li>
</ul>

<h3>Title: RDDM: Practicing RAW Domain Diffusion Model for Real-world Image Restoration</h3>
<ul>
<li><strong>Authors: </strong>Yan Chen, Yi Wen, Wei Li, Junchao Liu, Yong Guo, Jie Hu, Xinghao Chen</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.19154">https://arxiv.org/abs/2508.19154</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.19154">https://arxiv.org/pdf/2508.19154</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.19154]] RDDM: Practicing RAW Domain Diffusion Model for Real-world Image Restoration(https://arxiv.org/abs/2508.19154)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>We present the RAW domain diffusion model (RDDM), an end-to-end diffusion model that restores photo-realistic images directly from the sensor RAW data. While recent sRGB-domain diffusion methods achieve impressive results, they are caught in a dilemma between high fidelity and realistic generation. As these models process lossy sRGB inputs and neglect the accessibility of the sensor RAW images in many scenarios, e.g., in image and video capturing in edge devices, resulting in sub-optimal performance. RDDM bypasses this limitation by directly restoring images in the RAW domain, replacing the conventional two-stage image signal processing (ISP) + IR pipeline. However, a simple adaptation of pre-trained diffusion models to the RAW domain confronts the out-of-distribution (OOD) issues. To this end, we propose: (1) a RAW-domain VAE (RVAE) learning optimal latent representations, (2) a differentiable Post Tone Processing (PTP) module enabling joint RAW and sRGB space optimization. To compensate for the deficiency in the dataset, we develop a scalable degradation pipeline synthesizing RAW LQ-HQ pairs from existing sRGB datasets for large-scale training. Furthermore, we devise a configurable multi-bayer (CMB) LoRA module handling diverse RAW patterns such as RGGB, BGGR, etc. Extensive experiments demonstrate RDDM's superiority over state-of-the-art sRGB diffusion methods, yielding higher fidelity results with fewer artifacts.</li>
</ul>

<h3>Title: Few-Shot Connectivity-Aware Text Line Segmentation in Historical Documents</h3>
<ul>
<li><strong>Authors: </strong>Rafael Sterzinger, Tingyu Lin, Robert Sablatnig</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.19162">https://arxiv.org/abs/2508.19162</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.19162">https://arxiv.org/pdf/2508.19162</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.19162]] Few-Shot Connectivity-Aware Text Line Segmentation in Historical Documents(https://arxiv.org/abs/2508.19162)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>A foundational task for the digital analysis of documents is text line segmentation. However, automating this process with deep learning models is challenging because it requires large, annotated datasets that are often unavailable for historical documents. Additionally, the annotation process is a labor- and cost-intensive task that requires expert knowledge, which makes few-shot learning a promising direction for reducing data requirements. In this work, we demonstrate that small and simple architectures, coupled with a topology-aware loss function, are more accurate and data-efficient than more complex alternatives. We pair a lightweight UNet++ with a connectivity-aware loss, initially developed for neuron morphology, which explicitly penalizes structural errors like line fragmentation and unintended line merges. To increase our limited data, we train on small patches extracted from a mere three annotated pages per manuscript. Our methodology significantly improves upon the current state-of-the-art on the U-DIADS-TL dataset, with a 200% increase in Recognition Accuracy and a 75% increase in Line Intersection over Union. Our method also achieves an F-Measure score on par with or even exceeding that of the competition winner of the DIVA-HisDB baseline detection task, all while requiring only three annotated pages, exemplifying the efficacy of our approach. Our implementation is publicly available at: this https URL.</li>
</ul>

<h3>Title: Beyond flattening: a geometrically principled positional encoding for vision transformers with Weierstrass elliptic functions</h3>
<ul>
<li><strong>Authors: </strong>Zhihang Xin, Xitong Hu, Rui Wang</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.19167">https://arxiv.org/abs/2508.19167</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.19167">https://arxiv.org/pdf/2508.19167</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.19167]] Beyond flattening: a geometrically principled positional encoding for vision transformers with Weierstrass elliptic functions(https://arxiv.org/abs/2508.19167)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Vision Transformers have demonstrated remarkable success in computer vision tasks, yet their reliance on learnable one-dimensional positional embeddings fundamentally disrupts the inherent two-dimensional spatial structure of images through patch flattening procedures. Traditional positional encoding approaches lack geometric constraints and fail to establish monotonic correspondence between Euclidean spatial distances and sequential index distances, thereby limiting the model's capacity to leverage spatial proximity priors effectively. We propose Weierstrass Elliptic Function Positional Encoding (WEF-PE), a mathematically principled approach that directly addresses two-dimensional coordinates through natural complex domain representation, where the doubly periodic properties of elliptic functions align remarkably with translational invariance patterns commonly observed in visual data. Our method exploits the non-linear geometric nature of elliptic functions to encode spatial distance relationships naturally, while the algebraic addition formula enables direct derivation of relative positional information between arbitrary patch pairs from their absolute encodings. Comprehensive experiments demonstrate that WEF-PE achieves superior performance across diverse scenarios, including 63.78\% accuracy on CIFAR-100 from-scratch training with ViT-Tiny architecture, 93.28\% on CIFAR-100 fine-tuning with ViT-Base, and consistent improvements on VTAB-1k benchmark tasks. Theoretical analysis confirms the distance-decay property through rigorous mathematical proof, while attention visualization reveals enhanced geometric inductive bias and more coherent semantic focus compared to conventional this http URL source code implementing the methods described in this paper is publicly available on GitHub.</li>
</ul>

<h3>Title: Get Global Guarantees: On the Probabilistic Nature of Perturbation Robustness</h3>
<ul>
<li><strong>Authors: </strong>Wenchuan Mu, Kwan Hui Lim</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.19183">https://arxiv.org/abs/2508.19183</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.19183">https://arxiv.org/pdf/2508.19183</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.19183]] Get Global Guarantees: On the Probabilistic Nature of Perturbation Robustness(https://arxiv.org/abs/2508.19183)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>In safety-critical deep learning applications, robustness measures the ability of neural models that handle imperceptible perturbations in input data, which may lead to potential safety hazards. Existing pre-deployment robustness assessment methods typically suffer from significant trade-offs between computational cost and measurement precision, limiting their practical utility. To address these limitations, this paper conducts a comprehensive comparative analysis of existing robustness definitions and associated assessment methodologies. We propose tower robustness to evaluate robustness, which is a novel, practical metric based on hypothesis testing to quantitatively evaluate probabilistic robustness, enabling more rigorous and efficient pre-deployment assessments. Our extensive comparative evaluation illustrates the advantages and applicability of our proposed approach, thereby advancing the systematic understanding and enhancement of model robustness in safety-critical deep learning applications.</li>
</ul>

<h3>Title: FastMesh:Efficient Artistic Mesh Generation via Component Decoupling</h3>
<ul>
<li><strong>Authors: </strong>Jeonghwan Kim, Yushi Lan, Armando Fortes, Yongwei Chen, Xingang Pan</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.19188">https://arxiv.org/abs/2508.19188</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.19188">https://arxiv.org/pdf/2508.19188</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.19188]] FastMesh:Efficient Artistic Mesh Generation via Component Decoupling(https://arxiv.org/abs/2508.19188)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Recent mesh generation approaches typically tokenize triangle meshes into sequences of tokens and train autoregressive models to generate these tokens sequentially. Despite substantial progress, such token sequences inevitably reuse vertices multiple times to fully represent manifold meshes, as each vertex is shared by multiple faces. This redundancy leads to excessively long token sequences and inefficient generation processes. In this paper, we propose an efficient framework that generates artistic meshes by treating vertices and faces separately, significantly reducing redundancy. We employ an autoregressive model solely for vertex generation, decreasing the token count to approximately 23\% of that required by the most compact existing tokenizer. Next, we leverage a bidirectional transformer to complete the mesh in a single step by capturing inter-vertex relationships and constructing the adjacency matrix that defines the mesh faces. To further improve the generation quality, we introduce a fidelity enhancer to refine vertex positioning into more natural arrangements and propose a post-processing framework to remove undesirable edge connections. Experimental results show that our method achieves more than 8$\times$ faster speed on mesh generation compared to state-of-the-art approaches, while producing higher mesh quality.</li>
</ul>

<h3>Title: All-in-One Slider for Attribute Manipulation in Diffusion Models</h3>
<ul>
<li><strong>Authors: </strong>Weixin Ye, Hongguang Zhu, Wei Wang, Yahui Liu, Mengyu Wang</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.19195">https://arxiv.org/abs/2508.19195</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.19195">https://arxiv.org/pdf/2508.19195</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.19195]] All-in-One Slider for Attribute Manipulation in Diffusion Models(https://arxiv.org/abs/2508.19195)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>Text-to-image (T2I) diffusion models have made significant strides in generating high-quality images. However, progressively manipulating certain attributes of generated images to meet the desired user expectations remains challenging, particularly for content with rich details, such as human faces. Some studies have attempted to address this by training slider modules. However, they follow a One-for-One manner, where an independent slider is trained for each attribute, requiring additional training whenever a new attribute is introduced. This not only results in parameter redundancy accumulated by sliders but also restricts the flexibility of practical applications and the scalability of attribute manipulation. To address this issue, we introduce the All-in-One Slider, a lightweight module that decomposes the text embedding space into sparse, semantically meaningful attribute directions. Once trained, it functions as a general-purpose slider, enabling interpretable and fine-grained continuous control over various attributes. Moreover, by recombining the learned directions, the All-in-One Slider supports zero-shot manipulation of unseen attributes (e.g., races and celebrities) and the composition of multiple attributes. Extensive experiments demonstrate that our method enables accurate and scalable attribute manipulation, achieving notable improvements compared to previous methods. Furthermore, our method can be extended to integrate with the inversion framework to perform attribute manipulation on real images, broadening its applicability to various real-world scenarios. The code and trained model will be released at: this https URL.</li>
</ul>

<h3>Title: Understanding Tool-Integrated Reasoning</h3>
<ul>
<li><strong>Authors: </strong>Heng Lin, Zhongwen Xu</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.19201">https://arxiv.org/abs/2508.19201</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.19201">https://arxiv.org/pdf/2508.19201</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.19201]] Understanding Tool-Integrated Reasoning(https://arxiv.org/abs/2508.19201)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>We study why Tool-Integrated Reasoning (TIR) makes Large Language Models (LLMs) more capable. While LLMs integrated with tools like Python code interpreters show great promise, a principled theory explaining why this paradigm is effective has been missing. This work provides the first formal proof that TIR fundamentally expands an LLM's capabilities. We demonstrate that tools enable a strict expansion of the model's empirical and feasible support, breaking the capability ceiling of pure-text models by unlocking problem-solving strategies that are otherwise impossible or intractably verbose. To guide model behavior without compromising training stability and performance, we also introduce Advantage Shaping Policy Optimization (ASPO), a novel algorithm that directly modifies the advantage function to guide the policy behavior. We conduct comprehensive experiments on challenging mathematical benchmarks, leveraging a Python interpreter as the external tool. Our results show that the TIR model decisively outperforms its pure-text counterpart on the pass@k metric. Crucially, this advantage is not confined to computationally-intensive problems but extends to those requiring significant abstract insight. We further identify the emergent cognitive patterns that illustrate how models learn to think with tools. Finally, we report improved tool usage behavior with early code invocation and much more interactive turns with ASPO. Overall, our work provides the first principled explanation for TIR's success, shifting the focus from the mere fact that tools work to why and how they enable more powerful reasoning.</li>
</ul>

<h3>Title: LSD-3D: Large-Scale 3D Driving Scene Generation with Geometry Grounding</h3>
<ul>
<li><strong>Authors: </strong>Julian Ost, Andrea Ramazzina, Amogh Joshi, Maximilian BÃ¶mer, Mario Bijelic, Felix Heide</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI, cs.GR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.19204">https://arxiv.org/abs/2508.19204</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.19204">https://arxiv.org/pdf/2508.19204</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.19204]] LSD-3D: Large-Scale 3D Driving Scene Generation with Geometry Grounding(https://arxiv.org/abs/2508.19204)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>Large-scale scene data is essential for training and testing in robot learning. Neural reconstruction methods have promised the capability of reconstructing large physically-grounded outdoor scenes from captured sensor data. However, these methods have baked-in static environments and only allow for limited scene control -- they are functionally constrained in scene and trajectory diversity by the captures from which they are reconstructed. In contrast, generating driving data with recent image or video diffusion models offers control, however, at the cost of geometry grounding and causality. In this work, we aim to bridge this gap and present a method that directly generates large-scale 3D driving scenes with accurate geometry, allowing for causal novel view synthesis with object permanence and explicit 3D geometry estimation. The proposed method combines the generation of a proxy geometry and environment representation with score distillation from learned 2D image priors. We find that this approach allows for high controllability, enabling the prompt-guided geometry and high-fidelity texture and structure that can be conditioned on map layouts -- producing realistic and geometrically consistent 3D generations of complex driving scenes.</li>
</ul>

<h3>Title: VibeVoice Technical Report</h3>
<ul>
<li><strong>Authors: </strong>Zhiliang Peng, Jianwei Yu, Wenhui Wang, Yaoyao Chang, Yutao Sun, Li Dong, Yi Zhu, Weijiang Xu, Hangbo Bao, Zehua Wang, Shaohan Huang, Yan Xia, Furu Wei</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.SD</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.19205">https://arxiv.org/abs/2508.19205</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.19205">https://arxiv.org/pdf/2508.19205</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.19205]] VibeVoice Technical Report(https://arxiv.org/abs/2508.19205)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>This report presents VibeVoice, a novel model designed to synthesize long-form speech with multiple speakers by employing next-token diffusion, which is a unified method for modeling continuous data by autoregressively generating latent vectors via diffusion. To enable this, we introduce a novel continuous speech tokenizer that, when compared to the popular Encodec model, improves data compression by 80 times while maintaining comparable performance. The tokenizer effectively preserves audio fidelity while significantly boosting computational efficiency for processing long sequences. Thus, VibeVoice can synthesize long-form speech for up to 90 minutes (in a 64K context window length) with a maximum of 4 speakers, capturing the authentic conversational ``vibe'' and surpassing open-source and proprietary dialogue models.</li>
</ul>

<h3>Title: OmniHuman-1.5: Instilling an Active Mind in Avatars via Cognitive Simulation</h3>
<ul>
<li><strong>Authors: </strong>Jianwen Jiang, Weihong Zeng, Zerong Zheng, Jiaqi Yang, Chao Liang, Wang Liao, Han Liang, Yuan Zhang, Mingyuan Gao</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.19209">https://arxiv.org/abs/2508.19209</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.19209">https://arxiv.org/pdf/2508.19209</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.19209]] OmniHuman-1.5: Instilling an Active Mind in Avatars via Cognitive Simulation(https://arxiv.org/abs/2508.19209)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Existing video avatar models can produce fluid human animations, yet they struggle to move beyond mere physical likeness to capture a character's authentic essence. Their motions typically synchronize with low-level cues like audio rhythm, lacking a deeper semantic understanding of emotion, intent, or context. To bridge this gap, \textbf{we propose a framework designed to generate character animations that are not only physically plausible but also semantically coherent and expressive.} Our model, \textbf{OmniHuman-1.5}, is built upon two key technical contributions. First, we leverage Multimodal Large Language Models to synthesize a structured textual representation of conditions that provides high-level semantic guidance. This guidance steers our motion generator beyond simplistic rhythmic synchronization, enabling the production of actions that are contextually and emotionally resonant. Second, to ensure the effective fusion of these multimodal inputs and mitigate inter-modality conflicts, we introduce a specialized Multimodal DiT architecture with a novel Pseudo Last Frame design. The synergy of these components allows our model to accurately interpret the joint semantics of audio, images, and text, thereby generating motions that are deeply coherent with the character, scene, and linguistic content. Extensive experiments demonstrate that our model achieves leading performance across a comprehensive set of metrics, including lip-sync accuracy, video quality, motion naturalness and semantic consistency with textual prompts. Furthermore, our approach shows remarkable extensibility to complex scenarios, such as those involving multi-person and non-human subjects. Homepage: \href{this https URL}</li>
</ul>

<h3>Title: Generative Interfaces for Language Models</h3>
<ul>
<li><strong>Authors: </strong>Jiaqi Chen, Yanzhe Zhang, Yutong Zhang, Yijia Shao, Diyi Yang</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.HC</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.19227">https://arxiv.org/abs/2508.19227</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.19227">https://arxiv.org/pdf/2508.19227</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.19227]] Generative Interfaces for Language Models(https://arxiv.org/abs/2508.19227)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative, large language model</a></li>
<li><strong>Abstract: </strong>Large language models (LLMs) are increasingly seen as assistants, copilots, and consultants, capable of supporting a wide range of tasks through natural conversation. However, most systems remain constrained by a linear request-response format that often makes interactions inefficient in multi-turn, information-dense, and exploratory tasks. To address these limitations, we propose Generative Interfaces for Language Models, a paradigm in which LLMs respond to user queries by proactively generating user interfaces (UIs) that enable more adaptive and interactive engagement. Our framework leverages structured interface-specific representations and iterative refinements to translate user queries into task-specific UIs. For systematic evaluation, we introduce a multidimensional assessment framework that compares generative interfaces with traditional chat-based ones across diverse tasks, interaction patterns, and query types, capturing functional, interactive, and emotional aspects of user experience. Results show that generative interfaces consistently outperform conversational ones, with humans preferring them in over 70% of cases. These findings clarify when and why users favor generative interfaces, paving the way for future advancements in human-AI interaction.</li>
</ul>

<h3>Title: Predicting the Order of Upcoming Tokens Improves Language Modeling</h3>
<ul>
<li><strong>Authors: </strong>Zayd M. K. Zuhri, Erland Hilman Fuadi, Alham Fikri Aji</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.19228">https://arxiv.org/abs/2508.19228</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.19228">https://arxiv.org/pdf/2508.19228</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.19228]] Predicting the Order of Upcoming Tokens Improves Language Modeling(https://arxiv.org/abs/2508.19228)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Multi-Token Prediction (MTP) has been proposed as an auxiliary objective to improve next-token prediction (NTP) in language model training but shows inconsistent improvements, underperforming in standard NLP benchmarks. We argue that MTP's exact future token prediction is too difficult as an auxiliary loss. Instead, we propose Token Order Prediction (TOP), which trains models to order upcoming tokens by their proximity using a learning-to-rank loss. TOP requires only a single additional unembedding layer compared to MTP's multiple transformer layers. We pretrain models of 340M, 1.8B, and 7B parameters using NTP, MTP, and TOP objectives. Results on eight standard NLP benchmarks show that TOP overall outperforms both NTP and MTP even at scale. Our code is available at this https URL</li>
</ul>

<h3>Title: Autoregressive Universal Video Segmentation Model</h3>
<ul>
<li><strong>Authors: </strong>Miran Heo, Sukjun Hwang, Min-Hung Chen, Yu-Chiang Frank Wang, Albert Gu, Seon Joo Kim, Ryo Hachiuma</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.19242">https://arxiv.org/abs/2508.19242</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.19242">https://arxiv.org/pdf/2508.19242</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.19242]] Autoregressive Universal Video Segmentation Model(https://arxiv.org/abs/2508.19242)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>Recent video foundation models such as SAM2 excel at prompted video segmentation by treating masks as a general-purpose primitive. However, many real-world settings require unprompted segmentation that aims to detect and track all objects in a video without external cues, leaving today's landscape fragmented across task-specific models and pipelines. We recast streaming video segmentation as sequential mask prediction, analogous to language modeling, and introduce the Autoregressive Universal Segmentation Model (AUSM), a single architecture that unifies both prompted and unprompted video segmentation. Built on recent state-space models, AUSM maintains a fixed-size spatial state and scales to video streams of arbitrary length. Furthermore, all components of AUSM are designed for parallel training across frames, yielding substantial speedups over iterative training. On standard benchmarks (DAVIS17, YouTube-VOS 2018 & 2019, MOSE, YouTube-VIS 2019 & 2021, and OVIS) AUSM outperforms prior universal streaming video segmentation methods and achieves up to 2.5x faster training on 16-frame sequences.</li>
</ul>

<h3>Title: Articulate3D: Zero-Shot Text-Driven 3D Object Posing</h3>
<ul>
<li><strong>Authors: </strong>Oishi Deb, Anjun Hu, Ashkan Khakzar, Philip Torr, Christian Rupprecht</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.19244">https://arxiv.org/abs/2508.19244</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.19244">https://arxiv.org/pdf/2508.19244</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.19244]] Articulate3D: Zero-Shot Text-Driven 3D Object Posing(https://arxiv.org/abs/2508.19244)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>We propose a training-free method, Articulate3D, to pose a 3D asset through language control. Despite advances in vision and language models, this task remains surprisingly challenging. To achieve this goal, we decompose the problem into two steps. We modify a powerful image-generator to create target images conditioned on the input image and a text instruction. We then align the mesh to the target images through a multi-view pose optimisation step. In detail, we introduce a self-attention rewiring mechanism (RSActrl) that decouples the source structure from pose within an image generative model, allowing it to maintain a consistent structure across varying poses. We observed that differentiable rendering is an unreliable signal for articulation optimisation; instead, we use keypoints to establish correspondences between input and target images. The effectiveness of Articulate3D is demonstrated across a diverse range of 3D objects and free-form text prompts, successfully manipulating poses while maintaining the original identity of the mesh. Quantitative evaluations and a comparative user study, in which our method was preferred over 85\% of the time, confirm its superiority over existing approaches. Project page:this https URL</li>
</ul>

<h3>Title: VoxHammer: Training-Free Precise and Coherent 3D Editing in Native 3D Space</h3>
<ul>
<li><strong>Authors: </strong>Lin Li, Zehuan Huang, Haoran Feng, Gengxiong Zhuang, Rui Chen, Chunchao Guo, Lu Sheng</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.19247">https://arxiv.org/abs/2508.19247</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.19247">https://arxiv.org/pdf/2508.19247</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.19247]] VoxHammer: Training-Free Precise and Coherent 3D Editing in Native 3D Space(https://arxiv.org/abs/2508.19247)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>3D local editing of specified regions is crucial for game industry and robot interaction. Recent methods typically edit rendered multi-view images and then reconstruct 3D models, but they face challenges in precisely preserving unedited regions and overall coherence. Inspired by structured 3D generative models, we propose VoxHammer, a novel training-free approach that performs precise and coherent editing in 3D latent space. Given a 3D model, VoxHammer first predicts its inversion trajectory and obtains its inverted latents and key-value tokens at each timestep. Subsequently, in the denoising and editing phase, we replace the denoising features of preserved regions with the corresponding inverted latents and cached key-value tokens. By retaining these contextual features, this approach ensures consistent reconstruction of preserved areas and coherent integration of edited parts. To evaluate the consistency of preserved regions, we constructed Edit3D-Bench, a human-annotated dataset comprising hundreds of samples, each with carefully labeled 3D editing regions. Experiments demonstrate that VoxHammer significantly outperforms existing methods in terms of both 3D consistency of preserved regions and overall quality. Our method holds promise for synthesizing high-quality edited paired data, thereby laying the data foundation for in-context 3D generation. See our project page at this https URL.</li>
</ul>

<button id="copy">Copy All</button>
</article>
<script src="../../javascript/clipboard.min.js"></script>
<script src="../../javascript/clipboard.js"></script>
