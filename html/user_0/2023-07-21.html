<link rel="stylesheet" href="../../css/markdown.css" />
<article class="markdown-body">
<h2>secure</h2>
<h3>Title: Hidden Markov Models with Random Restarts vs Boosting for Malware Detection. (arXiv:2307.10256v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2307.10256">http://arxiv.org/abs/2307.10256</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2307.10256] Hidden Markov Models with Random Restarts vs Boosting for Malware Detection](http://arxiv.org/abs/2307.10256) #secure</code></li>
<li>Summary: <p>Effective and efficient malware detection is at the forefront of research
into building secure digital systems. As with many other fields, malware
detection research has seen a dramatic increase in the application of machine
learning algorithms. One machine learning technique that has been used widely
in the field of pattern matching in general-and malware detection in
particular-is hidden Markov models (HMMs). HMM training is based on a hill
climb, and hence we can often improve a model by training multiple times with
different initial values. In this research, we compare boosted HMMs (using
AdaBoost) to HMMs trained with multiple random restarts, in the context of
malware detection. These techniques are applied to a variety of challenging
malware datasets. We find that random restarts perform surprisingly well in
comparison to boosting. Only in the most difficult "cold start" cases (where
training data is severely limited) does boosting appear to offer sufficient
improvement to justify its higher computational cost in the scoring phase.
</p></li>
</ul>

<h3>Title: SecureTrack- A contact tracing IoT platform for monitoring infectious diseases. (arXiv:2307.10311v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2307.10311">http://arxiv.org/abs/2307.10311</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2307.10311] SecureTrack- A contact tracing IoT platform for monitoring infectious diseases](http://arxiv.org/abs/2307.10311) #secure</code></li>
<li>Summary: <p>The COVID-19 pandemic has highlighted the need for innovative solutions to
monitor and control the spread of infectious diseases. With the potential for
future pandemics and the risk of outbreaks particularly in academic
institutions, there is a pressing need for effective approaches to monitor and
manage such diseases. Contact tracing using Global Positioning Systems (GPS)
has been found to be the most prevalent method to detect and tackle the extent
of outbreaks during the pandemic. However, these services suffer from the
inherent problems of infringement of data privacy that creates hindrance in
adoption of the technology. Non-cellular wireless technologies on the other
hand are well-suited to provide secure contact tracing methods. Such approaches
integrated with the Internet of Things (IoT) have a great potential to aid in
the fight against any type of infectious diseases. In response, we present a
unique approach that utilizes an IoT based generic framework to identify
individuals who may have been exposed to the virus, using contact tracing
methods, without compromising the privacy aspect. We develop the architecture
of our platform, including both the frontend and backend components, and
demonstrate its effectiveness in identifying potential COVID-19 exposures (as a
test case) through a proof-of-concept implementation. We also implement and
verify a prototype of the device. Our framework is easily deployable and can be
scaled up as needed with the existing infrastructure.
</p></li>
</ul>

<h3>Title: SecureBoost Hyperparameter Tuning via Multi-Objective Federated Learning. (arXiv:2307.10579v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2307.10579">http://arxiv.org/abs/2307.10579</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2307.10579] SecureBoost Hyperparameter Tuning via Multi-Objective Federated Learning](http://arxiv.org/abs/2307.10579) #secure</code></li>
<li>Summary: <p>SecureBoost is a tree-boosting algorithm leveraging homomorphic encryption to
protect data privacy in vertical federated learning setting. It is widely used
in fields such as finance and healthcare due to its interpretability,
effectiveness, and privacy-preserving capability. However, SecureBoost suffers
from high computational complexity and risk of label leakage. To harness the
full potential of SecureBoost, hyperparameters of SecureBoost should be
carefully chosen to strike an optimal balance between utility, efficiency, and
privacy. Existing methods either set hyperparameters empirically or
heuristically, which are far from optimal. To fill this gap, we propose a
Constrained Multi-Objective SecureBoost (CMOSB) algorithm to find Pareto
optimal solutions that each solution is a set of hyperparameters achieving
optimal tradeoff between utility loss, training cost, and privacy leakage. We
design measurements of the three objectives. In particular, the privacy leakage
is measured using our proposed instance clustering attack. Experimental results
demonstrate that the CMOSB yields not only hyperparameters superior to the
baseline but also optimal sets of hyperparameters that can support the flexible
requirements of FL participants.
</p></li>
</ul>

<h3>Title: A Blockchain-based Electronic Voting System: EtherVote. (arXiv:2307.10726v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2307.10726">http://arxiv.org/abs/2307.10726</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2307.10726] A Blockchain-based Electronic Voting System: EtherVote](http://arxiv.org/abs/2307.10726) #secure</code></li>
<li>Summary: <p>The development of an electronic voting system that would replace traditional
election procedures is a research topic of great interest for many years.
Blockchain technology could provide some guarantees and fulfill strong
requirements for electronic voting platforms, such as transparency,
immutability, and confidentiality. From time to time research is conducted to
address problems in voting systems. Many research works attempt to implement
secure and reliable voting systems, which address known security, anonymity,
and fraud issues that might threaten such systems.
</p></li>
</ul>

<p>This paper presents a proposal of a secure electronic voting system, the
EtherVote, using the Ethereum Blockchain network that focuses deeply on the
field of identification of eligible citizens. The proposed system will be
entirely based on Blockchain without any central authority servers or
databases, thus improving security, privacy, and election cost. Limitations,
problems, and solutions are discussed, in order to make the proposed electronic
voting system ideal and ready to use for national elections.
</p>

<h2>security</h2>
<h3>Title: A Lightweight Approach for Network Intrusion Detection based on Self-Knowledge Distillation. (arXiv:2307.10191v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2307.10191">http://arxiv.org/abs/2307.10191</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2307.10191] A Lightweight Approach for Network Intrusion Detection based on Self-Knowledge Distillation](http://arxiv.org/abs/2307.10191) #security</code></li>
<li>Summary: <p>Network Intrusion Detection (NID) works as a kernel technology for the
security network environment, obtaining extensive research and application.
Despite enormous efforts by researchers, NID still faces challenges in
deploying on resource-constrained devices. To improve detection accuracy while
reducing computational costs and model storage simultaneously, we propose a
lightweight intrusion detection approach based on self-knowledge distillation,
namely LNet-SKD, which achieves the trade-off between accuracy and efficiency.
Specifically, we carefully design the DeepMax block to extract compact
representation efficiently and construct the LNet by stacking DeepMax blocks.
Furthermore, considering compensating for performance degradation caused by the
lightweight network, we adopt batch-wise self-knowledge distillation to provide
the regularization of training consistency. Experiments on benchmark datasets
demonstrate the effectiveness of our proposed LNet-SKD, which outperforms
existing state-of-the-art techniques with fewer parameters and lower
computation loads.
</p></li>
</ul>

<h3>Title: Time for aCTIon: Automated Analysis of Cyber Threat Intelligence in the Wild. (arXiv:2307.10214v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2307.10214">http://arxiv.org/abs/2307.10214</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2307.10214] Time for aCTIon: Automated Analysis of Cyber Threat Intelligence in the Wild](http://arxiv.org/abs/2307.10214) #security</code></li>
<li>Summary: <p>Cyber Threat Intelligence (CTI) plays a crucial role in assessing risks and
enhancing security for organizations. However, the process of extracting
relevant information from unstructured text sources can be expensive and
time-consuming. Our empirical experience shows that existing tools for
automated structured CTI extraction have performance limitations. Furthermore,
the community lacks a common benchmark to quantitatively assess their
performance. We fill these gaps providing a new large open benchmark dataset
and aCTIon, a structured CTI information extraction tool. The dataset includes
204 real-world publicly available reports and their corresponding structured
CTI information in STIX format. Our team curated the dataset involving three
independent groups of CTI analysts working over the course of several months.
To the best of our knowledge, this dataset is two orders of magnitude larger
than previously released open source datasets. We then design aCTIon,
leveraging recently introduced large language models (GPT3.5) in the context of
two custom information extraction pipelines. We compare our method with 10
solutions presented in previous work, for which we develop our own
implementations when open-source implementations were lacking. Our results show
that aCTIon outperforms previous work for structured CTI extraction with an
improvement of the F1-score from 10%points to 50%points across all tasks.
</p></li>
</ul>

<h3>Title: CCTFv1: Computational Modeling of Cyber Team Formation Strategies. (arXiv:2307.10258v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2307.10258">http://arxiv.org/abs/2307.10258</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2307.10258] CCTFv1: Computational Modeling of Cyber Team Formation Strategies](http://arxiv.org/abs/2307.10258) #security</code></li>
<li>Summary: <p>Rooted in collaborative efforts, cybersecurity spans the scope of cyber
competitions and warfare. Despite extensive research into team strategy in
sports and project management, empirical study in cyber-security is minimal.
This gap motivates this paper, which presents the Collaborative Cyber Team
Formation (CCTF) Simulation Framework. Using Agent-Based Modeling, we delve
into the dynamics of team creation and output. We focus on exposing the impact
of structural dynamics on performance while controlling other variables
carefully. Our findings highlight the importance of strategic team formations,
an aspect often overlooked in corporate cybersecurity and cyber competition
teams.
</p></li>
</ul>

<h3>Title: Student Assessment in Cybersecurity Training Automated by Pattern Mining and Clustering. (arXiv:2307.10260v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2307.10260">http://arxiv.org/abs/2307.10260</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2307.10260] Student Assessment in Cybersecurity Training Automated by Pattern Mining and Clustering](http://arxiv.org/abs/2307.10260) #security</code></li>
<li>Summary: <p>Hands-on cybersecurity training allows students and professionals to practice
various tools and improve their technical skills. The training occurs in an
interactive learning environment that enables completing sophisticated tasks in
full-fledged operating systems, networks, and applications. During the
training, the learning environment allows collecting data about trainees'
interactions with the environment, such as their usage of command-line tools.
These data contain patterns indicative of trainees' learning processes, and
revealing them allows to assess the trainees and provide feedback to help them
learn. However, automated analysis of these data is challenging. The training
tasks feature complex problem-solving, and many different solution approaches
are possible. Moreover, the trainees generate vast amounts of interaction data.
This paper explores a dataset from 18 cybersecurity training sessions using
data mining and machine learning techniques. We employed pattern mining and
clustering to analyze 8834 commands collected from 113 trainees, revealing
their typical behavior, mistakes, solution strategies, and difficult training
stages. Pattern mining proved suitable in capturing timing information and tool
usage frequency. Clustering underlined that many trainees often face the same
issues, which can be addressed by targeted scaffolding. Our results show that
data mining methods are suitable for analyzing cybersecurity training data.
Educational researchers and practitioners can apply these methods in their
contexts to assess trainees, support them, and improve the training design.
Artifacts associated with this research are publicly available.
</p></li>
</ul>

<h3>Title: NFT-Based Blockchain-Oriented Security Framework for Metaverse Applications. (arXiv:2307.10342v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2307.10342">http://arxiv.org/abs/2307.10342</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2307.10342] NFT-Based Blockchain-Oriented Security Framework for Metaverse Applications](http://arxiv.org/abs/2307.10342) #security</code></li>
<li>Summary: <p>The Metaverse is rapidly evolving, bringing us closer to its imminent
reality. However, the widespread adoption of this new automated technology
poses significant research challenges in terms of authenticity, integrity,
interoperability, and efficiency. These challenges originate from the core
technologies underlying the Metaverse and are exacerbated by its complex
nature. As a solution to these challenges, this paper presents a novel
framework based on Non-Fungible Tokens (NFTs). The framework employs the
Proof-of-Stake consensus algorithm, a blockchain-based technology, for data
transaction, validation, and resource management. PoS efficiently consume
energy and provide a streamlined validation approach instead of
resource-intensive mining. This ability makes PoS an ideal candidate for
Metaverse applications. By combining NFTs for user authentication and PoS for
data integrity, enhanced transaction throughput, and improved scalability, the
proposed blockchain mechanism demonstrates noteworthy advantages. Through
security analysis, experimental and simulation results, it is established that
the NFT-based approach coupled with the PoS algorithm is secure and efficient
for Metaverse applications.
</p></li>
</ul>

<h3>Title: Shared Adversarial Unlearning: Backdoor Mitigation by Unlearning Shared Adversarial Examples. (arXiv:2307.10562v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2307.10562">http://arxiv.org/abs/2307.10562</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2307.10562] Shared Adversarial Unlearning: Backdoor Mitigation by Unlearning Shared Adversarial Examples](http://arxiv.org/abs/2307.10562) #security</code></li>
<li>Summary: <p>Backdoor attacks are serious security threats to machine learning models
where an adversary can inject poisoned samples into the training set, causing a
backdoored model which predicts poisoned samples with particular triggers to
particular target classes, while behaving normally on benign samples. In this
paper, we explore the task of purifying a backdoored model using a small clean
dataset. By establishing the connection between backdoor risk and adversarial
risk, we derive a novel upper bound for backdoor risk, which mainly captures
the risk on the shared adversarial examples (SAEs) between the backdoored model
and the purified model. This upper bound further suggests a novel bi-level
optimization problem for mitigating backdoor using adversarial training
techniques. To solve it, we propose Shared Adversarial Unlearning (SAU).
Specifically, SAU first generates SAEs, and then, unlearns the generated SAEs
such that they are either correctly classified by the purified model and/or
differently classified by the two models, such that the backdoor effect in the
backdoored model will be mitigated in the purified model. Experiments on
various benchmark datasets and network architectures show that our proposed
method achieves state-of-the-art performance for backdoor defense.
</p></li>
</ul>

<h3>Title: Deep fused flow and topology features for botnet detection basing on pretrained GCN. (arXiv:2307.10583v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2307.10583">http://arxiv.org/abs/2307.10583</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2307.10583] Deep fused flow and topology features for botnet detection basing on pretrained GCN](http://arxiv.org/abs/2307.10583) #security</code></li>
<li>Summary: <p>Nowadays, botnets have become one of the major threats to cyber security. The
characteristics of botnets are mainly reflected in bots network behavior and
their intercommunication relationships. Existing botnet detection methods use
flow features or topological features of the communication graph individually
and overlook the other type of feature, which affects model performance. In
this paper, we propose a botnet detection model which uses graph convolutional
network (GCN) to deeply fuse flow features and topological features for the
first time. We construct communication graphs from network traffic and
represent nodes with flow features. Due to the imbalance of existing public
traffic flow datasets, it is impossible to train a GCN model on these datasets.
Therefore, we use a balanced public communication graph dataset to pretrain a
GCN model, thereby guaranteeing its capacity for recognizing topological
features. We then feed the communication graph with flow features into the
pretrained GCN. The output from the last hidden layer is treated as the fusion
of flow and topological features. Additionally, by adjusting the number of
layers in the GCN network, the model can effectively detect botnets operating
under both C2 and P2P structures. Validated on the public ISCX2014 dataset, our
approach achieves a remarkable accuracy of 98.85% and a recall rate of 92.90%
for C2 botnets, alongside an accuracy of 99.10% and a recall rate of 94.66% for
P2P botnets. These results not only demonstrate the efficacy of our method, but
also surpass the performance of the currently leading detection models.
</p></li>
</ul>

<h3>Title: A Holistic Assessment of the Reliability of Machine Learning Systems. (arXiv:2307.10586v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2307.10586">http://arxiv.org/abs/2307.10586</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2307.10586] A Holistic Assessment of the Reliability of Machine Learning Systems](http://arxiv.org/abs/2307.10586) #security</code></li>
<li>Summary: <p>As machine learning (ML) systems increasingly permeate high-stakes settings
such as healthcare, transportation, military, and national security, concerns
regarding their reliability have emerged. Despite notable progress, the
performance of these systems can significantly diminish due to adversarial
attacks or environmental changes, leading to overconfident predictions,
failures to detect input faults, and an inability to generalize in unexpected
scenarios. This paper proposes a holistic assessment methodology for the
reliability of ML systems. Our framework evaluates five key properties:
in-distribution accuracy, distribution-shift robustness, adversarial
robustness, calibration, and out-of-distribution detection. A reliability score
is also introduced and used to assess the overall system reliability. To
provide insights into the performance of different algorithmic approaches, we
identify and categorize state-of-the-art techniques, then evaluate a selection
on real-world tasks using our proposed reliability metrics and reliability
score. Our analysis of over 500 models reveals that designing for one metric
does not necessarily constrain others but certain algorithmic techniques can
improve reliability across multiple metrics simultaneously. This study
contributes to a more comprehensive understanding of ML reliability and
provides a roadmap for future research and development.
</p></li>
</ul>

<h3>Title: Ensemble Learning based Anomaly Detection for IoT Cybersecurity via Bayesian Hyperparameters Sensitivity Analysis. (arXiv:2307.10596v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2307.10596">http://arxiv.org/abs/2307.10596</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2307.10596] Ensemble Learning based Anomaly Detection for IoT Cybersecurity via Bayesian Hyperparameters Sensitivity Analysis](http://arxiv.org/abs/2307.10596) #security</code></li>
<li>Summary: <p>The Internet of Things (IoT) integrates more than billions of intelligent
devices over the globe with the capability of communicating with other
connected devices with little to no human intervention. IoT enables data
aggregation and analysis on a large scale to improve life quality in many
domains. In particular, data collected by IoT contain a tremendous amount of
information for anomaly detection. The heterogeneous nature of IoT is both a
challenge and an opportunity for cybersecurity. Traditional approaches in
cybersecurity monitoring often require different kinds of data pre-processing
and handling for various data types, which might be problematic for datasets
that contain heterogeneous features. However, heterogeneous types of network
devices can often capture a more diverse set of signals than a single type of
device readings, which is particularly useful for anomaly detection. In this
paper, we present a comprehensive study on using ensemble machine learning
methods for enhancing IoT cybersecurity via anomaly detection. Rather than
using one single machine learning model, ensemble learning combines the
predictive power from multiple models, enhancing their predictive accuracy in
heterogeneous datasets rather than using one single machine learning model. We
propose a unified framework with ensemble learning that utilises Bayesian
hyperparameter optimisation to adapt to a network environment that contains
multiple IoT sensor readings. Experimentally, we illustrate their high
predictive power when compared to traditional methods.
</p></li>
</ul>

<h2>privacy</h2>
<h3>Title: What can we learn from Data Leakage and Unlearning for Law?. (arXiv:2307.10476v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2307.10476">http://arxiv.org/abs/2307.10476</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2307.10476] What can we learn from Data Leakage and Unlearning for Law?](http://arxiv.org/abs/2307.10476) #privacy</code></li>
<li>Summary: <p>Large Language Models (LLMs) have a privacy concern because they memorize
training data (including personally identifiable information (PII) like emails
and phone numbers) and leak it during inference. A company can train an LLM on
its domain-customized data which can potentially also include their users' PII.
In order to comply with privacy laws such as the "right to be forgotten", the
data points of users that are most vulnerable to extraction could be deleted.
We find that once the most vulnerable points are deleted, a new set of points
become vulnerable to extraction. So far, little attention has been given to
understanding memorization for fine-tuned models. In this work, we also show
that not only do fine-tuned models leak their training data but they also leak
the pre-training data (and PII) memorized during the pre-training phase. The
property of new data points becoming vulnerable to extraction after unlearning
and leakage of pre-training data through fine-tuned models can pose significant
privacy and legal concerns for companies that use LLMs to offer services. We
hope this work will start an interdisciplinary discussion within AI and law
communities regarding the need for policies to tackle these issues.
</p></li>
</ul>

<h3>Title: Privacy Amplification via Importance Sampling. (arXiv:2307.10187v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2307.10187">http://arxiv.org/abs/2307.10187</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2307.10187] Privacy Amplification via Importance Sampling](http://arxiv.org/abs/2307.10187) #privacy</code></li>
<li>Summary: <p>We examine the privacy-enhancing properties of subsampling a data set via
importance sampling as a pre-processing step for differentially private
mechanisms. This extends the established privacy amplification by subsampling
result to importance sampling where each data point is weighted by the
reciprocal of its selection probability. The implications for privacy of
weighting each point are not obvious. On the one hand, a lower selection
probability leads to a stronger privacy amplification. On the other hand, the
higher the weight, the stronger the influence of the point on the output of the
mechanism in the event that the point does get selected. We provide a general
result that quantifies the trade-off between these two effects. We show that
heterogeneous sampling probabilities can lead to both stronger privacy and
better utility than uniform subsampling while retaining the subsample size. In
particular, we formulate and solve the problem of privacy-optimal sampling,
that is, finding the importance weights that minimize the expected subset size
subject to a given privacy budget. Empirically, we evaluate the privacy,
efficiency, and accuracy of importance sampling-based privacy amplification on
the example of k-means clustering.
</p></li>
</ul>

<h3>Title: A Survey of What to Share in Federated Learning: Perspectives on Model Utility, Privacy Leakage, and Communication Efficiency. (arXiv:2307.10655v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2307.10655">http://arxiv.org/abs/2307.10655</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2307.10655] A Survey of What to Share in Federated Learning: Perspectives on Model Utility, Privacy Leakage, and Communication Efficiency](http://arxiv.org/abs/2307.10655) #privacy</code></li>
<li>Summary: <p>Federated learning (FL) has emerged as a highly effective paradigm for
privacy-preserving collaborative training among different parties. Unlike
traditional centralized learning, which requires collecting data from each
party, FL allows clients to share privacy-preserving information without
exposing private datasets. This approach not only guarantees enhanced privacy
protection but also facilitates more efficient and secure collaboration among
multiple participants. Therefore, FL has gained considerable attention from
researchers, promoting numerous surveys to summarize the related works.
However, the majority of these surveys concentrate on methods sharing model
parameters during the training process, while overlooking the potential of
sharing other forms of local information. In this paper, we present a
systematic survey from a new perspective, i.e., what to share in FL, with an
emphasis on the model utility, privacy leakage, and communication efficiency.
This survey differs from previous ones due to four distinct contributions.
First, we present a new taxonomy of FL methods in terms of the sharing methods,
which includes three categories of shared information: model sharing, synthetic
data sharing, and knowledge sharing. Second, we analyze the vulnerability of
different sharing methods to privacy attacks and review the defense mechanisms
that provide certain privacy guarantees. Third, we conduct extensive
experiments to compare the performance and communication overhead of various
sharing methods in FL. Besides, we assess the potential privacy leakage through
model inversion and membership inference attacks, while comparing the
effectiveness of various defense approaches. Finally, we discuss potential
deficiencies in current methods and outline future directions for improvement.
</p></li>
</ul>

<h3>Title: Threshold Encrypted Mempools: Limitations and Considerations. (arXiv:2307.10878v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2307.10878">http://arxiv.org/abs/2307.10878</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2307.10878] Threshold Encrypted Mempools: Limitations and Considerations](http://arxiv.org/abs/2307.10878) #privacy</code></li>
<li>Summary: <p>Encrypted mempools are a class of solutions aimed at preventing or reducing
negative externalities of MEV extraction using cryptographic privacy. Mempool
encryption aims to hide information related to pending transactions until a
block including the transactions is committed, targeting the prevention of
frontrunning and similar behaviour. Among the various methods of encryption,
threshold schemes are particularly interesting for the design of MEV mitigation
mechanisms, as their distributed nature and minimal hardware requirements
harmonize with a broader goal of decentralization.
</p></li>
</ul>

<p>This work looks beyond the formal and technical cryptographic aspects of
threshold encryption schemes to focus on the market and incentive implications
of implementing encrypted mempools as MEV mitigation techniques. In particular,
this paper argues that the deployment of such protocols without proper
consideration and understanding of market impact invites several undesired
outcomes, with the ultimate goal of stimulating further analysis of this class
of solutions outside of pure cryptograhic considerations. Included in the paper
is an overview of a series of problems, various candidate solutions in the form
of mempool encryption techniques with a focus on threshold encryption,
potential drawbacks to these solutions, and Osmosis as a case study. The paper
targets a broad audience and remains agnostic to blockchain design where
possible while drawing from mostly financial examples.
</p>

<h3>Title: Decentralized Smart Charging of Large-Scale EVs using Adaptive Multi-Agent Multi-Armed Bandits. (arXiv:2307.10704v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2307.10704">http://arxiv.org/abs/2307.10704</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2307.10704] Decentralized Smart Charging of Large-Scale EVs using Adaptive Multi-Agent Multi-Armed Bandits](http://arxiv.org/abs/2307.10704) #privacy</code></li>
<li>Summary: <p>The drastic growth of electric vehicles and photovoltaics can introduce new
challenges, such as electrical current congestion and voltage limit violations
due to peak load demands. These issues can be mitigated by controlling the
operation of electric vehicles i.e., smart charging. Centralized smart charging
solutions have already been proposed in the literature. But such solutions may
lack scalability and suffer from inherent drawbacks of centralization, such as
a single point of failure, and data privacy concerns. Decentralization can help
tackle these challenges. In this paper, a fully decentralized smart charging
system is proposed using the philosophy of adaptive multi-agent systems. The
proposed system utilizes multi-armed bandit learning to handle uncertainties in
the system. The presented system is decentralized, scalable, real-time,
model-free, and takes fairness among different players into account. A detailed
case study is also presented for performance evaluation.
</p></li>
</ul>

<h2>protect</h2>
<h2>defense</h2>
<h3>Title: CAPTCHA Types and Breaking Techniques: Design Issues, Challenges, and Future Research Directions. (arXiv:2307.10239v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2307.10239">http://arxiv.org/abs/2307.10239</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2307.10239] CAPTCHA Types and Breaking Techniques: Design Issues, Challenges, and Future Research Directions](http://arxiv.org/abs/2307.10239) #defense</code></li>
<li>Summary: <p>The proliferation of the Internet and mobile devices has resulted in
malicious bots access to genuine resources and data. Bots may instigate
phishing, unauthorized access, denial-of-service, and spoofing attacks to
mention a few. Authentication and testing mechanisms to verify the end-users
and prohibit malicious programs from infiltrating the services and data are
strong defense systems against malicious bots. Completely Automated Public
Turing test to tell Computers and Humans Apart (CAPTCHA) is an authentication
process to confirm that the user is a human hence, access is granted. This
paper provides an in-depth survey on CAPTCHAs and focuses on two main things:
(1) a detailed discussion on various CAPTCHA types along with their advantages,
disadvantages, and design recommendations, and (2) an in-depth analysis of
different CAPTCHA breaking techniques. The survey is based on over two hundred
studies on the subject matter conducted since 2003 to date. The analysis
reinforces the need to design more attack-resistant CAPTCHAs while keeping
their usability intact. The paper also highlights the design challenges and
open issues related to CAPTCHAs. Furthermore, it also provides useful
recommendations for breaking CAPTCHAs.
</p></li>
</ul>

<h3>Title: Battle Ground: Data Collection and Labeling of CTF Games to Understand Human Cyber Operators. (arXiv:2307.10877v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2307.10877">http://arxiv.org/abs/2307.10877</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2307.10877] Battle Ground: Data Collection and Labeling of CTF Games to Understand Human Cyber Operators](http://arxiv.org/abs/2307.10877) #defense</code></li>
<li>Summary: <p>Industry standard frameworks are now widespread for labeling the high-level
stages and granular actions of attacker and defender behavior in cyberspace.
While these labels are used for atomic actions, and to some extent for
sequences of actions, there remains a need for labeled data from realistic
full-scale attacks. This data is valuable for better understanding human
actors' decisions, behaviors, and individual attributes. The analysis could
lead to more effective attribution and disruption of attackers.
</p></li>
</ul>

<p>We present a methodological approach and exploratory case study for
systematically analyzing human behavior during a cyber offense/defense
capture-the-flag (CTF) game. We describe the data collection and analysis to
derive a metric called keystroke accuracy. After collecting players' commands,
we label them using the MITRE ATT&amp;CK framework using a new tool called
Pathfinder. We present results from preliminary analysis of participants'
keystroke accuracy and its relation to score outcome in CTF games. We describe
frequency of action classification within the MITRE ATT&amp;CK framework and
discuss some of the mathematical trends suggested by our observations. We
conclude with a discussion of extensions for the methodology, including
performance evaluation during games and the potential use of this methodology
for training artificial intelligence.
</p>

<h2>attack</h2>
<h3>Title: Towards Viewpoint-Invariant Visual Recognition via Adversarial Training. (arXiv:2307.10235v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2307.10235">http://arxiv.org/abs/2307.10235</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2307.10235] Towards Viewpoint-Invariant Visual Recognition via Adversarial Training](http://arxiv.org/abs/2307.10235) #attack</code></li>
<li>Summary: <p>Visual recognition models are not invariant to viewpoint changes in the 3D
world, as different viewing directions can dramatically affect the predictions
given the same object. Although many efforts have been devoted to making neural
networks invariant to 2D image translations and rotations, viewpoint invariance
is rarely investigated. As most models process images in the perspective view,
it is challenging to impose invariance to 3D viewpoint changes based only on 2D
inputs. Motivated by the success of adversarial training in promoting model
robustness, we propose Viewpoint-Invariant Adversarial Training (VIAT) to
improve viewpoint robustness of common image classifiers. By regarding
viewpoint transformation as an attack, VIAT is formulated as a minimax
optimization problem, where the inner maximization characterizes diverse
adversarial viewpoints by learning a Gaussian mixture distribution based on a
new attack GMVFool, while the outer minimization trains a viewpoint-invariant
classifier by minimizing the expected loss over the worst-case adversarial
viewpoint distributions. To further improve the generalization performance, a
distribution sharing strategy is introduced leveraging the transferability of
adversarial viewpoints across objects. Experiments validate the effectiveness
of VIAT in improving the viewpoint robustness of various image classifiers
based on the diversity of adversarial viewpoints generated by GMVFool.
</p></li>
</ul>

<h3>Title: Backdoor Attack against Object Detection with Clean Annotation. (arXiv:2307.10487v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2307.10487">http://arxiv.org/abs/2307.10487</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2307.10487] Backdoor Attack against Object Detection with Clean Annotation](http://arxiv.org/abs/2307.10487) #attack</code></li>
<li>Summary: <p>Deep neural networks (DNNs) have shown unprecedented success in object
detection tasks. However, it was also discovered that DNNs are vulnerable to
multiple kinds of attacks, including Backdoor Attacks. Through the attack, the
attacker manages to embed a hidden backdoor into the DNN such that the model
behaves normally on benign data samples, but makes attacker-specified judgments
given the occurrence of a predefined trigger. Although numerous backdoor
attacks have been experimented on image classification, backdoor attacks on
object detection tasks have not been properly investigated and explored. As
object detection has been adopted as an important module in multiple
security-sensitive applications such as autonomous driving, backdoor attacks on
object detection could pose even more severe threats. Inspired by the inherent
property of deep learning-based object detectors, we propose a simple yet
effective backdoor attack method against object detection without modifying the
ground truth annotations, specifically focusing on the object disappearance
attack and object generation attack. Extensive experiments and ablation studies
prove the effectiveness of our attack on two benchmark object detection
datasets, PASCAL VOC07+12 and MSCOCO, on which we achieve an attack success
rate of more than 92% with a poison rate of only 5%.
</p></li>
</ul>

<h3>Title: (Ab)using Images and Sounds for Indirect Instruction Injection in Multi-Modal LLMs. (arXiv:2307.10490v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2307.10490">http://arxiv.org/abs/2307.10490</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2307.10490] (Ab)using Images and Sounds for Indirect Instruction Injection in Multi-Modal LLMs](http://arxiv.org/abs/2307.10490) #attack</code></li>
<li>Summary: <p>We demonstrate how images and sounds can be used for indirect prompt and
instruction injection in multi-modal LLMs. An attacker generates an adversarial
perturbation corresponding to the prompt and blends it into an image or audio
recording. When the user asks the (unmodified, benign) model about the
perturbed image or audio, the perturbation steers the model to output the
attacker-chosen text and/or make the subsequent dialog follow the attacker's
instruction. We illustrate this attack with several proof-of-concept examples
targeting LLaVa and PandaGPT.
</p></li>
</ul>

<h3>Title: On the Sensitivity of Deep Load Disaggregation to Adversarial Attacks. (arXiv:2307.10209v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2307.10209">http://arxiv.org/abs/2307.10209</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2307.10209] On the Sensitivity of Deep Load Disaggregation to Adversarial Attacks](http://arxiv.org/abs/2307.10209) #attack</code></li>
<li>Summary: <p>Non-intrusive Load Monitoring (NILM) algorithms, commonly referred to as load
disaggregation algorithms, are fundamental tools for effective energy
management. Despite the success of deep models in load disaggregation, they
face various challenges, particularly those pertaining to privacy and security.
This paper investigates the sensitivity of prominent deep NILM baselines to
adversarial attacks, which have proven to be a significant threat in domains
such as computer vision and speech recognition. Adversarial attacks entail the
introduction of imperceptible noise into the input data with the aim of
misleading the neural network into generating erroneous outputs. We investigate
the Fast Gradient Sign Method (FGSM), a well-known adversarial attack, to
perturb the input sequences fed into two commonly employed CNN-based NILM
baselines: the Sequence-to-Sequence (S2S) and Sequence-to-Point (S2P) models.
Our findings provide compelling evidence for the vulnerability of these models,
particularly the S2P model which exhibits an average decline of 20\% in the
F1-score even with small amounts of noise. Such weakness has the potential to
generate profound implications for energy management systems in residential and
industrial sectors reliant on NILM models.
</p></li>
</ul>

<h3>Title: A Machine Learning based Empirical Evaluation of Cyber Threat Actors High Level Attack Patterns over Low level Attack Patterns in Attributing Attacks. (arXiv:2307.10252v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2307.10252">http://arxiv.org/abs/2307.10252</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2307.10252] A Machine Learning based Empirical Evaluation of Cyber Threat Actors High Level Attack Patterns over Low level Attack Patterns in Attributing Attacks](http://arxiv.org/abs/2307.10252) #attack</code></li>
<li>Summary: <p>Cyber threat attribution is the process of identifying the actor of an attack
incident in cyberspace. An accurate and timely threat attribution plays an
important role in deterring future attacks by applying appropriate and timely
defense mechanisms. Manual analysis of attack patterns gathered by honeypot
deployments, intrusion detection systems, firewalls, and via trace-back
procedures is still the preferred method of security analysts for cyber threat
attribution. Such attack patterns are low-level Indicators of Compromise (IOC).
They represent Tactics, Techniques, Procedures (TTP), and software tools used
by the adversaries in their campaigns. The adversaries rarely re-use them. They
can also be manipulated, resulting in false and unfair attribution. To
empirically evaluate and compare the effectiveness of both kinds of IOC, there
are two problems that need to be addressed. The first problem is that in recent
research works, the ineffectiveness of low-level IOC for cyber threat
attribution has been discussed intuitively. An empirical evaluation for the
measure of the effectiveness of low-level IOC based on a real-world dataset is
missing. The second problem is that the available dataset for high-level IOC
has a single instance for each predictive class label that cannot be used
directly for training machine learning models. To address these problems in
this research work, we empirically evaluate the effectiveness of low-level IOC
based on a real-world dataset that is specifically built for comparative
analysis with high-level IOC. The experimental results show that the high-level
IOC trained models effectively attribute cyberattacks with an accuracy of 95%
as compared to the low-level IOC trained models where accuracy is 40%.
</p></li>
</ul>

<h3>Title: A DPLL(T) Framework for Verifying Deep Neural Networks. (arXiv:2307.10266v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2307.10266">http://arxiv.org/abs/2307.10266</a></li>
<li>Code URL: <a href="https://github.com/dynaroars/neuralsat-solver">https://github.com/dynaroars/neuralsat-solver</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2307.10266] A DPLL(T) Framework for Verifying Deep Neural Networks](http://arxiv.org/abs/2307.10266) #attack</code></li>
<li>Summary: <p>Deep Neural Networks (DNNs) have emerged as an effective approach to tackling
real-world problems. However, like human-written software,
automatically-generated DNNs can have bugs and be attacked. This thus attracts
many recent interests in developing effective and scalable DNN verification
techniques and tools. In this work, we introduce a NeuralSAT, a new constraint
solving approach to DNN verification. The design of NeuralSAT follows the
DPLL(T) algorithm used modern SMT solving, which includes (conflict) clause
learning, abstraction, and theory solving, and thus NeuralSAT can be considered
as an SMT framework for DNNs. Preliminary results show that the NeuralSAT
prototype is competitive to the state-of-the-art. We hope, with proper
optimization and engineering, NeuralSAT will carry the power and success of
modern SAT/SMT solvers to DNN verification. NeuralSAT is avaliable from:
https://github.com/dynaroars/neuralsat-solver
</p></li>
</ul>

<h3>Title: FACADE: A Framework for Adversarial Circuit Anomaly Detection and Evaluation. (arXiv:2307.10563v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2307.10563">http://arxiv.org/abs/2307.10563</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2307.10563] FACADE: A Framework for Adversarial Circuit Anomaly Detection and Evaluation](http://arxiv.org/abs/2307.10563) #attack</code></li>
<li>Summary: <p>We present FACADE, a novel probabilistic and geometric framework designed for
unsupervised mechanistic anomaly detection in deep neural networks. Its primary
goal is advancing the understanding and mitigation of adversarial attacks.
FACADE aims to generate probabilistic distributions over circuits, which
provide critical insights to their contribution to changes in the manifold
properties of pseudo-classes, or high-dimensional modes in activation space,
yielding a powerful tool for uncovering and combating adversarial attacks. Our
approach seeks to improve model robustness, enhance scalable model oversight,
and demonstrates promising applications in real-world deployment settings.
</p></li>
</ul>

<h3>Title: Adversarial attacks for mixtures of classifiers. (arXiv:2307.10788v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2307.10788">http://arxiv.org/abs/2307.10788</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2307.10788] Adversarial attacks for mixtures of classifiers](http://arxiv.org/abs/2307.10788) #attack</code></li>
<li>Summary: <p>Mixtures of classifiers (a.k.a. randomized ensembles) have been proposed as a
way to improve robustness against adversarial attacks. However, it has been
shown that existing attacks are not well suited for this kind of classifiers.
In this paper, we discuss the problem of attacking a mixture in a principled
way and introduce two desirable properties of attacks based on a geometrical
analysis of the problem (effectiveness and maximality). We then show that
existing attacks do not meet both of these properties. Finally, we introduce a
new attack called lattice climber attack with theoretical guarantees on the
binary linear setting, and we demonstrate its performance by conducting
experiments on synthetic and real datasets.
</p></li>
</ul>

<h2>robust</h2>
<h3>Title: Combining Vision and EMG-Based Hand Tracking for Extended Reality Musical Instruments. (arXiv:2307.10203v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2307.10203">http://arxiv.org/abs/2307.10203</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2307.10203] Combining Vision and EMG-Based Hand Tracking for Extended Reality Musical Instruments](http://arxiv.org/abs/2307.10203) #robust</code></li>
<li>Summary: <p>Hand tracking is a critical component of natural user interactions in
extended reality (XR) environments, including extended reality musical
instruments (XRMIs). However, self-occlusion remains a significant challenge
for vision-based hand tracking systems, leading to inaccurate results and
degraded user experiences. In this paper, we propose a multimodal hand tracking
system that combines vision-based hand tracking with surface electromyography
(sEMG) data for finger joint angle estimation. We validate the effectiveness of
our system through a series of hand pose tasks designed to cover a wide range
of gestures, including those prone to self-occlusion. By comparing the
performance of our multimodal system to a baseline vision-based tracking
method, we demonstrate that our multimodal approach significantly improves
tracking accuracy for several finger joints prone to self-occlusion. These
findings suggest that our system has the potential to enhance XR experiences by
providing more accurate and robust hand tracking, even in the presence of
self-occlusion.
</p></li>
</ul>

<h3>Title: Adversarial Training Over Long-Tailed Distribution. (arXiv:2307.10205v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2307.10205">http://arxiv.org/abs/2307.10205</a></li>
<li>Code URL: <a href="https://github.com/guanlinlee/reat">https://github.com/guanlinlee/reat</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2307.10205] Adversarial Training Over Long-Tailed Distribution](http://arxiv.org/abs/2307.10205) #robust</code></li>
<li>Summary: <p>In this paper, we study adversarial training on datasets that obey the
long-tailed distribution, which is practical but rarely explored in previous
works. Compared with conventional adversarial training on balanced datasets,
this process falls into the dilemma of generating uneven adversarial examples
(AEs) and an unbalanced feature embedding space, causing the resulting model to
exhibit low robustness and accuracy on tail data. To combat that, we propose a
new adversarial training framework -- Re-balancing Adversarial Training (REAT).
This framework consists of two components: (1) a new training strategy inspired
by the term effective number to guide the model to generate more balanced and
informative AEs; (2) a carefully constructed penalty function to force a
satisfactory feature space. Evaluation results on different datasets and model
structures prove that REAT can effectively enhance the model's robustness and
preserve the model's clean accuracy. The code can be found in
https://github.com/GuanlinLee/REAT.
</p></li>
</ul>

<h3>Title: Ethosight: A Joint-Embedding Based System for Nuanced Perception Using Contextual Label Affinity Metric and Reasoning Based Iterative Learning. (arXiv:2307.10577v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2307.10577">http://arxiv.org/abs/2307.10577</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2307.10577] Ethosight: A Joint-Embedding Based System for Nuanced Perception Using Contextual Label Affinity Metric and Reasoning Based Iterative Learning](http://arxiv.org/abs/2307.10577) #robust</code></li>
<li>Summary: <p>Traditional computer vision models often require extensive manual effort for
data acquisition and validation, particularly when detecting subtle behavioral
nuances or events. The difficulty in distinguishing routine behaviors from
potential risks in real-world applications, like differentiating routine
shopping from potential shoplifting, further complicates the process.
</p></li>
</ul>

<p>We present Ethosight, a novel zero-shot computer vision algorithm. Ethosight
eradicates the need for pre-existing symbolic knowledge, initiating from a
clean slate based on user requirements and semantic knowledge of interest.
Using localized label affinity calculations and a reasoning-guided iterative
learning loop, Ethosight infers scene details and iteratively refines the label
set. Reasoning mechanisms can be derived from large language models like GPT4,
symbolic reasoners like OpenNARS, or hybrid systems.
</p>
<p>Ethosight further capitalizes on the capabilities of a pre-trained
multi-modal model, ImageBind, generating accurate semantic knowledge of images
within a few cycles. It successfully captures both explicit and nuanced
elements efficiently. We also introduce the implementation of Korzybski's
"time-binding" concept in machines, which allows for generational learning and
knowledge sharing across deployments.
</p>
<p>Our evaluations demonstrate Ethosight's efficacy across 40 complex use cases.
It has exhibited an exceptional ability to discern new areas of interest,
consistently generating high-affinity scores within the top five labels from a
set of a thousand. Tests conducted across diverse environments attest to
Ethosight's robust performance. Detailed results and case studies within the
main body of this paper and an appendix underscore a promising trajectory
towards enhancing the adaptability and resilience of computer vision models in
detecting and extracting subtle and nuanced behaviors.
</p>

<h3>Title: Learning and Evaluating Human Preferences for Conversational Head Generation. (arXiv:2307.10636v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2307.10636">http://arxiv.org/abs/2307.10636</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2307.10636] Learning and Evaluating Human Preferences for Conversational Head Generation](http://arxiv.org/abs/2307.10636) #robust</code></li>
<li>Summary: <p>A reliable and comprehensive evaluation metric that aligns with manual
preference assessments is crucial for conversational head video synthesis
method development. Existing quantitative evaluations often fail to capture the
full complexity of human preference, as they only consider limited evaluation
dimensions. Qualitative evaluations and user studies offer a solution but are
time-consuming and labor-intensive. This limitation hinders the advancement of
conversational head generation algorithms and systems. In this paper, we
propose a novel learning-based evaluation metric named Preference Score (PS)
for fitting human preference according to the quantitative evaluations across
different dimensions. PS can serve as a quantitative evaluation without the
need for human annotation. Experimental results validate the superiority of
Preference Score in aligning with human perception, and also demonstrates
robustness and generalizability to unseen data, making it a valuable tool for
advancing conversation head generation. We expect this metric could facilitate
new advances in conversational head generation.
</p></li>
</ul>

<h3>Title: HyperReenact: One-Shot Reenactment via Jointly Learning to Refine and Retarget Faces. (arXiv:2307.10797v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2307.10797">http://arxiv.org/abs/2307.10797</a></li>
<li>Code URL: <a href="https://github.com/stelabou/hyperreenact">https://github.com/stelabou/hyperreenact</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2307.10797] HyperReenact: One-Shot Reenactment via Jointly Learning to Refine and Retarget Faces](http://arxiv.org/abs/2307.10797) #robust</code></li>
<li>Summary: <p>In this paper, we present our method for neural face reenactment, called
HyperReenact, that aims to generate realistic talking head images of a source
identity, driven by a target facial pose. Existing state-of-the-art face
reenactment methods train controllable generative models that learn to
synthesize realistic facial images, yet producing reenacted faces that are
prone to significant visual artifacts, especially under the challenging
condition of extreme head pose changes, or requiring expensive few-shot
fine-tuning to better preserve the source identity characteristics. We propose
to address these limitations by leveraging the photorealistic generation
ability and the disentangled properties of a pretrained StyleGAN2 generator, by
first inverting the real images into its latent space and then using a
hypernetwork to perform: (i) refinement of the source identity characteristics
and (ii) facial pose re-targeting, eliminating this way the dependence on
external editing methods that typically produce artifacts. Our method operates
under the one-shot setting (i.e., using a single source frame) and allows for
cross-subject reenactment, without requiring any subject-specific fine-tuning.
We compare our method both quantitatively and qualitatively against several
state-of-the-art techniques on the standard benchmarks of VoxCeleb1 and
VoxCeleb2, demonstrating the superiority of our approach in producing
artifact-free images, exhibiting remarkable robustness even under extreme head
pose changes. We make the code and the pretrained models publicly available at:
https://github.com/StelaBou/HyperReenact .
</p></li>
</ul>

<h3>Title: Self-paced Weight Consolidation for Continual Learning. (arXiv:2307.10845v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2307.10845">http://arxiv.org/abs/2307.10845</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2307.10845] Self-paced Weight Consolidation for Continual Learning](http://arxiv.org/abs/2307.10845) #robust</code></li>
<li>Summary: <p>Continual learning algorithms which keep the parameters of new tasks close to
that of previous tasks, are popular in preventing catastrophic forgetting in
sequential task learning settings. However, 1) the performance for the new
continual learner will be degraded without distinguishing the contributions of
previously learned tasks; 2) the computational cost will be greatly increased
with the number of tasks, since most existing algorithms need to regularize all
previous tasks when learning new tasks. To address the above challenges, we
propose a self-paced Weight Consolidation (spWC) framework to attain robust
continual learning via evaluating the discriminative contributions of previous
tasks. To be specific, we develop a self-paced regularization to reflect the
priorities of past tasks via measuring difficulty based on key performance
indicator (i.e., accuracy). When encountering a new task, all previous tasks
are sorted from "difficult" to "easy" based on the priorities. Then the
parameters of the new continual learner will be learned via selectively
maintaining the knowledge amongst more difficult past tasks, which could well
overcome catastrophic forgetting with less computational cost. We adopt an
alternative convex search to iteratively update the model parameters and
priority weights in the bi-convex formulation. The proposed spWC framework is
plug-and-play, which is applicable to most continual learning algorithms (e.g.,
EWC, MAS and RCIL) in different directions (e.g., classification and
segmentation). Experimental results on several public benchmark datasets
demonstrate that our proposed framework can effectively improve performance
when compared with other popular continual learning algorithms.
</p></li>
</ul>

<h3>Title: Risk-optimized Outlier Removal for Robust Point Cloud Classification. (arXiv:2307.10875v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2307.10875">http://arxiv.org/abs/2307.10875</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2307.10875] Risk-optimized Outlier Removal for Robust Point Cloud Classification](http://arxiv.org/abs/2307.10875) #robust</code></li>
<li>Summary: <p>The popularity of point cloud deep models for safety-critical purposes has
increased, but the reliability and security of these models can be compromised
by intentional or naturally occurring point cloud noise. To combat this issue,
we present a novel point cloud outlier removal method called PointCVaR, which
empowers standard-trained models to eliminate additional outliers and restore
the data. Our approach begins by conducting attribution analysis to determine
the influence of each point on the model output, which we refer to as point
risk. We then optimize the process of filtering high-risk points using
Conditional Value at Risk (CVaR) as the objective. The rationale for this
approach is based on the observation that noise points in point clouds tend to
cluster in the tail of the risk distribution, with a low frequency but a high
level of risk, resulting in significant interference with classification
results. Despite requiring no additional training effort, our method produces
exceptional results in various removal-and-classification experiments for noisy
point clouds, which are corrupted by random noise, adversarial noise, and
backdoor trigger noise. Impressively, it achieves 87% accuracy in defense
against the backdoor attack by removing triggers. Overall, the proposed
PointCVaR effectively eliminates noise points and enhances point cloud
classification, making it a promising plug-in module for various models in
different scenarios.
</p></li>
</ul>

<h3>Title: General Debiasing for Multimodal Sentiment Analysis. (arXiv:2307.10511v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2307.10511">http://arxiv.org/abs/2307.10511</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2307.10511] General Debiasing for Multimodal Sentiment Analysis](http://arxiv.org/abs/2307.10511) #robust</code></li>
<li>Summary: <p>Existing work on Multimodal Sentiment Analysis (MSA) utilizes multimodal
information for prediction yet unavoidably suffers from fitting the spurious
correlations between multimodal features and sentiment labels. For example, if
most videos with a blue background have positive labels in a dataset, the model
will rely on such correlations for prediction, while ``blue background'' is not
a sentiment-related feature. To address this problem, we define a general
debiasing MSA task, which aims to enhance the Out-Of-Distribution (OOD)
generalization ability of MSA models by reducing their reliance on spurious
correlations. To this end, we propose a general debiasing framework based on
Inverse Probability Weighting (IPW), which adaptively assigns small weights to
the samples with larger bias i.e., the severer spurious correlations). The key
to this debiasing framework is to estimate the bias of each sample, which is
achieved by two steps: 1) disentangling the robust features and biased features
in each modality, and 2) utilizing the biased features to estimate the bias.
Finally, we employ IPW to reduce the effects of large-biased samples,
facilitating robust feature learning for sentiment prediction. To examine the
model's generalization ability, we keep the original testing sets on two
benchmarks and additionally construct multiple unimodal and multimodal OOD
testing sets. The empirical results demonstrate the superior generalization
ability of our proposed framework. We have released the code and data to
facilitate the reproduction.
</p></li>
</ul>

<h3>Title: A Deep Dive into the Disparity of Word Error Rates Across Thousands of NPTEL MOOC Videos. (arXiv:2307.10587v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2307.10587">http://arxiv.org/abs/2307.10587</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2307.10587] A Deep Dive into the Disparity of Word Error Rates Across Thousands of NPTEL MOOC Videos](http://arxiv.org/abs/2307.10587) #robust</code></li>
<li>Summary: <p>Automatic speech recognition (ASR) systems are designed to transcribe spoken
language into written text and find utility in a variety of applications
including voice assistants and transcription services. However, it has been
observed that state-of-the-art ASR systems which deliver impressive benchmark
results, struggle with speakers of certain regions or demographics due to
variation in their speech properties. In this work, we describe the curation of
a massive speech dataset of 8740 hours consisting of $\sim9.8$K technical
lectures in the English language along with their transcripts delivered by
instructors representing various parts of Indian demography. The dataset is
sourced from the very popular NPTEL MOOC platform. We use the curated dataset
to measure the existing disparity in YouTube Automatic Captions and OpenAI
Whisper model performance across the diverse demographic traits of speakers in
India. While there exists disparity due to gender, native region, age and
speech rate of speakers, disparity based on caste is non-existent. We also
observe statistically significant disparity across the disciplines of the
lectures. These results indicate the need of more inclusive and robust ASR
systems and more representational datasets for disparity evaluation in them.
</p></li>
</ul>

<h3>Title: Beyond Black-Box Advice: Learning-Augmented Algorithms for MDPs with Q-Value Predictions. (arXiv:2307.10524v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2307.10524">http://arxiv.org/abs/2307.10524</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2307.10524] Beyond Black-Box Advice: Learning-Augmented Algorithms for MDPs with Q-Value Predictions](http://arxiv.org/abs/2307.10524) #robust</code></li>
<li>Summary: <p>We study the tradeoff between consistency and robustness in the context of a
single-trajectory time-varying Markov Decision Process (MDP) with untrusted
machine-learned advice. Our work departs from the typical approach of treating
advice as coming from black-box sources by instead considering a setting where
additional information about how the advice is generated is available. We prove
a first-of-its-kind consistency and robustness tradeoff given Q-value advice
under a general MDP model that includes both continuous and discrete
state/action spaces. Our results highlight that utilizing Q-value advice
enables dynamic pursuit of the better of machine-learned advice and a robust
baseline, thus result in near-optimal performance guarantees, which provably
improves what can be obtained solely with black-box advice.
</p></li>
</ul>

<h3>Title: Forecasting Battery Electric Vehicle Charging Behavior: A Deep Learning Approach Equipped with Micro-Clustering and SMOTE Techniques. (arXiv:2307.10588v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2307.10588">http://arxiv.org/abs/2307.10588</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2307.10588] Forecasting Battery Electric Vehicle Charging Behavior: A Deep Learning Approach Equipped with Micro-Clustering and SMOTE Techniques](http://arxiv.org/abs/2307.10588) #robust</code></li>
<li>Summary: <p>Energy systems, climate change, and public health are among the primary
reasons for moving toward electrification in transportation. Transportation
electrification is being promoted worldwide to reduce emissions. As a result,
many automakers will soon start making only battery electric vehicles (BEVs).
BEV adoption rates are rising in California, mainly due to climate change and
air pollution concerns. While great for climate and pollution goals, improperly
managed BEV charging can lead to insufficient charging infrastructure and power
outages. This study develops a novel Micro Clustering Deep Neural Network
(MCDNN), an artificial neural network algorithm that is highly effective at
learning BEVs trip and charging data to forecast BEV charging events,
information that is essential for electricity load aggregators and utility
managers to provide charging stations and electricity capacity effectively. The
MCDNN is configured using a robust dataset of trips and charges that occurred
in California between 2015 and 2020 from 132 BEVs, spanning 5 BEV models for a
total of 1570167 vehicle miles traveled. The numerical findings revealed that
the proposed MCDNN is more effective than benchmark approaches in this field,
such as support vector machine, k nearest neighbors, decision tree, and other
neural network-based models in predicting the charging events.
</p></li>
</ul>

<h3>Title: Fisher-Rao distance and pullback SPD cone distances between multivariate normal distributions. (arXiv:2307.10644v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2307.10644">http://arxiv.org/abs/2307.10644</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2307.10644] Fisher-Rao distance and pullback SPD cone distances between multivariate normal distributions](http://arxiv.org/abs/2307.10644) #robust</code></li>
<li>Summary: <p>Data sets of multivariate normal distributions abound in many scientific
areas like diffusion tensor imaging, structure tensor computer vision, radar
signal processing, machine learning, just to name a few. In order to process
those normal data sets for downstream tasks like filtering, classification or
clustering, one needs to define proper notions of dissimilarities between
normals and paths joining them. The Fisher-Rao distance defined as the
Riemannian geodesic distance induced by the Fisher information metric is such a
principled metric distance which however is not known in closed-form excepts
for a few particular cases. In this work, we first report a fast and robust
method to approximate arbitrarily finely the Fisher-Rao distance between
multivariate normal distributions. Second, we introduce a class of distances
based on diffeomorphic embeddings of the normal manifold into a submanifold of
the higher-dimensional symmetric positive-definite cone corresponding to the
manifold of centered normal distributions. We show that the projective Hilbert
distance on the cone yields a metric on the embedded normal submanifold and we
pullback that cone distance with its associated straight line Hilbert cone
geodesics to obtain a distance and smooth paths between normal distributions.
Compared to the Fisher-Rao distance approximation, the pullback Hilbert cone
distance is computationally light since it requires to compute only the extreme
minimal and maximal eigenvalues of matrices. Finally, we show how to use those
distances in clustering tasks.
</p></li>
</ul>

<h2>biometric</h2>
<h2>steal</h2>
<h3>Title: A Dual Stealthy Backdoor: From Both Spatial and Frequency Perspectives. (arXiv:2307.10184v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2307.10184">http://arxiv.org/abs/2307.10184</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2307.10184] A Dual Stealthy Backdoor: From Both Spatial and Frequency Perspectives](http://arxiv.org/abs/2307.10184) #steal</code></li>
<li>Summary: <p>Backdoor attacks pose serious security threats to deep neural networks
(DNNs). Backdoored models make arbitrarily (targeted) incorrect predictions on
inputs embedded with well-designed triggers while behaving normally on clean
inputs. Many works have explored the invisibility of backdoor triggers to
improve attack stealthiness. However, most of them only consider the
invisibility in the spatial domain without explicitly accounting for the
generation of invisible triggers in the frequency domain, making the generated
poisoned images be easily detected by recent defense methods. To address this
issue, in this paper, we propose a DUal stealthy BAckdoor attack method named
DUBA, which simultaneously considers the invisibility of triggers in both the
spatial and frequency domains, to achieve desirable attack performance, while
ensuring strong stealthiness. Specifically, we first use Discrete Wavelet
Transform to embed the high-frequency information of the trigger image into the
clean image to ensure attack effectiveness. Then, to attain strong
stealthiness, we incorporate Fourier Transform and Discrete Cosine Transform to
mix the poisoned image and clean image in the frequency domain. Moreover, the
proposed DUBA adopts a novel attack strategy, in which the model is trained
with weak triggers and attacked with strong triggers to further enhance the
attack performance and stealthiness. We extensively evaluate DUBA against
popular image classifiers on four datasets. The results demonstrate that it
significantly outperforms the state-of-the-art backdoor attacks in terms of the
attack success rate and stealthiness
</p></li>
</ul>

<h2>extraction</h2>
<h3>Title: No-frills Temporal Video Grounding: Multi-Scale Neighboring Attention and Zoom-in Boundary Detection. (arXiv:2307.10567v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2307.10567">http://arxiv.org/abs/2307.10567</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2307.10567] No-frills Temporal Video Grounding: Multi-Scale Neighboring Attention and Zoom-in Boundary Detection](http://arxiv.org/abs/2307.10567) #extraction</code></li>
<li>Summary: <p>Temporal video grounding (TVG) aims to retrieve the time interval of a
language query from an untrimmed video. A significant challenge in TVG is the
low "Semantic Noise Ratio (SNR)", which results in worse performance with lower
SNR. Prior works have addressed this challenge using sophisticated techniques.
In this paper, we propose a no-frills TVG model that consists of two core
modules, namely multi-scale neighboring attention and zoom-in boundary
detection. The multi-scale neighboring attention restricts each video token to
only aggregate visual contexts from its neighbor, enabling the extraction of
the most distinguishing information with multi-scale feature hierarchies from
high-ratio noises. The zoom-in boundary detection then focuses on local-wise
discrimination of the selected top candidates for fine-grained grounding
adjustment. With an end-to-end training strategy, our model achieves
competitive performance on different TVG benchmarks, while also having the
advantage of faster inference speed and lighter model parameters, thanks to its
lightweight architecture.
</p></li>
</ul>

<h3>Title: Hybrid Feature Embedding For Automatic Building Outline Extraction. (arXiv:2307.10609v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2307.10609">http://arxiv.org/abs/2307.10609</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2307.10609] Hybrid Feature Embedding For Automatic Building Outline Extraction](http://arxiv.org/abs/2307.10609) #extraction</code></li>
<li>Summary: <p>Building outline extracted from high-resolution aerial images can be used in
various application fields such as change detection and disaster assessment.
However, traditional CNN model cannot recognize contours very precisely from
original images. In this paper, we proposed a CNN and Transformer based model
together with active contour model to deal with this problem. We also designed
a triple-branch decoder structure to handle different features generated by
encoder. Experiment results show that our model outperforms other baseline
model on two datasets, achieving 91.1% mIoU on Vaihingen and 83.8% on Bing
huts.
</p></li>
</ul>

<h3>Title: Self2Self+: Single-Image Denoising with Self-Supervised Learning and Image Quality Assessment Loss. (arXiv:2307.10695v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2307.10695">http://arxiv.org/abs/2307.10695</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2307.10695] Self2Self+: Single-Image Denoising with Self-Supervised Learning and Image Quality Assessment Loss](http://arxiv.org/abs/2307.10695) #extraction</code></li>
<li>Summary: <p>Recently, denoising methods based on supervised learning have exhibited
promising performance. However, their reliance on external datasets containing
noisy-clean image pairs restricts their applicability. To address this
limitation, researchers have focused on training denoising networks using
solely a set of noisy inputs. To improve the feasibility of denoising
procedures, in this study, we proposed a single-image self-supervised learning
method in which only the noisy input image is used for network training. Gated
convolution was used for feature extraction and no-reference image quality
assessment was used for guiding the training process. Moreover, the proposed
method sampled instances from the input image dataset using Bernoulli sampling
with a certain dropout rate for training. The corresponding result was produced
by averaging the generated predictions from various instances of the trained
network with dropouts. The experimental results indicated that the proposed
method achieved state-of-the-art denoising performance on both synthetic and
real-world datasets. This highlights the effectiveness and practicality of our
method as a potential solution for various noise removal tasks.
</p></li>
</ul>

<h3>Title: Mutual Reinforcement Effects in Japanese Sentence Classification and Named Entity Recognition Tasks. (arXiv:2307.10291v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2307.10291">http://arxiv.org/abs/2307.10291</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2307.10291] Mutual Reinforcement Effects in Japanese Sentence Classification and Named Entity Recognition Tasks](http://arxiv.org/abs/2307.10291) #extraction</code></li>
<li>Summary: <p>Information extraction(IE) is a crucial subfield within natural language
processing. However, for the traditionally segmented approach to sentence
classification and Named Entity Recognition, the intricate interactions between
these individual subtasks remain largely uninvestigated. In this study, we
propose an integrative analysis, converging sentence classification with Named
Entity Recognition, with the objective to unveil and comprehend the mutual
reinforcement effect within these two information extraction subtasks. To
achieve this, we introduce a Sentence Classification and Named Entity
Recognition Multi-task (SCNM) approach that combines Sentence Classification
(SC) and Named Entity Recognition (NER). We develop a Sentence-to-Label
Generation (SLG) framework for SCNM and construct a Wikipedia dataset
containing both SC and NER. Using a format converter, we unify input formats
and employ a generative model to generate SC-labels, NER-labels, and associated
text segments. We propose a Constraint Mechanism (CM) to improve generated
format accuracy. Our results show SC accuracy increased by 1.13 points and NER
by 1.06 points in SCNM compared to standalone tasks, with CM raising format
accuracy from 63.61 to 100. The findings indicate mutual reinforcement effects
between SC and NER, and integration enhances both tasks' performance. We
additionally implemented the SLG framework on single SC task. It yielded
superior accuracies compared to the baseline on two distinct Japanese SC
datasets. Notably, in the experiment of few-shot learning, SLG framework shows
much better performance than fine-tune method. These empirical findings
contribute additional evidence to affirm the efficacy of the SLG framework.
</p></li>
</ul>

<h3>Title: Extreme Multi-Label Skill Extraction Training using Large Language Models. (arXiv:2307.10778v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2307.10778">http://arxiv.org/abs/2307.10778</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2307.10778] Extreme Multi-Label Skill Extraction Training using Large Language Models](http://arxiv.org/abs/2307.10778) #extraction</code></li>
<li>Summary: <p>Online job ads serve as a valuable source of information for skill
requirements, playing a crucial role in labor market analysis and e-recruitment
processes. Since such ads are typically formatted in free text, natural
language processing (NLP) technologies are required to automatically process
them. We specifically focus on the task of detecting skills (mentioned
literally, or implicitly described) and linking them to a large skill ontology,
making it a challenging case of extreme multi-label classification (XMLC).
Given that there is no sizable labeled (training) dataset are available for
this specific XMLC task, we propose techniques to leverage general Large
Language Models (LLMs). We describe a cost-effective approach to generate an
accurate, fully synthetic labeled dataset for skill extraction, and present a
contrastive learning strategy that proves effective in the task. Our results
across three skill extraction benchmarks show a consistent increase of between
15 to 25 percentage points in \textit{R-Precision@5} compared to previously
published results that relied solely on distant supervision through literal
matches.
</p></li>
</ul>

<h2>membership infer</h2>
<h2>federate</h2>
<h3>Title: FedSoup: Improving Generalization and Personalization in Federated Learning via Selective Model Interpolation. (arXiv:2307.10507v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2307.10507">http://arxiv.org/abs/2307.10507</a></li>
<li>Code URL: <a href="https://github.com/ubc-tea/fedsoup">https://github.com/ubc-tea/fedsoup</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2307.10507] FedSoup: Improving Generalization and Personalization in Federated Learning via Selective Model Interpolation](http://arxiv.org/abs/2307.10507) #federate</code></li>
<li>Summary: <p>Cross-silo federated learning (FL) enables the development of machine
learning models on datasets distributed across data centers such as hospitals
and clinical research laboratories. However, recent research has found that
current FL algorithms face a trade-off between local and global performance
when confronted with distribution shifts. Specifically, personalized FL methods
have a tendency to overfit to local data, leading to a sharp valley in the
local model and inhibiting its ability to generalize to out-of-distribution
data. In this paper, we propose a novel federated model soup method (i.e.,
selective interpolation of model parameters) to optimize the trade-off between
local and global performance. Specifically, during the federated training
phase, each client maintains its own global model pool by monitoring the
performance of the interpolated model between the local and global models. This
allows us to alleviate overfitting and seek flat minima, which can
significantly improve the model's generalization performance. We evaluate our
method on retinal and pathological image classification tasks, and our proposed
method achieves significant improvements for out-of-distribution
generalization. Our code is available at https://github.com/ubc-tea/FedSoup.
</p></li>
</ul>

<h3>Title: Boosting Federated Learning Convergence with Prototype Regularization. (arXiv:2307.10575v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2307.10575">http://arxiv.org/abs/2307.10575</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2307.10575] Boosting Federated Learning Convergence with Prototype Regularization](http://arxiv.org/abs/2307.10575) #federate</code></li>
<li>Summary: <p>As a distributed machine learning technique, federated learning (FL) requires
clients to collaboratively train a shared model with an edge server without
leaking their local data. However, the heterogeneous data distribution among
clients often leads to a decrease in model performance. To tackle this issue,
this paper introduces a prototype-based regularization strategy to address the
heterogeneity in the data distribution. Specifically, the regularization
process involves the server aggregating local prototypes from distributed
clients to generate a global prototype, which is then sent back to the
individual clients to guide their local training. The experimental results on
MNIST and Fashion-MNIST show that our proposal achieves improvements of 3.3%
and 8.9% in average test accuracy, respectively, compared to the most popular
baseline FedAvg. Furthermore, our approach has a fast convergence rate in
heterogeneous settings.
</p></li>
</ul>

<h3>Title: Heterogeneous Federated Learning: State-of-the-art and Research Challenges. (arXiv:2307.10616v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2307.10616">http://arxiv.org/abs/2307.10616</a></li>
<li>Code URL: <a href="https://github.com/marswhu/hfl_survey">https://github.com/marswhu/hfl_survey</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2307.10616] Heterogeneous Federated Learning: State-of-the-art and Research Challenges](http://arxiv.org/abs/2307.10616) #federate</code></li>
<li>Summary: <p>Federated learning (FL) has drawn increasing attention owing to its potential
use in large-scale industrial applications. Existing federated learning works
mainly focus on model homogeneous settings. However, practical federated
learning typically faces the heterogeneity of data distributions, model
architectures, network environments, and hardware devices among participant
clients. Heterogeneous Federated Learning (HFL) is much more challenging, and
corresponding solutions are diverse and complex. Therefore, a systematic survey
on this topic about the research challenges and state-of-the-art is essential.
In this survey, we firstly summarize the various research challenges in HFL
from five aspects: statistical heterogeneity, model heterogeneity,
communication heterogeneity, device heterogeneity, and additional challenges.
In addition, recent advances in HFL are reviewed and a new taxonomy of existing
HFL methods is proposed with an in-depth analysis of their pros and cons. We
classify existing methods from three different levels according to the HFL
procedure: data-level, model-level, and server-level. Finally, several critical
and promising future research directions in HFL are discussed, which may
facilitate further developments in this field. A periodically updated
collection on HFL is available at https://github.com/marswhu/HFL_Survey.
</p></li>
</ul>

<h3>Title: Eliminating Label Leakage in Tree-Based Vertical Federated Learning. (arXiv:2307.10318v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2307.10318">http://arxiv.org/abs/2307.10318</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2307.10318] Eliminating Label Leakage in Tree-Based Vertical Federated Learning](http://arxiv.org/abs/2307.10318) #federate</code></li>
<li>Summary: <p>Vertical federated learning (VFL) enables multiple parties with disjoint
features of a common user set to train a machine learning model without sharing
their private data. Tree-based models have become prevalent in VFL due to their
interpretability and efficiency. However, the vulnerability of tree-based VFL
has not been sufficiently investigated. In this study, we first introduce a
novel label inference attack, ID2Graph, which utilizes the sets of record-IDs
assigned to each node (i.e., instance space) to deduce private training labels.
The ID2Graph attack generates a graph structure from training samples, extracts
communities from the graph, and clusters the local dataset using community
information. To counteract label leakage from the instance space, we propose an
effective defense mechanism, ID-LMID, which prevents label leakage by focusing
on mutual information regularization. Comprehensive experiments conducted on
various datasets reveal that the ID2Graph attack presents significant risks to
tree-based models such as Random Forest and XGBoost. Further evaluations on
these benchmarks demonstrate that ID-LMID effectively mitigates label leakage
in such instances.
</p></li>
</ul>

<h3>Title: FedBug: A Bottom-Up Gradual Unfreezing Framework for Federated Learning. (arXiv:2307.10317v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2307.10317">http://arxiv.org/abs/2307.10317</a></li>
<li>Code URL: <a href="https://github.com/iandrover/fedbug">https://github.com/iandrover/fedbug</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2307.10317] FedBug: A Bottom-Up Gradual Unfreezing Framework for Federated Learning](http://arxiv.org/abs/2307.10317) #federate</code></li>
<li>Summary: <p>Federated Learning (FL) offers a collaborative training framework, allowing
multiple clients to contribute to a shared model without compromising data
privacy. Due to the heterogeneous nature of local datasets, updated client
models may overfit and diverge from one another, commonly known as the problem
of client drift. In this paper, we propose FedBug (Federated Learning with
Bottom-Up Gradual Unfreezing), a novel FL framework designed to effectively
mitigate client drift. FedBug adaptively leverages the client model parameters,
distributed by the server at each global round, as the reference points for
cross-client alignment. Specifically, on the client side, FedBug begins by
freezing the entire model, then gradually unfreezes the layers, from the input
layer to the output layer. This bottom-up approach allows models to train the
newly thawed layers to project data into a latent space, wherein the separating
hyperplanes remain consistent across all clients. We theoretically analyze
FedBug in a novel over-parameterization FL setup, revealing its superior
convergence rate compared to FedAvg. Through comprehensive experiments,
spanning various datasets, training conditions, and network architectures, we
validate the efficacy of FedBug. Our contributions encompass a novel FL
framework, theoretical analysis, and empirical validation, demonstrating the
wide potential and applicability of FedBug.
</p></li>
</ul>

<h3>Title: Blockchain-Based Federated Learning: Incentivizing Data Sharing and Penalizing Dishonest Behavior. (arXiv:2307.10492v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2307.10492">http://arxiv.org/abs/2307.10492</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2307.10492] Blockchain-Based Federated Learning: Incentivizing Data Sharing and Penalizing Dishonest Behavior](http://arxiv.org/abs/2307.10492) #federate</code></li>
<li>Summary: <p>With the increasing importance of data sharing for collaboration and
innovation, it is becoming more important to ensure that data is managed and
shared in a secure and trustworthy manner. Data governance is a common approach
to managing data, but it faces many challenges such as data silos, data
consistency, privacy, security, and access control. To address these
challenges, this paper proposes a comprehensive framework that integrates data
trust in federated learning with InterPlanetary File System, blockchain, and
smart contracts to facilitate secure and mutually beneficial data sharing while
providing incentives, access control mechanisms, and penalizing any dishonest
behavior. The experimental results demonstrate that the proposed model is
effective in improving the accuracy of federated learning models while ensuring
the security and fairness of the data-sharing process. The research paper also
presents a decentralized federated learning platform that successfully trained
a CNN model on the MNIST dataset using blockchain technology. The platform
enables multiple workers to train the model simultaneously while maintaining
data privacy and security. The decentralized architecture and use of blockchain
technology allow for efficient communication and coordination between workers.
This platform has the potential to facilitate decentralized machine learning
and support privacy-preserving collaboration in various domains.
</p></li>
</ul>

<h3>Title: Fairness-Aware Client Selection for Federated Learning. (arXiv:2307.10738v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2307.10738">http://arxiv.org/abs/2307.10738</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2307.10738] Fairness-Aware Client Selection for Federated Learning](http://arxiv.org/abs/2307.10738) #federate</code></li>
<li>Summary: <p>Federated learning (FL) has enabled multiple data owners (a.k.a. FL clients)
to train machine learning models collaboratively without revealing private
data. Since the FL server can only engage a limited number of clients in each
training round, FL client selection has become an important research problem.
Existing approaches generally focus on either enhancing FL model performance or
enhancing the fair treatment of FL clients. The problem of balancing
performance and fairness considerations when selecting FL clients remains open.
To address this problem, we propose the Fairness-aware Federated Client
Selection (FairFedCS) approach. Based on Lyapunov optimization, it dynamically
adjusts FL clients' selection probabilities by jointly considering their
reputations, times of participation in FL tasks and contributions to the
resulting model performance. By not using threshold-based reputation filtering,
it provides FL clients with opportunities to redeem their reputations after a
perceived poor performance, thereby further enhancing fair client treatment.
Extensive experiments based on real-world multimedia datasets show that
FairFedCS achieves 19.6% higher fairness and 0.73% higher test accuracy on
average than the best-performing state-of-the-art approach.
</p></li>
</ul>

<h2>fair</h2>
<h3>Title: Mitigating Bias in Conversations: A Hate Speech Classifier and Debiaser with Prompts. (arXiv:2307.10213v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2307.10213">http://arxiv.org/abs/2307.10213</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2307.10213] Mitigating Bias in Conversations: A Hate Speech Classifier and Debiaser with Prompts](http://arxiv.org/abs/2307.10213) #fair</code></li>
<li>Summary: <p>Discriminatory language and biases are often present in hate speech during
conversations, which usually lead to negative impacts on targeted groups such
as those based on race, gender, and religion. To tackle this issue, we propose
an approach that involves a two-step process: first, detecting hate speech
using a classifier, and then utilizing a debiasing component that generates
less biased or unbiased alternatives through prompts. We evaluated our approach
on a benchmark dataset and observed reduction in negativity due to hate speech
comments. The proposed method contributes to the ongoing efforts to reduce
biases in online discourse and promote a more inclusive and fair environment
for communication.
</p></li>
</ul>

<h2>interpretability</h2>
<h3>Title: Mitigating Viewer Impact from Disturbing Imagery using AI Filters: A User-Study. (arXiv:2307.10334v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2307.10334">http://arxiv.org/abs/2307.10334</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2307.10334] Mitigating Viewer Impact from Disturbing Imagery using AI Filters: A User-Study](http://arxiv.org/abs/2307.10334) #interpretability</code></li>
<li>Summary: <p>Exposure to disturbing imagery can significantly impact individuals,
especially professionals who encounter such content as part of their work. This
paper presents a user study, involving 107 participants, predominantly
journalists and human rights investigators, that explores the capability of
Artificial Intelligence (AI)-based image filters to potentially mitigate the
emotional impact of viewing such disturbing content. We tested five different
filter styles, both traditional (Blurring and Partial Blurring) and AI-based
(Drawing, Colored Drawing, and Painting), and measured their effectiveness in
terms of conveying image information while reducing emotional distress. Our
findings suggest that the AI-based Drawing style filter demonstrates the best
performance, offering a promising solution for reducing negative feelings
(-30.38%) while preserving the interpretability of the image (97.19%). Despite
the requirement for many professionals to eventually inspect the original
images, participants suggested potential strategies for integrating AI filters
into their workflow, such as using AI filters as an initial, preparatory step
before viewing the original image. Overall, this paper contributes to the
development of a more ethically considerate and effective visual environment
for professionals routinely engaging with potentially disturbing imagery.
</p></li>
</ul>

<h3>Title: Interpreting and Correcting Medical Image Classification with PIP-Net. (arXiv:2307.10404v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2307.10404">http://arxiv.org/abs/2307.10404</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2307.10404] Interpreting and Correcting Medical Image Classification with PIP-Net](http://arxiv.org/abs/2307.10404) #interpretability</code></li>
<li>Summary: <p>Part-prototype models are explainable-by-design image classifiers, and a
promising alternative to black box AI. This paper explores the applicability
and potential of interpretable machine learning, in particular PIP-Net, for
automated diagnosis support on real-world medical imaging data. PIP-Net learns
human-understandable prototypical image parts and we evaluate its accuracy and
interpretability for fracture detection and skin cancer diagnosis. We find that
PIP-Net's decision making process is in line with medical classification
standards, while only provided with image-level class labels. Because of
PIP-Net's unsupervised pretraining of prototypes, data quality problems such as
undesired text in an X-ray or labelling errors can be easily identified.
Additionally, we are the first to show that humans can manually correct the
reasoning of PIP-Net by directly disabling undesired prototypes. We conclude
that part-prototype models are promising for medical applications due to their
interpretability and potential for advanced model debugging.
</p></li>
</ul>

<h3>Title: Explaining Autonomous Driving Actions with Visual Question Answering. (arXiv:2307.10408v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2307.10408">http://arxiv.org/abs/2307.10408</a></li>
<li>Code URL: <a href="https://github.com/shahin-01/vqa-ad">https://github.com/shahin-01/vqa-ad</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2307.10408] Explaining Autonomous Driving Actions with Visual Question Answering](http://arxiv.org/abs/2307.10408) #interpretability</code></li>
<li>Summary: <p>The end-to-end learning ability of self-driving vehicles has achieved
significant milestones over the last decade owing to rapid advances in deep
learning and computer vision algorithms. However, as autonomous driving
technology is a safety-critical application of artificial intelligence (AI),
road accidents and established regulatory principles necessitate the need for
the explainability of intelligent action choices for self-driving vehicles. To
facilitate interpretability of decision-making in autonomous driving, we
present a Visual Question Answering (VQA) framework, which explains driving
actions with question-answering-based causal reasoning. To do so, we first
collect driving videos in a simulation environment using reinforcement learning
(RL) and extract consecutive frames from this log data uniformly for five
selected action categories. Further, we manually annotate the extracted frames
using question-answer pairs as justifications for the actions chosen in each
scenario. Finally, we evaluate the correctness of the VQA-predicted answers for
actions on unseen driving scenes. The empirical results suggest that the VQA
mechanism can provide support to interpret real-time decisions of autonomous
vehicles and help enhance overall driving safety.
</p></li>
</ul>

<h3>Title: Identifying Interpretable Subspaces in Image Representations. (arXiv:2307.10504v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2307.10504">http://arxiv.org/abs/2307.10504</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2307.10504] Identifying Interpretable Subspaces in Image Representations](http://arxiv.org/abs/2307.10504) #interpretability</code></li>
<li>Summary: <p>We propose Automatic Feature Explanation using Contrasting Concepts (FALCON),
an interpretability framework to explain features of image representations. For
a target feature, FALCON captions its highly activating cropped images using a
large captioning dataset (like LAION-400m) and a pre-trained vision-language
model like CLIP. Each word among the captions is scored and ranked leading to a
small number of shared, human-understandable concepts that closely describe the
target feature. FALCON also applies contrastive interpretation using lowly
activating (counterfactual) images, to eliminate spurious concepts. Although
many existing approaches interpret features independently, we observe in
state-of-the-art self-supervised and supervised models, that less than 20% of
the representation space can be explained by individual features. We show that
features in larger spaces become more interpretable when studied in groups and
can be explained with high-order scoring concepts through FALCON. We discuss
how extracted concepts can be used to explain and debug failures in downstream
tasks. Finally, we present a technique to transfer concepts from one
(explainable) representation space to another unseen representation space by
learning a simple linear transformation.
</p></li>
</ul>

<h2>explainability</h2>
<h2>watermark</h2>
<h2>diffusion</h2>
<h3>Title: TokenFlow: Consistent Diffusion Features for Consistent Video Editing. (arXiv:2307.10373v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2307.10373">http://arxiv.org/abs/2307.10373</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2307.10373] TokenFlow: Consistent Diffusion Features for Consistent Video Editing](http://arxiv.org/abs/2307.10373) #diffusion</code></li>
<li>Summary: <p>The generative AI revolution has recently expanded to videos. Nevertheless,
current state-of-the-art video models are still lagging behind image models in
terms of visual quality and user control over the generated content. In this
work, we present a framework that harnesses the power of a text-to-image
diffusion model for the task of text-driven video editing. Specifically, given
a source video and a target text-prompt, our method generates a high-quality
video that adheres to the target text, while preserving the spatial layout and
motion of the input video. Our method is based on a key observation that
consistency in the edited video can be obtained by enforcing consistency in the
diffusion feature space. We achieve this by explicitly propagating diffusion
features based on inter-frame correspondences, readily available in the model.
Thus, our framework does not require any training or fine-tuning, and can work
in conjunction with any off-the-shelf text-to-image editing method. We
demonstrate state-of-the-art editing results on a variety of real-world videos.
Webpage: https://diffusion-tokenflow.github.io/
</p></li>
</ul>

<h3>Title: PreDiff: Precipitation Nowcasting with Latent Diffusion Models. (arXiv:2307.10422v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2307.10422">http://arxiv.org/abs/2307.10422</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2307.10422] PreDiff: Precipitation Nowcasting with Latent Diffusion Models](http://arxiv.org/abs/2307.10422) #diffusion</code></li>
<li>Summary: <p>Earth system forecasting has traditionally relied on complex physical models
that are computationally expensive and require significant domain expertise. In
the past decade, the unprecedented increase in spatiotemporal Earth observation
data has enabled data-driven forecasting models using deep learning techniques.
These models have shown promise for diverse Earth system forecasting tasks but
either struggle with handling uncertainty or neglect domain-specific prior
knowledge, resulting in averaging possible futures to blurred forecasts or
generating physically implausible predictions. To address these limitations, we
propose a two-stage pipeline for probabilistic spatiotemporal forecasting: 1)
We develop PreDiff, a conditional latent diffusion model capable of
probabilistic forecasts. 2) We incorporate an explicit knowledge control
mechanism to align forecasts with domain-specific physical constraints. This is
achieved by estimating the deviation from imposed constraints at each denoising
step and adjusting the transition distribution accordingly. We conduct
empirical studies on two datasets: N-body MNIST, a synthetic dataset with
chaotic behavior, and SEVIR, a real-world precipitation nowcasting dataset.
Specifically, we impose the law of conservation of energy in N-body MNIST and
anticipated precipitation intensity in SEVIR. Experiments demonstrate the
effectiveness of PreDiff in handling uncertainty, incorporating domain-specific
prior knowledge, and generating forecasts that exhibit high operational
utility.
</p></li>
</ul>

<h3>Title: Reference-based Painterly Inpainting via Diffusion: Crossing the Wild Reference Domain Gap. (arXiv:2307.10584v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2307.10584">http://arxiv.org/abs/2307.10584</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2307.10584] Reference-based Painterly Inpainting via Diffusion: Crossing the Wild Reference Domain Gap](http://arxiv.org/abs/2307.10584) #diffusion</code></li>
<li>Summary: <p>Have you ever imagined how it would look if we placed new objects into
paintings? For example, what would it look like if we placed a basketball into
Claude Monet's <code>Water Lilies, Evening Effect''? We propose Reference-based
Painterly Inpainting, a novel task that crosses the wild reference domain gap
and implants novel objects into artworks. Although previous works have examined
reference-based inpainting, they are not designed for large domain
discrepancies between the target and the reference, such as inpainting an
artistic image using a photorealistic reference. This paper proposes a novel
diffusion framework, dubbed RefPaint, to</code>inpaint more wildly'' by taking such
references with large domain gaps. Built with an image-conditioned diffusion
model, we introduce a ladder-side branch and a masked fusion mechanism to work
with the inpainting mask. By decomposing the CLIP image embeddings at inference
time, one can manipulate the strength of semantic and style information with
ease. Experiments demonstrate that our proposed RefPaint framework produces
significantly better results than existing methods. Our method enables creative
painterly image inpainting with reference objects that would otherwise be
difficult to achieve. Project page: https://vita-group.github.io/RefPaint/
</p></li>
</ul>

<h3>Title: AdjointDPM: Adjoint Sensitivity Method for Gradient Backpropagation of Diffusion Probabilistic Models. (arXiv:2307.10711v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2307.10711">http://arxiv.org/abs/2307.10711</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2307.10711] AdjointDPM: Adjoint Sensitivity Method for Gradient Backpropagation of Diffusion Probabilistic Models](http://arxiv.org/abs/2307.10711) #diffusion</code></li>
<li>Summary: <p>Existing customization methods require access to multiple reference examples
to align pre-trained diffusion probabilistic models (DPMs) with user-provided
concepts. This paper aims to address the challenge of DPM customization when
the only available supervision is a differentiable metric defined on the
generated contents. Since the sampling procedure of DPMs involves recursive
calls to the denoising UNet, na\"ive gradient backpropagation requires storing
the intermediate states of all iterations, resulting in extremely high memory
consumption. To overcome this issue, we propose a novel method AdjointDPM,
which first generates new samples from diffusion models by solving the
corresponding probability-flow ODEs. It then uses the adjoint sensitivity
method to backpropagate the gradients of the loss to the models' parameters
(including conditioning signals, network weights, and initial noises) by
solving another augmented ODE. To reduce numerical errors in both the forward
generation and gradient backpropagation processes, we further reparameterize
the probability-flow ODE and augmented ODE as simple non-stiff ODEs using
exponential integration. Finally, we demonstrate the effectiveness of
AdjointDPM on three interesting tasks: converting visual effects into
identification text embeddings, finetuning DPMs for specific types of
stylization, and optimizing initial noise to generate adversarial samples for
security auditing.
</p></li>
</ul>

<h3>Title: BoxDiff: Text-to-Image Synthesis with Training-Free Box-Constrained Diffusion. (arXiv:2307.10816v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2307.10816">http://arxiv.org/abs/2307.10816</a></li>
<li>Code URL: <a href="https://github.com/sierkinhane/boxdiff">https://github.com/sierkinhane/boxdiff</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2307.10816] BoxDiff: Text-to-Image Synthesis with Training-Free Box-Constrained Diffusion](http://arxiv.org/abs/2307.10816) #diffusion</code></li>
<li>Summary: <p>Recent text-to-image diffusion models have demonstrated an astonishing
capacity to generate high-quality images. However, researchers mainly studied
the way of synthesizing images with only text prompts. While some works have
explored using other modalities as conditions, considerable paired data, e.g.,
box/mask-image pairs, and fine-tuning time are required for nurturing models.
As such paired data is time-consuming and labor-intensive to acquire and
restricted to a closed set, this potentially becomes the bottleneck for
applications in an open world. This paper focuses on the simplest form of
user-provided conditions, e.g., box or scribble. To mitigate the aforementioned
problem, we propose a training-free method to control objects and contexts in
the synthesized images adhering to the given spatial conditions. Specifically,
three spatial constraints, i.e., Inner-Box, Outer-Box, and Corner Constraints,
are designed and seamlessly integrated into the denoising step of diffusion
models, requiring no additional training and massive annotated layout data.
Extensive results show that the proposed constraints can control what and where
to present in the images while retaining the ability of the Stable Diffusion
model to synthesize with high fidelity and diverse concept coverage. The code
is publicly available at https://github.com/Sierkinhane/BoxDiff.
</p></li>
</ul>

<h3>Title: Exact Diffusion Inversion via Bi-directional Integration Approximation. (arXiv:2307.10829v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2307.10829">http://arxiv.org/abs/2307.10829</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2307.10829] Exact Diffusion Inversion via Bi-directional Integration Approximation](http://arxiv.org/abs/2307.10829) #diffusion</code></li>
<li>Summary: <p>Recently, different methods have been proposed to address the inconsistency
issue of DDIM inversion to enable image editing, such as EDICT [36] and
Null-text inversion [22]. However, the above methods introduce considerable
computational overhead. In this paper, we propose a new technique, named
bi-directional integration approximation (BDIA), to perform exact diffusion
inversion with neglible computational overhead. Suppose we would like to
estimate the next diffusion state $\boldsymbol{z}<em>{i-1}$ at timestep $t_i$ with
the historical information $(i,\boldsymbol{z}_i)$ and
$(i+1,\boldsymbol{z}</em>{i+1})$. We first obtain the estimated Gaussian noise
$\hat{\boldsymbol{\epsilon}}(\boldsymbol{z}<em>i,i)$, and then apply the DDIM
update procedure twice for approximating the ODE integration over the next
time-slot $[t_i, t</em>{i-1}]$ in the forward manner and the previous time-slot
$[t_i, t_{t+1}]$ in the backward manner. The DDIM step for the previous
time-slot is used to refine the integration approximation made earlier when
computing $\boldsymbol{z}<em>i$. One nice property with BDIA-DDIM is that the
update expression for $\boldsymbol{z}</em>{i-1}$ is a linear combination of
$(\boldsymbol{z}<em>{i+1}, \boldsymbol{z}_i,
\hat{\boldsymbol{\epsilon}}(\boldsymbol{z}_i,i))$. This allows for exact
backward computation of $\boldsymbol{z}</em>{i+1}$ given $(\boldsymbol{z}<em>i,
\boldsymbol{z}</em>{i-1})$, thus leading to exact diffusion inversion. Experiments
on both image reconstruction and image editing were conducted, confirming our
statement.
</p></li>
</ul>

<p>BDIA can also be applied to improve the performance of other ODE solvers in
addition to DDIM. In our work, it is found that applying BDIA to the EDM
sampling procedure produces slightly better FID score over CIFAR10.
</p>

<h2>noise learning</h2>
<h2>data-free</h2>
<h2>transformer</h2>
<h3>Title: RayMVSNet++: Learning Ray-based 1D Implicit Fields for Accurate Multi-View Stereo. (arXiv:2307.10233v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2307.10233">http://arxiv.org/abs/2307.10233</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2307.10233] RayMVSNet++: Learning Ray-based 1D Implicit Fields for Accurate Multi-View Stereo](http://arxiv.org/abs/2307.10233) #transformer</code></li>
<li>Summary: <p>Learning-based multi-view stereo (MVS) has by far centered around 3D
convolution on cost volumes. Due to the high computation and memory consumption
of 3D CNN, the resolution of output depth is often considerably limited.
Different from most existing works dedicated to adaptive refinement of cost
volumes, we opt to directly optimize the depth value along each camera ray,
mimicking the range finding of a laser scanner. This reduces the MVS problem to
ray-based depth optimization which is much more light-weight than full cost
volume optimization. In particular, we propose RayMVSNet which learns
sequential prediction of a 1D implicit field along each camera ray with the
zero-crossing point indicating scene depth. This sequential modeling, conducted
based on transformer features, essentially learns the epipolar line search in
traditional multi-view stereo. We devise a multi-task learning for better
optimization convergence and depth accuracy. We found the monotonicity property
of the SDFs along each ray greatly benefits the depth estimation. Our method
ranks top on both the DTU and the Tanks &amp; Temples datasets over all previous
learning-based methods, achieving an overall reconstruction score of 0.33mm on
DTU and an F-score of 59.48% on Tanks &amp; Temples. It is able to produce
high-quality depth estimation and point cloud reconstruction in challenging
scenarios such as objects/scenes with non-textured surface, severe occlusion,
and highly varying depth range. Further, we propose RayMVSNet++ to enhance
contextual feature aggregation for each ray through designing an attentional
gating unit to select semantically relevant neighboring rays within the local
frustum around that ray. RayMVSNet++ achieves state-of-the-art performance on
the ScanNet dataset. In particular, it attains an AbsRel of 0.058m and produces
accurate results on the two subsets of textureless regions and large depth
variation.
</p></li>
</ul>

<h3>Title: Classification of Visualization Types and Perspectives in Patents. (arXiv:2307.10471v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2307.10471">http://arxiv.org/abs/2307.10471</a></li>
<li>Code URL: <a href="https://github.com/tibhannover/patentimageclassification">https://github.com/tibhannover/patentimageclassification</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2307.10471] Classification of Visualization Types and Perspectives in Patents](http://arxiv.org/abs/2307.10471) #transformer</code></li>
<li>Summary: <p>Due to the swift growth of patent applications each year, information and
multimedia retrieval approaches that facilitate patent exploration and
retrieval are of utmost importance. Different types of visualizations (e.g.,
graphs, technical drawings) and perspectives (e.g., side view, perspective) are
used to visualize details of innovations in patents. The classification of
these images enables a more efficient search and allows for further analysis.
So far, datasets for image type classification miss some important
visualization types for patents. Furthermore, related work does not make use of
recent deep learning approaches including transformers. In this paper, we adopt
state-of-the-art deep learning methods for the classification of visualization
types and perspectives in patent images. We extend the CLEF-IP dataset for
image type classification in patents to ten classes and provide manual ground
truth annotations. In addition, we derive a set of hierarchical classes from a
dataset that provides weakly-labeled data for image perspectives. Experimental
results have demonstrated the feasibility of the proposed approaches. Source
code, models, and dataset will be made publicly available.
</p></li>
</ul>

<h3>Title: Quantized Feature Distillation for Network Quantization. (arXiv:2307.10638v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2307.10638">http://arxiv.org/abs/2307.10638</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2307.10638] Quantized Feature Distillation for Network Quantization](http://arxiv.org/abs/2307.10638) #transformer</code></li>
<li>Summary: <p>Neural network quantization aims to accelerate and trim full-precision neural
network models by using low bit approximations. Methods adopting the
quantization aware training (QAT) paradigm have recently seen a rapid growth,
but are often conceptually complicated. This paper proposes a novel and highly
effective QAT method, quantized feature distillation (QFD). QFD first trains a
quantized (or binarized) representation as the teacher, then quantize the
network using knowledge distillation (KD). Quantitative results show that QFD
is more flexible and effective (i.e., quantization friendly) than previous
quantization methods. QFD surpasses existing methods by a noticeable margin on
not only image classification but also object detection, albeit being much
simpler. Furthermore, QFD quantizes ViT and Swin-Transformer on MS-COCO
detection and segmentation, which verifies its potential in real world
deployment. To the best of our knowledge, this is the first time that vision
transformers have been quantized in object detection and image segmentation
tasks.
</p></li>
</ul>

<h3>Title: Reverse Knowledge Distillation: Training a Large Model using a Small One for Retinal Image Matching on Limited Data. (arXiv:2307.10698v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2307.10698">http://arxiv.org/abs/2307.10698</a></li>
<li>Code URL: <a href="https://github.com/SaharAlmahfouzNasser/MeDAL-Retina">https://github.com/SaharAlmahfouzNasser/MeDAL-Retina</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2307.10698] Reverse Knowledge Distillation: Training a Large Model using a Small One for Retinal Image Matching on Limited Data](http://arxiv.org/abs/2307.10698) #transformer</code></li>
<li>Summary: <p>Retinal image matching plays a crucial role in monitoring disease progression
and treatment response. However, datasets with matched keypoints between
temporally separated pairs of images are not available in abundance to train
transformer-based model. We propose a novel approach based on reverse knowledge
distillation to train large models with limited data while preventing
overfitting. Firstly, we propose architectural modifications to a CNN-based
semi-supervised method called SuperRetina that help us improve its results on a
publicly available dataset. Then, we train a computationally heavier model
based on a vision transformer encoder using the lighter CNN-based model, which
is counter-intuitive in the field knowledge-distillation research where
training lighter models based on heavier ones is the norm. Surprisingly, such
reverse knowledge distillation improves generalization even further. Our
experiments suggest that high-dimensional fitting in representation space may
prevent overfitting unlike training directly to match the final output. We also
provide a public dataset with annotations for retinal image keypoint detection
and matching to help the research community develop algorithms for retinal
image applications.
</p></li>
</ul>

<h3>Title: MSQNet: Actor-agnostic Action Recognition with Multi-modal Query. (arXiv:2307.10763v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2307.10763">http://arxiv.org/abs/2307.10763</a></li>
<li>Code URL: <a href="https://github.com/mondalanindya/msqnet">https://github.com/mondalanindya/msqnet</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2307.10763] MSQNet: Actor-agnostic Action Recognition with Multi-modal Query](http://arxiv.org/abs/2307.10763) #transformer</code></li>
<li>Summary: <p>Existing action recognition methods are typically actor-specific due to the
intrinsic topological and apparent differences among the actors. This requires
actor-specific pose estimation (e.g., humans vs. animals), leading to
cumbersome model design complexity and high maintenance costs. Moreover, they
often focus on learning the visual modality alone and single-label
classification whilst neglecting other available information sources (e.g.,
class name text) and the concurrent occurrence of multiple actions. To overcome
these limitations, we propose a new approach called 'actor-agnostic multi-modal
multi-label action recognition,' which offers a unified solution for various
types of actors, including humans and animals. We further formulate a novel
Multi-modal Semantic Query Network (MSQNet) model in a transformer-based object
detection framework (e.g., DETR), characterized by leveraging visual and
textual modalities to represent the action classes better. The elimination of
actor-specific model designs is a key advantage, as it removes the need for
actor pose estimation altogether. Extensive experiments on five publicly
available benchmarks show that our MSQNet consistently outperforms the prior
arts of actor-specific alternatives on human and animal single- and multi-label
action recognition tasks by up to 50%. Code will be released at
https://github.com/mondalanindya/MSQNet.
</p></li>
</ul>

<h3>Title: Learned Thresholds Token Merging and Pruning for Vision Transformers. (arXiv:2307.10780v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2307.10780">http://arxiv.org/abs/2307.10780</a></li>
<li>Code URL: <a href="https://github.com/mxbonn/ltmp">https://github.com/mxbonn/ltmp</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2307.10780] Learned Thresholds Token Merging and Pruning for Vision Transformers](http://arxiv.org/abs/2307.10780) #transformer</code></li>
<li>Summary: <p>Vision transformers have demonstrated remarkable success in a wide range of
computer vision tasks over the last years. However, their high computational
costs remain a significant barrier to their practical deployment. In
particular, the complexity of transformer models is quadratic with respect to
the number of input tokens. Therefore techniques that reduce the number of
input tokens that need to be processed have been proposed. This paper
introduces Learned Thresholds token Merging and Pruning (LTMP), a novel
approach that leverages the strengths of both token merging and token pruning.
LTMP uses learned threshold masking modules that dynamically determine which
tokens to merge and which to prune. We demonstrate our approach with extensive
experiments on vision transformers on the ImageNet classification task. Our
results demonstrate that LTMP achieves state-of-the-art accuracy across
reduction rates while requiring only a single fine-tuning epoch, which is an
order of magnitude faster than previous methods. Code is available at
https://github.com/Mxbonn/ltmp .
</p></li>
</ul>

<h3>Title: Meta-Transformer: A Unified Framework for Multimodal Learning. (arXiv:2307.10802v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2307.10802">http://arxiv.org/abs/2307.10802</a></li>
<li>Code URL: <a href="https://github.com/invictus717/MetaTransformer">https://github.com/invictus717/MetaTransformer</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2307.10802] Meta-Transformer: A Unified Framework for Multimodal Learning](http://arxiv.org/abs/2307.10802) #transformer</code></li>
<li>Summary: <p>Multimodal learning aims to build models that can process and relate
information from multiple modalities. Despite years of development in this
field, it still remains challenging to design a unified network for processing
various modalities ($\textit{e.g.}$ natural language, 2D images, 3D point
clouds, audio, video, time series, tabular data) due to the inherent gaps among
them. In this work, we propose a framework, named Meta-Transformer, that
leverages a $\textbf{frozen}$ encoder to perform multimodal perception without
any paired multimodal training data. In Meta-Transformer, the raw input data
from various modalities are mapped into a shared token space, allowing a
subsequent encoder with frozen parameters to extract high-level semantic
features of the input data. Composed of three main components: a unified data
tokenizer, a modality-shared encoder, and task-specific heads for downstream
tasks, Meta-Transformer is the first framework to perform unified learning
across 12 modalities with unpaired data. Experiments on different benchmarks
reveal that Meta-Transformer can handle a wide range of tasks including
fundamental perception (text, image, point cloud, audio, video), practical
application (X-Ray, infrared, hyperspectral, and IMU), and data mining (graph,
tabular, and time-series). Meta-Transformer indicates a promising future for
developing unified multimodal intelligence with transformers. Code will be
available at https://github.com/invictus717/MetaTransformer
</p></li>
</ul>

<h3>Title: Exploring Effective Priors and Efficient Models for Weakly-Supervised Change Detection. (arXiv:2307.10853v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2307.10853">http://arxiv.org/abs/2307.10853</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2307.10853] Exploring Effective Priors and Efficient Models for Weakly-Supervised Change Detection](http://arxiv.org/abs/2307.10853) #transformer</code></li>
<li>Summary: <p>Weakly-supervised change detection (WSCD) aims to detect pixel-level changes
with only image-level annotations. Owing to its label efficiency, WSCD is
drawing increasing attention recently. However, current WSCD methods often
encounter the challenge of change missing and fabricating, i.e., the
inconsistency between image-level annotations and pixel-level predictions.
Specifically, change missing refer to the situation that the WSCD model fails
to predict any changed pixels, even though the image-level label indicates
changed, and vice versa for change fabricating. To address this challenge, in
this work, we leverage global-scale and local-scale priors in WSCD and propose
two components: a Dilated Prior (DP) decoder and a Label Gated (LG) constraint.
The DP decoder decodes samples with the changed image-level label, skips
samples with the unchanged label, and replaces them with an all-unchanged
pixel-level label. The LG constraint is derived from the correspondence between
changed representations and image-level labels, penalizing the model when it
mispredicts the change status. Additionally, we develop TransWCD, a simple yet
powerful transformer-based model, showcasing the potential of weakly-supervised
learning in change detection. By integrating the DP decoder and LG constraint
into TransWCD, we form TransWCD-DL. Our proposed TransWCD and TransWCD-DL
achieve significant +6.33% and +9.55% F1 score improvements over the
state-of-the-art methods on the WHU-CD dataset, respectively. Some performance
metrics even exceed several fully-supervised change detection (FSCD)
competitors. Code will be available at
https://github.com/zhenghuizhao/TransWCD.
</p></li>
</ul>

<h3>Title: ChatGPT for Digital Forensic Investigation: The Good, The Bad, and The Unknown. (arXiv:2307.10195v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2307.10195">http://arxiv.org/abs/2307.10195</a></li>
<li>Code URL: <a href="https://github.com/markscanlonucd/chatgpt-for-digital-forensics">https://github.com/markscanlonucd/chatgpt-for-digital-forensics</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2307.10195] ChatGPT for Digital Forensic Investigation: The Good, The Bad, and The Unknown](http://arxiv.org/abs/2307.10195) #transformer</code></li>
<li>Summary: <p>The disruptive application of ChatGPT (GPT-3.5, GPT-4) to a variety of
domains has become a topic of much discussion in the scientific community and
society at large. Large Language Models (LLMs), e.g., BERT, Bard, Generative
Pre-trained Transformers (GPTs), LLaMA, etc., have the ability to take
instructions, or prompts, from users and generate answers and solutions based
on very large volumes of text-based training data. This paper assesses the
impact and potential impact of ChatGPT on the field of digital forensics,
specifically looking at its latest pre-trained LLM, GPT-4. A series of
experiments are conducted to assess its capability across several digital
forensic use cases including artefact understanding, evidence searching, code
generation, anomaly detection, incident response, and education. Across these
topics, its strengths and risks are outlined and a number of general
conclusions are drawn. Overall this paper concludes that while there are some
potential low-risk applications of ChatGPT within digital forensics, many are
either unsuitable at present, since the evidence would need to be uploaded to
the service, or they require sufficient knowledge of the topic being asked of
the tool to identify incorrect assumptions, inaccuracies, and mistakes.
However, to an appropriately knowledgeable user, it could act as a useful
supporting tool in some circumstances.
</p></li>
</ul>

<h3>Title: SentimentGPT: Exploiting GPT for Advanced Sentiment Analysis and its Departure from Current Machine Learning. (arXiv:2307.10234v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2307.10234">http://arxiv.org/abs/2307.10234</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2307.10234] SentimentGPT: Exploiting GPT for Advanced Sentiment Analysis and its Departure from Current Machine Learning](http://arxiv.org/abs/2307.10234) #transformer</code></li>
<li>Summary: <p>This study presents a thorough examination of various Generative Pretrained
Transformer (GPT) methodologies in sentiment analysis, specifically in the
context of Task 4 on the SemEval 2017 dataset. Three primary strategies are
employed: 1) prompt engineering using the advanced GPT-3.5 Turbo, 2)
fine-tuning GPT models, and 3) an inventive approach to embedding
classification. The research yields detailed comparative insights among these
strategies and individual GPT models, revealing their unique strengths and
potential limitations. Additionally, the study compares these GPT-based
methodologies with other contemporary, high-performing models previously used
with the same dataset. The results illustrate the significant superiority of
the GPT approaches in terms of predictive performance, more than 22% in
F1-score compared to the state-of-the-art. Further, the paper addresses common
challenges in sentiment analysis tasks, such as understanding context and
detecting sarcasm. It underscores the enhanced capabilities of the GPT models
to effectively navigate these complexities. Collectively, these findings
highlight the promising potential of GPT models in sentiment analysis, setting
the stage for future research in this field. The code can be found at
https://github.com/DSAatUSU/SentimentGPT.
</p></li>
</ul>

<h3>Title: Integrating a Heterogeneous Graph with Entity-aware Self-attention using Relative Position Labels for Reading Comprehension Model. (arXiv:2307.10443v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2307.10443">http://arxiv.org/abs/2307.10443</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2307.10443] Integrating a Heterogeneous Graph with Entity-aware Self-attention using Relative Position Labels for Reading Comprehension Model](http://arxiv.org/abs/2307.10443) #transformer</code></li>
<li>Summary: <p>Despite the significant progress made by transformer models in machine
reading comprehension tasks, they still face limitations in handling complex
reasoning tasks due to the absence of explicit knowledge in the input sequence.
This paper proposes a novel attention pattern to overcome this limitation,
which integrates reasoning knowledge derived from a heterogeneous graph into
the transformer architecture using a graph-enhanced self-attention mechanism.
The proposed attention pattern comprises three key elements: global-local
attention for word tokens, graph attention for entity tokens that exhibit
strong attention towards tokens connected in the graph as opposed to those
unconnected, and the consideration of the type of relationship between each
entity token and word token. This results in optimized attention between the
two if a relationship exists. The pattern is coupled with special relative
position labels, allowing it to integrate with LUKE's entity-aware
self-attention mechanism. The experimental findings corroborate that our model
outperforms both the cutting-edge LUKE-Graph and the baseline LUKE model on the
ReCoRD dataset that focuses on commonsense reasoning.
</p></li>
</ul>

<h3>Title: A Dataset and Strong Baselines for Classification of Czech News Texts. (arXiv:2307.10666v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2307.10666">http://arxiv.org/abs/2307.10666</a></li>
<li>Code URL: <a href="https://github.com/hynky1999/czech-news-classification-dataset">https://github.com/hynky1999/czech-news-classification-dataset</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2307.10666] A Dataset and Strong Baselines for Classification of Czech News Texts](http://arxiv.org/abs/2307.10666) #transformer</code></li>
<li>Summary: <p>Pre-trained models for Czech Natural Language Processing are often evaluated
on purely linguistic tasks (POS tagging, parsing, NER) and relatively simple
classification tasks such as sentiment classification or article classification
from a single news source. As an alternative, we present
CZEch~NEws~Classification~dataset (CZE-NEC), one of the largest Czech
classification datasets, composed of news articles from various sources
spanning over twenty years, which allows a more rigorous evaluation of such
models. We define four classification tasks: news source, news category,
inferred author's gender, and day of the week. To verify the task difficulty,
we conducted a human evaluation, which revealed that human performance lags
behind strong machine-learning baselines built upon pre-trained transformer
models. Furthermore, we show that language-specific pre-trained encoder
analysis outperforms selected commercially available large-scale generative
language models.
</p></li>
</ul>

<h3>Title: Layer-wise Representation Fusion for Compositional Generalization. (arXiv:2307.10799v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2307.10799">http://arxiv.org/abs/2307.10799</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2307.10799] Layer-wise Representation Fusion for Compositional Generalization](http://arxiv.org/abs/2307.10799) #transformer</code></li>
<li>Summary: <p>Despite successes across a broad range of applications, sequence-to-sequence
models' construct of solutions are argued to be less compositional than
human-like generalization. There is mounting evidence that one of the reasons
hindering compositional generalization is representations of the encoder and
decoder uppermost layer are entangled. In other words, the syntactic and
semantic representations of sequences are twisted inappropriately. However,
most previous studies mainly concentrate on enhancing token-level semantic
information to alleviate the representations entanglement problem, rather than
composing and using the syntactic and semantic representations of sequences
appropriately as humans do. In addition, we explain why the entanglement
problem exists from the perspective of recent studies about training deeper
Transformer, mainly owing to the ``shallow'' residual connections and its
simple, one-step operations, which fails to fuse previous layers' information
effectively. Starting from this finding and inspired by humans' strategies, we
propose \textsc{FuSion} (\textbf{Fu}sing \textbf{S}yntactic and
Semant\textbf{i}c Representati\textbf{on}s), an extension to
sequence-to-sequence models to learn to fuse previous layers' information back
into the encoding and decoding process appropriately through introducing a
\emph{fuse-attention module} at each encoder and decoder layer. \textsc{FuSion}
achieves competitive and even \textbf{state-of-the-art} results on two
realistic benchmarks, which empirically demonstrates the effectiveness of our
proposal.
</p></li>
</ul>

<h3>Title: DP-TBART: A Transformer-based Autoregressive Model for Differentially Private Tabular Data Generation. (arXiv:2307.10430v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2307.10430">http://arxiv.org/abs/2307.10430</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2307.10430] DP-TBART: A Transformer-based Autoregressive Model for Differentially Private Tabular Data Generation](http://arxiv.org/abs/2307.10430) #transformer</code></li>
<li>Summary: <p>The generation of synthetic tabular data that preserves differential privacy
is a problem of growing importance. While traditional marginal-based methods
have achieved impressive results, recent work has shown that deep
learning-based approaches tend to lag behind. In this work, we present
Differentially-Private TaBular AutoRegressive Transformer (DP-TBART), a
transformer-based autoregressive model that maintains differential privacy and
achieves performance competitive with marginal-based methods on a wide variety
of datasets, capable of even outperforming state-of-the-art methods in certain
settings. We also provide a theoretical framework for understanding the
limitations of marginal-based approaches and where deep learning-based
approaches stand to contribute most. These results suggest that deep
learning-based techniques should be considered as a viable alternative to
marginal-based methods in the generation of differentially private synthetic
tabular data.
</p></li>
</ul>

<h3>Title: Efficient Beam Tree Recursion. (arXiv:2307.10779v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2307.10779">http://arxiv.org/abs/2307.10779</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2307.10779] Efficient Beam Tree Recursion](http://arxiv.org/abs/2307.10779) #transformer</code></li>
<li>Summary: <p>Beam Tree Recursive Neural Network (BT-RvNN) was recently proposed as a
simple extension of Gumbel Tree RvNN and it was shown to achieve
state-of-the-art length generalization performance in ListOps while maintaining
comparable performance on other tasks. However, although not the worst in its
kind, BT-RvNN can be still exorbitantly expensive in memory usage. In this
paper, we identify the main bottleneck in BT-RvNN's memory usage to be the
entanglement of the scorer function and the recursive cell function. We propose
strategies to remove this bottleneck and further simplify its memory usage.
Overall, our strategies not only reduce the memory usage of BT-RvNN by
$10$-$16$ times but also create a new state-of-the-art in ListOps while
maintaining similar performance in other tasks. In addition, we also propose a
strategy to utilize the induced latent-tree node representations produced by
BT-RvNN to turn BT-RvNN from a sentence encoder of the form $f:\mathbb{R}^{n
\times d} \rightarrow \mathbb{R}^{d}$ into a sequence contextualizer of the
form $f:\mathbb{R}^{n \times d} \rightarrow \mathbb{R}^{n \times d}$. Thus, our
proposals not only open up a path for further scalability of RvNNs but also
standardize a way to use BT-RvNNs as another building block in the deep
learning toolkit that can be easily stacked or interfaced with other popular
models such as Transformers and Structured State Space models.
</p></li>
</ul>

<h2>generative</h2>
<h3>Title: Survey on Controlable Image Synthesis with Deep Learning. (arXiv:2307.10275v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2307.10275">http://arxiv.org/abs/2307.10275</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2307.10275] Survey on Controlable Image Synthesis with Deep Learning](http://arxiv.org/abs/2307.10275) #generative</code></li>
<li>Summary: <p>Image synthesis has attracted emerging research interests in academic and
industry communities. Deep learning technologies especially the generative
models greatly inspired controllable image synthesis approaches and
applications, which aim to generate particular visual contents with latent
prompts. In order to further investigate low-level controllable image synthesis
problem which is crucial for fine image rendering and editing tasks, we present
a survey of some recent works on 3D controllable image synthesis using deep
learning. We first introduce the datasets and evaluation indicators for 3D
controllable image synthesis. Then, we review the state-of-the-art research for
geometrically controllable image synthesis in two aspects: 1)
Viewpoint/pose-controllable image synthesis; 2) Structure/shape-controllable
image synthesis. Furthermore, the photometrically controllable image synthesis
approaches are also reviewed for 3D re-lighting researches. While the emphasis
is on 3D controllable image synthesis algorithms, the related applications,
products and resources are also briefly summarized for practitioners.
</p></li>
</ul>

<h3>Title: Generative Visual Question Answering. (arXiv:2307.10405v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2307.10405">http://arxiv.org/abs/2307.10405</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2307.10405] Generative Visual Question Answering](http://arxiv.org/abs/2307.10405) #generative</code></li>
<li>Summary: <p>Multi-modal tasks involving vision and language in deep learning continue to
rise in popularity and are leading to the development of newer models that can
generalize beyond the extent of their training data. The current models lack
temporal generalization which enables models to adapt to changes in future
data. This paper discusses a viable approach to creating an advanced Visual
Question Answering (VQA) model which can produce successful results on temporal
generalization. We propose a new data set, GenVQA, utilizing images and
captions from the VQAv2 and MS-COCO dataset to generate new images through
stable diffusion. This augmented dataset is then used to test a combination of
seven baseline and cutting edge VQA models. Performance evaluation focuses on
questions mirroring the original VQAv2 dataset, with the answers having been
adjusted to the new images. This paper's purpose is to investigate the
robustness of several successful VQA models to assess their performance on
future data distributions. Model architectures are analyzed to identify common
stylistic choices that improve generalization under temporal distribution
shifts. This research highlights the importance of creating a large-scale
future shifted dataset. This data can enhance the robustness of VQA models,
allowing their future peers to have improved ability to adapt to temporal
distribution shifts.
</p></li>
</ul>

<h3>Title: BlendFace: Re-designing Identity Encoders for Face-Swapping. (arXiv:2307.10854v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2307.10854">http://arxiv.org/abs/2307.10854</a></li>
<li>Code URL: <a href="https://github.com/mapooon/blendface">https://github.com/mapooon/blendface</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2307.10854] BlendFace: Re-designing Identity Encoders for Face-Swapping](http://arxiv.org/abs/2307.10854) #generative</code></li>
<li>Summary: <p>The great advancements of generative adversarial networks and face
recognition models in computer vision have made it possible to swap identities
on images from single sources. Although a lot of studies seems to have proposed
almost satisfactory solutions, we notice previous methods still suffer from an
identity-attribute entanglement that causes undesired attributes swapping
because widely used identity encoders, eg, ArcFace, have some crucial attribute
biases owing to their pretraining on face recognition tasks. To address this
issue, we design BlendFace, a novel identity encoder for face-swapping. The key
idea behind BlendFace is training face recognition models on blended images
whose attributes are replaced with those of another mitigates inter-personal
biases such as hairsyles. BlendFace feeds disentangled identity features into
generators and guides generators properly as an identity loss function.
Extensive experiments demonstrate that BlendFace improves the
identity-attribute disentanglement in face-swapping models, maintaining a
comparable quantitative performance to previous methods.
</p></li>
</ul>

<h3>Title: Divide &amp; Bind Your Attention for Improved Generative Semantic Nursing. (arXiv:2307.10864v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2307.10864">http://arxiv.org/abs/2307.10864</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2307.10864] Divide &amp; Bind Your Attention for Improved Generative Semantic Nursing](http://arxiv.org/abs/2307.10864) #generative</code></li>
<li>Summary: <p>Emerging large-scale text-to-image generative models, e.g., Stable Diffusion
(SD), have exhibited overwhelming results with high fidelity. Despite the
magnificent progress, current state-of-the-art models still struggle to
generate images fully adhering to the input prompt. Prior work, Attend &amp;
Excite, has introduced the concept of Generative Semantic Nursing (GSN), aiming
to optimize cross-attention during inference time to better incorporate the
semantics. It demonstrates promising results in generating simple prompts,
e.g., ``a cat and a dog''. However, its efficacy declines when dealing with
more complex prompts, and it does not explicitly address the problem of
improper attribute binding. To address the challenges posed by complex prompts
or scenarios involving multiple entities and to achieve improved attribute
binding, we propose Divide &amp; Bind. We introduce two novel loss objectives for
GSN: a novel attendance loss and a binding loss. Our approach stands out in its
ability to faithfully synthesize desired objects with improved attribute
alignment from complex prompts and exhibits superior performance across
multiple evaluation benchmarks. More videos and updates can be found on the
project page \url{https://sites.google.com/view/divide-and-bind}.
</p></li>
</ul>

<h3>Title: FigCaps-HF: A Figure-to-Caption Generative Framework and Benchmark with Human Feedback. (arXiv:2307.10867v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2307.10867">http://arxiv.org/abs/2307.10867</a></li>
<li>Code URL: <a href="https://github.com/figcapshf/figcapshf">https://github.com/figcapshf/figcapshf</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2307.10867] FigCaps-HF: A Figure-to-Caption Generative Framework and Benchmark with Human Feedback](http://arxiv.org/abs/2307.10867) #generative</code></li>
<li>Summary: <p>Captions are crucial for understanding scientific visualizations and
documents. Existing captioning methods for scientific figures rely on
figure-caption pairs extracted from documents for training, many of which fall
short with respect to metrics like helpfulness, explainability, and
visual-descriptiveness [15] leading to generated captions being misaligned with
reader preferences. To enable the generation of high-quality figure captions,
we introduce FigCaps-HF a new framework for figure-caption generation that can
incorporate domain expert feedback in generating captions optimized for reader
preferences. Our framework comprises of 1) an automatic method for evaluating
quality of figure-caption pairs, 2) a novel reinforcement learning with human
feedback (RLHF) method to optimize a generative figure-to-caption model for
reader preferences. We demonstrate the effectiveness of our simple learning
framework by improving performance over standard fine-tuning across different
types of models. In particular, when using BLIP as the base model, our RLHF
framework achieves a mean gain of 35.7%, 16.9%, and 9% in ROUGE, BLEU, and
Meteor, respectively. Finally, we release a large-scale benchmark dataset with
human feedback on figure-caption pairs to enable further evaluation and
development of RLHF techniques for this problem.
</p></li>
</ul>

<h3>Title: Building Socio-culturally Inclusive Stereotype Resources with Community Engagement. (arXiv:2307.10514v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2307.10514">http://arxiv.org/abs/2307.10514</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2307.10514] Building Socio-culturally Inclusive Stereotype Resources with Community Engagement](http://arxiv.org/abs/2307.10514) #generative</code></li>
<li>Summary: <p>With rapid development and deployment of generative language models in global
settings, there is an urgent need to also scale our measurements of harm, not
just in the number and types of harms covered, but also how well they account
for local cultural contexts, including marginalized identities and the social
biases experienced by them. Current evaluation paradigms are limited in their
abilities to address this, as they are not representative of diverse, locally
situated but global, socio-cultural perspectives. It is imperative that our
evaluation resources are enhanced and calibrated by including people and
experiences from different cultures and societies worldwide, in order to
prevent gross underestimations or skews in measurements of harm. In this work,
we demonstrate a socio-culturally aware expansion of evaluation resources in
the Indian societal context, specifically for the harm of stereotyping. We
devise a community engaged effort to build a resource which contains
stereotypes for axes of disparity that are uniquely present in India. The
resultant resource increases the number of stereotypes known for and in the
Indian context by over 1000 stereotypes across many unique identities. We also
demonstrate the utility and effectiveness of such expanded resources for
evaluations of language models. CONTENT WARNING: This paper contains examples
of stereotypes that may be offensive.
</p></li>
</ul>

<h3>Title: Reparameterized Policy Learning for Multimodal Trajectory Optimization. (arXiv:2307.10710v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2307.10710">http://arxiv.org/abs/2307.10710</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2307.10710] Reparameterized Policy Learning for Multimodal Trajectory Optimization](http://arxiv.org/abs/2307.10710) #generative</code></li>
<li>Summary: <p>We investigate the challenge of parametrizing policies for reinforcement
learning (RL) in high-dimensional continuous action spaces. Our objective is to
develop a multimodal policy that overcomes limitations inherent in the
commonly-used Gaussian parameterization. To achieve this, we propose a
principled framework that models the continuous RL policy as a generative model
of optimal trajectories. By conditioning the policy on a latent variable, we
derive a novel variational bound as the optimization objective, which promotes
exploration of the environment. We then present a practical model-based RL
method, called Reparameterized Policy Gradient (RPG), which leverages the
multimodal policy parameterization and learned world model to achieve strong
exploration capabilities and high data efficiency. Empirical results
demonstrate that our method can help agents evade local optima in tasks with
dense rewards and solve challenging sparse-reward environments by incorporating
an object-centric intrinsic reward. Our method consistently outperforms
previous approaches across a range of tasks. Code and supplementary materials
are available on the project page https://haosulab.github.io/RPG/
</p></li>
</ul>

<h2>large language model</h2>
<h3>Title: Dynamic Large Language Models on Blockchains. (arXiv:2307.10549v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2307.10549">http://arxiv.org/abs/2307.10549</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2307.10549] Dynamic Large Language Models on Blockchains](http://arxiv.org/abs/2307.10549) #large language model</code></li>
<li>Summary: <p>Training and deploying the large language models requires a large mount of
computational resource because the language models contain billions of
parameters and the text has thousands of tokens. Another problem is that the
large language models are static. They are fixed after the training process. To
tackle these issues, in this paper, we propose to train and deploy the dynamic
large language model on blockchains, which have high computation performance
and are distributed across a network of computers. A blockchain is a secure,
decentralized, and transparent system that allows for the creation of a
tamper-proof ledger for transactions without the need for intermediaries. The
dynamic large language models can continuously learn from the user input after
the training process. Our method provides a new way to develop the large
language models and also sheds a light on the next generation artificial
intelligence systems.
</p></li>
</ul>

<h3>Title: Several categories of Large Language Models (LLMs): A Short Survey. (arXiv:2307.10188v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2307.10188">http://arxiv.org/abs/2307.10188</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2307.10188] Several categories of Large Language Models (LLMs): A Short Survey](http://arxiv.org/abs/2307.10188) #large language model</code></li>
<li>Summary: <p>Large Language Models(LLMs)have become effective tools for natural language
processing and have been used in many different fields. This essay offers a
succinct summary of various LLM subcategories. The survey emphasizes recent
developments and efforts made for various LLM kinds, including task-based
financial LLMs, multilingual language LLMs, biomedical and clinical LLMs,
vision language LLMs, and code language models. The survey gives a general
summary of the methods, attributes, datasets, transformer models, and
comparison metrics applied in each category of LLMs. Furthermore, it highlights
unresolved problems in the field of developing chatbots and virtual assistants,
such as boosting natural language processing, enhancing chatbot intelligence,
and resolving moral and legal dilemmas. The purpose of this study is to provide
readers, developers, academics, and users interested in LLM-based chatbots and
virtual intelligent assistant technologies with useful information and future
directions.
</p></li>
</ul>

<h3>Title: PharmacyGPT: The AI Pharmacist. (arXiv:2307.10432v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2307.10432">http://arxiv.org/abs/2307.10432</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2307.10432] PharmacyGPT: The AI Pharmacist](http://arxiv.org/abs/2307.10432) #large language model</code></li>
<li>Summary: <p>In this study, we introduce PharmacyGPT, a novel framework to assess the
capabilities of large language models (LLMs) such as ChatGPT and GPT-4 in
emulating the role of clinical pharmacists. Our methodology encompasses the
utilization of LLMs to generate comprehensible patient clusters, formulate
medication plans, and forecast patient outcomes. We conduct our investigation
using real data acquired from the intensive care unit (ICU) at the University
of North Carolina Chapel Hill (UNC) Hospital. Our analysis offers valuable
insights into the potential applications and limitations of LLMs in the field
of clinical pharmacy, with implications for both patient care and the
development of future AI-driven healthcare solutions. By evaluating the
performance of PharmacyGPT, we aim to contribute to the ongoing discourse
surrounding the integration of artificial intelligence in healthcare settings,
ultimately promoting the responsible and efficacious use of such technologies.
</p></li>
</ul>

<h3>Title: Thrust: Adaptively Propels Large Language Models with External Knowledge. (arXiv:2307.10442v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2307.10442">http://arxiv.org/abs/2307.10442</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2307.10442] Thrust: Adaptively Propels Large Language Models with External Knowledge](http://arxiv.org/abs/2307.10442) #large language model</code></li>
<li>Summary: <p>Although large-scale pre-trained language models (PTLMs) are shown to encode
rich knowledge in their model parameters, the inherent knowledge in PTLMs can
be opaque or static, making external knowledge necessary. However, the existing
information retrieval techniques could be costly and may even introduce noisy
and sometimes misleading knowledge. To address these challenges, we propose the
instance-level adaptive propulsion of external knowledge (IAPEK), where we only
conduct the retrieval when necessary. To achieve this goal, we propose
measuring whether a PTLM contains enough knowledge to solve an instance with a
novel metric, Thrust, which leverages the representation distribution of a
small number of seen instances. Extensive experiments demonstrate that thrust
is a good measurement of PTLM models' instance-level knowledgeability.
Moreover, we can achieve significantly higher cost-efficiency with the Thrust
score as the retrieval indicator than the naive usage of external knowledge on
88% of the evaluated tasks with 26% average performance improvement. Such
findings shed light on the real-world practice of knowledge-enhanced LMs with a
limited knowledge-seeking budget due to computation latency or costs.
</p></li>
</ul>

<h3>Title: FinGPT: Democratizing Internet-scale Data for Financial Large Language Models. (arXiv:2307.10485v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2307.10485">http://arxiv.org/abs/2307.10485</a></li>
<li>Code URL: <a href="https://github.com/ai4finance-foundation/fingpt">https://github.com/ai4finance-foundation/fingpt</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2307.10485] FinGPT: Democratizing Internet-scale Data for Financial Large Language Models](http://arxiv.org/abs/2307.10485) #large language model</code></li>
<li>Summary: <p>Large language models (LLMs) have demonstrated remarkable proficiency in
understanding and generating human-like texts, which may potentially
revolutionize the finance industry. However, existing LLMs often fall short in
the financial field, which is mainly attributed to the disparities between
general text data and financial text data. Unfortunately, there is only a
limited number of financial text datasets available (quite small size), and
BloombergGPT, the first financial LLM (FinLLM), is close-sourced (only the
training logs were released). In light of this, we aim to democratize
Internet-scale financial data for LLMs, which is an open challenge due to
diverse data sources, low signal-to-noise ratio, and high time-validity. To
address the challenges, we introduce an open-sourced and data-centric
framework, \textit{Financial Generative Pre-trained Transformer (FinGPT)}, that
automates the collection and curation of real-time financial data from >34
diverse sources on the Internet, providing researchers and practitioners with
accessible and transparent resources to develop their FinLLMs. Additionally, we
propose a simple yet effective strategy for fine-tuning FinLLM using the
inherent feedback from the market, dubbed Reinforcement Learning with Stock
Prices (RLSP). We also adopt the Low-rank Adaptation (LoRA, QLoRA) method that
enables users to customize their own FinLLMs from open-source general-purpose
LLMs at a low cost. Finally, we showcase several FinGPT applications, including
robo-advisor, sentiment analysis for algorithmic trading, and low-code
development. FinGPT aims to democratize FinLLMs, stimulate innovation, and
unlock new opportunities in open finance. The codes are available at
https://github.com/AI4Finance-Foundation/FinGPT and
https://github.com/AI4Finance-Foundation/FinNLP
</p></li>
</ul>

<h3>Title: IvyGPT: InteractiVe Chinese pathwaY language model in medical domain. (arXiv:2307.10512v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2307.10512">http://arxiv.org/abs/2307.10512</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2307.10512] IvyGPT: InteractiVe Chinese pathwaY language model in medical domain](http://arxiv.org/abs/2307.10512) #large language model</code></li>
<li>Summary: <p>General large language models (LLMs) such as ChatGPT have shown remarkable
success. However, such LLMs have not been widely adopted for medical purposes,
due to poor accuracy and inability to provide medical advice. We propose
IvyGPT, an LLM based on LLaMA that is trained and fine-tuned with high-quality
medical question-answer (QA) instances and Reinforcement Learning from Human
Feedback (RLHF). After supervised fine-tuning, IvyGPT has good multi-turn
conversation capabilities, but it cannot perform like a doctor in other
aspects, such as comprehensive diagnosis. Through RLHF, IvyGPT can output
richer diagnosis and treatment answers that are closer to human. In the
training, we used QLoRA to train 33 billion parameters on a small number of
NVIDIA A100 (80GB) GPUs. Experimental results show that IvyGPT has outperformed
other medical GPT models.
</p></li>
</ul>

<h3>Title: Multi-Method Self-Training: Improving Code Generation With Text, And Vice Versa. (arXiv:2307.10633v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2307.10633">http://arxiv.org/abs/2307.10633</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2307.10633] Multi-Method Self-Training: Improving Code Generation With Text, And Vice Versa](http://arxiv.org/abs/2307.10633) #large language model</code></li>
<li>Summary: <p>Large Language Models have many methods for solving the same problem. This
introduces novel strengths (different methods may work well for different
problems) and weaknesses (it may be difficult for users to know which method to
use). In this paper, we introduce Multi-Method Self-Training (MMST), where one
method is trained on the filtered outputs of another, allowing us to augment
the strengths and ameliorate the weaknesses of each method. Using a 176B
parameter model trained on both language and code, we show that MMST can 1)
improve the less performant method (up to 30%) making the model easier to use,
2) improve the more performant method (up to 32.2%) making the model more
performant, and 3) improve the performance of related but distinct tasks (up to
10.3%) by improving the ability of the model to generate rationales. We then
conduct ablation analyses to explore why MMST works. We show that MMST
generates more data than traditional self-training, but the improvement in
performance is driven by the use of multiple methods. We also analyze
prompt-engineering and anti-correlated performance between methods as means of
making MMST more effective. We hope the evidence from our paper motivates
machine learning researchers to explore ways in which advances in language
models allow for new forms of training.
</p></li>
</ul>

<h3>Title: SciBench: Evaluating College-Level Scientific Problem-Solving Abilities of Large Language Models. (arXiv:2307.10635v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2307.10635">http://arxiv.org/abs/2307.10635</a></li>
<li>Code URL: <a href="https://github.com/mandyyyyii/scibench">https://github.com/mandyyyyii/scibench</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2307.10635] SciBench: Evaluating College-Level Scientific Problem-Solving Abilities of Large Language Models](http://arxiv.org/abs/2307.10635) #large language model</code></li>
<li>Summary: <p>Recent advances in large language models (LLMs) have demonstrated notable
progress on many mathematical benchmarks. However, most of these benchmarks
only feature problems grounded in junior and senior high school subjects,
contain only multiple-choice questions, and are confined to a limited scope of
elementary arithmetic operations. To address these issues, this paper
introduces an expansive benchmark suite SciBench that aims to systematically
examine the reasoning capabilities required for complex scientific problem
solving. SciBench contains two carefully curated datasets: an open set
featuring a range of collegiate-level scientific problems drawn from
mathematics, chemistry, and physics textbooks, and a closed set comprising
problems from undergraduate-level exams in computer science and mathematics.
Based on the two datasets, we conduct an in-depth benchmark study of two
representative LLMs with various prompting strategies. The results reveal that
current LLMs fall short of delivering satisfactory performance, with an overall
score of merely 35.80%. Furthermore, through a detailed user study, we
categorize the errors made by LLMs into ten problem-solving abilities. Our
analysis indicates that no single prompting strategy significantly outperforms
others and some strategies that demonstrate improvements in certain
problem-solving skills result in declines in other skills. We envision that
SciBench will catalyze further developments in the reasoning abilities of LLMs,
thereby ultimately contributing to scientific research and discovery.
</p></li>
</ul>

<h2>segmentation</h2>
<h3>Title: On the Real-Time Semantic Segmentation of Aphid Clusters in the Wild. (arXiv:2307.10267v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2307.10267">http://arxiv.org/abs/2307.10267</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2307.10267] On the Real-Time Semantic Segmentation of Aphid Clusters in the Wild](http://arxiv.org/abs/2307.10267) #segmentation</code></li>
<li>Summary: <p>Aphid infestations can cause extensive damage to wheat and sorghum fields and
spread plant viruses, resulting in significant yield losses in agriculture. To
address this issue, farmers often rely on chemical pesticides, which are
inefficiently applied over large areas of fields. As a result, a considerable
amount of pesticide is wasted on areas without pests, while inadequate amounts
are applied to areas with severe infestations. The paper focuses on the urgent
need for an intelligent autonomous system that can locate and spray
infestations within complex crop canopies, reducing pesticide use and
environmental impact. We have collected and labeled a large aphid image dataset
in the field, and propose the use of real-time semantic segmentation models to
segment clusters of aphids. A multiscale dataset is generated to allow for
learning the clusters at different scales. We compare the segmentation speeds
and accuracy of four state-of-the-art real-time semantic segmentation models on
the aphid cluster dataset, benchmarking them against nonreal-time models. The
study results show the effectiveness of a real-time solution, which can reduce
inefficient pesticide use and increase crop yields, paving the way towards an
autonomous pest detection system.
</p></li>
</ul>

<h3>Title: CPCM: Contextual Point Cloud Modeling for Weakly-supervised Point Cloud Semantic Segmentation. (arXiv:2307.10316v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2307.10316">http://arxiv.org/abs/2307.10316</a></li>
<li>Code URL: <a href="https://github.com/lizhaoliu-Lec/CPCM">https://github.com/lizhaoliu-Lec/CPCM</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2307.10316] CPCM: Contextual Point Cloud Modeling for Weakly-supervised Point Cloud Semantic Segmentation](http://arxiv.org/abs/2307.10316) #segmentation</code></li>
<li>Summary: <p>We study the task of weakly-supervised point cloud semantic segmentation with
sparse annotations (e.g., less than 0.1% points are labeled), aiming to reduce
the expensive cost of dense annotations. Unfortunately, with extremely sparse
annotated points, it is very difficult to extract both contextual and object
information for scene understanding such as semantic segmentation. Motivated by
masked modeling (e.g., MAE) in image and video representation learning, we seek
to endow the power of masked modeling to learn contextual information from
sparsely-annotated points. However, directly applying MAE to 3D point clouds
with sparse annotations may fail to work. First, it is nontrivial to
effectively mask out the informative visual context from 3D point clouds.
Second, how to fully exploit the sparse annotations for context modeling
remains an open question. In this paper, we propose a simple yet effective
Contextual Point Cloud Modeling (CPCM) method that consists of two parts: a
region-wise masking (RegionMask) strategy and a contextual masked training
(CMT) method. Specifically, RegionMask masks the point cloud continuously in
geometric space to construct a meaningful masked prediction task for subsequent
context learning. CMT disentangles the learning of supervised segmentation and
unsupervised masked context prediction for effectively learning the very
limited labeled points and mass unlabeled points, respectively. Extensive
experiments on the widely-tested ScanNet V2 and S3DIS benchmarks demonstrate
the superiority of CPCM over the state-of-the-art.
</p></li>
</ul>

<h3>Title: POV-Surgery: A Dataset for Egocentric Hand and Tool Pose Estimation During Surgical Activities. (arXiv:2307.10387v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2307.10387">http://arxiv.org/abs/2307.10387</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2307.10387] POV-Surgery: A Dataset for Egocentric Hand and Tool Pose Estimation During Surgical Activities](http://arxiv.org/abs/2307.10387) #segmentation</code></li>
<li>Summary: <p>The surgical usage of Mixed Reality (MR) has received growing attention in
areas such as surgical navigation systems, skill assessment, and robot-assisted
surgeries. For such applications, pose estimation for hand and surgical
instruments from an egocentric perspective is a fundamental task and has been
studied extensively in the computer vision field in recent years. However, the
development of this field has been impeded by a lack of datasets, especially in
the surgical field, where bloody gloves and reflective metallic tools make it
hard to obtain 3D pose annotations for hands and objects using conventional
methods. To address this issue, we propose POV-Surgery, a large-scale,
synthetic, egocentric dataset focusing on pose estimation for hands with
different surgical gloves and three orthopedic surgical instruments, namely
scalpel, friem, and diskplacer. Our dataset consists of 53 sequences and 88,329
frames, featuring high-resolution RGB-D video streams with activity
annotations, accurate 3D and 2D annotations for hand-object pose, and 2D
hand-object segmentation masks. We fine-tune the current SOTA methods on
POV-Surgery and further show the generalizability when applying to real-life
cases with surgical gloves and tools by extensive evaluations. The code and the
dataset are publicly available at batfacewayne.github.io/POV_Surgery_io/.
</p></li>
</ul>

<h3>Title: Confidence Estimation Using Unlabeled Data. (arXiv:2307.10440v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2307.10440">http://arxiv.org/abs/2307.10440</a></li>
<li>Code URL: <a href="https://github.com/topoxlab/consistency-ranking-loss">https://github.com/topoxlab/consistency-ranking-loss</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2307.10440] Confidence Estimation Using Unlabeled Data](http://arxiv.org/abs/2307.10440) #segmentation</code></li>
<li>Summary: <p>Overconfidence is a common issue for deep neural networks, limiting their
deployment in real-world applications. To better estimate confidence, existing
methods mostly focus on fully-supervised scenarios and rely on training labels.
In this paper, we propose the first confidence estimation method for a
semi-supervised setting, when most training labels are unavailable. We
stipulate that even with limited training labels, we can still reasonably
approximate the confidence of model on unlabeled samples by inspecting the
prediction consistency through the training process. We use training
consistency as a surrogate function and propose a consistency ranking loss for
confidence estimation. On both image classification and segmentation tasks, our
method achieves state-of-the-art performances in confidence estimation.
Furthermore, we show the benefit of the proposed method through a downstream
active learning task. The code is available at
https://github.com/TopoXLab/consistency-ranking-loss
</p></li>
</ul>

<h3>Title: Interactive Segmentation for Diverse Gesture Types Without Context. (arXiv:2307.10518v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2307.10518">http://arxiv.org/abs/2307.10518</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2307.10518] Interactive Segmentation for Diverse Gesture Types Without Context](http://arxiv.org/abs/2307.10518) #segmentation</code></li>
<li>Summary: <p>Interactive segmentation entails a human marking an image to guide how a
model either creates or edits a segmentation. Our work addresses limitations of
existing methods: they either only support one gesture type for marking an
image (e.g., either clicks or scribbles) or require knowledge of the gesture
type being employed, and require specifying whether marked regions should be
included versus excluded in the final segmentation. We instead propose a
simplified interactive segmentation task where a user only must mark an image,
where the input can be of any gesture type without specifying the gesture type.
We support this new task by introducing the first interactive segmentation
dataset with multiple gesture types as well as a new evaluation metric capable
of holistically evaluating interactive segmentation algorithms. We then analyze
numerous interactive segmentation algorithms, including ones adapted for our
novel task. While we observe promising performance overall, we also highlight
areas for future improvement. To facilitate further extensions of this work, we
publicly share our new dataset at https://github.com/joshmyersdean/dig.
</p></li>
</ul>

<h3>Title: TwinLiteNet: An Efficient and Lightweight Model for Driveable Area and Lane Segmentation in Self-Driving Cars. (arXiv:2307.10705v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2307.10705">http://arxiv.org/abs/2307.10705</a></li>
<li>Code URL: <a href="https://github.com/chequanghuy/TwinLiteNet">https://github.com/chequanghuy/TwinLiteNet</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2307.10705] TwinLiteNet: An Efficient and Lightweight Model for Driveable Area and Lane Segmentation in Self-Driving Cars](http://arxiv.org/abs/2307.10705) #segmentation</code></li>
<li>Summary: <p>Semantic segmentation is a common task in autonomous driving to understand
the surrounding environment. Driveable Area Segmentation and Lane Detection are
particularly important for safe and efficient navigation on the road. However,
original semantic segmentation models are computationally expensive and require
high-end hardware, which is not feasible for embedded systems in autonomous
vehicles. This paper proposes a lightweight model for the driveable area and
lane line segmentation. TwinLiteNet is designed cheaply but achieves accurate
and efficient segmentation results. We evaluate TwinLiteNet on the BDD100K
dataset and compare it with modern models. Experimental results show that our
TwinLiteNet performs similarly to existing approaches, requiring significantly
fewer computational resources. Specifically, TwinLiteNet achieves a mIoU score
of 91.3% for the Drivable Area task and 31.08% IoU for the Lane Detection task
with only 0.4 million parameters and achieves 415 FPS on GPU RTX A5000.
Furthermore, TwinLiteNet can run in real-time on embedded devices with limited
computing power, especially since it achieves 60FPS on Jetson Xavier NX, making
it an ideal solution for self-driving vehicles. Code is available:
url{https://github.com/chequanghuy/TwinLiteNet}.
</p></li>
</ul>

<h3>Title: EdgeAL: An Edge Estimation Based Active Learning Approach for OCT Segmentation. (arXiv:2307.10745v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2307.10745">http://arxiv.org/abs/2307.10745</a></li>
<li>Code URL: <a href="https://github.com/mak-ta-reque/edgeal">https://github.com/mak-ta-reque/edgeal</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2307.10745] EdgeAL: An Edge Estimation Based Active Learning Approach for OCT Segmentation](http://arxiv.org/abs/2307.10745) #segmentation</code></li>
<li>Summary: <p>Active learning algorithms have become increasingly popular for training
models with limited data. However, selecting data for annotation remains a
challenging problem due to the limited information available on unseen data. To
address this issue, we propose EdgeAL, which utilizes the edge information of
unseen images as {\it a priori} information for measuring uncertainty. The
uncertainty is quantified by analyzing the divergence and entropy in model
predictions across edges. This measure is then used to select superpixels for
annotation. We demonstrate the effectiveness of EdgeAL on multi-class Optical
Coherence Tomography (OCT) segmentation tasks, where we achieved a 99% dice
score while reducing the annotation label cost to 12%, 2.3%, and 3%,
respectively, on three publicly available datasets (Duke, AROI, and UMN). The
source code is available at \url{https://github.com/Mak-Ta-Reque/EdgeAL}
</p></li>
</ul>

<h3>Title: See More and Know More: Zero-shot Point Cloud Segmentation via Multi-modal Visual Data. (arXiv:2307.10782v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2307.10782">http://arxiv.org/abs/2307.10782</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2307.10782] See More and Know More: Zero-shot Point Cloud Segmentation via Multi-modal Visual Data](http://arxiv.org/abs/2307.10782) #segmentation</code></li>
<li>Summary: <p>Zero-shot point cloud segmentation aims to make deep models capable of
recognizing novel objects in point cloud that are unseen in the training phase.
Recent trends favor the pipeline which transfers knowledge from seen classes
with labels to unseen classes without labels. They typically align visual
features with semantic features obtained from word embedding by the supervision
of seen classes' annotations. However, point cloud contains limited information
to fully match with semantic features. In fact, the rich appearance information
of images is a natural complement to the textureless point cloud, which is not
well explored in previous literature. Motivated by this, we propose a novel
multi-modal zero-shot learning method to better utilize the complementary
information of point clouds and images for more accurate visual-semantic
alignment. Extensive experiments are performed in two popular benchmarks, i.e.,
SemanticKITTI and nuScenes, and our method outperforms current SOTA methods
with 52% and 49% improvement on average for unseen class mIoU, respectively.
</p></li>
</ul>

<h3>Title: Optimizing PatchCore for Few/many-shot Anomaly Detection. (arXiv:2307.10792v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2307.10792">http://arxiv.org/abs/2307.10792</a></li>
<li>Code URL: <a href="https://github.com/scortexio/patchcore-few-shot">https://github.com/scortexio/patchcore-few-shot</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2307.10792] Optimizing PatchCore for Few/many-shot Anomaly Detection](http://arxiv.org/abs/2307.10792) #segmentation</code></li>
<li>Summary: <p>Few-shot anomaly detection (AD) is an emerging sub-field of general AD, and
tries to distinguish between normal and anomalous data using only few selected
samples. While newly proposed few-shot AD methods do compare against
pre-existing algorithms developed for the full-shot domain as baselines, they
do not dedicatedly optimize them for the few-shot setting. It thus remains
unclear if the performance of such pre-existing algorithms can be further
improved. We address said question in this work. Specifically, we present a
study on the AD/anomaly segmentation (AS) performance of PatchCore, the current
state-of-the-art full-shot AD/AS algorithm, in both the few-shot and the
many-shot settings. We hypothesize that further performance improvements can be
realized by (I) optimizing its various hyperparameters, and by (II)
transferring techniques known to improve few-shot supervised learning to the AD
domain. Exhaustive experiments on the public VisA and MVTec AD datasets reveal
that (I) significant performance improvements can be realized by optimizing
hyperparameters such as the underlying feature extractor, and that (II)
image-level augmentations can, but are not guaranteed, to improve performance.
Based on these findings, we achieve a new state of the art in few-shot AD on
VisA, further demonstrating the merit of adapting pre-existing AD/AS methods to
the few-shot setting. Last, we identify the investigation of feature extractors
with a strong inductive bias as a potential future research direction for
(few-shot) AD/AS.
</p></li>
</ul>

<h3>Title: Gradient-Semantic Compensation for Incremental Semantic Segmentation. (arXiv:2307.10822v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2307.10822">http://arxiv.org/abs/2307.10822</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2307.10822] Gradient-Semantic Compensation for Incremental Semantic Segmentation](http://arxiv.org/abs/2307.10822) #segmentation</code></li>
<li>Summary: <p>Incremental semantic segmentation aims to continually learn the segmentation
of new coming classes without accessing the training data of previously learned
classes. However, most current methods fail to address catastrophic forgetting
and background shift since they 1) treat all previous classes equally without
considering different forgetting paces caused by imbalanced gradient
back-propagation; 2) lack strong semantic guidance between classes. To tackle
the above challenges, in this paper, we propose a Gradient-Semantic
Compensation (GSC) model, which surmounts incremental semantic segmentation
from both gradient and semantic perspectives. Specifically, to address
catastrophic forgetting from the gradient aspect, we develop a step-aware
gradient compensation that can balance forgetting paces of previously seen
classes via re-weighting gradient backpropagation. Meanwhile, we propose a
soft-sharp semantic relation distillation to distill consistent inter-class
semantic relations via soft labels for alleviating catastrophic forgetting from
the semantic aspect. In addition, we develop a prototypical pseudo re-labeling
that provides strong semantic guidance to mitigate background shift. It
produces high-quality pseudo labels for old classes in the background by
measuring distances between pixels and class-wise prototypes. Extensive
experiments on three public datasets, i.e., Pascal VOC 2012, ADE20K, and
Cityscapes, demonstrate the effectiveness of our proposed GSC model.
</p></li>
</ul>

<h3>Title: Label Calibration for Semantic Segmentation Under Domain Shift. (arXiv:2307.10842v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2307.10842">http://arxiv.org/abs/2307.10842</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2307.10842] Label Calibration for Semantic Segmentation Under Domain Shift](http://arxiv.org/abs/2307.10842) #segmentation</code></li>
<li>Summary: <p>Performance of a pre-trained semantic segmentation model is likely to
substantially decrease on data from a new domain. We show a pre-trained model
can be adapted to unlabelled target domain data by calculating soft-label
prototypes under the domain shift and making predictions according to the
prototype closest to the vector with predicted class probabilities. The
proposed adaptation procedure is fast, comes almost for free in terms of
computational resources and leads to considerable performance improvements. We
demonstrate the benefits of such label calibration on the highly-practical
synthetic-to-real semantic segmentation problem.
</p></li>
</ul>

<button id="copy">Copy All</button>
</article>
<script src="https://cdn.staticfile.org/clipboard.js/2.0.4/clipboard.min.js"></script>
<script src="../../javascript/clipboard.js"></script>
