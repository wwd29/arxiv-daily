<link rel="stylesheet" href="../../css/markdown.css" />
<article class="markdown-body">
<h2>secure</h2>
<h2>security</h2>
<h3>Title: AI Model Utilization Measurements For Finding Class Encoding Patterns. (arXiv:2212.06576v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2212.06576">http://arxiv.org/abs/2212.06576</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2212.06576] AI Model Utilization Measurements For Finding Class Encoding Patterns](http://arxiv.org/abs/2212.06576) #security</code></li>
<li>Summary: <p>This work addresses the problems of (a) designing utilization measurements of
trained artificial intelligence (AI) models and (b) explaining how training
data are encoded in AI models based on those measurements. The problems are
motivated by the lack of explainability of AI models in security and safety
critical applications, such as the use of AI models for classification of
traffic signs in self-driving cars. We approach the problems by introducing
theoretical underpinnings of AI model utilization measurement and understanding
patterns in utilization-based class encodings of traffic signs at the level of
computation graphs (AI models), subgraphs, and graph nodes. Conceptually,
utilization is defined at each graph node (computation unit) of an AI model
based on the number and distribution of unique outputs in the space of all
possible outputs (tensor-states). In this work, utilization measurements are
extracted from AI models, which include poisoned and clean AI models. In
contrast to clean AI models, the poisoned AI models were trained with traffic
sign images containing systematic, physically realizable, traffic sign
modifications (i.e., triggers) to change a correct class label to another label
in a presence of such a trigger. We analyze class encodings of such clean and
poisoned AI models, and conclude with implications for trojan injection and
detection.
</p></li>
</ul>

<h3>Title: A Taxonomy and Review of Lightweight Blockchain Solutions for Internet of Things Networks. (arXiv:2212.06272v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2212.06272">http://arxiv.org/abs/2212.06272</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2212.06272] A Taxonomy and Review of Lightweight Blockchain Solutions for Internet of Things Networks](http://arxiv.org/abs/2212.06272) #security</code></li>
<li>Summary: <p>Internet of things networks have spread to most digital applications in the
past years. Examples of these networks include smart home networks, wireless
sensor networks, Internet of Flying Things, and many others. One of the main
difficulties that confront these networks is the security of their information
and communications. A large number of solutions have been proposed to safeguard
these networks from various types of cyberattacks. Among these solutions is the
blockchain, which gained popularity in the last few years due to its strong
security characteristics, such as immutability, cryptography, and distributed
consensus. However, implementing the blockchain framework within the devices of
these networks is very challenging, due to the limited resources of these
devices and the resource-demanding requirements of the blockchain. For this
reason, a large number of researchers proposed various types of lightweight
blockchain solutions for resource-constrained networks. The "lightweight"
aspect can be related to the blockchain architecture, device authentication,
cryptography model, consensus algorithm, or storage method. In this paper, we
present a taxonomy of the lightweight blockchain solutions that have been
proposed in the literature and discuss the different methods that have been
applied so far in each "lightweight" category. Our review highlights the
missing points in existing systems and paves the way to building a complete
lightweight blockchain solution for resource-constrained networks.
</p></li>
</ul>

<h3>Title: Privacy-preserving Security Inference Towards Cloud-Edge Collaborative Using Differential Privacy. (arXiv:2212.06428v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2212.06428">http://arxiv.org/abs/2212.06428</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2212.06428] Privacy-preserving Security Inference Towards Cloud-Edge Collaborative Using Differential Privacy](http://arxiv.org/abs/2212.06428) #security</code></li>
<li>Summary: <p>Cloud-edge collaborative inference approach splits deep neural networks
(DNNs) into two parts that run collaboratively on resource-constrained edge
devices and cloud servers, aiming at minimizing inference latency and
protecting data privacy. However, even if the raw input data from edge devices
is not directly exposed to the cloud, state-of-the-art attacks targeting
collaborative inference are still able to reconstruct the raw private data from
the intermediate outputs of the exposed local models, introducing serious
privacy risks. In this paper, a secure privacy inference framework for
cloud-edge collaboration is proposed, termed CIS, which supports adaptively
partitioning the network according to the dynamically changing network
bandwidth and fully releases the computational power of edge devices. To
mitigate the influence introduced by private perturbation, CIS provides a way
to achieve differential privacy protection by adding refined noise to the
intermediate layer feature maps offloaded to the cloud. Meanwhile, with a given
total privacy budget, the budget is reasonably allocated by the size of the
feature graph rank generated by different convolution filters, which makes the
inference in the cloud robust to the perturbed data, thus effectively trade-off
the conflicting problem between privacy and availability. Finally, we construct
a real cloud-edge collaborative inference computing scenario to verify the
effectiveness of inference latency and model partitioning on
resource-constrained edge devices. Furthermore, the state-of-the-art cloud-edge
collaborative reconstruction attack is used to evaluate the practical
availability of the end-to-end privacy protection mechanism provided by CIS.
</p></li>
</ul>

<h3>Title: OpenAPI Specification Extended Security Scheme: A method to reduce the prevalence of Broken Object Level Authorization. (arXiv:2212.06606v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2212.06606">http://arxiv.org/abs/2212.06606</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2212.06606] OpenAPI Specification Extended Security Scheme: A method to reduce the prevalence of Broken Object Level Authorization](http://arxiv.org/abs/2212.06606) #security</code></li>
<li>Summary: <p>APIs have become the prominent technology of choice for achieving
inter-service communications. The growth of API deployments has driven the
urgency in addressing its lack of security standards. API Security is a topic
for concern given the absence of standardized authorization in the OpenAPI
standard, improper authorization opens the possibility for known and unknown
vulnerabilities, which in the past years have been exploited by malicious
actors resulting in data loss. This paper examines the number one vulnerability
in API Security: Broken Object Level Authorization(BOLA), and proposes methods
and tools to reduce the prevalence of this vulnerability. BOLA affects various
API frameworks, our scope is fixated on the OpenAPI Specification(OAS). The OAS
is a standard for describing and implementing APIs; popular OAS Implementations
are FastAPI, Connexion (Flask), and many more. These implementations carry the
pros and cons that are associated with the OASs knowledge of API properties.
The Open API Specifications security properties do not address object
authorization and provide no standardized approach to define such object
properties. This leaves object-level security at the mercy of developers, which
presents an increased risk of unintentionally creating attack vectors. Our aim
is to tackle this void by introducing 1) the OAS ESS (OpenAPI Specification
Extended Security Scheme) which includes declarative security controls for
objects in OAS (design-based approach), and 2) an authorization module that can
be imported to API services (Flask/FastAPI) to enforce authorization checks at
the object level (development-based approach). When building an API service, a
developer can start with the API design (specification) or its code. In both
cases, a set of mechanisms are introduced to help developers mitigate and
reduce the prevalence of BOLA.
</p></li>
</ul>

<h2>privacy</h2>
<h3>Title: Privacy-Preserving Collaborative Learning through Feature Extraction. (arXiv:2212.06322v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2212.06322">http://arxiv.org/abs/2212.06322</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2212.06322] Privacy-Preserving Collaborative Learning through Feature Extraction](http://arxiv.org/abs/2212.06322) #privacy</code></li>
<li>Summary: <p>We propose a framework in which multiple entities collaborate to build a
machine learning model while preserving privacy of their data. The approach
utilizes feature embeddings from shared/per-entity feature extractors
transforming data into a feature space for cooperation between entities. We
propose two specific methods and compare them with a baseline method. In Shared
Feature Extractor (SFE) Learning, the entities use a shared feature extractor
to compute feature embeddings of samples. In Locally Trained Feature Extractor
(LTFE) Learning, each entity uses a separate feature extractor and models are
trained using concatenated features from all entities. As a baseline, in
Cooperatively Trained Feature Extractor (CTFE) Learning, the entities train
models by sharing raw data. Secure multi-party algorithms are utilized to train
models without revealing data or features in plain text. We investigate the
trade-offs among SFE, LTFE, and CTFE in regard to performance, privacy leakage
(using an off-the-shelf membership inference attack), and computational cost.
LTFE provides the most privacy, followed by SFE, and then CTFE. Computational
cost is lowest for SFE and the relative speed of CTFE and LTFE depends on
network architecture. CTFE and LTFE provide the best accuracy. We use MNIST, a
synthetic dataset, and a credit card fraud detection dataset for evaluations.
</p></li>
</ul>

<h3>Title: Considerations for Differentially Private Learning with Large-Scale Public Pretraining. (arXiv:2212.06470v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2212.06470">http://arxiv.org/abs/2212.06470</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2212.06470] Considerations for Differentially Private Learning with Large-Scale Public Pretraining](http://arxiv.org/abs/2212.06470) #privacy</code></li>
<li>Summary: <p>The performance of differentially private machine learning can be boosted
significantly by leveraging the transfer learning capabilities of non-private
models pretrained on large public datasets. We critically review this approach.
</p></li>
</ul>

<p>We primarily question whether the use of large Web-scraped datasets should be
viewed as differential-privacy-preserving. We caution that publicizing these
models pretrained on Web data as "private" could lead to harm and erode the
public's trust in differential privacy as a meaningful definition of privacy.
</p>
<p>Beyond the privacy considerations of using public data, we further question
the utility of this paradigm. We scrutinize whether existing machine learning
benchmarks are appropriate for measuring the ability of pretrained models to
generalize to sensitive domains, which may be poorly represented in public Web
data. Finally, we notice that pretraining has been especially impactful for the
largest available models -- models sufficiently large to prohibit end users
running them on their own devices. Thus, deploying such models today could be a
net loss for privacy, as it would require (private) data to be outsourced to a
more compute-powerful third party.
</p>
<p>We conclude by discussing potential paths forward for the field of private
learning, as public pretraining becomes more popular and powerful.
</p>

<h3>Title: Trajectory Privacy Protection Mechanism based on Social Attributes. (arXiv:2212.06600v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2212.06600">http://arxiv.org/abs/2212.06600</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2212.06600] Trajectory Privacy Protection Mechanism based on Social Attributes](http://arxiv.org/abs/2212.06600) #privacy</code></li>
<li>Summary: <p>The current trajectory privacy protection technology only considers the
temporal and spatial attributes of trajectory data, but ignores the social
attributes. However, there is an intrinsic relationship between social
attributes and human activity trajectories, which brings new challenges to
trajectory privacy protection, making existing trajectory privacy protection
technologies unable to resist trajectory privacy attacks based on social
attributes. To this end, this paper first studies the social privacy attack in
the trajectory data, builds a social privacy attack model based on the fusion
of "space-time" features, and reveals the internal impact of the spatial and
temporal features in the trajectory data on social privacy leaks. -Anonymous
algorithm and trajectory release privacy protection provide theoretical
support. On this basis, integrate social attributes into trajectory privacy
protection technology, design trajectory k-anonymity algorithm based on
"space-time-social" three-dimensional mobile model, and construct trajectory
data based on "space-time-social-semantic" multi-dimensional correlation
Publish privacy-preserving models.
</p></li>
</ul>

<h3>Title: Plausible deniability for privacy-preserving data synthesis. (arXiv:2212.06604v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2212.06604">http://arxiv.org/abs/2212.06604</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2212.06604] Plausible deniability for privacy-preserving data synthesis](http://arxiv.org/abs/2212.06604) #privacy</code></li>
<li>Summary: <p>In the field of privacy protection, publishing complete data (especially
high-dimensional data sets) is one of the most challenging problems. The common
encryption technology can not deal with the attacker to take differential
attack to obtain sensitive information, while the existing differential privacy
protection algorithm model takes a long time for high-dimensional calculation
and needs to add noise to reduce data accuracy, which is not suitable for
high-dimensional large data sets. In view of this situation, this paper designs
a complete data synthesis scheme to protect data privacy around the concept of
"plausible denial". Firstly, the paper provides the theoretical support for the
difference between "plausible data" and "plausible data". In the process of
scheme designing, this paper decomposes the scheme design into construction
data synthesis module and privacy test module, then designs algorithm models
for them respectively and realizes the function of privacy protection. When
evaluating the feasibility of the scheme, the paper selects the Results of the
2013 community census in the United States as the high-dimensional data set,
uses the simulation program that is based on Python to test and analyzes the
efficiency and reliability of the data synthesis scheme. This portion focuses
on the evaluation of the privacy protection effectiveness of the scheme.
</p></li>
</ul>

<h2>protect</h2>
<h2>defense</h2>
<h2>attack</h2>
<h3>Title: Object-fabrication Targeted Attack for Object Detection. (arXiv:2212.06431v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2212.06431">http://arxiv.org/abs/2212.06431</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2212.06431] Object-fabrication Targeted Attack for Object Detection](http://arxiv.org/abs/2212.06431) #attack</code></li>
<li>Summary: <p>Recent researches show that the deep learning based object detection is
vulnerable to adversarial examples. Generally, the adversarial attack for
object detection contains targeted attack and untargeted attack. According to
our detailed investigations, the research on the former is relatively fewer
than the latter and all the existing methods for the targeted attack follow the
same mode, i.e., the object-mislabeling mode that misleads detectors to
mislabel the detected object as a specific wrong label. However, this mode has
limited attack success rate, universal and generalization performances. In this
paper, we propose a new object-fabrication targeted attack mode which can
mislead detectors to `fabricate' extra false objects with specific target
labels. Furthermore, we design a dual attention based targeted feature space
attack method to implement the proposed targeted attack mode. The attack
performances of the proposed mode and method are evaluated on MS COCO and
BDD100K datasets using FasterRCNN and YOLOv5. Evaluation results demonstrate
that, the proposed object-fabrication targeted attack mode and the
corresponding targeted feature space attack method show significant
improvements in terms of image-specific attack, universal performance and
generalization capability, compared with the previous targeted attack for
object detection. Code will be made available.
</p></li>
</ul>

<h3>Title: Pixel is All You Need: Adversarial Trajectory-Ensemble Active Learning for Salient Object Detection. (arXiv:2212.06493v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2212.06493">http://arxiv.org/abs/2212.06493</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2212.06493] Pixel is All You Need: Adversarial Trajectory-Ensemble Active Learning for Salient Object Detection](http://arxiv.org/abs/2212.06493) #attack</code></li>
<li>Summary: <p>Although weakly-supervised techniques can reduce the labeling effort, it is
unclear whether a saliency model trained with weakly-supervised data (e.g.,
point annotation) can achieve the equivalent performance of its
fully-supervised version. This paper attempts to answer this unexplored
question by proving a hypothesis: there is a point-labeled dataset where
saliency models trained on it can achieve equivalent performance when trained
on the densely annotated dataset. To prove this conjecture, we proposed a novel
yet effective adversarial trajectory-ensemble active learning (ATAL). Our
contributions are three-fold: 1) Our proposed adversarial attack triggering
uncertainty can conquer the overconfidence of existing active learning methods
and accurately locate these uncertain pixels. {2)} Our proposed
trajectory-ensemble uncertainty estimation method maintains the advantages of
the ensemble networks while significantly reducing the computational cost. {3)}
Our proposed relationship-aware diversity sampling algorithm can conquer
oversampling while boosting performance. Experimental results show that our
ATAL can find such a point-labeled dataset, where a saliency model trained on
it obtained $97\%$ -- $99\%$ performance of its fully-supervised version with
only ten annotated points per image.
</p></li>
</ul>

<h3>Title: Unfolding Local Growth Rate Estimates for (Almost) Perfect Adversarial Detection. (arXiv:2212.06776v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2212.06776">http://arxiv.org/abs/2212.06776</a></li>
<li>Code URL: <a href="https://github.com/adverml/multilid">https://github.com/adverml/multilid</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2212.06776] Unfolding Local Growth Rate Estimates for (Almost) Perfect Adversarial Detection](http://arxiv.org/abs/2212.06776) #attack</code></li>
<li>Summary: <p>Convolutional neural networks (CNN) define the state-of-the-art solution on
many perceptual tasks. However, current CNN approaches largely remain
vulnerable against adversarial perturbations of the input that have been
crafted specifically to fool the system while being quasi-imperceptible to the
human eye. In recent years, various approaches have been proposed to defend
CNNs against such attacks, for example by model hardening or by adding explicit
defence mechanisms. Thereby, a small "detector" is included in the network and
trained on the binary classification task of distinguishing genuine data from
data containing adversarial perturbations. In this work, we propose a simple
and light-weight detector, which leverages recent findings on the relation
between networks' local intrinsic dimensionality (LID) and adversarial attacks.
Based on a re-interpretation of the LID measure and several simple adaptations,
we surpass the state-of-the-art on adversarial detection by a significant
margin and reach almost perfect results in terms of F1-score for several
networks and datasets. Sources available at:
https://github.com/adverML/multiLID
</p></li>
</ul>

<h3>Title: Adversarial Attacks and Defences for Skin Cancer Classification. (arXiv:2212.06822v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2212.06822">http://arxiv.org/abs/2212.06822</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2212.06822] Adversarial Attacks and Defences for Skin Cancer Classification](http://arxiv.org/abs/2212.06822) #attack</code></li>
<li>Summary: <p>There has been a concurrent significant improvement in the medical images
used to facilitate diagnosis and the performance of machine learning techniques
to perform tasks such as classification, detection, and segmentation in recent
years. As a result, a rapid increase in the usage of such systems can be
observed in the healthcare industry, for instance in the form of medical image
classification systems, where these models have achieved diagnostic parity with
human physicians. One such application where this can be observed is in
computer vision tasks such as the classification of skin lesions in
dermatoscopic images. However, as stakeholders in the healthcare industry, such
as insurance companies, continue to invest extensively in machine learning
infrastructure, it becomes increasingly important to understand the
vulnerabilities in such systems. Due to the highly critical nature of the tasks
being carried out by these machine learning models, it is necessary to analyze
techniques that could be used to take advantage of these vulnerabilities and
methods to defend against them. This paper explores common adversarial attack
techniques. The Fast Sign Gradient Method and Projected Descent Gradient are
used against a Convolutional Neural Network trained to classify dermatoscopic
images of skin lesions. Following that, it also discusses one of the most
popular adversarial defense techniques, adversarial training. The performance
of the model that has been trained on adversarial examples is then tested
against the previously mentioned attacks, and recommendations to improve neural
networks robustness are thus provided based on the results of the experiment.
</p></li>
</ul>

<h2>robust</h2>
<h3>Title: Breaking the "Object" in Video Object Segmentation. (arXiv:2212.06200v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2212.06200">http://arxiv.org/abs/2212.06200</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2212.06200] Breaking the "Object" in Video Object Segmentation](http://arxiv.org/abs/2212.06200) #robust</code></li>
<li>Summary: <p>The appearance of an object can be fleeting when it transforms. As eggs are
broken or paper is torn, their color, shape and texture can change
dramatically, preserving virtually nothing of the original except for the
identity itself. Yet, this important phenomenon is largely absent from existing
video object segmentation (VOS) benchmarks. In this work, we close the gap by
collecting a new dataset for Video Object Segmentation under Transformations
(VOST). It consists of more than 700 high-resolution videos, captured in
diverse environments, which are 20 seconds long on average and densely labeled
with instance masks. A careful, multi-step approach is adopted to ensure that
these videos focus on complex object transformations, capturing their full
temporal extent. We then extensively evaluate state-of-the-art VOS methods and
make a number of important discoveries. In particular, we show that existing
methods struggle when applied to this novel task and that their main limitation
lies in over-reliance on static appearance cues. This motivates us to propose a
few modifications for the top-performing baseline that improve its capabilities
by better modeling spatio-temporal information. But more broadly, the hope is
to stimulate discussion on learning more robust video object representations.
</p></li>
</ul>

<h3>Title: Test-time Adaptation vs. Training-time Generalization: A Case Study in Human Instance Segmentation using Keypoints Estimation. (arXiv:2212.06242v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2212.06242">http://arxiv.org/abs/2212.06242</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2212.06242] Test-time Adaptation vs](http://arxiv.org/abs/2212.06242) #robust</code></li>
<li>Summary: <p>We consider the problem of improving the human instance segmentation mask
quality for a given test image using keypoints estimation. We compare two
alternative approaches. The first approach is a test-time adaptation (TTA)
method, where we allow test-time modification of the segmentation network's
weights using a single unlabeled test image. In this approach, we do not assume
test-time access to the labeled source dataset. More specifically, our TTA
method consists of using the keypoints estimates as pseudo labels and
backpropagating them to adjust the backbone weights. The second approach is a
training-time generalization (TTG) method, where we permit offline access to
the labeled source dataset but not the test-time modification of weights.
Furthermore, we do not assume the availability of any images from or knowledge
about the target domain. Our TTG method consists of augmenting the backbone
features with those generated by the keypoints head and feeding the aggregate
vector to the mask head. Through a comprehensive set of ablations, we evaluate
both approaches and identify several factors limiting the TTA gains. In
particular, we show that in the absence of a significant domain shift, TTA may
hurt and TTG show only a small gain in performance, whereas for a large domain
shift, TTA gains are smaller and dependent on the heuristics used, while TTG
gains are larger and robust to architectural choices.
</p></li>
</ul>

<h3>Title: You Only Need a Good Embeddings Extractor to Fix Spurious Correlations. (arXiv:2212.06254v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2212.06254">http://arxiv.org/abs/2212.06254</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2212.06254] You Only Need a Good Embeddings Extractor to Fix Spurious Correlations](http://arxiv.org/abs/2212.06254) #robust</code></li>
<li>Summary: <p>Spurious correlations in training data often lead to robustness issues since
models learn to use them as shortcuts. For example, when predicting whether an
object is a cow, a model might learn to rely on its green background, so it
would do poorly on a cow on a sandy background. A standard dataset for
measuring state-of-the-art on methods mitigating this problem is Waterbirds.
The best method (Group Distributionally Robust Optimization - GroupDRO)
currently achieves 89\% worst group accuracy and standard training from scratch
on raw images only gets 72\%. GroupDRO requires training a model in an
end-to-end manner with subgroup labels. In this paper, we show that we can
achieve up to 90\% accuracy without using any sub-group information in the
training set by simply using embeddings from a large pre-trained vision model
extractor and training a linear classifier on top of it. With experiments on a
wide range of pre-trained models and pre-training datasets, we show that the
capacity of the pre-training model and the size of the pre-training dataset
matters. Our experiments reveal that high capacity vision transformers perform
better compared to high capacity convolutional neural networks, and larger
pre-training dataset leads to better worst-group accuracy on the spurious
correlation dataset.
</p></li>
</ul>

<h3>Title: DifFace: Blind Face Restoration with Diffused Error Contraction. (arXiv:2212.06512v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2212.06512">http://arxiv.org/abs/2212.06512</a></li>
<li>Code URL: <a href="https://github.com/zsyoaoa/difface">https://github.com/zsyoaoa/difface</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2212.06512] DifFace: Blind Face Restoration with Diffused Error Contraction](http://arxiv.org/abs/2212.06512) #robust</code></li>
<li>Summary: <p>While deep learning-based methods for blind face restoration have achieved
unprecedented success, they still suffer from two major limitations. First,
most of them deteriorate when facing complex degradations out of their training
data. Second, these methods require multiple constraints, e.g., fidelity,
perceptual, and adversarial losses, which require laborious hyper-parameter
tuning to stabilize and balance their influences. In this work, we propose a
novel method named DifFace that is capable of coping with unseen and complex
degradations more gracefully without complicated loss designs. The key of our
method is to establish a posterior distribution from the observed low-quality
(LQ) image to its high-quality (HQ) counterpart. In particular, we design a
transition distribution from the LQ image to the intermediate state of a
pre-trained diffusion model and then gradually transmit from this intermediate
state to the HQ target by recursively applying a pre-trained diffusion model.
The transition distribution only relies on a restoration backbone that is
trained with $L_2$ loss on some synthetic data, which favorably avoids the
cumbersome training process in existing methods. Moreover, the transition
distribution can contract the error of the restoration backbone and thus makes
our method more robust to unknown degradations. Comprehensive experiments show
that DifFace is superior to current state-of-the-art methods, especially in
cases with severe degradations. Our code and model are available at
https://github.com/zsyOAOA/DifFace.
</p></li>
</ul>

<h3>Title: OAMixer: Object-aware Mixing Layer for Vision Transformers. (arXiv:2212.06595v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2212.06595">http://arxiv.org/abs/2212.06595</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2212.06595] OAMixer: Object-aware Mixing Layer for Vision Transformers](http://arxiv.org/abs/2212.06595) #robust</code></li>
<li>Summary: <p>Patch-based models, e.g., Vision Transformers (ViTs) and Mixers, have shown
impressive results on various visual recognition tasks, alternating classic
convolutional networks. While the initial patch-based models (ViTs) treated all
patches equally, recent studies reveal that incorporating inductive bias like
spatiality benefits the representations. However, most prior works solely
focused on the location of patches, overlooking the scene structure of images.
Thus, we aim to further guide the interaction of patches using the object
information. Specifically, we propose OAMixer (object-aware mixing layer),
which calibrates the patch mixing layers of patch-based models based on the
object labels. Here, we obtain the object labels in unsupervised or
weakly-supervised manners, i.e., no additional human-annotating cost is
necessary. Using the object labels, OAMixer computes a reweighting mask with a
learnable scale parameter that intensifies the interaction of patches
containing similar objects and applies the mask to the patch mixing layers. By
learning an object-centric representation, we demonstrate that OAMixer improves
the classification accuracy and background robustness of various patch-based
models, including ViTs, MLP-Mixers, and ConvMixers. Moreover, we show that
OAMixer enhances various downstream tasks, including large-scale
classification, self-supervised learning, and multi-object recognition,
verifying the generic applicability of OAMixer
</p></li>
</ul>

<h3>Title: DELS-MVS: Deep Epipolar Line Search for Multi-View Stereo. (arXiv:2212.06626v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2212.06626">http://arxiv.org/abs/2212.06626</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2212.06626] DELS-MVS: Deep Epipolar Line Search for Multi-View Stereo](http://arxiv.org/abs/2212.06626) #robust</code></li>
<li>Summary: <p>We propose a novel approach for deep learning-based Multi-View Stereo (MVS).
For each pixel in the reference image, our method leverages a deep architecture
to search for the corresponding point in the source image directly along the
corresponding epipolar line. We denote our method DELS-MVS: Deep Epipolar Line
Search Multi-View Stereo. Previous works in deep MVS select a range of interest
within the depth space, discretize it, and sample the epipolar line according
to the resulting depth values: this can result in an uneven scanning of the
epipolar line, hence of the image space. Instead, our method works directly on
the epipolar line: this guarantees an even scanning of the image space and
avoids both the need to select a depth range of interest, which is often not
known a priori and can vary dramatically from scene to scene, and the need for
a suitable discretization of the depth space. In fact, our search is iterative,
which avoids the building of a cost volume, costly both to store and to
process. Finally, our method performs a robust geometry-aware fusion of the
estimated depth maps, leveraging a confidence predicted alongside each depth.
We test DELS-MVS on the ETH3D, Tanks and Temples and DTU benchmarks and achieve
competitive results with respect to state-of-the-art approaches.
</p></li>
</ul>

<h3>Title: Learning 3D Representations from 2D Pre-trained Models via Image-to-Point Masked Autoencoders. (arXiv:2212.06785v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2212.06785">http://arxiv.org/abs/2212.06785</a></li>
<li>Code URL: <a href="https://github.com/zrrskywalker/i2p-mae">https://github.com/zrrskywalker/i2p-mae</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2212.06785] Learning 3D Representations from 2D Pre-trained Models via Image-to-Point Masked Autoencoders](http://arxiv.org/abs/2212.06785) #robust</code></li>
<li>Summary: <p>Pre-training by numerous image data has become de-facto for robust 2D
representations. In contrast, due to the expensive data acquisition and
annotation, a paucity of large-scale 3D datasets severely hinders the learning
for high-quality 3D features. In this paper, we propose an alternative to
obtain superior 3D representations from 2D pre-trained models via
Image-to-Point Masked Autoencoders, named as I2P-MAE. By self-supervised
pre-training, we leverage the well learned 2D knowledge to guide 3D masked
autoencoding, which reconstructs the masked point tokens with an
encoder-decoder architecture. Specifically, we first utilize off-the-shelf 2D
models to extract the multi-view visual features of the input point cloud, and
then conduct two types of image-to-point learning schemes on top. For one, we
introduce a 2D-guided masking strategy that maintains semantically important
point tokens to be visible for the encoder. Compared to random masking, the
network can better concentrate on significant 3D structures and recover the
masked tokens from key spatial cues. For another, we enforce these visible
tokens to reconstruct the corresponding multi-view 2D features after the
decoder. This enables the network to effectively inherit high-level 2D
semantics learned from rich image data for discriminative 3D modeling. Aided by
our image-to-point pre-training, the frozen I2P-MAE, without any fine-tuning,
achieves 93.4% accuracy for linear SVM on ModelNet40, competitive to the fully
trained results of existing methods. By further fine-tuning on on
ScanObjectNN's hardest split, I2P-MAE attains the state-of-the-art 90.11%
accuracy, +3.68% to the second-best, demonstrating superior transferable
capacity. Code will be available at https://github.com/ZrrSkywalker/I2P-MAE.
</p></li>
</ul>

<h3>Title: Distantly-Supervised Named Entity Recognition with Adaptive Teacher Learning and Fine-grained Student Ensemble. (arXiv:2212.06522v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2212.06522">http://arxiv.org/abs/2212.06522</a></li>
<li>Code URL: <a href="https://github.com/zenhjunpro/atsen">https://github.com/zenhjunpro/atsen</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2212.06522] Distantly-Supervised Named Entity Recognition with Adaptive Teacher Learning and Fine-grained Student Ensemble](http://arxiv.org/abs/2212.06522) #robust</code></li>
<li>Summary: <p>Distantly-Supervised Named Entity Recognition (DS-NER) effectively alleviates
the data scarcity problem in NER by automatically generating training samples.
Unfortunately, the distant supervision may induce noisy labels, thus
undermining the robustness of the learned models and restricting the practical
application. To relieve this problem, recent works adopt self-training
teacher-student frameworks to gradually refine the training labels and improve
the generalization ability of NER models. However, we argue that the
performance of the current self-training frameworks for DS-NER is severely
underestimated by their plain designs, including both inadequate student
learning and coarse-grained teacher updating. Therefore, in this paper, we make
the first attempt to alleviate these issues by proposing: (1) adaptive teacher
learning comprised of joint training of two teacher-student networks and
considering both consistent and inconsistent predictions between two teachers,
thus promoting comprehensive student learning. (2) fine-grained student
ensemble that updates each fragment of the teacher model with a temporal moving
average of the corresponding fragment of the student, which enhances consistent
predictions on each model fragment against noise. To verify the effectiveness
of our proposed method, we conduct experiments on four DS-NER datasets. The
experimental results demonstrate that our method significantly surpasses
previous SOTA methods.
</p></li>
</ul>

<h3>Title: Exploring Fake News Detection with Heterogeneous Social Media Context Graphs. (arXiv:2212.06560v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2212.06560">http://arxiv.org/abs/2212.06560</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2212.06560] Exploring Fake News Detection with Heterogeneous Social Media Context Graphs](http://arxiv.org/abs/2212.06560) #robust</code></li>
<li>Summary: <p>Fake news detection has become a research area that goes way beyond a purely
academic interest as it has direct implications on our society as a whole.
Recent advances have primarily focused on textbased approaches. However, it has
become clear that to be effective one needs to incorporate additional,
contextual information such as spreading behaviour of news articles and user
interaction patterns on social media. We propose to construct heterogeneous
social context graphs around news articles and reformulate the problem as a
graph classification task. Exploring the incorporation of different types of
information (to get an idea as to what level of social context is most
effective) and using different graph neural network architectures indicates
that this approach is highly effective with robust results on a common
benchmark dataset.
</p></li>
</ul>

<h3>Title: AFLGuard: Byzantine-robust Asynchronous Federated Learning. (arXiv:2212.06325v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2212.06325">http://arxiv.org/abs/2212.06325</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2212.06325] AFLGuard: Byzantine-robust Asynchronous Federated Learning](http://arxiv.org/abs/2212.06325) #robust</code></li>
<li>Summary: <p>Federated learning (FL) is an emerging machine learning paradigm, in which
clients jointly learn a model with the help of a cloud server. A fundamental
challenge of FL is that the clients are often heterogeneous, e.g., they have
different computing powers, and thus the clients may send model updates to the
server with substantially different delays. Asynchronous FL aims to address
this challenge by enabling the server to update the model once any client's
model update reaches it without waiting for other clients' model updates.
However, like synchronous FL, asynchronous FL is also vulnerable to poisoning
attacks, in which malicious clients manipulate the model via poisoning their
local data and/or model updates sent to the server. Byzantine-robust FL aims to
defend against poisoning attacks. In particular, Byzantine-robust FL can learn
an accurate model even if some clients are malicious and have Byzantine
behaviors. However, most existing studies on Byzantine-robust FL focused on
synchronous FL, leaving asynchronous FL largely unexplored. In this work, we
bridge this gap by proposing AFLGuard, a Byzantine-robust asynchronous FL
method. We show that, both theoretically and empirically, AFLGuard is robust
against various existing and adaptive poisoning attacks (both untargeted and
targeted). Moreover, AFLGuard outperforms existing Byzantine-robust
asynchronous FL methods.
</p></li>
</ul>

<h3>Title: A fast and Accurate Sketch Method for Estimating User Similarities over Trajectory Data. (arXiv:2212.06601v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2212.06601">http://arxiv.org/abs/2212.06601</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2212.06601] A fast and Accurate Sketch Method for Estimating User Similarities over Trajectory Data](http://arxiv.org/abs/2212.06601) #robust</code></li>
<li>Summary: <p>In a complex urban environment, due to the unavoidable interruption of GNSS
positioning signals and the accumulation of errors during vehicle driving, the
collected vehicle trajectory data is likely to be inaccurate and incomplete. A
weighted trajectory reconstruction algorithm based on a bidirectional RNN deep
network is proposed. GNSS/OBD trajectory acquisition equipment is used to
collect vehicle trajectory information, and multi-source data fusion is used to
realize bidirectional weighted trajectory reconstruction. At the same time, the
neural arithmetic logic unit (NALU) is introduced into the trajectory
reconstruction model to strengthen the extrapolation ability of the deep
network and ensure the accuracy of trajectory prediction, which can improve the
robustness of the algorithm in trajectory reconstruction when dealing with
complex urban road sections. The actual urban road section was selected for
testing experiments, and a comparative analysis was carried out with existing
methods. Through root mean square error (RMSE, root-mean-square error) and
using Google Earth to visualize the reconstructed trajectory, the experimental
results demonstrate the effectiveness and reliability of the proposed
algorithm.
</p></li>
</ul>

<h3>Title: ALRt: An Active Learning Framework for Irregularly Sampled Temporal Data. (arXiv:2212.06364v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2212.06364">http://arxiv.org/abs/2212.06364</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2212.06364] ALRt: An Active Learning Framework for Irregularly Sampled Temporal Data](http://arxiv.org/abs/2212.06364) #robust</code></li>
<li>Summary: <p>Sepsis is a deadly condition affecting many patients in the hospital. Recent
studies have shown that patients diagnosed with sepsis have significant
mortality and morbidity, resulting from the body's dysfunctional host response
to infection. Clinicians often rely on the use of Sequential Organ Failure
Assessment (SOFA), Systemic Inflammatory Response Syndrome (SIRS), and the
Modified Early Warning Score (MEWS) to identify early signs of clinical
deterioration requiring further work-up and treatment. However, many of these
tools are manually computed and were not designed for automated computation.
There have been different methods used for developing sepsis onset models, but
many of these models must be trained on a sufficient number of patient
observations in order to form accurate sepsis predictions. Additionally, the
accurate annotation of patients with sepsis is a major ongoing challenge. In
this paper, we propose the use of Active Learning Recurrent Neural Networks
(ALRts) for short temporal horizons to improve the prediction of irregularly
sampled temporal events such as sepsis. We show that an active learning RNN
model trained on limited data can form robust sepsis predictions comparable to
models using the entire training dataset.
</p></li>
</ul>

<h3>Title: CropCat: Data Augmentation for Smoothing the Feature Distribution of EEG Signals. (arXiv:2212.06413v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2212.06413">http://arxiv.org/abs/2212.06413</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2212.06413] CropCat: Data Augmentation for Smoothing the Feature Distribution of EEG Signals](http://arxiv.org/abs/2212.06413) #robust</code></li>
<li>Summary: <p>Brain-computer interface (BCI) is a communication system between humans and
computers reflecting human intention without using a physical control device.
Since deep learning is robust in extracting features from data, research on
decoding electroencephalograms by applying deep learning has progressed in the
BCI domain. However, the application of deep learning in the BCI domain has
issues with a lack of data and overconfidence. To solve these issues, we
proposed a novel data augmentation method, CropCat. CropCat consists of two
versions, CropCat-spatial and CropCat-temporal. We designed our method by
concatenating the cropped data after cropping the data, which have different
labels in spatial and temporal axes. In addition, we adjusted the label based
on the ratio of cropped length. As a result, the generated data from our
proposed method assisted in revising the ambiguous decision boundary into
apparent caused by a lack of data. Due to the effectiveness of the proposed
method, the performance of the four EEG signal decoding models is improved in
two motor imagery public datasets compared to when the proposed method is not
applied. Hence, we demonstrate that generated data by CropCat smooths the
feature distribution of EEG signals when training the model.
</p></li>
</ul>

<h3>Title: Multi-objective Tree-structured Parzen Estimator Meets Meta-learning. (arXiv:2212.06751v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2212.06751">http://arxiv.org/abs/2212.06751</a></li>
<li>Code URL: <a href="https://github.com/nabenabe0928/meta-learn-tpe">https://github.com/nabenabe0928/meta-learn-tpe</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2212.06751] Multi-objective Tree-structured Parzen Estimator Meets Meta-learning](http://arxiv.org/abs/2212.06751) #robust</code></li>
<li>Summary: <p>Hyperparameter optimization (HPO) is essential for the better performance of
deep learning, and practitioners often need to consider the trade-off between
multiple metrics, such as error rate, latency, memory requirements, robustness,
and algorithmic fairness. Due to this demand and the heavy computation of deep
learning, the acceleration of multi-objective (MO) optimization becomes ever
more important. Although meta-learning has been extensively studied to speedup
HPO, existing methods are not applicable to the MO tree-structured parzen
estimator (MO-TPE), a simple yet powerful MO-HPO algorithm. In this paper, we
extend TPE's acquisition function to the meta-learning setting, using a task
similarity defined by the overlap in promising domains of each task. In a
comprehensive set of experiments, we demonstrate that our method accelerates
MO-TPE on tabular HPO benchmarks and yields state-of-the-art performance. Our
method was also validated externally by winning the AutoML 2022 competition on
"Multiobjective Hyperparameter Optimization for Transformers".
</p></li>
</ul>

<h2>biometric</h2>
<h2>steal</h2>
<h2>extraction</h2>
<h3>Title: Contextual Explainable Video Representation:\Human Perception-based Understanding. (arXiv:2212.06206v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2212.06206">http://arxiv.org/abs/2212.06206</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2212.06206] Contextual Explainable Video Representation:\\Human Perception-based Understanding](http://arxiv.org/abs/2212.06206) #extraction</code></li>
<li>Summary: <p>Video understanding is a growing field and a subject of intense research,
which includes many interesting tasks to understanding both spatial and
temporal information, e.g., action detection, action recognition, video
captioning, video retrieval. One of the most challenging problems in video
understanding is dealing with feature extraction, i.e. extract contextual
visual representation from given untrimmed video due to the long and
complicated temporal structure of unconstrained videos. Different from existing
approaches, which apply a pre-trained backbone network as a black-box to
extract visual representation, our approach aims to extract the most contextual
information with an explainable mechanism. As we observed, humans typically
perceive a video through the interactions between three main factors, i.e., the
actors, the relevant objects, and the surrounding environment. Therefore, it is
very crucial to design a contextual explainable video representation extraction
that can capture each of such factors and model the relationships between them.
In this paper, we discuss approaches, that incorporate the human perception
process into modeling actors, objects, and the environment. We choose video
paragraph captioning and temporal action detection to illustrate the
effectiveness of human perception based-contextual representation in video
understanding. Source code is publicly available at
https://github.com/UARK-AICV/Video_Representation.
</p></li>
</ul>

<h2>membership infer</h2>
<h2>federate</h2>
<h2>fair</h2>
<h3>Title: Improving Depression estimation from facial videos with face alignment, training optimization and scheduling. (arXiv:2212.06400v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2212.06400">http://arxiv.org/abs/2212.06400</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2212.06400] Improving Depression estimation from facial videos with face alignment, training optimization and scheduling](http://arxiv.org/abs/2212.06400) #fair</code></li>
<li>Summary: <p>Deep learning models have shown promising results in recognizing depressive
states using video-based facial expressions. While successful models typically
leverage using 3D-CNNs or video distillation techniques, the different use of
pretraining, data augmentation, preprocessing, and optimization techniques
across experiments makes it difficult to make fair architectural comparisons.
We propose instead to enhance two simple models based on ResNet-50 that use
only static spatial information by using two specific face alignment methods
and improved data augmentation, optimization, and scheduling techniques. Our
extensive experiments on benchmark datasets obtain similar results to
sophisticated spatio-temporal models for single streams, while the score-level
fusion of two different streams outperforms state-of-the-art methods. Our
findings suggest that specific modifications in the preprocessing and training
process result in noticeable differences in the performance of the models and
could hide the actual originally attributed to the use of different neural
network architectures.
</p></li>
</ul>

<h3>Title: On Text-based Personality Computing: Challenges and Future Directions. (arXiv:2212.06711v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2212.06711">http://arxiv.org/abs/2212.06711</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2212.06711] On Text-based Personality Computing: Challenges and Future Directions](http://arxiv.org/abs/2212.06711) #fair</code></li>
<li>Summary: <p>Text-based personality computing (TPC) has gained many research interests in
NLP. In this paper, we describe 15 challenges that we consider deserving the
attention of the research community. These challenges are organized by the
following topics: personality taxonomies, measurement quality, datasets,
performance evaluation, modelling choices, as well as ethics and fairness. When
addressing each challenge, not only do we combine perspectives from both NLP
and social sciences, but also offer concrete suggestions towards more valid and
reliable TPC research.
</p></li>
</ul>

<h3>Title: Fairify: Fairness Verification of Neural Networks. (arXiv:2212.06140v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2212.06140">http://arxiv.org/abs/2212.06140</a></li>
<li>Code URL: <a href="https://github.com/sumonbis/farify">https://github.com/sumonbis/farify</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2212.06140] Fairify: Fairness Verification of Neural Networks](http://arxiv.org/abs/2212.06140) #fair</code></li>
<li>Summary: <p>Fairness of machine learning (ML) software has become a major concern in the
recent past. Although recent research on testing and improving fairness have
demonstrated impact on real-world software, providing fairness guarantee in
practice is still lacking. Certification of ML models is challenging because of
the complex decision-making process of the models. In this paper, we proposed
Fairify, the first SMT-based approach to verify individual fairness property in
neural network (NN) models. Individual fairness ensures that any two similar
individuals get similar treatment irrespective of their protected attributes
e.g., race, sex, age. Verifying this fairness property is hard because of its
global nature and the presence of non-linear computation nodes in NN. We
proposed sound approach to make individual fairness verification tractable for
the developers. The key idea is that many neurons in the NN always remain
inactive when a smaller part of the input domain is considered. So, Fairify
leverages white-box access to the models in production and then apply formal
analysis based pruning. Our approach adopts input partitioning and then prunes
the NN for each partition to provide fairness certification or counterexample.
We leveraged interval arithmetic and activation heuristic of the neurons to
perform the pruning as necessary. We evaluated Fairify on 25 real-world neural
networks collected from four different sources, and demonstrated the
effectiveness, scalability and performance over baseline and closely related
work. Fairify is also configurable based on the domain and size of the NN. Our
novel formulation of the problem can answer targeted verification queries with
relaxations and counterexamples, which have practical implications.
</p></li>
</ul>

<h3>Title: Simplicity Bias Leads to Amplified Performance Disparities. (arXiv:2212.06641v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2212.06641">http://arxiv.org/abs/2212.06641</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2212.06641] Simplicity Bias Leads to Amplified Performance Disparities](http://arxiv.org/abs/2212.06641) #fair</code></li>
<li>Summary: <p>The simple idea that not all things are equally difficult has surprising
implications when applied in a fairness context. In this work we explore how
"difficulty" is model-specific, such that different models find different parts
of a dataset challenging. When difficulty correlates with group information, we
term this difficulty disparity. Drawing a connection with recent work exploring
the inductive bias towards simplicity of SGD-trained models, we show that when
such a disparity exists, it is further amplified by commonly-used models. We
quantify this amplification factor across a range of settings aiming towards a
fuller understanding of the role of model bias. We also present a challenge to
the simplifying assumption that "fixing" a dataset is sufficient to ensure
unbiased performance.
</p></li>
</ul>

<h3>Title: Fair Infinitesimal Jackknife: Mitigating the Influence of Biased Training Data Points Without Refitting. (arXiv:2212.06803v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2212.06803">http://arxiv.org/abs/2212.06803</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2212.06803] Fair Infinitesimal Jackknife: Mitigating the Influence of Biased Training Data Points Without Refitting](http://arxiv.org/abs/2212.06803) #fair</code></li>
<li>Summary: <p>In consequential decision-making applications, mitigating unwanted biases in
machine learning models that yield systematic disadvantage to members of groups
delineated by sensitive attributes such as race and gender is one key
intervention to strive for equity. Focusing on demographic parity and equality
of opportunity, in this paper we propose an algorithm that improves the
fairness of a pre-trained classifier by simply dropping carefully selected
training data points. We select instances based on their influence on the
fairness metric of interest, computed using an infinitesimal jackknife-based
approach. The dropping of training points is done in principle, but in practice
does not require the model to be refit. Crucially, we find that such an
intervention does not substantially reduce the predictive performance of the
model but drastically improves the fairness metric. Through careful
experiments, we evaluate the effectiveness of the proposed approach on diverse
tasks and find that it consistently improves upon existing alternatives.
</p></li>
</ul>

<h2>interpretability</h2>
<h3>Title: Improving Mutual Information based Feature Selection by Boosting Unique Relevance. (arXiv:2212.06143v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2212.06143">http://arxiv.org/abs/2212.06143</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2212.06143] Improving Mutual Information based Feature Selection by Boosting Unique Relevance](http://arxiv.org/abs/2212.06143) #interpretability</code></li>
<li>Summary: <p>Mutual Information (MI) based feature selection makes use of MI to evaluate
each feature and eventually shortlists a relevant feature subset, in order to
address issues associated with high-dimensional datasets. Despite the
effectiveness of MI in feature selection, we notice that many state-of-the-art
algorithms disregard the so-called unique relevance (UR) of features, and
arrive at a suboptimal selected feature subset which contains a non-negligible
number of redundant features. We point out that the heart of the problem is
that all these MIBFS algorithms follow the criterion of Maximize Relevance with
Minimum Redundancy (MRwMR), which does not explicitly target UR. This motivates
us to augment the existing criterion with the objective of boosting unique
relevance (BUR), leading to a new criterion called MRwMR-BUR. Depending on the
task being addressed, MRwMR-BUR has two variants, termed MRwMR-BUR-KSG and
MRwMR-BUR-CLF, which estimate UR differently. MRwMR-BUR-KSG estimates UR via a
nearest-neighbor based approach called the KSG estimator and is designed for
three major tasks: (i) Classification Performance. (ii) Feature
Interpretability. (iii) Classifier Generalization. MRwMR-BUR-CLF estimates UR
via a classifier based approach. It adapts UR to different classifiers, further
improving the competitiveness of MRwMR-BUR for classification performance
oriented tasks. The performance of both MRwMR-BUR-KSG and MRwMR-BUR-CLF is
validated via experiments using six public datasets and three popular
classifiers. Specifically, as compared to MRwMR, the proposed MRwMR-BUR-KSG
improves the test accuracy by 2% - 3% with 25% - 30% fewer features being
selected, without increasing the algorithm complexity. MRwMR-BUR-CLF further
improves the classification performance by 3.8%- 5.5% (relative to MRwMR), and
it also outperforms three popular classifier dependent feature selection
methods.
</p></li>
</ul>

<h3>Title: Improving Accuracy Without Losing Interpretability: A ML Approach for Time Series Forecasting. (arXiv:2212.06620v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2212.06620">http://arxiv.org/abs/2212.06620</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2212.06620] Improving Accuracy Without Losing Interpretability: A ML Approach for Time Series Forecasting](http://arxiv.org/abs/2212.06620) #interpretability</code></li>
<li>Summary: <p>In time series forecasting, decomposition-based algorithms break aggregate
data into meaningful components and are therefore appreciated for their
particular advantages in interpretability. Recent algorithms often combine
machine learning (hereafter ML) methodology with decomposition to improve
prediction accuracy. However, incorporating ML is generally considered to
sacrifice interpretability inevitably. In addition, existing hybrid algorithms
usually rely on theoretical models with statistical assumptions and focus only
on the accuracy of aggregate predictions, and thus suffer from accuracy
problems, especially in component estimates. In response to the above issues,
this research explores the possibility of improving accuracy without losing
interpretability in time series forecasting. We first quantitatively define
interpretability for data-driven forecasts and systematically review the
existing forecasting algorithms from the perspective of interpretability.
Accordingly, we propose the W-R algorithm, a hybrid algorithm that combines
decomposition and ML from a novel perspective. Specifically, the W-R algorithm
replaces the standard additive combination function with a weighted variant and
uses ML to modify the estimates of all components simultaneously. We
mathematically analyze the theoretical basis of the algorithm and validate its
performance through extensive numerical experiments. In general, the W-R
algorithm outperforms all decomposition-based and ML benchmarks. Based on
P50_QL, the algorithm relatively improves by 8.76% in accuracy on the practical
sales forecasts of JD.com and 77.99% on a public dataset of electricity loads.
This research offers an innovative perspective to combine the statistical and
ML algorithms, and JD.com has implemented the W-R algorithm to make accurate
sales predictions and guide its marketing activities.
</p></li>
</ul>

<h2>explainability</h2>
<h2>watermark</h2>
<h2>diffusion</h2>
<h3>Title: HS-Diffusion: Learning a Semantic-Guided Diffusion Model for Head Swapping. (arXiv:2212.06458v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2212.06458">http://arxiv.org/abs/2212.06458</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2212.06458] HS-Diffusion: Learning a Semantic-Guided Diffusion Model for Head Swapping](http://arxiv.org/abs/2212.06458) #diffusion</code></li>
<li>Summary: <p>Image-based head swapping task aims to stitch a source head to another source
body flawlessly. This seldom-studied task faces two major challenges: 1)
Preserving the head and body from various sources while generating a seamless
transition region. 2) No paired head swapping dataset and benchmark so far. In
this paper, we propose an image-based head swapping framework (HS-Diffusion)
which consists of a semantic-guided latent diffusion model (SG-LDM) and a
semantic layout generator. We blend the semantic layouts of source head and
source body, and then inpaint the transition region by the semantic layout
generator, achieving a coarse-grained head swapping. SG-LDM can further
implement fine-grained head swapping with the blended layout as condition by a
progressive fusion process, while preserving source head and source body with
high-quality reconstruction. To this end, we design a head-cover augmentation
strategy for training and a neck alignment trick for geometric realism.
Importantly, we construct a new image-based head swapping benchmark and propose
two tailor-designed metrics (Mask-FID and Focal-FID). Extensive experiments
demonstrate the superiority of our framework. The code will be available:
https://github.com/qinghew/HS-Diffusion.
</p></li>
</ul>

<h3>Title: Semantic Brain Decoding: from fMRI to conceptually similar image reconstruction of visual stimuli. (arXiv:2212.06726v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2212.06726">http://arxiv.org/abs/2212.06726</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2212.06726] Semantic Brain Decoding: from fMRI to conceptually similar image reconstruction of visual stimuli](http://arxiv.org/abs/2212.06726) #diffusion</code></li>
<li>Summary: <p>Brain decoding is a field of computational neuroscience that uses measurable
brain activity to infer mental states or internal representations of perceptual
inputs. Therefore, we propose a novel approach to brain decoding that also
relies on semantic and contextual similarity. We employ an fMRI dataset of
natural image vision and create a deep learning decoding pipeline inspired by
the existence of both bottom-up and top-down processes in human vision. We
train a linear brain-to-feature model to map fMRI activity features to visual
stimuli features, assuming that the brain projects visual information onto a
space that is homeomorphic to the latent space represented by the last
convolutional layer of a pretrained convolutional neural network, which
typically collects a variety of semantic features that summarize and highlight
similarities and differences between concepts. These features are then
categorized in the latent space using a nearest-neighbor strategy, and the
results are used to condition a generative latent diffusion model to create
novel images. From fMRI data only, we produce reconstructions of visual stimuli
that match the original content very well on a semantic level, surpassing the
state of the art in previous literature. We evaluate our work and obtain good
results using a quantitative semantic metric (the Wu-Palmer similarity metric
over the WordNet lexicon, which had an average value of 0.57) and perform a
human evaluation experiment that resulted in correct evaluation, according to
the multiplicity of human criteria in evaluating image similarity, in over 80%
of the test set.
</p></li>
</ul>

<h3>Title: Score-based Generative Modeling Secretly Minimizes the Wasserstein Distance. (arXiv:2212.06359v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2212.06359">http://arxiv.org/abs/2212.06359</a></li>
<li>Code URL: <a href="https://github.com/uw-madison-lee-lab/score-wasserstein">https://github.com/uw-madison-lee-lab/score-wasserstein</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2212.06359] Score-based Generative Modeling Secretly Minimizes the Wasserstein Distance](http://arxiv.org/abs/2212.06359) #diffusion</code></li>
<li>Summary: <p>Score-based generative models are shown to achieve remarkable empirical
performances in various applications such as image generation and audio
synthesis. However, a theoretical understanding of score-based diffusion models
is still incomplete. Recently, Song et al. showed that the training objective
of score-based generative models is equivalent to minimizing the
Kullback-Leibler divergence of the generated distribution from the data
distribution. In this work, we show that score-based models also minimize the
Wasserstein distance between them under suitable assumptions on the model.
Specifically, we prove that the Wasserstein distance is upper bounded by the
square root of the objective function up to multiplicative constants and a
fixed constant offset. Our proof is based on a novel application of the theory
of optimal transport, which can be of independent interest to the society. Our
numerical experiments support our findings. By analyzing our upper bounds, we
provide a few techniques to obtain tighter upper bounds.
</p></li>
</ul>

<button id="copy">Copy All</button>
</article>
<script src="https://cdn.staticfile.org/clipboard.js/2.0.4/clipboard.min.js"></script>
<script src="../../javascript/clipboard.js"></script>
