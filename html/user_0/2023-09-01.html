<link rel="stylesheet" href="../../css/markdown.css" />
<article class="markdown-body">
<h2>secure</h2>
<h3>Title: Two-Stage Violence Detection Using ViTPose and Classification Models at Smart Airports. (arXiv:2308.16325v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2308.16325">http://arxiv.org/abs/2308.16325</a></li>
<li>Code URL: https://github.com/asami-1/gdp</li>
<li>Copy Paste: <code><input type="checkbox">[[2308.16325]] Two-Stage Violence Detection Using ViTPose and Classification Models at Smart Airports(http://arxiv.org/abs/2308.16325)</code></li>
<li>Summary: <p>This study introduces an innovative violence detection framework tailored to
the unique requirements of smart airports, where prompt responses to violent
situations are crucial. The proposed framework harnesses the power of ViTPose
for human pose estimation. It employs a CNN - BiLSTM network to analyse spatial
and temporal information within keypoints sequences, enabling the accurate
classification of violent behaviour in real time. Seamlessly integrated within
the SAFE (Situational Awareness for Enhanced Security framework of SAAB, the
solution underwent integrated testing to ensure robust performance in real
world scenarios. The AIRTLab dataset, characterized by its high video quality
and relevance to surveillance scenarios, is utilized in this study to enhance
the model's accuracy and mitigate false positives. As airports face increased
foot traffic in the post pandemic era, implementing AI driven violence
detection systems, such as the one proposed, is paramount for improving
security, expediting response times, and promoting data informed decision
making. The implementation of this framework not only diminishes the
probability of violent events but also assists surveillance teams in
effectively addressing potential threats, ultimately fostering a more secure
and protected aviation sector. Codes are available at:
https://github.com/Asami-1/GDP.
</p></li>
</ul>

<h3>Title: Proof of Deep Learning: Approaches, Challenges, and Future Directions. (arXiv:2308.16730v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2308.16730">http://arxiv.org/abs/2308.16730</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2308.16730]] Proof of Deep Learning: Approaches, Challenges, and Future Directions(http://arxiv.org/abs/2308.16730)</code></li>
<li>Summary: <p>The rise of computational power has led to unprecedented performance gains
for deep learning models. As more data becomes available and model
architectures become more complex, the need for more computational power
increases. On the other hand, since the introduction of Bitcoin as the first
cryptocurrency and the establishment of the concept of blockchain as a
distributed ledger, many variants and approaches have been proposed. However,
many of them have one thing in common, which is the Proof of Work (PoW)
consensus mechanism. PoW is mainly used to support the process of new block
generation. While PoW has proven its robustness, its main drawback is that it
requires a significant amount of processing power to maintain the security and
integrity of the blockchain. This is due to applying brute force to solve a
hashing puzzle. To utilize the computational power available in useful and
meaningful work while keeping the blockchain secure, many techniques have been
proposed, one of which is known as Proof of Deep Learning (PoDL). PoDL is a
consensus mechanism that uses the process of training a deep learning model as
proof of work to add new blocks to the blockchain. In this paper, we survey the
various approaches for PoDL. We discuss the different types of PoDL algorithms,
their advantages and disadvantages, and their potential applications. We also
discuss the challenges of implementing PoDL and future research directions.
</p></li>
</ul>

<h3>Title: IoMT-Blockchain based Secured Remote Patient Monitoring Framework for Neuro-Stimulation Device. (arXiv:2308.16857v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2308.16857">http://arxiv.org/abs/2308.16857</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2308.16857]] IoMT-Blockchain based Secured Remote Patient Monitoring Framework for Neuro-Stimulation Device(http://arxiv.org/abs/2308.16857)</code></li>
<li>Summary: <p>Biomedical Engineering's Internet of Medical Things (IoMT) is helping to
improve the accuracy, dependability, and productivity of electronic equipment
in the healthcare business. Real-time sensory data from patients may be
delivered and subsequently analyzed through rapid development of wearable IoMT
devices, such as neuro-stimulation devices with a range of functions. Data from
the Internet of Things is gathered, analyzed, and stored in a single location.
However, single-point failure, data manipulation, privacy difficulties, and
other challenges might arise as a result of centralization. Due to its
decentralized nature, blockchain (BC) can alleviate these issues. The viability
of establishing a non-invasive remote neurostimulation system employing
IoMT-based transcranial Direct Current Stimulation is investigated in this work
(tDCS). A hardware-based prototype tDCS device has been developed that can be
operated over the internet using an android application. Our suggested
framework addresses the problems of IoMTBC-based systems, meets the criteria of
real-time remote patient monitoring systems, and incorporates literature best
practices in the relevant fields.
</p></li>
</ul>

<h2>security</h2>
<h3>Title: Exposing and Addressing Security Vulnerabilities in Browser Text Input Fields. (arXiv:2308.16321v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2308.16321">http://arxiv.org/abs/2308.16321</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2308.16321]] Exposing and Addressing Security Vulnerabilities in Browser Text Input Fields(http://arxiv.org/abs/2308.16321)</code></li>
<li>Summary: <p>In this work, we perform a comprehensive analysis of the security of text
input fields in web browsers. We find that browsers' coarse-grained permission
model violates two security design principles: least privilege and complete
mediation. We further uncover two vulnerabilities in input fields, including
the alarming discovery of passwords in plaintext within the HTML source code of
the web page. To demonstrate the real-world impact of these vulnerabilities, we
design a proof-of-concept extension, leveraging techniques from static and
dynamic code injection attacks to bypass the web store review process. Our
measurements and case studies reveal that these vulnerabilities are prevalent
across various websites, with sensitive user information, such as passwords,
exposed in the HTML source code of even high-traffic sites like Google and
Cloudflare. We find that a significant percentage (12.5\%) of extensions
possess the necessary permissions to exploit these vulnerabilities and identify
190 extensions that directly access password fields. Finally, we propose two
countermeasures to address these risks: a bolt-on JavaScript package for
immediate adoption by website developers allowing them to protect sensitive
input fields, and a browser-level solution that alerts users when an extension
accesses sensitive input fields. Our research highlights the urgent need for
improved security measures to protect sensitive user information online.
</p></li>
</ul>

<h3>Title: Design Challenges for the Implementation of Smart Homes. (arXiv:2308.16602v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2308.16602">http://arxiv.org/abs/2308.16602</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2308.16602]] Design Challenges for the Implementation of Smart Homes(http://arxiv.org/abs/2308.16602)</code></li>
<li>Summary: <p>Home automation for many years had faced challenges that limit its spreading
around the world. These challenges caused by the high cost of Own such a home,
inflexibility system (cannot be monitored outside the home) and issues to
achieve optimal security. Our main objective is to design and implement a smart
home model that is simple, affordable to the users. The proposed system provide
flexibility to monitor the home, using the reliable cellular network. The user
will be able what is inside the home when he /she is away from home. In
addition to that, our model overcome the issue of the security by providing
different sensors that detects smoke, gas, leakage of water and incases of
burglary. Moreover, a camera will be available in the home to give a full view
for the user when he/she is outside the home. The user will be informed by an
application on his/she phone incase if there is a fire, water leakage and if
someone break into the house. This will give the user a chance to take an
action if such cases happened. Furthermore, the user can monitor the lighting
system of the home, by giving the user a chance to turn the lights on and off
remotely.
</p></li>
</ul>

<h3>Title: Fault Injection on Embedded Neural Networks: Impact of a Single Instruction Skip. (arXiv:2308.16665v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2308.16665">http://arxiv.org/abs/2308.16665</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2308.16665]] Fault Injection on Embedded Neural Networks: Impact of a Single Instruction Skip(http://arxiv.org/abs/2308.16665)</code></li>
<li>Summary: <p>With the large-scale integration and use of neural network models, especially
in critical embedded systems, their security assessment to guarantee their
reliability is becoming an urgent need. More particularly, models deployed in
embedded platforms, such as 32-bit microcontrollers, are physically accessible
by adversaries and therefore vulnerable to hardware disturbances. We present
the first set of experiments on the use of two fault injection means,
electromagnetic and laser injections, applied on neural networks models
embedded on a Cortex M4 32-bit microcontroller platform. Contrary to most of
state-of-the-art works dedicated to the alteration of the internal parameters
or input values, our goal is to simulate and experimentally demonstrate the
impact of a specific fault model that is instruction skip. For that purpose, we
assessed several modification attacks on the control flow of a neural network
inference. We reveal integrity threats by targeting several steps in the
inference program of typical convolutional neural network models, which may be
exploited by an attacker to alter the predictions of the target models with
different adversarial goals.
</p></li>
</ul>

<h3>Title: Towards Low-Barrier Cybersecurity Research and Education for Industrial Control Systems. (arXiv:2308.16769v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2308.16769">http://arxiv.org/abs/2308.16769</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2308.16769]] Towards Low-Barrier Cybersecurity Research and Education for Industrial Control Systems(http://arxiv.org/abs/2308.16769)</code></li>
<li>Summary: <p>The protection of Industrial Control Systems (ICS) that are employed in
public critical infrastructures is of utmost importance due to catastrophic
physical damages cyberattacks may cause. The research community requires
testbeds for validation and comparing various intrusion detection algorithms to
protect ICS. However, there exist high barriers to entry for research and
education in the ICS cybersecurity domain due to expensive hardware, software,
and inherent dangers of manipulating real-world systems. To close the gap,
built upon recently developed 3D high-fidelity simulators, we further showcase
our integrated framework to automatically launch cyberattacks, collect data,
train machine learning models, and evaluate for practical chemical and
manufacturing processes. On our testbed, we validate our proposed intrusion
detection model called Minimal Threshold and Window SVM (MinTWin SVM) that
utilizes unsupervised machine learning via a one-class SVM in combination with
a sliding window and classification threshold. Results show that MinTWin SVM
minimizes false positives and is responsive to physical process anomalies.
Furthermore, we incorporate our framework with ICS cybersecurity education by
using our dataset in an undergraduate machine learning course where students
gain hands-on experience in practicing machine learning theory with a practical
ICS dataset. All of our implementations have been open-sourced.
</p></li>
</ul>

<h2>privacy</h2>
<h3>Title: Privacy-Preserving Medical Image Classification through Deep Learning and Matrix Decomposition. (arXiv:2308.16530v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2308.16530">http://arxiv.org/abs/2308.16530</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2308.16530]] Privacy-Preserving Medical Image Classification through Deep Learning and Matrix Decomposition(http://arxiv.org/abs/2308.16530)</code></li>
<li>Summary: <p>Deep learning (DL)-based solutions have been extensively researched in the
medical domain in recent years, enhancing the efficacy of diagnosis, planning,
and treatment. Since the usage of health-related data is strictly regulated,
processing medical records outside the hospital environment for developing and
using DL models demands robust data protection measures. At the same time, it
can be challenging to guarantee that a DL solution delivers a minimum level of
performance when being trained on secured data, without being specifically
designed for the given task. Our approach uses singular value decomposition
(SVD) and principal component analysis (PCA) to obfuscate the medical images
before employing them in the DL analysis. The capability of DL algorithms to
extract relevant information from secured data is assessed on a task of
angiographic view classification based on obfuscated frames. The security level
is probed by simulated artificial intelligence (AI)-based reconstruction
attacks, considering two threat actors with different prior knowledge of the
targeted data. The degree of privacy is quantitatively measured using
similarity indices. Although a trade-off between privacy and accuracy should be
considered, the proposed technique allows for training the angiographic view
classifier exclusively on secured data with satisfactory performance and with
no computational overhead, model adaptation, or hyperparameter tuning. While
the obfuscated medical image content is well protected against human
perception, the hypothetical reconstruction attack proved that it is also
difficult to recover the complete information of the original frames.
</p></li>
</ul>

<h3>Title: Publishing Wikipedia usage data with strong privacy guarantees. (arXiv:2308.16298v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2308.16298">http://arxiv.org/abs/2308.16298</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2308.16298]] Publishing Wikipedia usage data with strong privacy guarantees(http://arxiv.org/abs/2308.16298)</code></li>
<li>Summary: <p>For almost 20 years, the Wikimedia Foundation has been publishing statistics
about how many people visited each Wikipedia page on each day. This data helps
Wikipedia editors determine where to focus their efforts to improve the online
encyclopedia, and enables academic research. In June 2023, the Wikimedia
Foundation, helped by Tumult Labs, addressed a long-standing request from
Wikipedia editors and academic researchers: it started publishing these
statistics with finer granularity, including the country of origin in the daily
counts of page views. This new data publication uses differential privacy to
provide robust guarantees to people browsing or editing Wikipedia. This paper
describes this data publication: its goals, the process followed from its
inception to its deployment, the algorithms used to produce the data, and the
outcomes of the data release.
</p></li>
</ul>

<h3>Title: A Survey on Privacy in Graph Neural Networks: Attacks, Preservation, and Applications. (arXiv:2308.16375v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2308.16375">http://arxiv.org/abs/2308.16375</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2308.16375]] A Survey on Privacy in Graph Neural Networks: Attacks, Preservation, and Applications(http://arxiv.org/abs/2308.16375)</code></li>
<li>Summary: <p>Graph Neural Networks (GNNs) have gained significant attention owing to their
ability to handle graph-structured data and the improvement in practical
applications. However, many of these models prioritize high utility
performance, such as accuracy, with a lack of privacy consideration, which is a
major concern in modern society where privacy attacks are rampant. To address
this issue, researchers have started to develop privacy-preserving GNNs.
Despite this progress, there is a lack of a comprehensive overview of the
attacks and the techniques for preserving privacy in the graph domain. In this
survey, we aim to address this gap by summarizing the attacks on graph data
according to the targeted information, categorizing the privacy preservation
techniques in GNNs, and reviewing the datasets and applications that could be
used for analyzing/solving privacy issues in GNNs. We also outline potential
directions for future research in order to build better privacy-preserving
GNNs.
</p></li>
</ul>

<h3>Title: Exact and Efficient Bayesian Inference for Privacy Risk Quantification (Extended Version). (arXiv:2308.16700v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2308.16700">http://arxiv.org/abs/2308.16700</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2308.16700]] Exact and Efficient Bayesian Inference for Privacy Risk Quantification (Extended Version)(http://arxiv.org/abs/2308.16700)</code></li>
<li>Summary: <p>Data analysis has high value both for commercial and research purposes.
However, disclosing analysis results may pose severe privacy risk to
individuals. Privug is a method to quantify privacy risks of data analytics
programs by analyzing their source code. The method uses probability
distributions to model attacker knowledge and Bayesian inference to update said
knowledge based on observable outputs. Currently, Privug uses Markov Chain
Monte Carlo (MCMC) to perform inference, which is a flexible but approximate
solution. This paper presents an exact Bayesian inference engine based on
multivariate Gaussian distributions to accurately and efficiently quantify
privacy risks. The inference engine is implemented for a subset of Python
programs that can be modeled as multivariate Gaussian models. We evaluate the
method by analyzing privacy risks in programs to release public statistics. The
evaluation shows that our method accurately and efficiently analyzes privacy
risks, and outperforms existing methods. Furthermore, we demonstrate the use of
our engine to analyze the effect of differential privacy in public statistics.
</p></li>
</ul>

<h2>protect</h2>
<h2>defense</h2>
<h3>Title: Towards Vehicle-to-everything Autonomous Driving: A Survey on Collaborative Perception. (arXiv:2308.16714v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2308.16714">http://arxiv.org/abs/2308.16714</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2308.16714]] Towards Vehicle-to-everything Autonomous Driving: A Survey on Collaborative Perception(http://arxiv.org/abs/2308.16714)</code></li>
<li>Summary: <p>Vehicle-to-everything (V2X) autonomous driving opens up a promising direction
for developing a new generation of intelligent transportation systems.
Collaborative perception (CP) as an essential component to achieve V2X can
overcome the inherent limitations of individual perception, including occlusion
and long-range perception. In this survey, we provide a comprehensive review of
CP methods for V2X scenarios, bringing a profound and in-depth understanding to
the community. Specifically, we first introduce the architecture and workflow
of typical V2X systems, which affords a broader perspective to understand the
entire V2X system and the role of CP within it. Then, we thoroughly summarize
and analyze existing V2X perception datasets and CP methods. Particularly, we
introduce numerous CP methods from various crucial perspectives, including
collaboration stages, roadside sensors placement, latency compensation,
performance-bandwidth trade-off, attack/defense, pose alignment, etc. Moreover,
we conduct extensive experimental analyses to compare and examine current CP
methods, revealing some essential and unexplored insights. Specifically, we
analyze the performance changes of different methods under different
bandwidths, providing a deep insight into the performance-bandwidth trade-off
issue. Also, we examine methods under different LiDAR ranges. To study the
model robustness, we further investigate the effects of various simulated
real-world noises on the performance of different CP methods, covering
communication latency, lossy communication, localization errors, and mixed
noises. In addition, we look into the sim-to-real generalization ability of
existing CP methods. At last, we thoroughly discuss issues and challenges,
highlighting promising directions for future efforts. Our codes for
experimental analysis will be public at
https://github.com/memberRE/Collaborative-Perception.
</p></li>
</ul>

<h2>attack</h2>
<h3>Title: Everyone Can Attack: Repurpose Lossy Compression as a Natural Backdoor Attack. (arXiv:2308.16684v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2308.16684">http://arxiv.org/abs/2308.16684</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2308.16684]] Everyone Can Attack: Repurpose Lossy Compression as a Natural Backdoor Attack(http://arxiv.org/abs/2308.16684)</code></li>
<li>Summary: <p>The vulnerabilities to backdoor attacks have recently threatened the
trustworthiness of machine learning models in practical applications.
Conventional wisdom suggests that not everyone can be an attacker since the
process of designing the trigger generation algorithm often involves
significant effort and extensive experimentation to ensure the attack's
stealthiness and effectiveness. Alternatively, this paper shows that there
exists a more severe backdoor threat: anyone can exploit an easily-accessible
algorithm for silent backdoor attacks. Specifically, this attacker can employ
the widely-used lossy image compression from a plethora of compression tools to
effortlessly inject a trigger pattern into an image without leaving any
noticeable trace; i.e., the generated triggers are natural artifacts. One does
not require extensive knowledge to click on the "convert" or "save as" button
while using tools for lossy image compression. Via this attack, the adversary
does not need to design a trigger generator as seen in prior works and only
requires poisoning the data. Empirically, the proposed attack consistently
achieves 100% attack success rate in several benchmark datasets such as MNIST,
CIFAR-10, GTSRB and CelebA. More significantly, the proposed attack can still
achieve almost 100% attack success rate with very small (approximately 10%)
poisoning rates in the clean label setting. The generated trigger of the
proposed attack using one lossy compression algorithm is also transferable
across other related compression algorithms, exacerbating the severity of this
backdoor threat. This work takes another crucial step toward understanding the
extensive risks of backdoor attacks in practice, urging practitioners to
investigate similar attacks and relevant backdoor mitigation methods.
</p></li>
</ul>

<h3>Title: The Power of MEME: Adversarial Malware Creation with Model-Based Reinforcement Learning. (arXiv:2308.16562v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2308.16562">http://arxiv.org/abs/2308.16562</a></li>
<li>Code URL: https://github.com/stratosphereips/meme_malware_rl</li>
<li>Copy Paste: <code><input type="checkbox">[[2308.16562]] The Power of MEME: Adversarial Malware Creation with Model-Based Reinforcement Learning(http://arxiv.org/abs/2308.16562)</code></li>
<li>Summary: <p>Due to the proliferation of malware, defenders are increasingly turning to
automation and machine learning as part of the malware detection tool-chain.
However, machine learning models are susceptible to adversarial attacks,
requiring the testing of model and product robustness. Meanwhile, attackers
also seek to automate malware generation and evasion of antivirus systems, and
defenders try to gain insight into their methods. This work proposes a new
algorithm that combines Malware Evasion and Model Extraction (MEME) attacks.
MEME uses model-based reinforcement learning to adversarially modify Windows
executable binary samples while simultaneously training a surrogate model with
a high agreement with the target model to evade. To evaluate this method, we
compare it with two state-of-the-art attacks in adversarial malware creation,
using three well-known published models and one antivirus product as targets.
Results show that MEME outperforms the state-of-the-art methods in terms of
evasion capabilities in almost all cases, producing evasive malware with an
evasion rate in the range of 32-73%. It also produces surrogate models with a
prediction label agreement with the respective target models between 97-99%.
The surrogate could be used to fine-tune and improve the evasion rate in the
future.
</p></li>
</ul>

<h3>Title: MONDEO: Multistage Botnet Detection. (arXiv:2308.16570v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2308.16570">http://arxiv.org/abs/2308.16570</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2308.16570]] MONDEO: Multistage Botnet Detection(http://arxiv.org/abs/2308.16570)</code></li>
<li>Summary: <p>Mobile devices have widespread to become the most used piece of technology.
Due to their characteristics, they have become major targets for botnet-related
malware. FluBot is one example of botnet malware that infects mobile devices.
In particular, FluBot is a DNS-based botnet that uses Domain Generation
Algorithms (DGA) to establish communication with the Command and Control Server
(C2). MONDEO is a multistage mechanism with a flexible design to detect
DNS-based botnet malware. MONDEO is lightweight and can be deployed without
requiring the deployment of software, agents, or configuration in mobile
devices, allowing easy integration in core networks. MONDEO comprises four
detection stages: Blacklisting/Whitelisting, Query rate analysis, DGA analysis,
and Machine learning evaluation. It was created with the goal of processing
streams of packets to identify attacks with high efficiency, in the distinct
phases. MONDEO was tested against several datasets to measure its efficiency
and performance, being able to achieve high performance with RandomForest
classifiers. The implementation is available at github.
</p></li>
</ul>

<h3>Title: Fault Injection and Safe-Error Attack for Extraction of Embedded Neural Network Models. (arXiv:2308.16703v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2308.16703">http://arxiv.org/abs/2308.16703</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2308.16703]] Fault Injection and Safe-Error Attack for Extraction of Embedded Neural Network Models(http://arxiv.org/abs/2308.16703)</code></li>
<li>Summary: <p>Model extraction emerges as a critical security threat with attack vectors
exploiting both algorithmic and implementation-based approaches. The main goal
of an attacker is to steal as much information as possible about a protected
victim model, so that he can mimic it with a substitute model, even with a
limited access to similar training data. Recently, physical attacks such as
fault injection have shown worrying efficiency against the integrity and
confidentiality of embedded models. We focus on embedded deep neural network
models on 32-bit microcontrollers, a widespread family of hardware platforms in
IoT, and the use of a standard fault injection strategy - Safe Error Attack
(SEA) - to perform a model extraction attack with an adversary having a limited
access to training data. Since the attack strongly depends on the input
queries, we propose a black-box approach to craft a successful attack set. For
a classical convolutional neural network, we successfully recover at least 90%
of the most significant bits with about 1500 crafted inputs. These information
enable to efficiently train a substitute model, with only 8% of the training
dataset, that reaches high fidelity and near identical accuracy level than the
victim model.
</p></li>
</ul>

<h2>robust</h2>
<h3>Title: Active Neural Mapping. (arXiv:2308.16246v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2308.16246">http://arxiv.org/abs/2308.16246</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2308.16246]] Active Neural Mapping(http://arxiv.org/abs/2308.16246)</code></li>
<li>Summary: <p>We address the problem of active mapping with a continually-learned neural
scene representation, namely Active Neural Mapping. The key lies in actively
finding the target space to be explored with efficient agent movement, thus
minimizing the map uncertainty on-the-fly within a previously unseen
environment. In this paper, we examine the weight space of the
continually-learned neural field, and show empirically that the neural
variability, the prediction robustness against random weight perturbation, can
be directly utilized to measure the instant uncertainty of the neural map.
Together with the continuous geometric information inherited in the neural map,
the agent can be guided to find a traversable path to gradually gain knowledge
of the environment. We present for the first time an active mapping system with
a coordinate-based implicit neural representation for online scene
reconstruction. Experiments in the visually-realistic Gibson and Matterport3D
environment demonstrate the efficacy of the proposed method.
</p></li>
</ul>

<h3>Title: Robust Principles: Architectural Design Principles for Adversarially Robust CNNs. (arXiv:2308.16258v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2308.16258">http://arxiv.org/abs/2308.16258</a></li>
<li>Code URL: https://github.com/poloclub/robust-principles</li>
<li>Copy Paste: <code><input type="checkbox">[[2308.16258]] Robust Principles: Architectural Design Principles for Adversarially Robust CNNs(http://arxiv.org/abs/2308.16258)</code></li>
<li>Summary: <p>Our research aims to unify existing works' diverging opinions on how
architectural components affect the adversarial robustness of CNNs. To
accomplish our goal, we synthesize a suite of three generalizable robust
architectural design principles: (a) optimal range for depth and width
configurations, (b) preferring convolutional over patchify stem stage, and (c)
robust residual block design through adopting squeeze and excitation blocks and
non-parametric smooth activation functions. Through extensive experiments
across a wide spectrum of dataset scales, adversarial training methods, model
parameters, and network design spaces, our principles consistently and markedly
improve AutoAttack accuracy: 1-3 percentage points (pp) on CIFAR-10 and
CIFAR-100, and 4-9 pp on ImageNet. The code is publicly available at
https://github.com/poloclub/robust-principles.
</p></li>
</ul>

<h3>Title: 3D vision-based structural masonry damage detection. (arXiv:2308.16380v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2308.16380">http://arxiv.org/abs/2308.16380</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2308.16380]] 3D vision-based structural masonry damage detection(http://arxiv.org/abs/2308.16380)</code></li>
<li>Summary: <p>The detection of masonry damage is essential for preventing potentially
disastrous outcomes. Manual inspection can, however, take a long time and be
hazardous to human inspectors. Automation of the inspection process using novel
computer vision and machine learning algorithms can be a more efficient and
safe solution to prevent further deterioration of the masonry structures. Most
existing 2D vision-based methods are limited to qualitative damage
classification, 2D localization, and in-plane quantification. In this study, we
present a 3D vision-based methodology for accurate masonry damage detection,
which offers a more robust solution with a greater field of view, depth of
vision, and the ability to detect failures in complex environments. First,
images of the masonry specimens are collected to generate a 3D point cloud.
Second, 3D point clouds processing methods are developed to evaluate the
masonry damage. We demonstrate the effectiveness of our approach through
experiments on structural masonry components. Our experiments showed the
proposed system can effectively classify damage states and localize and
quantify critical damage features. The result showed the proposed method can
improve the level of autonomy during the inspection of masonry structures.
</p></li>
</ul>

<h3>Title: Deformation Robust Text Spotting with Geometric Prior. (arXiv:2308.16404v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2308.16404">http://arxiv.org/abs/2308.16404</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2308.16404]] Deformation Robust Text Spotting with Geometric Prior(http://arxiv.org/abs/2308.16404)</code></li>
<li>Summary: <p>The goal of text spotting is to perform text detection and recognition in an
end-to-end manner. Although the diversity of luminosity and orientation in
scene texts has been widely studied, the font diversity and shape variance of
the same character are ignored in recent works, since most characters in
natural images are rendered in standard fonts. To solve this problem, we
present a Chinese Artistic Dataset, termed as ARText, which contains 33,000
artistic images with rich shape deformation and font diversity. Based on this
database, we develop a deformation robust text spotting method (DR TextSpotter)
to solve the recognition problem of complex deformation of characters in
different fonts. Specifically, we propose a geometric prior module to highlight
the important features based on the unsupervised landmark detection
sub-network. A graph convolution network is further constructed to fuse the
character features and landmark features, and then performs semantic reasoning
to enhance the discrimination for different characters. The experiments are
conducted on ARText and IC19-ReCTS datasets. Our results demonstrate the
effectiveness of our proposed method.
</p></li>
</ul>

<h3>Title: Adversarial Finetuning with Latent Representation Constraint to Mitigate Accuracy-Robustness Tradeoff. (arXiv:2308.16454v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2308.16454">http://arxiv.org/abs/2308.16454</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2308.16454]] Adversarial Finetuning with Latent Representation Constraint to Mitigate Accuracy-Robustness Tradeoff(http://arxiv.org/abs/2308.16454)</code></li>
<li>Summary: <p>This paper addresses the tradeoff between standard accuracy on clean examples
and robustness against adversarial examples in deep neural networks (DNNs).
Although adversarial training (AT) improves robustness, it degrades the
standard accuracy, thus yielding the tradeoff. To mitigate this tradeoff, we
propose a novel AT method called ARREST, which comprises three components: (i)
adversarial finetuning (AFT), (ii) representation-guided knowledge distillation
(RGKD), and (iii) noisy replay (NR). AFT trains a DNN on adversarial examples
by initializing its parameters with a DNN that is standardly pretrained on
clean examples. RGKD and NR respectively entail a regularization term and an
algorithm to preserve latent representations of clean examples during AFT. RGKD
penalizes the distance between the representations of the standardly pretrained
and AFT DNNs. NR switches input adversarial examples to nonadversarial ones
when the representation changes significantly during AFT. By combining these
components, ARREST achieves both high standard accuracy and robustness.
Experimental results demonstrate that ARREST mitigates the tradeoff more
effectively than previous AT-based methods do.
</p></li>
</ul>

<h3>Title: Robust GAN inversion. (arXiv:2308.16510v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2308.16510">http://arxiv.org/abs/2308.16510</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2308.16510]] Robust GAN inversion(http://arxiv.org/abs/2308.16510)</code></li>
<li>Summary: <p>Recent advancements in real image editing have been attributed to the
exploration of Generative Adversarial Networks (GANs) latent space. However,
the main challenge of this procedure is GAN inversion, which aims to map the
image to the latent space accurately. Existing methods that work on extended
latent space $W+$ are unable to achieve low distortion and high editability
simultaneously. To address this issue, we propose an approach which works in
native latent space $W$ and tunes the generator network to restore missing
image details. We introduce a novel regularization strategy with learnable
coefficients obtained by training randomized StyleGAN 2 model - WRanGAN. This
method outperforms traditional approaches in terms of reconstruction quality
and computational efficiency, achieving the lowest distortion with 4 times
fewer parameters. Furthermore, we observe a slight improvement in the quality
of constructing hyperplanes corresponding to binary image attributes. We
demonstrate the effectiveness of our approach on two complex datasets:
Flickr-Faces-HQ and LSUN Church.
</p></li>
</ul>

<h3>Title: E3CM: Epipolar-Constrained Cascade Correspondence Matching. (arXiv:2308.16555v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2308.16555">http://arxiv.org/abs/2308.16555</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2308.16555]] E3CM: Epipolar-Constrained Cascade Correspondence Matching(http://arxiv.org/abs/2308.16555)</code></li>
<li>Summary: <p>Accurate and robust correspondence matching is of utmost importance for
various 3D computer vision tasks. However, traditional explicit
programming-based methods often struggle to handle challenging scenarios, and
deep learning-based methods require large well-labeled datasets for network
training. In this article, we introduce Epipolar-Constrained Cascade
Correspondence (E3CM), a novel approach that addresses these limitations.
Unlike traditional methods, E3CM leverages pre-trained convolutional neural
networks to match correspondence, without requiring annotated data for any
network training or fine-tuning. Our method utilizes epipolar constraints to
guide the matching process and incorporates a cascade structure for progressive
refinement of matches. We extensively evaluate the performance of E3CM through
comprehensive experiments and demonstrate its superiority over existing
methods. To promote further research and facilitate reproducibility, we make
our source code publicly available at https://mias.group/E3CM.
</p></li>
</ul>

<h3>Title: CL-MAE: Curriculum-Learned Masked Autoencoders. (arXiv:2308.16572v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2308.16572">http://arxiv.org/abs/2308.16572</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2308.16572]] CL-MAE: Curriculum-Learned Masked Autoencoders(http://arxiv.org/abs/2308.16572)</code></li>
<li>Summary: <p>Masked image modeling has been demonstrated as a powerful pretext task for
generating robust representations that can be effectively generalized across
multiple downstream tasks. Typically, this approach involves randomly masking
patches (tokens) in input images, with the masking strategy remaining unchanged
during training. In this paper, we propose a curriculum learning approach that
updates the masking strategy to continually increase the complexity of the
self-supervised reconstruction task. We conjecture that, by gradually
increasing the task complexity, the model can learn more sophisticated and
transferable representations. To facilitate this, we introduce a novel
learnable masking module that possesses the capability to generate masks of
different complexities, and integrate the proposed module into masked
autoencoders (MAE). Our module is jointly trained with the MAE, while adjusting
its behavior during training, transitioning from a partner to the MAE
(optimizing the same reconstruction loss) to an adversary (optimizing the
opposite loss), while passing through a neutral state. The transition between
these behaviors is smooth, being regulated by a factor that is multiplied with
the reconstruction loss of the masking module. The resulting training procedure
generates an easy-to-hard curriculum. We train our Curriculum-Learned Masked
Autoencoder (CL-MAE) on ImageNet and show that it exhibits superior
representation learning capabilities compared to MAE. The empirical results on
five downstream tasks confirm our conjecture, demonstrating that curriculum
learning can be successfully used to self-supervise masked autoencoders.
</p></li>
</ul>

<h3>Title: ViLTA: Enhancing Vision-Language Pre-training through Textual Augmentation. (arXiv:2308.16689v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2308.16689">http://arxiv.org/abs/2308.16689</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2308.16689]] ViLTA: Enhancing Vision-Language Pre-training through Textual Augmentation(http://arxiv.org/abs/2308.16689)</code></li>
<li>Summary: <p>Vision-language pre-training (VLP) methods are blossoming recently, and its
crucial goal is to jointly learn visual and textual features via a
transformer-based architecture, demonstrating promising improvements on a
variety of vision-language tasks. Prior arts usually focus on how to align
visual and textual features, but strategies for improving the robustness of
model and speeding up model convergence are left insufficiently explored.
</p>
<p>In this paper, we propose a novel method ViLTA, comprising of two components
to further facilitate the model to learn fine-grained representations among
image-text pairs. For Masked Language Modeling (MLM), we propose a
cross-distillation method to generate soft labels to enhance the robustness of
model, which alleviates the problem of treating synonyms of masked words as
negative samples in one-hot labels. For Image-Text Matching (ITM), we leverage
the current language encoder to synthesize hard negatives based on the context
of language input, encouraging the model to learn high-quality representations
by increasing the difficulty of the ITM task. By leveraging the above
techniques, our ViLTA can achieve better performance on various vision-language
tasks. Extensive experiments on benchmark datasets demonstrate that the
effectiveness of ViLTA and its promising potential for vision-language
pre-training.
</p></li>
</ul>

<h3>Title: Fine-Grained Cross-View Geo-Localization Using a Correlation-Aware Homography Estimator. (arXiv:2308.16906v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2308.16906">http://arxiv.org/abs/2308.16906</a></li>
<li>Code URL: https://github.com/xlwangdev/hc-net</li>
<li>Copy Paste: <code><input type="checkbox">[[2308.16906]] Fine-Grained Cross-View Geo-Localization Using a Correlation-Aware Homography Estimator(http://arxiv.org/abs/2308.16906)</code></li>
<li>Summary: <p>In this paper, we introduce a novel approach to fine-grained cross-view
geo-localization. Our method aligns a warped ground image with a corresponding
GPS-tagged satellite image covering the same area using homography estimation.
We first employ a differentiable spherical transform, adhering to geometric
principles, to accurately align the perspective of the ground image with the
satellite map. This transformation effectively places ground and aerial images
in the same view and on the same plane, reducing the task to an image alignment
problem. To address challenges such as occlusion, small overlapping range, and
seasonal variations, we propose a robust correlation-aware homography estimator
to align similar parts of the transformed ground image with the satellite
image. Our method achieves sub-pixel resolution and meter-level GPS accuracy by
mapping the center point of the transformed ground image to the satellite image
using a homography matrix and determining the orientation of the ground camera
using a point above the central axis. Operating at a speed of 30 FPS, our
method outperforms state-of-the-art techniques, reducing the mean metric
localization error by 21.3% and 32.4% in same-area and cross-area
generalization tasks on the VIGOR benchmark, respectively, and by 34.4% on the
KITTI benchmark in same-area evaluation.
</p></li>
</ul>

<h3>Title: ToddlerBERTa: Exploiting BabyBERTa for Grammar Learning and Language Understanding. (arXiv:2308.16336v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2308.16336">http://arxiv.org/abs/2308.16336</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2308.16336]] ToddlerBERTa: Exploiting BabyBERTa for Grammar Learning and Language Understanding(http://arxiv.org/abs/2308.16336)</code></li>
<li>Summary: <p>We present ToddlerBERTa, a BabyBERTa-like language model, exploring its
capabilities through five different models with varied hyperparameters.
Evaluating on BLiMP, SuperGLUE, MSGS, and a Supplement benchmark from the
BabyLM challenge, we find that smaller models can excel in specific tasks,
while larger models perform well with substantial data. Despite training on a
smaller dataset, ToddlerBERTa demonstrates commendable performance, rivalling
the state-of-the-art RoBERTa-base. The model showcases robust language
understanding, even with single-sentence pretraining, and competes with
baselines that leverage broader contextual information. Our work provides
insights into hyperparameter choices, and data utilization, contributing to the
advancement of language models.
</p></li>
</ul>

<h3>Title: Towards Multilingual Automatic Dialogue Evaluation. (arXiv:2308.16795v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2308.16795">http://arxiv.org/abs/2308.16795</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2308.16795]] Towards Multilingual Automatic Dialogue Evaluation(http://arxiv.org/abs/2308.16795)</code></li>
<li>Summary: <p>The main limiting factor in the development of robust multilingual dialogue
evaluation metrics is the lack of multilingual data and the limited
availability of open sourced multilingual dialogue systems. In this work, we
propose a workaround for this lack of data by leveraging a strong multilingual
pretrained LLM and augmenting existing English dialogue data using Machine
Translation. We empirically show that the naive approach of finetuning a
pretrained multilingual encoder model with translated data is insufficient to
outperform the strong baseline of finetuning a multilingual model with only
source data. Instead, the best approach consists in the careful curation of
translated data using MT Quality Estimation metrics, excluding low quality
translations that hinder its performance.
</p></li>
</ul>

<h3>Title: Simple LLM Prompting is State-of-the-Art for Robust and Multilingual Dialogue Evaluation. (arXiv:2308.16797v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2308.16797">http://arxiv.org/abs/2308.16797</a></li>
<li>Code URL: https://github.com/johndmendonca/dialevalml</li>
<li>Copy Paste: <code><input type="checkbox">[[2308.16797]] Simple LLM Prompting is State-of-the-Art for Robust and Multilingual Dialogue Evaluation(http://arxiv.org/abs/2308.16797)</code></li>
<li>Summary: <p>Despite significant research effort in the development of automatic dialogue
evaluation metrics, little thought is given to evaluating dialogues other than
in English. At the same time, ensuring metrics are invariant to semantically
similar responses is also an overlooked topic. In order to achieve the desired
properties of robustness and multilinguality for dialogue evaluation metrics,
we propose a novel framework that takes advantage of the strengths of current
evaluation models with the newly-established paradigm of prompting Large
Language Models (LLMs). Empirical results show our framework achieves state of
the art results in terms of mean Spearman correlation scores across several
benchmarks and ranks first place on both the Robust and Multilingual tasks of
the DSTC11 Track 4 "Automatic Evaluation Metrics for Open-Domain Dialogue
Systems", proving the evaluation capabilities of prompted LLMs.
</p></li>
</ul>

<h3>Title: Improving Robustness and Accuracy of Ponzi Scheme Detection on Ethereum Using Time-Dependent Features. (arXiv:2308.16391v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2308.16391">http://arxiv.org/abs/2308.16391</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2308.16391]] Improving Robustness and Accuracy of Ponzi Scheme Detection on Ethereum Using Time-Dependent Features(http://arxiv.org/abs/2308.16391)</code></li>
<li>Summary: <p>The rapid development of blockchain has led to more and more funding pouring
into the cryptocurrency market, which also attracted cybercriminals' interest
in recent years. The Ponzi scheme, an old-fashioned fraud, is now popular on
the blockchain, causing considerable financial losses to many crypto-investors.
A few Ponzi detection methods have been proposed in the literature, most of
which detect a Ponzi scheme based on its smart contract source code or opcode.
The contract-code-based approach, while achieving very high accuracy, is not
robust: first, the source codes of a majority of contracts on Ethereum are not
available, and second, a Ponzi developer can fool a contract-code-based
detection model by obfuscating the opcode or inventing a new profit
distribution logic that cannot be detected (since these models were trained on
existing Ponzi logics only). A transaction-based approach could improve the
robustness of detection because transactions, unlike smart contracts, are
harder to be manipulated. However, the current transaction-based detection
models achieve fairly low accuracy. We address this gap in the literature by
developing new detection models that rely only on the transactions, hence
guaranteeing the robustness, and moreover, achieve considerably higher
Accuracy, Precision, Recall, and F1-score than existing transaction-based
models. This is made possible thanks to the introduction of novel
time-dependent features that capture Ponzi behaviours characteristics derived
from our comprehensive data analyses on Ponzi and non-Ponzi data from the
XBlock-ETH repository
</p></li>
</ul>

<h3>Title: Listen to Minority: Encrypted Traffic Classification for Class Imbalance with Contrastive Pre-Training. (arXiv:2308.16453v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2308.16453">http://arxiv.org/abs/2308.16453</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2308.16453]] Listen to Minority: Encrypted Traffic Classification for Class Imbalance with Contrastive Pre-Training(http://arxiv.org/abs/2308.16453)</code></li>
<li>Summary: <p>Mobile Internet has profoundly reshaped modern lifestyles in various aspects.
Encrypted Traffic Classification (ETC) naturally plays a crucial role in
managing mobile Internet, especially with the explosive growth of mobile apps
using encrypted communication. Despite some existing learning-based ETC methods
showing promising results, three-fold limitations still remain in real-world
network environments, 1) label bias caused by traffic class imbalance, 2)
traffic homogeneity caused by component sharing, and 3) training with reliance
on sufficient labeled traffic. None of the existing ETC methods can address all
these limitations. In this paper, we propose a novel Pre-trAining
Semi-Supervised ETC framework, dubbed PASS. Our key insight is to resample the
original train dataset and perform contrastive pre-training without using
individual app labels directly to avoid label bias issues caused by class
imbalance, while obtaining a robust feature representation to differentiate
overlapping homogeneous traffic by pulling positive traffic pairs closer and
pushing negative pairs away. Meanwhile, PASS designs a semi-supervised
optimization strategy based on pseudo-label iteration and dynamic loss
weighting algorithms in order to effectively utilize massive unlabeled traffic
data and alleviate manual train dataset annotation workload. PASS outperforms
state-of-the-art ETC methods and generic sampling approaches on four public
datasets with significant class imbalance and traffic homogeneity, remarkably
pushing the F1 of Cross-Platform215 with 1.31%, ISCX-17 with 9.12%.
Furthermore, we validate the generality of the contrastive pre-training and
pseudo-label iteration components of PASS, which can adaptively benefit ETC
methods with diverse feature extractors.
</p></li>
</ul>

<h3>Title: Facing Unknown: Open-World Encrypted Traffic Classification Based on Contrastive Pre-Training. (arXiv:2308.16861v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2308.16861">http://arxiv.org/abs/2308.16861</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2308.16861]] Facing Unknown: Open-World Encrypted Traffic Classification Based on Contrastive Pre-Training(http://arxiv.org/abs/2308.16861)</code></li>
<li>Summary: <p>Traditional Encrypted Traffic Classification (ETC) methods face a significant
challenge in classifying large volumes of encrypted traffic in the open-world
assumption, i.e., simultaneously classifying the known applications and
detecting unknown applications. We propose a novel Open-World Contrastive
Pre-training (OWCP) framework for this. OWCP performs contrastive pre-training
to obtain a robust feature representation. Based on this, we determine the
spherical mapping space to find the marginal flows for each known class, which
are used to train GANs to synthesize new flows similar to the known parts but
do not belong to any class. These synthetic flows are assigned to Softmax's
unknown node to modify the classifier, effectively enhancing sensitivity
towards known flows and significantly suppressing unknown ones. Extensive
experiments on three datasets show that OWCP significantly outperforms existing
ETC and generic open-world classification methods. Furthermore, we conduct
comprehensive ablation studies and sensitivity analyses to validate each
integral component of OWCP.
</p></li>
</ul>

<h3>Title: Calibrated Explanations for Regression. (arXiv:2308.16245v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2308.16245">http://arxiv.org/abs/2308.16245</a></li>
<li>Code URL: https://github.com/moffran/calibrated_explanations</li>
<li>Copy Paste: <code><input type="checkbox">[[2308.16245]] Calibrated Explanations for Regression(http://arxiv.org/abs/2308.16245)</code></li>
<li>Summary: <p>Artificial Intelligence (AI) is often an integral part of modern decision
support systems (DSSs). The best-performing predictive models used in AI-based
DSSs lack transparency. Explainable Artificial Intelligence (XAI) aims to
create AI systems that can explain their rationale to human users. Local
explanations in XAI can provide information about the causes of individual
predictions in terms of feature importance. However, a critical drawback of
existing local explanation methods is their inability to quantify the
uncertainty associated with a feature's importance. This paper introduces an
extension of a feature importance explanation method, Calibrated Explanations
(CE), previously only supporting classification, with support for standard
regression and probabilistic regression, i.e., the probability that the target
is above an arbitrary threshold. The extension for regression keeps all the
benefits of CE, such as calibration of the prediction from the underlying model
with confidence intervals, uncertainty quantification of feature importance,
and allows both factual and counterfactual explanations. CE for standard
regression provides fast, reliable, stable, and robust explanations. CE for
probabilistic regression provides an entirely new way of creating probabilistic
explanations from any ordinary regression model and with a dynamic selection of
thresholds. The performance of CE for probabilistic regression regarding
stability and speed is comparable to LIME. The method is model agnostic with
easily understood conditional rules. An implementation in Python is freely
available on GitHub and for installation using pip making the results in this
paper easily replicable.
</p></li>
</ul>

<h3>Title: Robust Representation Learning for Unreliable Partial Label Learning. (arXiv:2308.16718v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2308.16718">http://arxiv.org/abs/2308.16718</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2308.16718]] Robust Representation Learning for Unreliable Partial Label Learning(http://arxiv.org/abs/2308.16718)</code></li>
<li>Summary: <p>Partial Label Learning (PLL) is a type of weakly supervised learning where
each training instance is assigned a set of candidate labels, but only one
label is the ground-truth. However, this idealistic assumption may not always
hold due to potential annotation inaccuracies, meaning the ground-truth may not
be present in the candidate label set. This is known as Unreliable Partial
Label Learning (UPLL) that introduces an additional complexity due to the
inherent unreliability and ambiguity of partial labels, often resulting in a
sub-optimal performance with existing methods. To address this challenge, we
propose the Unreliability-Robust Representation Learning framework (URRL) that
leverages unreliability-robust contrastive learning to help the model fortify
against unreliable partial labels effectively. Concurrently, we propose a dual
strategy that combines KNN-based candidate label set correction and
consistency-regularization-based label disambiguation to refine label quality
and enhance the ability of representation learning within the URRL framework.
Extensive experiments demonstrate that the proposed method outperforms
state-of-the-art PLL methods on various datasets with diverse degrees of
unreliability and ambiguity. Furthermore, we provide a theoretical analysis of
our approach from the perspective of the expectation maximization (EM)
algorithm. Upon acceptance, we pledge to make the code publicly accessible.
</p></li>
</ul>

<h3>Title: Robust Networked Federated Learning for Localization. (arXiv:2308.16737v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2308.16737">http://arxiv.org/abs/2308.16737</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2308.16737]] Robust Networked Federated Learning for Localization(http://arxiv.org/abs/2308.16737)</code></li>
<li>Summary: <p>This paper addresses the problem of localization, which is inherently
non-convex and non-smooth in a federated setting where the data is distributed
across a multitude of devices. Due to the decentralized nature of federated
environments, distributed learning becomes essential for scalability and
adaptability. Moreover, these environments are often plagued by outlier data,
which presents substantial challenges to conventional methods, particularly in
maintaining estimation accuracy and ensuring algorithm convergence. To mitigate
these challenges, we propose a method that adopts an $L_1$-norm robust
formulation within a distributed sub-gradient framework, explicitly designed to
handle these obstacles. Our approach addresses the problem in its original
form, without resorting to iterative simplifications or approximations,
resulting in enhanced computational efficiency and improved estimation
accuracy. We demonstrate that our method converges to a stationary point,
highlighting its effectiveness and reliability. Through numerical simulations,
we confirm the superior performance of our approach, notably in outlier-rich
environments, which surpasses existing state-of-the-art localization methods.
</p></li>
</ul>

<h2>biometric</h2>
<h2>steal</h2>
<h2>extraction</h2>
<h3>Title: Document Layout Analysis on BaDLAD Dataset: A Comprehensive MViTv2 Based Approach. (arXiv:2308.16571v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2308.16571">http://arxiv.org/abs/2308.16571</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2308.16571]] Document Layout Analysis on BaDLAD Dataset: A Comprehensive MViTv2 Based Approach(http://arxiv.org/abs/2308.16571)</code></li>
<li>Summary: <p>In the rapidly evolving digital era, the analysis of document layouts plays a
pivotal role in automated information extraction and interpretation. In our
work, we have trained MViTv2 transformer model architecture with cascaded mask
R-CNN on BaDLAD dataset to extract text box, paragraphs, images and tables from
a document. After training on 20365 document images for 36 epochs in a 3 phase
cycle, we achieved a training loss of 0.2125 and a mask loss of 0.19. Our work
extends beyond training, delving into the exploration of potential enhancement
avenues. We investigate the impact of rotation and flip augmentation, the
effectiveness of slicing input images pre-inference, the implications of
varying the resolution of the transformer backbone, and the potential of
employing a dual-pass inference to uncover missed text-boxes. Through these
explorations, we observe a spectrum of outcomes, where some modifications
result in tangible performance improvements, while others offer unique insights
for future endeavors.
</p></li>
</ul>

<h3>Title: Enhancing PLM Performance on Labour Market Tasks via Instruction-based Finetuning and Prompt-tuning with Rules. (arXiv:2308.16770v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2308.16770">http://arxiv.org/abs/2308.16770</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2308.16770]] Enhancing PLM Performance on Labour Market Tasks via Instruction-based Finetuning and Prompt-tuning with Rules(http://arxiv.org/abs/2308.16770)</code></li>
<li>Summary: <p>The increased digitization of the labour market has given researchers,
educators, and companies the means to analyze and better understand the labour
market. However, labour market resources, although available in high volumes,
tend to be unstructured, and as such, research towards methodologies for the
identification, linking, and extraction of entities becomes more and more
important. Against the backdrop of this quest for better labour market
representations, resource constraints and the unavailability of large-scale
annotated data cause a reliance on human domain experts. We demonstrate the
effectiveness of prompt-based tuning of pre-trained language models (PLM) in
labour market specific applications. Our results indicate that cost-efficient
methods such as PTR and instruction tuning without exemplars can significantly
increase the performance of PLMs on downstream labour market applications
without introducing additional model layers, manual annotations, and data
augmentation.
</p></li>
</ul>

<h2>membership infer</h2>
<h2>federate</h2>
<h3>Title: Post-Deployment Adaptation with Access to Source Data via Federated Learning and Source-Target Remote Gradient Alignment. (arXiv:2308.16735v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2308.16735">http://arxiv.org/abs/2308.16735</a></li>
<li>Code URL: https://github.com/felixwag/staralign</li>
<li>Copy Paste: <code><input type="checkbox">[[2308.16735]] Post-Deployment Adaptation with Access to Source Data via Federated Learning and Source-Target Remote Gradient Alignment(http://arxiv.org/abs/2308.16735)</code></li>
<li>Summary: <p>Deployment of Deep Neural Networks in medical imaging is hindered by
distribution shift between training data and data processed after deployment,
causing performance degradation. Post-Deployment Adaptation (PDA) addresses
this by tailoring a pre-trained, deployed model to the target data distribution
using limited labelled or entirely unlabelled target data, while assuming no
access to source training data as they cannot be deployed with the model due to
privacy concerns and their large size. This makes reliable adaptation
challenging due to limited learning signal. This paper challenges this
assumption and introduces FedPDA, a novel adaptation framework that brings the
utility of learning from remote data from Federated Learning into PDA. FedPDA
enables a deployed model to obtain information from source data via remote
gradient exchange, while aiming to optimize the model specifically for the
target domain. Tailored for FedPDA, we introduce a novel optimization method
StarAlign (Source-Target Remote Gradient Alignment) that aligns gradients
between source-target domain pairs by maximizing their inner product, to
facilitate learning a target-specific model. We demonstrate the method's
effectiveness using multi-center databases for the tasks of cancer metastases
detection and skin lesion classification, where our method compares favourably
to previous work. Code is available at: https://github.com/FelixWag/StarAlign
</p></li>
</ul>

<h3>Title: Communication-Efficient Decentralized Federated Learning via One-Bit Compressive Sensing. (arXiv:2308.16671v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2308.16671">http://arxiv.org/abs/2308.16671</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2308.16671]] Communication-Efficient Decentralized Federated Learning via One-Bit Compressive Sensing(http://arxiv.org/abs/2308.16671)</code></li>
<li>Summary: <p>Decentralized federated learning (DFL) has gained popularity due to its
practicality across various applications. Compared to the centralized version,
training a shared model among a large number of nodes in DFL is more
challenging, as there is no central server to coordinate the training process.
Especially when distributed nodes suffer from limitations in communication or
computational resources, DFL will experience extremely inefficient and unstable
training. Motivated by these challenges, in this paper, we develop a novel
algorithm based on the framework of the inexact alternating direction method
(iADM). On one hand, our goal is to train a shared model with a sparsity
constraint. This constraint enables us to leverage one-bit compressive sensing
(1BCS), allowing transmission of one-bit information among neighbour nodes. On
the other hand, communication between neighbour nodes occurs only at certain
steps, reducing the number of communication rounds. Therefore, the algorithm
exhibits notable communication efficiency. Additionally, as each node selects
only a subset of neighbours to participate in the training, the algorithm is
robust against stragglers. Additionally, complex items are computed only once
for several consecutive steps and subproblems are solved inexactly using
closed-form solutions, resulting in high computational efficiency. Finally,
numerical experiments showcase the algorithm's effectiveness in both
communication and computation.
</p></li>
</ul>

<h3>Title: FedDD: Toward Communication-efficient Federated Learning with Differential Parameter Dropout. (arXiv:2308.16835v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2308.16835">http://arxiv.org/abs/2308.16835</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2308.16835]] FedDD: Toward Communication-efficient Federated Learning with Differential Parameter Dropout(http://arxiv.org/abs/2308.16835)</code></li>
<li>Summary: <p>Federated Learning (FL) requires frequent exchange of model parameters, which
leads to long communication delay, especially when the network environments of
clients vary greatly. Moreover, the parameter server needs to wait for the
slowest client (i.e., straggler, which may have the largest model size, lowest
computing capability or worst network condition) to upload parameters, which
may significantly degrade the communication efficiency. Commonly-used client
selection methods such as partial client selection would lead to the waste of
computing resources and weaken the generalization of the global model. To
tackle this problem, along a different line, in this paper, we advocate the
approach of model parameter dropout instead of client selection, and
accordingly propose a novel framework of Federated learning scheme with
Differential parameter Dropout (FedDD). FedDD consists of two key modules:
dropout rate allocation and uploaded parameter selection, which will optimize
the model parameter uploading ratios tailored to different clients'
heterogeneous conditions and also select the proper set of important model
parameters for uploading subject to clients' dropout rate constraints.
Specifically, the dropout rate allocation is formulated as a convex
optimization problem, taking system heterogeneity, data heterogeneity, and
model heterogeneity among clients into consideration. The uploaded parameter
selection strategy prioritizes on eliciting important parameters for uploading
to speedup convergence. Furthermore, we theoretically analyze the convergence
of the proposed FedDD scheme. Extensive performance evaluations demonstrate
that the proposed FedDD scheme can achieve outstanding performances in both
communication efficiency and model convergence, and also possesses a strong
generalization capability to data of rare classes.
</p></li>
</ul>

<h3>Title: Federated Learning in UAV-Enhanced Networks: Joint Coverage and Convergence Time Optimization. (arXiv:2308.16889v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2308.16889">http://arxiv.org/abs/2308.16889</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2308.16889]] Federated Learning in UAV-Enhanced Networks: Joint Coverage and Convergence Time Optimization(http://arxiv.org/abs/2308.16889)</code></li>
<li>Summary: <p>Federated learning (FL) involves several devices that collaboratively train a
shared model without transferring their local data. FL reduces the
communication overhead, making it a promising learning method in UAV-enhanced
wireless networks with scarce energy resources. Despite the potential,
implementing FL in UAV-enhanced networks is challenging, as conventional UAV
placement methods that maximize coverage increase the FL delay significantly.
Moreover, the uncertainty and lack of a priori information about crucial
variables, such as channel quality, exacerbate the problem. In this paper, we
first analyze the statistical characteristics of a UAV-enhanced wireless sensor
network (WSN) with energy harvesting. We then develop a model and solution
based on the multi-objective multi-armed bandit theory to maximize the network
coverage while minimizing the FL delay. Besides, we propose another solution
that is particularly useful with large action sets and strict energy
constraints at the UAVs. Our proposal uses a scalarized best-arm identification
algorithm to find the optimal arms that maximize the ratio of the expected
reward to the expected energy cost by sequentially eliminating one or more arms
in each round. Then, we derive the upper bound on the error probability of our
multi-objective and cost-aware algorithm. Numerical results show the
effectiveness of our approach.
</p></li>
</ul>

<h2>fair</h2>
<h3>Title: Thesis Distillation: Investigating The Impact of Bias in NLP Models on Hate Speech Detection. (arXiv:2308.16549v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2308.16549">http://arxiv.org/abs/2308.16549</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2308.16549]] Thesis Distillation: Investigating The Impact of Bias in NLP Models on Hate Speech Detection(http://arxiv.org/abs/2308.16549)</code></li>
<li>Summary: <p>This paper is a summary of the work in my PhD thesis. In which, I investigate
the impact of bias in NLP models on the task of hate speech detection from
three perspectives: explainability, offensive stereotyping bias, and fairness.
I discuss the main takeaways from my thesis and how they can benefit the
broader NLP community. Finally, I discuss important future research directions.
The findings of my thesis suggest that bias in NLP models impacts the task of
hate speech detection from all three perspectives. And that unless we start
incorporating social sciences in studying bias in NLP models, we will not
effectively overcome the current limitations of measuring and mitigating bias
in NLP models.
</p></li>
</ul>

<h3>Title: BenchTemp: A General Benchmark for Evaluating Temporal Graph Neural Networks. (arXiv:2308.16385v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2308.16385">http://arxiv.org/abs/2308.16385</a></li>
<li>Code URL: https://github.com/qianghuangwhu/benchtemp</li>
<li>Copy Paste: <code><input type="checkbox">[[2308.16385]] BenchTemp: A General Benchmark for Evaluating Temporal Graph Neural Networks(http://arxiv.org/abs/2308.16385)</code></li>
<li>Summary: <p>To handle graphs in which features or connectivities are evolving over time,
a series of temporal graph neural networks (TGNNs) have been proposed. Despite
the success of these TGNNs, the previous TGNN evaluations reveal several
limitations regarding four critical issues: 1) inconsistent datasets, 2)
inconsistent evaluation pipelines, 3) lacking workload diversity, and 4)
lacking efficient comparison. Overall, there lacks an empirical study that puts
TGNN models onto the same ground and compares them comprehensively. To this
end, we propose BenchTemp, a general benchmark for evaluating TGNN models on
various workloads. BenchTemp provides a set of benchmark datasets so that
different TGNN models can be fairly compared. Further, BenchTemp engineers a
standard pipeline that unifies the TGNN evaluation. With BenchTemp, we
extensively compare the representative TGNN models on different tasks (e.g.,
link prediction and node classification) and settings (transductive and
inductive), w.r.t. both effectiveness and efficiency metrics. We have made
BenchTemp publicly available at https://github.com/qianghuangwhu/benchtemp.
</p></li>
</ul>

<h2>interpretability</h2>
<h2>explainability</h2>
<h3>Title: Learning with Multi-modal Gradient Attention for Explainable Composed Image Retrieval. (arXiv:2308.16649v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2308.16649">http://arxiv.org/abs/2308.16649</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2308.16649]] Learning with Multi-modal Gradient Attention for Explainable Composed Image Retrieval(http://arxiv.org/abs/2308.16649)</code></li>
<li>Summary: <p>We consider the problem of composed image retrieval that takes an input query
consisting of an image and a modification text indicating the desired changes
to be made on the image and retrieves images that match these changes. Current
state-of-the-art techniques that address this problem use global features for
the retrieval, resulting in incorrect localization of the regions of interest
to be modified because of the global nature of the features, more so in cases
of real-world, in-the-wild images. Since modifier texts usually correspond to
specific local changes in an image, it is critical that models learn local
features to be able to both localize and retrieve better. To this end, our key
novelty is a new gradient-attention-based learning objective that explicitly
forces the model to focus on the local regions of interest being modified in
each retrieval step. We achieve this by first proposing a new visual image
attention computation technique, which we call multi-modal gradient attention
(MMGrad) that is explicitly conditioned on the modifier text. We next
demonstrate how MMGrad can be incorporated into an end-to-end model training
strategy with a new learning objective that explicitly forces these MMGrad
attention maps to highlight the correct local regions corresponding to the
modifier text. By training retrieval models with this new loss function, we
show improved grounding by means of better visual attention maps, leading to
better explainability of the models as well as competitive quantitative
retrieval performance on standard benchmark datasets.
</p></li>
</ul>

<h2>watermark</h2>
<h2>diffusion</h2>
<h3>Title: MVDream: Multi-view Diffusion for 3D Generation. (arXiv:2308.16512v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2308.16512">http://arxiv.org/abs/2308.16512</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2308.16512]] MVDream: Multi-view Diffusion for 3D Generation(http://arxiv.org/abs/2308.16512)</code></li>
<li>Summary: <p>We propose MVDream, a multi-view diffusion model that is able to generate
geometrically consistent multi-view images from a given text prompt. By
leveraging image diffusion models pre-trained on large-scale web datasets and a
multi-view dataset rendered from 3D assets, the resulting multi-view diffusion
model can achieve both the generalizability of 2D diffusion and the consistency
of 3D data. Such a model can thus be applied as a multi-view prior for 3D
generation via Score Distillation Sampling, where it greatly improves the
stability of existing 2D-lifting methods by solving the 3D consistency problem.
Finally, we show that the multi-view diffusion model can also be fine-tuned
under a few shot setting for personalized 3D generation, i.e. DreamBooth3D
application, where the consistency can be maintained after learning the subject
identity.
</p></li>
</ul>

<h3>Title: Any-Size-Diffusion: Toward Efficient Text-Driven Synthesis for Any-Size HD Images. (arXiv:2308.16582v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2308.16582">http://arxiv.org/abs/2308.16582</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2308.16582]] Any-Size-Diffusion: Toward Efficient Text-Driven Synthesis for Any-Size HD Images(http://arxiv.org/abs/2308.16582)</code></li>
<li>Summary: <p>Stable diffusion, a generative model used in text-to-image synthesis,
frequently encounters resolution-induced composition problems when generating
images of varying sizes. This issue primarily stems from the model being
trained on pairs of single-scale images and their corresponding text
descriptions. Moreover, direct training on images of unlimited sizes is
unfeasible, as it would require an immense number of text-image pairs and
entail substantial computational expenses. To overcome these challenges, we
propose a two-stage pipeline named Any-Size-Diffusion (ASD), designed to
efficiently generate well-composed images of any size, while minimizing the
need for high-memory GPU resources. Specifically, the initial stage, dubbed Any
Ratio Adaptability Diffusion (ARAD), leverages a selected set of images with a
restricted range of ratios to optimize the text-conditional diffusion model,
thereby improving its ability to adjust composition to accommodate diverse
image sizes. To support the creation of images at any desired size, we further
introduce a technique called Fast Seamless Tiled Diffusion (FSTD) at the
subsequent stage. This method allows for the rapid enlargement of the ASD
output to any high-resolution size, avoiding seaming artifacts or memory
overloads. Experimental results on the LAION-COCO and MM-CelebA-HQ benchmarks
demonstrate that ASD can produce well-structured images of arbitrary sizes,
cutting down the inference time by 2x compared to the traditional tiled
algorithm.
</p></li>
</ul>

<h3>Title: Detecting Out-of-Context Image-Caption Pairs in News: A Counter-Intuitive Method. (arXiv:2308.16611v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2308.16611">http://arxiv.org/abs/2308.16611</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2308.16611]] Detecting Out-of-Context Image-Caption Pairs in News: A Counter-Intuitive Method(http://arxiv.org/abs/2308.16611)</code></li>
<li>Summary: <p>The growth of misinformation and re-contextualized media in social media and
news leads to an increasing need for fact-checking methods. Concurrently, the
advancement in generative models makes cheapfakes and deepfakes both easier to
make and harder to detect. In this paper, we present a novel approach using
generative image models to our advantage for detecting Out-of-Context (OOC) use
of images-caption pairs in news. We present two new datasets with a total of
$6800$ images generated using two different generative models including (1)
DALL-E 2, and (2) Stable-Diffusion. We are confident that the method proposed
in this paper can further research on generative models in the field of
cheapfake detection, and that the resulting datasets can be used to train and
evaluate new models aimed at detecting cheapfakes. We run a preliminary
qualitative and quantitative analysis to evaluate the performance of each image
generation model for this task, and evaluate a handful of methods for computing
image similarity.
</p></li>
</ul>

<h3>Title: MFR-Net: Multi-faceted Responsive Listening Head Generation via Denoising Diffusion Model. (arXiv:2308.16635v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2308.16635">http://arxiv.org/abs/2308.16635</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2308.16635]] MFR-Net: Multi-faceted Responsive Listening Head Generation via Denoising Diffusion Model(http://arxiv.org/abs/2308.16635)</code></li>
<li>Summary: <p>Face-to-face communication is a common scenario including roles of speakers
and listeners. Most existing research methods focus on producing speaker
videos, while the generation of listener heads remains largely overlooked.
Responsive listening head generation is an important task that aims to model
face-to-face communication scenarios by generating a listener head video given
a speaker video and a listener head image. An ideal generated responsive
listening video should respond to the speaker with attitude or viewpoint
expressing while maintaining diversity in interaction patterns and accuracy in
listener identity information. To achieve this goal, we propose the
\textbf{M}ulti-\textbf{F}aceted \textbf{R}esponsive Listening Head Generation
Network (MFR-Net). Specifically, MFR-Net employs the probabilistic denoising
diffusion model to predict diverse head pose and expression features. In order
to perform multi-faceted response to the speaker video, while maintaining
accurate listener identity preservation, we design the Feature Aggregation
Module to boost listener identity features and fuse them with other
speaker-related features. Finally, a renderer finetuned with identity
consistency loss produces the final listening head videos. Our extensive
experiments demonstrate that MFR-Net not only achieves multi-faceted responses
in diversity and speaker identity information but also in attitude and
viewpoint expression.
</p></li>
</ul>

<h3>Title: Generate Your Own Scotland: Satellite Image Generation Conditioned on Maps. (arXiv:2308.16648v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2308.16648">http://arxiv.org/abs/2308.16648</a></li>
<li>Code URL: https://github.com/miquel-espinosa/map-sat</li>
<li>Copy Paste: <code><input type="checkbox">[[2308.16648]] Generate Your Own Scotland: Satellite Image Generation Conditioned on Maps(http://arxiv.org/abs/2308.16648)</code></li>
<li>Summary: <p>Despite recent advancements in image generation, diffusion models still
remain largely underexplored in Earth Observation. In this paper we show that
state-of-the-art pretrained diffusion models can be conditioned on cartographic
data to generate realistic satellite images. We provide two large datasets of
paired OpenStreetMap images and satellite views over the region of Mainland
Scotland and the Central Belt. We train a ControlNet model and qualitatively
evaluate the results, demonstrating that both image quality and map fidelity
are possible. Finally, we provide some insights on the opportunities and
challenges of applying these models for remote sensing. Our model weights and
code for creating the dataset are publicly available at
https://github.com/miquel-espinosa/map-sat.
</p></li>
</ul>

<h3>Title: Diffusion Inertial Poser: Human Motion Reconstruction from Arbitrary Sparse IMU Configurations. (arXiv:2308.16682v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2308.16682">http://arxiv.org/abs/2308.16682</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2308.16682]] Diffusion Inertial Poser: Human Motion Reconstruction from Arbitrary Sparse IMU Configurations(http://arxiv.org/abs/2308.16682)</code></li>
<li>Summary: <p>Motion capture from a limited number of inertial measurement units (IMUs) has
important applications in health, human performance, and virtual reality.
Real-world limitations and application-specific goals dictate different IMU
configurations (i.e., number of IMUs and chosen attachment body segments),
trading off accuracy and practicality. Although recent works were successful in
accurately reconstructing whole-body motion from six IMUs, these systems only
work with a specific IMU configuration. Here we propose a single diffusion
generative model, Diffusion Inertial Poser (DiffIP), which reconstructs human
motion in real-time from arbitrary IMU configurations. We show that DiffIP has
the benefit of flexibility with respect to the IMU configuration while being as
accurate as the state-of-the-art for the commonly used six IMU configuration.
Our system enables selecting an optimal configuration for different
applications without retraining the model. For example, when only four IMUs are
available, DiffIP found that the configuration that minimizes errors in joint
kinematics instruments the thighs and forearms. However, global translation
reconstruction is better when instrumenting the feet instead of the thighs.
Although our approach is agnostic to the underlying model, we built DiffIP
based on physiologically realistic musculoskeletal models to enable use in
biomedical research and health applications.
</p></li>
</ul>

<h3>Title: Terrain Diffusion Network: Climatic-Aware Terrain Generation with Geological Sketch Guidance. (arXiv:2308.16725v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2308.16725">http://arxiv.org/abs/2308.16725</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2308.16725]] Terrain Diffusion Network: Climatic-Aware Terrain Generation with Geological Sketch Guidance(http://arxiv.org/abs/2308.16725)</code></li>
<li>Summary: <p>Sketch-based terrain generation seeks to create realistic landscapes for
virtual environments in various applications such as computer games, animation
and virtual reality. Recently, deep learning based terrain generation has
emerged, notably the ones based on generative adversarial networks (GAN).
However, these methods often struggle to fulfill the requirements of flexible
user control and maintain generative diversity for realistic terrain.
Therefore, we propose a novel diffusion-based method, namely terrain diffusion
network (TDN), which actively incorporates user guidance for enhanced
controllability, taking into account terrain features like rivers, ridges,
basins, and peaks. Instead of adhering to a conventional monolithic denoising
process, which often compromises the fidelity of terrain details or the
alignment with user control, a multi-level denoising scheme is proposed to
generate more realistic terrains by taking into account fine-grained details,
particularly those related to climatic patterns influenced by erosion and
tectonic activities. Specifically, three terrain synthesisers are designed for
structural, intermediate, and fine-grained level denoising purposes, which
allow each synthesiser concentrate on a distinct terrain aspect. Moreover, to
maximise the efficiency of our TDN, we further introduce terrain and sketch
latent spaces for the synthesizers with pre-trained terrain autoencoders.
Comprehensive experiments on a new dataset constructed from NASA Topology
Images clearly demonstrate the effectiveness of our proposed method, achieving
the state-of-the-art performance. Our code and dataset will be publicly
available.
</p></li>
</ul>

<h3>Title: Diffusion Models for Interferometric Satellite Aperture Radar. (arXiv:2308.16847v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2308.16847">http://arxiv.org/abs/2308.16847</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2308.16847]] Diffusion Models for Interferometric Satellite Aperture Radar(http://arxiv.org/abs/2308.16847)</code></li>
<li>Summary: <p>Probabilistic Diffusion Models (PDMs) have recently emerged as a very
promising class of generative models, achieving high performance in natural
image generation. However, their performance relative to non-natural images,
like radar-based satellite data, remains largely unknown. Generating large
amounts of synthetic (and especially labelled) satellite data is crucial to
implement deep-learning approaches for the processing and analysis of
(interferometric) satellite aperture radar data. Here, we leverage PDMs to
generate several radar-based satellite image datasets. We show that PDMs
succeed in generating images with complex and realistic structures, but that
sampling time remains an issue. Indeed, accelerated sampling strategies, which
work well on simple image datasets like MNIST, fail on our radar datasets. We
provide a simple and versatile open-source
https://github.com/thomaskerdreux/PDM_SAR_InSAR_generation to train, sample and
evaluate PDMs using any dataset on a single GPU.
</p></li>
</ul>

<h3>Title: InterDiff: Generating 3D Human-Object Interactions with Physics-Informed Diffusion. (arXiv:2308.16905v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2308.16905">http://arxiv.org/abs/2308.16905</a></li>
<li>Code URL: https://github.com/Sirui-Xu/InterDiff</li>
<li>Copy Paste: <code><input type="checkbox">[[2308.16905]] InterDiff: Generating 3D Human-Object Interactions with Physics-Informed Diffusion(http://arxiv.org/abs/2308.16905)</code></li>
<li>Summary: <p>This paper addresses a novel task of anticipating 3D human-object
interactions (HOIs). Most existing research on HOI synthesis lacks
comprehensive whole-body interactions with dynamic objects, e.g., often limited
to manipulating small or static objects. Our task is significantly more
challenging, as it requires modeling dynamic objects with various shapes,
capturing whole-body motion, and ensuring physically valid interactions. To
this end, we propose InterDiff, a framework comprising two key steps: (i)
interaction diffusion, where we leverage a diffusion model to encode the
distribution of future human-object interactions; (ii) interaction correction,
where we introduce a physics-informed predictor to correct denoised HOIs in a
diffusion step. Our key insight is to inject prior knowledge that the
interactions under reference with respect to contact points follow a simple
pattern and are easily predictable. Experiments on multiple human-object
interaction datasets demonstrate the effectiveness of our method for this task,
capable of producing realistic, vivid, and remarkably long-term 3D HOI
predictions.
</p></li>
</ul>

<h3>Title: Irregular Traffic Time Series Forecasting Based on Asynchronous Spatio-Temporal Graph Convolutional Network. (arXiv:2308.16818v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2308.16818">http://arxiv.org/abs/2308.16818</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2308.16818]] Irregular Traffic Time Series Forecasting Based on Asynchronous Spatio-Temporal Graph Convolutional Network(http://arxiv.org/abs/2308.16818)</code></li>
<li>Summary: <p>Accurate traffic forecasting at intersections governed by intelligent traffic
signals is critical for the advancement of an effective intelligent traffic
signal control system. However, due to the irregular traffic time series
produced by intelligent intersections, the traffic forecasting task becomes
much more intractable and imposes three major new challenges: 1) asynchronous
spatial dependency, 2) irregular temporal dependency among traffic data, and 3)
variable-length sequence to be predicted, which severely impede the performance
of current traffic forecasting methods. To this end, we propose an Asynchronous
Spatio-tEmporal graph convolutional nEtwoRk (ASeer) to predict the traffic
states of the lanes entering intelligent intersections in a future time window.
Specifically, by linking lanes via a traffic diffusion graph, we first propose
an Asynchronous Graph Diffusion Network to model the asynchronous spatial
dependency between the time-misaligned traffic state measurements of lanes.
After that, to capture the temporal dependency within irregular traffic state
sequence, a learnable personalized time encoding is devised to embed the
continuous time for each lane. Then we propose a Transformable Time-aware
Convolution Network that learns meta-filters to derive time-aware convolution
filters with transformable filter sizes for efficient temporal convolution on
the irregular sequence. Furthermore, a Semi-Autoregressive Prediction Network
consisting of a state evolution unit and a semiautoregressive predictor is
designed to effectively and efficiently predict variable-length traffic state
sequences. Extensive experiments on two real-world datasets demonstrate the
effectiveness of ASeer in six metrics.
</p></li>
</ul>

<h2>noise learning</h2>
<h2>data-free</h2>
<h2>transformer</h2>
<h3>Title: Emergence of Segmentation with Minimalistic White-Box Transformers. (arXiv:2308.16271v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2308.16271">http://arxiv.org/abs/2308.16271</a></li>
<li>Code URL: https://github.com/ma-lab-berkeley/crate</li>
<li>Copy Paste: <code><input type="checkbox">[[2308.16271]] Emergence of Segmentation with Minimalistic White-Box Transformers(http://arxiv.org/abs/2308.16271)</code></li>
<li>Summary: <p>Transformer-like models for vision tasks have recently proven effective for a
wide range of downstream applications such as segmentation and detection.
Previous works have shown that segmentation properties emerge in vision
transformers (ViTs) trained using self-supervised methods such as DINO, but not
in those trained on supervised classification tasks. In this study, we probe
whether segmentation emerges in transformer-based models solely as a result of
intricate self-supervised learning mechanisms, or if the same emergence can be
achieved under much broader conditions through proper design of the model
architecture. Through extensive experimental results, we demonstrate that when
employing a white-box transformer-like architecture known as CRATE, whose
design explicitly models and pursues low-dimensional structures in the data
distribution, segmentation properties, at both the whole and parts levels,
already emerge with a minimalistic supervised training recipe. Layer-wise
finer-grained analysis reveals that the emergent properties strongly
corroborate the designed mathematical functions of the white-box network. Our
results suggest a path to design white-box foundation models that are
simultaneously highly performant and mathematically fully interpretable. Code
is at \url{https://github.com/Ma-Lab-Berkeley/CRATE}.
</p></li>
</ul>

<h3>Title: Learning Diverse Features in Vision Transformers for Improved Generalization. (arXiv:2308.16274v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2308.16274">http://arxiv.org/abs/2308.16274</a></li>
<li>Code URL: https://github.com/armandnm/diverse-vit</li>
<li>Copy Paste: <code><input type="checkbox">[[2308.16274]] Learning Diverse Features in Vision Transformers for Improved Generalization(http://arxiv.org/abs/2308.16274)</code></li>
<li>Summary: <p>Deep learning models often rely only on a small set of features even when
there is a rich set of predictive signals in the training data. This makes
models brittle and sensitive to distribution shifts. In this work, we first
examine vision transformers (ViTs) and find that they tend to extract robust
and spurious features with distinct attention heads. As a result of this
modularity, their performance under distribution shifts can be significantly
improved at test time by pruning heads corresponding to spurious features,
which we demonstrate using an "oracle selection" on validation data. Second, we
propose a method to further enhance the diversity and complementarity of the
learned features by encouraging orthogonality of the attention heads' input
gradients. We observe improved out-of-distribution performance on diagnostic
benchmarks (MNIST-CIFAR, Waterbirds) as a consequence of the enhanced diversity
of features and the pruning of undesirable heads.
</p></li>
</ul>

<h3>Title: Catalog Phrase Grounding (CPG): Grounding of Product Textual Attributes in Product Images for e-commerce Vision-Language Applications. (arXiv:2308.16354v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2308.16354">http://arxiv.org/abs/2308.16354</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2308.16354]] Catalog Phrase Grounding (CPG): Grounding of Product Textual Attributes in Product Images for e-commerce Vision-Language Applications(http://arxiv.org/abs/2308.16354)</code></li>
<li>Summary: <p>We present Catalog Phrase Grounding (CPG), a model that can associate product
textual data (title, brands) into corresponding regions of product images
(isolated product region, brand logo region) for e-commerce vision-language
applications. We use a state-of-the-art modulated multimodal transformer
encoder-decoder architecture unifying object detection and phrase-grounding. We
train the model in self-supervised fashion with 2.3 million image-text pairs
synthesized from an e-commerce site. The self-supervision data is annotated
with high-confidence pseudo-labels generated with a combination of teacher
models: a pre-trained general domain phrase grounding model (e.g. MDETR) and a
specialized logo detection model. This allows CPG, as a student model, to
benefit from transfer knowledge from these base models combining general-domain
knowledge and specialized knowledge. Beyond immediate catalog phrase grounding
tasks, we can benefit from CPG representations by incorporating them as ML
features into downstream catalog applications that require deep semantic
understanding of products. Our experiments on product-brand matching, a
challenging e-commerce application, show that incorporating CPG representations
into the existing production ensemble system leads to on average 5% recall
improvement across all countries globally (with the largest lift of 11% in a
single country) at fixed 95% precision, outperforming other alternatives
including a logo detection teacher model and ResNet50.
</p></li>
</ul>

<h3>Title: Prompt-enhanced Hierarchical Transformer Elevating Cardiopulmonary Resuscitation Instruction via Temporal Action Segmentation. (arXiv:2308.16552v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2308.16552">http://arxiv.org/abs/2308.16552</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2308.16552]] Prompt-enhanced Hierarchical Transformer Elevating Cardiopulmonary Resuscitation Instruction via Temporal Action Segmentation(http://arxiv.org/abs/2308.16552)</code></li>
<li>Summary: <p>The vast majority of people who suffer unexpected cardiac arrest are
performed cardiopulmonary resuscitation (CPR) by passersby in a desperate
attempt to restore life, but endeavors turn out to be fruitless on account of
disqualification. Fortunately, many pieces of research manifest that
disciplined training will help to elevate the success rate of resuscitation,
which constantly desires a seamless combination of novel techniques to yield
further advancement. To this end, we collect a custom CPR video dataset in
which trainees make efforts to behave resuscitation on mannequins independently
in adherence to approved guidelines, thereby devising an auxiliary toolbox to
assist supervision and rectification of intermediate potential issues via
modern deep learning methodologies. Our research empirically views this problem
as a temporal action segmentation (TAS) task in computer vision, which aims to
segment an untrimmed video at a frame-wise level. Here, we propose a
Prompt-enhanced hierarchical Transformer (PhiTrans) that integrates three
indispensable modules, including a textual prompt-based Video Features
Extractor (VFE), a transformer-based Action Segmentation Executor (ASE), and a
regression-based Prediction Refinement Calibrator (PRC). The backbone of the
model preferentially derives from applications in three approved public
datasets (GTEA, 50Salads, and Breakfast) collected for TAS tasks, which
accounts for the excavation of the segmentation pipeline on the CPR dataset. In
general, we unprecedentedly probe into a feasible pipeline that genuinely
elevates the CPR instruction qualification via action segmentation in
conjunction with cutting-edge deep learning techniques. Associated experiments
advocate our implementation with multiple metrics surpassing 91.0%.
</p></li>
</ul>

<h3>Title: Transformer Compression via Subspace Projection. (arXiv:2308.16475v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2308.16475">http://arxiv.org/abs/2308.16475</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2308.16475]] Transformer Compression via Subspace Projection(http://arxiv.org/abs/2308.16475)</code></li>
<li>Summary: <p>We propose TCSP, a novel method for compressing a transformer model by
focusing on reducing the hidden size of the model. By projecting the whole
transform model into a subspace, we enable matrix operations between the weight
matrices in the model and features in a reduced-dimensional space, leading to
significant reductions in model parameters and computing resources. To
establish this subspace, we decompose the feature matrix, derived from
different layers of sampled data instances, into a projection matrix. For
evaluation, TCSP is applied to compress T5 and BERT models on the GLUE and
SQuAD benchmarks. Experimental results demonstrate that TCSP achieves a
compression ratio of 44\% with at most 1.6\% degradation in accuracy,
surpassing or matching prior compression methods. Furthermore, TCSP exhibits
compatibility with other methods targeting filter and attention head size
compression.
</p></li>
</ul>

<h3>Title: Transformers as Support Vector Machines. (arXiv:2308.16898v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2308.16898">http://arxiv.org/abs/2308.16898</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2308.16898]] Transformers as Support Vector Machines(http://arxiv.org/abs/2308.16898)</code></li>
<li>Summary: <p>Since its inception in "Attention Is All You Need", transformer architecture
has led to revolutionary advancements in NLP. The attention layer within the
transformer admits a sequence of input tokens $X$ and makes them interact
through pairwise similarities computed as softmax$(XQK^\top X^\top)$, where
$(K,Q)$ are the trainable key-query parameters. In this work, we establish a
formal equivalence between the optimization geometry of self-attention and a
hard-margin SVM problem that separates optimal input tokens from non-optimal
tokens using linear constraints on the outer-products of token pairs. This
formalism allows us to characterize the implicit bias of 1-layer transformers
optimized with gradient descent: (1) Optimizing the attention layer with
vanishing regularization, parameterized by $(K,Q)$, converges in direction to
an SVM solution minimizing the nuclear norm of the combined parameter
$W=KQ^\top$. Instead, directly parameterizing by $W$ minimizes a Frobenius norm
objective. We characterize this convergence, highlighting that it can occur
toward locally-optimal directions rather than global ones. (2) Complementing
this, we prove the local/global directional convergence of gradient descent
under suitable geometric conditions. Importantly, we show that
over-parameterization catalyzes global convergence by ensuring the feasibility
of the SVM problem and by guaranteeing a benign optimization landscape devoid
of stationary points. (3) While our theory applies primarily to linear
prediction heads, we propose a more general SVM equivalence that predicts the
implicit bias with nonlinear heads. Our findings are applicable to arbitrary
datasets and their validity is verified via experiments. We also introduce
several open problems and research directions. We believe these findings
inspire the interpretation of transformers as a hierarchy of SVMs that
separates and selects optimal tokens.
</p></li>
</ul>

<h3>Title: Materials Informatics Transformer: A Language Model for Interpretable Materials Properties Prediction. (arXiv:2308.16259v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2308.16259">http://arxiv.org/abs/2308.16259</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2308.16259]] Materials Informatics Transformer: A Language Model for Interpretable Materials Properties Prediction(http://arxiv.org/abs/2308.16259)</code></li>
<li>Summary: <p>Recently, the remarkable capabilities of large language models (LLMs) have
been illustrated across a variety of research domains such as natural language
processing, computer vision, and molecular modeling. We extend this paradigm by
utilizing LLMs for material property prediction by introducing our model
Materials Informatics Transformer (MatInFormer). Specifically, we introduce a
novel approach that involves learning the grammar of crystallography through
the tokenization of pertinent space group information. We further illustrate
the adaptability of MatInFormer by incorporating task-specific data pertaining
to Metal-Organic Frameworks (MOFs). Through attention visualization, we uncover
the key features that the model prioritizes during property prediction. The
effectiveness of our proposed model is empirically validated across 14 distinct
datasets, hereby underscoring its potential for high throughput screening
through accurate material property prediction.
</p></li>
</ul>

<h3>Title: Multi-Objective Decision Transformers for Offline Reinforcement Learning. (arXiv:2308.16379v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2308.16379">http://arxiv.org/abs/2308.16379</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2308.16379]] Multi-Objective Decision Transformers for Offline Reinforcement Learning(http://arxiv.org/abs/2308.16379)</code></li>
<li>Summary: <p>Offline Reinforcement Learning (RL) is structured to derive policies from
static trajectory data without requiring real-time environment interactions.
Recent studies have shown the feasibility of framing offline RL as a sequence
modeling task, where the sole aim is to predict actions based on prior context
using the transformer architecture. However, the limitation of this single task
learning approach is its potential to undermine the transformer model's
attention mechanism, which should ideally allocate varying attention weights
across different tokens in the input context for optimal prediction. To address
this, we reformulate offline RL as a multi-objective optimization problem,
where the prediction is extended to states and returns. We also highlight a
potential flaw in the trajectory representation used for sequence modeling,
which could generate inaccuracies when modeling the state and return
distributions. This is due to the non-smoothness of the action distribution
within the trajectory dictated by the behavioral policy. To mitigate this
issue, we introduce action space regions to the trajectory representation. Our
experiments on D4RL benchmark locomotion tasks reveal that our propositions
allow for more effective utilization of the attention mechanism in the
transformer model, resulting in performance that either matches or outperforms
current state-of-the art methods.
</p></li>
</ul>

<h2>generative</h2>
<h3>Title: Ten Years of Generative Adversarial Nets (GANs): A survey of the state-of-the-art. (arXiv:2308.16316v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2308.16316">http://arxiv.org/abs/2308.16316</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2308.16316]] Ten Years of Generative Adversarial Nets (GANs): A survey of the state-of-the-art(http://arxiv.org/abs/2308.16316)</code></li>
<li>Summary: <p>Since their inception in 2014, Generative Adversarial Networks (GANs) have
rapidly emerged as powerful tools for generating realistic and diverse data
across various domains, including computer vision and other applied areas.
Consisting of a discriminative network and a generative network engaged in a
Minimax game, GANs have revolutionized the field of generative modeling. In
February 2018, GAN secured the leading spot on the ``Top Ten Global
Breakthrough Technologies List'' issued by the Massachusetts Science and
Technology Review. Over the years, numerous advancements have been proposed,
leading to a rich array of GAN variants, such as conditional GAN, Wasserstein
GAN, CycleGAN, and StyleGAN, among many others. This survey aims to provide a
general overview of GANs, summarizing the latent architecture, validation
metrics, and application areas of the most widely recognized variants. We also
delve into recent theoretical developments, exploring the profound connection
between the adversarial principle underlying GAN and Jensen-Shannon divergence,
while discussing the optimality characteristics of the GAN framework. The
efficiency of GAN variants and their model architectures will be evaluated
along with training obstacles as well as training solutions. In addition, a
detailed discussion will be provided, examining the integration of GANs with
newly developed deep learning frameworks such as Transformers, Physics-Informed
Neural Networks, Large Language models, and Diffusion models. Finally, we
reveal several issues as well as future research outlines in this field.
</p></li>
</ul>

<h3>Title: Latent Painter. (arXiv:2308.16490v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2308.16490">http://arxiv.org/abs/2308.16490</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2308.16490]] Latent Painter(http://arxiv.org/abs/2308.16490)</code></li>
<li>Summary: <p>Latent diffusers revolutionized the generative AI and inspired creative art.
When denoising the latent, the predicted original image at each step
collectively animates the formation. However, the animation is limited by the
denoising nature of the diffuser, and only renders a sharpening process. This
work presents Latent Painter, which uses the latent as the canvas, and the
diffuser predictions as the plan, to generate painting animation. Latent
Painter also transits one generated image to another, which can happen between
images from two different sets of checkpoints.
</p></li>
</ul>

<h3>Title: Ref-Diff: Zero-shot Referring Image Segmentation with Generative Models. (arXiv:2308.16777v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2308.16777">http://arxiv.org/abs/2308.16777</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2308.16777]] Ref-Diff: Zero-shot Referring Image Segmentation with Generative Models(http://arxiv.org/abs/2308.16777)</code></li>
<li>Summary: <p>Zero-shot referring image segmentation is a challenging task because it aims
to find an instance segmentation mask based on the given referring
descriptions, without training on this type of paired data. Current zero-shot
methods mainly focus on using pre-trained discriminative models (e.g., CLIP).
However, we have observed that generative models (e.g., Stable Diffusion) have
potentially understood the relationships between various visual elements and
text descriptions, which are rarely investigated in this task. In this work, we
introduce a novel Referring Diffusional segmentor (Ref-Diff) for this task,
which leverages the fine-grained multi-modal information from generative
models. We demonstrate that without a proposal generator, a generative model
alone can achieve comparable performance to existing SOTA weakly-supervised
models. When we combine both generative and discriminative models, our Ref-Diff
outperforms these competing methods by a significant margin. This indicates
that generative models are also beneficial for this task and can complement
discriminative models for better referring segmentation. Our code is publicly
available at https://github.com/kodenii/Ref-Diff.
</p></li>
</ul>

<h3>Title: Unsupervised Text Style Transfer with Deep Generative Models. (arXiv:2308.16584v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2308.16584">http://arxiv.org/abs/2308.16584</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2308.16584]] Unsupervised Text Style Transfer with Deep Generative Models(http://arxiv.org/abs/2308.16584)</code></li>
<li>Summary: <p>We present a general framework for unsupervised text style transfer with deep
generative models. The framework models each sentence-label pair in the
non-parallel corpus as partially observed from a complete quadruplet which
additionally contains two latent codes representing the content and style,
respectively. These codes are learned by exploiting dependencies inside the
observed data. Then a sentence is transferred by manipulating them. Our
framework is able to unify previous embedding and prototype methods as two
special forms. It also provides a principled perspective to explain previously
proposed techniques in the field such as aligned encoder and adversarial
training. We further conduct experiments on three benchmarks. Both automatic
and human evaluation results show that our methods achieve better or
competitive results compared to several strong baselines.
</p></li>
</ul>

<h3>Title: Conditioning Score-Based Generative Models by Neuro-Symbolic Constraints. (arXiv:2308.16534v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2308.16534">http://arxiv.org/abs/2308.16534</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2308.16534]] Conditioning Score-Based Generative Models by Neuro-Symbolic Constraints(http://arxiv.org/abs/2308.16534)</code></li>
<li>Summary: <p>Score-based and diffusion models have emerged as effective approaches for
both conditional and unconditional generation. Still conditional generation is
based on either a specific training of a conditional model or classifier
guidance, which requires training a noise-dependent classifier, even when the
classifier for uncorrupted data is given. We propose an approach to sample from
unconditional score-based generative models enforcing arbitrary logical
constraints, without any additional training. Firstly, we show how to
manipulate the learned score in order to sample from an un-normalized
distribution conditional on a user-defined constraint. Then, we define a
flexible and numerically stable neuro-symbolic framework for encoding soft
logical constraints. Combining these two ingredients we obtain a general, but
approximate, conditional sampling algorithm. We further developed effective
heuristics aimed at improving the approximation. Finally, we show the
effectiveness of our approach for various types of constraints and data:
tabular data, images and time series.
</p></li>
</ul>

<h2>large language model</h2>
<h3>Title: Sparkles: Unlocking Chats Across Multiple Images for Multimodal Instruction-Following Models. (arXiv:2308.16463v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2308.16463">http://arxiv.org/abs/2308.16463</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2308.16463]] Sparkles: Unlocking Chats Across Multiple Images for Multimodal Instruction-Following Models(http://arxiv.org/abs/2308.16463)</code></li>
<li>Summary: <p>Large language models exhibit enhanced zero-shot performance on various tasks
when fine-tuned with instruction-following data. Multimodal
instruction-following models extend these capabilities by integrating both text
and images. However, existing models such as MiniGPT-4 face challenges in
maintaining dialogue coherence in scenarios involving multiple images. A
primary reason is the lack of a specialized dataset for this critical
application. To bridge these gaps, we present SparklesChat, a multimodal
instruction-following model for open-ended dialogues across multiple images. To
support the training, we introduce SparklesDialogue, the first
machine-generated dialogue dataset tailored for word-level interleaved
multi-image and text interactions. Furthermore, we construct SparklesEval, a
GPT-assisted benchmark for quantitatively assessing a model's conversational
competence across multiple images and dialogue turns. Our experiments validate
the effectiveness of SparklesChat in understanding and reasoning across
multiple images and dialogue turns. Specifically, SparklesChat outperformed
MiniGPT-4 on established vision-and-language benchmarks, including the BISON
binary image selection task and the NLVR2 visual reasoning task. Moreover,
SparklesChat scored 8.56 out of 10 on SparklesEval, substantially exceeding
MiniGPT-4's score of 3.91 and nearing GPT-4's score of 9.26. Qualitative
evaluations further demonstrate SparklesChat's generality in handling
real-world applications. All resources will be available at
https://github.com/HYPJUDY/Sparkles.
</p></li>
</ul>

<h3>Title: PointLLM: Empowering Large Language Models to Understand Point Clouds. (arXiv:2308.16911v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2308.16911">http://arxiv.org/abs/2308.16911</a></li>
<li>Code URL: https://github.com/openrobotlab/pointllm</li>
<li>Copy Paste: <code><input type="checkbox">[[2308.16911]] PointLLM: Empowering Large Language Models to Understand Point Clouds(http://arxiv.org/abs/2308.16911)</code></li>
<li>Summary: <p>The unprecedented advancements in Large Language Models (LLMs) have created a
profound impact on natural language processing but are yet to fully embrace the
realm of 3D understanding. This paper introduces PointLLM, a preliminary effort
to fill this gap, thereby enabling LLMs to understand point clouds and offering
a new avenue beyond 2D visual data. PointLLM processes colored object point
clouds with human instructions and generates contextually appropriate
responses, illustrating its grasp of point clouds and common sense.
Specifically, it leverages a point cloud encoder with a powerful LLM to
effectively fuse geometric, appearance, and linguistic information. We collect
a novel dataset comprising 660K simple and 70K complex point-text instruction
pairs to enable a two-stage training strategy: initially aligning latent spaces
and subsequently instruction-tuning the unified model. To rigorously evaluate
our model's perceptual abilities and its generalization capabilities, we
establish two benchmarks: Generative 3D Object Classification and 3D Object
Captioning, assessed through three different methods, including human
evaluation, GPT-4/ChatGPT evaluation, and traditional metrics. Experiment
results show that PointLLM demonstrates superior performance over existing 2D
baselines. Remarkably, in human-evaluated object captioning tasks, PointLLM
outperforms human annotators in over 50% of the samples. Codes, datasets, and
benchmarks are available at https://github.com/OpenRobotLab/PointLLM .
</p></li>
</ul>

<h3>Title: Enhancing Subtask Performance of Multi-modal Large Language Model. (arXiv:2308.16474v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2308.16474">http://arxiv.org/abs/2308.16474</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2308.16474]] Enhancing Subtask Performance of Multi-modal Large Language Model(http://arxiv.org/abs/2308.16474)</code></li>
<li>Summary: <p>Multi-modal Large Language Model (MLLM) refers to a model expanded from a
Large Language Model (LLM) that possesses the capability to handle and infer
multi-modal data. Current MLLMs typically begin by using LLMs to decompose
tasks into multiple subtasks, then employing individual pre-trained models to
complete specific subtasks, and ultimately utilizing LLMs to integrate the
results of each subtasks to obtain the results of the task. In real-world
scenarios, when dealing with large projects, it is common practice to break
down the project into smaller sub-projects, with different teams providing
corresponding solutions or results. The project owner then decides which
solution or result to use, ensuring the best possible outcome for each subtask
and, consequently, for the entire project. Inspired by this, this study
considers selecting multiple pre-trained models to complete the same subtask.
By combining the results from multiple pre-trained models, the optimal subtask
result is obtained, enhancing the performance of the MLLM. Specifically, this
study first selects multiple pre-trained models focused on the same subtask
based on distinct evaluation approaches, and then invokes these models in
parallel to process input data and generate corresponding subtask results.
Finally, the results from multiple pre-trained models for the same subtask are
compared using the LLM, and the best result is chosen as the outcome for that
subtask. Extensive experiments are conducted in this study using GPT-4
annotated datasets and human-annotated datasets. The results of various
evaluation metrics adequately demonstrate the effectiveness of the proposed
approach in this paper.
</p></li>
</ul>

<h3>Title: Using Large Language Models to Automate Category and Trend Analysis of Scientific Articles: An Application in Ophthalmology. (arXiv:2308.16688v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2308.16688">http://arxiv.org/abs/2308.16688</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2308.16688]] Using Large Language Models to Automate Category and Trend Analysis of Scientific Articles: An Application in Ophthalmology(http://arxiv.org/abs/2308.16688)</code></li>
<li>Summary: <p>Purpose: In this paper, we present an automated method for article
classification, leveraging the power of Large Language Models (LLM). The
primary focus is on the field of ophthalmology, but the model is extendable to
other fields. Methods: We have developed a model based on Natural Language
Processing (NLP) techniques, including advanced LLMs, to process and analyze
the textual content of scientific papers. Specifically, we have employed
zero-shot learning (ZSL) LLM models and compared against Bidirectional and
Auto-Regressive Transformers (BART) and its variants, and Bidirectional Encoder
Representations from Transformers (BERT), and its variant such as distilBERT,
SciBERT, PubmedBERT, BioBERT. Results: The classification results demonstrate
the effectiveness of LLMs in categorizing large number of ophthalmology papers
without human intervention. Results: To evalute the LLMs, we compiled a dataset
(RenD) of 1000 ocular disease-related articles, which were expertly annotated
by a panel of six specialists into 15 distinct categories. The model achieved
mean accuracy of 0.86 and mean F1 of 0.85 based on the RenD dataset.
Conclusion: The proposed framework achieves notable improvements in both
accuracy and efficiency. Its application in the domain of ophthalmology
showcases its potential for knowledge organization and retrieval in other
domains too. We performed trend analysis that enables the researchers and
clinicians to easily categorize and retrieve relevant papers, saving time and
effort in literature review and information gathering as well as identification
of emerging scientific trends within different disciplines. Moreover, the
extendibility of the model to other scientific fields broadens its impact in
facilitating research and trend analysis across diverse disciplines.
</p></li>
</ul>

<h3>Title: SpeechTokenizer: Unified Speech Tokenizer for Speech Large Language Models. (arXiv:2308.16692v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2308.16692">http://arxiv.org/abs/2308.16692</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2308.16692]] SpeechTokenizer: Unified Speech Tokenizer for Speech Large Language Models(http://arxiv.org/abs/2308.16692)</code></li>
<li>Summary: <p>Current speech large language models build upon discrete speech
representations, which can be categorized into semantic tokens and acoustic
tokens. However, existing speech tokens are not specifically designed for
speech language modeling. To assess the suitability of speech tokens for
building speech language models, we established the first benchmark,
SLMTokBench. Our results indicate that neither semantic nor acoustic tokens are
ideal for this purpose. Therefore, we propose SpeechTokenizer, a unified speech
tokenizer for speech large language models. SpeechTokenizer adopts the
Encoder-Decoder architecture with residual vector quantization (RVQ). Unifying
semantic and acoustic tokens, SpeechTokenizer disentangles different aspects of
speech information hierarchically across different RVQ layers. Furthermore, We
construct a Unified Speech Language Model (USLM) leveraging SpeechTokenizer.
Experiments show that SpeechTokenizer performs comparably to EnCodec in speech
reconstruction and demonstrates strong performance on the SLMTokBench
benchmark. Also, USLM outperforms VALL-E in zero-shot Text-to-Speech tasks.
Code and models are available at
https://github.com/ZhangXInFD/SpeechTokenizer/.
</p></li>
</ul>

<h3>Title: Ladder-of-Thought: Using Knowledge as Steps to Elevate Stance Detection. (arXiv:2308.16763v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2308.16763">http://arxiv.org/abs/2308.16763</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2308.16763]] Ladder-of-Thought: Using Knowledge as Steps to Elevate Stance Detection(http://arxiv.org/abs/2308.16763)</code></li>
<li>Summary: <p>Chain-of-Thought Prompting (CoT) reinforces the reasoning capabilities of
Large Language Models (LLMs) through the generation of intermediate rationales.
However, these enhancements predominantly benefit large-scale models, leaving
small LMs without significant performance improvements when directly applying
CoT. Despite the advanced reasoning capabilities of LLMs, CoT relies primarily
on their pre-trained internal knowledge. The external knowledge that is
previously unknown to the model remains unexploited. This omission becomes
pronounced in tasks such as stance detection, where the external background
knowledge plays a pivotal role. Additionally, the large-scale architecture of
LLMs inevitably present efficiency challenges during deployment. To address
these challenges, we introduce the Ladder-of-Thought (LoT) for stance
detection. Grounded in a dual-phase Cascaded Optimization framework, LoT
directs the model to incorporate high-quality external knowledge, enhancing the
intermediate rationales it generates. These bolstered rationales subsequently
serve as the foundation for more precise predictions - akin to how a ladder
facilitates reaching elevated goals. LoT achieves a balance between efficiency
and accuracy, making it an adaptable and efficient framework for stance
detection. Our empirical evaluations underscore LoT's effectiveness, marking a
16% improvement over ChatGPT and a 10% enhancement compared to ChatGPT with
CoT.
</p></li>
</ul>

<h3>Title: Can Programming Languages Boost Each Other via Instruction Tuning?. (arXiv:2308.16824v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2308.16824">http://arxiv.org/abs/2308.16824</a></li>
<li>Code URL: https://github.com/nl2code/codem</li>
<li>Copy Paste: <code><input type="checkbox">[[2308.16824]] Can Programming Languages Boost Each Other via Instruction Tuning?(http://arxiv.org/abs/2308.16824)</code></li>
<li>Summary: <p>When human programmers have mastered a programming language, it would be
easier when they learn a new programming language. In this report, we focus on
exploring whether programming languages can boost each other during the
instruction fine-tuning phase of code large language models. We conduct
extensive experiments of 8 popular programming languages (Python, JavaScript,
TypeScript, C, C++, Java, Go, HTML) on StarCoder. Results demonstrate that
programming languages can significantly improve each other. For example,
CodeM-Python 15B trained on Python is able to increase Java by an absolute
17.95% pass@1 on HumanEval-X. More surprisingly, we found that CodeM-HTML 7B
trained on the HTML corpus can improve Java by an absolute 15.24% pass@1. Our
training data is released at https://github.com/NL2Code/CodeM.
</p></li>
</ul>

<h3>Title: The Belebele Benchmark: a Parallel Reading Comprehension Dataset in 122 Language Variants. (arXiv:2308.16884v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2308.16884">http://arxiv.org/abs/2308.16884</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2308.16884]] The Belebele Benchmark: a Parallel Reading Comprehension Dataset in 122 Language Variants(http://arxiv.org/abs/2308.16884)</code></li>
<li>Summary: <p>We present Belebele, a multiple-choice machine reading comprehension (MRC)
dataset spanning 122 language variants. Significantly expanding the language
coverage of natural language understanding (NLU) benchmarks, this dataset
enables the evaluation of text models in high-, medium-, and low-resource
languages. Each question is based on a short passage from the Flores-200
dataset and has four multiple-choice answers. The questions were carefully
curated to discriminate between models with different levels of general
language comprehension. The English dataset on its own proves difficult enough
to challenge state-of-the-art language models. Being fully parallel, this
dataset enables direct comparison of model performance across all languages. We
use this dataset to evaluate the capabilities of multilingual masked language
models (MLMs) and large language models (LLMs). We present extensive results
and find that despite significant cross-lingual transfer in English-centric
LLMs, much smaller MLMs pretrained on balanced multilingual data still
understand far more languages. We also observe that larger vocabulary size and
conscious vocabulary construction correlate with better performance on
low-resource languages. Overall, Belebele opens up new avenues for evaluating
and analyzing the multilingual capabilities of NLP systems.
</p></li>
</ul>

<h3>Title: SARATHI: Efficient LLM Inference by Piggybacking Decodes with Chunked Prefills. (arXiv:2308.16369v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2308.16369">http://arxiv.org/abs/2308.16369</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2308.16369]] SARATHI: Efficient LLM Inference by Piggybacking Decodes with Chunked Prefills(http://arxiv.org/abs/2308.16369)</code></li>
<li>Summary: <p>Large Language Model (LLM) inference consists of two distinct phases -
prefill phase which processes the input prompt and decode phase which generates
output tokens autoregressively. While the prefill phase effectively saturates
GPU compute at small batch sizes, the decode phase results in low compute
utilization as it generates one token at a time per request. The varying
prefill and decode times also lead to imbalance across micro-batches when using
pipeline parallelism, resulting in further inefficiency due to bubbles.
</p>
<p>We present SARATHI to address these challenges. SARATHI employs
chunked-prefills, which splits a prefill request into equal sized chunks, and
decode-maximal batching, which constructs a batch using a single prefill chunk
and populates the remaining slots with decodes. During inference, the prefill
chunk saturates GPU compute, while the decode requests 'piggyback' and cost up
to an order of magnitude less compared to a decode-only batch. Chunked-prefills
allows constructing multiple decode-maximal batches from a single prefill
request, maximizing coverage of decodes that can piggyback. Furthermore, the
uniform compute design of these batches ameliorates the imbalance between
micro-batches, significantly reducing pipeline bubbles.
</p>
<p>Our techniques yield significant improvements in inference performance across
models and hardware. For the LLaMA-13B model on A6000 GPU, SARATHI improves
decode throughput by up to 10x, and accelerates end-to-end throughput by up to
1.33x. For LLaMa-33B on A100 GPU, we achieve 1.25x higher end-to-end-throughput
and up to 4.25x higher decode throughput. When used with pipeline parallelism
on GPT-3, SARATHI reduces bubbles by 6.29x, resulting in an end-to-end
throughput improvement of 1.91x.
</p></li>
</ul>

<h2>segmentation</h2>
<h3>Title: Domain Adaptive Synapse Detection with Weak Point Annotations. (arXiv:2308.16461v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2308.16461">http://arxiv.org/abs/2308.16461</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2308.16461]] Domain Adaptive Synapse Detection with Weak Point Annotations(http://arxiv.org/abs/2308.16461)</code></li>
<li>Summary: <p>The development of learning-based methods has greatly improved the detection
of synapses from electron microscopy (EM) images. However, training a model for
each dataset is time-consuming and requires extensive annotations.
Additionally, it is difficult to apply a learned model to data from different
brain regions due to variations in data distributions. In this paper, we
present AdaSyn, a two-stage segmentation-based framework for domain adaptive
synapse detection with weak point annotations. In the first stage, we address
the detection problem by utilizing a segmentation-based pipeline to obtain
synaptic instance masks. In the second stage, we improve model generalizability
on target data by regenerating square masks to get high-quality pseudo labels.
Benefiting from our high-accuracy detection results, we introduce the distance
nearest principle to match paired pre-synapses and post-synapses. In the
WASPSYN challenge at ISBI 2023, our method ranks the 1st place.
</p></li>
</ul>

<h3>Title: Self-Sampling Meta SAM: Enhancing Few-shot Medical Image Segmentation with Meta-Learning. (arXiv:2308.16466v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2308.16466">http://arxiv.org/abs/2308.16466</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2308.16466]] Self-Sampling Meta SAM: Enhancing Few-shot Medical Image Segmentation with Meta-Learning(http://arxiv.org/abs/2308.16466)</code></li>
<li>Summary: <p>While the Segment Anything Model (SAM) excels in semantic segmentation for
general-purpose images, its performance significantly deteriorates when applied
to medical images, primarily attributable to insufficient representation of
medical images in its training dataset. Nonetheless, gathering comprehensive
datasets and training models that are universally applicable is particularly
challenging due to the long-tail problem common in medical images. To address
this gap, here we present a Self-Sampling Meta SAM (SSM-SAM) framework for
few-shot medical image segmentation. Our innovation lies in the design of three
key modules: 1) An online fast gradient descent optimizer, further optimized by
a meta-learner, which ensures swift and robust adaptation to new tasks. 2) A
Self-Sampling module designed to provide well-aligned visual prompts for
improved attention allocation; and 3) A robust attention-based decoder
specifically designed for medical few-shot learning to capture relationship
between different slices. Extensive experiments on a popular abdominal CT
dataset and an MRI dataset demonstrate that the proposed method achieves
significant improvements over state-of-the-art methods in few-shot
segmentation, with an average improvements of 10.21% and 1.80% in terms of DSC,
respectively. In conclusion, we present a novel approach for rapid online
adaptation in interactive image segmentation, adapting to a new organ in just
0.83 minutes. Code is publicly available on GitHub upon acceptance.
</p></li>
</ul>

<h3>Title: SA6D: Self-Adaptive Few-Shot 6D Pose Estimator for Novel and Occluded Objects. (arXiv:2308.16528v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2308.16528">http://arxiv.org/abs/2308.16528</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2308.16528]] SA6D: Self-Adaptive Few-Shot 6D Pose Estimator for Novel and Occluded Objects(http://arxiv.org/abs/2308.16528)</code></li>
<li>Summary: <p>To enable meaningful robotic manipulation of objects in the real-world, 6D
pose estimation is one of the critical aspects. Most existing approaches have
difficulties to extend predictions to scenarios where novel object instances
are continuously introduced, especially with heavy occlusions. In this work, we
propose a few-shot pose estimation (FSPE) approach called SA6D, which uses a
self-adaptive segmentation module to identify the novel target object and
construct a point cloud model of the target object using only a small number of
cluttered reference images. Unlike existing methods, SA6D does not require
object-centric reference images or any additional object information, making it
a more generalizable and scalable solution across categories. We evaluate SA6D
on real-world tabletop object datasets and demonstrate that SA6D outperforms
existing FSPE methods, particularly in cluttered scenes with occlusions, while
requiring fewer reference images.
</p></li>
</ul>

<h3>Title: 3D-STMN: Dependency-Driven Superpoint-Text Matching Network for End-to-End 3D Referring Expression Segmentation. (arXiv:2308.16632v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2308.16632">http://arxiv.org/abs/2308.16632</a></li>
<li>Code URL: https://github.com/sosppxo/3d-stmn</li>
<li>Copy Paste: <code><input type="checkbox">[[2308.16632]] 3D-STMN: Dependency-Driven Superpoint-Text Matching Network for End-to-End 3D Referring Expression Segmentation(http://arxiv.org/abs/2308.16632)</code></li>
<li>Summary: <p>In 3D Referring Expression Segmentation (3D-RES), the earlier approach adopts
a two-stage paradigm, extracting segmentation proposals and then matching them
with referring expressions. However, this conventional paradigm encounters
significant challenges, most notably in terms of the generation of lackluster
initial proposals and a pronounced deceleration in inference speed. Recognizing
these limitations, we introduce an innovative end-to-end Superpoint-Text
Matching Network (3D-STMN) that is enriched by dependency-driven insights. One
of the keystones of our model is the Superpoint-Text Matching (STM) mechanism.
Unlike traditional methods that navigate through instance proposals, STM
directly correlates linguistic indications with their respective superpoints,
clusters of semantically related points. This architectural decision empowers
our model to efficiently harness cross-modal semantic relationships, primarily
leveraging densely annotated superpoint-text pairs, as opposed to the more
sparse instance-text pairs. In pursuit of enhancing the role of text in guiding
the segmentation process, we further incorporate the Dependency-Driven
Interaction (DDI) module to deepen the network's semantic comprehension of
referring expressions. Using the dependency trees as a beacon, this module
discerns the intricate relationships between primary terms and their associated
descriptors in expressions, thereby elevating both the localization and
segmentation capacities of our model. Comprehensive experiments on the
ScanRefer benchmark reveal that our model not only set new performance
standards, registering an mIoU gain of 11.7 points but also achieve a
staggering enhancement in inference speed, surpassing traditional methods by
95.7 times. The code and models are available at
https://github.com/sosppxo/3D-STMN.
</p></li>
</ul>

<h3>Title: Semi-Supervised SAR ATR Framework with Transductive Auxiliary Segmentation. (arXiv:2308.16633v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2308.16633">http://arxiv.org/abs/2308.16633</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2308.16633]] Semi-Supervised SAR ATR Framework with Transductive Auxiliary Segmentation(http://arxiv.org/abs/2308.16633)</code></li>
<li>Summary: <p>Convolutional neural networks (CNNs) have achieved high performance in
synthetic aperture radar (SAR) automatic target recognition (ATR). However, the
performance of CNNs depends heavily on a large amount of training data. The
insufficiency of labeled training SAR images limits the recognition performance
and even invalidates some ATR methods. Furthermore, under few labeled training
data, many existing CNNs are even ineffective. To address these challenges, we
propose a Semi-supervised SAR ATR Framework with transductive Auxiliary
Segmentation (SFAS). The proposed framework focuses on exploiting the
transductive generalization on available unlabeled samples with an auxiliary
loss serving as a regularizer. Through auxiliary segmentation of unlabeled SAR
samples and information residue loss (IRL) in training, the framework can
employ the proposed training loop process and gradually exploit the information
compilation of recognition and segmentation to construct a helpful inductive
bias and achieve high performance. Experiments conducted on the MSTAR dataset
have shown the effectiveness of our proposed SFAS for few-shot learning. The
recognition performance of 94.18\% can be achieved under 20 training samples in
each class with simultaneous accurate segmentation results. Facing variances of
EOCs, the recognition ratios are higher than 88.00\% when 10 training samples
each class.
</p></li>
</ul>

<h3>Title: Parsing is All You Need for Accurate Gait Recognition in the Wild. (arXiv:2308.16739v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2308.16739">http://arxiv.org/abs/2308.16739</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2308.16739]] Parsing is All You Need for Accurate Gait Recognition in the Wild(http://arxiv.org/abs/2308.16739)</code></li>
<li>Summary: <p>Binary silhouettes and keypoint-based skeletons have dominated human gait
recognition studies for decades since they are easy to extract from video
frames. Despite their success in gait recognition for in-the-lab environments,
they usually fail in real-world scenarios due to their low information entropy
for gait representations. To achieve accurate gait recognition in the wild,
this paper presents a novel gait representation, named Gait Parsing Sequence
(GPS). GPSs are sequences of fine-grained human segmentation, i.e., human
parsing, extracted from video frames, so they have much higher information
entropy to encode the shapes and dynamics of fine-grained human parts during
walking. Moreover, to effectively explore the capability of the GPS
representation, we propose a novel human parsing-based gait recognition
framework, named ParsingGait. ParsingGait contains a Convolutional Neural
Network (CNN)-based backbone and two light-weighted heads. The first head
extracts global semantic features from GPSs, while the other one learns mutual
information of part-level features through Graph Convolutional Networks to
model the detailed dynamics of human walking. Furthermore, due to the lack of
suitable datasets, we build the first parsing-based dataset for gait
recognition in the wild, named Gait3D-Parsing, by extending the large-scale and
challenging Gait3D dataset. Based on Gait3D-Parsing, we comprehensively
evaluate our method and existing gait recognition methods. The experimental
results show a significant improvement in accuracy brought by the GPS
representation and the superiority of ParsingGait. The code and dataset are
available at https://gait3d.github.io/gait3d-parsing-hp .
</p></li>
</ul>

<h3>Title: BTSeg: Barlow Twins Regularization for Domain Adaptation in Semantic Segmentation. (arXiv:2308.16819v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2308.16819">http://arxiv.org/abs/2308.16819</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2308.16819]] BTSeg: Barlow Twins Regularization for Domain Adaptation in Semantic Segmentation(http://arxiv.org/abs/2308.16819)</code></li>
<li>Summary: <p>Semantic image segmentation is a critical component in many computer vision
systems, such as autonomous driving. In such applications, adverse conditions
(heavy rain, night time, snow, extreme lighting) on the one hand pose specific
challenges, yet are typically underrepresented in the available datasets.
Generating more training data is cumbersome and expensive, and the process
itself is error-prone due to the inherent aleatoric uncertainty. To address
this challenging problem, we propose BTSeg, which exploits image-level
correspondences as weak supervision signal to learn a segmentation model that
is agnostic to adverse conditions. To this end, our approach uses the Barlow
twins loss from the field of unsupervised learning and treats images taken at
the same location but under different adverse conditions as "augmentations" of
the same unknown underlying base image. This allows the training of a
segmentation model that is robust to appearance changes introduced by different
adverse conditions. We evaluate our approach on ACDC and the new challenging
ACG benchmark to demonstrate its robustness and generalization capabilities.
Our approach performs favorably when compared to the current state-of-the-art
methods, while also being simpler to implement and train. The code will be
released upon acceptance.
</p></li>
</ul>

<h3>Title: Coarse-to-Fine Amodal Segmentation with Shape Prior. (arXiv:2308.16825v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2308.16825">http://arxiv.org/abs/2308.16825</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2308.16825]] Coarse-to-Fine Amodal Segmentation with Shape Prior(http://arxiv.org/abs/2308.16825)</code></li>
<li>Summary: <p>Amodal object segmentation is a challenging task that involves segmenting
both visible and occluded parts of an object. In this paper, we propose a novel
approach, called Coarse-to-Fine Segmentation (C2F-Seg), that addresses this
problem by progressively modeling the amodal segmentation. C2F-Seg initially
reduces the learning space from the pixel-level image space to the
vector-quantized latent space. This enables us to better handle long-range
dependencies and learn a coarse-grained amodal segment from visual features and
visible segments. However, this latent space lacks detailed information about
the object, which makes it difficult to provide a precise segmentation
directly. To address this issue, we propose a convolution refine module to
inject fine-grained information and provide a more precise amodal object
segmentation based on visual features and coarse-predicted segmentation. To
help the studies of amodal object segmentation, we create a synthetic amodal
dataset, named as MOViD-Amodal (MOViD-A), which can be used for both image and
video amodal object segmentation. We extensively evaluate our model on two
benchmark datasets: KINS and COCO-A. Our empirical results demonstrate the
superiority of C2F-Seg. Moreover, we exhibit the potential of our approach for
video amodal object segmentation tasks on FISHBOWL and our proposed MOViD-A.
Project page at: <a href="http://jianxgao.github.io/C2F-Seg.">this http URL</a>
</p></li>
</ul>

<h3>Title: Holistic Processing of Colour Images Using Novel Quaternion-Valued Wavelets on the Plane. (arXiv:2308.16875v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2308.16875">http://arxiv.org/abs/2308.16875</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2308.16875]] Holistic Processing of Colour Images Using Novel Quaternion-Valued Wavelets on the Plane(http://arxiv.org/abs/2308.16875)</code></li>
<li>Summary: <p>We investigate the applicability of quaternion-valued wavelets on the plane
to holistic colour image processing. We present a methodology for decomposing
and reconstructing colour images using quaternionic wavelet filters associated
to recently developed quaternion-valued wavelets on the plane. We consider
compression, enhancement, segmentation, and denoising techniques to demonstrate
quaternion-valued wavelets as a promising tool for holistic colour image
processing.
</p></li>
</ul>

<h3>Title: SportsSloMo: A New Benchmark and Baselines for Human-centric Video Frame Interpolation. (arXiv:2308.16876v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2308.16876">http://arxiv.org/abs/2308.16876</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2308.16876]] SportsSloMo: A New Benchmark and Baselines for Human-centric Video Frame Interpolation(http://arxiv.org/abs/2308.16876)</code></li>
<li>Summary: <p>Human-centric video frame interpolation has great potential for improving
people's entertainment experiences and finding commercial applications in the
sports analysis industry, e.g., synthesizing slow-motion videos. Although there
are multiple benchmark datasets available in the community, none of them is
dedicated for human-centric scenarios. To bridge this gap, we introduce
SportsSloMo, a benchmark consisting of more than 130K video clips and 1M video
frames of high-resolution ($\geq$720p) slow-motion sports videos crawled from
YouTube. We re-train several state-of-the-art methods on our benchmark, and the
results show a decrease in their accuracy compared to other datasets. It
highlights the difficulty of our benchmark and suggests that it poses
significant challenges even for the best-performing methods, as human bodies
are highly deformable and occlusions are frequent in sports videos. To improve
the accuracy, we introduce two loss terms considering the human-aware priors,
where we add auxiliary supervision to panoptic segmentation and human keypoints
detection, respectively. The loss terms are model agnostic and can be easily
plugged into any video frame interpolation approaches. Experimental results
validate the effectiveness of our proposed loss terms, leading to consistent
performance improvement over 5 existing models, which establish strong baseline
models on our benchmark. The dataset and code can be found at:
https://neu-vi.github.io/SportsSlomo/.
</p></li>
</ul>

<h3>Title: Text2Scene: Text-driven Indoor Scene Stylization with Part-aware Details. (arXiv:2308.16880v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2308.16880">http://arxiv.org/abs/2308.16880</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2308.16880]] Text2Scene: Text-driven Indoor Scene Stylization with Part-aware Details(http://arxiv.org/abs/2308.16880)</code></li>
<li>Summary: <p>We propose Text2Scene, a method to automatically create realistic textures
for virtual scenes composed of multiple objects. Guided by a reference image
and text descriptions, our pipeline adds detailed texture on labeled 3D
geometries in the room such that the generated colors respect the hierarchical
structure or semantic parts that are often composed of similar materials.
Instead of applying flat stylization on the entire scene at a single step, we
obtain weak semantic cues from geometric segmentation, which are further
clarified by assigning initial colors to segmented parts. Then we add texture
details for individual objects such that their projections on image space
exhibit feature embedding aligned with the embedding of the input. The
decomposition makes the entire pipeline tractable to a moderate amount of
computation resources and memory. As our framework utilizes the existing
resources of image and text embedding, it does not require dedicated datasets
with high-quality textures designed by skillful artists. To the best of our
knowledge, it is the first practical and scalable approach that can create
detailed and realistic textures of the desired style that maintain structural
context for scenes with multiple objects.
</p></li>
</ul>

<h3>Title: PointOcc: Cylindrical Tri-Perspective View for Point-based 3D Semantic Occupancy Prediction. (arXiv:2308.16896v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2308.16896">http://arxiv.org/abs/2308.16896</a></li>
<li>Code URL: https://github.com/wzzheng/pointocc</li>
<li>Copy Paste: <code><input type="checkbox">[[2308.16896]] PointOcc: Cylindrical Tri-Perspective View for Point-based 3D Semantic Occupancy Prediction(http://arxiv.org/abs/2308.16896)</code></li>
<li>Summary: <p>Semantic segmentation in autonomous driving has been undergoing an evolution
from sparse point segmentation to dense voxel segmentation, where the objective
is to predict the semantic occupancy of each voxel in the concerned 3D space.
The dense nature of the prediction space has rendered existing efficient
2D-projection-based methods (e.g., bird's eye view, range view, etc.)
ineffective, as they can only describe a subspace of the 3D scene. To address
this, we propose a cylindrical tri-perspective view to represent point clouds
effectively and comprehensively and a PointOcc model to process them
efficiently. Considering the distance distribution of LiDAR point clouds, we
construct the tri-perspective view in the cylindrical coordinate system for
more fine-grained modeling of nearer areas. We employ spatial group pooling to
maintain structural details during projection and adopt 2D backbones to
efficiently process each TPV plane. Finally, we obtain the features of each
point by aggregating its projected features on each of the processed TPV planes
without the need for any post-processing. Extensive experiments on both 3D
occupancy prediction and LiDAR segmentation benchmarks demonstrate that the
proposed PointOcc achieves state-of-the-art performance with much faster speed.
Specifically, despite only using LiDAR, PointOcc significantly outperforms all
other methods, including multi-modal methods, with a large margin on the
OpenOccupancy benchmark. Code: https://github.com/wzzheng/PointOcc.
</p></li>
</ul>

<h3>Title: DictaBERT: A State-of-the-Art BERT Suite for Modern Hebrew. (arXiv:2308.16687v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2308.16687">http://arxiv.org/abs/2308.16687</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2308.16687]] DictaBERT: A State-of-the-Art BERT Suite for Modern Hebrew(http://arxiv.org/abs/2308.16687)</code></li>
<li>Summary: <p>We present DictaBERT, a new state-of-the-art pre-trained BERT model for
modern Hebrew, outperforming existing models on most benchmarks. Additionally,
we release two fine-tuned versions of the model, designed to perform two
specific foundational tasks in the analysis of Hebrew texts: prefix
segmentation and morphological tagging. These fine-tuned models allow any
developer to perform prefix segmentation and morphological tagging of a Hebrew
sentence with a single call to a HuggingFace model, without the need to
integrate any additional libraries or code. In this paper we describe the
details of the training as well and the results on the different benchmarks. We
release the models to the community, along with sample code demonstrating their
use. We release these models as part of our goal to help further research and
development in Hebrew NLP.
</p></li>
</ul>

<h3>Title: Constructing Indoor Region-based Radio Map without Location Labels. (arXiv:2308.16759v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2308.16759">http://arxiv.org/abs/2308.16759</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2308.16759]] Constructing Indoor Region-based Radio Map without Location Labels(http://arxiv.org/abs/2308.16759)</code></li>
<li>Summary: <p>Radio map construction requires a large amount of radio measurement data with
location labels, which imposes a high deployment cost. This paper develops a
region-based radio map from received signal strength (RSS) measurements without
location labels. The construction is based on a set of blindly collected RSS
measurement data from a device that visits each region in an indoor area
exactly once, where the footprints and timestamps are not recorded. The main
challenge is to cluster the RSS data and match clusters with the physical
regions. Classical clustering algorithms fail to work as the RSS data naturally
appears as non-clustered due to multipaths and noise. In this paper, a signal
subspace model with a sequential prior is constructed for the RSS data, and an
integrated segmentation and clustering algorithm is developed, which is shown
to find the globally optimal solution in a special case. Furthermore, the
clustered data is matched with the physical regions using a graph-based
approach. Based on real measurements from an office space, the proposed scheme
reduces the region localization error by roughly 50% compared to a weighted
centroid localization (WCL) baseline, and it even outperforms some supervised
localization schemes, including k-nearest neighbor (KNN), support vector
machine (SVM), and deep neural network (DNN), which require labeled data for
training.
</p></li>
</ul>

<button id="copy">Copy All</button>
</article>
<script src="../../javascript/clipboard.min.js"></script>
<script src="../../javascript/clipboard.js"></script>
