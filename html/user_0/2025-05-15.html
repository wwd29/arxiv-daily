<link rel="stylesheet" href="../../css/markdown.css" />
<article class="markdown-body">
<h1>2025-05-15</h1>
<h3>Title: Post-Quantum Cryptography: An Analysis of Code-Based and Lattice-Based Cryptosystems</h3>
<ul>
<li><strong>Authors: </strong>Alexander Meyer</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.IT</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.08791">https://arxiv.org/abs/2505.08791</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.08791">https://arxiv.org/pdf/2505.08791</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.08791]] Post-Quantum Cryptography: An Analysis of Code-Based and Lattice-Based Cryptosystems(https://arxiv.org/abs/2505.08791)</code><input type="text"></li>
<li><strong>Keywords: </strong>secure, security, attack</a></li>
<li><strong>Abstract: </strong>Most modern cryptographic systems, such as RSA and the Diffie-Hellman Key Exchange, rely on "trapdoor" mathematical functions that are presumed to be computationally difficult with existing tools. However, quantum computers will be able to break these systems using Shor's Algorithm, necessitating the development of quantum-resistant alternatives. We first examine the McEliece cryptosystem, a code-based scheme believed to be secure against quantum attacks due to the hardness of decoding arbitrary linear codes. We then explore NTRU, a lattice-based system grounded in the difficulty of solving the Shortest Vector Problem. Finally, we establish connections between the structural foundations and security of the two systems.</li>
</ul>

<h3>Title: Onboard Optimization and Learning: A Survey</h3>
<ul>
<li><strong>Authors: </strong>Monirul Islam Pavel, Siyi Hu, Mahardhika Pratama, Ryszard Kowalczyk</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.08793">https://arxiv.org/abs/2505.08793</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.08793">https://arxiv.org/pdf/2505.08793</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.08793]] Onboard Optimization and Learning: A Survey(https://arxiv.org/abs/2505.08793)</code><input type="text"></li>
<li><strong>Keywords: </strong>secure, security, privacy, robust</a></li>
<li><strong>Abstract: </strong>Onboard learning is a transformative approach in edge AI, enabling real-time data processing, decision-making, and adaptive model training directly on resource-constrained devices without relying on centralized servers. This paradigm is crucial for applications demanding low latency, enhanced privacy, and energy efficiency. However, onboard learning faces challenges such as limited computational resources, high inference costs, and security vulnerabilities. This survey explores a comprehensive range of methodologies that address these challenges, focusing on techniques that optimize model efficiency, accelerate inference, and support collaborative learning across distributed devices. Approaches for reducing model complexity, improving inference speed, and ensuring privacy-preserving computation are examined alongside emerging strategies that enhance scalability and adaptability in dynamic environments. By bridging advancements in hardware-software co-design, model compression, and decentralized learning, this survey provides insights into the current state of onboard learning to enable robust, efficient, and secure AI deployment at the edge.</li>
</ul>

<h3>Title: Measuring Security in 5G and Future Networks</h3>
<ul>
<li><strong>Authors: </strong>Loay Abdelrazek, Rim ElMalki, Filippo Rebecchi, Daniel Cho</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.08799">https://arxiv.org/abs/2505.08799</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.08799">https://arxiv.org/pdf/2505.08799</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.08799]] Measuring Security in 5G and Future Networks(https://arxiv.org/abs/2505.08799)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, attack</a></li>
<li><strong>Abstract: </strong>In today's increasingly interconnected and fast-paced digital ecosystem, mobile networks, such as 5G and future generations such as 6G, play a pivotal role and must be considered as critical infrastructures. Ensuring their security is paramount to safeguard both individual users and the industries that depend on these networks. An essential condition for maintaining and improving the security posture of a system is the ability to effectively measure and monitor its security state. In this work we address the need for an objective measurement of the security state of 5G and future networks. We introduce a state machine model designed to capture the security life cycle of network functions and the transitions between different states within the life cycle. Such a model can be computed locally at each node, or hierarchically, by aggregating measurements into security domains or the whole network. We identify three essential security metrics -- attack surface exposure, impact of system vulnerabilities, and effectiveness of applied security controls -- that collectively form the basis for calculating the overall security score. With this approach, it is possible to provide a holistic understanding of the security posture, laying the foundation for effective security management in the expected dynamic threat landscape of 6G networks. Through practical examples, we illustrate the real-world application of our proposed methodology, offering valuable insights for developing risk management and informed decision-making strategies in 5G and 6G security operations and laying the foundation for effective security management in the expected dynamic threat landscape of 6G networks.</li>
</ul>

<h3>Title: Multi-modal Synthetic Data Training and Model Collapse: Insights from VLMs and Diffusion Models</h3>
<ul>
<li><strong>Authors: </strong>Zizhao Hu, Mohammad Rostami, Jesse Thomason</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.08803">https://arxiv.org/abs/2505.08803</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.08803">https://arxiv.org/pdf/2505.08803</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.08803]] Multi-modal Synthetic Data Training and Model Collapse: Insights from VLMs and Diffusion Models(https://arxiv.org/abs/2505.08803)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, diffusion, generative</a></li>
<li><strong>Abstract: </strong>Recent research has highlighted the risk of generative model collapse, where performance progressively degrades when continually trained on self-generated data. However, existing exploration on model collapse is limited to single, unimodal models, limiting our understanding in more realistic scenarios, such as diverse multi-modal AI agents interacting autonomously through synthetic data and continually evolving. We expand the synthetic data training and model collapse study to multi-modal vision-language generative systems, such as vision-language models (VLMs) and text-to-image diffusion models, as well as recursive generate-train loops with multiple models. We find that model collapse, previously observed in single-modality generative models, exhibits distinct characteristics in the multi-modal context, such as improved vision-language alignment and increased variance in VLM image-captioning task. Additionally, we find that general approaches such as increased decoding budgets, greater model diversity, and relabeling with frozen models can effectively mitigate model collapse. Our findings provide initial insights and practical guidelines for reducing the risk of model collapse in self-improving multi-agent AI systems and curating robust multi-modal synthetic datasets.</li>
</ul>

<h3>Title: TokenProber: Jailbreaking Text-to-image Models via Fine-grained Word Impact Analysis</h3>
<ul>
<li><strong>Authors: </strong>Longtian Wang, Xiaofei Xie, Tianlin Li, Yuhan Zhi, Chao Shen</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.08804">https://arxiv.org/abs/2505.08804</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.08804">https://arxiv.org/pdf/2505.08804</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.08804]] TokenProber: Jailbreaking Text-to-image Models via Fine-grained Word Impact Analysis(https://arxiv.org/abs/2505.08804)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Text-to-image (T2I) models have significantly advanced in producing high-quality images. However, such models have the ability to generate images containing not-safe-for-work (NSFW) content, such as pornography, violence, political content, and discrimination. To mitigate the risk of generating NSFW content, refusal mechanisms, i.e., safety checkers, have been developed to check potential NSFW content. Adversarial prompting techniques have been developed to evaluate the robustness of the refusal mechanisms. The key challenge remains to subtly modify the prompt in a way that preserves its sensitive nature while bypassing the refusal mechanisms. In this paper, we introduce TokenProber, a method designed for sensitivity-aware differential testing, aimed at evaluating the robustness of the refusal mechanisms in T2I models by generating adversarial prompts. Our approach is based on the key observation that adversarial prompts often succeed by exploiting discrepancies in how T2I models and safety checkers interpret sensitive content. Thus, we conduct a fine-grained analysis of the impact of specific words within prompts, distinguishing between dirty words that are essential for NSFW content generation and discrepant words that highlight the different sensitivity assessments between T2I models and safety checkers. Through the sensitivity-aware mutation, TokenProber generates adversarial prompts, striking a balance between maintaining NSFW content generation and evading detection. Our evaluation of TokenProber against 5 safety checkers on 3 popular T2I models, using 324 NSFW prompts, demonstrates its superior effectiveness in bypassing safety filters compared to existing methods (e.g., 54%+ increase on average), highlighting TokenProber's ability to uncover robustness issues in the existing refusal mechanisms.</li>
</ul>

<h3>Title: Security of Internet of Agents: Attacks and Countermeasures</h3>
<ul>
<li><strong>Authors: </strong>Yuntao Wang, Yanghe Pan, Shaolong Guo, Zhou Su</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.08807">https://arxiv.org/abs/2505.08807</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.08807">https://arxiv.org/pdf/2505.08807</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.08807]] Security of Internet of Agents: Attacks and Countermeasures(https://arxiv.org/abs/2505.08807)</code><input type="text"></li>
<li><strong>Keywords: </strong>secure, security, privacy, defense, attack</a></li>
<li><strong>Abstract: </strong>With the rise of large language and vision-language models, AI agents have evolved into autonomous, interactive systems capable of perception, reasoning, and decision-making. As they proliferate across virtual and physical domains, the Internet of Agents (IoA) has emerged as a key infrastructure for enabling scalable and secure coordination among heterogeneous agents. This survey offers a comprehensive examination of the security and privacy landscape in IoA systems. We begin by outlining the IoA architecture and its distinct vulnerabilities compared to traditional networks, focusing on four critical aspects: identity authentication threats, cross-agent trust issues, embodied security, and privacy risks. We then review existing and emerging defense mechanisms and highlight persistent challenges. Finally, we identify open research directions to advance the development of resilient and privacy-preserving IoA ecosystems.</li>
</ul>

<h3>Title: SparseMeXT Unlocking the Potential of Sparse Representations for HD Map Construction</h3>
<ul>
<li><strong>Authors: </strong>Anqing Jiang, Jinhao Chai, Yu Gao, Yiru Wang, Yuwen Heng, Zhigang Sun, Hao Sun, Zezhong Zhao, Li Sun, Jian Zhou, Lijuan Zhu, Shugong Xu, Hao Zhao</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.08808">https://arxiv.org/abs/2505.08808</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.08808">https://arxiv.org/pdf/2505.08808</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.08808]] SparseMeXT Unlocking the Potential of Sparse Representations for HD Map Construction(https://arxiv.org/abs/2505.08808)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction, segmentation</a></li>
<li><strong>Abstract: </strong>Recent advancements in high-definition \emph{HD} map construction have demonstrated the effectiveness of dense representations, which heavily rely on computationally intensive bird's-eye view \emph{BEV} features. While sparse representations offer a more efficient alternative by avoiding dense BEV processing, existing methods often lag behind due to the lack of tailored designs. These limitations have hindered the competitiveness of sparse representations in online HD map construction. In this work, we systematically revisit and enhance sparse representation techniques, identifying key architectural and algorithmic improvements that bridge the gap with--and ultimately surpass--dense approaches. We introduce a dedicated network architecture optimized for sparse map feature extraction, a sparse-dense segmentation auxiliary task to better leverage geometric and semantic cues, and a denoising module guided by physical priors to refine predictions. Through these enhancements, our method achieves state-of-the-art performance on the nuScenes dataset, significantly advancing HD map construction and centerline detection. Specifically, SparseMeXt-Tiny reaches a mean average precision \emph{mAP} of 55.5% at 32 frames per second \emph{fps}, while SparseMeXt-Base attains 65.2% mAP. Scaling the backbone and decoder further, SparseMeXt-Large achieves an mAP of 68.9% at over 20 fps, establishing a new benchmark for sparse representations in HD map construction. These results underscore the untapped potential of sparse methods, challenging the conventional reliance on dense representations and redefining efficiency-performance trade-offs in the field.</li>
</ul>

<h3>Title: MixBridge: Heterogeneous Image-to-Image Backdoor Attack through Mixture of Schrödinger Bridges</h3>
<ul>
<li><strong>Authors: </strong>Shixi Qin, Zhiyong Yang, Shilong Bao, Shi Wang, Qianqian Xu, Qingming Huang</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.08809">https://arxiv.org/abs/2505.08809</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.08809">https://arxiv.org/pdf/2505.08809</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.08809]] MixBridge: Heterogeneous Image-to-Image Backdoor Attack through Mixture of Schrödinger Bridges(https://arxiv.org/abs/2505.08809)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack, steal, diffusion</a></li>
<li><strong>Abstract: </strong>This paper focuses on implanting multiple heterogeneous backdoor triggers in bridge-based diffusion models designed for complex and arbitrary input distributions. Existing backdoor formulations mainly address single-attack scenarios and are limited to Gaussian noise input models. To fill this gap, we propose MixBridge, a novel diffusion Schrödinger bridge (DSB) framework to cater to arbitrary input distributions (taking I2I tasks as special cases). Beyond this trait, we demonstrate that backdoor triggers can be injected into MixBridge by directly training with poisoned image pairs. This eliminates the need for the cumbersome modifications to stochastic differential equations required in previous studies, providing a flexible tool to study backdoor behavior for bridge models. However, a key question arises: can a single DSB model train multiple backdoor triggers? Unfortunately, our theory shows that when attempting this, the model ends up following the geometric mean of benign and backdoored distributions, leading to performance conflict across backdoor tasks. To overcome this, we propose a Divide-and-Merge strategy to mix different bridges, where models are independently pre-trained for each specific objective (Divide) and then integrated into a unified model (Merge). In addition, a Weight Reallocation Scheme (WRS) is also designed to enhance the stealthiness of MixBridge. Empirical studies across diverse generation tasks speak to the efficacy of MixBridge.</li>
</ul>

<h3>Title: Machine Learning-Based Detection of DDoS Attacks in VANETs for Emergency Vehicle Communication</h3>
<ul>
<li><strong>Authors: </strong>Bappa Muktar, Vincent Fono, Adama Nouboukpo</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.08810">https://arxiv.org/abs/2505.08810</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.08810">https://arxiv.org/pdf/2505.08810</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.08810]] Machine Learning-Based Detection of DDoS Attacks in VANETs for Emergency Vehicle Communication(https://arxiv.org/abs/2505.08810)</code><input type="text"></li>
<li><strong>Keywords: </strong>secure, attack, robust</a></li>
<li><strong>Abstract: </strong>Vehicular Ad Hoc Networks (VANETs) play a key role in Intelligent Transportation Systems (ITS), particularly in enabling real-time communication for emergency vehicles. However, Distributed Denial of Service (DDoS) attacks, which interfere with safety-critical communication channels, can severely impair their reliability. This study introduces a robust and scalable framework to detect DDoS attacks in highway-based VANET environments. A synthetic dataset was constructed using Network Simulator 3 (NS-3) in conjunction with the Simulation of Urban Mobility (SUMO) and further enriched with real-world mobility traces from Germany's A81 highway, extracted via OpenStreetMap (OSM). Three traffic categories were simulated: DDoS, VoIP, and TCP-based video streaming (VideoTCP). The data preprocessing pipeline included normalization, signal-to-noise ratio (SNR) feature engineering, missing value imputation, and class balancing using the Synthetic Minority Over-sampling Technique (SMOTE). Feature importance was assessed using SHapley Additive exPlanations (SHAP). Eleven classifiers were benchmarked, among them XGBoost (XGB), CatBoost (CB), AdaBoost (AB), GradientBoosting (GB), and an Artificial Neural Network (ANN). XGB and CB achieved the best performance, each attaining an F1-score of 96%. These results highlight the robustness of the proposed framework and its potential for real-time deployment in VANETs to secure critical emergency communications.</li>
</ul>

<h3>Title: Towards Understanding Deep Learning Model in Image Recognition via Coverage Test</h3>
<ul>
<li><strong>Authors: </strong>Wenkai Li, Xiaoqi Li, Yingjie Mao, Yishun Wang</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.08814">https://arxiv.org/abs/2505.08814</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.08814">https://arxiv.org/pdf/2505.08814</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.08814]] Towards Understanding Deep Learning Model in Image Recognition via Coverage Test(https://arxiv.org/abs/2505.08814)</code><input type="text"></li>
<li><strong>Keywords: </strong>security</a></li>
<li><strong>Abstract: </strong>Deep neural networks (DNNs) play a crucial role in the field of artificial intelligence, and their security-related testing has been a prominent research focus. By inputting test cases, the behavior of models is examined for anomalies, and coverage metrics are utilized to determine the extent of neurons covered by these test cases. With the widespread application and advancement of DNNs, different types of neural behaviors have garnered attention, leading to the emergence of various coverage metrics for neural networks. However, there is currently a lack of empirical research on these coverage metrics, specifically in analyzing the relationships and patterns between model depth, configuration information, and neural network coverage. This paper aims to investigate the relationships and patterns of four coverage metrics: primary functionality, boundary, hierarchy, and structural coverage. A series of empirical experiments were conducted, selecting LeNet, VGG, and ResNet as different DNN architectures, along with 10 models of varying depths ranging from 5 to 54 layers, to compare and study the relationships between different depths, configuration information, and various neural network coverage metrics. Additionally, an investigation was carried out on the relationships between modified decision/condition coverage and dataset size. Finally, three potential future directions are proposed to further contribute to the security testing of DNN Models.</li>
</ul>

<h3>Title: Self-Supervised Transformer-based Contrastive Learning for Intrusion Detection Systems</h3>
<ul>
<li><strong>Authors: </strong>Ippokratis Koukoulis, Ilias Syrigos, Thanasis Korakis</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.08816">https://arxiv.org/abs/2505.08816</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.08816">https://arxiv.org/pdf/2505.08816</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.08816]] Self-Supervised Transformer-based Contrastive Learning for Intrusion Detection Systems(https://arxiv.org/abs/2505.08816)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack, transformer</a></li>
<li><strong>Abstract: </strong>As the digital landscape becomes more interconnected, the frequency and severity of zero-day attacks, have significantly increased, leading to an urgent need for innovative Intrusion Detection Systems (IDS). Machine Learning-based IDS that learn from the network traffic characteristics and can discern attack patterns from benign traffic offer an advanced solution to traditional signature-based IDS. However, they heavily rely on labeled datasets, and their ability to generalize when encountering unseen traffic patterns remains a challenge. This paper proposes a novel self-supervised contrastive learning approach based on transformer encoders, specifically tailored for generalizable intrusion detection on raw packet sequences. Our proposed learning scheme employs a packet-level data augmentation strategy combined with a transformer-based architecture to extract and generate meaningful representations of traffic flows. Unlike traditional methods reliant on handcrafted statistical features (NetFlow), our approach automatically learns comprehensive packet sequence representations, significantly enhancing performance in anomaly identification tasks and supervised learning for intrusion detection. Our transformer-based framework exhibits better performance in comparison to existing NetFlow self-supervised methods. Specifically, we achieve up to a 3% higher AUC in anomaly detection for intra-dataset evaluation and up to 20% higher AUC scores in inter-dataset evaluation. Moreover, our model provides a strong baseline for supervised intrusion detection with limited labeled data, exhibiting an improvement over self-supervised NetFlow models of up to 1.5% AUC when pretrained and evaluated on the same dataset. Additionally, we show the adaptability of our pretrained model when fine-tuned across different datasets, demonstrating strong performance even when lacking benign data from the target domain.</li>
</ul>

<h3>Title: Towards SFW sampling for diffusion models via external conditioning</h3>
<ul>
<li><strong>Authors: </strong>Camilo Carvajal Reyes, Joaquín Fontbona, Felipe Tobar</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.08817">https://arxiv.org/abs/2505.08817</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.08817">https://arxiv.org/pdf/2505.08817</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.08817]] Towards SFW sampling for diffusion models via external conditioning(https://arxiv.org/abs/2505.08817)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, generative</a></li>
<li><strong>Abstract: </strong>Score-based generative models (SBM), also known as diffusion models, are the de facto state of the art for image synthesis. Despite their unparalleled performance, SBMs have recently been in the spotlight for being tricked into creating not-safe-for-work (NSFW) content, such as violent images and non-consensual nudity. Current approaches that prevent unsafe generation are based on the models' own knowledge, and the majority of them require fine-tuning. This article explores the use of external sources for ensuring safe outputs in SBMs. Our safe-for-work (SFW) sampler implements a Conditional Trajectory Correction step that guides the samples away from undesired regions in the ambient space using multimodal models as the source of conditioning. Furthermore, using Contrastive Language Image Pre-training (CLIP), our method admits user-defined NSFW classes, which can vary in different settings. Our experiments on the text-to-image SBM Stable Diffusion validate that the proposed SFW sampler effectively reduces the generation of explicit content while being competitive with other fine-tuning-based approaches, as assessed via independent NSFW detectors. Moreover, we evaluate the impact of the SFW sampler on image quality and show that the proposed correction scheme comes at a minor cost with negligible effect on samples not needing correction. Our study confirms the suitability of the SFW sampler towards aligned SBM models and the potential of using model-agnostic conditioning for the prevention of unwanted images.</li>
</ul>

<h3>Title: An Extra RMSNorm is All You Need for Fine Tuning to 1.58 Bits</h3>
<ul>
<li><strong>Authors: </strong>Cody Steinmetz, Gavin Childress, Aaron Herbst, Gavin Jones, Jasdeep Singh, Eli Vang, Keagan Weinstock</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.08823">https://arxiv.org/abs/2505.08823</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.08823">https://arxiv.org/pdf/2505.08823</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.08823]] An Extra RMSNorm is All You Need for Fine Tuning to 1.58 Bits(https://arxiv.org/abs/2505.08823)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer, large language model</a></li>
<li><strong>Abstract: </strong>Large language models (LLMs) have transformed natural-language processing, yet their scale makes real-world deployment costly. Post-training quantization reduces memory and computation but often degrades accuracy, while quantization-aware training can recover performance at the cost of extra training. Pushing quantization to the ternary (2-bit) regime yields even larger savings but is notoriously unstable. Building on recent work showing that a bias-free, RMS-normalized Transformer with straight-through estimation can reach 1.58-bit precision, we demonstrate that simply inserting RMS normalization before every linear projection and applying a gradual, layer-wise quantization schedule stably fine-tunes full-precision checkpoints into ternary LLMs. Our approach matches or surpasses more elaborate knowledge-distillation pipelines on standard language-modeling benchmarks without adding model complexity. These results indicate that careful normalization alone can close much of the accuracy gap between ternary and full-precision LLMs, making ultra-low-bit inference practical.</li>
</ul>

<h3>Title: Self Rewarding Self Improving</h3>
<ul>
<li><strong>Authors: </strong>Toby Simonds, Kevin Lopez, Akira Yoshiyama, Dominique Garmier</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.08827">https://arxiv.org/abs/2505.08827</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.08827">https://arxiv.org/pdf/2505.08827</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.08827]] Self Rewarding Self Improving(https://arxiv.org/abs/2505.08827)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>We demonstrate that large language models can effectively self-improve through self-judging without requiring reference solutions, leveraging the inherent asymmetry between generating and verifying solutions. Our experiments on Countdown puzzles and MIT Integration Bee problems show that models can provide reliable reward signals without ground truth answers, enabling reinforcement learning in domains previously not possible. By implementing self-judging, we achieve significant performance gains maintaining alignment with formal verification. When combined with synthetic question generation, we establish a complete self-improvement loop where models generate practice problems, solve them, and evaluate their own performance-achieving an 8% improvement with Qwen 2.5 7B over baseline and surpassing GPT-4o performance on integration tasks. Our findings demonstrate that LLM judges can provide effective reward signals for training models, unlocking many reinforcement learning environments previously limited by the difficulty of creating programmatic rewards. This suggests a potential paradigm shift toward AI systems that continuously improve through self-directed learning rather than human-guided training, potentially accelerating progress in domains with scarce training data or complex evaluation requirements.</li>
</ul>

<h3>Title: Human-AI Collaboration or Academic Misconduct? Measuring AI Use in Student Writing Through Stylometric Evidence</h3>
<ul>
<li><strong>Authors: </strong>Eduardo Araujo Oliveira, Madhavi Mohoni, Sonsoles López-Pernas, Mohammed Saqr</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.CY</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.08828">https://arxiv.org/abs/2505.08828</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.08828">https://arxiv.org/pdf/2505.08828</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.08828]] Human-AI Collaboration or Academic Misconduct? Measuring AI Use in Student Writing Through Stylometric Evidence(https://arxiv.org/abs/2505.08828)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, interpretability</a></li>
<li><strong>Abstract: </strong>As human-AI collaboration becomes increasingly prevalent in educational contexts, understanding and measuring the extent and nature of such interactions pose significant challenges. This research investigates the use of authorship verification (AV) techniques not as a punitive measure, but as a means to quantify AI assistance in academic writing, with a focus on promoting transparency, interpretability, and student development. Building on prior work, we structured our investigation into three stages: dataset selection and expansion, AV method development, and systematic evaluation. Using three datasets - including a public dataset (PAN-14) and two from University of Melbourne students from various courses - we expanded the data to include LLM-generated texts, totalling 1,889 documents and 540 authorship problems from 506 students. We developed an adapted Feature Vector Difference AV methodology to construct robust academic writing profiles for students, designed to capture meaningful, individual characteristics of their writing. The method's effectiveness was evaluated across multiple scenarios, including distinguishing between student-authored and LLM-generated texts and testing resilience against LLMs' attempts to mimic student writing styles. Results demonstrate the enhanced AV classifier's ability to identify stylometric discrepancies and measure human-AI collaboration at word and sentence levels while providing educators with a transparent tool to support academic integrity investigations. This work advances AV technology, offering actionable insights into the dynamics of academic writing in an AI-driven era.</li>
</ul>

<h3>Title: Aggregating Concepts of Fairness and Accuracy in Predictive Systems</h3>
<ul>
<li><strong>Authors: </strong>David Kinney</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.08829">https://arxiv.org/abs/2505.08829</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.08829">https://arxiv.org/pdf/2505.08829</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.08829]] Aggregating Concepts of Fairness and Accuracy in Predictive Systems(https://arxiv.org/abs/2505.08829)</code><input type="text"></li>
<li><strong>Keywords: </strong>fair</a></li>
<li><strong>Abstract: </strong>An algorithm that outputs predictions about the state of the world will almost always be designed with the implicit or explicit goal of outputting accurate predictions (i.e., predictions that are likely to be true). In addition, the rise of increasingly powerful predictive algorithms brought about by the recent revolution in artificial intelligence has led to an emphasis on building predictive algorithms that are fair, in the sense that their predictions do not systematically evince bias or bring about harm to certain individuals or groups. This state of affairs presents two conceptual challenges. First, the goals of accuracy and fairness can sometimes be in tension, and there are no obvious normative guidelines for managing the trade-offs between these two desiderata when they arise. Second, there are many distinct ways of measuring both the accuracy and fairness of a predictive algorithm; here too, there are no obvious guidelines on how to aggregate our preferences for predictive algorithms that satisfy disparate measures of fairness and accuracy to various extents. The goal of this paper is to address these challenges by arguing that there are good reasons for using a linear combination of accuracy and fairness metrics to measure the all-things-considered value of a predictive algorithm for agents who care about both accuracy and fairness. My argument depends crucially on a classic result in the preference aggregation literature due to Harsanyi. After making this formal argument, I apply my result to an analysis of accuracy-fairness trade-offs using the COMPAS dataset compiled by Angwin et al.</li>
</ul>

<h3>Title: Federated Large Language Models: Feasibility, Robustness, Security and Future Directions</h3>
<ul>
<li><strong>Authors: </strong>Wenhao Jiang, Yuchuan Luo, Guilin Deng, Silong Chen, Xu Yang, Shihong Wu, Xinwen Gao, Lin Liu, Shaojing Fu</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.08830">https://arxiv.org/abs/2505.08830</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.08830">https://arxiv.org/pdf/2505.08830</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.08830]] Federated Large Language Models: Feasibility, Robustness, Security and Future Directions(https://arxiv.org/abs/2505.08830)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, privacy, protect, defense, robust, federate, large language model</a></li>
<li><strong>Abstract: </strong>The integration of Large Language Models (LLMs) and Federated Learning (FL) presents a promising solution for joint training on distributed data while preserving privacy and addressing data silo issues. However, this emerging field, known as Federated Large Language Models (FLLM), faces significant challenges, including communication and computation overheads, heterogeneity, privacy and security concerns. Current research has primarily focused on the feasibility of FLLM, but future trends are expected to emphasize enhancing system robustness and security. This paper provides a comprehensive review of the latest advancements in FLLM, examining challenges from four critical perspectives: feasibility, robustness, security, and future directions. We present an exhaustive survey of existing studies on FLLM feasibility, introduce methods to enhance robustness in the face of resource, data, and task heterogeneity, and analyze novel risks associated with this integration, including privacy threats and security challenges. We also review the latest developments in defense mechanisms and explore promising future research directions, such as few-shot learning, machine unlearning, and IP protection. This survey highlights the pressing need for further research to enhance system robustness and security while addressing the unique challenges posed by the integration of FL and LLM.</li>
</ul>

<h3>Title: Generative AI for Urban Planning: Synthesizing Satellite Imagery via Diffusion Models</h3>
<ul>
<li><strong>Authors: </strong>Qingyi Wang, Yuebing Liang, Yunhan Zheng, Kaiyuan Xu, Jinhua Zhao, Shenhao Wang</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.08833">https://arxiv.org/abs/2505.08833</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.08833">https://arxiv.org/pdf/2505.08833</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.08833]] Generative AI for Urban Planning: Synthesizing Satellite Imagery via Diffusion Models(https://arxiv.org/abs/2505.08833)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, diffusion, generative</a></li>
<li><strong>Abstract: </strong>Generative AI offers new opportunities for automating urban planning by creating site-specific urban layouts and enabling flexible design exploration. However, existing approaches often struggle to produce realistic and practical designs at scale. Therefore, we adapt a state-of-the-art Stable Diffusion model, extended with ControlNet, to generate high-fidelity satellite imagery conditioned on land use descriptions, infrastructure, and natural environments. To overcome data availability limitations, we spatially link satellite imagery with structured land use and constraint information from OpenStreetMap. Using data from three major U.S. cities, we demonstrate that the proposed diffusion model generates realistic and diverse urban landscapes by varying land-use configurations, road networks, and water bodies, facilitating cross-city learning and design diversity. We also systematically evaluate the impacts of varying language prompts and control imagery on the quality of satellite imagery generation. Our model achieves high FID and KID scores and demonstrates robustness across diverse urban contexts. Qualitative assessments from urban planners and the general public show that generated images align closely with design descriptions and constraints, and are often preferred over real images. This work establishes a benchmark for controlled urban imagery generation and highlights the potential of generative AI as a tool for enhancing planning workflows and public engagement.</li>
</ul>

<h3>Title: Robustness Analysis against Adversarial Patch Attacks in Fully Unmanned Stores</h3>
<ul>
<li><strong>Authors: </strong>Hyunsik Na, Wonho Lee, Seungdeok Roh, Sohee Park, Daeseon Choi</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.AI, cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.08835">https://arxiv.org/abs/2505.08835</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.08835">https://arxiv.org/pdf/2505.08835</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.08835]] Robustness Analysis against Adversarial Patch Attacks in Fully Unmanned Stores(https://arxiv.org/abs/2505.08835)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, protect, defense, attack, robust</a></li>
<li><strong>Abstract: </strong>The advent of convenient and efficient fully unmanned stores equipped with artificial intelligence-based automated checkout systems marks a new era in retail. However, these systems have inherent artificial intelligence security vulnerabilities, which are exploited via adversarial patch attacks, particularly in physical environments. This study demonstrated that adversarial patches can severely disrupt object detection models used in unmanned stores, leading to issues such as theft, inventory discrepancies, and interference. We investigated three types of adversarial patch attacks -- Hiding, Creating, and Altering attacks -- and highlighted their effectiveness. We also introduce the novel color histogram similarity loss function by leveraging attacker knowledge of the color information of a target class object. Besides the traditional confusion-matrix-based attack success rate, we introduce a new bounding-boxes-based metric to analyze the practical impact of these attacks. Starting with attacks on object detection models trained on snack and fruit datasets in a digital environment, we evaluated the effectiveness of adversarial patches in a physical testbed that mimicked a real unmanned store with RGB cameras and realistic conditions. Furthermore, we assessed the robustness of these attacks in black-box scenarios, demonstrating that shadow attacks can enhance success rates of attacks even without direct access to model parameters. Our study underscores the necessity for robust defense strategies to protect unmanned stores from adversarial threats. Highlighting the limitations of the current defense mechanisms in real-time detection systems and discussing various proactive measures, we provide insights into improving the robustness of object detection models and fortifying unmanned retail environments against these attacks.</li>
</ul>

<h3>Title: Adaptive Security Policy Management in Cloud Environments Using Reinforcement Learning</h3>
<ul>
<li><strong>Authors: </strong>Muhammad Saqib, Dipkumar Mehta, Fnu Yashu, Shubham Malhotra</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.CV, cs.DC, cs.LG, cs.NI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.08837">https://arxiv.org/abs/2505.08837</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.08837">https://arxiv.org/pdf/2505.08837</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.08837]] Adaptive Security Policy Management in Cloud Environments Using Reinforcement Learning(https://arxiv.org/abs/2505.08837)</code><input type="text"></li>
<li><strong>Keywords: </strong>security</a></li>
<li><strong>Abstract: </strong>The security of cloud environments, such as Amazon Web Services (AWS), is complex and dynamic. Static security policies have become inadequate as threats evolve and cloud resources exhibit elasticity [1]. This paper addresses the limitations of static policies by proposing a security policy management framework that uses reinforcement learning (RL) to adapt dynamically. Specifically, we employ deep reinforcement learning algorithms, including deep Q Networks and proximal policy optimization, enabling the learning and continuous adjustment of controls such as firewall rules and Identity and Access Management (IAM) policies. The proposed RL based solution leverages cloud telemetry data (AWS Cloud Trail logs, network traffic data, threat intelligence feeds) to continuously refine security policies, maximizing threat mitigation, and compliance while minimizing resource impact. Experimental results demonstrate that our adaptive RL based framework significantly outperforms static policies, achieving higher intrusion detection rates (92% compared to 82% for static policies) and substantially reducing incident detection and response times by 58%. In addition, it maintains high conformity with security requirements and efficient resource usage. These findings validate the effectiveness of adaptive reinforcement learning approaches in improving cloud security policy management.</li>
</ul>

<h3>Title: Lightweight Hybrid Block-Stream Cryptographic Algorithm for the Internet of Things</h3>
<ul>
<li><strong>Authors: </strong>Arsalan Vahi, Mirkamal Mirnia</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.08840">https://arxiv.org/abs/2505.08840</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.08840">https://arxiv.org/pdf/2505.08840</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.08840]] Lightweight Hybrid Block-Stream Cryptographic Algorithm for the Internet of Things(https://arxiv.org/abs/2505.08840)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, attack, robust</a></li>
<li><strong>Abstract: </strong>In this thesis, a novel lightweight hybrid encryption algorithm named SEPAR is proposed, featuring a 16-bit block length and a 128-bit initialization vector. The algorithm is designed specifically for application in Internet of Things (IoT) technology devices. The design concept of this algorithm is based on the integration of a pseudo-random permutation function and a pseudo-random generator function. This intelligent combination not only enhances the algorithm's resistance against cryptographic attacks but also improves its processing speed. The security analyses conducted on the algorithm, along with the results of NIST statistical tests, confirm its robustness against most common and advanced cryptographic attacks, including linear and differential attacks. The proposed algorithm has been implemented on various software platform architectures. The software implementation was carried out on three platforms: 8-bit, 16-bit, and 32-bit architectures. A comparative analysis with the BORON algorithm on a 32-bit ARM processor indicates a performance improvement of 42.25%. Furthermore, implementation results on 8-bit and 16-bit microcontrollers demonstrate performance improvements of 87.91% and 98.01% respectively, compared to the PRESENT cipher.</li>
</ul>

<h3>Title: LibVulnWatch: A Deep Assessment Agent System and Leaderboard for Uncovering Hidden Vulnerabilities in Open-Source AI Libraries</h3>
<ul>
<li><strong>Authors: </strong>Zekun Wu, Seonglae Cho, Umar Mohammed, Cristian Munoz, Kleyton Costa, Xin Guan, Theo King, Ze Wang, Emre Kazim, Adriano Koshiyama</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.08842">https://arxiv.org/abs/2505.08842</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.08842">https://arxiv.org/pdf/2505.08842</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.08842]] LibVulnWatch: A Deep Assessment Agent System and Leaderboard for Uncovering Hidden Vulnerabilities in Open-Source AI Libraries(https://arxiv.org/abs/2505.08842)</code><input type="text"></li>
<li><strong>Keywords: </strong>security</a></li>
<li><strong>Abstract: </strong>Open-source AI libraries are foundational to modern AI systems but pose significant, underexamined risks across security, licensing, maintenance, supply chain integrity, and regulatory compliance. We present LibVulnWatch, a graph-based agentic assessment framework that performs deep, source-grounded evaluations of these libraries. Built on LangGraph, the system coordinates a directed acyclic graph of specialized agents to extract, verify, and quantify risk using evidence from trusted sources such as repositories, documentation, and vulnerability databases. LibVulnWatch generates reproducible, governance-aligned scores across five critical domains, publishing them to a public leaderboard for longitudinal ecosystem monitoring. Applied to 20 widely used libraries, including ML frameworks, LLM inference engines, and agent orchestration tools, our system covers up to 88% of OpenSSF Scorecard checks while uncovering up to 19 additional risks per library. These include critical Remote Code Execution (RCE) vulnerabilities, absent Software Bills of Materials (SBOMs), licensing constraints, undocumented telemetry, and widespread gaps in regulatory documentation and auditability. By translating high-level governance principles into practical, verifiable metrics, LibVulnWatch advances technical AI governance with a scalable, transparent mechanism for continuous supply chain risk assessment and informed library selection.</li>
</ul>

<h3>Title: Evaluating Simplification Algorithms for Interpretability of Time Series Classification</h3>
<ul>
<li><strong>Authors: </strong>Felix Marti-Perez, Brigt Håvardstun, Cèsar Ferri, Carlos Monserrat, Jan Arne Telle</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.08846">https://arxiv.org/abs/2505.08846</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.08846">https://arxiv.org/pdf/2505.08846</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.08846]] Evaluating Simplification Algorithms for Interpretability of Time Series Classification(https://arxiv.org/abs/2505.08846)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability</a></li>
<li><strong>Abstract: </strong>In this work, we introduce metrics to evaluate the use of simplified time series in the context of interpretability of a TSC - a Time Series Classifier. Such simplifications are important because time series data, in contrast to text and image data, are not intuitively understandable to humans. These metrics are related to the complexity of the simplifications - how many segments they contain - and to their loyalty - how likely they are to maintain the classification of the original time series. We employ these metrics to evaluate four distinct simplification algorithms, across several TSC algorithms and across datasets of varying characteristics, from seasonal or stationary to short or long. Our findings suggest that using simplifications for interpretability of TSC is much better than using the original time series, particularly when the time series are seasonal, non-stationary and/or with low entropy.</li>
</ul>

<h3>Title: On the interplay of Explainability, Privacy and Predictive Performance with Explanation-assisted Model Extraction</h3>
<ul>
<li><strong>Authors: </strong>Fatima Ezzeddine, Rinad Akel, Ihab Sbeity, Silvia Giordano, Marc Langheinrich, Omran Ayoub</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.08847">https://arxiv.org/abs/2505.08847</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.08847">https://arxiv.org/pdf/2505.08847</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.08847]] On the interplay of Explainability, Privacy and Predictive Performance with Explanation-assisted Model Extraction(https://arxiv.org/abs/2505.08847)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, privacy, attack, extraction, explainability</a></li>
<li><strong>Abstract: </strong>Machine Learning as a Service (MLaaS) has gained important attraction as a means for deploying powerful predictive models, offering ease of use that enables organizations to leverage advanced analytics without substantial investments in specialized infrastructure or expertise. However, MLaaS platforms must be safeguarded against security and privacy attacks, such as model extraction (MEA) attacks. The increasing integration of explainable AI (XAI) within MLaaS has introduced an additional privacy challenge, as attackers can exploit model explanations particularly counterfactual explanations (CFs) to facilitate MEA. In this paper, we investigate the trade offs among model performance, privacy, and explainability when employing Differential Privacy (DP), a promising technique for mitigating CF facilitated MEA. We evaluate two distinct DP strategies: implemented during the classification model training and at the explainer during CF generation.</li>
</ul>

<h3>Title: Improved Algorithms for Differentially Private Language Model Alignment</h3>
<ul>
<li><strong>Authors: </strong>Keyu Chen, Hao Tang, Qinglin Liu, Yizhao Xu</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.08849">https://arxiv.org/abs/2505.08849</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.08849">https://arxiv.org/pdf/2505.08849</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.08849]] Improved Algorithms for Differentially Private Language Model Alignment(https://arxiv.org/abs/2505.08849)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, large language model</a></li>
<li><strong>Abstract: </strong>Language model alignment is crucial for ensuring that large language models (LLMs) align with human preferences, yet it often involves sensitive user data, raising significant privacy concerns. While prior work has integrated differential privacy (DP) with alignment techniques, their performance remains limited. In this paper, we propose novel algorithms for privacy-preserving alignment and rigorously analyze their effectiveness across varying privacy budgets and models. Our framework can be deployed on two celebrated alignment techniques, namely direct preference optimization (DPO) and reinforcement learning from human feedback (RLHF). Through systematic experiments on large-scale language models, we demonstrate that our approach achieves state-of-the-art performance. Notably, one of our algorithms, DP-AdamW, combined with DPO, surpasses existing methods, improving alignment quality by up to 15% under moderate privacy budgets ({\epsilon}=2-5). We further investigate the interplay between privacy guarantees, alignment efficacy, and computational demands, providing practical guidelines for optimizing these trade-offs.</li>
</ul>

<h3>Title: Generative AI for Autonomous Driving: Frontiers and Opportunities</h3>
<ul>
<li><strong>Authors: </strong>Yuping Wang, Shuo Xing, Cui Can, Renjie Li, Hongyuan Hua, Kexin Tian, Zhaobin Mo, Xiangbo Gao, Keshu Wu, Sulong Zhou, Hengxu You, Juntong Peng, Junge Zhang, Zehao Wang, Rui Song, Mingxuan Yan, Walter Zimmer, Xingcheng Zhou, Peiran Li, Zhaohan Lu, Chia-Ju Chen, Yue Huang, Ryan A. Rossi, Lichao Sun, Hongkai Yu, Zhiwen Fan, Frank Hao Yang, Yuhao Kang, Ross Greer, Chenxi Liu, Eun Hak Lee, Xuan Di, Xinyue Ye, Liu Ren, Alois Knoll, Xiaopeng Li, Shuiwang Ji, Masayoshi Tomizuka, Marco Pavone, Tianbao Yang, Jing Du, Ming-Hsuan Yang, Hua Wei, Ziran Wang, Yang Zhou, Jiachen Li, Zhengzhong Tu</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI, cs.RO</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.08854">https://arxiv.org/abs/2505.08854</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.08854">https://arxiv.org/pdf/2505.08854</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.08854]] Generative AI for Autonomous Driving: Frontiers and Opportunities(https://arxiv.org/abs/2505.08854)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, generative, large language model</a></li>
<li><strong>Abstract: </strong>Generative Artificial Intelligence (GenAI) constitutes a transformative technological wave that reconfigures industries through its unparalleled capabilities for content creation, reasoning, planning, and multimodal understanding. This revolutionary force offers the most promising path yet toward solving one of engineering's grandest challenges: achieving reliable, fully autonomous driving, particularly the pursuit of Level 5 autonomy. This survey delivers a comprehensive and critical synthesis of the emerging role of GenAI across the autonomous driving stack. We begin by distilling the principles and trade-offs of modern generative modeling, encompassing VAEs, GANs, Diffusion Models, and Large Language Models (LLMs). We then map their frontier applications in image, LiDAR, trajectory, occupancy, video generation as well as LLM-guided reasoning and decision making. We categorize practical applications, such as synthetic data workflows, end-to-end driving strategies, high-fidelity digital twin systems, smart transportation networks, and cross-domain transfer to embodied AI. We identify key obstacles and possibilities such as comprehensive generalization across rare cases, evaluation and safety checks, budget-limited implementation, regulatory compliance, ethical concerns, and environmental effects, while proposing research plans across theoretical assurances, trust metrics, transport integration, and socio-technical influence. By unifying these threads, the survey provides a forward-looking reference for researchers, engineers, and policymakers navigating the convergence of generative AI and advanced autonomous mobility. An actively maintained repository of cited works is available at this https URL.</li>
</ul>

<h3>Title: Optimized Couplings for Watermarking Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Dor Tsur, Carol Xuan Long, Claudio Mayrink Verdun, Hsiang Hsu, Haim Permuter, Flavio P. Calmon</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.AI, cs.IT</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.08878">https://arxiv.org/abs/2505.08878</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.08878">https://arxiv.org/pdf/2505.08878</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.08878]] Optimized Couplings for Watermarking Large Language Models(https://arxiv.org/abs/2505.08878)</code><input type="text"></li>
<li><strong>Keywords: </strong>watermark, large language model</a></li>
<li><strong>Abstract: </strong>Large-language models (LLMs) are now able to produce text that is, in many cases, seemingly indistinguishable from human-generated content. This has fueled the development of watermarks that imprint a ``signal'' in LLM-generated text with minimal perturbation of an LLM's output. This paper provides an analysis of text watermarking in a one-shot setting. Through the lens of hypothesis testing with side information, we formulate and analyze the fundamental trade-off between watermark detection power and distortion in generated textual quality. We argue that a key component in watermark design is generating a coupling between the side information shared with the watermark detector and a random partition of the LLM vocabulary. Our analysis identifies the optimal coupling and randomization strategy under the worst-case LLM next-token distribution that satisfies a min-entropy constraint. We provide a closed-form expression of the resulting detection rate under the proposed scheme and quantify the cost in a max-min sense. Finally, we provide an array of numerical results, comparing the proposed scheme with the theoretical optimum and existing schemes, in both synthetic data and LLM watermarking. Our code is available at this https URL</li>
</ul>

<h3>Title: NeurIPS 2024 Ariel Data Challenge: Characterisation of Exoplanetary Atmospheres Using a Data-Centric Approach</h3>
<ul>
<li><strong>Authors: </strong>Jeremie Blanchard, Lisa Casino, Jordan Gierschendorf</a></li>
<li><strong>Subjects: </strong>cs.LG, astro-ph.IM</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.08940">https://arxiv.org/abs/2505.08940</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.08940">https://arxiv.org/pdf/2505.08940</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.08940]] NeurIPS 2024 Ariel Data Challenge: Characterisation of Exoplanetary Atmospheres Using a Data-Centric Approach(https://arxiv.org/abs/2505.08940)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction, interpretability</a></li>
<li><strong>Abstract: </strong>The characterization of exoplanetary atmospheres through spectral analysis is a complex challenge. The NeurIPS 2024 Ariel Data Challenge, in collaboration with the European Space Agency's (ESA) Ariel mission, provided an opportunity to explore machine learning techniques for extracting atmospheric compositions from simulated spectral data. In this work, we focus on a data-centric business approach, prioritizing generalization over competition-specific optimization. We briefly outline multiple experimental axes, including feature extraction, signal transformation, and heteroskedastic uncertainty modeling. Our experiments demonstrate that uncertainty estimation plays a crucial role in the Gaussian Log-Likelihood (GLL) score, impacting performance by several percentage points. Despite improving the GLL score by 11%, our results highlight the inherent limitations of tabular modeling and feature engineering for this task, as well as the constraints of a business-driven approach within a Kaggle-style competition framework. Our findings emphasize the trade-offs between model simplicity, interpretability, and generalization in astrophysical data analysis.</li>
</ul>

<h3>Title: ForeCite: Adapting Pre-Trained Language Models to Predict Future Citation Rates of Academic Papers</h3>
<ul>
<li><strong>Authors: </strong>Gavin Hull, Alex Bihlo</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.08941">https://arxiv.org/abs/2505.08941</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.08941">https://arxiv.org/pdf/2505.08941</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.08941]] ForeCite: Adapting Pre-Trained Language Models to Predict Future Citation Rates of Academic Papers(https://arxiv.org/abs/2505.08941)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, transformer</a></li>
<li><strong>Abstract: </strong>Predicting the future citation rates of academic papers is an important step toward the automation of research evaluation and the acceleration of scientific progress. We present $\textbf{ForeCite}$, a simple but powerful framework to append pre-trained causal language models with a linear head for average monthly citation rate prediction. Adapting transformers for regression tasks, ForeCite achieves a test correlation of $\rho = 0.826$ on a curated dataset of 900K+ biomedical papers published between 2000 and 2024, a 27-point improvement over the previous state-of-the-art. Comprehensive scaling-law analysis reveals consistent gains across model sizes and data volumes, while temporal holdout experiments confirm practical robustness. Gradient-based saliency heatmaps suggest a potentially undue reliance on titles and abstract texts. These results establish a new state-of-the-art in forecasting the long-term influence of academic research and lay the groundwork for the automated, high-fidelity evaluation of scientific contributions.</li>
</ul>

<h3>Title: Differentiable Channel Selection in Self-Attention For Person Re-Identification</h3>
<ul>
<li><strong>Authors: </strong>Yancheng Wang, Nebojsa Jojic, Yingzhen Yang</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.08961">https://arxiv.org/abs/2505.08961</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.08961">https://arxiv.org/pdf/2505.08961</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.08961]] Differentiable Channel Selection in Self-Attention For Person Re-Identification(https://arxiv.org/abs/2505.08961)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction</a></li>
<li><strong>Abstract: </strong>In this paper, we propose a novel attention module termed the Differentiable Channel Selection Attention module, or the DCS-Attention module. In contrast with conventional self-attention, the DCS-Attention module features selection of informative channels in the computation of the attention weights. The selection of the feature channels is performed in a differentiable manner, enabling seamless integration with DNN training. Our DCS-Attention is compatible with either fixed neural network backbones or learnable backbones with Differentiable Neural Architecture Search (DNAS), leading to DCS with Fixed Backbone (DCS-FB) and DCS-DNAS, respectively. Importantly, our DCS-Attention is motivated by the principle of Information Bottleneck (IB), and a novel variational upper bound for the IB loss, which can be optimized by SGD, is derived and incorporated into the training loss of the networks with the DCS-Attention modules. In this manner, a neural network with DCS-Attention modules is capable of selecting the most informative channels for feature extraction so that it enjoys state-of-the-art performance for the Re-ID task. Extensive experiments on multiple person Re-ID benchmarks using both DCS-FB and DCS-DNAS show that DCS-Attention significantly enhances the prediction accuracy of DNNs for person Re-ID, which demonstrates the effectiveness of DCS-Attention in learning discriminative features critical to identifying person identities. The code of our work is available at this https URL.</li>
</ul>

<h3>Title: GPML: Graph Processing for Machine Learning</h3>
<ul>
<li><strong>Authors: </strong>Majed Jaber, Julien Michel, Nicolas Boutry, Pierre Parrend</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.08964">https://arxiv.org/abs/2505.08964</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.08964">https://arxiv.org/pdf/2505.08964</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.08964]] GPML: Graph Processing for Machine Learning(https://arxiv.org/abs/2505.08964)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, attack, robust, extraction</a></li>
<li><strong>Abstract: </strong>The dramatic increase of complex, multi-step, and rapidly evolving attacks in dynamic networks involves advanced cyber-threat detectors. The GPML (Graph Processing for Machine Learning) library addresses this need by transforming raw network traffic traces into graph representations, enabling advanced insights into network behaviors. The library provides tools to detect anomalies in interaction and community shifts in dynamic networks. GPML supports community and spectral metrics extraction, enhancing both real-time detection and historical forensics analysis. This library supports modern cybersecurity challenges with a robust, graph-based approach.</li>
</ul>

<h3>Title: Prioritizing Image-Related Tokens Enhances Vision-Language Pre-Training</h3>
<ul>
<li><strong>Authors: </strong>Yangyi Chen, Hao Peng, Tong Zhang, Heng Ji</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.CL, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.08971">https://arxiv.org/abs/2505.08971</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.08971">https://arxiv.org/pdf/2505.08971</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.08971]] Prioritizing Image-Related Tokens Enhances Vision-Language Pre-Training(https://arxiv.org/abs/2505.08971)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>In standard large vision-language models (LVLMs) pre-training, the model typically maximizes the joint probability of the caption conditioned on the image via next-token prediction (NTP); however, since only a small subset of caption tokens directly relates to the visual content, this naive NTP unintentionally fits the model to noise and increases the risk of hallucination. We present PRIOR, a simple vision-language pre-training approach that addresses this issue by prioritizing image-related tokens through differential weighting in the NTP loss, drawing from the importance sampling framework. PRIOR introduces a reference model-a text-only large language model (LLM) trained on the captions without image inputs, to weight each token based on its probability for LVLMs training. Intuitively, tokens that are directly related to the visual inputs are harder to predict without the image and thus receive lower probabilities from the text-only reference LLM. During training, we implement a token-specific re-weighting term based on the importance scores to adjust each token's loss. We implement PRIOR in two distinct settings: LVLMs with visual encoders and LVLMs without visual encoders. We observe 19% and 8% average relative improvement, respectively, on several vision-language benchmarks compared to NTP. In addition, PRIOR exhibits superior scaling properties, as demonstrated by significantly higher scaling coefficients, indicating greater potential for performance gains compared to NTP given increasing compute and data.</li>
</ul>

<h3>Title: Inference Attacks for X-Vector Speaker Anonymization</h3>
<ul>
<li><strong>Authors: </strong>Luke Bauer, Wenxuan Bao, Malvika Jadhav, Vincent Bindschaedler</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.SD, eess.AS</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.08978">https://arxiv.org/abs/2505.08978</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.08978">https://arxiv.org/pdf/2505.08978</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.08978]] Inference Attacks for X-Vector Speaker Anonymization(https://arxiv.org/abs/2505.08978)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, attack</a></li>
<li><strong>Abstract: </strong>We revisit the privacy-utility tradeoff of x-vector speaker anonymization. Existing approaches quantify privacy through training complex speaker verification or identification models that are later used as attacks. Instead, we propose a novel inference attack for de-anonymization. Our attack is simple and ML-free yet we show experimentally that it outperforms existing approaches.</li>
</ul>

<h3>Title: A suite of LMs comprehend puzzle statements as well as humans</h3>
<ul>
<li><strong>Authors: </strong>Adele E Goldberg, Supantho Rakshit, Jennifer Hu, Kyle Mahowald</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.08996">https://arxiv.org/abs/2505.08996</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.08996">https://arxiv.org/pdf/2505.08996</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.08996]] A suite of LMs comprehend puzzle statements as well as humans(https://arxiv.org/abs/2505.08996)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Recent claims suggest that large language models (LMs) underperform humans in comprehending minimally complex English statements (Dentella et al., 2024). Here, we revisit those findings and argue that human performance was overestimated, while LLM abilities were underestimated. Using the same stimuli, we report a preregistered study comparing human responses in two conditions: one allowed rereading (replicating the original study), and one that restricted rereading (a more naturalistic comprehension test). Human accuracy dropped significantly when rereading was restricted (73%), falling below that of Falcon-180B-Chat (76%) and GPT-4 (81%). The newer GPT-o1 model achieves perfect accuracy. Results further show that both humans and models are disproportionately challenged by queries involving potentially reciprocal actions (e.g., kissing), suggesting shared pragmatic sensitivities rather than model-specific deficits. Additional analyses using Llama-2-70B log probabilities, a recoding of open-ended model responses, and grammaticality ratings of other sentences reveal systematic underestimation of model performance. We find that GPT-4o can align with either naive or expert grammaticality judgments, depending on prompt framing. These findings underscore the need for more careful experimental design and coding practices in LLM evaluation, and they challenge the assumption that current models are inherently weaker than humans at language comprehension.</li>
</ul>

<h3>Title: Towards Adaptive Meta-Gradient Adversarial Examples for Visual Tracking</h3>
<ul>
<li><strong>Authors: </strong>Wei-Long Tian, Peng Gao, Xiao Liu, Long Xu, Hamido Fujita, Hanan Aljuai, Mao-Li Wang</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.08999">https://arxiv.org/abs/2505.08999</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.08999">https://arxiv.org/pdf/2505.08999</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.08999]] Towards Adaptive Meta-Gradient Adversarial Examples for Visual Tracking(https://arxiv.org/abs/2505.08999)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, attack, transformer</a></li>
<li><strong>Abstract: </strong>In recent years, visual tracking methods based on convolutional neural networks and Transformers have achieved remarkable performance and have been successfully applied in fields such as autonomous driving. However, the numerous security issues exposed by deep learning models have gradually affected the reliable application of visual tracking methods in real-world scenarios. Therefore, how to reveal the security vulnerabilities of existing visual trackers through effective adversarial attacks has become a critical problem that needs to be addressed. To this end, we propose an adaptive meta-gradient adversarial attack (AMGA) method for visual tracking. This method integrates multi-model ensembles and meta-learning strategies, combining momentum mechanisms and Gaussian smoothing, which can significantly enhance the transferability and attack effectiveness of adversarial examples. AMGA randomly selects models from a large model repository, constructs diverse tracking scenarios, and iteratively performs both white- and black-box adversarial attacks in each scenario, optimizing the gradient directions of each model. This paradigm minimizes the gap between white- and black-box adversarial attacks, thus achieving excellent attack performance in black-box scenarios. Extensive experimental results on large-scale datasets such as OTB2015, LaSOT, and GOT-10k demonstrate that AMGA significantly improves the attack performance, transferability, and deception of adversarial examples. Codes and data are available at this https URL.</li>
</ul>

<h3>Title: SAFE-SiP: Secure Authentication Framework for System-in-Package Using Multi-party Computation</h3>
<ul>
<li><strong>Authors: </strong>Ishraq Tashdid, Tasnuva Farheen, Sazadur Rahman</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.09002">https://arxiv.org/abs/2505.09002</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.09002">https://arxiv.org/pdf/2505.09002</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.09002]] SAFE-SiP: Secure Authentication Framework for System-in-Package Using Multi-party Computation(https://arxiv.org/abs/2505.09002)</code><input type="text"></li>
<li><strong>Keywords: </strong>secure, security, attack</a></li>
<li><strong>Abstract: </strong>The emergence of chiplet-based heterogeneous integration is transforming the semiconductor, AI, and high-performance computing industries by enabling modular designs and improved scalability. However, assembling chiplets from multiple vendors after fabrication introduces a complex supply chain that raises serious security concerns, including counterfeiting, overproduction, and unauthorized access. Current solutions often depend on dedicated security chiplets or changes to the timing flow, which assume a trusted SiP integrator. This assumption can expose chiplet signatures to other vendors and create new attack surfaces. This work addresses those vulnerabilities using Multi-party Computation (MPC), which enables zero-trust authentication without disclosing sensitive information to any party. We present SAFE-SiP, a scalable authentication framework that garbles chiplet signatures and uses MPC for verifying integrity, effectively blocking unauthorized access and adversarial inference. SAFE-SiP removes the need for a dedicated security chiplet and ensures secure authentication, even in untrusted integration scenarios. We evaluated SAFE-SiP on five RISC-V-based System-in-Package (SiP) designs. Experimental results show that SAFE-SiP incurs minimal power overhead, an average area overhead of only 3.05%, and maintains a computational complexity of 2^192, offering a highly efficient and scalable security solution.</li>
</ul>

<h3>Title: Signal-based AI-driven software solution for automated quantification of metastatic bone disease and treatment response assessment using Whole-Body Diffusion-Weighted MRI (WB-DWI) biomarkers in Advanced Prostate Cancer</h3>
<ul>
<li><strong>Authors: </strong>Antonio Candito, Matthew D Blackledge, Richard Holbrey, Nuria Porta, Ana Ribeiro, Fabio Zugni, Luca D'Erme, Francesca Castagnoli, Alina Dragan, Ricardo Donners, Christina Messiou, Nina Tunariu, Dow-Mu Koh</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.09011">https://arxiv.org/abs/2505.09011</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.09011">https://arxiv.org/pdf/2505.09011</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.09011]] Signal-based AI-driven software solution for automated quantification of metastatic bone disease and treatment response assessment using Whole-Body Diffusion-Weighted MRI (WB-DWI) biomarkers in Advanced Prostate Cancer(https://arxiv.org/abs/2505.09011)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>We developed an AI-driven software solution to quantify metastatic bone disease from WB-DWI scans. Core technologies include: (i) a weakly-supervised Residual U-Net model generating a skeleton probability map to isolate bone; (ii) a statistical framework for WB-DWI intensity normalisation, obtaining a signal-normalised b=900s/mm^2 (b900) image; and (iii) a shallow convolutional neural network that processes outputs from (i) and (ii) to generate a mask of suspected bone lesions, characterised by higher b900 signal intensity due to restricted water diffusion. This mask is applied to the gADC map to extract TDV and gADC statistics. We tested the tool using expert-defined metastatic bone disease delineations on 66 datasets, assessed repeatability of imaging biomarkers (N=10), and compared software-based response assessment with a construct reference standard based on clinical, laboratory and imaging assessments (N=118). Dice score between manual and automated delineations was 0.6 for lesions within pelvis and spine, with an average surface distance of 2mm. Relative differences for log-transformed TDV (log-TDV) and median gADC were below 9% and 5%, respectively. Repeatability analysis showed coefficients of variation of 4.57% for log-TDV and 3.54% for median gADC, with intraclass correlation coefficients above 0.9. The software achieved 80.5% accuracy, 84.3% sensitivity, and 85.7% specificity in assessing response to treatment compared to the construct reference standard. Computation time generating a mask averaged 90 seconds per scan. Our software enables reproducible TDV and gADC quantification from WB-DWI scans for monitoring metastatic bone disease response, thus providing potentially useful measurements for clinical decision-making in APC patients.</li>
</ul>

<h3>Title: DyGSSM: Multi-view Dynamic Graph Embeddings with State Space Model Gradient Update</h3>
<ul>
<li><strong>Authors: </strong>Bizhan Alipour Pijan, Serdar Bozdag</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.SI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.09017">https://arxiv.org/abs/2505.09017</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.09017">https://arxiv.org/pdf/2505.09017</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.09017]] DyGSSM: Multi-view Dynamic Graph Embeddings with State Space Model Gradient Update(https://arxiv.org/abs/2505.09017)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction, transformer</a></li>
<li><strong>Abstract: </strong>Most of the dynamic graph representation learning methods involve dividing a dynamic graph into discrete snapshots to capture the evolving behavior of nodes over time. Existing methods primarily capture only local or global structures of each node within a snapshot using message-passing and random walk-based methods. Then, they utilize sequence-based models (e.g., transformers) to encode the temporal evolution of node embeddings, and meta-learning techniques to update the model parameters. However, these approaches have two limitations. First, they neglect the extraction of global and local information simultaneously in each snapshot. Second, they fail to consider the model's performance in the current snapshot during parameter updates, resulting in a lack of temporal dependency management. Recently, HiPPO (High-order Polynomial Projection Operators) algorithm has gained attention for their ability to optimize and preserve sequence history in State Space Model (SSM). To address the aforementioned limitations in dynamic graph representation learning, we propose a novel method called Multi-view Dynamic Graph Embeddings with State Space Model Gradient Update (DyGSSM). Our approach combines Graph Convolution Networks (GCN) for local feature extraction and random walk with Gated Recurrent Unit (GRU) for global feature extraction in each snapshot. We then integrate the local and global features using a cross-attention mechanism. Additionally, we incorporate an SSM based on HiPPO algorithm to account for long-term dependencies when updating model parameters, ensuring that model performance in each snapshot informs subsequent updates. Experiments on five public datasets show that our method outperforms existing baseline and state-of-the-art (SOTA) methods in 17 out of 20 cases.</li>
</ul>

<h3>Title: Multimodal Fusion of Glucose Monitoring and Food Imagery for Caloric Content Prediction</h3>
<ul>
<li><strong>Authors: </strong>Adarsh Kumar</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.09018">https://arxiv.org/abs/2505.09018</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.09018">https://arxiv.org/pdf/2505.09018</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.09018]] Multimodal Fusion of Glucose Monitoring and Food Imagery for Caloric Content Prediction(https://arxiv.org/abs/2505.09018)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction</a></li>
<li><strong>Abstract: </strong>Effective dietary monitoring is critical for managing Type 2 diabetes, yet accurately estimating caloric intake remains a major challenge. While continuous glucose monitors (CGMs) offer valuable physiological data, they often fall short in capturing the full nutritional profile of meals due to inter-individual and meal-specific variability. In this work, we introduce a multimodal deep learning framework that jointly leverages CGM time-series data, Demographic/Microbiome, and pre-meal food images to enhance caloric estimation. Our model utilizes attention based encoding and a convolutional feature extraction for meal imagery, multi-layer perceptrons for CGM and Microbiome data followed by a late fusion strategy for joint reasoning. We evaluate our approach on a curated dataset of over 40 participants, incorporating synchronized CGM, Demographic and Microbiome data and meal photographs with standardized caloric labels. Our model achieves a Root Mean Squared Relative Error (RMSRE) of 0.2544, outperforming the baselines models by over 50%. These findings demonstrate the potential of multimodal sensing to improve automated dietary assessment tools for chronic disease management.</li>
</ul>

<h3>Title: Multiparty Selective Disclosure using Attribute-Based Encryption</h3>
<ul>
<li><strong>Authors: </strong>Shigenori Ohashi</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.09034">https://arxiv.org/abs/2505.09034</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.09034">https://arxiv.org/pdf/2505.09034</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.09034]] Multiparty Selective Disclosure using Attribute-Based Encryption(https://arxiv.org/abs/2505.09034)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy</a></li>
<li><strong>Abstract: </strong>This study proposes a mechanism for encrypting SD-JWT (Selective Disclosure JSON Web Token) Disclosures using Attribute-Based Encryption (ABE) to enable flexible access control on the basis of the Verifier's attributes. By integrating Ciphertext-Policy ABE (CP-ABE) into the existing SD-JWT framework, the Holder can assign decryption policies to Disclosures, ensuring information is selectively disclosed. The mechanism's feasibility was evaluated in a virtualized environment by measuring the processing times for SD-JWT generation, encryption, and decryption with varying Disclosure counts (5, 10, 20). Results showed that SD-JWT generation is lightweight, while encryption and decryption times increase linearly with the number of Disclosures. This approach is suitable for privacy-sensitive applications like healthcare, finance, and supply chain tracking but requires optimization for real-time use cases such as IoT. Future research should focus on improving ABE efficiency and addressing scalability challenges.</li>
</ul>

<h3>Title: Unencrypted Flying Objects: Security Lessons from University Small Satellite Developers and Their Code</h3>
<ul>
<li><strong>Authors: </strong>Rachel McAmis, Gregor Haas, Mattea Sim, David Kohlbrenner, Tadayoshi Kohno</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.09038">https://arxiv.org/abs/2505.09038</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.09038">https://arxiv.org/pdf/2505.09038</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.09038]] Unencrypted Flying Objects: Security Lessons from University Small Satellite Developers and Their Code(https://arxiv.org/abs/2505.09038)</code><input type="text"></li>
<li><strong>Keywords: </strong>secure, security, attack</a></li>
<li><strong>Abstract: </strong>Satellites face a multitude of security risks that set them apart from hardware on Earth. Small satellites may face additional challenges, as they are often developed on a budget and by amateur organizations or universities that do not consider security. We explore the security practices and preferences of small satellite teams, particularly university satellite teams, to understand what barriers exist to building satellites securely. We interviewed 8 university satellite club leaders across 4 clubs in the U.S. and perform a code audit of 3 of these clubs' code repositories. We find that security practices vary widely across teams, but all teams studied had vulnerabilities available to an unprivileged, ground-based attacker. Participants foresee many risks of unsecured small satellites and indicate security shortcomings in industry and government. Lastly, we identify a set of considerations for how to build future small satellites securely, in amateur organizations and beyond.</li>
</ul>

<h3>Title: Atomic Consistency Preference Optimization for Long-Form Question Answering</h3>
<ul>
<li><strong>Authors: </strong>Jingfeng Chen, Raghuveer Thirukovalluru, Junlin Wang, Kaiwei Luo, Bhuwan Dhingra</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.09039">https://arxiv.org/abs/2505.09039</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.09039">https://arxiv.org/pdf/2505.09039</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.09039]] Atomic Consistency Preference Optimization for Long-Form Question Answering(https://arxiv.org/abs/2505.09039)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large Language Models (LLMs) frequently produce factoid hallucinations - plausible yet incorrect answers. A common mitigation strategy is model alignment, which improves factual accuracy by training on curated factual and non-factual pairs. However, this approach often relies on a stronger model (e.g., GPT-4) or an external knowledge base to assess factual correctness, which may not always be accessible. To address this, we propose Atomic Consistency Preference Optimization (ACPO), a self-supervised preference-tuning method that enhances factual accuracy without external supervision. ACPO leverages atomic consistency signals, i.e., the agreement of individual facts across multiple stochastic responses, to identify high- and low-quality data pairs for model alignment. By eliminating the need for costly GPT calls, ACPO provides a scalable and efficient approach to improving factoid question-answering. Despite being self-supervised, empirical results demonstrate that ACPO outperforms FactAlign, a strong supervised alignment baseline, by 1.95 points on the LongFact and BioGen datasets, highlighting its effectiveness in enhancing factual reliability without relying on external models or knowledge bases.</li>
</ul>

<h3>Title: Modeling Interdependent Cybersecurity Threats Using Bayesian Networks: A Case Study on In-Vehicle Infotainment Systems</h3>
<ul>
<li><strong>Authors: </strong>Sangita Sridar</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.09048">https://arxiv.org/abs/2505.09048</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.09048">https://arxiv.org/pdf/2505.09048</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.09048]] Modeling Interdependent Cybersecurity Threats Using Bayesian Networks: A Case Study on In-Vehicle Infotainment Systems(https://arxiv.org/abs/2505.09048)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, attack</a></li>
<li><strong>Abstract: </strong>Cybersecurity threats are increasingly marked by interdependence, uncertainty, and evolving complexity challenges that traditional assessment methods such as CVSS, STRIDE, and attack trees fail to adequately capture. This paper reviews the application of Bayesian Networks (BNs) in cybersecurity risk modeling, highlighting their capacity to represent probabilistic dependencies, integrate diverse threat indicators, and support reasoning under uncertainty. A structured case study is presented in which a STRIDE-based attack tree for an automotive In-Vehicle Infotainment (IVI) system is transformed into a Bayesian Network. Logical relationships are encoded using Conditional Probability Tables (CPTs), and threat likelihoods are derived from normalized DREAD scores. The model enables not only probabilistic inference of system compromise likelihood but also supports causal analysis using do-calculus and local sensitivity analysis to identify high-impact vulnerabilities. These analyses provide insight into the most influential nodes within the threat propagation chain, informing targeted mitigation strategies. While demonstrating the potential of BNs for dynamic and context-aware risk assessment, the study also outlines limitations related to scalability, reliance on expert input, static structure assumptions, and limited temporal modeling. The paper concludes by advocating for future enhancements through Dynamic Bayesian Networks, structure learning, and adaptive inference to better support real-time cybersecurity decision-making in complex environments.</li>
</ul>

<h3>Title: A Comprehensive Analysis of Large Language Model Outputs: Similarity, Diversity, and Bias</h3>
<ul>
<li><strong>Authors: </strong>Brandon Smith, Mohamed Reda Bouadjenek, Tahsin Alamgir Kheya, Phillip Dawson, Sunil Aryal</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.09056">https://arxiv.org/abs/2505.09056</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.09056">https://arxiv.org/pdf/2505.09056</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.09056]] A Comprehensive Analysis of Large Language Model Outputs: Similarity, Diversity, and Bias(https://arxiv.org/abs/2505.09056)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large Language Models (LLMs) represent a major step toward artificial general intelligence, significantly advancing our ability to interact with technology. While LLMs perform well on Natural Language Processing tasks -- such as translation, generation, code writing, and summarization -- questions remain about their output similarity, variability, and ethical implications. For instance, how similar are texts generated by the same model? How does this compare across different models? And which models best uphold ethical standards? To investigate, we used 5{,}000 prompts spanning diverse tasks like generation, explanation, and rewriting. This resulted in approximately 3 million texts from 12 LLMs, including proprietary and open-source systems from OpenAI, Google, Microsoft, Meta, and Mistral. Key findings include: (1) outputs from the same LLM are more similar to each other than to human-written texts; (2) models like WizardLM-2-8x22b generate highly similar outputs, while GPT-4 produces more varied responses; (3) LLM writing styles differ significantly, with Llama 3 and Mistral showing higher similarity, and GPT-4 standing out for distinctiveness; (4) differences in vocabulary and tone underscore the linguistic uniqueness of LLM-generated content; (5) some LLMs demonstrate greater gender balance and reduced bias. These results offer new insights into the behavior and diversity of LLM outputs, helping guide future development and ethical evaluation.</li>
</ul>

<h3>Title: Single-shot prediction of parametric partial differential equations</h3>
<ul>
<li><strong>Authors: </strong>Khalid Rafiq, Wenjing Liao, Aditya G. Nair</a></li>
<li><strong>Subjects: </strong>cs.LG, math.NA</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.09063">https://arxiv.org/abs/2505.09063</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.09063">https://arxiv.org/pdf/2505.09063</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.09063]] Single-shot prediction of parametric partial differential equations(https://arxiv.org/abs/2505.09063)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, diffusion</a></li>
<li><strong>Abstract: </strong>We introduce Flexi-VAE, a data-driven framework for efficient single-shot forecasting of nonlinear parametric partial differential equations (PDEs), eliminating the need for iterative time-stepping while maintaining high accuracy and stability. Flexi-VAE incorporates a neural propagator that advances latent representations forward in time, aligning latent evolution with physical state reconstruction in a variational autoencoder setting. We evaluate two propagation strategies, the Direct Concatenation Propagator (DCP) and the Positional Encoding Propagator (PEP), and demonstrate, through representation-theoretic analysis, that DCP offers superior long-term generalization by fostering disentangled and physically meaningful latent spaces. Geometric diagnostics, including Jacobian spectral analysis, reveal that propagated latent states reside in regions of lower decoder sensitivity and more stable local geometry than those derived via direct encoding, enhancing robustness for long-horizon predictions. We validate Flexi-VAE on canonical PDE benchmarks, the 1D viscous Burgers equation and the 2D advection-diffusion equation, achieving accurate forecasts across wide parametric ranges. The model delivers over 50x CPU and 90x GPU speedups compared to autoencoder-LSTM baselines for large temporal shifts. These results position Flexi-VAE as a scalable and interpretable surrogate modeling tool for accelerating high-fidelity simulations in computational fluid dynamics (CFD) and other parametric PDE-driven applications, with extensibility to higher-dimensional and more complex systems.</li>
</ul>

<h3>Title: S-DAT: A Multilingual, GenAI-Driven Framework for Automated Divergent Thinking Assessment</h3>
<ul>
<li><strong>Authors: </strong>Jennifer Haase, Paul H. P. Hanel, Sebastian Pokutta</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.HC</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.09068">https://arxiv.org/abs/2505.09068</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.09068">https://arxiv.org/pdf/2505.09068</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.09068]] S-DAT: A Multilingual, GenAI-Driven Framework for Automated Divergent Thinking Assessment(https://arxiv.org/abs/2505.09068)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, fair, large language model</a></li>
<li><strong>Abstract: </strong>This paper introduces S-DAT (Synthetic-Divergent Association Task), a scalable, multilingual framework for automated assessment of divergent thinking (DT) -a core component of human creativity. Traditional creativity assessments are often labor-intensive, language-specific, and reliant on subjective human ratings, limiting their scalability and cross-cultural applicability. In contrast, S-DAT leverages large language models and advanced multilingual embeddings to compute semantic distance -- a language-agnostic proxy for DT. We evaluate S-DAT across eleven diverse languages, including English, Spanish, German, Russian, Hindi, and Japanese (Kanji, Hiragana, Katakana), demonstrating robust and consistent scoring across linguistic contexts. Unlike prior DAT approaches, the S-DAT shows convergent validity with other DT measures and correct discriminant validity with convergent thinking. This cross-linguistic flexibility allows for more inclusive, global-scale creativity research, addressing key limitations of earlier approaches. S-DAT provides a powerful tool for fairer, more comprehensive evaluation of cognitive flexibility in diverse populations and can be freely assessed online: this https URL.</li>
</ul>

<h3>Title: 2D-3D Attention and Entropy for Pose Robust 2D Facial Recognition</h3>
<ul>
<li><strong>Authors: </strong>J. Brennan Peace, Shuowen Hu, Benjamin S. Riggan</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.09073">https://arxiv.org/abs/2505.09073</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.09073">https://arxiv.org/pdf/2505.09073</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.09073]] 2D-3D Attention and Entropy for Pose Robust 2D Facial Recognition(https://arxiv.org/abs/2505.09073)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Despite recent advances in facial recognition, there remains a fundamental issue concerning degradations in performance due to substantial perspective (pose) differences between enrollment and query (probe) imagery. Therefore, we propose a novel domain adaptive framework to facilitate improved performances across large discrepancies in pose by enabling image-based (2D) representations to infer properties of inherently pose invariant point cloud (3D) representations. Specifically, our proposed framework achieves better pose invariance by using (1) a shared (joint) attention mapping to emphasize common patterns that are most correlated between 2D facial images and 3D facial data and (2) a joint entropy regularizing loss to promote better consistency$\unicode{x2014}$enhancing correlations among the intersecting 2D and 3D representations$\unicode{x2014}$by leveraging both attention maps. This framework is evaluated on FaceScape and ARL-VTF datasets, where it outperforms competitive methods by achieving profile (90$\unicode{x00b0}$$\unicode{x002b}$) TAR @ 1$\unicode{x0025}$ FAR improvements of at least 7.1$\unicode{x0025}$ and 1.57$\unicode{x0025}$, respectively.</li>
</ul>

<h3>Title: AdaFortiTran: An Adaptive Transformer Model for Robust OFDM Channel Estimation</h3>
<ul>
<li><strong>Authors: </strong>Berkay Guler, Hamid Jafarkhani</a></li>
<li><strong>Subjects: </strong>cs.LG, eess.SP</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.09076">https://arxiv.org/abs/2505.09076</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.09076">https://arxiv.org/pdf/2505.09076</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.09076]] AdaFortiTran: An Adaptive Transformer Model for Robust OFDM Channel Estimation(https://arxiv.org/abs/2505.09076)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, transformer</a></li>
<li><strong>Abstract: </strong>Deep learning models for channel estimation in Orthogonal Frequency Division Multiplexing (OFDM) systems often suffer from performance degradation under fast-fading channels and low-SNR scenarios. To address these limitations, we introduce the Adaptive Fortified Transformer (AdaFortiTran), a novel model specifically designed to enhance channel estimation in challenging environments. Our approach employs convolutional layers that exploit locality bias to capture strong correlations between neighboring channel elements, combined with a transformer encoder that applies the global Attention mechanism to channel patches. This approach effectively models both long-range dependencies and spectro-temporal interactions within single OFDM frames. We further augment the model's adaptability by integrating nonlinear representations of available channel statistics SNR, delay spread, and Doppler shift as priors. A residual connection is employed to merge global features from the transformer with local features from early convolutional processing, followed by final convolutional layers to refine the hierarchical channel representation. Despite its compact architecture, AdaFortiTran achieves up to 6 dB reduction in mean squared error (MSE) compared to state-of-the-art models. Tested across a wide range of Doppler shifts (200-1000 Hz), SNRs (0 to 25 dB), and delay spreads (50-300 ns), it demonstrates superior robustness in high-mobility environments.</li>
</ul>

<h3>Title: CEC-Zero: Chinese Error Correction Solution Based on LLM</h3>
<ul>
<li><strong>Authors: </strong>Sophie Zhang, Zhiming Lin</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.09082">https://arxiv.org/abs/2505.09082</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.09082">https://arxiv.org/pdf/2505.09082</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.09082]] CEC-Zero: Chinese Error Correction Solution Based on LLM(https://arxiv.org/abs/2505.09082)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, generative, large language model</a></li>
<li><strong>Abstract: </strong>Recent advancements in large language models (LLMs) demonstrate exceptional Chinese text processing capabilities, particularly in Chinese Spelling Correction (CSC). While LLMs outperform traditional BERT-based models in accuracy and robustness, challenges persist in reliability and generalization. This paper proposes CEC-Zero, a novel reinforcement learning (RL) framework enabling LLMs to self-correct through autonomous error strategy learning without external supervision. By integrating RL with LLMs' generative power, the method eliminates dependency on annotated data or auxiliary models. Experiments reveal RL-enhanced LLMs achieve industry-viable accuracy and superior cross-domain generalization, offering a scalable solution for reliability optimization in Chinese NLP applications. This breakthrough facilitates LLM deployment in practical Chinese text correction scenarios while establishing a new paradigm for self-improving language models.</li>
</ul>

<h3>Title: Generating time-consistent dynamics with discriminator-guided image diffusion models</h3>
<ul>
<li><strong>Authors: </strong>Philipp Hess, Maximilian Gelbrecht, Christof Schötz, Michael Aich, Yu Huang, Shangshang Yang, Niklas Boers</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.09089">https://arxiv.org/abs/2505.09089</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.09089">https://arxiv.org/pdf/2505.09089</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.09089]] Generating time-consistent dynamics with discriminator-guided image diffusion models(https://arxiv.org/abs/2505.09089)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>Realistic temporal dynamics are crucial for many video generation, processing and modelling applications, e.g. in computational fluid dynamics, weather prediction, or long-term climate simulations. Video diffusion models (VDMs) are the current state-of-the-art method for generating highly realistic dynamics. However, training VDMs from scratch can be challenging and requires large computational resources, limiting their wider application. Here, we propose a time-consistency discriminator that enables pretrained image diffusion models to generate realistic spatiotemporal dynamics. The discriminator guides the sampling inference process and does not require extensions or finetuning of the image diffusion model. We compare our approach against a VDM trained from scratch on an idealized turbulence simulation and a real-world global precipitation dataset. Our approach performs equally well in terms of temporal consistency, shows improved uncertainty calibration and lower biases compared to the VDM, and achieves stable centennial-scale climate simulations at daily time steps.</li>
</ul>

<h3>Title: Argus: Federated Non-convex Bilevel Learning over 6G Space-Air-Ground Integrated Network</h3>
<ul>
<li><strong>Authors: </strong>Ya Liu, Kai Yang, Yu Zhu, Keying Yang, Haibo Zhao</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.09106">https://arxiv.org/abs/2505.09106</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.09106">https://arxiv.org/pdf/2505.09106</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.09106]] Argus: Federated Non-convex Bilevel Learning over 6G Space-Air-Ground Integrated Network(https://arxiv.org/abs/2505.09106)</code><input type="text"></li>
<li><strong>Keywords: </strong>federate</a></li>
<li><strong>Abstract: </strong>The space-air-ground integrated network (SAGIN) has recently emerged as a core element in the 6G networks. However, traditional centralized and synchronous optimization algorithms are unsuitable for SAGIN due to infrastructureless and time-varying environments. This paper aims to develop a novel Asynchronous algorithm a.k.a. Argus for tackling non-convex and non-smooth decentralized federated bilevel learning over SAGIN. The proposed algorithm allows networked agents (e.g. autonomous aerial vehicles) to tackle bilevel learning problems in time-varying networks asynchronously, thereby averting stragglers from impeding the overall training speed. We provide a theoretical analysis of the iteration complexity, communication complexity, and computational complexity of Argus. Its effectiveness is further demonstrated through numerical experiments.</li>
</ul>

<h3>Title: Toward Malicious Clients Detection in Federated Learning</h3>
<ul>
<li><strong>Authors: </strong>Zhihao Dou, Jiaqi Wang, Wei Sun, Zhuqing Liu, Minghong Fang</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.DC, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.09110">https://arxiv.org/abs/2505.09110</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.09110">https://arxiv.org/pdf/2505.09110</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.09110]] Toward Malicious Clients Detection in Federated Learning(https://arxiv.org/abs/2505.09110)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack, robust, federate</a></li>
<li><strong>Abstract: </strong>Federated learning (FL) enables multiple clients to collaboratively train a global machine learning model without sharing their raw data. However, the decentralized nature of FL introduces vulnerabilities, particularly to poisoning attacks, where malicious clients manipulate their local models to disrupt the training process. While Byzantine-robust aggregation rules have been developed to mitigate such attacks, they remain inadequate against more advanced threats. In response, recent advancements have focused on FL detection techniques to identify potentially malicious participants. Unfortunately, these methods often misclassify numerous benign clients as threats or rely on unrealistic assumptions about the server's capabilities. In this paper, we propose a novel algorithm, SafeFL, specifically designed to accurately identify malicious clients in FL. The SafeFL approach involves the server collecting a series of global models to generate a synthetic dataset, which is then used to distinguish between malicious and benign models based on their behavior. Extensive testing demonstrates that SafeFL outperforms existing methods, offering superior efficiency and accuracy in detecting malicious clients.</li>
</ul>

<h3>Title: Sequential Treatment Effect Estimation with Unmeasured Confounders</h3>
<ul>
<li><strong>Authors: </strong>Yingrong Wang, Anpeng Wu, Baohong Li, Ziyang Xiao, Ruoxuan Xiong, Qing Han, Kun Kuang</a></li>
<li><strong>Subjects: </strong>cs.LG, stat.ME</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.09113">https://arxiv.org/abs/2505.09113</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.09113">https://arxiv.org/pdf/2505.09113</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.09113]] Sequential Treatment Effect Estimation with Unmeasured Confounders(https://arxiv.org/abs/2505.09113)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>This paper studies the cumulative causal effects of sequential treatments in the presence of unmeasured confounders. It is a critical issue in sequential decision-making scenarios where treatment decisions and outcomes dynamically evolve over time. Advanced causal methods apply transformer as a backbone to model such time sequences, which shows superiority in capturing long time dependence and periodic patterns via attention mechanism. However, even they control the observed confounding, these estimators still suffer from unmeasured confounders, which influence both treatment assignments and outcomes. How to adjust the latent confounding bias in sequential treatment effect estimation remains an open challenge. Therefore, we propose a novel Decomposing Sequential Instrumental Variable framework for CounterFactual Regression (DSIV-CFR), relying on a common negative control assumption. Specifically, an instrumental variable (IV) is a special negative control exposure, while the previous outcome serves as a negative control outcome. This allows us to recover the IVs latent in observation variables and estimate sequential treatment effects via a generalized moment condition. We conducted experiments on 4 datasets and achieved significant performance in one- and multi-step prediction, supported by which we can identify optimal treatments for dynamic systems.</li>
</ul>

<h3>Title: Seeing Beyond the Scene: Enhancing Vision-Language Models with Interactional Reasoning</h3>
<ul>
<li><strong>Authors: </strong>Dayong Liang, Changmeng Zheng, Zhiyuan Wen, Yi Cai, Xiao-Yong Wei, Qing Li</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.09118">https://arxiv.org/abs/2505.09118</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.09118">https://arxiv.org/pdf/2505.09118</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.09118]] Seeing Beyond the Scene: Enhancing Vision-Language Models with Interactional Reasoning(https://arxiv.org/abs/2505.09118)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction</a></li>
<li><strong>Abstract: </strong>Traditional scene graphs primarily focus on spatial relationships, limiting vision-language models' (VLMs) ability to reason about complex interactions in visual scenes. This paper addresses two key challenges: (1) conventional detection-to-construction methods produce unfocused, contextually irrelevant relationship sets, and (2) existing approaches fail to form persistent memories for generalizing interaction reasoning to new scenes. We propose Interaction-augmented Scene Graph Reasoning (ISGR), a framework that enhances VLMs' interactional reasoning through three complementary components. First, our dual-stream graph constructor combines SAM-powered spatial relation extraction with interaction-aware captioning to generate functionally salient scene graphs with spatial grounding. Second, we employ targeted interaction queries to activate VLMs' latent knowledge of object functionalities, converting passive recognition into active reasoning about how objects work together. Finally, we introduce a lone-term memory reinforcement learning strategy with a specialized interaction-focused reward function that transforms transient patterns into long-term reasoning heuristics. Extensive experiments demonstrate that our approach significantly outperforms baseline methods on interaction-heavy reasoning benchmarks, with particularly strong improvements on complex scene understanding tasks. The source code can be accessed at this https URL.</li>
</ul>

<h3>Title: Promoting SAM for Camouflaged Object Detection via Selective Key Point-based Guidance</h3>
<ul>
<li><strong>Authors: </strong>Guoying Liang, Su Yang</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.09123">https://arxiv.org/abs/2505.09123</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.09123">https://arxiv.org/pdf/2505.09123</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.09123]] Promoting SAM for Camouflaged Object Detection via Selective Key Point-based Guidance(https://arxiv.org/abs/2505.09123)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>Big model has emerged as a new research paradigm that can be applied to various down-stream tasks with only minor effort for domain adaption. Correspondingly, this study tackles Camouflaged Object Detection (COD) leveraging the Segment Anything Model (SAM). The previous studies declared that SAM is not workable for COD but this study reveals that SAM works if promoted properly, for which we devise a new framework to render point promotions: First, we develop the Promotion Point Targeting Network (PPT-net) to leverage multi-scale features in predicting the probabilities of camouflaged objects' presences at given candidate points over the image. Then, we develop a key point selection (KPS) algorithm to deploy both positive and negative point promotions contrastively to SAM to guide the segmentation. It is the first work to facilitate big model for COD and achieves plausible results experimentally over the existing methods on 3 data sets under 6 metrics. This study demonstrates an off-the-shelf methodology for COD by leveraging SAM, which gains advantage over designing professional models from scratch, not only in performance, but also in turning the problem to a less challenging task, that is, seeking informative but not exactly precise promotions.</li>
</ul>

<h3>Title: WSCIF: A Weakly-Supervised Color Intelligence Framework for Tactical Anomaly Detection in Surveillance Keyframes</h3>
<ul>
<li><strong>Authors: </strong>Wei Meng</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.09129">https://arxiv.org/abs/2505.09129</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.09129">https://arxiv.org/pdf/2505.09129</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.09129]] WSCIF: A Weakly-Supervised Color Intelligence Framework for Tactical Anomaly Detection in Surveillance Keyframes(https://arxiv.org/abs/2505.09129)</code><input type="text"></li>
<li><strong>Keywords: </strong>security</a></li>
<li><strong>Abstract: </strong>The deployment of traditional deep learning models in high-risk security tasks in an unlabeled, data-non-exploitable video intelligence environment faces significant challenges. In this paper, we propose a lightweight anomaly detection framework based on color features for surveillance video clips in a high sensitivity tactical mission, aiming to quickly identify and interpret potential threat events under resource-constrained and data-sensitive conditions. The method fuses unsupervised KMeans clustering with RGB channel histogram modeling to achieve composite detection of structural anomalies and color mutation signals in key frames. The experiment takes an operation surveillance video occurring in an African country as a research sample, and successfully identifies multiple highly anomalous frames related to high-energy light sources, target presence, and reflective interference under the condition of no access to the original data. The results show that this method can be effectively used for tactical assassination warning, suspicious object screening and environmental drastic change monitoring with strong deployability and tactical interpretation value. The study emphasizes the importance of color features as low semantic battlefield signal carriers, and its battlefield intelligent perception capability will be further extended by combining graph neural networks and temporal modeling in the future.</li>
</ul>

<h3>Title: Fair Clustering via Alignment</h3>
<ul>
<li><strong>Authors: </strong>Kunwoong Kim, Jihu Lee, Sangchul Park, Yongdai Kim</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.09131">https://arxiv.org/abs/2505.09131</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.09131">https://arxiv.org/pdf/2505.09131</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.09131]] Fair Clustering via Alignment(https://arxiv.org/abs/2505.09131)</code><input type="text"></li>
<li><strong>Keywords: </strong>protect, fair</a></li>
<li><strong>Abstract: </strong>Algorithmic fairness in clustering aims to balance the proportions of instances assigned to each cluster with respect to a given sensitive attribute. While recently developed fair clustering algorithms optimize clustering objectives under specific fairness constraints, their inherent complexity or approximation often results in suboptimal clustering utility or numerical instability in practice. To resolve these limitations, we propose a new fair clustering algorithm based on a novel decomposition of the fair K-means clustering objective function. The proposed algorithm, called Fair Clustering via Alignment (FCA), operates by alternately (i) finding a joint probability distribution to align the data from different protected groups, and (ii) optimizing cluster centers in the aligned space. A key advantage of FCA is that it theoretically guarantees approximately optimal clustering utility for any given fairness level without complex constraints, thereby enabling high-utility fair clustering in practice. Experiments show that FCA outperforms existing methods by (i) attaining a superior trade-off between fairness level and clustering utility, and (ii) achieving near-perfect fairness without numerical instability.</li>
</ul>

<h3>Title: Beyond General Prompts: Automated Prompt Refinement using Contrastive Class Alignment Scores for Disambiguating Objects in Vision-Language Models</h3>
<ul>
<li><strong>Authors: </strong>Lucas Choi, Ross Greer</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.09139">https://arxiv.org/abs/2505.09139</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.09139">https://arxiv.org/pdf/2505.09139</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.09139]] Beyond General Prompts: Automated Prompt Refinement using Contrastive Class Alignment Scores for Disambiguating Objects in Vision-Language Models(https://arxiv.org/abs/2505.09139)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer, large language model</a></li>
<li><strong>Abstract: </strong>Vision-language models (VLMs) offer flexible object detection through natural language prompts but suffer from performance variability depending on prompt phrasing. In this paper, we introduce a method for automated prompt refinement using a novel metric called the Contrastive Class Alignment Score (CCAS), which ranks prompts based on their semantic alignment with a target object class while penalizing similarity to confounding classes. Our method generates diverse prompt candidates via a large language model and filters them through CCAS, computed using prompt embeddings from a sentence transformer. We evaluate our approach on challenging object categories, demonstrating that our automatic selection of high-precision prompts improves object detection accuracy without the need for additional model training or labeled data. This scalable and model-agnostic pipeline offers a principled alternative to manual prompt engineering for VLM-based detection systems.</li>
</ul>

<h3>Title: TopoDiT-3D: Topology-Aware Diffusion Transformer with Bottleneck Structure for 3D Point Cloud Generation</h3>
<ul>
<li><strong>Authors: </strong>Zechao Guan, Feng Yan, Shuai Du, Lin Ma, Qingshan Liu</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.09140">https://arxiv.org/abs/2505.09140</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.09140">https://arxiv.org/pdf/2505.09140</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.09140]] TopoDiT-3D: Topology-Aware Diffusion Transformer with Bottleneck Structure for 3D Point Cloud Generation(https://arxiv.org/abs/2505.09140)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction, diffusion, transformer</a></li>
<li><strong>Abstract: </strong>Recent advancements in Diffusion Transformer (DiT) models have significantly improved 3D point cloud generation. However, existing methods primarily focus on local feature extraction while overlooking global topological information, such as voids, which are crucial for maintaining shape consistency and capturing complex geometries. To address this limitation, we propose TopoDiT-3D, a Topology-Aware Diffusion Transformer with a bottleneck structure for 3D point cloud generation. Specifically, we design the bottleneck structure utilizing Perceiver Resampler, which not only offers a mode to integrate topological information extracted through persistent homology into feature learning, but also adaptively filters out redundant local features to improve training efficiency. Experimental results demonstrate that TopoDiT-3D outperforms state-of-the-art models in visual quality, diversity, and training efficiency. Furthermore, TopoDiT-3D demonstrates the importance of rich topological information for 3D point cloud generation and its synergy with conventional local feature learning. Videos and code are available at this https URL.</li>
</ul>

<h3>Title: AMSnet 2.0: A Large AMS Database with AI Segmentation for Net Detection</h3>
<ul>
<li><strong>Authors: </strong>Yichen Shi, Zhuofu Tao, Yuhao Gao, Li Huang, Hongyang Wang, Zhiping Yu, Ting-Jung Lin, Lei He</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.09155">https://arxiv.org/abs/2505.09155</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.09155">https://arxiv.org/pdf/2505.09155</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.09155]] AMSnet 2.0: A Large AMS Database with AI Segmentation for Net Detection(https://arxiv.org/abs/2505.09155)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, large language model, segmentation</a></li>
<li><strong>Abstract: </strong>Current multimodal large language models (MLLMs) struggle to understand circuit schematics due to their limited recognition capabilities. This could be attributed to the lack of high-quality schematic-netlist training data. Existing work such as AMSnet applies schematic parsing to generate netlists. However, these methods rely on hard-coded heuristics and are difficult to apply to complex or noisy schematics in this paper. We therefore propose a novel net detection mechanism based on segmentation with high robustness. The proposed method also recovers positional information, allowing digital reconstruction of schematics. We then expand AMSnet dataset with schematic images from various sources and create AMSnet 2.0. AMSnet 2.0 contains 2,686 circuits with schematic images, Spectre-formatted netlists, OpenAccess digital schematics, and positional information for circuit components and nets, whereas AMSnet only includes 792 circuits with SPICE netlists but no digital schematics.</li>
</ul>

<h3>Title: A Multi-Task Foundation Model for Wireless Channel Representation Using Contrastive and Masked Autoencoder Learning</h3>
<ul>
<li><strong>Authors: </strong>Berkay Guler, Giovanni Geraci, Hamid Jafarkhani</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, eess.SP</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.09160">https://arxiv.org/abs/2505.09160</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.09160">https://arxiv.org/pdf/2505.09160</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.09160]] A Multi-Task Foundation Model for Wireless Channel Representation Using Contrastive and Masked Autoencoder Learning(https://arxiv.org/abs/2505.09160)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Current applications of self-supervised learning to wireless channel representation often borrow paradigms developed for text and image processing, without fully addressing the unique characteristics and constraints of wireless communications. Aiming to fill this gap, we first propose WiMAE (Wireless Masked Autoencoder), a transformer-based encoder-decoder foundation model pretrained on a realistic open-source multi-antenna wireless channel dataset. Building upon this foundation, we develop ContraWiMAE, which enhances WiMAE by incorporating a contrastive learning objective alongside the reconstruction task in a unified multi-task framework. By warm-starting from pretrained WiMAE weights and generating positive pairs via noise injection, the contrastive component enables the model to capture both structural and discriminative features, enhancing representation quality beyond what reconstruction alone can achieve. Through extensive evaluation on unseen scenarios, we demonstrate the effectiveness of both approaches across multiple downstream tasks, with ContraWiMAE showing further improvements in linear separability and adaptability in diverse wireless environments. Comparative evaluations against a state-of-the-art wireless channel foundation model confirm the superior performance and data efficiency of our models, highlighting their potential as powerful baselines for future research in self-supervised wireless channel representation learning.</li>
</ul>

<h3>Title: DRRNet: Macro-Micro Feature Fusion and Dual Reverse Refinement for Camouflaged Object Detection</h3>
<ul>
<li><strong>Authors: </strong>Jianlin Sun, Xiaolin Fang, Juwei Guan, Dongdong Gui, Teqi Wang, Tongxin Zhu</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.09168">https://arxiv.org/abs/2505.09168</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.09168">https://arxiv.org/pdf/2505.09168</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.09168]] DRRNet: Macro-Micro Feature Fusion and Dual Reverse Refinement for Camouflaged Object Detection(https://arxiv.org/abs/2505.09168)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction</a></li>
<li><strong>Abstract: </strong>The core challenge in Camouflage Object Detection (COD) lies in the indistinguishable similarity between targets and backgrounds in terms of color, texture, and shape. This causes existing methods to either lose edge details (such as hair-like fine structures) due to over-reliance on global semantic information or be disturbed by similar backgrounds (such as vegetation patterns) when relying solely on local features. We propose DRRNet, a four-stage architecture characterized by a "context-detail-fusion-refinement" pipeline to address these issues. Specifically, we introduce an Omni-Context Feature Extraction Module to capture global camouflage patterns and a Local Detail Extraction Module to supplement microstructural information for the full-scene context module. We then design a module for forming dual representations of scene understanding and structural awareness, which fuses panoramic features and local features across various scales. In the decoder, we also introduce a reverse refinement module that leverages spatial edge priors and frequency-domain noise suppression to perform a two-stage inverse refinement of the output. By applying two successive rounds of inverse refinement, the model effectively suppresses background interference and enhances the continuity of object boundaries. Experimental results demonstrate that DRRNet significantly outperforms state-of-the-art methods on benchmark datasets. Our code is available at this https URL.</li>
</ul>

<h3>Title: Quotient Complex Transformer (QCformer) for Perovskite Data Analysis</h3>
<ul>
<li><strong>Authors: </strong>Xinyu You, Xiang Liu, Chuan-Shen Hu, Kelin Xia, Tze Chien Sum</a></li>
<li><strong>Subjects: </strong>cs.LG, cond-mat.mtrl-sci</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.09174">https://arxiv.org/abs/2505.09174</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.09174">https://arxiv.org/pdf/2505.09174</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.09174]] Quotient Complex Transformer (QCformer) for Perovskite Data Analysis(https://arxiv.org/abs/2505.09174)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>The discovery of novel functional materials is crucial in addressing the challenges of sustainable energy generation and climate change. Hybrid organic-inorganic perovskites (HOIPs) have gained attention for their exceptional optoelectronic properties in photovoltaics. Recently, geometric deep learning, particularly graph neural networks (GNNs), has shown strong potential in predicting material properties and guiding material design. However, traditional GNNs often struggle to capture the periodic structures and higher-order interactions prevalent in such systems. To address these limitations, we propose a novel representation based on quotient complexes (QCs) and introduce the Quotient Complex Transformer (QCformer) for material property prediction. A material structure is modeled as a quotient complex, which encodes both pairwise and many-body interactions via simplices of varying dimensions and captures material periodicity through a quotient operation. Our model leverages higher-order features defined on simplices and processes them using a simplex-based Transformer module. We pretrain QCformer on benchmark datasets such as the Materials Project and JARVIS, and fine-tune it on HOIP datasets. The results show that QCformer outperforms state-of-the-art models in HOIP property prediction, demonstrating its effectiveness. The quotient complex representation and QCformer model together contribute a powerful new tool for predictive modeling of perovskite materials.</li>
</ul>

<h3>Title: UniCAD: Efficient and Extendable Architecture for Multi-Task Computer-Aided Diagnosis System</h3>
<ul>
<li><strong>Authors: </strong>Yitao Zhu, Yuan Yin, Zhenrong Shen, Zihao Zhao, Haiyu Song, Sheng Wang, Dinggang Shen, Qian Wang</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.09178">https://arxiv.org/abs/2505.09178</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.09178">https://arxiv.org/pdf/2505.09178</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.09178]] UniCAD: Efficient and Extendable Architecture for Multi-Task Computer-Aided Diagnosis System(https://arxiv.org/abs/2505.09178)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>The growing complexity and scale of visual model pre-training have made developing and deploying multi-task computer-aided diagnosis (CAD) systems increasingly challenging and resource-intensive. Furthermore, the medical imaging community lacks an open-source CAD platform to enable the rapid creation of efficient and extendable diagnostic models. To address these issues, we propose UniCAD, a unified architecture that leverages the robust capabilities of pre-trained vision foundation models to seamlessly handle both 2D and 3D medical images while requiring only minimal task-specific parameters. UniCAD introduces two key innovations: (1) Efficiency: A low-rank adaptation strategy is employed to adapt a pre-trained visual model to the medical image domain, achieving performance on par with fully fine-tuned counterparts while introducing only 0.17% trainable parameters. (2) Plug-and-Play: A modular architecture that combines a frozen foundation model with multiple plug-and-play experts, enabling diverse tasks and seamless functionality expansion. Building on this unified CAD architecture, we establish an open-source platform where researchers can share and access lightweight CAD experts, fostering a more equitable and efficient research ecosystem. Comprehensive experiments across 12 diverse medical datasets demonstrate that UniCAD consistently outperforms existing methods in both accuracy and deployment efficiency. The source code and project page are available at this https URL.</li>
</ul>

<h3>Title: Zero-shot Quantization: A Comprehensive Survey</h3>
<ul>
<li><strong>Authors: </strong>Minjun Kim, Jaehyeon Choi, Jongkeun Lee, Wonjin Cho, U Kang</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.09188">https://arxiv.org/abs/2505.09188</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.09188">https://arxiv.org/pdf/2505.09188</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.09188]] Zero-shot Quantization: A Comprehensive Survey(https://arxiv.org/abs/2505.09188)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, privacy</a></li>
<li><strong>Abstract: </strong>Network quantization has proven to be a powerful approach to reduce the memory and computational demands of deep learning models for deployment on resource-constrained devices. However, traditional quantization methods often rely on access to training data, which is impractical in many real-world scenarios due to privacy, security, or regulatory constraints. Zero-shot Quantization (ZSQ) emerges as a promising solution, achieving quantization without requiring any real data. In this paper, we provide a comprehensive overview of ZSQ methods and their recent advancements. First, we provide a formal definition of the ZSQ problem and highlight the key challenges. Then, we categorize the existing ZSQ methods into classes based on data generation strategies, and analyze their motivations, core ideas, and key takeaways. Lastly, we suggest future research directions to address the remaining limitations and advance the field of ZSQ. To the best of our knowledge, this paper is the first in-depth survey on ZSQ.</li>
</ul>

<h3>Title: The Larger the Merrier? Efficient Large AI Model Inference in Wireless Edge Networks</h3>
<ul>
<li><strong>Authors: </strong>Zhonghao Lyu, Ming Xiao, Jie Xu, Mikael Skoglund, Marco Di Renzo</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.09214">https://arxiv.org/abs/2505.09214</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.09214">https://arxiv.org/pdf/2505.09214</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.09214]] The Larger the Merrier? Efficient Large AI Model Inference in Wireless Edge Networks(https://arxiv.org/abs/2505.09214)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy</a></li>
<li><strong>Abstract: </strong>The growing demand for large artificial intelligence model (LAIM) services is driving a paradigm shift from traditional cloud-based inference to edge-based inference for low-latency, privacy-preserving applications. In particular, edge-device co-inference, which partitions LAIMs between edge devices and servers, has emerged as a promising strategy for resource-efficient LAIM execution in wireless networks. In this paper, we investigate a pruning-aware LAIM co-inference scheme, where a pre-trained LAIM is pruned and partitioned into on-device and on-server sub-models for deployment. For analysis, we first prove that the LAIM output distortion is upper bounded by its parameter distortion. Then, we derive a lower bound on parameter distortion via rate-distortion theory, analytically capturing the relationship between pruning ratio and co-inference performance. Next, based on the analytical results, we formulate an LAIM co-inference distortion bound minimization problem by jointly optimizing the pruning ratio, transmit power, and computation frequency under system latency, energy, and available resource constraints. Moreover, we propose an efficient algorithm to tackle the considered highly non-convex problem. Finally, extensive simulations demonstrate the effectiveness of the proposed design. In particular, model parameter distortion is shown to provide a reliable bound on output distortion. Also, the proposed joint pruning ratio and resource management design achieves superior performance in balancing trade-offs among inference performance, system latency, and energy consumption compared with benchmark schemes, such as fully on-device and on-server inference. Moreover, the split point is shown to play a critical role in system performance optimization under heterogeneous and resource-limited edge environments.</li>
</ul>

<h3>Title: Securing P4 Programs by Information Flow Control</h3>
<ul>
<li><strong>Authors: </strong>Anoud Alshnakat, Amir M. Ahmadian, Musard Balliu, Roberto Guanciale, Mads Dam</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.09221">https://arxiv.org/abs/2505.09221</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.09221">https://arxiv.org/pdf/2505.09221</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.09221]] Securing P4 Programs by Information Flow Control(https://arxiv.org/abs/2505.09221)</code><input type="text"></li>
<li><strong>Keywords: </strong>security</a></li>
<li><strong>Abstract: </strong>Software-Defined Networking (SDN) has transformed network architectures by decoupling the control and data-planes, enabling fine-grained control over packet processing and forwarding. P4, a language designed for programming data-plane devices, allows developers to define custom packet processing behaviors directly on programmable network devices. This provides greater control over packet forwarding, inspection, and modification. However, the increased flexibility provided by P4 also brings significant security challenges, particularly in managing sensitive data and preventing information leakage within the data-plane. This paper presents a novel security type system for analyzing information flow in P4 programs that combines security types with interval analysis. The proposed type system allows the specification of security policies in terms of input and output packet bit fields rather than program variables. We formalize this type system and prove it sound, guaranteeing that well-typed programs satisfy noninterference. Our prototype implementation, Tap4s, is evaluated on several use cases, demonstrating its effectiveness in detecting security violations and information leakages.</li>
</ul>

<h3>Title: Stable and Convexified Information Bottleneck Optimization via Symbolic Continuation and Entropy-Regularized Trajectories</h3>
<ul>
<li><strong>Authors: </strong>Faruk Alpay</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.09239">https://arxiv.org/abs/2505.09239</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.09239">https://arxiv.org/pdf/2505.09239</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.09239]] Stable and Convexified Information Bottleneck Optimization via Symbolic Continuation and Entropy-Regularized Trajectories(https://arxiv.org/abs/2505.09239)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>The Information Bottleneck (IB) method frequently suffers from unstable optimization, characterized by abrupt representation shifts near critical points of the IB trade-off parameter, beta. In this paper, I introduce a novel approach to achieve stable and convex IB optimization through symbolic continuation and entropy-regularized trajectories. I analytically prove convexity and uniqueness of the IB solution path when an entropy regularization term is included, and demonstrate how this stabilizes representation learning across a wide range of \b{eta} values. Additionally, I provide extensive sensitivity analyses around critical points (beta) with statistically robust uncertainty quantification (95% confidence intervals). The open-source implementation, experimental results, and reproducibility framework included in this work offer a clear path for practical deployment and future extension of my proposed method.</li>
</ul>

<h3>Title: A Surrogate Model for the Forward Design of Multi-layered Metasurface-based Radar Absorbing Structures</h3>
<ul>
<li><strong>Authors: </strong>Vineetha Joy, Aditya Anand, Nidhi, Anshuman Kumar, Amit Sethi, Hema Singh</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.09251">https://arxiv.org/abs/2505.09251</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.09251">https://arxiv.org/pdf/2505.09251</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.09251]] A Surrogate Model for the Forward Design of Multi-layered Metasurface-based Radar Absorbing Structures(https://arxiv.org/abs/2505.09251)</code><input type="text"></li>
<li><strong>Keywords: </strong>steal</a></li>
<li><strong>Abstract: </strong>Metasurface-based radar absorbing structures (RAS) are highly preferred for applications like stealth technology, electromagnetic (EM) shielding, etc. due to their capability to achieve frequency selective absorption characteristics with minimal thickness and reduced weight penalty. However, the conventional approach for the EM design and optimization of these structures relies on forward simulations, using full wave simulation tools, to predict the electromagnetic (EM) response of candidate meta atoms. This process is computationally intensive, extremely time consuming and requires exploration of large design spaces. To overcome this challenge, we propose a surrogate model that significantly accelerates the prediction of EM responses of multi-layered metasurface-based RAS. A convolutional neural network (CNN) based architecture with Huber loss function has been employed to estimate the reflection characteristics of the RAS model. The proposed model achieved a cosine similarity of 99.9% and a mean square error of 0.001 within 1000 epochs of training. The efficiency of the model has been established via full wave simulations as well as experiment where it demonstrated significant reduction in computational time while maintaining high predictive accuracy.</li>
</ul>

<h3>Title: Zero-Shot Multi-modal Large Language Model v.s. Supervised Deep Learning: A Comparative Study on CT-Based Intracranial Hemorrhage Subtyping</h3>
<ul>
<li><strong>Authors: </strong>Yinuo Wang, Yue Zeng, Kai Chen, Cai Meng, Chao Pan, Zhouping Tang</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.09252">https://arxiv.org/abs/2505.09252</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.09252">https://arxiv.org/pdf/2505.09252</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.09252]] Zero-Shot Multi-modal Large Language Model v.s. Supervised Deep Learning: A Comparative Study on CT-Based Intracranial Hemorrhage Subtyping(https://arxiv.org/abs/2505.09252)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability, transformer, large language model</a></li>
<li><strong>Abstract: </strong>Introduction: Timely identification of intracranial hemorrhage (ICH) subtypes on non-contrast computed tomography is critical for prognosis prediction and therapeutic decision-making, yet remains challenging due to low contrast and blurring boundaries. This study evaluates the performance of zero-shot multi-modal large language models (MLLMs) compared to traditional deep learning methods in ICH binary classification and subtyping. Methods: We utilized a dataset provided by RSNA, comprising 192 NCCT volumes. The study compares various MLLMs, including GPT-4o, Gemini 2.0 Flash, and Claude 3.5 Sonnet V2, with conventional deep learning models, including ResNet50 and Vision Transformer. Carefully crafted prompts were used to guide MLLMs in tasks such as ICH presence, subtype classification, localization, and volume estimation. Results: The results indicate that in the ICH binary classification task, traditional deep learning models outperform MLLMs comprehensively. For subtype classification, MLLMs also exhibit inferior performance compared to traditional deep learning models, with Gemini 2.0 Flash achieving an macro-averaged precision of 0.41 and a macro-averaged F1 score of 0.31. Conclusion: While MLLMs excel in interactive capabilities, their overall accuracy in ICH subtyping is inferior to deep networks. However, MLLMs enhance interpretability through language interactions, indicating potential in medical imaging analysis. Future efforts will focus on model refinement and developing more precise MLLMs to improve performance in three-dimensional medical image processing.</li>
</ul>

<h3>Title: Instantiating Standards: Enabling Standard-Driven Text TTP Extraction with Evolvable Memory</h3>
<ul>
<li><strong>Authors: </strong>Cheng Meng, ZhengWei Jiang, QiuYun Wang, XinYi Li, ChunYan Ma, FangMing Dong, FangLi Ren, BaoXu Liu</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.09261">https://arxiv.org/abs/2505.09261</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.09261">https://arxiv.org/pdf/2505.09261</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.09261]] Instantiating Standards: Enabling Standard-Driven Text TTP Extraction with Evolvable Memory(https://arxiv.org/abs/2505.09261)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction, explainability, large language model</a></li>
<li><strong>Abstract: </strong>Extracting MITRE ATT\&CK Tactics, Techniques, and Procedures (TTPs) from natural language threat reports is crucial yet challenging. Existing methods primarily focus on performance metrics using data-driven approaches, often neglecting mechanisms to ensure faithful adherence to the official standard. This deficiency compromises reliability and consistency of TTP assignments, creating intelligence silos and contradictory threat assessments across organizations. To address this, we introduce a novel framework that converts abstract standard definitions into actionable, contextualized knowledge. Our method utilizes Large Language Model (LLM) to generate, update, and apply this knowledge. This framework populates an evolvable memory with dual-layer situational knowledge instances derived from labeled examples and official definitions. The first layer identifies situational contexts (e.g., "Communication with C2 using encoded subdomains"), while the second layer captures distinctive features that differentiate similar techniques (e.g., distinguishing T1132 "Data Encoding" from T1071 "Application Layer Protocol" based on whether the focus is on encoding methods or protocol usage). This structured approach provides a transparent basis for explainable TTP assignments and enhanced human oversight, while also helping to standardize other TTP extraction systems. Experiments show our framework (using Qwen2.5-32B) boosts Technique F1 scores by 11\% over GPT-4o. Qualitative analysis confirms superior standardization, enhanced transparency, and improved explainability in real-world threat intelligence scenarios. To the best of our knowledge, this is the first work that uses the LLM to generate, update, and apply the a new knowledge for TTP extraction.</li>
</ul>

<h3>Title: Few-Shot Anomaly-Driven Generation for Anomaly Classification and Segmentation</h3>
<ul>
<li><strong>Authors: </strong>Guan Gui, Bin-Bin Gao, Jun Liu, Chengjie Wang, Yunsheng Wu</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.09263">https://arxiv.org/abs/2505.09263</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.09263">https://arxiv.org/pdf/2505.09263</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.09263]] Few-Shot Anomaly-Driven Generation for Anomaly Classification and Segmentation(https://arxiv.org/abs/2505.09263)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, segmentation</a></li>
<li><strong>Abstract: </strong>Anomaly detection is a practical and challenging task due to the scarcity of anomaly samples in industrial inspection. Some existing anomaly detection methods address this issue by synthesizing anomalies with noise or external data. However, there is always a large semantic gap between synthetic and real-world anomalies, resulting in weak performance in anomaly detection. To solve the problem, we propose a few-shot Anomaly-driven Generation (AnoGen) method, which guides the diffusion model to generate realistic and diverse anomalies with only a few real anomalies, thereby benefiting training anomaly detection models. Specifically, our work is divided into three stages. In the first stage, we learn the anomaly distribution based on a few given real anomalies and inject the learned knowledge into an embedding. In the second stage, we use the embedding and given bounding boxes to guide the diffusion model to generate realistic and diverse anomalies on specific objects (or textures). In the final stage, we propose a weakly-supervised anomaly detection method to train a more powerful model with generated anomalies. Our method builds upon DRAEM and DesTSeg as the foundation model and conducts experiments on the commonly used industrial anomaly detection dataset, MVTec. The experiments demonstrate that our generated anomalies effectively improve the model performance of both anomaly classification and segmentation tasks simultaneously, \eg, DRAEM and DseTSeg achieved a 5.8\% and 1.5\% improvement in AU-PR metric on segmentation task, respectively. The code and generated anomalous data are available at this https URL.</li>
</ul>

<h3>Title: Learning to Detect Multi-class Anomalies with Just One Normal Image Prompt</h3>
<ul>
<li><strong>Authors: </strong>Bin-Bin Gao</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.09264">https://arxiv.org/abs/2505.09264</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.09264">https://arxiv.org/pdf/2505.09264</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.09264]] Learning to Detect Multi-class Anomalies with Just One Normal Image Prompt(https://arxiv.org/abs/2505.09264)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer, segmentation</a></li>
<li><strong>Abstract: </strong>Unsupervised reconstruction networks using self-attention transformers have achieved state-of-the-art performance for multi-class (unified) anomaly detection with a single model. However, these self-attention reconstruction models primarily operate on target features, which may result in perfect reconstruction for both normal and anomaly features due to high consistency with context, leading to failure in detecting anomalies. Additionally, these models often produce inaccurate anomaly segmentation due to performing reconstruction in a low spatial resolution latent space. To enable reconstruction models enjoying high efficiency while enhancing their generalization for unified anomaly detection, we propose a simple yet effective method that reconstructs normal features and restores anomaly features with just One Normal Image Prompt (OneNIP). In contrast to previous work, OneNIP allows for the first time to reconstruct or restore anomalies with just one normal image prompt, effectively boosting unified anomaly detection performance. Furthermore, we propose a supervised refiner that regresses reconstruction errors by using both real normal and synthesized anomalous images, which significantly improves pixel-level anomaly segmentation. OneNIP outperforms previous methods on three industry anomaly detection benchmarks: MVTec, BTAD, and VisA. The code and pre-trained models are available at this https URL.</li>
</ul>

<h3>Title: MetaUAS: Universal Anomaly Segmentation with One-Prompt Meta-Learning</h3>
<ul>
<li><strong>Authors: </strong>Bin-Bin Gao</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.09265">https://arxiv.org/abs/2505.09265</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.09265">https://arxiv.org/pdf/2505.09265</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.09265]] MetaUAS: Universal Anomaly Segmentation with One-Prompt Meta-Learning(https://arxiv.org/abs/2505.09265)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>Zero- and few-shot visual anomaly segmentation relies on powerful vision-language models that detect unseen anomalies using manually designed textual prompts. However, visual representations are inherently independent of language. In this paper, we explore the potential of a pure visual foundation model as an alternative to widely used vision-language models for universal visual anomaly segmentation. We present a novel paradigm that unifies anomaly segmentation into change segmentation. This paradigm enables us to leverage large-scale synthetic image pairs, featuring object-level and local region changes, derived from existing image datasets, which are independent of target anomaly datasets. We propose a one-prompt Meta-learning framework for Universal Anomaly Segmentation (MetaUAS) that is trained on this synthetic dataset and then generalizes well to segment any novel or unseen visual anomalies in the real world. To handle geometrical variations between prompt and query images, we propose a soft feature alignment module that bridges paired-image change perception and single-image semantic segmentation. This is the first work to achieve universal anomaly segmentation using a pure vision model without relying on special anomaly detection datasets and pre-trained visual-language models. Our method effectively and efficiently segments any anomalies with only one normal image prompt and enjoys training-free without guidance from language. Our MetaUAS significantly outperforms previous zero-shot, few-shot, and even full-shot anomaly segmentation methods. The code and pre-trained models are available at this https URL.</li>
</ul>

<h3>Title: Recent Advances in Medical Imaging Segmentation: A Survey</h3>
<ul>
<li><strong>Authors: </strong>Fares Bougourzi, Abdenour Hadid</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.09274">https://arxiv.org/abs/2505.09274</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.09274">https://arxiv.org/pdf/2505.09274</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.09274]] Recent Advances in Medical Imaging Segmentation: A Survey(https://arxiv.org/abs/2505.09274)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, robust, generative, segmentation</a></li>
<li><strong>Abstract: </strong>Medical imaging is a cornerstone of modern healthcare, driving advancements in diagnosis, treatment planning, and patient care. Among its various tasks, segmentation remains one of the most challenging problem due to factors such as data accessibility, annotation complexity, structural variability, variation in medical imaging modalities, and privacy constraints. Despite recent progress, achieving robust generalization and domain adaptation remains a significant hurdle, particularly given the resource-intensive nature of some proposed models and their reliance on domain expertise. This survey explores cutting-edge advancements in medical image segmentation, focusing on methodologies such as Generative AI, Few-Shot Learning, Foundation Models, and Universal Models. These approaches offer promising solutions to longstanding challenges. We provide a comprehensive overview of the theoretical foundations, state-of-the-art techniques, and recent applications of these methods. Finally, we discuss inherent limitations, unresolved issues, and future research directions aimed at enhancing the practicality and accessibility of segmentation models in medical imaging. We are maintaining a \href{this https URL}{GitHub Repository} to continue tracking and updating innovations in this field.</li>
</ul>

<h3>Title: Privacy-Preserving Runtime Verification</h3>
<ul>
<li><strong>Authors: </strong>Thomas A. Henzinger, Mahyar Karimi, K. S. Thejaswini</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.FL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.09276">https://arxiv.org/abs/2505.09276</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.09276">https://arxiv.org/pdf/2505.09276</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.09276]] Privacy-Preserving Runtime Verification(https://arxiv.org/abs/2505.09276)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, protect</a></li>
<li><strong>Abstract: </strong>Runtime verification offers scalable solutions to improve the safety and reliability of systems. However, systems that require verification or monitoring by a third party to ensure compliance with a specification might contain sensitive information, causing privacy concerns when usual runtime verification approaches are used. Privacy is compromised if protected information about the system, or sensitive data that is processed by the system, is revealed. In addition, revealing the specification being monitored may undermine the essence of third-party verification. In this work, we propose two novel protocols for the privacy-preserving runtime verification of systems against formal sequential specifications. In our first protocol, the monitor verifies whether the system satisfies the specification without learning anything else, though both parties are aware of the specification. Our second protocol ensures that the system remains oblivious to the monitored specification, while the monitor learns only whether the system satisfies the specification and nothing more. Our protocols adapt and improve existing techniques used in cryptography, and more specifically, multi-party computation. The sequential specification defines the observation step of the monitor, whose granularity depends on the situation (e.g., banks may be monitored on a daily basis). Our protocols exchange a single message per observation step, after an initialisation phase. This design minimises communication overhead, enabling relatively lightweight privacy-preserving monitoring. We implement our approach for monitoring specifications described by register automata and evaluate it experimentally.</li>
</ul>

<h3>Title: Generating Full-field Evolution of Physical Dynamics from Irregular Sparse Observations</h3>
<ul>
<li><strong>Authors: </strong>Panqi Chen, Yifan Sun, Lei Cheng, Yang Yang, Weichang Li, Yang Liu, Weiqing Liu, Jiang Bian, Shikai Fang</a></li>
<li><strong>Subjects: </strong>cs.LG, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.09284">https://arxiv.org/abs/2505.09284</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.09284">https://arxiv.org/pdf/2505.09284</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.09284]] Generating Full-field Evolution of Physical Dynamics from Irregular Sparse Observations(https://arxiv.org/abs/2505.09284)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, generative</a></li>
<li><strong>Abstract: </strong>Modeling and reconstructing multidimensional physical dynamics from sparse and off-grid observations presents a fundamental challenge in scientific research. Recently, diffusion-based generative modeling shows promising potential for physical simulation. However, current approaches typically operate on on-grid data with preset spatiotemporal resolution, but struggle with the sparsely observed and continuous nature of real-world physical dynamics. To fill the gaps, we present SDIFT, Sequential DIffusion in Functional Tucker space, a novel framework that generates full-field evolution of physical dynamics from irregular sparse observations. SDIFT leverages the functional Tucker model as the latent space representer with proven universal approximation property, and represents observations as latent functions and Tucker core sequences. We then construct a sequential diffusion model with temporally augmented UNet in the functional Tucker space, denoising noise drawn from a Gaussian process to generate the sequence of core tensors. At the posterior sampling stage, we propose a Message-Passing Posterior Sampling mechanism, enabling conditional generation of the entire sequence guided by observations at limited time steps. We validate SDIFT on three physical systems spanning astronomical (supernova explosions, light-year scale), environmental (ocean sound speed fields, kilometer scale), and molecular (organic liquid, millimeter scale) domains, demonstrating significant improvements in both reconstruction accuracy and computational efficiency compared to state-of-the-art approaches.</li>
</ul>

<h3>Title: A Scalable Unsupervised Framework for multi-aspect labeling of Multilingual and Multi-Domain Review Data</h3>
<ul>
<li><strong>Authors: </strong>Jiin Park, Misuk Kim</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.09286">https://arxiv.org/abs/2505.09286</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.09286">https://arxiv.org/pdf/2505.09286</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.09286]] A Scalable Unsupervised Framework for multi-aspect labeling of Multilingual and Multi-Domain Review Data(https://arxiv.org/abs/2505.09286)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, large language model</a></li>
<li><strong>Abstract: </strong>Effectively analyzing online review data is essential across industries. However, many existing studies are limited to specific domains and languages or depend on supervised learning approaches that require large-scale labeled datasets. To address these limitations, we propose a multilingual, scalable, and unsupervised framework for cross-domain aspect detection. This framework is designed for multi-aspect labeling of multilingual and multi-domain review data. In this study, we apply automatic labeling to Korean and English review datasets spanning various domains and assess the quality of the generated labels through extensive experiments. Aspect category candidates are first extracted through clustering, and each review is then represented as an aspect-aware embedding vector using negative sampling. To evaluate the framework, we conduct multi-aspect labeling and fine-tune several pretrained language models to measure the effectiveness of the automatically generated labels. Results show that these models achieve high performance, demonstrating that the labels are suitable for training. Furthermore, comparisons with publicly available large language models highlight the framework's superior consistency and scalability when processing large-scale data. A human evaluation also confirms that the quality of the automatic labels is comparable to those created manually. This study demonstrates the potential of a robust multi-aspect labeling approach that overcomes limitations of supervised methods and is adaptable to multilingual, multi-domain environments. Future research will explore automatic review summarization and the integration of artificial intelligence agents to further improve the efficiency and depth of review analysis.</li>
</ul>

<h3>Title: Ranking-Based At-Risk Student Prediction Using Federated Learning and Differential Features</h3>
<ul>
<li><strong>Authors: </strong>Shunsuke Yoneda, Valdemar Švábenský, Gen Li, Daisuke Deguchi, Atsushi Shimada</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CY</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.09287">https://arxiv.org/abs/2505.09287</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.09287">https://arxiv.org/pdf/2505.09287</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.09287]] Ranking-Based At-Risk Student Prediction Using Federated Learning and Differential Features(https://arxiv.org/abs/2505.09287)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, federate</a></li>
<li><strong>Abstract: </strong>Digital textbooks are widely used in various educational contexts, such as university courses and online lectures. Such textbooks yield learning log data that have been used in numerous educational data mining (EDM) studies for student behavior analysis and performance prediction. However, these studies have faced challenges in integrating confidential data, such as academic records and learning logs, across schools due to privacy concerns. Consequently, analyses are often conducted with data limited to a single school, which makes developing high-performing and generalizable models difficult. This study proposes a method that combines federated learning and differential features to address these issues. Federated learning enables model training without centralizing data, thereby preserving student privacy. Differential features, which utilize relative values instead of absolute values, enhance model performance and generalizability. To evaluate the proposed method, a model for predicting at-risk students was trained using data from 1,136 students across 12 courses conducted over 4 years, and validated on hold-out test data from 5 other courses. Experimental results demonstrated that the proposed method addresses privacy concerns while achieving performance comparable to that of models trained via centralized learning in terms of Top-n precision, nDCG, and PR-AUC. Furthermore, using differential features improved prediction performance across all evaluation datasets compared to non-differential approaches. The trained models were also applicable for early prediction, achieving high performance in detecting at-risk students in earlier stages of the semester within the validation datasets.</li>
</ul>

<h3>Title: Detecting Sybil Addresses in Blockchain Airdrops: A Subgraph-based Feature Propagation and Fusion Approach</h3>
<ul>
<li><strong>Authors: </strong>Qiangqiang Liu, Qian Huang, Frank Fan, Haishan Wu, Xueyan Tang</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.09313">https://arxiv.org/abs/2505.09313</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.09313">https://arxiv.org/pdf/2505.09313</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.09313]] Detecting Sybil Addresses in Blockchain Airdrops: A Subgraph-based Feature Propagation and Fusion Approach(https://arxiv.org/abs/2505.09313)</code><input type="text"></li>
<li><strong>Keywords: </strong>secure, security, attack, extraction, fair</a></li>
<li><strong>Abstract: </strong>Sybil attacks pose a significant security threat to blockchain ecosystems, particularly in token airdrop events. This paper proposes a novel sybil address identification method based on subgraph feature extraction lightGBM. The method first constructs a two-layer deep transaction subgraph for each address, then extracts key event operation features according to the lifecycle of sybil addresses, including the time of first transaction, first gas acquisition, participation in airdrop activities, and last transaction. These temporal features effectively capture the consistency of sybil address behavior operations. Additionally, the method extracts amount and network structure features, comprehensively describing address behavior patterns and network topology through feature propagation and fusion. Experiments conducted on a dataset containing 193,701 addresses (including 23,240 sybil addresses) show that this method outperforms existing approaches in terms of precision, recall, F1 score, and AUC, with all metrics exceeding 0.9. The methods and results of this study can be further applied to broader blockchain security areas such as transaction manipulation identification and token liquidity risk assessment, contributing to the construction of a more secure and fair blockchain ecosystem.</li>
</ul>

<h3>Title: Scent of Knowledge: Optimizing Search-Enhanced Reasoning with Information Foraging</h3>
<ul>
<li><strong>Authors: </strong>Hongjin Qian, Zheng Liu</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.IR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.09316">https://arxiv.org/abs/2505.09316</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.09316">https://arxiv.org/pdf/2505.09316</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.09316]] Scent of Knowledge: Optimizing Search-Enhanced Reasoning with Information Foraging(https://arxiv.org/abs/2505.09316)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, large language model</a></li>
<li><strong>Abstract: </strong>Augmenting large language models (LLMs) with external retrieval has become a standard method to address their inherent knowledge cutoff limitations. However, traditional retrieval-augmented generation methods employ static, pre-inference retrieval strategies, making them inadequate for complex tasks involving ambiguous, multi-step, or evolving information needs. Recent advances in test-time scaling techniques have demonstrated significant potential in enabling LLMs to dynamically interact with external tools, motivating the shift toward adaptive inference-time retrieval. Inspired by Information Foraging Theory (IFT), we propose InForage, a reinforcement learning framework that formalizes retrieval-augmented reasoning as a dynamic information-seeking process. Unlike existing approaches, InForage explicitly rewards intermediate retrieval quality, encouraging LLMs to iteratively gather and integrate information through adaptive search behaviors. To facilitate training, we construct a human-guided dataset capturing iterative search and reasoning trajectories for complex, real-world web tasks. Extensive evaluations across general question answering, multi-hop reasoning tasks, and a newly developed real-time web QA dataset demonstrate InForage's superior performance over baseline methods. These results highlight InForage's effectiveness in building robust, adaptive, and efficient reasoning agents.</li>
</ul>

<h3>Title: Evaluating the Robustness of Adversarial Defenses in Malware Detection Systems</h3>
<ul>
<li><strong>Authors: </strong>Mostafa Jafari, Alireza Shameli-Sendi</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.09342">https://arxiv.org/abs/2505.09342</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.09342">https://arxiv.org/pdf/2505.09342</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.09342]] Evaluating the Robustness of Adversarial Defenses in Malware Detection Systems(https://arxiv.org/abs/2505.09342)</code><input type="text"></li>
<li><strong>Keywords: </strong>defense, attack, robust</a></li>
<li><strong>Abstract: </strong>Machine learning is a key tool for Android malware detection, effectively identifying malicious patterns in apps. However, ML-based detectors are vulnerable to evasion attacks, where small, crafted changes bypass detection. Despite progress in adversarial defenses, the lack of comprehensive evaluation frameworks in binary-constrained domains limits understanding of their robustness. We introduce two key contributions. First, Prioritized Binary Rounding, a technique to convert continuous perturbations into binary feature spaces while preserving high attack success and low perturbation size. Second, the sigma-binary attack, a novel adversarial method for binary domains, designed to achieve attack goals with minimal feature changes. Experiments on the Malscan dataset show that sigma-binary outperforms existing attacks and exposes key vulnerabilities in state-of-the-art defenses. Defenses equipped with adversary detectors, such as KDE, DLA, DNN+, and ICNN, exhibit significant brittleness, with attack success rates exceeding 90% using fewer than 10 feature modifications and reaching 100% with just 20. Adversarially trained defenses, including AT-rFGSM-k, AT-MaxMA, improves robustness under small budgets but remains vulnerable to unrestricted perturbations, with attack success rates of 99.45% and 96.62%, respectively. Although PAD-SMA demonstrates strong robustness against state-of-the-art gradient-based adversarial attacks by maintaining an attack success rate below 16.55%, the sigma-binary attack significantly outperforms these methods, achieving a 94.56% success rate under unrestricted perturbations. These findings highlight the critical need for precise method like sigma-binary to expose hidden vulnerabilities in existing defenses and support the development of more resilient malware detection systems.</li>
</ul>

<h3>Title: GreenFactory: Ensembling Zero-Cost Proxies to Estimate Performance of Neural Networks</h3>
<ul>
<li><strong>Authors: </strong>Gabriel Cortês, Nuno Lourenço, Paolo Romano, Penousal Machado</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.09344">https://arxiv.org/abs/2505.09344</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.09344">https://arxiv.org/pdf/2505.09344</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.09344]] GreenFactory: Ensembling Zero-Cost Proxies to Estimate Performance of Neural Networks(https://arxiv.org/abs/2505.09344)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Determining the performance of a Deep Neural Network during Neural Architecture Search processes is essential for identifying optimal architectures and hyperparameters. Traditionally, this process requires training and evaluation of each network, which is time-consuming and resource-intensive. Zero-cost proxies estimate performance without training, serving as an alternative to traditional training. However, recent proxies often lack generalization across diverse scenarios and provide only relative rankings rather than predicted accuracies. To address these limitations, we propose GreenFactory, an ensemble of zero-cost proxies that leverages a random forest regressor to combine multiple predictors' strengths and directly predict model test accuracy. We evaluate GreenFactory on NATS-Bench, achieving robust results across multiple datasets. Specifically, GreenFactory achieves high Kendall correlations on NATS-Bench-SSS, indicating substantial agreement between its predicted scores and actual performance: 0.907 for CIFAR-10, 0.945 for CIFAR-100, and 0.920 for ImageNet-16-120. Similarly, on NATS-Bench-TSS, we achieve correlations of 0.921 for CIFAR-10, 0.929 for CIFAR-100, and 0.908 for ImageNet-16-120, showcasing its reliability in both search spaces.</li>
</ul>

<h3>Title: Marigold: Affordable Adaptation of Diffusion-Based Image Generators for Image Analysis</h3>
<ul>
<li><strong>Authors: </strong>Bingxin Ke, Kevin Qu, Tianfu Wang, Nando Metzger, Shengyu Huang, Bo Li, Anton Obukhov, Konrad Schindler</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.09358">https://arxiv.org/abs/2505.09358</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.09358">https://arxiv.org/pdf/2505.09358</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.09358]] Marigold: Affordable Adaptation of Diffusion-Based Image Generators for Image Analysis(https://arxiv.org/abs/2505.09358)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, transformer, generative</a></li>
<li><strong>Abstract: </strong>The success of deep learning in computer vision over the past decade has hinged on large labeled datasets and strong pretrained models. In data-scarce settings, the quality of these pretrained models becomes crucial for effective transfer learning. Image classification and self-supervised learning have traditionally been the primary methods for pretraining CNNs and transformer-based architectures. Recently, the rise of text-to-image generative models, particularly those using denoising diffusion in a latent space, has introduced a new class of foundational models trained on massive, captioned image datasets. These models' ability to generate realistic images of unseen content suggests they possess a deep understanding of the visual world. In this work, we present Marigold, a family of conditional generative models and a fine-tuning protocol that extracts the knowledge from pretrained latent diffusion models like Stable Diffusion and adapts them for dense image analysis tasks, including monocular depth estimation, surface normals prediction, and intrinsic decomposition. Marigold requires minimal modification of the pre-trained latent diffusion model's architecture, trains with small synthetic datasets on a single GPU over a few days, and demonstrates state-of-the-art zero-shot generalization. Project page: this https URL</li>
</ul>

<h3>Title: RobustSpring: Benchmarking Robustness to Image Corruptions for Optical Flow, Scene Flow and Stereo</h3>
<ul>
<li><strong>Authors: </strong>Jenny Schmalfuss, Victor Oei, Lukas Mehl, Madlen Bartsch, Shashank Agnihotri, Margret Keuper, Andrés Bruhn</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.09368">https://arxiv.org/abs/2505.09368</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.09368">https://arxiv.org/pdf/2505.09368</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.09368]] RobustSpring: Benchmarking Robustness to Image Corruptions for Optical Flow, Scene Flow and Stereo(https://arxiv.org/abs/2505.09368)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Standard benchmarks for optical flow, scene flow, and stereo vision algorithms generally focus on model accuracy rather than robustness to image corruptions like noise or rain. Hence, the resilience of models to such real-world perturbations is largely unquantified. To address this, we present RobustSpring, a comprehensive dataset and benchmark for evaluating robustness to image corruptions for optical flow, scene flow, and stereo models. RobustSpring applies 20 different image corruptions, including noise, blur, color changes, quality degradations, and weather distortions, in a time-, stereo-, and depth-consistent manner to the high-resolution Spring dataset, creating a suite of 20,000 corrupted images that reflect challenging conditions. RobustSpring enables comparisons of model robustness via a new corruption robustness metric. Integration with the Spring benchmark enables public two-axis evaluations of both accuracy and robustness. We benchmark a curated selection of initial models, observing that accurate models are not necessarily robust and that robustness varies widely by corruption type. RobustSpring is a new computer vision benchmark that treats robustness as a first-class citizen to foster models that combine accuracy with resilience. It will be available at this https URL.</li>
</ul>

<h3>Title: MAKE: Multi-Aspect Knowledge-Enhanced Vision-Language Pretraining for Zero-shot Dermatological Assessment</h3>
<ul>
<li><strong>Authors: </strong>Siyuan Yan, Xieji Li, Ming Hu, Yiwen Jiang, Zhen Yu, Zongyuan Ge</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.09372">https://arxiv.org/abs/2505.09372</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.09372">https://arxiv.org/pdf/2505.09372</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.09372]] MAKE: Multi-Aspect Knowledge-Enhanced Vision-Language Pretraining for Zero-shot Dermatological Assessment(https://arxiv.org/abs/2505.09372)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Dermatological diagnosis represents a complex multimodal challenge that requires integrating visual features with specialized clinical knowledge. While vision-language pretraining (VLP) has advanced medical AI, its effectiveness in dermatology is limited by text length constraints and the lack of structured texts. In this paper, we introduce MAKE, a Multi-Aspect Knowledge-Enhanced vision-language pretraining framework for zero-shot dermatological tasks. Recognizing that comprehensive dermatological descriptions require multiple knowledge aspects that exceed standard text constraints, our framework introduces: (1) a multi-aspect contrastive learning strategy that decomposes clinical narratives into knowledge-enhanced sub-texts through large language models, (2) a fine-grained alignment mechanism that connects subcaptions with diagnostically relevant image features, and (3) a diagnosis-guided weighting scheme that adaptively prioritizes different sub-captions based on clinical significance prior. Through pretraining on 403,563 dermatological image-text pairs collected from education resources, MAKE significantly outperforms state-of-the-art VLP models on eight datasets across zero-shot skin disease classification, concept annotation, and cross-modal retrieval tasks. Our code will be made publicly available at https: //github.com/SiyuanYan1/MAKE.</li>
</ul>

<h3>Title: DNS Query Forgery: A Client-Side Defense Against Mobile App Traffic Profiling</h3>
<ul>
<li><strong>Authors: </strong>Andrea Jimenez-Berenguel, César Gil, Carlos Garcia-Rubio, Jordi Forné, Celeste Campo</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.NI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.09374">https://arxiv.org/abs/2505.09374</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.09374">https://arxiv.org/pdf/2505.09374</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.09374]] DNS Query Forgery: A Client-Side Defense Against Mobile App Traffic Profiling(https://arxiv.org/abs/2505.09374)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, protect, defense</a></li>
<li><strong>Abstract: </strong>Mobile applications continuously generate DNS queries that can reveal sensitive user behavioral patterns even when communications are encrypted. This paper presents a privacy enhancement framework based on query forgery to protect users against profiling attempts that leverage these background communications. We first mathematically model user profiles as probability distributions over interest categories derived from mobile application traffic. We then evaluate three query forgery strategies -- uniform sampling, TrackMeNot-based generation, and an optimized approach that minimizes Kullback-Leibler divergence -- to quantify their effectiveness in obfuscating user profiles. Then we create a synthetic dataset comprising 1,000 user traces constructed from real mobile application traffic and we extract the user profiles based on DNS traffic. Our evaluation reveals that a 50\% privacy improvement is achievable with less than 20\% traffic overhead when using our approach, while achieving 100\% privacy protection requires approximately 40-60\% additional traffic. We further propose a modular system architecture for practical implementation of our protection mechanisms on mobile devices. This work offers a client-side privacy solution that operates without third-party trust requirements, empowering individual users to defend against traffic analysis without compromising application functionality.</li>
</ul>

<h3>Title: Text-driven Motion Generation: Overview, Challenges and Directions</h3>
<ul>
<li><strong>Authors: </strong>Ali Rida Sahili, Najett Neji, Hedi Tabia</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.09379">https://arxiv.org/abs/2505.09379</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.09379">https://arxiv.org/pdf/2505.09379</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.09379]] Text-driven Motion Generation: Overview, Challenges and Directions(https://arxiv.org/abs/2505.09379)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>Text-driven motion generation offers a powerful and intuitive way to create human movements directly from natural language. By removing the need for predefined motion inputs, it provides a flexible and accessible approach to controlling animated characters. This makes it especially useful in areas like virtual reality, gaming, human-computer interaction, and robotics. In this review, we first revisit the traditional perspective on motion synthesis, where models focused on predicting future poses from observed initial sequences, often conditioned on action labels. We then provide a comprehensive and structured survey of modern text-to-motion generation approaches, categorizing them from two complementary perspectives: (i) architectural, dividing methods into VAE-based, diffusion-based, and hybrid models; and (ii) motion representation, distinguishing between discrete and continuous motion generation strategies. In addition, we explore the most widely used datasets, evaluation methods, and recent benchmarks that have shaped progress in this area. With this survey, we aim to capture where the field currently stands, bring attention to its key challenges and limitations, and highlight promising directions for future exploration. We hope this work offers a valuable starting point for researchers and practitioners working to push the boundaries of language-driven human motion synthesis.</li>
</ul>

<h3>Title: Examining Deployment and Refinement of the VIOLA-AI Intracranial Hemorrhage Model Using an Interactive NeoMedSys Platform</h3>
<ul>
<li><strong>Authors: </strong>Qinghui Liu, Jon Nesvold, Hanna Raaum, Elakkyen Murugesu, Martin Røvang, Bradley J Maclntosh, Atle Bjørnerud, Karoline Skogen</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.09380">https://arxiv.org/abs/2505.09380</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.09380">https://arxiv.org/pdf/2505.09380</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.09380]] Examining Deployment and Refinement of the VIOLA-AI Intracranial Hemorrhage Model Using an Interactive NeoMedSys Platform(https://arxiv.org/abs/2505.09380)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>Background: There are many challenges and opportunities in the clinical deployment of AI tools in radiology. The current study describes a radiology software platform called NeoMedSys that can enable efficient deployment and refinements of AI models. We evaluated the feasibility and effectiveness of running NeoMedSys for three months in real-world clinical settings and focused on improvement performance of an in-house developed AI model (VIOLA-AI) designed for intracranial hemorrhage (ICH) detection. Methods: NeoMedSys integrates tools for deploying, testing, and optimizing AI models with a web-based medical image viewer, annotation system, and hospital-wide radiology information systems. A pragmatic investigation was deployed using clinical cases of patients presenting to the largest Emergency Department in Norway (site-1) with suspected traumatic brain injury (TBI) or patients with suspected stroke (site-2). We assessed ICH classification performance as VIOLA-AI encountered new data and underwent pre-planned model retraining. Performance metrics included sensitivity, specificity, accuracy, and the area under the receiver operating characteristic curve (AUC). Results: NeoMedSys facilitated iterative improvements in the AI model, significantly enhancing its diagnostic accuracy. Automated bleed detection and segmentation were reviewed in near real-time to facilitate re-training VIOLA-AI. The iterative refinement process yielded a marked improvement in classification sensitivity, rising to 90.3% (from 79.2%), and specificity that reached 89.3% (from 80.7%). The bleed detection ROC analysis for the entire sample demonstrated a high area-under-the-curve (AUC) of 0.949 (from 0.873). Model refinement stages were associated with notable gains, highlighting the value of real-time radiologist feedback.</li>
</ul>

<h3>Title: CANTXSec: A Deterministic Intrusion Detection and Prevention System for CAN Bus Monitoring ECU Activations</h3>
<ul>
<li><strong>Authors: </strong>Denis Donadel, Kavya Balasubramanian, Alessandro Brighente, Bhaskar Ramasubramanian, Mauro Conti, Radha Poovendran</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.09384">https://arxiv.org/abs/2505.09384</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.09384">https://arxiv.org/pdf/2505.09384</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.09384]] CANTXSec: A Deterministic Intrusion Detection and Prevention System for CAN Bus Monitoring ECU Activations(https://arxiv.org/abs/2505.09384)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, attack</a></li>
<li><strong>Abstract: </strong>Despite being a legacy protocol with various known security issues, Controller Area Network (CAN) still represents the de-facto standard for communications within vehicles, ships, and industrial control systems. Many research works have designed Intrusion Detection Systems (IDSs) to identify attacks by training machine learning classifiers on bus traffic or its properties. Actions to take after detection are, on the other hand, less investigated, and prevention mechanisms usually include protocol modification (e.g., adding authentication). An effective solution has yet to be implemented on a large scale in the wild. The reasons are related to the effort to handle sporadic false positives, the inevitable delay introduced by authentication, and the closed-source automobile environment that does not easily permit modifying Electronic Control Units (ECUs) software. In this paper, we propose CANTXSec, the first deterministic Intrusion Detection and Prevention system based on physical ECU activations. It employs a new classification of attacks based on the attacker's need in terms of access level to the bus, distinguishing between Frame Injection Attacks (FIAs) (i.e., using frame-level access) and Single-Bit Attacks (SBAs) (i.e., employing bit-level access). CANTXSec detects and prevents classical attacks in the CAN bus, while detecting advanced attacks that have been less investigated in the literature. We prove the effectiveness of our solution on a physical testbed, where we achieve 100% detection accuracy in both classes of attacks while preventing 100% of FIAs. Moreover, to encourage developers to employ CANTXSec, we discuss implementation details, providing an analysis based on each user's risk assessment.</li>
</ul>

<h3>Title: FedSaaS: Class-Consistency Federated Semantic Segmentation via Global Prototype Supervision and Local Adversarial Harmonization</h3>
<ul>
<li><strong>Authors: </strong>Xiaoyang Yu, Xiaoming Wu, Xin Wang, Dongrun Li, Ming Yang, Peng Cheng</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.09385">https://arxiv.org/abs/2505.09385</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.09385">https://arxiv.org/pdf/2505.09385</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.09385]] FedSaaS: Class-Consistency Federated Semantic Segmentation via Global Prototype Supervision and Local Adversarial Harmonization(https://arxiv.org/abs/2505.09385)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, federate, segmentation</a></li>
<li><strong>Abstract: </strong>Federated semantic segmentation enables pixel-level classification in images through collaborative learning while maintaining data privacy. However, existing research commonly overlooks the fine-grained class relationships within the semantic space when addressing heterogeneous problems, particularly domain shift. This oversight results in ambiguities between class representation. To overcome this challenge, we propose a novel federated segmentation framework that strikes class consistency, termed FedSaaS. Specifically, we introduce class exemplars as a criterion for both local- and global-level class representations. On the server side, the uploaded class exemplars are leveraged to model class prototypes, which supervise global branch of clients, ensuring alignment with global-level representation. On the client side, we incorporate an adversarial mechanism to harmonize contributions of global and local branches, leading to consistent output. Moreover, multilevel contrastive losses are employed on both sides to enforce consistency between two-level representations in the same semantic space. Extensive experiments on several driving scene segmentation datasets demonstrate that our framework outperforms state-of-the-art methods, significantly improving average segmentation accuracy and effectively addressing the class-consistency representation problem.</li>
</ul>

<h3>Title: Qwen3 Technical Report</h3>
<ul>
<li><strong>Authors: </strong>An Yang, Anfeng Li, Baosong Yang, Beichen Zhang, Binyuan Hui, Bo Zheng, Bowen Yu, Chang Gao, Chengen Huang, Chenxu Lv, Chujie Zheng, Dayiheng Liu, Fan Zhou, Fei Huang, Feng Hu, Hao Ge, Haoran Wei, Huan Lin, Jialong Tang, Jian Yang, Jianhong Tu, Jianwei Zhang, Jianxin Yang, Jiaxi Yang, Jing Zhou, Jingren Zhou, Junyang Lin, Kai Dang, Keqin Bao, Kexin Yang, Le Yu, Lianghao Deng, Mei Li, Mingfeng Xue, Mingze Li, Pei Zhang, Peng Wang, Qin Zhu, Rui Men, Ruize Gao, Shixuan Liu, Shuang Luo, Tianhao Li, Tianyi Tang, Wenbiao Yin, Xingzhang Ren, Xinyu Wang, Xinyu Zhang, Xuancheng Ren, Yang Fan, Yang Su, Yichang Zhang, Yinger Zhang, Yu Wan, Yuqiong Liu, Zekun Wang, Zeyu Cui, Zhenru Zhang, Zhipeng Zhou, Zihan Qiu</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.09388">https://arxiv.org/abs/2505.09388</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.09388">https://arxiv.org/pdf/2505.09388</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.09388]] Qwen3 Technical Report(https://arxiv.org/abs/2505.09388)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>In this work, we present Qwen3, the latest version of the Qwen model family. Qwen3 comprises a series of large language models (LLMs) designed to advance performance, efficiency, and multilingual capabilities. The Qwen3 series includes models of both dense and Mixture-of-Expert (MoE) architectures, with parameter scales ranging from 0.6 to 235 billion. A key innovation in Qwen3 is the integration of thinking mode (for complex, multi-step reasoning) and non-thinking mode (for rapid, context-driven responses) into a unified framework. This eliminates the need to switch between different models--such as chat-optimized models (e.g., GPT-4o) and dedicated reasoning models (e.g., QwQ-32B)--and enables dynamic mode switching based on user queries or chat templates. Meanwhile, Qwen3 introduces a thinking budget mechanism, allowing users to allocate computational resources adaptively during inference, thereby balancing latency and performance based on task complexity. Moreover, by leveraging the knowledge from the flagship models, we significantly reduce the computational resources required to build smaller-scale models, while ensuring their highly competitive performance. Empirical evaluations demonstrate that Qwen3 achieves state-of-the-art results across diverse benchmarks, including tasks in code generation, mathematical reasoning, agent tasks, etc., competitive against larger MoE models and proprietary models. Compared to its predecessor Qwen2.5, Qwen3 expands multilingual support from 29 to 119 languages and dialects, enhancing global accessibility through improved cross-lingual understanding and generation capabilities. To facilitate reproducibility and community-driven research and development, all Qwen3 models are publicly accessible under Apache 2.0.</li>
</ul>

<h3>Title: FaceShield: Explainable Face Anti-Spoofing with Multimodal Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Hongyang Wang, Yichen Shi, Zhuofu Tao, Yuhao Gao, Liepiao Zhang, Xun Lin, Jun Feng, Xiaochen Yuan, Zitong Yu, Xiaochun Cao</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.09415">https://arxiv.org/abs/2505.09415</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.09415">https://arxiv.org/pdf/2505.09415</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.09415]] FaceShield: Explainable Face Anti-Spoofing with Multimodal Large Language Models(https://arxiv.org/abs/2505.09415)</code><input type="text"></li>
<li><strong>Keywords: </strong>protect, attack, interpretability, large language model</a></li>
<li><strong>Abstract: </strong>Face anti-spoofing (FAS) is crucial for protecting facial recognition systems from presentation attacks. Previous methods approached this task as a classification problem, lacking interpretability and reasoning behind the predicted results. Recently, multimodal large language models (MLLMs) have shown strong capabilities in perception, reasoning, and decision-making in visual tasks. However, there is currently no universal and comprehensive MLLM and dataset specifically designed for FAS task. To address this gap, we propose FaceShield, a MLLM for FAS, along with the corresponding pre-training and supervised fine-tuning (SFT) datasets, FaceShield-pre10K and FaceShield-sft45K. FaceShield is capable of determining the authenticity of faces, identifying types of spoofing attacks, providing reasoning for its judgments, and detecting attack areas. Specifically, we employ spoof-aware vision perception (SAVP) that incorporates both the original image and auxiliary information based on prior knowledge. We then use an prompt-guided vision token masking (PVTM) strategy to random mask vision tokens, thereby improving the model's generalization ability. We conducted extensive experiments on three benchmark datasets, demonstrating that FaceShield significantly outperforms previous deep learning models and general MLLMs on four FAS tasks, i.e., coarse-grained classification, fine-grained classification, reasoning, and attack localization. Our instruction datasets, protocols, and codes will be released soon.</li>
</ul>

<h3>Title: MoRAL: Motion-aware Multi-Frame 4D Radar and LiDAR Fusion for Robust 3D Object Detection</h3>
<ul>
<li><strong>Authors: </strong>Xiangyuan Peng, Yu Wang, Miao Tang, Bierzynski Kay, Lorenzo Servadei, Robert Wille</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.09422">https://arxiv.org/abs/2505.09422</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.09422">https://arxiv.org/pdf/2505.09422</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.09422]] MoRAL: Motion-aware Multi-Frame 4D Radar and LiDAR Fusion for Robust 3D Object Detection(https://arxiv.org/abs/2505.09422)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Reliable autonomous driving systems require accurate detection of traffic participants. To this end, multi-modal fusion has emerged as an effective strategy. In particular, 4D radar and LiDAR fusion methods based on multi-frame radar point clouds have demonstrated the effectiveness in bridging the point density gap. However, they often neglect radar point clouds' inter-frame misalignment caused by object movement during accumulation and do not fully exploit the object dynamic information from 4D radar. In this paper, we propose MoRAL, a motion-aware multi-frame 4D radar and LiDAR fusion framework for robust 3D object detection. First, a Motion-aware Radar Encoder (MRE) is designed to compensate for inter-frame radar misalignment from moving objects. Later, a Motion Attention Gated Fusion (MAGF) module integrate radar motion features to guide LiDAR features to focus on dynamic foreground objects. Extensive evaluations on the View-of-Delft (VoD) dataset demonstrate that MoRAL outperforms existing methods, achieving the highest mAP of 73.30% in the entire area and 88.68% in the driving corridor. Notably, our method also achieves the best AP of 69.67% for pedestrians in the entire area and 96.25% for cyclists in the driving corridor.</li>
</ul>

<h3>Title: SafePath: Conformal Prediction for Safe LLM-Based Autonomous Navigation</h3>
<ul>
<li><strong>Authors: </strong>Achref Doula, Max Mühläuser, Alejandro Sanchez Guinea</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.RO</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.09427">https://arxiv.org/abs/2505.09427</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.09427">https://arxiv.org/pdf/2505.09427</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.09427]] SafePath: Conformal Prediction for Safe LLM-Based Autonomous Navigation(https://arxiv.org/abs/2505.09427)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large Language Models (LLMs) show growing promise in autonomous driving by reasoning over complex traffic scenarios to generate path plans. However, their tendencies toward overconfidence, and hallucinations raise critical safety concerns. We introduce SafePath, a modular framework that augments LLM-based path planning with formal safety guarantees using conformal prediction. SafePath operates in three stages. In the first stage, we use an LLM that generates a set of diverse candidate paths, exploring possible trajectories based on agent behaviors and environmental cues. In the second stage, SafePath filters out high-risk trajectories while guaranteeing that at least one safe option is included with a user-defined probability, through a multiple-choice question-answering formulation that integrates conformal prediction. In the final stage, our approach selects the path with the lowest expected collision risk when uncertainty is low or delegates control to a human when uncertainty is high. We theoretically prove that SafePath guarantees a safe trajectory with a user-defined probability, and we show how its human delegation rate can be tuned to balance autonomy and safety. Extensive experiments on nuScenes and Highway-env show that SafePath reduces planning uncertainty by 77\% and collision rates by up to 70\%, demonstrating effectiveness in making LLM-driven path planning more safer.</li>
</ul>

<h3>Title: Endo-CLIP: Progressive Self-Supervised Pre-training on Raw Colonoscopy Records</h3>
<ul>
<li><strong>Authors: </strong>Yili He, Yan Zhu, Peiyao Fu, Ruijie Yang, Tianyi Chen, Zhihua Wang, Quanlin Li, Pinghong Zhou, Xian Yang, Shuo Wang</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.09435">https://arxiv.org/abs/2505.09435</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.09435">https://arxiv.org/pdf/2505.09435</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.09435]] Endo-CLIP: Progressive Self-Supervised Pre-training on Raw Colonoscopy Records(https://arxiv.org/abs/2505.09435)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Pre-training on image-text colonoscopy records offers substantial potential for improving endoscopic image analysis, but faces challenges including non-informative background images, complex medical terminology, and ambiguous multi-lesion descriptions. We introduce Endo-CLIP, a novel self-supervised framework that enhances Contrastive Language-Image Pre-training (CLIP) for this domain. Endo-CLIP's three-stage framework--cleansing, attunement, and unification--addresses these challenges by (1) removing background frames, (2) leveraging large language models to extract clinical attributes for fine-grained contrastive learning, and (3) employing patient-level cross-attention to resolve multi-polyp ambiguities. Extensive experiments demonstrate that Endo-CLIP significantly outperforms state-of-the-art pre-training methods in zero-shot and few-shot polyp detection and classification, paving the way for more accurate and clinically relevant endoscopic analysis.</li>
</ul>

<h3>Title: CXMArena: Unified Dataset to benchmark performance in realistic CXM Scenarios</h3>
<ul>
<li><strong>Authors: </strong>Raghav Garg, Kapil Sharma, Karan Gupta</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CL, cs.IR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.09436">https://arxiv.org/abs/2505.09436</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.09436">https://arxiv.org/pdf/2505.09436</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.09436]] CXMArena: Unified Dataset to benchmark performance in realistic CXM Scenarios(https://arxiv.org/abs/2505.09436)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, large language model</a></li>
<li><strong>Abstract: </strong>Large Language Models (LLMs) hold immense potential for revolutionizing Customer Experience Management (CXM), particularly in contact center operations. However, evaluating their practical utility in complex operational environments is hindered by data scarcity (due to privacy concerns) and the limitations of current benchmarks. Existing benchmarks often lack realism, failing to incorporate deep knowledge base (KB) integration, real-world noise, or critical operational tasks beyond conversational fluency. To bridge this gap, we introduce CXMArena, a novel, large-scale synthetic benchmark dataset specifically designed for evaluating AI in operational CXM contexts. Given the diversity in possible contact center features, we have developed a scalable LLM-powered pipeline that simulates the brand's CXM entities that form the foundation of our datasets-such as knowledge articles including product specifications, issue taxonomies, and contact center conversations. The entities closely represent real-world distribution because of controlled noise injection (informed by domain experts) and rigorous automated validation. Building on this, we release CXMArena, which provides dedicated benchmarks targeting five important operational tasks: Knowledge Base Refinement, Intent Prediction, Agent Quality Adherence, Article Search, and Multi-turn RAG with Integrated Tools. Our baseline experiments underscore the benchmark's difficulty: even state of the art embedding and generation models achieve only 68% accuracy on article search, while standard embedding methods yield a low F1 score of 0.3 for knowledge base refinement, highlighting significant challenges for current models necessitating complex pipelines and solutions over conventional techniques.</li>
</ul>

<h3>Title: MrTrack: Register Mamba for Needle Tracking with Rapid Reciprocating Motion during Ultrasound-Guided Aspiration Biopsy</h3>
<ul>
<li><strong>Authors: </strong>Yuelin Zhang, Qingpeng Ding, Long Lei, Yongxuan Feng, Raymond Shing-Yan Tang, Shing Shin Cheng</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.09450">https://arxiv.org/abs/2505.09450</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.09450">https://arxiv.org/pdf/2505.09450</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.09450]] MrTrack: Register Mamba for Needle Tracking with Rapid Reciprocating Motion during Ultrasound-Guided Aspiration Biopsy(https://arxiv.org/abs/2505.09450)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Ultrasound-guided fine needle aspiration (FNA) biopsy is a common minimally invasive diagnostic procedure. However, an aspiration needle tracker addressing rapid reciprocating motion is still missing. MrTrack, an aspiration needle tracker with a mamba-based register mechanism, is proposed. MrTrack leverages a Mamba-based register extractor to sequentially distill global context from each historical search map, storing these temporal cues in a register bank. The Mamba-based register retriever then retrieves temporal prompts from the register bank to provide external cues when current vision features are temporarily unusable due to rapid reciprocating motion and imaging degradation. A self-supervised register diversify loss is proposed to encourage feature diversity and dimension independence within the learned register, mitigating feature collapse. Comprehensive experiments conducted on both motorized and manual aspiration datasets demonstrate that MrTrack not only outperforms state-of-the-art trackers in accuracy and robustness but also achieves superior inference efficiency.</li>
</ul>

<h3>Title: Beyond Pixels: Leveraging the Language of Soccer to Improve Spatio-Temporal Action Detection in Broadcast Videos</h3>
<ul>
<li><strong>Authors: </strong>Jeremie Ochin, Raphael Chekroun, Bogdan Stanciulescu, Sotiris Manitsaris</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.09455">https://arxiv.org/abs/2505.09455</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.09455">https://arxiv.org/pdf/2505.09455</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.09455]] Beyond Pixels: Leveraging the Language of Soccer to Improve Spatio-Temporal Action Detection in Broadcast Videos(https://arxiv.org/abs/2505.09455)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction, transformer</a></li>
<li><strong>Abstract: </strong>State-of-the-art spatio-temporal action detection (STAD) methods show promising results for extracting soccer events from broadcast videos. However, when operated in the high-recall, low-precision regime required for exhaustive event coverage in soccer analytics, their lack of contextual understanding becomes apparent: many false positives could be resolved by considering a broader sequence of actions and game-state information. In this work, we address this limitation by reasoning at the game level and improving STAD through the addition of a denoising sequence transduction task. Sequences of noisy, context-free player-centric predictions are processed alongside clean game state information using a Transformer-based encoder-decoder model. By modeling extended temporal context and reasoning jointly over team-level dynamics, our method leverages the "language of soccer" - its tactical regularities and inter-player dependencies - to generate "denoised" sequences of actions. This approach improves both precision and recall in low-confidence regimes, enabling more reliable event extraction from broadcast video and complementing existing pixel-based methods.</li>
</ul>

<h3>Title: Variational Rank Reduction Autoencoder</h3>
<ul>
<li><strong>Authors: </strong>Jad Mounayer, Alicia Tierz, Jerome Tomezyk, Chady Ghnatios, Francisco Chinesta</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.09458">https://arxiv.org/abs/2505.09458</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.09458">https://arxiv.org/pdf/2505.09458</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.09458]] Variational Rank Reduction Autoencoder(https://arxiv.org/abs/2505.09458)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, generative</a></li>
<li><strong>Abstract: </strong>Deterministic Rank Reduction Autoencoders (RRAEs) enforce by construction a regularization on the latent space by applying a truncated SVD. While this regularization makes Autoencoders more powerful, using them for generative purposes is counter-intuitive due to their deterministic nature. On the other hand, Variational Autoencoders (VAEs) are well known for their generative abilities by learning a probabilistic latent space. In this paper, we present Variational Rank Reduction Autoencoders (VRRAEs), a model that leverages the advantages of both RRAEs and VAEs. Our claims and results show that when carefully sampling the latent space of RRAEs and further regularizing with the Kullback-Leibler (KL) divergence (similarly to VAEs), VRRAEs outperform RRAEs and VAEs. Additionally, we show that the regularization induced by the SVD not only makes VRRAEs better generators than VAEs, but also reduces the possibility of posterior collapse. Our results include a synthetic dataset of a small size that showcases the robustness of VRRAEs against collapse, and three real-world datasets; the MNIST, CelebA, and CIFAR-10, over which VRRAEs are shown to outperform both VAEs and RRAEs on many random generation and interpolation tasks based on the FID score.</li>
</ul>

<h3>Title: A 2D Semantic-Aware Position Encoding for Vision Transformers</h3>
<ul>
<li><strong>Authors: </strong>Xi Chen, Shiyang Zhou, Muqi Huang, Jiaxu Feng, Yun Xiong, Kun Zhou, Biao Yang, Yuhui Zhang, Huishuai Bao, Sijia Peng, Chuan Li, Feng Shi</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.09466">https://arxiv.org/abs/2505.09466</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.09466">https://arxiv.org/pdf/2505.09466</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.09466]] A 2D Semantic-Aware Position Encoding for Vision Transformers(https://arxiv.org/abs/2505.09466)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Vision transformers have demonstrated significant advantages in computer vision tasks due to their ability to capture long-range dependencies and contextual relationships through self-attention. However, existing position encoding techniques, which are largely borrowed from natural language processing, fail to effectively capture semantic-aware positional relationships between image patches. Traditional approaches like absolute position encoding and relative position encoding primarily focus on 1D linear position relationship, often neglecting the semantic similarity between distant yet contextually related patches. These limitations hinder model generalization, translation equivariance, and the ability to effectively handle repetitive or structured patterns in images. In this paper, we propose 2-Dimensional Semantic-Aware Position Encoding ($\text{SaPE}^2$), a novel position encoding method with semantic awareness that dynamically adapts position representations by leveraging local content instead of fixed linear position relationship or spatial coordinates. Our method enhances the model's ability to generalize across varying image resolutions and scales, improves translation equivariance, and better aggregates features for visually similar but spatially distant patches. By integrating $\text{SaPE}^2$ into vision transformers, we bridge the gap between position encoding and perceptual similarity, thereby improving performance on computer vision tasks.</li>
</ul>

<h3>Title: Denoising and Alignment: Rethinking Domain Generalization for Multimodal Face Anti-Spoofing</h3>
<ul>
<li><strong>Authors: </strong>Yingjie Ma, Xun Lin, Zitong Yu, Xin Liu, Xiaochen Yuan, Weicheng Xie, Linlin Shen</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.09484">https://arxiv.org/abs/2505.09484</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.09484">https://arxiv.org/pdf/2505.09484</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.09484]] Denoising and Alignment: Rethinking Domain Generalization for Multimodal Face Anti-Spoofing(https://arxiv.org/abs/2505.09484)</code><input type="text"></li>
<li><strong>Keywords: </strong>security</a></li>
<li><strong>Abstract: </strong>Face Anti-Spoofing (FAS) is essential for the security of facial recognition systems in diverse scenarios such as payment processing and surveillance. Current multimodal FAS methods often struggle with effective generalization, mainly due to modality-specific biases and domain shifts. To address these challenges, we introduce the \textbf{M}ulti\textbf{m}odal \textbf{D}enoising and \textbf{A}lignment (\textbf{MMDA}) framework. By leveraging the zero-shot generalization capability of CLIP, the MMDA framework effectively suppresses noise in multimodal data through denoising and alignment mechanisms, thereby significantly enhancing the generalization performance of cross-modal alignment. The \textbf{M}odality-\textbf{D}omain Joint \textbf{D}ifferential \textbf{A}ttention (\textbf{MD2A}) module in MMDA concurrently mitigates the impacts of domain and modality noise by refining the attention mechanism based on extracted common noise features. Furthermore, the \textbf{R}epresentation \textbf{S}pace \textbf{S}oft (\textbf{RS2}) Alignment strategy utilizes the pre-trained CLIP model to align multi-domain multimodal data into a generalized representation space in a flexible manner, preserving intricate representations and enhancing the model's adaptability to various unseen conditions. We also design a \textbf{U}-shaped \textbf{D}ual \textbf{S}pace \textbf{A}daptation (\textbf{U-DSA}) module to enhance the adaptability of representations while maintaining generalization performance. These improvements not only enhance the framework's generalization capabilities but also boost its ability to represent complex representations. Our experimental results on four benchmark datasets under different evaluation protocols demonstrate that the MMDA framework outperforms existing state-of-the-art methods in terms of cross-domain generalization and multimodal detection accuracy. The code will be released soon.</li>
</ul>

<h3>Title: Layered Unlearning for Adversarial Relearning</h3>
<ul>
<li><strong>Authors: </strong>Timothy Qian, Vinith Suriyakumar, Ashia Wilson, Dylan Hadfield-Menell</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.09500">https://arxiv.org/abs/2505.09500</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.09500">https://arxiv.org/pdf/2505.09500</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.09500]] Layered Unlearning for Adversarial Relearning(https://arxiv.org/abs/2505.09500)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, large language model</a></li>
<li><strong>Abstract: </strong>Our goal is to understand how post-training methods, such as fine-tuning, alignment, and unlearning, modify language model behavior and representations. We are particularly interested in the brittle nature of these modifications that makes them easy to bypass through prompt engineering or relearning. Recent results suggest that post-training induces shallow context-dependent ``circuits'' that suppress specific response patterns. This could be one explanation for the brittleness of post-training. To test this hypothesis, we design an unlearning algorithm, Layered Unlearning (LU), that creates distinct inhibitory mechanisms for a growing subset of the data. By unlearning the first $i$ folds while retaining the remaining $k - i$ at the $i$th of $k$ stages, LU limits the ability of relearning on a subset of data to recover the full dataset. We evaluate LU through a combination of synthetic and large language model (LLM) experiments. We find that LU improves robustness to adversarial relearning for several different unlearning methods. Our results contribute to the state-of-the-art of machine unlearning and provide insight into the effect of post-training updates.</li>
</ul>

<h3>Title: Scaling Up: Revisiting Mining Android Sandboxes at Scale for Malware Classification</h3>
<ul>
<li><strong>Authors: </strong>Francisco Costa, Ismael Medeiros, Leandro Oliveira, João Calássio, Rodrigo Bonifácio, Krishna Narasimhan, Mira Mezini, Márcio Ribeiro</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.09501">https://arxiv.org/abs/2505.09501</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.09501">https://arxiv.org/pdf/2505.09501</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.09501]] Scaling Up: Revisiting Mining Android Sandboxes at Scale for Malware Classification(https://arxiv.org/abs/2505.09501)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, privacy</a></li>
<li><strong>Abstract: </strong>The widespread use of smartphones in daily life has raised concerns about privacy and security among researchers and practitioners. Privacy issues are generally highly prevalent in mobile applications, particularly targeting the Android platform, the most popular mobile operating system. For this reason, several techniques have been proposed to identify malicious behavior in Android applications, including the Mining Android Sandbox approach (MAS approach), which aims to identify malicious behavior in repackaged Android applications (apps). However, previous empirical studies evaluated the MAS approach using a small dataset consisting of only 102 pairs of original and repackaged apps. This limitation raises questions about the external validity of their findings and whether the MAS approach can be generalized to larger datasets. To address these concerns, this paper presents the results of a replication study focused on evaluating the performance of the MAS approach regarding its capabilities of correctly classifying malware from different families. Unlike previous studies, our research employs a dataset that is an order of magnitude larger, comprising 4,076 pairs of apps covering a more diverse range of Android malware families. Surprisingly, our findings indicate a poor performance of the MAS approach for identifying malware, with the F1-score decreasing from 0.90 for the small dataset used in the previous studies to 0.54 in our more extensive dataset. Upon closer examination, we discovered that certain malware families partially account for the low accuracy of the MAS approach, which fails to classify a repackaged version of an app as malware correctly. Our findings highlight the limitations of the MAS approach, particularly when scaled, and underscore the importance of complementing it with other techniques to detect a broader range of malware effectively.</li>
</ul>

<h3>Title: Towards Fair In-Context Learning with Tabular Foundation Models</h3>
<ul>
<li><strong>Authors: </strong>Patrik Kenfack, Samira Ebrahimi Kaho, Ulrich Aïvodji</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.09503">https://arxiv.org/abs/2505.09503</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.09503">https://arxiv.org/pdf/2505.09503</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.09503]] Towards Fair In-Context Learning with Tabular Foundation Models(https://arxiv.org/abs/2505.09503)</code><input type="text"></li>
<li><strong>Keywords: </strong>fair</a></li>
<li><strong>Abstract: </strong>Tabular foundational models have exhibited strong in-context learning (ICL) capabilities on structured data, allowing them to make accurate predictions on test sets without parameter updates, using training examples as context. This emerging approach positions itself as a competitive alternative to traditional gradient-boosted tree methods. However, while biases in conventional machine learning models are well documented, it remains unclear how these biases manifest in tabular ICL. The paper investigates the fairness implications of tabular ICL and explores three preprocessing strategies--correlation removal, group-balanced demonstration selection, and uncertainty-based demonstration selection--to address bias. Comprehensive experiments indicate that uncertainty-based demonstration selection consistently enhances group fairness of in-context predictions. The source code for reproducing the results of this work can be found at this https URL.</li>
</ul>

<h3>Title: PT-MoE: An Efficient Finetuning Framework for Integrating Mixture-of-Experts into Prompt Tuning</h3>
<ul>
<li><strong>Authors: </strong>Zongqian Li, Yixuan Su, Nigel Collier</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.09519">https://arxiv.org/abs/2505.09519</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.09519">https://arxiv.org/pdf/2505.09519</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.09519]] PT-MoE: An Efficient Finetuning Framework for Integrating Mixture-of-Experts into Prompt Tuning(https://arxiv.org/abs/2505.09519)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Parameter-efficient fine-tuning (PEFT) methods have shown promise in adapting large language models, yet existing approaches exhibit counter-intuitive phenomena: integrating router into prompt tuning (PT) increases training efficiency yet does not improve performance universally; parameter reduction through matrix decomposition can improve performance in specific domains. Motivated by these observations and the modular nature of PT, we propose PT-MoE, a novel framework that integrates matrix decomposition with mixture-of-experts (MoE) routing for efficient PT. Results across 17 datasets demonstrate that PT-MoE achieves state-of-the-art performance in both question answering (QA) and mathematical problem solving tasks, improving F1 score by 1.49 points over PT and 2.13 points over LoRA in QA tasks, while enhancing mathematical accuracy by 10.75 points over PT and 0.44 points over LoRA, all while using 25% fewer parameters than LoRA. Our analysis reveals that while PT methods generally excel in QA tasks and LoRA-based methods in math datasets, the integration of matrix decomposition and MoE in PT-MoE yields complementary benefits: decomposition enables efficient parameter sharing across experts while MoE provides dynamic adaptation, collectively enabling PT-MoE to demonstrate cross-task consistency and generalization abilities. These findings, along with ablation studies on routing mechanisms and architectural components, provide insights for future PEFT methods.</li>
</ul>

<h3>Title: Using Foundation Models as Pseudo-Label Generators for Pre-Clinical 4D Cardiac CT Segmentation</h3>
<ul>
<li><strong>Authors: </strong>Anne-Marie Rickmann, Stephanie L. Thorn, Shawn S. Ahn, Supum Lee, Selen Uman, Taras Lysyy, Rachel Burns, Nicole Guerrera, Francis G. Spinale, Jason A. Burdick, Albert J. Sinusas, James S. Duncan</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.09564">https://arxiv.org/abs/2505.09564</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.09564">https://arxiv.org/pdf/2505.09564</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.09564]] Using Foundation Models as Pseudo-Label Generators for Pre-Clinical 4D Cardiac CT Segmentation(https://arxiv.org/abs/2505.09564)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, segmentation</a></li>
<li><strong>Abstract: </strong>Cardiac image segmentation is an important step in many cardiac image analysis and modeling tasks such as motion tracking or simulations of cardiac mechanics. While deep learning has greatly advanced segmentation in clinical settings, there is limited work on pre-clinical imaging, notably in porcine models, which are often used due to their anatomical and physiological similarity to humans. However, differences between species create a domain shift that complicates direct model transfer from human to pig data. Recently, foundation models trained on large human datasets have shown promise for robust medical image segmentation; yet their applicability to porcine data remains largely unexplored. In this work, we investigate whether foundation models can generate sufficiently accurate pseudo-labels for pig cardiac CT and propose a simple self-training approach to iteratively refine these labels. Our method requires no manually annotated pig data, relying instead on iterative updates to improve segmentation quality. We demonstrate that this self-training process not only enhances segmentation accuracy but also smooths out temporal inconsistencies across consecutive frames. Although our results are encouraging, there remains room for improvement, for example by incorporating more sophisticated self-training strategies and by exploring additional foundation models and other cardiac imaging technologies.</li>
</ul>

<h3>Title: BLIP3-o: A Family of Fully Open Unified Multimodal Models-Architecture, Training and Dataset</h3>
<ul>
<li><strong>Authors: </strong>Jiuhai Chen, Zhiyang Xu, Xichen Pan, Yushi Hu, Can Qin, Tom Goldstein, Lifu Huang, Tianyi Zhou, Saining Xie, Silvio Savarese, Le Xue, Caiming Xiong, Ran Xu</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.09568">https://arxiv.org/abs/2505.09568</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.09568">https://arxiv.org/pdf/2505.09568</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.09568]] BLIP3-o: A Family of Fully Open Unified Multimodal Models-Architecture, Training and Dataset(https://arxiv.org/abs/2505.09568)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, transformer, generative</a></li>
<li><strong>Abstract: </strong>Unifying image understanding and generation has gained growing attention in recent research on multimodal models. Although design choices for image understanding have been extensively studied, the optimal model architecture and training recipe for a unified framework with image generation remain underexplored. Motivated by the strong potential of autoregressive and diffusion models for high-quality generation and scalability, we conduct a comprehensive study of their use in unified multimodal settings, with emphasis on image representations, modeling objectives, and training strategies. Grounded in these investigations, we introduce a novel approach that employs a diffusion transformer to generate semantically rich CLIP image features, in contrast to conventional VAE-based representations. This design yields both higher training efficiency and improved generative quality. Furthermore, we demonstrate that a sequential pretraining strategy for unified models-first training on image understanding and subsequently on image generation-offers practical advantages by preserving image understanding capability while developing strong image generation ability. Finally, we carefully curate a high-quality instruction-tuning dataset BLIP3o-60k for image generation by prompting GPT-4o with a diverse set of captions covering various scenes, objects, human gestures, and more. Building on our innovative model design, training recipe, and datasets, we develop BLIP3-o, a suite of state-of-the-art unified multimodal models. BLIP3-o achieves superior performance across most of the popular benchmarks spanning both image understanding and generation tasks. To facilitate future research, we fully open-source our models, including code, model weights, training scripts, and pretraining and instruction tuning datasets.</li>
</ul>

<h3>Title: Don't Forget your Inverse DDIM for Image Editing</h3>
<ul>
<li><strong>Authors: </strong>Guillermo Gomez-Trenado, Pablo Mesejo, Oscar Cordón, Stéphane Lathuilière</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.09571">https://arxiv.org/abs/2505.09571</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.09571">https://arxiv.org/pdf/2505.09571</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.09571]] Don't Forget your Inverse DDIM for Image Editing(https://arxiv.org/abs/2505.09571)</code><input type="text"></li>
<li><strong>Keywords: </strong>secure, diffusion</a></li>
<li><strong>Abstract: </strong>The field of text-to-image generation has undergone significant advancements with the introduction of diffusion models. Nevertheless, the challenge of editing real images persists, as most methods are either computationally intensive or produce poor reconstructions. This paper introduces SAGE (Self-Attention Guidance for image Editing) - a novel technique leveraging pre-trained diffusion models for image editing. SAGE builds upon the DDIM algorithm and incorporates a novel guidance mechanism utilizing the self-attention layers of the diffusion U-Net. This mechanism computes a reconstruction objective based on attention maps generated during the inverse DDIM process, enabling efficient reconstruction of unedited regions without the need to precisely reconstruct the entire input image. Thus, SAGE directly addresses the key challenges in image editing. The superiority of SAGE over other methods is demonstrated through quantitative and qualitative evaluations and confirmed by a statistically validated comprehensive user study, in which all 47 surveyed users preferred SAGE over competing methods. Additionally, SAGE ranks as the top-performing method in seven out of 10 quantitative analyses and secures second and third places in the remaining three.</li>
</ul>

<h3>Title: Online Isolation Forest</h3>
<ul>
<li><strong>Authors: </strong>Filippo Leveni, Guilherme Weigert Cassales, Bernhard Pfahringer, Albert Bifet, Giacomo Boracchi</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.09593">https://arxiv.org/abs/2505.09593</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.09593">https://arxiv.org/pdf/2505.09593</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.09593]] Online Isolation Forest(https://arxiv.org/abs/2505.09593)</code><input type="text"></li>
<li><strong>Keywords: </strong>security</a></li>
<li><strong>Abstract: </strong>The anomaly detection literature is abundant with offline methods, which require repeated access to data in memory, and impose impractical assumptions when applied to a streaming context. Existing online anomaly detection methods also generally fail to address these constraints, resorting to periodic retraining to adapt to the online context. We propose Online-iForest, a novel method explicitly designed for streaming conditions that seamlessly tracks the data generating process as it evolves over time. Experimental validation on real-world datasets demonstrated that Online-iForest is on par with online alternatives and closely rivals state-of-the-art offline anomaly detection techniques that undergo periodic retraining. Notably, Online-iForest consistently outperforms all competitors in terms of efficiency, making it a promising solution in applications where fast identification of anomalies is of primary importance such as cybersecurity, fraud and fault detection.</li>
</ul>

<h3>Title: WorldView-Bench: A Benchmark for Evaluating Global Cultural Perspectives in Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Abdullah Mushtaq, Imran Taj, Rafay Naeem, Ibrahim Ghaznavi, Junaid Qadir</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.CY, cs.MA</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.09595">https://arxiv.org/abs/2505.09595</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.09595">https://arxiv.org/pdf/2505.09595</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.09595]] WorldView-Bench: A Benchmark for Evaluating Global Cultural Perspectives in Large Language Models(https://arxiv.org/abs/2505.09595)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative, large language model</a></li>
<li><strong>Abstract: </strong>Large Language Models (LLMs) are predominantly trained and aligned in ways that reinforce Western-centric epistemologies and socio-cultural norms, leading to cultural homogenization and limiting their ability to reflect global civilizational plurality. Existing benchmarking frameworks fail to adequately capture this bias, as they rely on rigid, closed-form assessments that overlook the complexity of cultural inclusivity. To address this, we introduce WorldView-Bench, a benchmark designed to evaluate Global Cultural Inclusivity (GCI) in LLMs by analyzing their ability to accommodate diverse worldviews. Our approach is grounded in the Multiplex Worldview proposed by Senturk et al., which distinguishes between Uniplex models, reinforcing cultural homogenization, and Multiplex models, which integrate diverse perspectives. WorldView-Bench measures Cultural Polarization, the exclusion of alternative perspectives, through free-form generative evaluation rather than conventional categorical benchmarks. We implement applied multiplexity through two intervention strategies: (1) Contextually-Implemented Multiplex LLMs, where system prompts embed multiplexity principles, and (2) Multi-Agent System (MAS)-Implemented Multiplex LLMs, where multiple LLM agents representing distinct cultural perspectives collaboratively generate responses. Our results demonstrate a significant increase in Perspectives Distribution Score (PDS) entropy from 13% at baseline to 94% with MAS-Implemented Multiplex LLMs, alongside a shift toward positive sentiment (67.7%) and enhanced cultural balance. These findings highlight the potential of multiplex-aware AI evaluation in mitigating cultural bias in LLMs, paving the way for more inclusive and ethically aligned AI systems.</li>
</ul>

<h3>Title: Adversarial Suffix Filtering: a Defense Pipeline for LLMs</h3>
<ul>
<li><strong>Authors: </strong>David Khachaturov, Robert Mullins</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.09602">https://arxiv.org/abs/2505.09602</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.09602">https://arxiv.org/pdf/2505.09602</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.09602]] Adversarial Suffix Filtering: a Defense Pipeline for LLMs(https://arxiv.org/abs/2505.09602)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, protect, defense, attack, large language model</a></li>
<li><strong>Abstract: </strong>Large Language Models (LLMs) are increasingly embedded in autonomous systems and public-facing environments, yet they remain susceptible to jailbreak vulnerabilities that may undermine their security and trustworthiness. Adversarial suffixes are considered to be the current state-of-the-art jailbreak, consistently outperforming simpler methods and frequently succeeding even in black-box settings. Existing defenses rely on access to the internal architecture of models limiting diverse deployment, increase memory and computation footprints dramatically, or can be bypassed with simple prompt engineering methods. We introduce $\textbf{Adversarial Suffix Filtering}$ (ASF), a lightweight novel model-agnostic defensive pipeline designed to protect LLMs against adversarial suffix attacks. ASF functions as an input preprocessor and sanitizer that detects and filters adversarially crafted suffixes in prompts, effectively neutralizing malicious injections. We demonstrate that ASF provides comprehensive defense capabilities across both black-box and white-box attack settings, reducing the attack efficacy of state-of-the-art adversarial suffix generation methods to below 4%, while only minimally affecting the target model's capabilities in non-adversarial scenarios.</li>
</ul>

<h3>Title: LightLab: Controlling Light Sources in Images with Diffusion Models</h3>
<ul>
<li><strong>Authors: </strong>Nadav Magar, Amir Hertz, Eric Tabellion, Yael Pritch, Alex Rav-Acha, Ariel Shamir, Yedid Hoshen</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.GR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.09608">https://arxiv.org/abs/2505.09608</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.09608">https://arxiv.org/pdf/2505.09608</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.09608]] LightLab: Controlling Light Sources in Images with Diffusion Models(https://arxiv.org/abs/2505.09608)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>We present a simple, yet effective diffusion-based method for fine-grained, parametric control over light sources in an image. Existing relighting methods either rely on multiple input views to perform inverse rendering at inference time, or fail to provide explicit control over light changes. Our method fine-tunes a diffusion model on a small set of real raw photograph pairs, supplemented by synthetically rendered images at scale, to elicit its photorealistic prior for relighting. We leverage the linearity of light to synthesize image pairs depicting controlled light changes of either a target light source or ambient illumination. Using this data and an appropriate fine-tuning scheme, we train a model for precise illumination changes with explicit control over light intensity and color. Lastly, we show how our method can achieve compelling light editing results, and outperforms existing methods based on user preference.</li>
</ul>

<button id="copy">Copy All</button>
</article>
<script src="../../javascript/clipboard.min.js"></script>
<script src="../../javascript/clipboard.js"></script>
