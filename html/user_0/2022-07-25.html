<link rel="stylesheet" href="../../css/markdown.css" />
<article class="markdown-body">
<h2>secure</h2>
<h3>Title: Authentication and Billing Scheme for The Electric Vehicles: EVABS. (arXiv:2207.10789v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2207.10789">http://arxiv.org/abs/2207.10789</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2207.10789] Authentication and Billing Scheme for The Electric Vehicles: EVABS](http://arxiv.org/abs/2207.10789)</code></li>
<li>Summary: <p>The need for different energy sources has increased due to the decrease in
the amount and the harm caused to the environment by its usage. Today, fossil
fuels used as an energy source in land, sea or air vehicles are rapidly being
replaced by different energy sources. The number and types of vehicles using
energy sources other than fossil fuels are also increasing. Electricity stands
out among the energy sources used. The possibility of generating electricity
that is renewable, compatible with nature and at a lower cost provides a great
advantage. For all these reasons, the use of electric vehicles is increasing
day by day. Various solutions continue to be developed for the charging systems
and post-charge billing processes of these vehicles. As a result of these
solutions, the standards have not yet been fully formed. In this study, an
authentication and billing scheme is proposed for charging and post-charging
billing processes of electric land vehicles keeping security and privacy in the
foreground. This scheme is named EVABS, which derives from the phrase "Electric
Vehicle Authentication and Billing Scheme". An authentication and billing
scheme is proposed where data communication is encrypted, payment transactions
are handled securely and parties can authenticate over wired or wireless. The
security of the proposed scheme has been examined theoretically and it has been
determined that it is secure against known attacks.
</p></li>
</ul>

<h3>Title: WordSig: QR streams enabling platform-independent self-identification that's impossible to deepfake. (arXiv:2207.10806v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2207.10806">http://arxiv.org/abs/2207.10806</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2207.10806] WordSig: QR streams enabling platform-independent self-identification that's impossible to deepfake](http://arxiv.org/abs/2207.10806)</code></li>
<li>Summary: <p>Deepfakes can degrade the fabric of society by limiting our ability to trust
video content from leaders, authorities, and even friends. Cryptographically
secure digital signatures may be used by video streaming platforms to endorse
content, but these signatures are applied by the content distributor rather
than the participants in the video. We introduce WordSig, a simple protocol
allowing video participants to digitally sign the words they speak using a
stream of QR codes, and allowing viewers to verify the consistency of
signatures across videos. This allows establishing a trusted connection between
the viewer and the participant that is not mediated by the content distributor.
Given the widespread adoption of QR codes for distributing hyperlinks and
vaccination records, and the increasing prevalence of celebrity deepfakes, 2022
or later may be a good time for public figures to begin using and promoting
QR-based self-authentication tools.
</p></li>
</ul>

<h3>Title: RSU-Based Online Intrusion Detection and Mitigation for VANET. (arXiv:2207.10812v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2207.10812">http://arxiv.org/abs/2207.10812</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2207.10812] RSU-Based Online Intrusion Detection and Mitigation for VANET](http://arxiv.org/abs/2207.10812)</code></li>
<li>Summary: <p>Secure vehicular communication is a critical factor for secure traffic
management. Effective security in intelligent transportation systems (ITS)
requires effective and timely intrusion detection systems (IDS). In this paper,
we consider false data injection attacks and distributed denial-of-service
(DDoS) attacks, especially the stealthy DDoS attacks, targeting the integrity
and availability, respectively, in vehicular ad-hoc networks (VANET). Novel
statistical intrusion detection and mitigation techniques based on centralized
communications through roadside units (RSU) are proposed for the considered
attacks. The performance of the proposed methods are evaluated using a traffic
simulator and a real traffic dataset. Comparisons with the state-of-the-art
solutions clearly demonstrate the superior performance of the proposed methods
in terms of quick and accurate detection and localization of cyberattacks.
</p></li>
</ul>

<h3>Title: Secure and Lightweight Strong PUF Challenge Obfuscation with Keyed Non-linear FSR. (arXiv:2207.11181v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2207.11181">http://arxiv.org/abs/2207.11181</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2207.11181] Secure and Lightweight Strong PUF Challenge Obfuscation with Keyed Non-linear FSR](http://arxiv.org/abs/2207.11181)</code></li>
<li>Summary: <p>We propose a secure and lightweight key based challenge obfuscation for
strong PUFs. Our architecture is designed to be resilient against learning
attacks. Our obfuscation mechanism uses non-linear feedback shift registers
(NLFSRs). Responses are directly provided to the user, without error correction
or extra post-processing steps. We also discuss the cost of protecting our
architecture against power analysis attacks with clock randomization, and
Boolean masking. Security against learning attacks is assessed using avalanche
criterion, and deep-neural network attacks. We designed a testchip in 65 nm
CMOS. When compared to the baseline arbiter PUF implementation, the cost
increase of our proposed architecture is 1.27x, and 2.2x when using clock
randomization, and Boolean masking, respectively.
</p></li>
</ul>

<h2>security</h2>
<h3>Title: Multi-Level Fine-Tuning, Data Augmentation, and Few-Shot Learning for Specialized Cyber Threat Intelligence. (arXiv:2207.11076v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2207.11076">http://arxiv.org/abs/2207.11076</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2207.11076] Multi-Level Fine-Tuning, Data Augmentation, and Few-Shot Learning for Specialized Cyber Threat Intelligence](http://arxiv.org/abs/2207.11076)</code></li>
<li>Summary: <p>Gathering cyber threat intelligence from open sources is becoming
increasingly important for maintaining and achieving a high level of security
as systems become larger and more complex. However, these open sources are
often subject to information overload. It is therefore useful to apply machine
learning models that condense the amount of information to what is necessary.
Yet, previous studies and applications have shown that existing classifiers are
not able to extract specific information about emerging cybersecurity events
due to their low generalization ability. Therefore, we propose a system to
overcome this problem by training a new classifier for each new incident. Since
this requires a lot of labelled data using standard training methods, we
combine three different low-data regime techniques - transfer learning, data
augmentation, and few-shot learning - to train a high-quality classifier from
very few labelled instances. We evaluated our approach using a novel dataset
derived from the Microsoft Exchange Server data breach of 2021 which was
labelled by three experts. Our findings reveal an increase in F1 score of more
than 21 points compared to standard training methods and more than 18 points
compared to a state-of-the-art method in few-shot learning. Furthermore, the
classifier trained with this method and 32 instances is only less than 5 F1
score points worse than a classifier trained with 1800 instances.
</p></li>
</ul>

<h3>Title: IDPS Signature Classification with a Reject Option and the Incorporation of Expert Knowledge. (arXiv:2207.10797v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2207.10797">http://arxiv.org/abs/2207.10797</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2207.10797] IDPS Signature Classification with a Reject Option and the Incorporation of Expert Knowledge](http://arxiv.org/abs/2207.10797)</code></li>
<li>Summary: <p>As the importance of intrusion detection and prevention systems (IDPSs)
increases, great costs are incurred to manage the signatures that are generated
by malicious communication pattern files. Experts in network security need to
classify signatures by importance for an IDPS to work. We propose and evaluate
a machine learning signature classification model with a reject option (RO) to
reduce the cost of setting up an IDPS. To train the proposed model, it is
essential to design features that are effective for signature classification.
Experts classify signatures with predefined if-then rules. An if-then rule
returns a label of low, medium, high, or unknown importance based on keyword
matching of the elements in the signature. Therefore, we first design two types
of features, symbolic features (SFs) and keyword features (KFs), which are used
in keyword matching for the if-then rules. Next, we design web information and
message features (WMFs) to capture the properties of signatures that do not
match the if-then rules. The WMFs are extracted as term frequency-inverse
document frequency (TF-IDF) features of the message text in the signatures. The
features are obtained by web scraping from the referenced external attack
identification systems described in the signature. Because failure needs to be
minimized in the classification of IDPS signatures, as in the medical field, we
consider introducing a RO in our proposed model. The effectiveness of the
proposed classification model is evaluated in experiments with two real
datasets composed of signatures labeled by experts: a dataset that can be
classified with if-then rules and a dataset with elements that do not match an
if-then rule. In the experiment, the proposed model is evaluated. In both
cases, the combined SFs and WMFs performed better than the combined SFs and
KFs. In addition, we also performed feature analysis.
</p></li>
</ul>

<h3>Title: Security Challenges when Space Merges with Cyberspace. (arXiv:2207.10798v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2207.10798">http://arxiv.org/abs/2207.10798</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2207.10798] Security Challenges when Space Merges with Cyberspace](http://arxiv.org/abs/2207.10798)</code></li>
<li>Summary: <p>Spaceborne systems, such as communication satellites, sensory, surveillance,
GPS and a multitude of other functionalities, form an integral part of global
ICT cyberinfrastructures. However, a focussed discourse highlighting the
distinctive threats landscape of these spaceborne assets is conspicuous by its
absence. This position paper specifically considers the interplay of Space and
Cyberspace to highlight security challenges that warrant dedicated attention in
securing these complex infrastructures. The opinion piece additionally adds
summary opinions on (a) emerging technology trends and (b) advocacy on
technological and policy issues needed to support security responsiveness and
mitigation.
</p></li>
</ul>

<h3>Title: Security and Safety Aspects of AI in Industry Applications. (arXiv:2207.10809v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2207.10809">http://arxiv.org/abs/2207.10809</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2207.10809] Security and Safety Aspects of AI in Industry Applications](http://arxiv.org/abs/2207.10809)</code></li>
<li>Summary: <p>In this relatively informal discussion-paper we summarise issues in the
domains of safety and security in machine learning that will affect industry
sectors in the next five to ten years. Various products using neural network
classification, most often in vision related applications but also in
predictive maintenance, have been researched and applied in real-world
applications in recent years. Nevertheless, reports of underlying problems in
both safety and security related domains, for instance adversarial attacks have
unsettled early adopters and are threatening to hinder wider scale adoption of
this technology. The problem for real-world applicability lies in being able to
assess the risk of applying these technologies. In this discussion-paper we
describe the process of arriving at a machine-learnt neural network classifier
pointing out safety and security vulnerabilities in that workflow, citing
relevant research where appropriate.
</p></li>
</ul>

<h3>Title: Supervised Contrastive ResNet and Transfer Learning for the In-vehicle Intrusion Detection System. (arXiv:2207.10814v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2207.10814">http://arxiv.org/abs/2207.10814</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2207.10814] Supervised Contrastive ResNet and Transfer Learning for the In-vehicle Intrusion Detection System](http://arxiv.org/abs/2207.10814)</code></li>
<li>Summary: <p>High-end vehicles have been furnished with a number of electronic control
units (ECUs), which provide upgrading functions to enhance the driving
experience. The controller area network (CAN) is a well-known protocol that
connects these ECUs because of its modesty and efficiency. However, the CAN bus
is vulnerable to various types of attacks. Although the intrusion detection
system (IDS) is proposed to address the security problem of the CAN bus, most
previous studies only provide alerts when attacks occur without knowing the
specific type of attack. Moreover, an IDS is designed for a specific car model
due to diverse car manufacturers. In this study, we proposed a novel deep
learning model called supervised contrastive (SupCon) ResNet, which can handle
multiple attack identification on the CAN bus. Furthermore, the model can be
used to improve the performance of a limited-size dataset using a transfer
learning technique. The capability of the proposed model is evaluated on two
real car datasets. When tested with the car hacking dataset, the experiment
results show that the SupCon ResNet model improves the overall false-negative
rates of four types of attack by four times on average, compared to other
models. In addition, the model achieves the highest F1 score at 0.9994 on the
survival dataset by utilizing transfer learning. Finally, the model can adapt
to hardware constraints in terms of memory size and running time.
</p></li>
</ul>

<h3>Title: Mathematical Model of Strong Physically Unclonable Functions Based on Hybrid Boolean Networks. (arXiv:2207.10816v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2207.10816">http://arxiv.org/abs/2207.10816</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2207.10816] Mathematical Model of Strong Physically Unclonable Functions Based on Hybrid Boolean Networks](http://arxiv.org/abs/2207.10816)</code></li>
<li>Summary: <p>We introduce a mathematical framework for simulating Hybrid Boolean Network
(HBN) Physically Unclonable Functions (PUFs, HBN-PUFs). We verify that the
model is able to reproduce the experimentally observed PUF statistics for
uniqueness $\mu_{inter}$ and reliability $\mu_{intra}$ obtained from
experiments of HBN-PUFs on Cyclone V FPGAs. Our results suggest that the
HBN-PUF is a true `strong' PUF in the sense that its security properties depend
exponentially on both the manufacturing variation and the challenge-response
space. Our Python simulation methods are open-source and available at
https://github.com/Noeloikeau/networkm.
</p></li>
</ul>

<h3>Title: Cryptanalysis of a system based on Twisted Dihedral Group Algebras. (arXiv:2207.10979v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2207.10979">http://arxiv.org/abs/2207.10979</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2207.10979] Cryptanalysis of a system based on Twisted Dihedral Group Algebras](http://arxiv.org/abs/2207.10979)</code></li>
<li>Summary: <p>Several cryptographic protocols constructed based on less-known algorithmic
problems, such as those in non-commutative groups, group rings, semigroups,
etc., which claim quantum security, have been broken through classical
reduction methods within their specific proposed platforms. A rigorous
examination of the complexity of these algorithmic problems is therefore an
important topic of research. In this paper, we present a cryptanalysis of a
public key exchange system based on a decomposition-type problem in the
so-called twisted group algebras of the dihedral group $D_{2n}$ over a finite
field $\fq$. Our method of analysis relies on an algebraic reduction of the
original problem to a set of equations over $\fq$ involving circulant matrices,
and a subsequent solution to these equations. Our attack runs in polynomial
time and succeeds with probability at least $90$ percent for the parameter
values provided by the authors. We also show that the underlying algorithmic
problem, while based on a non-commutative structure, may be formulated as a
commutative semigroup action problem.
</p></li>
</ul>

<h2>privacy</h2>
<h3>Title: Open video data sharing in developmental and behavioural science. (arXiv:2207.11020v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2207.11020">http://arxiv.org/abs/2207.11020</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2207.11020] Open video data sharing in developmental and behavioural science](http://arxiv.org/abs/2207.11020)</code></li>
<li>Summary: <p>Video recording is a widely used method for documenting infant and child
behaviours in research and clinical practice. Video data has rarely been shared
due to ethical concerns of confidentiality, although the need of shared
large-scaled datasets remains increasing. This demand is even more imperative
when data-driven computer-based approaches are involved, such as screening
tools to complement clinical assessments. To share data while abiding by
privacy protection rules, a critical question arises whether efforts at data
de-identification reduce data utility? We addressed this question by showcasing
the Prechtl's general movements assessment (GMA), an established and globally
practised video-based diagnostic tool in early infancy for detecting
neurological deficits, such as cerebral palsy. To date, no shared
expert-annotated large data repositories for infant movement analyses exist.
Such datasets would massively benefit training and recalibration of human
assessors and the development of computer-based approaches. In the current
study, sequences from a prospective longitudinal infant cohort with a total of
19451 available general movements video snippets were randomly selected for
human clinical reasoning and computer-based analysis. We demonstrated for the
first time that pseudonymisation by face-blurring video recordings is a viable
approach. The video redaction did not affect classification accuracy for either
human assessors or computer vision methods, suggesting an adequate and
easy-to-apply solution for sharing movement video data. We call for further
explorations into efficient and privacy rule-conforming approaches for
deidentifying video data in scientific and clinical fields beyond movement
assessments. These approaches shall enable sharing and merging stand-alone
video datasets into large data pools to advance science and public health.
</p></li>
</ul>

<h3>Title: Few-Shot Class-Incremental Learning via Entropy-Regularized Data-Free Replay. (arXiv:2207.11213v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2207.11213">http://arxiv.org/abs/2207.11213</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2207.11213] Few-Shot Class-Incremental Learning via Entropy-Regularized Data-Free Replay](http://arxiv.org/abs/2207.11213)</code></li>
<li>Summary: <p>Few-shot class-incremental learning (FSCIL) has been proposed aiming to
enable a deep learning system to incrementally learn new classes with limited
data. Recently, a pioneer claims that the commonly used replay-based method in
class-incremental learning (CIL) is ineffective and thus not preferred for
FSCIL. This has, if truth, a significant influence on the fields of FSCIL. In
this paper, we show through empirical results that adopting the data replay is
surprisingly favorable. However, storing and replaying old data can lead to a
privacy concern. To address this issue, we alternatively propose using
data-free replay that can synthesize data by a generator without accessing real
data. In observing the the effectiveness of uncertain data for knowledge
distillation, we impose entropy regularization in the generator training to
encourage more uncertain examples. Moreover, we propose to relabel the
generated data with one-hot-like labels. This modification allows the network
to learn by solely minimizing the cross-entropy loss, which mitigates the
problem of balancing different objectives in the conventional knowledge
distillation approach. Finally, we show extensive experimental results and
analysis on CIFAR-100, miniImageNet and CUB-200 to demonstrate the
effectiveness of our proposed one.
</p></li>
</ul>

<h3>Title: Improved Generalization Guarantees in Restricted Data Models. (arXiv:2207.10668v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2207.10668">http://arxiv.org/abs/2207.10668</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2207.10668] Improved Generalization Guarantees in Restricted Data Models](http://arxiv.org/abs/2207.10668)</code></li>
<li>Summary: <p>Differential privacy is known to protect against threats to validity incurred
due to adaptive, or exploratory, data analysis -- even when the analyst
adversarially searches for a statistical estimate that diverges from the true
value of the quantity of interest on the underlying population. The cost of
this protection is the accuracy loss incurred by differential privacy. In this
work, inspired by standard models in the genomics literature, we consider data
models in which individuals are represented by a sequence of attributes with
the property that where distant attributes are only weakly correlated. We show
that, under this assumption, it is possible to "re-use" privacy budget on
different portions of the data, significantly improving accuracy without
increasing the risk of overfitting.
</p></li>
</ul>

<h3>Title: Privacy and Transparency in Graph Machine Learning: A Unified Perspective. (arXiv:2207.10896v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2207.10896">http://arxiv.org/abs/2207.10896</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2207.10896] Privacy and Transparency in Graph Machine Learning: A Unified Perspective](http://arxiv.org/abs/2207.10896)</code></li>
<li>Summary: <p>Graph Machine Learning (GraphML), whereby classical machine learning is
generalized to irregular graph domains, has enjoyed a recent renaissance,
leading to a dizzying array of models and their applications in several
domains. With its growing applicability to sensitive domains and regulations by
government agencies for trustworthy AI systems, researchers have started
looking into the issues of transparency and privacy of graph learning. However,
these topics have been mainly investigated independently. In this position
paper, we provide a unified perspective on the interplay of privacy and
transparency in GraphML.
</p></li>
</ul>

<h3>Title: ME-GAN: Learning Panoptic Electrocardio Representations for Multi-view ECG Synthesis Conditioned on Heart Diseases. (arXiv:2207.10670v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2207.10670">http://arxiv.org/abs/2207.10670</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2207.10670] ME-GAN: Learning Panoptic Electrocardio Representations for Multi-view ECG Synthesis Conditioned on Heart Diseases](http://arxiv.org/abs/2207.10670)</code></li>
<li>Summary: <p>Electrocardiogram (ECG) is a widely used non-invasive diagnostic tool for
heart diseases. Many studies have devised ECG analysis models (e.g.,
classifiers) to assist diagnosis. As an upstream task, researches have built
generative models to synthesize ECG data, which are beneficial to providing
training samples, privacy protection, and annotation reduction. However,
previous generative methods for ECG often neither synthesized multi-view data,
nor dealt with heart disease conditions. In this paper, we propose a novel
disease-aware generative adversarial network for multi-view ECG synthesis
called ME-GAN, which attains panoptic electrocardio representations conditioned
on heart diseases and projects the representations onto multiple standard views
to yield ECG signals. Since ECG manifestations of heart diseases are often
localized in specific waveforms, we propose a new "mixup normalization" to
inject disease information precisely into suitable locations. In addition, we
propose a view discriminator to revert disordered ECG views into a
pre-determined order, supervising the generator to obtain ECG representing
correct view characteristics. Besides, a new metric, rFID, is presented to
assess the quality of the synthesized ECG signals. Comprehensive experiments
verify that our ME-GAN performs well on multi-view ECG signal synthesis with
trusty morbid manifestations.
</p></li>
</ul>

<h2>protect</h2>
<h3>Title: Adaptive Graph-Based Feature Normalization for Facial Expression Recognition. (arXiv:2207.11123v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2207.11123">http://arxiv.org/abs/2207.11123</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2207.11123] Adaptive Graph-Based Feature Normalization for Facial Expression Recognition](http://arxiv.org/abs/2207.11123)</code></li>
<li>Summary: <p>Facial Expression Recognition (FER) suffers from data uncertainties caused by
ambiguous facial images and annotators' subjectiveness, resulting in excursive
semantic and feature covariate shifting problem. Existing works usually correct
mislabeled data by estimating noise distribution, or guide network training
with knowledge learned from clean data, neglecting the associative relations of
expressions. In this work, we propose an Adaptive Graph-based Feature
Normalization (AGFN) method to protect FER models from data uncertainties by
normalizing feature distributions with the association of expressions.
Specifically, we propose a Poisson graph generator to adaptively construct
topological graphs for samples in each mini-batches via a sampling process, and
correspondingly design a coordinate descent strategy to optimize proposed
network. Our method outperforms state-of-the-art works with accuracies of
91.84% and 91.11% on the benchmark datasets FERPlus and RAF-DB, respectively,
and when the percentage of mislabeled data increases (e.g., to 20%), our
network surpasses existing works significantly by 3.38% and 4.52%.
</p></li>
</ul>

<h3>Title: Two-Stage Fine-Tuning: A Novel Strategy for Learning Class-Imbalanced Data. (arXiv:2207.10858v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2207.10858">http://arxiv.org/abs/2207.10858</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2207.10858] Two-Stage Fine-Tuning: A Novel Strategy for Learning Class-Imbalanced Data](http://arxiv.org/abs/2207.10858)</code></li>
<li>Summary: <p>Classification on long-tailed distributed data is a challenging problem,
which suffers from serious class-imbalance and hence poor performance on tail
classes with only a few samples. Owing to this paucity of samples, learning on
the tail classes is especially challenging for the fine-tuning when
transferring a pretrained model to a downstream task. In this work, we present
a simple modification of standard fine-tuning to cope with these challenges.
Specifically, we propose a two-stage fine-tuning: we first fine-tune the final
layer of the pretrained model with class-balanced reweighting loss, and then we
perform the standard fine-tuning. Our modification has several benefits: (1) it
leverages pretrained representations by only fine-tuning a small portion of the
model parameters while keeping the rest untouched; (2) it allows the model to
learn an initial representation of the specific task; and importantly (3) it
protects the learning of tail classes from being at a disadvantage during the
model updating. We conduct extensive experiments on synthetic datasets of both
two-class and multi-class tasks of text classification as well as a real-world
application to ADME (i.e., absorption, distribution, metabolism, and excretion)
semantic labeling. The experimental results show that the proposed two-stage
fine-tuning outperforms both fine-tuning with conventional loss and fine-tuning
with a reweighting loss on the above datasets.
</p></li>
</ul>

<h3>Title: DJI drone IDs are not encrypted. (arXiv:2207.10795v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2207.10795">http://arxiv.org/abs/2207.10795</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2207.10795] DJI drone IDs are not encrypted](http://arxiv.org/abs/2207.10795)</code></li>
<li>Summary: <p>Drones are widely used in the energy, construction, agriculture,
transportation, warehousing, real estate and movie industries. Key applications
include surveys, inspections, deliveries and cinematography. With approximately
70-80% of the global market share of commercial off-the-shelf drones, Da-Jiang
Innovations (DJI), headquartered in Shenzhen, China, essentially monopolizes
the drone market. As commercial-off-the-shelf drone sales steadily rise, the
Federal Aviation Administration has instituted regulations to protect the
federal airspace. DJI has become a pioneer in developing remote identification
technology in the form of drone ID (also known as AeroScope signals). Despite
claims from the company touting its implementation of drone ID technology as
"encrypted" yet later being proved incorrect for the claim, it remains a
mystery on how one can grab and decode drone IDs over the air with low-cost
radio frequency hardware in real-time. This research paper discusses a
methodology using radio software and hardware to detect both Enhanced Wi-Fi and
OcuSync drone IDs, the three types of drone ID packet structures and a
functioning prototype of a DJI OcuSync detection system equipped with two
HackRF Ones.
</p></li>
</ul>

<h2>defense</h2>
<h2>attack</h2>
<h3>Title: Synthetic Dataset Generation for Adversarial Machine Learning Research. (arXiv:2207.10719v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2207.10719">http://arxiv.org/abs/2207.10719</a></li>
<li>Code URL: <a href="https://github.com/carla-simulator/carla">https://github.com/carla-simulator/carla</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2207.10719] Synthetic Dataset Generation for Adversarial Machine Learning Research](http://arxiv.org/abs/2207.10719)</code></li>
<li>Summary: <p>Existing adversarial example research focuses on digitally inserted
perturbations on top of existing natural image datasets. This construction of
adversarial examples is not realistic because it may be difficult, or even
impossible, for an attacker to deploy such an attack in the real-world due to
sensing and environmental effects. To better understand adversarial examples
against cyber-physical systems, we propose approximating the real-world through
simulation. In this paper we describe our synthetic dataset generation tool
that enables scalable collection of such a synthetic dataset with realistic
adversarial examples. We use the CARLA simulator to collect such a dataset and
demonstrate simulated attacks that undergo the same environmental transforms
and processing as real-world images. Our tools have been used to collect
datasets to help evaluate the efficacy of adversarial examples, and can be
found at https://github.com/carla-simulator/carla/pull/4992.
</p></li>
</ul>

<h3>Title: Just Rotate it: Deploying Backdoor Attacks via Rotation Transformation. (arXiv:2207.10825v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2207.10825">http://arxiv.org/abs/2207.10825</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2207.10825] Just Rotate it: Deploying Backdoor Attacks via Rotation Transformation](http://arxiv.org/abs/2207.10825)</code></li>
<li>Summary: <p>Recent works have demonstrated that deep learning models are vulnerable to
backdoor poisoning attacks, where these attacks instill spurious correlations
to external trigger patterns or objects (e.g., stickers, sunglasses, etc.). We
find that such external trigger signals are unnecessary, as highly effective
backdoors can be easily inserted using rotation-based image transformation. Our
method constructs the poisoned dataset by rotating a limited amount of objects
and labeling them incorrectly; once trained with it, the victim's model will
make undesirable predictions during run-time inference. It exhibits a
significantly high attack success rate while maintaining clean performance
through comprehensive empirical studies on image classification and object
detection tasks. Furthermore, we evaluate standard data augmentation techniques
and four different backdoor defenses against our attack and find that none of
them can serve as a consistent mitigation approach. Our attack can be easily
deployed in the real world since it only requires rotating the object, as we
show in both image classification and object detection applications. Overall,
our work highlights a new, simple, physically realizable, and highly effective
vector for backdoor attacks. Our video demo is available at
https://youtu.be/6JIF8wnX34M.
</p></li>
</ul>

<h3>Title: On Higher Adversarial Susceptibility of Contrastive Self-Supervised Learning. (arXiv:2207.10862v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2207.10862">http://arxiv.org/abs/2207.10862</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2207.10862] On Higher Adversarial Susceptibility of Contrastive Self-Supervised Learning](http://arxiv.org/abs/2207.10862)</code></li>
<li>Summary: <p>Contrastive self-supervised learning (CSL) has managed to match or surpass
the performance of supervised learning in image and video classification.
However, it is still largely unknown if the nature of the representation
induced by the two learning paradigms is similar. We investigate this under the
lens of adversarial robustness. Our analytical treatment of the problem reveals
intrinsic higher sensitivity of CSL over supervised learning. It identifies the
uniform distribution of data representation over a unit hypersphere in the CSL
representation space as the key contributor to this phenomenon. We establish
that this increases model sensitivity to input perturbations in the presence of
false negatives in the training data. Our finding is supported by extensive
experiments for image and video classification using adversarial perturbations
and other input corruptions. Building on the insights, we devise strategies
that are simple, yet effective in improving model robustness with CSL training.
We demonstrate up to 68% reduction in the performance gap between adversarially
attacked CSL and its supervised counterpart. Finally, we contribute to robust
CSL paradigm by incorporating our findings in adversarial self-supervised
learning. We demonstrate an average gain of about 5% over two different
state-of-the-art methods in this domain.
</p></li>
</ul>

<h3>Title: Active Data Pattern Extraction Attacks on Generative Language Models. (arXiv:2207.10802v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2207.10802">http://arxiv.org/abs/2207.10802</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2207.10802] Active Data Pattern Extraction Attacks on Generative Language Models](http://arxiv.org/abs/2207.10802)</code></li>
<li>Summary: <p>With the wide availability of large pre-trained language model checkpoints,
such as GPT-2 and BERT, the recent trend has been to fine-tune them on a
downstream task to achieve the state-of-the-art performance with a small
computation overhead. One natural example is the Smart Reply application where
a pre-trained model is fine-tuned for suggesting a number of responses given a
query message. In this work, we set out to investigate potential information
leakage vulnerabilities in a typical Smart Reply pipeline and show that it is
possible for an adversary, having black-box or gray-box access to a Smart Reply
model, to extract sensitive user information present in the training data. We
further analyse the privacy impact of specific components, e.g. the decoding
strategy, pertained to this application through our attack settings. We explore
potential mitigation strategies and demonstrate how differential privacy can be
a strong defense mechanism to such data extraction attacks.
</p></li>
</ul>

<h3>Title: NFDLM: A Lightweight Network Flow based Deep Learning Model for DDoS Attack Detection in IoT Domains. (arXiv:2207.10803v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2207.10803">http://arxiv.org/abs/2207.10803</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2207.10803] NFDLM: A Lightweight Network Flow based Deep Learning Model for DDoS Attack Detection in IoT Domains](http://arxiv.org/abs/2207.10803)</code></li>
<li>Summary: <p>In the recent years, Distributed Denial of Service (DDoS) attacks on Internet
of Things (IoT) devices have become one of the prime concerns to Internet users
around the world. One of the sources of the attacks on IoT ecosystems are
botnets. Intruders force IoT devices to become unavailable for its legitimate
users by sending large number of messages within a short interval. This study
proposes NFDLM, a lightweight and optimised Artificial Neural Network (ANN)
based Distributed Denial of Services (DDoS) attack detection framework with
mutual correlation as feature selection method which produces a superior result
when compared with Long Short Term Memory (LSTM) and simple ANN. Overall, the
detection performance achieves approximately 99\% accuracy for the detection of
attacks from botnets. In this work, we have designed and compared four
different models where two are based on ANN and the other two are based on LSTM
to detect the attack types of DDoS.
</p></li>
</ul>

<h3>Title: Suppressing Poisoning Attacks on Federated Learning for Medical Imaging. (arXiv:2207.10804v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2207.10804">http://arxiv.org/abs/2207.10804</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2207.10804] Suppressing Poisoning Attacks on Federated Learning for Medical Imaging](http://arxiv.org/abs/2207.10804)</code></li>
<li>Summary: <p>Collaboration among multiple data-owning entities (e.g., hospitals) can
accelerate the training process and yield better machine learning models due to
the availability and diversity of data. However, privacy concerns make it
challenging to exchange data while preserving confidentiality. Federated
Learning (FL) is a promising solution that enables collaborative training
through exchange of model parameters instead of raw data. However, most
existing FL solutions work under the assumption that participating clients are
\emph{honest} and thus can fail against poisoning attacks from malicious
parties, whose goal is to deteriorate the global model performance. In this
work, we propose a robust aggregation rule called Distance-based Outlier
Suppression (DOS) that is resilient to byzantine failures. The proposed method
computes the distance between local parameter updates of different clients and
obtains an outlier score for each client using Copula-based Outlier Detection
(COPOD). The resulting outlier scores are converted into normalized weights
using a softmax function, and a weighted average of the local parameters is
used for updating the global model. DOS aggregation can effectively suppress
parameter updates from malicious clients without the need for any
hyperparameter selection, even when the data distributions are heterogeneous.
Evaluation on two medical imaging datasets (CheXpert and HAM10000) demonstrates
the higher robustness of DOS method against a variety of poisoning attacks in
comparison to other state-of-the-art methods. The code can be found here
https://github.com/Naiftt/SPAFD.
</p></li>
</ul>

<h3>Title: PowerFDNet: Deep Learning-Based Stealthy False Data Injection Attack Detection for AC-model Transmission Systems. (arXiv:2207.10805v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2207.10805">http://arxiv.org/abs/2207.10805</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2207.10805] PowerFDNet: Deep Learning-Based Stealthy False Data Injection Attack Detection for AC-model Transmission Systems](http://arxiv.org/abs/2207.10805)</code></li>
<li>Summary: <p>Recent studies have demonstrated that smart grids are vulnerable to stealthy
false data injection attacks (SFDIAs), as SFDIAs can bypass residual-based bad
data detection mechanisms. The SFDIA detection has become one of the focuses of
smart grid research. Methods based on deep learning technology have shown
promising accuracy in the detection of SFDIAs. However, most existing methods
rely on the temporal structure of a sequence of measurements but do not take
account of the spatial structure between buses and transmission lines. To
address this issue, we propose a spatiotemporal deep network, PowerFDNet, for
the SFDIA detection in AC-model power grids. The PowerFDNet consists of two
sub-architectures: spatial architecture (SA) and temporal architecture (TA).
The SA is aimed at extracting representations of bus/line measurements and
modeling the spatial structure based on their representations. The TA is aimed
at modeling the temporal structure of a sequence of measurements. Therefore,
the proposed PowerFDNet can effectively model the spatiotemporal structure of
measurements. Case studies on the detection of SFDIAs on the benchmark smart
grids show that the PowerFDNet achieved significant improvement compared with
the state-of-the-art SFDIA detection methods. In addition, an IoT-oriented
lightweight prototype of size 52 MB is implemented and tested for mobile
devices, which demonstrates the potential applications on mobile devices. The
trained model will be available at
\textit{https://github.com/FrankYinXF/PowerFDNet}.
</p></li>
</ul>

<h3>Title: A Convolutional Attention Based Deep Network Solution for UAV Network Attack Recognition over Fading Channels and Interference. (arXiv:2207.10810v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2207.10810">http://arxiv.org/abs/2207.10810</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2207.10810] A Convolutional Attention Based Deep Network Solution for UAV Network Attack Recognition over Fading Channels and Interference](http://arxiv.org/abs/2207.10810)</code></li>
<li>Summary: <p>When users exchange data with Unmanned Aerial vehicles - (UAVs) over
air-to-ground (A2G) wireless communication networks, they expose the link to
attacks that could increase packet loss and might disrupt connectivity. For
example, in emergency deliveries, losing control information (i.e data related
to the UAV control communication) might result in accidents that cause UAV
destruction and damage to buildings or other elements in a city. To prevent
these problems, these issues must be addressed in 5G and 6G scenarios. This
research offers a deep learning (DL) approach for detecting attacks in UAVs
equipped with orthogonal frequency division multiplexing (OFDM) receivers on
Clustered Delay Line (CDL) channels in highly complex scenarios involving
authenticated terrestrial users, as well as attackers in unknown locations. We
use the two observable parameters available in 5G UAV connections: the Received
Signal Strength Indicator (RSSI) and the Signal to Interference plus Noise
Ratio (SINR). The prospective algorithm is generalizable regarding attack
identification, which does not occur during training. Further, it can identify
all the attackers in the environment with 20 terrestrial users. A deeper
investigation into the timing requirements for recognizing attacks show that
after training, the minimum time necessary after the attack begins is 100 ms,
and the minimum attack power is 2 dBm, which is the same power that the
authenticated UAV uses. Our algorithm also detects moving attackers from a
distance of 500 m.
</p></li>
</ul>

<h3>Title: Applying Machine Learning on RSRP-based Features for False Base Station Detection. (arXiv:2207.10999v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2207.10999">http://arxiv.org/abs/2207.10999</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2207.10999] Applying Machine Learning on RSRP-based Features for False Base Station Detection](http://arxiv.org/abs/2207.10999)</code></li>
<li>Summary: <p>False base stations -- IMSI catchers, Stingrays -- are devices that
impersonate legitimate base stations, as a part of malicious activities like
unauthorized surveillance or communication sabotage. Detecting them on the
network side using 3GPP standardized measurement reports is a promising
technique. While applying predetermined detection rules works well when an
attacker operates a false base station with an illegitimate Physical Cell
Identifiers (PCI), the detection will produce false negatives when a more
resourceful attacker operates the false base station with one of the legitimate
PCIs obtained by scanning the neighborhood first. In this paper, we show how
Machine Learning (ML) can be applied to alleviate such false negatives. We
demonstrate our approach by conducting experiments in a simulation setup using
the ns-3 LTE module. We propose three robust ML features (COL, DIST, XY) based
on Reference Signal Received Power (RSRP) contained in measurement reports and
cell locations. We evaluate four ML models (Regression Clustering, Anomaly
Detection Forest, Autoencoder, and RCGAN) and show that several of them have a
high precision in detection even when the false base station is using a
legitimate PCI. In our experiments with a layout of 12 cells, where one cell
acts as a moving false cell, between 75-95\% of the false positions are
detected by the best model at a cost of 0.5\% false positives.
</p></li>
</ul>

<h3>Title: Silent Spring: Prototype Pollution Leads to Remote Code Execution in Node.js. (arXiv:2207.11171v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2207.11171">http://arxiv.org/abs/2207.11171</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2207.11171] Silent Spring: Prototype Pollution Leads to Remote Code Execution in Node](http://arxiv.org/abs/2207.11171)</code></li>
<li>Summary: <p>Prototype pollution is a dangerous vulnerability affecting prototype-based
languages like JavaScript and the Node.js platform. It refers to the ability of
an attacker to inject properties into an object's root prototype at runtime and
subsequently trigger the execution of legitimate code gadgets that access these
properties on the object's prototype, leading to attacks such as DoS, privilege
escalation, and remote code execution (RCE). While there is anecdotal evidence
that prototype pollution leads to RCE, current research does not tackle the
challenge of gadget detection, thus only showing feasibility of DoS attacks
against Node.js libraries.
</p></li>
</ul>

<p>In this paper, we set out to study the problem in a holistic way, from the
detection of prototype pollution to detection of gadgets, with the ambitious
goal of finding end-to-end exploits beyond DoS, in full-fledged Node.js
applications. We build the first multi-staged framework that uses multi-label
static taint analysis to identify prototype pollution in Node.js libraries and
applications, as well as a hybrid approach to detect universal gadgets,
notably, by analyzing the Node.js source code. We implement our framework on
top of GitHub's static analysis framework CodeQL to find 11 universal gadgets
in core Node.js APIs, leading to code execution. Furthermore, we use our
methodology in a study of 15 popular Node.js applications to identify prototype
pollutions and gadgets. We manually exploit RCE in two high-profile
applications. Our results provide alarming evidence that prototype pollution in
combination with powerful universal gadgets lead to RCE in Node.js.
</p>

<h2>robust</h2>
<h3>Title: An advanced combination of semi-supervised Normalizing Flow &amp; Yolo (YoloNF) to detect and recognize vehicle license plates. (arXiv:2207.10777v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2207.10777">http://arxiv.org/abs/2207.10777</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2207.10777] An advanced combination of semi-supervised Normalizing Flow &amp; Yolo (YoloNF) to detect and recognize vehicle license plates](http://arxiv.org/abs/2207.10777)</code></li>
<li>Summary: <p>Fully Automatic License Plate Recognition (ALPR) has been a frequent research
topic due to several practical applications. However, many of the current
solutions are still not robust enough in real situations, commonly depending on
many constraints. This paper presents a robust and efficient ALPR system based
on the state-of-the-art YOLO object detector and Normalizing flows. The model
uses two new strategies. Firstly, a two-stage network using YOLO and a
normalization flow-based model for normalization to detect Licenses Plates (LP)
and recognize the LP with numbers and Arabic characters. Secondly, Multi-scale
image transformations are implemented to provide a solution to the problem of
the YOLO cropped LP detection including significant background noise.
Furthermore, extensive experiments are led on a new dataset with realistic
scenarios, we introduce a larger public annotated dataset collected from
Moroccan plates. We demonstrate that our proposed model can learn on a small
number of samples free of single or multiple characters. The dataset will also
be made publicly available to encourage further studies and research on plate
detection and recognition.
</p></li>
</ul>

<h3>Title: Uncertainty-aware Multi-modal Learning via Cross-modal Random Network Prediction. (arXiv:2207.10851v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2207.10851">http://arxiv.org/abs/2207.10851</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2207.10851] Uncertainty-aware Multi-modal Learning via Cross-modal Random Network Prediction](http://arxiv.org/abs/2207.10851)</code></li>
<li>Summary: <p>Multi-modal learning focuses on training models by equally combining multiple
input data modalities during the prediction process. However, this equal
combination can be detrimental to the prediction accuracy because different
modalities are usually accompanied by varying levels of uncertainty. Using such
uncertainty to combine modalities has been studied by a couple of approaches,
but with limited success because these approaches are either designed to deal
with specific classification or segmentation problems and cannot be easily
translated into other tasks, or suffer from numerical instabilities. In this
paper, we propose a new Uncertainty-aware Multi-modal Learner that estimates
uncertainty by measuring feature density via Cross-modal Random Network
Prediction (CRNP). CRNP is designed to require little adaptation to translate
between different prediction tasks, while having a stable training process.
From a technical point of view, CRNP is the first approach to explore random
network prediction to estimate uncertainty and to combine multi-modal data.
Experiments on two 3D multi-modal medical image segmentation tasks and three 2D
multi-modal computer vision classification tasks show the effectiveness,
adaptability and robustness of CRNP. Also, we provide an extensive discussion
on different fusion functions and visualization to validate the proposed model.
</p></li>
</ul>

<h3>Title: Decoupled Adversarial Contrastive Learning for Self-supervised Adversarial Robustness. (arXiv:2207.10899v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2207.10899">http://arxiv.org/abs/2207.10899</a></li>
<li>Code URL: <a href="https://github.com/pantheon5100/deacl">https://github.com/pantheon5100/deacl</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2207.10899] Decoupled Adversarial Contrastive Learning for Self-supervised Adversarial Robustness](http://arxiv.org/abs/2207.10899)</code></li>
<li>Summary: <p>Adversarial training (AT) for robust representation learning and
self-supervised learning (SSL) for unsupervised representation learning are two
active research fields. Integrating AT into SSL, multiple prior works have
accomplished a highly significant yet challenging task: learning robust
representation without labels. A widely used framework is adversarial
contrastive learning which couples AT and SSL, and thus constitute a very
complex optimization problem. Inspired by the divide-and-conquer philosophy, we
conjecture that it might be simplified as well as improved by solving two
sub-problems: non-robust SSL and pseudo-supervised AT. This motivation shifts
the focus of the task from seeking an optimal integrating strategy for a
coupled problem to finding sub-solutions for sub-problems. With this said, this
work discards prior practices of directly introducing AT to SSL frameworks and
proposed a two-stage framework termed Decoupled Adversarial Contrastive
Learning (DeACL). Extensive experimental results demonstrate that our DeACL
achieves SOTA self-supervised adversarial robustness while significantly
reducing the training time, which validates its effectiveness and efficiency.
Moreover, our DeACL constitutes a more explainable solution, and its success
also bridges the gap with semi-supervised AT for exploiting unlabeled samples
for robust representation learning. The code is publicly accessible at
https://github.com/pantheon5100/DeACL.
</p></li>
</ul>

<h3>Title: PLD-SLAM: A Real-Time Visual SLAM Using Points and Line Segments in Dynamic Scenes. (arXiv:2207.10916v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2207.10916">http://arxiv.org/abs/2207.10916</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2207.10916] PLD-SLAM: A Real-Time Visual SLAM Using Points and Line Segments in Dynamic Scenes](http://arxiv.org/abs/2207.10916)</code></li>
<li>Summary: <p>In this paper, we consider the problems in the practical application of
visual simultaneous localization and mapping (SLAM). With the popularization
and application of the technology in wide scope, the practicability of SLAM
system has become a new hot topic after the accuracy and robustness, e.g., how
to keep the stability of the system and achieve accurate pose estimation in the
low-texture and dynamic environment, and how to improve the universality and
real-time performance of the system in the real scenes, etc. This paper
proposes a real-time stereo indirect visual SLAM system, PLD-SLAM, which
combines point and line features, and avoid the impact of dynamic objects in
highly dynamic environments. We also present a novel global gray similarity
(GGS) algorithm to achieve reasonable keyframe selection and efficient loop
closure detection (LCD). Benefiting from the GGS, PLD-SLAM can realize
real-time accurate pose estimation in most real scenes without pre-training and
loading a huge feature dictionary model. To verify the performance of the
proposed system, we compare it with existing state-of-the-art (SOTA) methods on
the public datasets KITTI, EuRoC MAV, and the indoor stereo datasets provided
by us, etc. The experiments show that the PLD-SLAM has better real-time
performance while ensuring stability and accuracy in most scenarios. In
addition, through the analysis of the experimental results of the GGS, we can
find it has excellent performance in the keyframe selection and LCD.
</p></li>
</ul>

<h3>Title: Visible and Near Infrared Image Fusion Based on Texture Information. (arXiv:2207.10953v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2207.10953">http://arxiv.org/abs/2207.10953</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2207.10953] Visible and Near Infrared Image Fusion Based on Texture Information](http://arxiv.org/abs/2207.10953)</code></li>
<li>Summary: <p>Multi-sensor fusion is widely used in the environment perception system of
the autonomous vehicle. It solves the interference caused by environmental
changes and makes the whole driving system safer and more reliable. In this
paper, a novel visible and near-infrared fusion method based on texture
information is proposed to enhance unstructured environmental images. It aims
at the problems of artifact, information loss and noise in traditional visible
and near infrared image fusion methods. Firstly, the structure information of
the visible image (RGB) and the near infrared image (NIR) after texture removal
is obtained by relative total variation (RTV) calculation as the base layer of
the fused image; secondly, a Bayesian classification model is established to
calculate the noise weight and the noise information and the noise information
in the visible image is adaptively filtered by joint bilateral filter; finally,
the fused image is acquired by color space conversion. The experimental results
demonstrate that the proposed algorithm can preserve the spectral
characteristics and the unique information of visible and near-infrared images
without artifacts and color distortion, and has good robustness as well as
preserving the unique texture.
</p></li>
</ul>

<h3>Title: Learning Human Kinematics by Modeling Temporal Correlations between Joints for Video-based Human Pose Estimation. (arXiv:2207.10971v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2207.10971">http://arxiv.org/abs/2207.10971</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2207.10971] Learning Human Kinematics by Modeling Temporal Correlations between Joints for Video-based Human Pose Estimation](http://arxiv.org/abs/2207.10971)</code></li>
<li>Summary: <p>Estimating human poses from videos is critical in human-computer interaction.
By precisely estimating human poses, the robot can provide an appropriate
response to the human. Most existing approaches use the optical flow, RNNs, or
CNNs to extract temporal features from videos. Despite the positive results of
these attempts, most of them only straightforwardly integrate features along
the temporal dimension, ignoring temporal correlations between joints. In
contrast to previous methods, we propose a plug-and-play kinematics modeling
module (KMM) based on the domain-cross attention mechanism to model the
temporal correlation between joints across different frames explicitly.
Specifically, the proposed KMM models the temporal correlation between any two
joints by calculating their temporal similarity. In this way, KMM can learn the
motion cues of each joint. Using the motion cues (temporal domain) and
historical positions of joints (spatial domain), KMM can infer the initial
positions of joints in the current frame in advance. In addition, we present a
kinematics modeling network (KIMNet) based on the KMM for obtaining the final
positions of joints by combining pose features and initial positions of joints.
By explicitly modeling temporal correlations between joints, KIMNet can infer
the occluded joints at present according to all joints at the previous moment.
Furthermore, the KMM is achieved through an attention mechanism, which allows
it to maintain the high resolution of features. Therefore, it can transfer rich
historical pose information to the current frame, which provides effective pose
information for locating occluded joints. Our approach achieves
state-of-the-art results on two standard video-based pose estimation
benchmarks. Moreover, the proposed KIMNet shows some robustness to the
occlusion, demonstrating the effectiveness of the proposed method.
</p></li>
</ul>

<h3>Title: Taguchi based Design of Sequential Convolution Neural Network for Classification of Defective Fasteners. (arXiv:2207.10992v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2207.10992">http://arxiv.org/abs/2207.10992</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2207.10992] Taguchi based Design of Sequential Convolution Neural Network for Classification of Defective Fasteners](http://arxiv.org/abs/2207.10992)</code></li>
<li>Summary: <p>Fasteners play a critical role in securing various parts of machinery.
Deformations such as dents, cracks, and scratches on the surface of fasteners
are caused by material properties and incorrect handling of equipment during
production processes. As a result, quality control is required to ensure safe
and reliable operations. The existing defect inspection method relies on manual
examination, which consumes a significant amount of time, money, and other
resources; also, accuracy cannot be guaranteed due to human error. Automatic
defect detection systems have proven impactful over the manual inspection
technique for defect analysis. However, computational techniques such as
convolutional neural networks (CNN) and deep learning-based approaches are
evolutionary methods. By carefully selecting the design parameter values, the
full potential of CNN can be realised. Using Taguchi-based design of
experiments and analysis, an attempt has been made to develop a robust
automatic system in this study. The dataset used to train the system has been
created manually for M14 size nuts having two labeled classes: Defective and
Non-defective. There are a total of 264 images in the dataset. The proposed
sequential CNN comes up with a 96.3% validation accuracy, 0.277 validation loss
at 0.001 learning rate.
</p></li>
</ul>

<h3>Title: Learning Generalized Non-Rigid Multimodal Biomedical Image Registration from Generic Point Set Data. (arXiv:2207.10994v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2207.10994">http://arxiv.org/abs/2207.10994</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2207.10994] Learning Generalized Non-Rigid Multimodal Biomedical Image Registration from Generic Point Set Data](http://arxiv.org/abs/2207.10994)</code></li>
<li>Summary: <p>Free Point Transformer (FPT) has been proposed as a data-driven, non-rigid
point set registration approach using deep neural networks. As FPT does not
assume constraints based on point vicinity or correspondence, it may be trained
simply and in a flexible manner by minimizing an unsupervised loss based on the
Chamfer Distance. This makes FPT amenable to real-world medical imaging
applications where ground-truth deformations may be infeasible to obtain, or in
scenarios where only a varying degree of completeness in the point sets to be
aligned is available. To test the limit of the correspondence finding ability
of FPT and its dependency on training data sets, this work explores the
generalizability of the FPT from well-curated non-medical data sets to medical
imaging data sets. First, we train FPT on the ModelNet40 dataset to demonstrate
its effectiveness and the superior registration performance of FPT over
iterative and learning-based point set registration methods. Second, we
demonstrate superior performance in rigid and non-rigid registration and
robustness to missing data. Last, we highlight the interesting generalizability
of the ModelNet-trained FPT by registering reconstructed freehand ultrasound
scans of the spine and generic spine models without additional training,
whereby the average difference to the ground truth curvatures is 1.3 degrees,
across 13 patients.
</p></li>
</ul>

<h3>Title: POP: Mining POtential Performance of new fashion products via webly cross-modal query expansion. (arXiv:2207.11001v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2207.11001">http://arxiv.org/abs/2207.11001</a></li>
<li>Code URL: <a href="https://github.com/humaticslab/pop-mining-potential-performance">https://github.com/humaticslab/pop-mining-potential-performance</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2207.11001] POP: Mining POtential Performance of new fashion products via webly cross-modal query expansion](http://arxiv.org/abs/2207.11001)</code></li>
<li>Summary: <p>We propose a data-centric pipeline able to generate exogenous observation
data for the New Fashion Product Performance Forecasting (NFPPF) problem, i.e.,
predicting the performance of a brand-new clothing probe with no available past
observations. Our pipeline manufactures the missing past starting from a
single, available image of the clothing probe. It starts by expanding textual
tags associated with the image, querying related fashionable or unfashionable
images uploaded on the web at a specific time in the past. A binary classifier
is robustly trained on these web images by confident learning, to learn what
was fashionable in the past and how much the probe image conforms to this
notion of fashionability. This compliance produces the POtential Performance
(POP) time series, indicating how performing the probe could have been if it
were available earlier. POP proves to be highly predictive for the probe's
future performance, ameliorating the sales forecasts of all state-of-the-art
models on the recent VISUELLE fast-fashion dataset. We also show that POP
reflects the ground-truth popularity of new styles (ensembles of clothing
items) on the Fashion Forward benchmark, demonstrating that our webly-learned
signal is a truthful expression of popularity, accessible by everyone and
generalizable to any time of analysis. Forecasting code, data and the POP time
series are available at:
https://github.com/HumaticsLAB/POP-Mining-POtential-Performance
</p></li>
</ul>

<h3>Title: Training Certifiably Robust Neural Networks Against Semantic Perturbations. (arXiv:2207.11177v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2207.11177">http://arxiv.org/abs/2207.11177</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2207.11177] Training Certifiably Robust Neural Networks Against Semantic Perturbations](http://arxiv.org/abs/2207.11177)</code></li>
<li>Summary: <p>Semantic image perturbations, such as scaling and rotation, have been shown
to easily deceive deep neural networks (DNNs). Hence, training DNNs to be
certifiably robust to these perturbations is critical. However, no prior work
has been able to incorporate the objective of deterministic semantic robustness
into the training procedure, as existing deterministic semantic verifiers are
exceedingly slow. To address these challenges, we propose Certified Semantic
Training (CST), the first training framework for deterministic certified
robustness against semantic image perturbations. Our framework leverages a
novel GPU-optimized verifier that, unlike existing works, is fast enough for
use in training. Our results show that networks trained via CST consistently
achieve both better provable semantic robustness and clean accuracy, compared
to networks trained via baselines based on existing works.
</p></li>
</ul>

<h3>Title: Target Identification and Bayesian Model Averaging with Probabilistic Hierarchical Factor Probabilities. (arXiv:2207.11212v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2207.11212">http://arxiv.org/abs/2207.11212</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2207.11212] Target Identification and Bayesian Model Averaging with Probabilistic Hierarchical Factor Probabilities](http://arxiv.org/abs/2207.11212)</code></li>
<li>Summary: <p>Target detection in hyperspectral imagery is the process of locating pixels
from an image which are likely to contain target, typically done by comparing
one or more spectra for the desired target material to each pixel in the image.
Target identification is the process of target detection incorporating an
additional process to identify more specifically the material that is present
in each pixel that scored high in detection. Detection is generally a 2-class
problem of target vs. background, and identification is a many class problem
including target, background, and additional know materials. The identification
process we present is probabilistic and hierarchical which provides
transparency to the process and produces trustworthy output. In this paper we
show that target identification has a much lower false alarm rate than
detection alone, and provide a detailed explanation of a robust identification
method using probabilistic hierarchical classification that handles the vague
categories of materials that depend on users which are different than the
specific physical categories of chemical constituents. Identification is often
done by comparing mixtures of materials including the target spectra to
mixtures of materials that do not include the target spectra, possibly with
other steps. (band combinations, feature checking, background removal, etc.)
Standard linear regression does not handle these problems well because the
number of regressors (identification spectra) is greater than the number of
feature variables (bands), and there are multiple correlated spectra. Our
proposed method handles these challenges efficiently and provides additional
important practical information in the form of hierarchical probabilities
computed from Bayesian model averaging.
</p></li>
</ul>

<h3>Title: Classification via score-based generative modelling. (arXiv:2207.11091v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2207.11091">http://arxiv.org/abs/2207.11091</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2207.11091] Classification via score-based generative modelling](http://arxiv.org/abs/2207.11091)</code></li>
<li>Summary: <p>In this work, we investigated the application of score-based gradient
learning in discriminative and generative classification settings. Score
function can be used to characterize data distribution as an alternative to
density. It can be efficiently learned via score matching, and used to flexibly
generate credible samples to enhance discriminative classification quality, to
recover density and to build generative classifiers. We analysed the decision
theories involving score-based representations, and performed experiments on
simulated and real-world datasets, demonstrating its effectiveness in achieving
and improving binary classification performance, and robustness to
perturbations, particularly in high dimensions and imbalanced situations.
</p></li>
</ul>

<h3>Title: Heterogeneous Ensemble Learning for Enhanced Crash Forecasts -- A Frequentest and Machine Learning based Stacking Framework. (arXiv:2207.10721v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2207.10721">http://arxiv.org/abs/2207.10721</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2207.10721] Heterogeneous Ensemble Learning for Enhanced Crash Forecasts -- A Frequentest and Machine Learning based Stacking Framework](http://arxiv.org/abs/2207.10721)</code></li>
<li>Summary: <p>A variety of statistical and machine learning methods are used to model crash
frequency on specific roadways with machine learning methods generally having a
higher prediction accuracy. Recently, heterogeneous ensemble methods (HEM),
including stacking, have emerged as more accurate and robust intelligent
techniques and are often used to solve pattern recognition problems by
providing more reliable and accurate predictions. In this study, we apply one
of the key HEM methods, Stacking, to model crash frequency on five lane
undivided segments (5T) of urban and suburban arterials. The prediction
performance of Stacking is compared with parametric statistical models (Poisson
and negative binomial) and three state of the art machine learning techniques
(Decision tree, random forest, and gradient boosting), each of which is termed
as the base learner. By employing an optimal weight scheme to combine
individual base learners through stacking, the problem of biased predictions in
individual base-learners due to differences in specifications and prediction
accuracies is avoided. Data including crash, traffic, and roadway inventory
were collected and integrated from 2013 to 2017. The data are split into
training, validation, and testing datasets. Estimation results of statistical
models reveal that besides other factors, crashes increase with density (number
per mile) of different types of driveways. Comparison of out-of-sample
predictions of various models confirms the superiority of Stacking over the
alternative methods considered. From a practical standpoint, stacking can
enhance prediction accuracy (compared to using only one base learner with a
particular specification). When applied systemically, stacking can help
identify more appropriate countermeasures.
</p></li>
</ul>

<h3>Title: Robust Knowledge Adaptation for Dynamic Graph Neural Networks. (arXiv:2207.10839v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2207.10839">http://arxiv.org/abs/2207.10839</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2207.10839] Robust Knowledge Adaptation for Dynamic Graph Neural Networks](http://arxiv.org/abs/2207.10839)</code></li>
<li>Summary: <p>Graph structured data often possess dynamic characters in nature, e.g., the
addition of links and nodes, in many real-world applications. Recent years have
witnessed the increasing attentions paid to dynamic graph neural networks for
modelling such graph data, where almost all the existing approaches assume that
when a new link is built, the embeddings of the neighbor nodes should be
updated by learning the temporal dynamics to propagate new information.
However, such approaches suffer from the limitation that if the node introduced
by a new connection contains noisy information, propagating its knowledge to
other nodes is not reliable and even leads to the collapse of the model. In
this paper, we propose AdaNet: a robust knowledge Adaptation framework via
reinforcement learning for dynamic graph neural Networks. In contrast to
previous approaches immediately updating the embeddings of the neighbor nodes
once adding a new link, AdaNet attempts to adaptively determine which nodes
should be updated because of the new link involved. Considering that the
decision whether to update the embedding of one neighbor node will have great
impact on other neighbor nodes, we thus formulate the selection of node update
as a sequence decision problem, and address this problem via reinforcement
learning. By this means, we can adaptively propagate knowledge to other nodes
for learning robust node embedding representations. To the best of our
knowledge, our approach constitutes the first attempt to explore robust
knowledge adaptation via reinforcement learning for dynamic graph neural
networks. Extensive experiments on three benchmark datasets demonstrate that
AdaNet achieves the state-of-the-art performance. In addition, we perform the
experiments by adding different degrees of noise into the dataset,
quantitatively and qualitatively illustrating the robustness of AdaNet.
</p></li>
</ul>

<h3>Title: Multilabel Prototype Generation for Data Reduction in k-Nearest Neighbour classification. (arXiv:2207.10947v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2207.10947">http://arxiv.org/abs/2207.10947</a></li>
<li>Code URL: <a href="https://github.com/jose-jvmas/multilabel_pg">https://github.com/jose-jvmas/multilabel_pg</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2207.10947] Multilabel Prototype Generation for Data Reduction in k-Nearest Neighbour classification](http://arxiv.org/abs/2207.10947)</code></li>
<li>Summary: <p>Prototype Generation (PG) methods are typically considered for improving the
efficiency of the $k$-Nearest Neighbour ($k$NN) classifier when tackling
high-size corpora. Such approaches aim at generating a reduced version of the
corpus without decreasing the classification performance when compared to the
initial set. Despite their large application in multiclass scenarios, very few
works have addressed the proposal of PG methods for the multilabel space. In
this regard, this work presents the novel adaptation of four multiclass PG
strategies to the multilabel case. These proposals are evaluated with three
multilabel $k$NN-based classifiers, 12 corpora comprising a varied range of
domains and corpus sizes, and different noise scenarios artificially induced in
the data. The results obtained show that the proposed adaptations are capable
of significantly improving -- both in terms of efficiency and classification
performance -- the only reference multilabel PG work in the literature as well
as the case in which no PG method is applied, also presenting a statistically
superior robustness in noisy scenarios. Moreover, these novel PG strategies
allow prioritising either the efficiency or efficacy criteria through its
configuration depending on the target scenario, hence covering a wide area in
the solution space not previously filled by other works.
</p></li>
</ul>

<h2>biometric</h2>
<h3>Title: Smart speaker design and implementation with biometric authentication and advanced voice interaction capability. (arXiv:2207.10811v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2207.10811">http://arxiv.org/abs/2207.10811</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2207.10811] Smart speaker design and implementation with biometric authentication and advanced voice interaction capability](http://arxiv.org/abs/2207.10811)</code></li>
<li>Summary: <p>Advancements in semiconductor technology have reduced dimensions and cost
while improving the performance and capacity of chipsets. In addition,
advancement in the AI frameworks and libraries brings possibilities to
accommodate more AI at the resource-constrained edge of consumer IoT devices.
Sensors are nowadays an integral part of our environment which provide
continuous data streams to build intelligent applications. An example could be
a smart home scenario with multiple interconnected devices. In such smart
environments, for convenience and quick access to web-based service and
personal information such as calendars, notes, emails, reminders, banking, etc,
users link third-party skills or skills from the Amazon store to their smart
speakers. Also, in current smart home scenarios, several smart home products
such as smart security cameras, video doorbells, smart plugs, smart carbon
monoxide monitors, and smart door locks, etc. are interlinked to a modern smart
speaker via means of custom skill addition. Since smart speakers are linked to
such services and devices via the smart speaker user's account. They can be
used by anyone with physical access to the smart speaker via voice commands. If
done so, the data privacy, home security and other aspects of the user get
compromised. Recently launched, Tensor Cam's AI Camera, Toshiba's Symbio,
Facebook's Portal are camera-enabled smart speakers with AI functionalities.
Although they are camera-enabled, yet they do not have an authentication scheme
in addition to calling out the wake-word. This paper provides an overview of
cybersecurity risks faced by smart speaker users due to lack of authentication
scheme and discusses the development of a state-of-the-art camera-enabled,
microphone array-based modern Alexa smart speaker prototype to address these
risks.
</p></li>
</ul>

<h2>steal</h2>
<h2>extraction</h2>
<h3>Title: Seeing 3D Objects in a Single Image via Self-Supervised Static-Dynamic Disentanglement. (arXiv:2207.11232v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2207.11232">http://arxiv.org/abs/2207.11232</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2207.11232] Seeing 3D Objects in a Single Image via Self-Supervised Static-Dynamic Disentanglement](http://arxiv.org/abs/2207.11232)</code></li>
<li>Summary: <p>Human perception reliably identifies movable and immovable parts of 3D
scenes, and completes the 3D structure of objects and background from
incomplete observations. We learn this skill not via labeled examples, but
simply by observing objects move. In this work, we propose an approach that
observes unlabeled multi-view videos at training time and learns to map a
single image observation of a complex scene, such as a street with cars, to a
3D neural scene representation that is disentangled into movable and immovable
parts while plausibly completing its 3D structure. We separately parameterize
movable and immovable scene parts via 2D neural ground plans. These ground
plans are 2D grids of features aligned with the ground plane that can be
locally decoded into 3D neural radiance fields. Our model is trained
self-supervised via neural rendering. We demonstrate that the structure
inherent to our disentangled 3D representation enables a variety of downstream
tasks in street-scale 3D scenes using simple heuristics, such as extraction of
object-centric 3D representations, novel view synthesis, instance segmentation,
and 3D bounding box prediction, highlighting its value as a backbone for
data-efficient 3D scene understanding models. This disentanglement further
enables scene editing via object manipulation such as deletion, insertion, and
rigid-body motion.
</p></li>
</ul>

<h3>Title: PhishSim: Aiding Phishing Website Detection with a Feature-Free Tool. (arXiv:2207.10801v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2207.10801">http://arxiv.org/abs/2207.10801</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2207.10801] PhishSim: Aiding Phishing Website Detection with a Feature-Free Tool](http://arxiv.org/abs/2207.10801)</code></li>
<li>Summary: <p>In this paper, we propose a feature-free method for detecting phishing
websites using the Normalized Compression Distance (NCD), a parameter-free
similarity measure which computes the similarity of two websites by compressing
them, thus eliminating the need to perform any feature extraction. It also
removes any dependence on a specific set of website features. This method
examines the HTML of webpages and computes their similarity with known phishing
websites, in order to classify them. We use the Furthest Point First algorithm
to perform phishing prototype extractions, in order to select instances that
are representative of a cluster of phishing webpages. We also introduce the use
of an incremental learning algorithm as a framework for continuous and adaptive
detection without extracting new features when concept drift occurs. On a large
dataset, our proposed method significantly outperforms previous methods in
detecting phishing websites, with an AUC score of 98.68%, a high true positive
rate (TPR) of around 90%, while maintaining a low false positive rate (FPR) of
0.58%. Our approach uses prototypes, eliminating the need to retain long term
data in the future, and is feasible to deploy in real systems with a processing
time of roughly 0.3 seconds.
</p></li>
</ul>

<h3>Title: GreenDB -- A Dataset and Benchmark for Extraction of Sustainability Information of Consumer Goods. (arXiv:2207.10733v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2207.10733">http://arxiv.org/abs/2207.10733</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2207.10733] GreenDB -- A Dataset and Benchmark for Extraction of Sustainability Information of Consumer Goods](http://arxiv.org/abs/2207.10733)</code></li>
<li>Summary: <p>The production, shipping, usage, and disposal of consumer goods have a
substantial impact on greenhouse gas emissions and the depletion of resources.
Machine Learning (ML) can help to foster sustainable consumption patterns by
accounting for sustainability aspects in product search or recommendations of
modern retail platforms. However, the lack of large high quality publicly
available product data with trustworthy sustainability information impedes the
development of ML technology that can help to reach our sustainability goals.
Here we present GreenDB, a database that collects products from European online
shops on a weekly basis. As proxy for the products' sustainability, it relies
on sustainability labels, which are evaluated by experts. The GreenDB schema
extends the well-known schema.org Product definition and can be readily
integrated into existing product catalogs. We present initial results
demonstrating that ML models trained with our data can reliably (F1 score 96%)
predict the sustainability label of products. These contributions can help to
complement existing e-commerce experiences and ultimately encourage users to
more sustainable consumption patterns.
</p></li>
</ul>

<h3>Title: Spatial-Temporal Feature Extraction and Evaluation Network for Citywide Traffic Condition Prediction. (arXiv:2207.11034v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2207.11034">http://arxiv.org/abs/2207.11034</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2207.11034] Spatial-Temporal Feature Extraction and Evaluation Network for Citywide Traffic Condition Prediction](http://arxiv.org/abs/2207.11034)</code></li>
<li>Summary: <p>Traffic prediction plays an important role in the realization of traffic
control and scheduling tasks in intelligent transportation systems. With the
diversification of data sources, reasonably using rich traffic data to model
the complex spatial-temporal dependence and nonlinear characteristics in
traffic flow are the key challenge for intelligent transportation system. In
addition, clearly evaluating the importance of spatial-temporal features
extracted from different data becomes a challenge. A Double Layer - Spatial
Temporal Feature Extraction and Evaluation (DL-STFEE) model is proposed. The
lower layer of DL-STFEE is spatial-temporal feature extraction layer. The
spatial and temporal features in traffic data are extracted by multi-graph
graph convolution and attention mechanism, and different combinations of
spatial and temporal features are generated. The upper layer of DL-STFEE is the
spatial-temporal feature evaluation layer. Through the attention score matrix
generated by the high-dimensional self-attention mechanism, the
spatial-temporal features combinations are fused and evaluated, so as to get
the impact of different combinations on prediction effect. Three sets of
experiments are performed on actual traffic datasets to show that DL-STFEE can
effectively capture the spatial-temporal features and evaluate the importance
of different spatial-temporal feature combinations.
</p></li>
</ul>

<h2>membership infer</h2>
<h2>federate</h2>
<h3>Title: Federated Semi-Supervised Domain Adaptation via Knowledge Transfer. (arXiv:2207.10727v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2207.10727">http://arxiv.org/abs/2207.10727</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2207.10727] Federated Semi-Supervised Domain Adaptation via Knowledge Transfer](http://arxiv.org/abs/2207.10727)</code></li>
<li>Summary: <p>Given the rapidly changing machine learning environments and expensive data
labeling, semi-supervised domain adaptation (SSDA) is imperative when the
labeled data from the source domain is statistically different from the
partially labeled data from the target domain. Most prior SSDA research is
centrally performed, requiring access to both source and target data. However,
data in many fields nowadays is generated by distributed end devices. Due to
privacy concerns, the data might be locally stored and cannot be shared,
resulting in the ineffectiveness of existing SSDA research. This paper proposes
an innovative approach to achieve SSDA over multiple distributed and
confidential datasets, named by Federated Semi-Supervised Domain Adaptation
(FSSDA). FSSDA integrates SSDA with federated learning based on strategically
designed knowledge distillation techniques, whose efficiency is improved by
performing source and target training in parallel. Moreover, FSSDA controls the
amount of knowledge transferred across domains by properly selecting a key
parameter, i.e., the imitation parameter. Further, the proposed FSSDA can be
effectively generalized to multi-source domain adaptation scenarios. Extensive
experiments are conducted to demonstrate the effectiveness and efficiency of
FSSDA design.
</p></li>
</ul>

<h3>Title: Federated Learning on Adaptively Weighted Nodes by Bilevel Optimization. (arXiv:2207.10751v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2207.10751">http://arxiv.org/abs/2207.10751</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2207.10751] Federated Learning on Adaptively Weighted Nodes by Bilevel Optimization](http://arxiv.org/abs/2207.10751)</code></li>
<li>Summary: <p>We propose a federated learning method with weighted nodes in which the
weights can be modified to optimize the model's performance on a separate
validation set. The problem is formulated as a bilevel optimization where the
inner problem is a federated learning problem with weighted nodes and the outer
problem focuses on optimizing the weights based on the validation performance
of the model returned from the inner problem. A communication-efficient
federated optimization algorithm is designed to solve this bilevel optimization
problem. Under an error-bound assumption, we analyze the generalization
performance of the output model and identify scenarios when our method is in
theory superior to training a model only locally and to federated learning with
static and evenly distributed weights.
</p></li>
</ul>

<h2>fair</h2>
<h3>Title: FairGRAPE: Fairness-aware GRAdient Pruning mEthod for Face Attribute Classification. (arXiv:2207.10888v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2207.10888">http://arxiv.org/abs/2207.10888</a></li>
<li>Code URL: <a href="https://github.com/bernardo1998/fairgrape">https://github.com/bernardo1998/fairgrape</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2207.10888] FairGRAPE: Fairness-aware GRAdient Pruning mEthod for Face Attribute Classification](http://arxiv.org/abs/2207.10888)</code></li>
<li>Summary: <p>Existing pruning techniques preserve deep neural networks' overall ability to
make correct predictions but may also amplify hidden biases during the
compression process. We propose a novel pruning method, Fairness-aware GRAdient
Pruning mEthod (FairGRAPE), that minimizes the disproportionate impacts of
pruning on different sub-groups. Our method calculates the per-group importance
of each model weight and selects a subset of weights that maintain the relative
between-group total importance in pruning. The proposed method then prunes
network edges with small importance values and repeats the procedure by
updating importance values. We demonstrate the effectiveness of our method on
four different datasets, FairFace, UTKFace, CelebA, and ImageNet, for the tasks
of face attribute classification where our method reduces the disparity in
performance degradation by up to 90% compared to the state-of-the-art pruning
algorithms. Our method is substantially more effective in a setting with a high
pruning rate (99%). The code and dataset used in the experiments are available
at https://github.com/Bernardo1998/FairGRAPE
</p></li>
</ul>

<h3>Title: Cryptographic and Financial Fairness. (arXiv:2207.10780v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2207.10780">http://arxiv.org/abs/2207.10780</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2207.10780] Cryptographic and Financial Fairness](http://arxiv.org/abs/2207.10780)</code></li>
<li>Summary: <p>A recent trend in multi-party computation is to achieve cryptographic
fairness via monetary penalties, i.e. each honest player either obtains the
output or receives a compensation in the form of a cryptocurrency. We pioneer
another type of fairness, financial fairness, that is closer to the real-world
valuation of financial transactions. Intuitively, a penalty protocol is
financially fair if the net present cost of participation (the total value of
cash inflows less cash outflows, weighted by the relative discount rate) is the
same for all honest participants, even when some parties cheat.
</p></li>
</ul>

<p>We formally define the notion, show several impossibility results based on
game theory, and analyze the practical effects of (lack of) financial fairness
if one was to run the protocols for real on Bitcoin using Bloomberg's dark pool
trading.
</p>
<p>For example, we show that the ladder protocol (CRYPTO'14), and its variants
(CCS'15 and CCS'16), fail to achieve financial fairness both in theory and in
practice, while the penalty protocols of Kumaresan and Bentov (CCS'14) and
Baum, David and Dowsley (FC'20) are financially fair.
</p>
<p>This version contains formal definitions, detailed security proofs, demos and
experimental data in the appendix.
</p>

<h3>Title: Algorithmic Fairness in Business Analytics: Directions for Research and Practice. (arXiv:2207.10991v1 [cs.AI])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2207.10991">http://arxiv.org/abs/2207.10991</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2207.10991] Algorithmic Fairness in Business Analytics: Directions for Research and Practice](http://arxiv.org/abs/2207.10991)</code></li>
<li>Summary: <p>The extensive adoption of business analytics (BA) has brought financial gains
and increased efficiencies. However, these advances have simultaneously drawn
attention to rising legal and ethical challenges when BA inform decisions with
fairness implications. As a response to these concerns, the emerging study of
algorithmic fairness deals with algorithmic outputs that may result in
disparate outcomes or other forms of injustices for subgroups of the
population, especially those who have been historically marginalized. Fairness
is relevant on the basis of legal compliance, social responsibility, and
utility; if not adequately and systematically addressed, unfair BA systems may
lead to societal harms and may also threaten an organization's own survival,
its competitiveness, and overall performance. This paper offers a
forward-looking, BA-focused review of algorithmic fairness. We first review the
state-of-the-art research on sources and measures of bias, as well as bias
mitigation algorithms. We then provide a detailed discussion of the
utility-fairness relationship, emphasizing that the frequent assumption of a
trade-off between these two constructs is often mistaken or short-sighted.
Finally, we chart a path forward by identifying opportunities for business
scholars to address impactful, open challenges that are key to the effective
and responsible deployment of BA.
</p></li>
</ul>

<h2>interpretability</h2>
<h3>Title: Learning to identify cracks on wind turbine blade surfaces using drone-based inspection images. (arXiv:2207.11186v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2207.11186">http://arxiv.org/abs/2207.11186</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2207.11186] Learning to identify cracks on wind turbine blade surfaces using drone-based inspection images](http://arxiv.org/abs/2207.11186)</code></li>
<li>Summary: <p>Wind energy is expected to be one of the leading ways to achieve the goals of
the Paris Agreement but it in turn heavily depends on effective management of
its operations and maintenance (O&amp;M) costs. Blade failures account for
one-third of all O&amp;M costs thus making accurate detection of blade damages,
especially cracks, very important for sustained operations and cost savings.
Traditionally, damage inspection has been a completely manual process thus
making it subjective, error-prone, and time-consuming. Hence in this work, we
bring more objectivity, scalability, and repeatability in our damage inspection
process, using deep learning, to miss fewer cracks. We build a deep learning
model trained on a large dataset of blade damages, collected by our drone-based
inspection, to correctly detect cracks. Our model is already in production and
has processed more than a million damages with a recall of 0.96. We also focus
on model interpretability using class activation maps to get a peek into the
model workings. The model not only performs as good as human experts but also
better in certain tricky cases. Thus, in this work, we aim to increase wind
energy adoption by decreasing one of its major hurdles - the O\&amp;M costs
resulting from missing blade failures like cracks.
</p></li>
</ul>

<h2>exlainability</h2>
<h2>watermark</h2>
<button id="copy">Copy All</button>
</article>
<script src="https://cdn.staticfile.org/clipboard.js/2.0.4/clipboard.min.js"></script>
<script src="../../javascript/clipboard.js"></script>
