<link rel="stylesheet" href="../../css/markdown.css" />
<article class="markdown-body">
<h1>2025-06-23</h1>
<h3>Title: Ignition Phase : Standard Training for Fast Adversarial Robustness</h3>
<ul>
<li><strong>Authors: </strong>Wang Yu-Hang, Liu ying, Fang liang, Wang Xuelin, Junkang Guo, Shiwei Li, Lei Gao, Jian Liu, Wenfei Yin</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.15685">https://arxiv.org/abs/2506.15685</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.15685">https://arxiv.org/pdf/2506.15685</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.15685]] Ignition Phase : Standard Training for Fast Adversarial Robustness(https://arxiv.org/abs/2506.15685)</code><input type="text"></li>
<li><strong>Keywords: </strong>defense, attack, robust</a></li>
<li><strong>Abstract: </strong>Adversarial Training (AT) is a cornerstone defense, but many variants overlook foundational feature representations by primarily focusing on stronger attack generation. We introduce Adversarial Evolution Training (AET), a simple yet powerful framework that strategically prepends an Empirical Risk Minimization (ERM) phase to conventional AT. We hypothesize this initial ERM phase cultivates a favorable feature manifold, enabling more efficient and effective robustness acquisition. Empirically, AET achieves comparable or superior robustness more rapidly, improves clean accuracy, and cuts training costs by 8-25\%. Its effectiveness is shown across multiple datasets, architectures, and when augmenting established AT methods. Our findings underscore the impact of feature pre-conditioning via standard training for developing more efficient, principled robust defenses. Code is available in the supplementary material.</li>
</ul>

<h3>Title: BASE-Q: Bias and Asymmetric Scaling Enhanced Rotational Quantization for Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Liulu He, Shenli Zhen, Karwei Sun, Yijiang Liu, Yufei Zhao, Chongkang Tan, Huanrui Yang, Yuan Du, Li Du</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.15689">https://arxiv.org/abs/2506.15689</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.15689">https://arxiv.org/pdf/2506.15689</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.15689]] BASE-Q: Bias and Asymmetric Scaling Enhanced Rotational Quantization for Large Language Models(https://arxiv.org/abs/2506.15689)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Rotations have become essential to state-of-the-art quantization pipelines for large language models (LLMs) by effectively smoothing outliers in weights and activations. However, further optimizing the rotation parameters offers only limited performance gains and introduces significant training overhead: due to rotation parameter sharing, full-model must be loaded simultaneously to enable backpropagation, resulting in substantial memory consumption and limited practical utility. In this work, we identify two fundamental limitations of current rotational quantization methods: (i) rotation fails to align channel means, resulting in wider quantization bounds and increased rounding errors; and (ii) rotation makes the activation distribution more Gaussian-like, increasing energy loss caused by clipping errors. To address these issues, we introduce \textbf{BASE-Q}, a simple yet powerful approach that combines bias correction and asymmetric scaling to effectively reduce rounding and clipping errors. Furthermore, BASE-Q enables blockwise optimization, eliminating the need for memory-intensive full-model backpropagation. Extensive experiments on various LLMs and benchmarks demonstrate the effectiveness of BASE-Q, narrowing the accuracy gap to full-precision models by 50.5\%, 42.9\%, and 29.2\% compared to QuaRot, SpinQuant, and OSTQuant, respectively. The code will be released soon.</li>
</ul>

<h3>Title: LLM Web Dynamics: Tracing Model Collapse in a Network of LLMs</h3>
<ul>
<li><strong>Authors: </strong>Tianyu Wang, Lingyou Pang, Akira Horiguchi, Carey E. Priebe</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.SI, stat.ME</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.15690">https://arxiv.org/abs/2506.15690</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.15690">https://arxiv.org/pdf/2506.15690</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.15690]] LLM Web Dynamics: Tracing Model Collapse in a Network of LLMs(https://arxiv.org/abs/2506.15690)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>The increasing use of synthetic data from the public Internet has enhanced data usage efficiency in large language model (LLM) training. However, the potential threat of model collapse remains insufficiently explored. Existing studies primarily examine model collapse in a single model setting or rely solely on statistical surrogates. In this work, we introduce LLM Web Dynamics (LWD), an efficient framework for investigating model collapse at the network level. By simulating the Internet with a retrieval-augmented generation (RAG) database, we analyze the convergence pattern of model outputs. Furthermore, we provide theoretical guarantees for this convergence by drawing an analogy to interacting Gaussian Mixture Models.</li>
</ul>

<h3>Title: MLE-STAR: Machine Learning Engineering Agent via Search and Targeted Refinement</h3>
<ul>
<li><strong>Authors: </strong>Jaehyun Nam, Jinsung Yoon, Jiefeng Chen, Jinwoo Shin, Sercan Ö. Arık, Tomas Pfister</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.15692">https://arxiv.org/abs/2506.15692</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.15692">https://arxiv.org/pdf/2506.15692</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.15692]] MLE-STAR: Machine Learning Engineering Agent via Search and Targeted Refinement(https://arxiv.org/abs/2506.15692)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Agents based on large language models (LLMs) for machine learning engineering (MLE) can automatically implement ML models via code generation. However, existing approaches to build such agents often rely heavily on inherent LLM knowledge and employ coarse exploration strategies that modify the entire code structure at once. This limits their ability to select effective task-specific models and perform deep exploration within specific components, such as experimenting extensively with feature engineering options. To overcome these, we propose MLE-STAR, a novel approach to build MLE agents. MLE-STAR first leverages external knowledge by using a search engine to retrieve effective models from the web, forming an initial solution, then iteratively refines it by exploring various strategies targeting specific ML components. This exploration is guided by ablation studies analyzing the impact of individual code blocks. Furthermore, we introduce a novel ensembling method using an effective strategy suggested by MLE-STAR. Our experimental results show that MLE-STAR achieves medals in 44% of the Kaggle competitions on the MLE-bench, significantly outperforming the best alternative.</li>
</ul>

<h3>Title: Development of a Multiprocessing Interface Genetic Algorithm for Optimising a Multilayer Perceptron for Disease Prediction</h3>
<ul>
<li><strong>Authors: </strong>Iliyas Ibrahim Iliyas, Souley Boukari, Abdulsalam Yau Gital</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.15694">https://arxiv.org/abs/2506.15694</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.15694">https://arxiv.org/pdf/2506.15694</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.15694]] Development of a Multiprocessing Interface Genetic Algorithm for Optimising a Multilayer Perceptron for Disease Prediction(https://arxiv.org/abs/2506.15694)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction</a></li>
<li><strong>Abstract: </strong>This study introduces a framework that integrates nonlinear feature extraction, classification, and efficient optimization. First, kernel principal component analysis with a radial basis function kernel reduces dimensionality while preserving 95% of the variance. Second, a multilayer perceptron (MLP) learns to predict disease status. Finally, a modified multiprocessing genetic algorithm (MIGA) optimizes MLP hyperparameters in parallel over ten generations. We evaluated this approach on three datasets: the Wisconsin Diagnostic Breast Cancer dataset, the Parkinson's Telemonitoring dataset, and the chronic kidney disease dataset. The MLP tuned by the MIGA achieved the best accuracy of 99.12% for breast cancer, 94.87% for Parkinson's disease, and 100% for chronic kidney disease. These results outperform those of other methods, such as grid search, random search, and Bayesian optimization. Compared with a standard genetic algorithm, kernel PCA revealed nonlinear relationships that improved classification, and the MIGA's parallel fitness evaluations reduced the tuning time by approximately 60%. The genetic algorithm incurs high computational cost from sequential fitness evaluations, but our multiprocessing interface GA (MIGA) parallelizes this step, slashing the tuning time and steering the MLP toward the best accuracy score of 99.12%, 94.87%, and 100% for breast cancer, Parkinson's disease, and CKD, respectively.</li>
</ul>

<h3>Title: SimuGen: Multi-modal Agentic Framework for Constructing Block Diagram-Based Simulation Models</h3>
<ul>
<li><strong>Authors: </strong>Xinxing Ren, Qianbo Zang, Zekun Guo</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.15695">https://arxiv.org/abs/2506.15695</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.15695">https://arxiv.org/pdf/2506.15695</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.15695]] SimuGen: Multi-modal Agentic Framework for Constructing Block Diagram-Based Simulation Models(https://arxiv.org/abs/2506.15695)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, large language model</a></li>
<li><strong>Abstract: </strong>Recent advances in large language models (LLMs) have shown impressive performance in mathematical reasoning and code generation. However, LLMs still struggle in the simulation domain, particularly in generating Simulink models, which are essential tools in engineering and scientific research. Our preliminary experiments indicate that LLM agents often fail to produce reliable and complete Simulink simulation code from text-only inputs, likely due to the lack of Simulink-specific data in their pretraining. To address this challenge, we propose SimuGen, a multimodal agent-based framework that automatically generates accurate Simulink simulation code by leveraging both the visual Simulink diagram and domain knowledge. SimuGen coordinates several specialized agents, including an investigator, unit test reviewer, code generator, executor, debug locator, and report writer, supported by a domain-specific knowledge base. This collaborative and modular design enables interpretable, robust, and reproducible Simulink simulation generation. Our source code is publicly available at this https URL.</li>
</ul>

<h3>Title: DeepRTL2: A Versatile Model for RTL-Related Tasks</h3>
<ul>
<li><strong>Authors: </strong>Yi Liu, Hongji Zhang, Yunhao Zhou, Zhengyuan Shi, Changran Xu, Qiang Xu</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AR, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.15697">https://arxiv.org/abs/2506.15697</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.15697">https://arxiv.org/pdf/2506.15697</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.15697]] DeepRTL2: A Versatile Model for RTL-Related Tasks(https://arxiv.org/abs/2506.15697)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>The integration of large language models (LLMs) into electronic design automation (EDA) has significantly advanced the field, offering transformative benefits, particularly in register transfer level (RTL) code generation and understanding. While previous studies have demonstrated the efficacy of fine-tuning LLMs for these generation-based tasks, embedding-based tasks, which are equally critical to EDA workflows, have been largely overlooked. These tasks, including natural language code search, RTL code functionality equivalence checking, and performance prediction, are essential for accelerating and optimizing the hardware design process. To address this gap, we present DeepRTL2, a family of versatile LLMs that unifies both generation- and embedding-based tasks related to RTL. By simultaneously tackling a broad range of tasks, DeepRTL2 represents the first model to provide a comprehensive solution to the diverse challenges in EDA. Through extensive experiments, we show that DeepRTL2 achieves state-of-the-art performance across all evaluated tasks.</li>
</ul>

<h3>Title: BLUR: A Benchmark for LLM Unlearning Robust to Forget-Retain Overlap</h3>
<ul>
<li><strong>Authors: </strong>Shengyuan Hu, Neil Kale, Pratiksha Thaker, Yiwei Fu, Steven Wu, Virginia Smith</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.15699">https://arxiv.org/abs/2506.15699</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.15699">https://arxiv.org/pdf/2506.15699</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.15699]] BLUR: A Benchmark for LLM Unlearning Robust to Forget-Retain Overlap(https://arxiv.org/abs/2506.15699)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack, robust, large language model</a></li>
<li><strong>Abstract: </strong>Machine unlearning has the potential to improve the safety of large language models (LLMs) by removing sensitive or harmful information post hoc. A key challenge in unlearning involves balancing between forget quality (effectively unlearning undesirable information) and retain quality (maintaining good performance on other, general tasks). Unfortunately, as we show, current LLM unlearning benchmarks contain highly disparate forget and retain sets -- painting a false picture of the effectiveness of LLM unlearning methods. This can be particularly problematic because it opens the door for benign perturbations, such as relearning attacks, to easily reveal supposedly unlearned knowledge once models are deployed. To address this, we present $\texttt{BLUR}$: a benchmark for LLM unlearning that provides more realistic scenarios of forget-retain overlap. $\texttt{BLUR}$ significantly expands on existing unlearning benchmarks by providing extended evaluation tasks, combined forget/retain queries, and relearning datasets of varying degrees of difficulty. Despite the benign nature of the queries considered, we find that the performance of existing methods drops significantly when evaluated on $\texttt{BLUR}$, with simple approaches performing better on average than more recent methods. These results highlight the importance of robust evaluation and suggest several important directions of future study. Our benchmark is publicly available at: this https URL</li>
</ul>

<h3>Title: Contraction Actor-Critic: Contraction Metric-Guided Reinforcement Learning for Robust Path Tracking</h3>
<ul>
<li><strong>Authors: </strong>Minjae Cho, Hiroyasu Tsukamoto, Huy Trong Tran</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.15700">https://arxiv.org/abs/2506.15700</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.15700">https://arxiv.org/pdf/2506.15700</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.15700]] Contraction Actor-Critic: Contraction Metric-Guided Reinforcement Learning for Robust Path Tracking(https://arxiv.org/abs/2506.15700)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Control contraction metrics (CCMs) provide a framework to co-synthesize a controller and a corresponding contraction metric -- a positive-definite Riemannian metric under which a closed-loop system is guaranteed to be incrementally exponentially stable. However, the synthesized controller only ensures that all the trajectories of the system converge to one single trajectory and, as such, does not impose any notion of optimality across an entire trajectory. Furthermore, constructing CCMs requires a known dynamics model and non-trivial effort in solving an infinite-dimensional convex feasibility problem, which limits its scalability to complex systems featuring high dimensionality with uncertainty. To address these issues, we propose to integrate CCMs into reinforcement learning (RL), where CCMs provide dynamics-informed feedback for learning control policies that minimize cumulative tracking error under unknown dynamics. We show that our algorithm, called contraction actor-critic (CAC), formally enhances the capability of CCMs to provide a set of contracting policies with the long-term optimality of RL in a fully automated setting. Given a pre-trained dynamics model, CAC simultaneously learns a contraction metric generator (CMG) -- which generates a contraction metric -- and uses an actor-critic algorithm to learn an optimal tracking policy guided by that metric. We demonstrate the effectiveness of our algorithm relative to established baselines through extensive empirical studies, including simulated and real-world robot experiments, and provide a theoretical rationale for incorporating contraction theory into RL.</li>
</ul>

<h3>Title: Compiler-R1: Towards Agentic Compiler Auto-tuning with Reinforcement Learning</h3>
<ul>
<li><strong>Authors: </strong>Haolin Pan, Hongyu Lin, Haoran Luo, Yang Liu, Kaichun Yao, Libo Zhang, Mingjie Xing, Yanjun Wu</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.15701">https://arxiv.org/abs/2506.15701</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.15701">https://arxiv.org/pdf/2506.15701</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.15701]] Compiler-R1: Towards Agentic Compiler Auto-tuning with Reinforcement Learning(https://arxiv.org/abs/2506.15701)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Compiler auto-tuning optimizes pass sequences to improve performance metrics such as Intermediate Representation (IR) instruction count. Although recent advances leveraging Large Language Models (LLMs) have shown promise in automating compiler tuning, two significant challenges still remain: the absence of high-quality reasoning datasets for agents training, and limited effective interactions with the compilation environment. In this work, we introduce Compiler-R1, the first reinforcement learning (RL)-driven framework specifically augmenting LLM capabilities for compiler auto-tuning. Compiler-R1 features a curated, high-quality reasoning dataset and a novel two-stage end-to-end RL training pipeline, enabling efficient environment exploration and learning through an outcome-based reward. Extensive experiments across seven datasets demonstrate Compiler-R1 achieving an average 8.46% IR instruction count reduction compared to opt -Oz, showcasing the strong potential of RL-trained LLMs for compiler optimization. Our code and datasets are publicly available at this https URL.</li>
</ul>

<h3>Title: Minifinetuning: Low-Data Generation Domain Adaptation through Corrective Self-Distillation</h3>
<ul>
<li><strong>Authors: </strong>Peter Belcak, Greg Heinrich, Jan Kautz, Pavlo Molchanov</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.15702">https://arxiv.org/abs/2506.15702</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.15702">https://arxiv.org/pdf/2506.15702</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.15702]] Minifinetuning: Low-Data Generation Domain Adaptation through Corrective Self-Distillation(https://arxiv.org/abs/2506.15702)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Finetuning language models for a new domain inevitably leads to the deterioration of their general performance. This becomes more pronounced the more limited the finetuning data resource. We introduce minifinetuning (MFT), a method for language model domain adaptation that considerably reduces the effects of overfitting-induced degeneralization in low-data settings and which does so in the absence of any pre-training data for replay. MFT demonstrates 2-10x more favourable specialization-to-degeneralization ratios than standard finetuning across a wide range of models and domains and exhibits an intrinsic robustness to overfitting when data in the new domain is scarce and down to as little as 500 samples. Employing corrective self-distillation that is individualized on the sample level, MFT outperforms parameter-efficient finetuning methods, demonstrates replay-like degeneralization mitigation properties, and is composable with either for a combined effect.</li>
</ul>

<h3>Title: Federated Incomplete Multi-view Clustering with Globally Fused Graph Guidance</h3>
<ul>
<li><strong>Authors: </strong>Guoqing Chao, Zhenghao Zhang, Lei Meng, Jie Wen, Dianhui Chu</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.15703">https://arxiv.org/abs/2506.15703</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.15703">https://arxiv.org/pdf/2506.15703</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.15703]] Federated Incomplete Multi-view Clustering with Globally Fused Graph Guidance(https://arxiv.org/abs/2506.15703)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, federate</a></li>
<li><strong>Abstract: </strong>Federated multi-view clustering has been proposed to mine the valuable information within multi-view data distributed across different devices and has achieved impressive results while preserving the privacy. Despite great progress, most federated multi-view clustering methods only used global pseudo-labels to guide the downstream clustering process and failed to exploit the global information when extracting features. In addition, missing data problem in federated multi-view clustering task is less explored. To address these problems, we propose a novel Federated Incomplete Multi-view Clustering method with globally Fused Graph guidance (FIMCFG). Specifically, we designed a dual-head graph convolutional encoder at each client to extract two kinds of underlying features containing global and view-specific information. Subsequently, under the guidance of the fused graph, the two underlying features are fused into high-level features, based on which clustering is conducted under the supervision of pseudo-labeling. Finally, the high-level features are uploaded to the server to refine the graph fusion and pseudo-labeling computation. Extensive experimental results demonstrate the effectiveness and superiority of FIMCFG. Our code is publicly available at this https URL.</li>
</ul>

<h3>Title: Learn from the Past: Fast Sparse Indexing for Large Language Model Decoding</h3>
<ul>
<li><strong>Authors: </strong>Feiyu Yao, Qian Wang</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.15704">https://arxiv.org/abs/2506.15704</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.15704">https://arxiv.org/pdf/2506.15704</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.15704]] Learn from the Past: Fast Sparse Indexing for Large Language Model Decoding(https://arxiv.org/abs/2506.15704)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>As large language models (LLMs) continue to support increasingly longer contexts, the memory demand for key-value (KV) caches during decoding grows rapidly, becoming a critical bottleneck in both GPU memory capacity and PCIe bandwidth. Sparse attention mechanisms alleviate this issue by computing attention weights only for selected key-value pairs. However, their indexing computation typically requires traversing all key vectors, resulting in significant computational and data transfer overhead. To reduce the cost of index retrieval, existing methods often treat each decoding step as an independent process, failing to exploit the temporal correlations embedded in historical decoding information. To this end, we propose LFPS(Learn From the Past for Sparse Indexing), an acceleration method that dynamically constructs sparse indexing candidates based on historical attention patterns. LFPS captures two prevalent trends in decoder attention -vertical patterns (attending to fixed positions) and slash patterns (attending to relative positions) -and incorporates a positional expansion strategy to effectively predict the Top-k indices for the current step. We validate LFPS on challenging long-context benchmarks such as LongBench-RULER, using Llama-3.1-8B-Instruct as the base model. Experimental results show that LFPS achieves up to 22.8$\times$ speedup over full attention and 9.6$\times$ speedup over exact Top-k retrieval on an RTX 4090 GPU and a single CPU core of a Xeon Gold 6430, respectively, while preserving generation accuracy. These results demonstrate that LFPS offers a practical and efficient solution for decoding optimization in long-context LLM inference.</li>
</ul>

<h3>Title: MDPO: Multi-Granularity Direct Preference Optimization for Mathematical Reasoning</h3>
<ul>
<li><strong>Authors: </strong>Yunze Lin</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.15706">https://arxiv.org/abs/2506.15706</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.15706">https://arxiv.org/pdf/2506.15706</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.15706]] MDPO: Multi-Granularity Direct Preference Optimization for Mathematical Reasoning(https://arxiv.org/abs/2506.15706)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Mathematical reasoning presents a significant challenge for Large Language Models (LLMs) as it requires ensuring the correctness of each reasoning step. Researchers have been strengthening the mathematical reasoning abilities of LLMs through supervised fine-tuning, but due to the inability to suppress incorrect outputs, illusions can easily arise. Recently, Direct Preference Optimization (DPO) has been widely adopted for aligning human intent by using preference data to prevent LLMs from generating incorrect outputs. However, it has shown limited benefits in long-chain mathematical reasoning, mainly because DPO struggles to effectively capture the differences between accepted and rejected answers from preferences in long-chain data. The inconsistency between DPO training and LLMs' generation metrics also affects the effectiveness of suppressing incorrect outputs. We propose the Multi-Granularity Direct Preference Optimization (MDPO) method, optimizing the mathematical reasoning of LLMs at three granularities: Solution2Solution, Inference2Inference, and Step2Step. Solution2Solution focuses on the correctness of entire long-chain reasoning; Inference2Inference concentrates on logical reasoning between steps; Step2Step corrects computational errors in steps, enhancing the computational capabilities of LLMs. Additionally, we unify the training objectives of the three granularities to align with the generation metrics. We conducted experiments on the open-source models Qwen2 and Llama3, achieving improvements of 1.7% and 0.9% on the GSM8K dataset, and 2.3% and 1.2% on the MATH dataset, outperforming DPO and other DPO variant methods. Furthermore, we also provide a pipeline for constructing MDPO training data that is simple and does not require manual annotation costs.</li>
</ul>

<h3>Title: Every Rollout Counts: Optimal Resource Allocation for Efficient Test-Time Scaling</h3>
<ul>
<li><strong>Authors: </strong>Xinglin Wang, Yiwei Li, Shaoxiong Feng, Peiwen Yuan, Yueqi Zhang, Jiayi Shi, Chuyi Tan, Boyuan Pan, Yao Hu, Kan Li</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.15707">https://arxiv.org/abs/2506.15707</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.15707">https://arxiv.org/pdf/2506.15707</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.15707]] Every Rollout Counts: Optimal Resource Allocation for Efficient Test-Time Scaling(https://arxiv.org/abs/2506.15707)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Test-Time Scaling (TTS) improves the performance of Large Language Models (LLMs) by using additional inference-time computation to explore multiple reasoning paths through search. Yet how to allocate a fixed rollout budget most effectively during search remains underexplored, often resulting in inefficient use of compute at test time. To bridge this gap, we formulate test-time search as a resource allocation problem and derive the optimal allocation strategy that maximizes the probability of obtaining a correct solution under a fixed rollout budget. Within this formulation, we reveal a core limitation of existing search methods: solution-level allocation tends to favor reasoning directions with more candidates, leading to theoretically suboptimal and inefficient use of compute. To address this, we propose Direction-Oriented Resource Allocation (DORA), a provably optimal method that mitigates this bias by decoupling direction quality from candidate count and allocating resources at the direction level. To demonstrate DORA's effectiveness, we conduct extensive experiments on challenging mathematical reasoning benchmarks including MATH500, AIME2024, and AIME2025. The empirical results show that DORA consistently outperforms strong baselines with comparable computational cost, achieving state-of-the-art accuracy. We hope our findings contribute to a broader understanding of optimal TTS for LLMs.</li>
</ul>

<h3>Title: Studying and Improving Graph Neural Network-based Motif Estimation</h3>
<ul>
<li><strong>Authors: </strong>Pedro C. Vieira, Miguel E. P. Silva, Pedro Manuel Pinto Ribeiro</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.15709">https://arxiv.org/abs/2506.15709</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.15709">https://arxiv.org/pdf/2506.15709</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.15709]] Studying and Improving Graph Neural Network-based Motif Estimation(https://arxiv.org/abs/2506.15709)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability</a></li>
<li><strong>Abstract: </strong>Graph Neural Networks (GNNs) are a predominant method for graph representation learning. However, beyond subgraph frequency estimation, their application to network motif significance-profile (SP) prediction remains under-explored, with no established benchmarks in the literature. We propose to address this problem, framing SP estimation as a task independent of subgraph frequency estimation. Our approach shifts from frequency counting to direct SP estimation and modulates the problem as multitarget regression. The reformulation is optimised for interpretability, stability and scalability on large graphs. We validate our method using a large synthetic dataset and further test it on real-world graphs. Our experiments reveal that 1-WL limited models struggle to make precise estimations of SPs. However, they can generalise to approximate the graph generation processes of networks by comparing their predicted SP with the ones originating from synthetic generators. This first study on GNN-based motif estimation also hints at how using direct SP estimation can help go past the theoretical limitations that motif estimation faces when performed through subgraph counting.</li>
</ul>

<h3>Title: RAST: Reasoning Activation in LLMs via Small-model Transfer</h3>
<ul>
<li><strong>Authors: </strong>Siru Ouyang, Xinyu Zhu, Zilin Xiao, Minhao Jiang, Yu Meng, Jiawei Han</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.15710">https://arxiv.org/abs/2506.15710</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.15710">https://arxiv.org/pdf/2506.15710</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.15710]] RAST: Reasoning Activation in LLMs via Small-model Transfer(https://arxiv.org/abs/2506.15710)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Reinforcement learning (RL) has become a powerful approach for improving the reasoning capabilities of large language models (LLMs), as evidenced by recent successes such as OpenAI's o1 and Deepseek-R1. However, applying RL at scale remains intimidatingly resource-intensive, requiring multiple model copies and extensive GPU workloads. On the other hand, while being powerful, recent studies suggest that RL does not fundamentally endow models with new knowledge; rather, it primarily reshapes the model's output distribution to activate reasoning capabilities latent in the base model. Building on this insight, we hypothesize that the changes in output probabilities induced by RL are largely model-size invariant, opening the door to a more efficient paradigm: training a small model with RL and transferring its induced probability shifts to larger base models. To verify our hypothesis, we conduct a token-level analysis of decoding trajectories and find high alignment in RL-induced output distributions across model scales, validating our hypothesis. Motivated by this, we propose RAST, a simple yet effective method that transfers reasoning behaviors by injecting RL-induced probability adjustments from a small RL-trained model into larger models. Experiments across multiple mathematical reasoning benchmarks show that RAST substantially and consistently enhances the reasoning capabilities of base models while requiring significantly lower GPU memory than direct RL training, sometimes even yielding better performance than the RL-trained counterparts. Our findings offer new insights into the nature of RL-driven reasoning and practical strategies for scaling its benefits without incurring its full computational cost. The project page of RAST is available at this https URL.</li>
</ul>

<h3>Title: Shadow defense against gradient inversion attack in federated learning</h3>
<ul>
<li><strong>Authors: </strong>Le Jiang, Liyan Ma, Guang Yang</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CR, cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.15711">https://arxiv.org/abs/2506.15711</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.15711">https://arxiv.org/pdf/2506.15711</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.15711]] Shadow defense against gradient inversion attack in federated learning(https://arxiv.org/abs/2506.15711)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, protect, defense, attack, steal, federate, interpretability</a></li>
<li><strong>Abstract: </strong>Federated learning (FL) has emerged as a transformative framework for privacy-preserving distributed training, allowing clients to collaboratively train a global model without sharing their local data. This is especially crucial in sensitive fields like healthcare, where protecting patient data is paramount. However, privacy leakage remains a critical challenge, as the communication of model updates can be exploited by potential adversaries. Gradient inversion attacks (GIAs), for instance, allow adversaries to approximate the gradients used for training and reconstruct training images, thus stealing patient privacy. Existing defense mechanisms obscure gradients, yet lack a nuanced understanding of which gradients or types of image information are most vulnerable to such attacks. These indiscriminate calibrated perturbations result in either excessive privacy protection degrading model accuracy, or insufficient one failing to safeguard sensitive information. Therefore, we introduce a framework that addresses these challenges by leveraging a shadow model with interpretability for identifying sensitive areas. This enables a more targeted and sample-specific noise injection. Specially, our defensive strategy achieves discrepancies of 3.73 in PSNR and 0.2 in SSIM compared to the circumstance without defense on the ChestXRay dataset, and 2.78 in PSNR and 0.166 in the EyePACS dataset. Moreover, it minimizes adverse effects on model performance, with less than 1\% F1 reduction compared to SOTA methods. Our extensive experiments, conducted across diverse types of medical images, validate the generalization of the proposed framework. The stable defense improvements for FedAvg are consistently over 1.5\% times in LPIPS and SSIM. It also offers a universal defense against various GIA types, especially for these sensitive areas in images.</li>
</ul>

<h3>Title: BatteryBERT for Realistic Battery Fault Detection Using Point-Masked Signal Modeling</h3>
<ul>
<li><strong>Authors: </strong>Songqi Zhou, Ruixue Liu, Yixing Wang, Jia Lu, Benben Jiang</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.15712">https://arxiv.org/abs/2506.15712</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.15712">https://arxiv.org/pdf/2506.15712</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.15712]] BatteryBERT for Realistic Battery Fault Detection Using Point-Masked Signal Modeling(https://arxiv.org/abs/2506.15712)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, large language model</a></li>
<li><strong>Abstract: </strong>Accurate fault detection in lithium-ion batteries is essential for the safe and reliable operation of electric vehicles and energy storage systems. However, existing methods often struggle to capture complex temporal dependencies and cannot fully leverage abundant unlabeled data. Although large language models (LLMs) exhibit strong representation capabilities, their architectures are not directly suited to the numerical time-series data common in industrial settings. To address these challenges, we propose a novel framework that adapts BERT-style pretraining for battery fault detection by extending the standard BERT architecture with a customized time-series-to-token representation module and a point-level Masked Signal Modeling (point-MSM) pretraining task tailored to battery applications. This approach enables self-supervised learning on sequential current, voltage, and other charge-discharge cycle data, yielding distributionally robust, context-aware temporal embeddings. We then concatenate these embeddings with battery metadata and feed them into a downstream classifier for accurate fault classification. Experimental results on a large-scale real-world dataset show that models initialized with our pretrained parameters significantly improve both representation quality and classification accuracy, achieving an AUROC of 0.945 and substantially outperforming existing approaches. These findings validate the effectiveness of BERT-style pretraining for time-series fault detection.</li>
</ul>

<h3>Title: Adaptive Two Sided Laplace Transforms: A Learnable, Interpretable, and Scalable Replacement for Self-Attention</h3>
<ul>
<li><strong>Authors: </strong>Andrew Kiruluta</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.15714">https://arxiv.org/abs/2506.15714</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.15714">https://arxiv.org/pdf/2506.15714</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.15714]] Adaptive Two Sided Laplace Transforms: A Learnable, Interpretable, and Scalable Replacement for Self-Attention(https://arxiv.org/abs/2506.15714)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, interpretability, transformer</a></li>
<li><strong>Abstract: </strong>We propose an innovative, learnable two-sided short-time Laplace transform (STLT) mechanism to supplant the traditional self attention in transformer-based LLMs. Our STLT introduces trainable parameters for each Laplace node, enabling end-to-end learning of decay rates , oscillatory frequencies, and window bandwidth T. This flexibility allows the model to dynamically adapt token relevance half lives and frequency responses during training. By selecting S learnable nodes and leveraging fast recursive convolution, we achieve an effective complexity of in time and memory. We further incorporate an efficient FFT-based computation of the relevance matrix and an adaptive node allocation mechanism to dynamically adjust the number of active Laplace nodes. Empirical results on language modeling (WikiText\-103, Project Gutenberg), machine translation (WMT'14 En\-De), and long document question answering (NarrativeQA) demonstrate that our learnable STLT achieves perplexities and scores on par with or better than existing efficient transformers while naturally extending to context lengths exceeding 100k tokens or more limited only by available hardware. Ablation studies confirm the importance of learnable parameters and adaptive node allocation. The proposed approach combines interpretability, through explicit decay and frequency parameters, with scalability and robustness, offering a pathway towards ultra-long-sequence language modeling without the computational bottleneck of self-attention.</li>
</ul>

<h3>Title: daDPO: Distribution-Aware DPO for Distilling Conversational Abilities</h3>
<ul>
<li><strong>Authors: </strong>Zhengze Zhang, Shiqi Wang, Yiqun Shen, Simin Guo, Dahua Lin, Xiaoliang Wang, Nguyen Cam-Tu, Fei Tan</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.15717">https://arxiv.org/abs/2506.15717</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.15717">https://arxiv.org/pdf/2506.15717</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.15717]] daDPO: Distribution-Aware DPO for Distilling Conversational Abilities(https://arxiv.org/abs/2506.15717)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large language models (LLMs) have demonstrated exceptional performance across various applications, but their conversational abilities decline sharply as model size decreases, presenting a barrier to their deployment in resource-constrained environments. Knowledge distillation with Direct Preference Optimization (dDPO) has emerged as a promising approach to enhancing the conversational abilities of smaller models using a larger teacher model. However, current methods primarily focus on 'black-box' KD, which only uses the teacher's responses, overlooking the output distribution offered by the teacher. This paper addresses this gap by introducing daDPO (Distribution-Aware DPO), a unified method for preference optimization and distribution-based distillation. We provide rigorous theoretical analysis and empirical validation, showing that daDPO outperforms existing methods in restoring performance for pruned models and enhancing smaller LLM models. Notably, in in-domain evaluation, our method enables a 20% pruned Vicuna1.5-7B to achieve near-teacher performance (-7.3% preference rate compared to that of dDPO's -31%), and allows Qwen2.5-1.5B to occasionally outperform its 7B teacher model (14.0% win rate).</li>
</ul>

<h3>Title: Bohdi: Heterogeneous LLM Fusion with Automatic Data Exploration</h3>
<ul>
<li><strong>Authors: </strong>Junqi Gao, Zhichang Guo, Dazhi Zhang, Dong Li, Runze Liu, Pengfei Li, Kai Tian, Biqing Qi</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.15721">https://arxiv.org/abs/2506.15721</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.15721">https://arxiv.org/pdf/2506.15721</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.15721]] Bohdi: Heterogeneous LLM Fusion with Automatic Data Exploration(https://arxiv.org/abs/2506.15721)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Heterogeneous Large Language Model (LLM) fusion integrates the strengths of multiple source LLMs with different architectures into a target LLM with low computational overhead. While promising, existing methods suffer from two major limitations: 1) reliance on real data from limited domain for knowledge fusion, preventing the target LLM from fully acquiring knowledge across diverse domains, and 2) fixed data allocation proportions across domains, failing to dynamically adjust according to the target LLM's varying capabilities across domains, leading to a capability imbalance. To overcome these limitations, we propose Bohdi, a synthetic-data-only heterogeneous LLM fusion framework. Through the organization of knowledge domains into a hierarchical tree structure, Bohdi enables automatic domain exploration and multi-domain data generation through multi-model collaboration, thereby comprehensively extracting knowledge from source LLMs. By formalizing domain expansion and data sampling proportion allocation on the knowledge tree as a Hierarchical Multi-Armed Bandit problem, Bohdi leverages the designed DynaBranches mechanism to adaptively adjust sampling proportions based on the target LLM's performance feedback across domains. Integrated with our proposed Introspection-Rebirth (IR) mechanism, DynaBranches dynamically tracks capability shifts during target LLM's updates via Sliding Window Binomial Likelihood Ratio Testing (SWBLRT), further enhancing its online adaptation capability. Comparative experimental results on a comprehensive suite of benchmarks demonstrate that Bohdi significantly outperforms existing baselines on multiple target LLMs, exhibits higher data efficiency, and virtually eliminates the imbalance in the target LLM's capabilities. Our code is available at this https URL.</li>
</ul>

<h3>Title: UniMate: A Unified Model for Mechanical Metamaterial Generation, Property Prediction, and Condition Confirmation</h3>
<ul>
<li><strong>Authors: </strong>Wangzhi Zhan, Jianpeng Chen, Dongqi Fu, Dawei Zhou</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.15722">https://arxiv.org/abs/2506.15722</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.15722">https://arxiv.org/pdf/2506.15722</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.15722]] UniMate: A Unified Model for Mechanical Metamaterial Generation, Property Prediction, and Condition Confirmation(https://arxiv.org/abs/2506.15722)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>Metamaterials are artificial materials that are designed to meet unseen properties in nature, such as ultra-stiffness and negative materials indices. In mechanical metamaterial design, three key modalities are typically involved, i.e., 3D topology, density condition, and mechanical property. Real-world complex application scenarios place the demanding requirements on machine learning models to consider all three modalities together. However, a comprehensive literature review indicates that most existing works only consider two modalities, e.g., predicting mechanical properties given the 3D topology or generating 3D topology given the required properties. Therefore, there is still a significant gap for the state-of-the-art machine learning models capturing the whole. Hence, we propose a unified model named UNIMATE, which consists of a modality alignment module and a synergetic diffusion generation module. Experiments indicate that UNIMATE outperforms the other baseline models in topology generation task, property prediction task, and condition confirmation task by up to 80.2%, 5.1%, and 50.2%, respectively. We opensource our proposed UNIMATE model and corresponding results at this https URL.</li>
</ul>

<h3>Title: MadaKV: Adaptive Modality-Perception KV Cache Eviction for Efficient Multimodal Long-Context Inference</h3>
<ul>
<li><strong>Authors: </strong>Kunxi Li, Zhonghua Jiang, Zhouzhou Shen, Zhaode Wang, Chengfei Lv, Shengyu Zhang, Fan Wu, Fei Wu</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.15724">https://arxiv.org/abs/2506.15724</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.15724">https://arxiv.org/pdf/2506.15724</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.15724]] MadaKV: Adaptive Modality-Perception KV Cache Eviction for Efficient Multimodal Long-Context Inference(https://arxiv.org/abs/2506.15724)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>This paper introduces MadaKV, a modality-adaptive key-value (KV) cache eviction strategy designed to enhance the efficiency of multimodal large language models (MLLMs) in long-context inference. In multimodal scenarios, attention heads exhibit varying preferences for different modalities, resulting in significant disparities in modality importance across attention heads. Traditional KV cache eviction methods, which are tailored for unimodal settings, fail to capture modality-specific information, thereby yielding suboptimal performance. MadaKV addresses these challenges through two key components: modality preference adaptation and hierarchical compression compensation. By dynamically sensing modality information within attention heads and adaptively retaining critical tokens, MadaKV achieves substantial reductions in KV cache memory footprint and model inference decoding latency (1.3 to 1.5 times improvement) while maintaining high accuracy across various multimodal long-context tasks. Extensive experiments on representative MLLMs and the MileBench benchmark demonstrate the effectiveness of MadaKV compared to existing KV cache eviction methods.</li>
</ul>

<h3>Title: Graph Diffusion that can Insert and Delete</h3>
<ul>
<li><strong>Authors: </strong>Matteo Ninniri, Marco Podda, Davide Bacciu</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.15725">https://arxiv.org/abs/2506.15725</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.15725">https://arxiv.org/pdf/2506.15725</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.15725]] Graph Diffusion that can Insert and Delete(https://arxiv.org/abs/2506.15725)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, generative</a></li>
<li><strong>Abstract: </strong>Generative models of graphs based on discrete Denoising Diffusion Probabilistic Models (DDPMs) offer a principled approach to molecular generation by systematically removing structural noise through iterative atom and bond adjustments. However, existing formulations are fundamentally limited by their inability to adapt the graph size (that is, the number of atoms) during the diffusion process, severely restricting their effectiveness in conditional generation scenarios such as property-driven molecular design, where the targeted property often correlates with the molecular size. In this paper, we reformulate the noising and denoising processes to support monotonic insertion and deletion of nodes. The resulting model, which we call GrIDDD, dynamically grows or shrinks the chemical graph during generation. GrIDDD matches or exceeds the performance of existing graph diffusion models on molecular property targeting despite being trained on a more difficult problem. Furthermore, when applied to molecular optimization, GrIDDD exhibits competitive performance compared to specialized optimization models. This work paves the way for size-adaptive molecular generation with graph diffusion.</li>
</ul>

<h3>Title: VLMInferSlow: Evaluating the Efficiency Robustness of Large Vision-Language Models as a Service</h3>
<ul>
<li><strong>Authors: </strong>Xiasi Wang, Tianliang Yao, Simin Chen, Runqi Wang, Lei YE, Kuofeng Gao, Yi Huang, Yuan Yao</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.15755">https://arxiv.org/abs/2506.15755</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.15755">https://arxiv.org/pdf/2506.15755</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.15755]] VLMInferSlow: Evaluating the Efficiency Robustness of Large Vision-Language Models as a Service(https://arxiv.org/abs/2506.15755)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Vision-Language Models (VLMs) have demonstrated great potential in real-world applications. While existing research primarily focuses on improving their accuracy, the efficiency remains underexplored. Given the real-time demands of many applications and the high inference overhead of VLMs, efficiency robustness is a critical issue. However, previous studies evaluate efficiency robustness under unrealistic assumptions, requiring access to the model architecture and parameters -- an impractical scenario in ML-as-a-service settings, where VLMs are deployed via inference APIs. To address this gap, we propose VLMInferSlow, a novel approach for evaluating VLM efficiency robustness in a realistic black-box setting. VLMInferSlow incorporates fine-grained efficiency modeling tailored to VLM inference and leverages zero-order optimization to search for adversarial examples. Experimental results show that VLMInferSlow generates adversarial images with imperceptible perturbations, increasing the computational cost by up to 128.47%. We hope this research raises the community's awareness about the efficiency robustness of VLMs.</li>
</ul>

<h3>Title: Weakly-supervised VLM-guided Partial Contrastive Learning for Visual Language Navigation</h3>
<ul>
<li><strong>Authors: </strong>Ruoyu Wang, Tong Yu, Junda Wu, Yao Liu, Julian McAuley, Lina Yao</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.15757">https://arxiv.org/abs/2506.15757</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.15757">https://arxiv.org/pdf/2506.15757</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.15757]] Weakly-supervised VLM-guided Partial Contrastive Learning for Visual Language Navigation(https://arxiv.org/abs/2506.15757)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Visual Language Navigation (VLN) is a fundamental task within the field of Embodied AI, focusing on the ability of agents to navigate complex environments based on natural language instructions. Despite the progress made by existing methods, these methods often present some common challenges. First, they rely on pre-trained backbone models for visual perception, which struggle with the dynamic viewpoints in VLN scenarios. Second, the performance is limited when using pre-trained LLMs or VLMs without fine-tuning, due to the absence of VLN domain knowledge. Third, while fine-tuning LLMs and VLMs can improve results, their computational costs are higher than those without fine-tuning. To address these limitations, we propose Weakly-supervised Partial Contrastive Learning (WPCL), a method that enhances an agent's ability to identify objects from dynamic viewpoints in VLN scenarios by effectively integrating pre-trained VLM knowledge into the perception process, without requiring VLM fine-tuning. Our method enhances the agent's ability to interpret and respond to environmental cues while ensuring computational efficiency. Experimental results have shown that our method outperforms the baseline methods on multiple benchmarks, which validate the effectiveness, robustness and generalizability of our method.</li>
</ul>

<h3>Title: ETrace:Event-Driven Vulnerability Detection in Smart Contracts via LLM-Based Trace Analysis</h3>
<ul>
<li><strong>Authors: </strong>Chenyang Peng, Haijun Wang, Yin Wu, Hao Wu, Ming Fan, Yitao Zhao, Ting Liu</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.SE</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.15790">https://arxiv.org/abs/2506.15790</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.15790">https://arxiv.org/pdf/2506.15790</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.15790]] ETrace:Event-Driven Vulnerability Detection in Smart Contracts via LLM-Based Trace Analysis(https://arxiv.org/abs/2506.15790)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, attack, large language model</a></li>
<li><strong>Abstract: </strong>With the advance application of blockchain technology in various fields, ensuring the security and stability of smart contracts has emerged as a critical challenge. Current security analysis methodologies in vulnerability detection can be categorized into static analysis and dynamic analysis this http URL, these existing traditional vulnerability detection methods predominantly rely on analyzing original contract code, not all smart contracts provide accessible this http URL present ETrace, a novel event-driven vulnerability detection framework for smart contracts, which uniquely identifies potential vulnerabilities through LLM-powered trace analysis without requiring source code access. By extracting fine-grained event sequences from transaction logs, the framework leverages Large Language Models (LLMs) as adaptive semantic interpreters to reconstruct event analysis through chain-of-thought reasoning. ETrace implements pattern-matching to establish causal links between transaction behavior patterns and known attack behaviors. Furthermore, we validate the effectiveness of ETrace through preliminary experimental results.</li>
</ul>

<h3>Title: Veracity: An Open-Source AI Fact-Checking System</h3>
<ul>
<li><strong>Authors: </strong>Taylor Lynn Curtis, Maximilian Puelma Touzel, William Garneau, Manon Gruaz, Mike Pinder, Li Wei Wang, Sukanya Krishna, Luda Cohen, Jean-François Godbout, Reihaneh Rabbany, Kellin Pelrine</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.HC</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.15794">https://arxiv.org/abs/2506.15794</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.15794">https://arxiv.org/pdf/2506.15794</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.15794]] Veracity: An Open-Source AI Fact-Checking System(https://arxiv.org/abs/2506.15794)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative, large language model</a></li>
<li><strong>Abstract: </strong>The proliferation of misinformation poses a significant threat to society, exacerbated by the capabilities of generative AI. This demo paper introduces Veracity, an open-source AI system designed to empower individuals to combat misinformation through transparent and accessible fact-checking. Veracity leverages the synergy between Large Language Models (LLMs) and web retrieval agents to analyze user-submitted claims and provide grounded veracity assessments with intuitive explanations. Key features include multilingual support, numerical scoring of claim veracity, and an interactive interface inspired by familiar messaging applications. This paper will showcase Veracity's ability to not only detect misinformation but also explain its reasoning, fostering media literacy and promoting a more informed society.</li>
</ul>

<h3>Title: DeepJ: Graph Convolutional Transformers with Differentiable Pooling for Patient Trajectory Modeling</h3>
<ul>
<li><strong>Authors: </strong>Deyi Li, Zijun Yao, Muxuan Liang, Mei Liu</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.15809">https://arxiv.org/abs/2506.15809</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.15809">https://arxiv.org/pdf/2506.15809</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.15809]] DeepJ: Graph Convolutional Transformers with Differentiable Pooling for Patient Trajectory Modeling(https://arxiv.org/abs/2506.15809)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability, transformer</a></li>
<li><strong>Abstract: </strong>In recent years, graph learning has gained significant interest for modeling complex interactions among medical events in structured Electronic Health Record (EHR) data. However, existing graph-based approaches often work in a static manner, either restricting interactions within individual encounters or collapsing all historical encounters into a single snapshot. As a result, when it is necessary to identify meaningful groups of medical events spanning longitudinal encounters, existing methods are inadequate in modeling interactions cross encounters while accounting for temporal dependencies. To address this limitation, we introduce Deep Patient Journey (DeepJ), a novel graph convolutional transformer model with differentiable graph pooling to effectively capture intra-encounter and inter-encounter medical event interactions. DeepJ can identify groups of temporally and functionally related medical events, offering valuable insights into key event clusters pertinent to patient outcome prediction. DeepJ significantly outperformed five state-of-the-art baseline models while enhancing interpretability, demonstrating its potential for improved patient risk stratification.</li>
</ul>

<h3>Title: Heterogeneous Federated Reinforcement Learning Using Wasserstein Barycenters</h3>
<ul>
<li><strong>Authors: </strong>Luiz Pereira, M. Hadi Amini</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.15825">https://arxiv.org/abs/2506.15825</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.15825">https://arxiv.org/pdf/2506.15825</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.15825]] Heterogeneous Federated Reinforcement Learning Using Wasserstein Barycenters(https://arxiv.org/abs/2506.15825)</code><input type="text"></li>
<li><strong>Keywords: </strong>federate</a></li>
<li><strong>Abstract: </strong>In this paper, we first propose a novel algorithm for model fusion that leverages Wasserstein barycenters in training a global Deep Neural Network (DNN) in a distributed architecture. To this end, we divide the dataset into equal parts that are fed to "agents" who have identical deep neural networks and train only over the dataset fed to them (known as the local dataset). After some training iterations, we perform an aggregation step where we combine the weight parameters of all neural networks using Wasserstein barycenters. These steps form the proposed algorithm referred to as FedWB. Moreover, we leverage the processes created in the first part of the paper to develop an algorithm to tackle Heterogeneous Federated Reinforcement Learning (HFRL). Our test experiment is the CartPole toy problem, where we vary the lengths of the poles to create heterogeneous environments. We train a deep Q-Network (DQN) in each environment to learn to control each cart, while occasionally performing a global aggregation step to generalize the local models; the end outcome is a global DQN that functions across all environments.</li>
</ul>

<h3>Title: Rethinking LLM Training through Information Geometry and Quantum Metrics</h3>
<ul>
<li><strong>Authors: </strong>Riccardo Di Sipio</a></li>
<li><strong>Subjects: </strong>cs.CL, quant-ph</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.15830">https://arxiv.org/abs/2506.15830</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.15830">https://arxiv.org/pdf/2506.15830</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.15830]] Rethinking LLM Training through Information Geometry and Quantum Metrics(https://arxiv.org/abs/2506.15830)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Optimization in large language models (LLMs) unfolds over high-dimensional parameter spaces with non-Euclidean structure. Information geometry frames this landscape using the Fisher information metric, enabling more principled learning via natural gradient descent. Though often impractical, this geometric lens clarifies phenomena such as sharp minima, generalization, and observed scaling laws. We argue that curvature-aware approaches deepen our understanding of LLM training. Finally, we speculate on quantum analogies based on the Fubini-Study metric and Quantum Fisher Information, hinting at efficient optimization in quantum-enhanced systems.</li>
</ul>

<h3>Title: EchoShot: Multi-Shot Portrait Video Generation</h3>
<ul>
<li><strong>Authors: </strong>Jiahao Wang, Hualian Sheng, Sijia Cai, Weizhan Zhang, Caixia Yan, Yachuang Feng, Bing Deng, Jieping Ye</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.15838">https://arxiv.org/abs/2506.15838</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.15838">https://arxiv.org/pdf/2506.15838</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.15838]] EchoShot: Multi-Shot Portrait Video Generation(https://arxiv.org/abs/2506.15838)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, transformer, generative</a></li>
<li><strong>Abstract: </strong>Video diffusion models substantially boost the productivity of artistic workflows with high-quality portrait video generative capacity. However, prevailing pipelines are primarily constrained to single-shot creation, while real-world applications urge for multiple shots with identity consistency and flexible content controllability. In this work, we propose EchoShot, a native and scalable multi-shot framework for portrait customization built upon a foundation video diffusion model. To start with, we propose shot-aware position embedding mechanisms within video diffusion transformer architecture to model inter-shot variations and establish intricate correspondence between multi-shot visual content and their textual descriptions. This simple yet effective design enables direct training on multi-shot video data without introducing additional computational overhead. To facilitate model training within multi-shot scenario, we construct PortraitGala, a large-scale and high-fidelity human-centric video dataset featuring cross-shot identity consistency and fine-grained captions such as facial attributes, outfits, and dynamic motions. To further enhance applicability, we extend EchoShot to perform reference image-based personalized multi-shot generation and long video synthesis with infinite shot counts. Extensive evaluations demonstrate that EchoShot achieves superior identity consistency as well as attribute-level controllability in multi-shot portrait video generation. Notably, the proposed framework demonstrates potential as a foundational paradigm for general multi-shot video modeling.</li>
</ul>

<h3>Title: A Sea of Cyber Threats: Maritime Cybersecurity from the Perspective of Mariners</h3>
<ul>
<li><strong>Authors: </strong>Anna Raymaker, Akshaya Kumar, Miuyin Yong Wong, Ryan Pickren, Animesh Chhotaray, Frank Li, Saman Zonouz, Raheem Beyah</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.15842">https://arxiv.org/abs/2506.15842</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.15842">https://arxiv.org/pdf/2506.15842</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.15842]] A Sea of Cyber Threats: Maritime Cybersecurity from the Perspective of Mariners(https://arxiv.org/abs/2506.15842)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, attack</a></li>
<li><strong>Abstract: </strong>Maritime systems, including ships and ports, are critical components of global infrastructure, essential for transporting over 80% of the world's goods and supporting internet connectivity. However, these systems face growing cybersecurity threats, as shown by recent attacks disrupting Maersk, one of the world's largest shipping companies, causing widespread impacts on international trade. The unique challenges of the maritime environment--such as diverse operational conditions, extensive physical access points, fragmented regulatory frameworks, and its deeply interconnected structure--require maritime-specific cybersecurity research. Despite the sector's importance, maritime cybersecurity remains underexplored, leaving significant gaps in understanding its challenges and risks. To address these gaps, we investigate how maritime system operators perceive and navigate cybersecurity challenges within this complex landscape. We conducted a user study comprising surveys and semi-structured interviews with 21 officer-level mariners. Participants reported direct experiences with shipboard cyber-attacks, including GPS spoofing and logistics-disrupting ransomware, demonstrating the real-world impact of these threats. Our findings reveal systemic and human-centric issues, such as training poorly aligned with maritime needs, insufficient detection and response tools, and serious gaps in mariners' cybersecurity understanding. Our contributions include a categorization of threats identified by mariners and recommendations for improving maritime security, including better training, response protocols, and regulation. These insights aim to guide future research and policy to strengthen the resilience of maritime systems.</li>
</ul>

<h3>Title: Privacy-Preserving in Connected and Autonomous Vehicles Through Vision to Text Transformation</h3>
<ul>
<li><strong>Authors: </strong>Abdolazim Rezaei, Mehdi Sookhak, Ahmad Patooghy</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.15854">https://arxiv.org/abs/2506.15854</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.15854">https://arxiv.org/pdf/2506.15854</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.15854]] Privacy-Preserving in Connected and Autonomous Vehicles Through Vision to Text Transformation(https://arxiv.org/abs/2506.15854)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, protect</a></li>
<li><strong>Abstract: </strong>Connected and Autonomous Vehicles (CAVs) rely on a range of devices that often process privacy-sensitive data. Among these, roadside units play a critical role particularly through the use of AI-equipped (AIE) cameras for applications such as violation detection. However, the privacy risks associated with captured imagery remain a major concern, as such data can be misused for identity theft, profiling, or unauthorized commercial purposes. While traditional techniques such as face blurring and obfuscation have been applied to mitigate privacy risks, individual privacy remains at risk, as individuals can still be tracked using other features such as their clothing. This paper introduces a novel privacy-preserving framework that leverages feedback-based reinforcement learning (RL) and vision-language models (VLMs) to protect sensitive visual information captured by AIE cameras. The main idea is to convert images into semantically equivalent textual descriptions, ensuring that scene-relevant information is retained while visual privacy is preserved. A hierarchical RL strategy is employed to iteratively refine the generated text, enhancing both semantic accuracy and privacy. Evaluation results demonstrate significant improvements in both privacy protection and textual quality, with the Unique Word Count increasing by approximately 77\% and Detail Density by around 50\% compared to existing approaches.</li>
</ul>

<h3>Title: Improving Rectified Flow with Boundary Conditions</h3>
<ul>
<li><strong>Authors: </strong>Xixi Hu, Runlong Liao, Keyang Xu, Bo Liu, Yeqing Li, Eugene Ie, Hongliang Fei, Qiang Liu</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.15864">https://arxiv.org/abs/2506.15864</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.15864">https://arxiv.org/pdf/2506.15864</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.15864]] Improving Rectified Flow with Boundary Conditions(https://arxiv.org/abs/2506.15864)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>Rectified Flow offers a simple and effective approach to high-quality generative modeling by learning a velocity field. However, we identify a limitation in directly modeling the velocity with an unconstrained neural network: the learned velocity often fails to satisfy certain boundary conditions, leading to inaccurate velocity field estimations that deviate from the desired ODE. This issue is particularly critical during stochastic sampling at inference, as the score function's errors are amplified near the boundary. To mitigate this, we propose a Boundary-enforced Rectified Flow Model (Boundary RF Model), in which we enforce boundary conditions with a minimal code modification. Boundary RF Model improves performance over vanilla RF model, demonstrating 8.01% improvement in FID score on ImageNet using ODE sampling and 8.98% improvement using SDE sampling.</li>
</ul>

<h3>Title: Hidden Breakthroughs in Language Model Training</h3>
<ul>
<li><strong>Authors: </strong>Sara Kangaslahti, Elan Rosenfeld, Naomi Saphra</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.15872">https://arxiv.org/abs/2506.15872</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.15872">https://arxiv.org/pdf/2506.15872</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.15872]] Hidden Breakthroughs in Language Model Training(https://arxiv.org/abs/2506.15872)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability</a></li>
<li><strong>Abstract: </strong>Loss curves are smooth during most of model training, so visible discontinuities stand out as possible conceptual breakthroughs. Studying these breakthroughs enables a deeper understanding of learning dynamics, but only when they are properly identified. This paper argues that similar breakthroughs occur frequently throughout training but they are obscured by a loss metric that collapses all variation into a single scalar. To find these hidden transitions, we introduce POLCA, a method for decomposing changes in loss along arbitrary bases of the low-rank training subspace. We use our method to identify clusters of samples that share similar changes in loss during training, disaggregating the overall loss into that of smaller groups of conceptually similar data. We validate our method on synthetic arithmetic and natural language tasks, showing that POLCA recovers clusters that represent interpretable breakthroughs in the model's capabilities. We demonstrate the promise of these hidden phase transitions as a tool for unsupervised interpretability.</li>
</ul>

<h3>Title: Job Market Cheat Codes: Prototyping Salary Prediction and Job Grouping with Synthetic Job Listings</h3>
<ul>
<li><strong>Authors: </strong>Abdel Rahman Alsheyab (1), Mohammad Alkhasawneh (1), Nidal Shahin (1) ((1) Jordan University of Science and Technology, Irbid, Jordan)</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.15879">https://arxiv.org/abs/2506.15879</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.15879">https://arxiv.org/pdf/2506.15879</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.15879]] Job Market Cheat Codes: Prototyping Salary Prediction and Job Grouping with Synthetic Job Listings(https://arxiv.org/abs/2506.15879)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction</a></li>
<li><strong>Abstract: </strong>This paper presents a machine learning methodology prototype using a large synthetic dataset of job listings to identify trends, predict salaries, and group similar job roles. Employing techniques such as regression, classification, clustering, and natural language processing (NLP) for text-based feature extraction and representation, this study aims to uncover the key features influencing job market dynamics and provide valuable insights for job seekers, employers, and researchers. Exploratory data analysis was conducted to understand the dataset's characteristics. Subsequently, regression models were developed to predict salaries, classification models to predict job titles, and clustering techniques were applied to group similar jobs. The analyses revealed significant factors influencing salary and job roles, and identified distinct job clusters based on the provided data. While the results are based on synthetic data and not intended for real-world deployment, the methodology demonstrates a transferable framework for job market analysis.</li>
</ul>

<h3>Title: T-SHRED: Symbolic Regression for Regularization and Model Discovery with Transformer Shallow Recurrent Decoders</h3>
<ul>
<li><strong>Authors: </strong>Alexey Yermakov, David Zoro, Mars Liyao Gao, J. Nathan Kutz</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.15881">https://arxiv.org/abs/2506.15881</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.15881">https://arxiv.org/pdf/2506.15881</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.15881]] T-SHRED: Symbolic Regression for Regularization and Model Discovery with Transformer Shallow Recurrent Decoders(https://arxiv.org/abs/2506.15881)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability, transformer</a></li>
<li><strong>Abstract: </strong>SHallow REcurrent Decoders (SHRED) are effective for system identification and forecasting from sparse sensor measurements. Such models are light-weight and computationally efficient, allowing them to be trained on consumer laptops. SHRED-based models rely on Recurrent Neural Networks (RNNs) and a simple Multi-Layer Perceptron (MLP) for the temporal encoding and spatial decoding respectively. Despite the relatively simple structure of SHRED, they are able to predict chaotic dynamical systems on different physical, spatial, and temporal scales directly from a sparse set of sensor measurements. In this work, we improve SHRED by leveraging transformers (T-SHRED) for the temporal encoding which improves performance on next-step state prediction on large datasets. We also introduce a sparse identification of nonlinear dynamics (SINDy) attention mechanism into T-SHRED to perform symbolic regression directly on the latent space as part of the model regularization architecture. Symbolic regression improves model interpretability by learning and regularizing the dynamics of the latent space during training. We analyze the performance of T-SHRED on three different dynamical systems ranging from low-data to high-data regimes. We observe that SINDy attention T-SHRED accurately predicts future frames based on an interpretable symbolic model across all tested datasets.</li>
</ul>

<h3>Title: Fractional Reasoning via Latent Steering Vectors Improves Inference Time Compute</h3>
<ul>
<li><strong>Authors: </strong>Sheng Liu, Tianlang Chen, Pan Lu, Haotian Ye, Yizheng Chen, Lei Xing, James Zou</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CL, eess.SP</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.15882">https://arxiv.org/abs/2506.15882</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.15882">https://arxiv.org/pdf/2506.15882</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.15882]] Fractional Reasoning via Latent Steering Vectors Improves Inference Time Compute(https://arxiv.org/abs/2506.15882)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Test-time compute has emerged as a powerful paradigm for improving the performance of large language models (LLMs), where generating multiple outputs or refining individual chains can significantly boost answer accuracy. However, existing methods like Best-of-N, majority voting, and self-reflection typically apply reasoning in a uniform way across inputs, overlooking the fact that different problems may require different levels of reasoning depth. In this work, we propose Fractional Reasoning, a training-free and model-agnostic framework that enables continuous control over reasoning intensity at inference time, going beyond the limitations of fixed instructional prompts. Our method operates by extracting the latent steering vector associated with deeper reasoning and reapplying it with a tunable scaling factor, allowing the model to tailor its reasoning process to the complexity of each input. This supports two key modes of test-time scaling: (1) improving output quality in breadth-based strategies (e.g., Best-of-N, majority voting), and (2) enhancing the correctness of individual reasoning chains in depth-based strategies (e.g., self-reflection). Experiments on GSM8K, MATH500, and GPQA demonstrate that Fractional Reasoning consistently improves performance across diverse reasoning tasks and models.</li>
</ul>

<h3>Title: Entropy-Driven Pre-Tokenization for Byte-Pair Encoding</h3>
<ul>
<li><strong>Authors: </strong>Yifan Hu, Frank Liang, Dachuan Zhao, Jonathan Geuter, Varshini Reddy, Craig W. Schmidt, Chris Tanner</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.15889">https://arxiv.org/abs/2506.15889</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.15889">https://arxiv.org/pdf/2506.15889</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.15889]] Entropy-Driven Pre-Tokenization for Byte-Pair Encoding(https://arxiv.org/abs/2506.15889)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>Byte-Pair Encoding (BPE) has become a widely adopted subword tokenization method in modern language models due to its simplicity and strong empirical performance across downstream tasks. However, applying BPE to unsegmented languages such as Chinese presents significant challenges, as its frequency-driven merge operation is agnostic to linguistic boundaries. To address this, we propose two entropy-informed pre-tokenization strategies that guide BPE segmentation using unsupervised information-theoretic cues. The first approach uses pointwise mutual information and left/right entropy to identify coherent character spans, while the second leverages predictive entropy derived from a pretrained GPT-2 model to detect boundary uncertainty. We evaluate both methods on a subset of the PKU dataset and demonstrate substantial improvements in segmentation precision, recall, and F1 score compared to standard BPE. Our results suggest that entropy-guided pre-tokenization not only enhances alignment with gold-standard linguistic units but also offers a promising direction for improving tokenization quality in low-resource and multilingual settings.</li>
</ul>

<h3>Title: Language Models can perform Single-Utterance Self-Correction of Perturbed Reasoning</h3>
<ul>
<li><strong>Authors: </strong>Sam Silver, Jimin Sun, Ivan Zhang, Sara Hooker, Eddie Kim</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.15894">https://arxiv.org/abs/2506.15894</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.15894">https://arxiv.org/pdf/2506.15894</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.15894]] Language Models can perform Single-Utterance Self-Correction of Perturbed Reasoning(https://arxiv.org/abs/2506.15894)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, large language model</a></li>
<li><strong>Abstract: </strong>Large Language Models (LLMs) have demonstrated impressive mathematical reasoning capabilities, yet their performance remains brittle to minor variations in problem description and prompting strategy. Furthermore, reasoning is vulnerable to sampling-induced errors which autoregressive models must primarily address using self-correction via additionally-generated tokens. To better understand self-correction capabilities of recent models, we conduct experiments measuring models' ability to self-correct synthetic perturbations introduced into their Chain of Thought (CoT) reasoning. We observe robust single-utterance intrinsic self-correction behavior across a range of open-weight models and datasets, ranging from subtle, implicit corrections to explicit acknowledgments and corrections of errors. Our findings suggest that LLMs, including those not finetuned for long CoT, may possess stronger intrinsic self-correction capabilities than commonly shown in the literature. The presence of this ability suggests that recent "reasoning" model work involves amplification of traits already meaningfully present in models.</li>
</ul>

<h3>Title: TrajDiff: Diffusion Bridge Network with Semantic Alignment for Trajectory Similarity Computation</h3>
<ul>
<li><strong>Authors: </strong>Xiao Zhang, Xingyu Zhao, Hong Xia, Yuan Cao, Guiyuan Jiang, Junyu Dong, Yanwei Yu</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.15898">https://arxiv.org/abs/2506.15898</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.15898">https://arxiv.org/pdf/2506.15898</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.15898]] TrajDiff: Diffusion Bridge Network with Semantic Alignment for Trajectory Similarity Computation(https://arxiv.org/abs/2506.15898)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, diffusion</a></li>
<li><strong>Abstract: </strong>With the proliferation of location-tracking technologies, massive volumes of trajectory data are continuously being collected. As a fundamental task in trajectory data mining, trajectory similarity computation plays a critical role in a wide range of real-world applications. However, existing learning-based methods face three challenges: First, they ignore the semantic gap between GPS and grid features in trajectories, making it difficult to obtain meaningful trajectory embeddings. Second, the noise inherent in the trajectories, as well as the noise introduced during grid discretization, obscures the true motion patterns of the trajectories. Third, existing methods focus solely on point-wise and pair-wise losses, without utilizing the global ranking information obtained by sorting all trajectories according to their similarity to a given trajectory. To address the aforementioned challenges, we propose a novel trajectory similarity computation framework, named TrajDiff. Specifically, the semantic alignment module relies on cross-attention and an attention score mask mechanism with adaptive fusion, effectively eliminating semantic discrepancies between data at two scales and generating a unified representation. Additionally, the DDBM-based Noise-robust Pre-Training introduces the transfer patterns between any two trajectories into the model training process, enhancing the model's noise robustness. Finally, the overall ranking-aware regularization shifts the model's focus from a local to a global perspective, enabling it to capture the holistic ordering information among trajectories. Extensive experiments on three publicly available datasets show that TrajDiff consistently outperforms state-of-the-art baselines. In particular, it achieves an average HR@1 gain of 33.38% across all three evaluation metrics and datasets.</li>
</ul>

<h3>Title: Clinically Interpretable Mortality Prediction for ICU Patients with Diabetes and Atrial Fibrillation: A Machine Learning Approach</h3>
<ul>
<li><strong>Authors: </strong>Li Sun, Shuheng Chen, Yong Si, Junyi Fan, Maryam Pishgar, Elham Pishgar, Kamiar Alaei, Greg Placencia</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.15901">https://arxiv.org/abs/2506.15901</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.15901">https://arxiv.org/pdf/2506.15901</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.15901]] Clinically Interpretable Mortality Prediction for ICU Patients with Diabetes and Atrial Fibrillation: A Machine Learning Approach(https://arxiv.org/abs/2506.15901)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability</a></li>
<li><strong>Abstract: </strong>Background: Patients with both diabetes mellitus (DM) and atrial fibrillation (AF) face elevated mortality in intensive care units (ICUs), yet models targeting this high-risk group remain limited. Objective: To develop an interpretable machine learning (ML) model predicting 28-day mortality in ICU patients with concurrent DM and AF using early-phase clinical data. Methods: A retrospective cohort of 1,535 adult ICU patients with DM and AF was extracted from the MIMIC-IV database. Data preprocessing involved median/mode imputation, z-score normalization, and early temporal feature engineering. A two-step feature selection pipeline-univariate filtering (ANOVA F-test) and Random Forest-based multivariate ranking-yielded 19 interpretable features. Seven ML models were trained with stratified 5-fold cross-validation and SMOTE oversampling. Interpretability was assessed via ablation and Accumulated Local Effects (ALE) analysis. Results: Logistic regression achieved the best performance (AUROC: 0.825; 95% CI: 0.779-0.867), surpassing more complex models. Key predictors included RAS, age, bilirubin, and extubation. ALE plots showed intuitive, non-linear effects such as age-related risk acceleration and bilirubin thresholds. Conclusion: This interpretable ML model offers accurate risk prediction and clinical insights for early ICU triage in patients with DM and AF.</li>
</ul>

<h3>Title: VectorEdits: A Dataset and Benchmark for Instruction-Based Editing of Vector Graphics</h3>
<ul>
<li><strong>Authors: </strong>Josef Kuchař, Marek Kadlčík, Michal Spiegel, Michal Štefánik</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.15903">https://arxiv.org/abs/2506.15903</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.15903">https://arxiv.org/pdf/2506.15903</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.15903]] VectorEdits: A Dataset and Benchmark for Instruction-Based Editing of Vector Graphics(https://arxiv.org/abs/2506.15903)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>We introduce a large-scale dataset for instruction-guided vector image editing, consisting of over 270,000 pairs of SVG images paired with natural language edit instructions. Our dataset enables training and evaluation of models that modify vector graphics based on textual commands. We describe the data collection process, including image pairing via CLIP similarity and instruction generation with vision-language models. Initial experiments with state-of-the-art large language models reveal that current methods struggle to produce accurate and valid edits, underscoring the challenge of this task. To foster research in natural language-driven vector graphic generation and editing, we make our resources created within this work publicly available.</li>
</ul>

<h3>Title: Pieceformer: Similarity-Driven Knowledge Transfer via Scalable Graph Transformer in VLSI</h3>
<ul>
<li><strong>Authors: </strong>Hang Yang, Yusheng Hu, Yong Liu, Cong (Callie)Hao</a></li>
<li><strong>Subjects: </strong>cs.LG, eess.SY</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.15907">https://arxiv.org/abs/2506.15907</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.15907">https://arxiv.org/pdf/2506.15907</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.15907]] Pieceformer: Similarity-Driven Knowledge Transfer via Scalable Graph Transformer in VLSI(https://arxiv.org/abs/2506.15907)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Accurate graph similarity is critical for knowledge transfer in VLSI design, enabling the reuse of prior solutions to reduce engineering effort and turnaround time. We propose Pieceformer, a scalable, self-supervised similarity assessment framework, equipped with a hybrid message-passing and graph transformer encoder. To address transformer scalability, we incorporate a linear transformer backbone and introduce a partitioned training pipeline for efficient memory and parallelism management. Evaluations on synthetic and real-world CircuitNet datasets show that Pieceformer reduces mean absolute error (MAE) by 24.9% over the baseline and is the only method to correctly cluster all real-world design groups. We further demonstrate the practical usage of our model through a case study on a partitioning task, achieving up to 89% runtime reduction. These results validate the framework's effectiveness for scalable, unbiased design reuse in modern VLSI systems.</li>
</ul>

<h3>Title: Pediatric Pancreas Segmentation from MRI Scans with Deep Learning</h3>
<ul>
<li><strong>Authors: </strong>Elif Keles, Merve Yazol, Gorkem Durak, Ziliang Hong, Halil Ertugrul Aktas, Zheyuan Zhang, Linkai Peng, Onkar Susladkar, Necati Guzelyel, Oznur Leman Boyunaga, Cemal Yazici, Mark Lowe, Aliye Uc, Ulas Bagci</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.15908">https://arxiv.org/abs/2506.15908</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.15908">https://arxiv.org/pdf/2506.15908</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.15908]] Pediatric Pancreas Segmentation from MRI Scans with Deep Learning(https://arxiv.org/abs/2506.15908)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>Objective: Our study aimed to evaluate and validate PanSegNet, a deep learning (DL) algorithm for pediatric pancreas segmentation on MRI in children with acute pancreatitis (AP), chronic pancreatitis (CP), and healthy controls. Methods: With IRB approval, we retrospectively collected 84 MRI scans (1.5T/3T Siemens Aera/Verio) from children aged 2-19 years at Gazi University (2015-2024). The dataset includes healthy children as well as patients diagnosed with AP or CP based on clinical criteria. Pediatric and general radiologists manually segmented the pancreas, then confirmed by a senior pediatric radiologist. PanSegNet-generated segmentations were assessed using Dice Similarity Coefficient (DSC) and 95th percentile Hausdorff distance (HD95). Cohen's kappa measured observer agreement. Results: Pancreas MRI T2W scans were obtained from 42 children with AP/CP (mean age: 11.73 +/- 3.9 years) and 42 healthy children (mean age: 11.19 +/- 4.88 years). PanSegNet achieved DSC scores of 88% (controls), 81% (AP), and 80% (CP), with HD95 values of 3.98 mm (controls), 9.85 mm (AP), and 15.67 mm (CP). Inter-observer kappa was 0.86 (controls), 0.82 (pancreatitis), and intra-observer agreement reached 0.88 and 0.81. Strong agreement was observed between automated and manual volumes (R^2 = 0.85 in controls, 0.77 in diseased), demonstrating clinical reliability. Conclusion: PanSegNet represents the first validated deep learning solution for pancreatic MRI segmentation, achieving expert-level performance across healthy and diseased states. This tool, algorithm, along with our annotated dataset, are freely available on GitHub and OSF, advancing accessible, radiation-free pediatric pancreatic imaging and fostering collaborative research in this underserved domain.</li>
</ul>

<h3>Title: Early Attentive Sparsification Accelerates Neural Speech Transcription</h3>
<ul>
<li><strong>Authors: </strong>Zifei Xu, Sayeh Sharify, Hesham Mostafa, Tristan Webb, Wanzin Yazar, Xin Wang</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CL, cs.SD, eess.AS</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.15912">https://arxiv.org/abs/2506.15912</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.15912">https://arxiv.org/pdf/2506.15912</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.15912]] Early Attentive Sparsification Accelerates Neural Speech Transcription(https://arxiv.org/abs/2506.15912)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability, transformer</a></li>
<li><strong>Abstract: </strong>Transformer-based neural speech processing has achieved state-of-the-art performance. Since speech audio signals are known to be highly compressible, here we seek to accelerate neural speech transcription by time-domain signal sparsification early in the neural encoding stage, taking advantage of the interpretability of the self-attention mechanism in transformer audio encoders. With the Whisper family of models, we perform a systematic architecture search over the joint space of sparsification stage (a certain encoder layer) and compression ratio (sparsity). We found that the best resulting solutions under 1% accuracy degradation choose to sparsify the hidden state to 40-60% sparsity at an early encoding stage, and thereby achieve up to 1.6x runtime acceleration in English speech transcription tasks on Nvidia GPUs without any fine-tuning.</li>
</ul>

<h3>Title: Sudoku: Decomposing DRAM Address Mapping into Component Functions</h3>
<ul>
<li><strong>Authors: </strong>Minbok Wi, Seungmin Baek, Seonyong Park, Mattan Erez, Jung Ho Ahn</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.AR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.15918">https://arxiv.org/abs/2506.15918</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.15918">https://arxiv.org/pdf/2506.15918</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.15918]] Sudoku: Decomposing DRAM Address Mapping into Component Functions(https://arxiv.org/abs/2506.15918)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack</a></li>
<li><strong>Abstract: </strong>Decomposing DRAM address mappings into component-level functions is critical for understanding memory behavior and enabling precise RowHammer attacks, yet existing reverse-engineering methods fall short. We introduce novel timing-based techniques leveraging DRAM refresh intervals and consecutive access latencies to infer component-specific functions. Based on this, we present Sudoku, the first software-based tool to automatically decompose full DRAM address mappings into channel, rank, bank group, and bank functions while identifying row and column bits. We validate Sudoku's effectiveness, successfully decomposing mappings on recent Intel and AMD processors.</li>
</ul>

<h3>Title: PNCS:Power-Norm Cosine Similarity for Diverse Client Selection in Federated Learning</h3>
<ul>
<li><strong>Authors: </strong>Liangyan Li, Yangyi Liu, Yimo Ning, Stefano Rini, Jun Chen</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.DC</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.15923">https://arxiv.org/abs/2506.15923</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.15923">https://arxiv.org/pdf/2506.15923</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.15923]] PNCS:Power-Norm Cosine Similarity for Diverse Client Selection in Federated Learning(https://arxiv.org/abs/2506.15923)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, federate</a></li>
<li><strong>Abstract: </strong>Federated Learning (FL) has emerged as a powerful paradigm for leveraging diverse datasets from multiple sources while preserving data privacy by avoiding centralized storage. However, many existing approaches fail to account for the intricate gradient correlations between remote clients, a limitation that becomes especially problematic in data heterogeneity scenarios. In this work, we propose a novel FL framework utilizing Power-Norm Cosine Similarity (PNCS) to improve client selection for model aggregation. By capturing higher-order gradient moments, PNCS addresses non-IID data challenges, enhancing convergence speed and accuracy. Additionally, we introduce a simple algorithm ensuring diverse client selection through a selection history queue. Experiments with a VGG16 model across varied data partitions demonstrate consistent improvements over state-of-the-art methods.</li>
</ul>

<h3>Title: FARFETCH'D: A Side-Channel Analysis Framework for Privacy Applications on Confidential Virtual Machines</h3>
<ul>
<li><strong>Authors: </strong>Ruiyi Zhang, Albert Cheu, Adria Gascon, Daniel Moghimi, Phillipp Schoppmann, Michael Schwarz, Octavian Suciu</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.15924">https://arxiv.org/abs/2506.15924</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.15924">https://arxiv.org/pdf/2506.15924</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.15924]] FARFETCH'D: A Side-Channel Analysis Framework for Privacy Applications on Confidential Virtual Machines(https://arxiv.org/abs/2506.15924)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, attack</a></li>
<li><strong>Abstract: </strong>Confidential virtual machines (CVMs) based on trusted execution environments (TEEs) enable new privacy-preserving solutions. Yet, they leave side-channel leakage outside their threat model, shifting the responsibility of mitigating such attacks to developers. However, mitigations are either not generic or too slow for practical use, and developers currently lack a systematic, efficient way to measure and compare leakage across real-world deployments. In this paper, we present FARFETCH'D, an open-source toolkit that offers configurable side-channel tracing primitives on production AMD SEV-SNP hardware and couples them with statistical and machine-learning-based analysis pipelines for automated leakage estimation. We apply FARFETCH'D to three representative workloads that are deployed on CVMs to enhance user privacy - private information retrieval, private heavy hitters, and Wasm user-defined functions - and uncover previously unnoticed leaks, including a covert channel that exfiltrated data at 497 kbit/s. The results show that FARFETCH'D pinpoints vulnerabilities and guides low-overhead mitigations based on oblivious memory and differential privacy, giving practitioners a practical path to deploy CVMs with meaningful confidentiality guarantees.</li>
</ul>

<h3>Title: Reranking-based Generation for Unbiased Perspective Summarization</h3>
<ul>
<li><strong>Authors: </strong>Narutatsu Ri, Nicholas Deas, Kathleen McKeown</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.15925">https://arxiv.org/abs/2506.15925</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.15925">https://arxiv.org/pdf/2506.15925</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.15925]] Reranking-based Generation for Unbiased Perspective Summarization(https://arxiv.org/abs/2506.15925)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Generating unbiased summaries in real-world settings such as political perspective summarization remains a crucial application of Large Language Models (LLMs). Yet, existing evaluation frameworks rely on traditional metrics for measuring key attributes such as coverage and faithfulness without verifying their applicability, and efforts to develop improved summarizers are still nascent. We address these gaps by (1) identifying reliable metrics for measuring perspective summary quality, and (2) investigating the efficacy of LLM-based methods beyond zero-shot inference. Namely, we build a test set for benchmarking metric reliability using human annotations and show that traditional metrics underperform compared to language model-based metrics, which prove to be strong evaluators. Using these metrics, we show that reranking-based methods yield strong results, and preference tuning with synthetically generated and reranking-labeled data further boosts performance. Our findings aim to contribute to the reliable evaluation and development of perspective summarization methods.</li>
</ul>

<h3>Title: MoiréXNet: Adaptive Multi-Scale Demoiréing with Linear Attention Test-Time Training and Truncated Flow Matching Prior</h3>
<ul>
<li><strong>Authors: </strong>Liangyan Li, Yimo Ning, Kevin Le, Wei Dong, Yunzhe Li, Jun Chen, Xiaohong Liu</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI, eess.IV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.15929">https://arxiv.org/abs/2506.15929</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.15929">https://arxiv.org/pdf/2506.15929</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.15929]] MoiréXNet: Adaptive Multi-Scale Demoiréing with Linear Attention Test-Time Training and Truncated Flow Matching Prior(https://arxiv.org/abs/2506.15929)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>This paper introduces a novel framework for image and video demoiréing by integrating Maximum A Posteriori (MAP) estimation with advanced deep learning techniques. Demoiréing addresses inherently nonlinear degradation processes, which pose significant challenges for existing methods. Traditional supervised learning approaches either fail to remove moiré patterns completely or produce overly smooth results. This stems from constrained model capacity and scarce training data, which inadequately represent the clean image distribution and hinder accurate reconstruction of ground-truth images. While generative models excel in image restoration for linear degradations, they struggle with nonlinear cases such as demoiréing and often introduce artifacts. To address these limitations, we propose a hybrid MAP-based framework that integrates two complementary components. The first is a supervised learning model enhanced with efficient linear attention Test-Time Training (TTT) modules, which directly learn nonlinear mappings for RAW-to-sRGB demoiréing. The second is a Truncated Flow Matching Prior (TFMP) that further refines the outputs by aligning them with the clean image distribution, effectively restoring high-frequency details and suppressing artifacts. These two components combine the computational efficiency of linear attention with the refinement abilities of generative models, resulting in improved restoration performance.</li>
</ul>

<h3>Title: CORAL: Disentangling Latent Representations in Long-Tailed Diffusion</h3>
<ul>
<li><strong>Authors: </strong>Esther Rodriguez, Monica Welfert, Samuel McDowell, Nathan Stromberg, Julian Antolin Camarena, Lalitha Sankar</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.15933">https://arxiv.org/abs/2506.15933</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.15933">https://arxiv.org/pdf/2506.15933</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.15933]] CORAL: Disentangling Latent Representations in Long-Tailed Diffusion(https://arxiv.org/abs/2506.15933)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>Diffusion models have achieved impressive performance in generating high-quality and diverse synthetic data. However, their success typically assumes a class-balanced training distribution. In real-world settings, multi-class data often follow a long-tailed distribution, where standard diffusion models struggle -- producing low-diversity and lower-quality samples for tail classes. While this degradation is well-documented, its underlying cause remains poorly understood. In this work, we investigate the behavior of diffusion models trained on long-tailed datasets and identify a key issue: the latent representations (from the bottleneck layer of the U-Net) for tail class subspaces exhibit significant overlap with those of head classes, leading to feature borrowing and poor generation quality. Importantly, we show that this is not merely due to limited data per class, but that the relative class imbalance significantly contributes to this phenomenon. To address this, we propose COntrastive Regularization for Aligning Latents (CORAL), a contrastive latent alignment framework that leverages supervised contrastive losses to encourage well-separated latent class representations. Experiments demonstrate that CORAL significantly improves both the diversity and visual quality of samples generated for tail classes relative to state-of-the-art methods.</li>
</ul>

<h3>Title: Beyond Audio and Pose: A General-Purpose Framework for Video Synchronization</h3>
<ul>
<li><strong>Authors: </strong>Yosub Shin, Igor Molybog</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.15937">https://arxiv.org/abs/2506.15937</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.15937">https://arxiv.org/pdf/2506.15937</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.15937]] Beyond Audio and Pose: A General-Purpose Framework for Video Synchronization(https://arxiv.org/abs/2506.15937)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, extraction, fair</a></li>
<li><strong>Abstract: </strong>Video synchronization-aligning multiple video streams capturing the same event from different angles-is crucial for applications such as reality TV show production, sports analysis, surveillance, and autonomous systems. Prior work has heavily relied on audio cues or specific visual events, limiting applicability in diverse settings where such signals may be unreliable or absent. Additionally, existing benchmarks for video synchronization lack generality and reproducibility, restricting progress in the field. In this work, we introduce VideoSync, a video synchronization framework that operates independently of specific feature extraction methods, such as human pose estimation, enabling broader applicability across different content types. We evaluate our system on newly composed datasets covering single-human, multi-human, and non-human scenarios, providing both the methodology and code for dataset creation to establish reproducible benchmarks. Our analysis reveals biases in prior SOTA work, particularly in SeSyn-Net's preprocessing pipeline, leading to inflated performance claims. We correct these biases and propose a more rigorous evaluation framework, demonstrating that VideoSync outperforms existing approaches, including SeSyn-Net, under fair experimental conditions. Additionally, we explore various synchronization offset prediction methods, identifying a convolutional neural network (CNN)-based model as the most effective. Our findings advance video synchronization beyond domain-specific constraints, making it more generalizable and robust for real-world applications.</li>
</ul>

<h3>Title: Polyline Path Masked Attention for Vision Transformer</h3>
<ul>
<li><strong>Authors: </strong>Zhongchen Zhao, Chaodong Xiao, Hui Lin, Qi Xie, Lei Zhang, Deyu Meng</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.15940">https://arxiv.org/abs/2506.15940</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.15940">https://arxiv.org/pdf/2506.15940</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.15940]] Polyline Path Masked Attention for Vision Transformer(https://arxiv.org/abs/2506.15940)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer, segmentation</a></li>
<li><strong>Abstract: </strong>Global dependency modeling and spatial position modeling are two core issues of the foundational architecture design in current deep learning frameworks. Recently, Vision Transformers (ViTs) have achieved remarkable success in computer vision, leveraging the powerful global dependency modeling capability of the self-attention mechanism. Furthermore, Mamba2 has demonstrated its significant potential in natural language processing tasks by explicitly modeling the spatial adjacency prior through the structured mask. In this paper, we propose Polyline Path Masked Attention (PPMA) that integrates the self-attention mechanism of ViTs with an enhanced structured mask of Mamba2, harnessing the complementary strengths of both architectures. Specifically, we first ameliorate the traditional structured mask of Mamba2 by introducing a 2D polyline path scanning strategy and derive its corresponding structured mask, polyline path mask, which better preserves the adjacency relationships among image tokens. Notably, we conduct a thorough theoretical analysis on the structural characteristics of the proposed polyline path mask and design an efficient algorithm for the computation of the polyline path mask. Next, we embed the polyline path mask into the self-attention mechanism of ViTs, enabling explicit modeling of spatial adjacency prior. Extensive experiments on standard benchmarks, including image classification, object detection, and segmentation, demonstrate that our model outperforms previous state-of-the-art approaches based on both state-space models and Transformers. For example, our proposed PPMA-T/S/B models achieve 48.7%/51.1%/52.3% mIoU on the ADE20K semantic segmentation task, surpassing RMT-T/S/B by 0.7%/1.3%/0.3%, respectively. Code is available at this https URL.</li>
</ul>

<h3>Title: On the Theoretical Understanding of Identifiable Sparse Autoencoders and Beyond</h3>
<ul>
<li><strong>Authors: </strong>Jingyi Cui, Qi Zhang, Yifei Wang, Yisen Wang</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.15963">https://arxiv.org/abs/2506.15963</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.15963">https://arxiv.org/pdf/2506.15963</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.15963]] On the Theoretical Understanding of Identifiable Sparse Autoencoders and Beyond(https://arxiv.org/abs/2506.15963)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability, large language model</a></li>
<li><strong>Abstract: </strong>Sparse autoencoders (SAEs) have emerged as a powerful tool for interpreting features learned by large language models (LLMs). It aims to recover complex superposed polysemantic features into interpretable monosemantic ones through feature reconstruction via sparsely activated neural networks. Despite the wide applications of SAEs, it remains unclear under what conditions an SAE can fully recover the ground truth monosemantic features from the superposed polysemantic ones. In this paper, through theoretical analysis, we for the first time propose the necessary and sufficient conditions for identifiable SAEs (SAEs that learn unique and ground truth monosemantic features), including 1) extreme sparsity of the ground truth feature, 2) sparse activation of SAEs, and 3) enough hidden dimensions of SAEs. Moreover, when the identifiable conditions are not fully met, we propose a reweighting strategy to improve the identifiability. Specifically, following the theoretically suggested weight selection principle, we prove that the gap between the loss functions of SAE reconstruction and monosemantic feature reconstruction can be narrowed, so that the reweighted SAEs have better reconstruction of the ground truth monosemantic features than the uniformly weighted ones. In experiments, we validate our theoretical findings and show that our weighted SAE significantly improves feature monosemanticity and interpretability.</li>
</ul>

<h3>Title: LazyEviction: Lagged KV Eviction with Attention Pattern Observation for Efficient Long Reasoning</h3>
<ul>
<li><strong>Authors: </strong>Haoyue Zhang, Hualei Zhang, Xiaosong Ma, Jie Zhang, Song Guo</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.15969">https://arxiv.org/abs/2506.15969</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.15969">https://arxiv.org/pdf/2506.15969</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.15969]] LazyEviction: Lagged KV Eviction with Attention Pattern Observation for Efficient Long Reasoning(https://arxiv.org/abs/2506.15969)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large Language Models (LLMs) exhibit enhanced reasoning capabilities by employing Chain-of-Thought (CoT). However, the extended reasoning sequences introduce significant GPU memory overhead due to increased key-value (KV) cache size, particularly in tasks requiring long reasoning sequences, such as mathematics and programming. Existing KV cache compression methods mitigate memory bottlenecks but struggle in long reasoning tasks. In this paper, we analyze attention patterns in reasoning tasks and reveal a Token Importance Recurrence phenomenon: a large proportion of tokens receive renewed attention after multiple decoding steps, which is failed to capture by existing works and may lead to unpredictable eviction on such periodically critical tokens. To address this, we propose LazyEviction, a lagged KV eviction framework designed to maintain reasoning performance while reducing KV memory. LazyEviction is an Observation Window-based Lagged Eviction Mechanism retaining latent recurring tokens by performing lagged evictions across decoding steps, which contains two key components: (1) Recurrence Interval Tracking for capturing temporal variations in token importance, and (2) an Maximum Recurrence Interval-Centric Eviction Policy that prioritizes eviction based on tokens' recurrence patterns. Extensive experiments demonstrate that LazyEviction reduces KV cache size by 50% while maintaining comparable accuracy on mathematics reasoning datasets, outperforming state-of-the-art methods. Our findings highlight the importance of preserving recurring tokens, which are critical for maintaining knowledge continuity in multi-step reasoning tasks.</li>
</ul>

<h3>Title: Heterogeneous-Modal Unsupervised Domain Adaptation via Latent Space Bridging</h3>
<ul>
<li><strong>Authors: </strong>Jiawen Yang, Shuhao Chen, Yucong Duan, Ke Tang, Yu Zhang</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.15971">https://arxiv.org/abs/2506.15971</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.15971">https://arxiv.org/pdf/2506.15971</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.15971]] Heterogeneous-Modal Unsupervised Domain Adaptation via Latent Space Bridging(https://arxiv.org/abs/2506.15971)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>Unsupervised domain adaptation (UDA) methods effectively bridge domain gaps but become struggled when the source and target domains belong to entirely distinct modalities. To address this limitation, we propose a novel setting called Heterogeneous-Modal Unsupervised Domain Adaptation (HMUDA), which enables knowledge transfer between completely different modalities by leveraging a bridge domain containing unlabeled samples from both modalities. To learn under the HMUDA setting, we propose Latent Space Bridging (LSB), a specialized framework designed for the semantic segmentation task. Specifically, LSB utilizes a dual-branch architecture, incorporating a feature consistency loss to align representations across modalities and a domain alignment loss to reduce discrepancies between class centroids across domains. Extensive experiments conducted on six benchmark datasets demonstrate that LSB achieves state-of-the-art performance.</li>
</ul>

<h3>Title: Multi-use LLM Watermarking and the False Detection Problem</h3>
<ul>
<li><strong>Authors: </strong>Zihao Fu, Chris Russell</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.15975">https://arxiv.org/abs/2506.15975</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.15975">https://arxiv.org/pdf/2506.15975</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.15975]] Multi-use LLM Watermarking and the False Detection Problem(https://arxiv.org/abs/2506.15975)</code><input type="text"></li>
<li><strong>Keywords: </strong>watermark</a></li>
<li><strong>Abstract: </strong>Digital watermarking is a promising solution for mitigating some of the risks arising from the misuse of automatically generated text. These approaches either embed non-specific watermarks to allow for the detection of any text generated by a particular sampler, or embed specific keys that allow the identification of the LLM user. However, simultaneously using the same embedding for both detection and user identification leads to a false detection problem, whereby, as user capacity grows, unwatermarked text is increasingly likely to be falsely detected as watermarked. Through theoretical analysis, we identify the underlying causes of this phenomenon. Building on these insights, we propose Dual Watermarking which jointly encodes detection and identification watermarks into generated text, significantly reducing false positives while maintaining high detection accuracy. Our experimental results validate our theoretical findings and demonstrate the effectiveness of our approach.</li>
</ul>

<h3>Title: LBMamba: Locally Bi-directional Mamba</h3>
<ul>
<li><strong>Authors: </strong>Jingwei Zhang, Xi Han, Hong Qin, Mahdi S. Hosseini, Dimitris Samaras</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.15976">https://arxiv.org/abs/2506.15976</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.15976">https://arxiv.org/pdf/2506.15976</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.15976]] LBMamba: Locally Bi-directional Mamba(https://arxiv.org/abs/2506.15976)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>Mamba, a State Space Model (SSM) that accelerates training by recasting recurrence as a parallel selective scan, has recently emerged as a linearly-scaling, efficient alternative to self-attention. Because of its unidirectional nature, each state in Mamba only has information of its previous states and is blind to states after. Current Mamba-based computer-vision methods typically overcome this limitation by augmenting Mamba's global forward scan with a global backward scan, forming a bi-directional scan that restores a full receptive field. However, this operation doubles the computational load, eroding much of the efficiency advantage that originally Mamba have. To eliminate this extra scans, we introduce LBMamba, a locally bi-directional SSM block that embeds a lightweight locally backward scan inside the forward selective scan and executes it entirely in per-thread registers. Building on LBMamba, we present LBVim, a scalable vision backbone that alternates scan directions every two layers to recover a global receptive field without extra backward sweeps. We validate the versatility of our approach on both natural images and whole slide images (WSIs). We show that our LBVim constantly offers a superior performance-throughput trade-off. That is under the same throughput, LBVim achieves 0.8% to 1.6% higher top-1 accuracy on the ImageNet-1K classification dataset, 0.6% to 2.7% higher mIoU on the ADE20K semantic segmentation dataset, 0.9% higher APb and 1.1% higher APm on the COCO detection dataset. We also integrate LBMamba into the SOTA pathology multiple instance learning (MIL) approach, MambaMIL, which uses single directional scan. Experiments on 3 public WSI classification datasets for show that our method achieves a relative improvement of up to 3.06% better AUC, 3.39% better F1, 1.67% better accuracy.</li>
</ul>

<h3>Title: A Vietnamese Dataset for Text Segmentation and Multiple Choices Reading Comprehension</h3>
<ul>
<li><strong>Authors: </strong>Toan Nguyen Hai, Ha Nguyen Viet, Truong Quan Xuan, Duc Do Minh</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.15978">https://arxiv.org/abs/2506.15978</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.15978">https://arxiv.org/pdf/2506.15978</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.15978]] A Vietnamese Dataset for Text Segmentation and Multiple Choices Reading Comprehension(https://arxiv.org/abs/2506.15978)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, segmentation</a></li>
<li><strong>Abstract: </strong>Vietnamese, the 20th most spoken language with over 102 million native speakers, lacks robust resources for key natural language processing tasks such as text segmentation and machine reading comprehension (MRC). To address this gap, we present VSMRC, the Vietnamese Text Segmentation and Multiple-Choice Reading Comprehension Dataset. Sourced from Vietnamese Wikipedia, our dataset includes 15,942 documents for text segmentation and 16,347 synthetic multiple-choice question-answer pairs generated with human quality assurance, ensuring a reliable and diverse resource. Experiments show that mBERT consistently outperforms monolingual models on both tasks, achieving an accuracy of 88.01% on MRC test set and an F1 score of 63.15\% on text segmentation test set. Our analysis reveals that multilingual models excel in NLP tasks for Vietnamese, suggesting potential applications to other under-resourced languages. VSMRC is available at HuggingFace</li>
</ul>

<h3>Title: Advanced Sign Language Video Generation with Compressed and Quantized Multi-Condition Tokenization</h3>
<ul>
<li><strong>Authors: </strong>Cong Wang, Zexuan Deng, Zhiwei Jiang, Fei Shen, Yafeng Yin, Shiwei Gan, Zifeng Cheng, Shiping Ge, Qing Gu</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.15980">https://arxiv.org/abs/2506.15980</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.15980">https://arxiv.org/pdf/2506.15980</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.15980]] Advanced Sign Language Video Generation with Compressed and Quantized Multi-Condition Tokenization(https://arxiv.org/abs/2506.15980)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>Sign Language Video Generation (SLVG) seeks to generate identity-preserving sign language videos from spoken language texts. Existing methods primarily rely on the single coarse condition (\eg, skeleton sequences) as the intermediary to bridge the translation model and the video generation model, which limits both the naturalness and expressiveness of the generated videos. To overcome these limitations, we propose SignViP, a novel SLVG framework that incorporates multiple fine-grained conditions for improved generation fidelity. Rather than directly translating error-prone high-dimensional conditions, SignViP adopts a discrete tokenization paradigm to integrate and represent fine-grained conditions (\ie, fine-grained poses and 3D hands). SignViP contains three core components. (1) Sign Video Diffusion Model is jointly trained with a multi-condition encoder to learn continuous embeddings that encapsulate fine-grained motion and appearance. (2) Finite Scalar Quantization (FSQ) Autoencoder is further trained to compress and quantize these embeddings into discrete tokens for compact representation of the conditions. (3) Multi-Condition Token Translator is trained to translate spoken language text to discrete multi-condition tokens. During inference, Multi-Condition Token Translator first translates the spoken language text into discrete multi-condition tokens. These tokens are then decoded to continuous embeddings by FSQ Autoencoder, which are subsequently injected into Sign Video Diffusion Model to guide video generation. Experimental results show that SignViP achieves state-of-the-art performance across metrics, including video quality, temporal coherence, and semantic fidelity. The code is available at this https URL.</li>
</ul>

<h3>Title: Double Entendre: Robust Audio-Based AI-Generated Lyrics Detection via Multi-View Fusion</h3>
<ul>
<li><strong>Authors: </strong>Markus Frohmann, Gabriel Meseguer-Brocal, Markus Schedl, Elena V. Epure</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.SD, eess.AS</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.15981">https://arxiv.org/abs/2506.15981</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.15981">https://arxiv.org/pdf/2506.15981</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.15981]] Double Entendre: Robust Audio-Based AI-Generated Lyrics Detection via Multi-View Fusion(https://arxiv.org/abs/2506.15981)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>The rapid advancement of AI-based music generation tools is revolutionizing the music industry but also posing challenges to artists, copyright holders, and providers alike. This necessitates reliable methods for detecting such AI-generated content. However, existing detectors, relying on either audio or lyrics, face key practical limitations: audio-based detectors fail to generalize to new or unseen generators and are vulnerable to audio perturbations; lyrics-based methods require cleanly formatted and accurate lyrics, unavailable in practice. To overcome these limitations, we propose a novel, practically grounded approach: a multimodal, modular late-fusion pipeline that combines automatically transcribed sung lyrics and speech features capturing lyrics-related information within the audio. By relying on lyrical aspects directly from audio, our method enhances robustness, mitigates susceptibility to low-level artifacts, and enables practical applicability. Experiments show that our method, DE-detect, outperforms existing lyrics-based detectors while also being more robust to audio perturbations. Thus, it offers an effective, robust solution for detecting AI-generated music in real-world scenarios. Our code is available at this https URL.</li>
</ul>

<h3>Title: Adversarial Attacks and Detection in Visual Place Recognition for Safer Robot Navigation</h3>
<ul>
<li><strong>Authors: </strong>Connor Malone, Owen Claxton, Iman Shames, Michael Milford</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.RO</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.15988">https://arxiv.org/abs/2506.15988</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.15988">https://arxiv.org/pdf/2506.15988</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.15988]] Adversarial Attacks and Detection in Visual Place Recognition for Safer Robot Navigation(https://arxiv.org/abs/2506.15988)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack</a></li>
<li><strong>Abstract: </strong>Stand-alone Visual Place Recognition (VPR) systems have little defence against a well-designed adversarial attack, which can lead to disastrous consequences when deployed for robot navigation. This paper extensively analyzes the effect of four adversarial attacks common in other perception tasks and four novel VPR-specific attacks on VPR localization performance. We then propose how to close the loop between VPR, an Adversarial Attack Detector (AAD), and active navigation decisions by demonstrating the performance benefit of simulated AADs in a novel experiment paradigm -- which we detail for the robotics community to use as a system framework. In the proposed experiment paradigm, we see the addition of AADs across a range of detection accuracies can improve performance over baseline; demonstrating a significant improvement -- such as a ~50% reduction in the mean along-track localization error -- can be achieved with True Positive and False Positive detection rates of only 75% and up to 25% respectively. We examine a variety of metrics including: Along-Track Error, Percentage of Time Attacked, Percentage of Time in an `Unsafe' State, and Longest Continuous Time Under Attack. Expanding further on these results, we provide the first investigation into the efficacy of the Fast Gradient Sign Method (FGSM) adversarial attack for VPR. The analysis in this work highlights the need for AADs in real-world systems for trustworthy navigation, and informs quantitative requirements for system design.</li>
</ul>

<h3>Title: AutoHFormer: Efficient Hierarchical Autoregressive Transformer for Time Series Prediction</h3>
<ul>
<li><strong>Authors: </strong>Qianru Zhang, Honggang Wen, Ming Li, Dong Huang, Siu-Ming Yiu, Christian S. Jensen, Pietro Liò</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.16001">https://arxiv.org/abs/2506.16001</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.16001">https://arxiv.org/pdf/2506.16001</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.16001]] AutoHFormer: Efficient Hierarchical Autoregressive Transformer for Time Series Prediction(https://arxiv.org/abs/2506.16001)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Time series forecasting requires architectures that simultaneously achieve three competing objectives: (1) strict temporal causality for reliable predictions, (2) sub-quadratic complexity for practical scalability, and (3) multi-scale pattern recognition for accurate long-horizon forecasting. We introduce AutoHFormer, a hierarchical autoregressive transformer that addresses these challenges through three key innovations: 1) Hierarchical Temporal Modeling: Our architecture decomposes predictions into segment-level blocks processed in parallel, followed by intra-segment sequential refinement. This dual-scale approach maintains temporal coherence while enabling efficient computation. 2) Dynamic Windowed Attention: The attention mechanism employs learnable causal windows with exponential decay, reducing complexity while preserving precise temporal relationships. This design avoids both the anti-causal violations of standard transformers and the sequential bottlenecks of RNN hybrids. 3) Adaptive Temporal Encoding: a novel position encoding system is adopted to capture time patterns at multiple scales. It combines fixed oscillating patterns for short-term variations with learnable decay rates for long-term trends. Comprehensive experiments demonstrate that AutoHFormer 10.76X faster training and 6.06X memory reduction compared to PatchTST on PEMS08, while maintaining consistent accuracy across 96-720 step horizons in most of cases. These breakthroughs establish new benchmarks for efficient and precise time series modeling. Implementations of our method and all baselines in hierarchical autoregressive mechanism are available at this https URL.</li>
</ul>

<h3>Title: DIGMAPPER: A Modular System for Automated Geologic Map Digitization</h3>
<ul>
<li><strong>Authors: </strong>Weiwei Duan, Michael P. Gerlek, Steven N. Minton, Craig A. Knoblock, Fandel Lin, Theresa Chen, Leeje Jang, Sofia Kirsanova, Zekun Li, Yijun Lin, Yao-Yi Chiang</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.16006">https://arxiv.org/abs/2506.16006</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.16006">https://arxiv.org/pdf/2506.16006</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.16006]] DIGMAPPER: A Modular System for Automated Geologic Map Digitization(https://arxiv.org/abs/2506.16006)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, extraction, transformer, large language model</a></li>
<li><strong>Abstract: </strong>Historical geologic maps contain rich geospatial information, such as rock units, faults, folds, and bedding planes, that is critical for assessing mineral resources essential to renewable energy, electric vehicles, and national security. However, digitizing maps remains a labor-intensive and time-consuming task. We present DIGMAPPER, a modular, scalable system developed in collaboration with the United States Geological Survey (USGS) to automate the digitization of geologic maps. DIGMAPPER features a fully dockerized, workflow-orchestrated architecture that integrates state-of-the-art deep learning models for map layout analysis, feature extraction, and georeferencing. To overcome challenges such as limited training data and complex visual content, our system employs innovative techniques, including in-context learning with large language models, synthetic data generation, and transformer-based models. Evaluations on over 100 annotated maps from the DARPA-USGS dataset demonstrate high accuracy across polygon, line, and point feature extraction, and reliable georeferencing performance. Deployed at USGS, DIGMAPPER significantly accelerates the creation of analysis-ready geospatial datasets, supporting national-scale critical mineral assessments and broader geoscientific applications.</li>
</ul>

<h3>Title: VRAIL: Vectorized Reward-based Attribution for Interpretable Learning</h3>
<ul>
<li><strong>Authors: </strong>Jina Kim, Youjin Jang, Jeongjin Han</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.16014">https://arxiv.org/abs/2506.16014</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.16014">https://arxiv.org/pdf/2506.16014</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.16014]] VRAIL: Vectorized Reward-based Attribution for Interpretable Learning(https://arxiv.org/abs/2506.16014)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability</a></li>
<li><strong>Abstract: </strong>We propose VRAIL (Vectorized Reward-based Attribution for Interpretable Learning), a bi-level framework for value-based reinforcement learning (RL) that learns interpretable weight representations from state features. VRAIL consists of two stages: a deep learning (DL) stage that fits an estimated value function using state features, and an RL stage that uses this to shape learning via potential-based reward transformations. The estimator is modeled in either linear or quadratic form, allowing attribution of importance to individual features and their interactions. Empirical results on the Taxi-v3 environment demonstrate that VRAIL improves training stability and convergence compared to standard DQN, without requiring environment modifications. Further analysis shows that VRAIL uncovers semantically meaningful subgoals, such as passenger possession, highlighting its ability to produce human-interpretable behavior. Our findings suggest that VRAIL serves as a general, model-agnostic framework for reward shaping that enhances both learning and interpretability.</li>
</ul>

<h3>Title: Efficient Blockchain-based Steganography via Backcalculating Generative Adversarial Network</h3>
<ul>
<li><strong>Authors: </strong>Zhuo Chen, Jialing He, Jiacheng Wang, Zehui Xiong, Tao Xiang, Liehuang Zhu, Dusit Niyato</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.16023">https://arxiv.org/abs/2506.16023</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.16023">https://arxiv.org/pdf/2506.16023</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.16023]] Efficient Blockchain-based Steganography via Backcalculating Generative Adversarial Network(https://arxiv.org/abs/2506.16023)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>Blockchain-based steganography enables data hiding via encoding the covert data into a specific blockchain transaction field. However, previous works focus on the specific field-embedding methods while lacking a consideration on required field-generation embedding. In this paper, we propose a generic blockchain-based steganography framework (GBSF). The sender generates the required fields such as amount and fees, where the additional covert data is embedded to enhance the channel capacity. Based on GBSF, we design a reversible generative adversarial network (R-GAN) that utilizes the generative adversarial network with a reversible generator to generate the required fields and encode additional covert data into the input noise of the reversible generator. We then explore the performance flaw of R-GAN. To further improve the performance, we propose R-GAN with Counter-intuitive data preprocessing and Custom activation functions, namely CCR-GAN. The counter-intuitive data preprocessing (CIDP) mechanism is used to reduce decoding errors in covert data, while it incurs gradient explosion for model convergence. The custom activation function named ClipSigmoid is devised to overcome the problem. Theoretical justification for CIDP and ClipSigmoid is also provided. We also develop a mechanism named T2C, which balances capacity and concealment. We conduct experiments using the transaction amount of the Bitcoin mainnet as the required field to verify the feasibility. We then apply the proposed schemes to other transaction fields and blockchains to demonstrate the scalability. Finally, we evaluate capacity and concealment for various blockchains and transaction fields and explore the trade-off between capacity and concealment. The results demonstrate that R-GAN and CCR-GAN are able to enhance the channel capacity effectively and outperform state-of-the-art works.</li>
</ul>

<h3>Title: From General to Targeted Rewards: Surpassing GPT-4 in Open-Ended Long-Context Generation</h3>
<ul>
<li><strong>Authors: </strong>Zhihan Guo, Jiele Wu, Wenqian Cui, Yifei Zhang, Minda Hu, Yufei Wang, Irwin King</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.16024">https://arxiv.org/abs/2506.16024</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.16024">https://arxiv.org/pdf/2506.16024</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.16024]] From General to Targeted Rewards: Surpassing GPT-4 in Open-Ended Long-Context Generation(https://arxiv.org/abs/2506.16024)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Current research on long-form context in Large Language Models (LLMs) primarily focuses on the understanding of long-contexts, the Open-ended Long Text Generation (Open-LTG) remains insufficiently explored. Training a long-context generation model requires curation of gold standard reference data, which is typically nonexistent for informative Open-LTG tasks. However, previous methods only utilize general assessments as reward signals, which limits accuracy. To bridge this gap, we introduce ProxyReward, an innovative reinforcement learning (RL) based framework, which includes a dataset and a reward signal computation method. Firstly, ProxyReward Dataset generation is accomplished through simple prompts that enables the model to create automatically, obviating extensive labeled data or significant manual effort. Secondly, ProxyReward Signal offers a targeted evaluation of information comprehensiveness and accuracy for specific questions. The experimental results indicate that our method ProxyReward surpasses even GPT-4-Turbo. It can significantly enhance performance by 20% on the Open-LTG task when training widely used open-source models, while also surpassing the LLM-as-a-Judge approach. Our work presents effective methods to enhance the ability of LLMs to address complex open-ended questions posed by human.</li>
</ul>

<h3>Title: Enhancing Document-Level Question Answering via Multi-Hop Retrieval-Augmented Generation with LLaMA 3</h3>
<ul>
<li><strong>Authors: </strong>Xinyue Huang, Ziqi Lin, Fang Sun, Wenchao Zhang, Kejian Tong, Yunbo Liu</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.16037">https://arxiv.org/abs/2506.16037</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.16037">https://arxiv.org/pdf/2506.16037</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.16037]] Enhancing Document-Level Question Answering via Multi-Hop Retrieval-Augmented Generation with LLaMA 3(https://arxiv.org/abs/2506.16037)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, generative</a></li>
<li><strong>Abstract: </strong>This paper presents a novel Retrieval-Augmented Generation (RAG) framework tailored for complex question answering tasks, addressing challenges in multi-hop reasoning and contextual understanding across lengthy documents. Built upon LLaMA 3, the framework integrates a dense retrieval module with advanced context fusion and multi-hop reasoning mechanisms, enabling more accurate and coherent response generation. A joint optimization strategy combining retrieval likelihood and generation cross-entropy improves the model's robustness and adaptability. Experimental results show that the proposed system outperforms existing retrieval-augmented and generative baselines, confirming its effectiveness in delivering precise, contextually grounded answers.</li>
</ul>

<h3>Title: DynScaling: Efficient Verifier-free Inference Scaling via Dynamic and Integrated Sampling</h3>
<ul>
<li><strong>Authors: </strong>Fei Wang, Xingchen Wan, Ruoxi Sun, Jiefeng Chen, Sercan Ö. Arık</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.16043">https://arxiv.org/abs/2506.16043</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.16043">https://arxiv.org/pdf/2506.16043</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.16043]] DynScaling: Efficient Verifier-free Inference Scaling via Dynamic and Integrated Sampling(https://arxiv.org/abs/2506.16043)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Inference-time scaling has proven effective in boosting large language model (LLM) performance through increased test-time computation. Yet, its practical application is often hindered by reliance on external verifiers or a lack of optimization for realistic computational constraints. We propose DynScaling, which addresses these limitations through two primary innovations: an integrated parallel-sequential sampling strategy and a bandit-based dynamic budget allocation framework. The integrated sampling strategy unifies parallel and sequential sampling by constructing synthetic sequential reasoning chains from initially independent parallel responses, promoting diverse and coherent reasoning trajectories. The dynamic budget allocation framework formulates the allocation of computational resources as a multi-armed bandit problem, adaptively distributing the inference budget across queries based on the uncertainty of previously sampled responses, thereby maximizing computational efficiency. By combining these components, DynScaling effectively improves LLM performance under practical resource constraints without the need for external verifiers. Experimental results demonstrate that DynScaling consistently surpasses existing verifier-free inference scaling baselines in both task performance and computational cost.</li>
</ul>

<h3>Title: A Hybrid DeBERTa and Gated Broad Learning System for Cyberbullying Detection in English Text</h3>
<ul>
<li><strong>Authors: </strong>Devesh Kumar</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.16052">https://arxiv.org/abs/2506.16052</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.16052">https://arxiv.org/pdf/2506.16052</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.16052]] A Hybrid DeBERTa and Gated Broad Learning System for Cyberbullying Detection in English Text(https://arxiv.org/abs/2506.16052)</code><input type="text"></li>
<li><strong>Keywords: </strong>explainability, transformer</a></li>
<li><strong>Abstract: </strong>The proliferation of online communication platforms has created unprecedented opportunities for global connectivity while simultaneously enabling harmful behaviors such as cyberbullying, which affects approximately 54.4\% of teenagers according to recent research. This paper presents a hybrid architecture that combines the contextual understanding capabilities of transformer-based models with the pattern recognition strengths of broad learning systems for effective cyberbullying detection. This approach integrates a modified DeBERTa model augmented with Squeeze-and-Excitation blocks and sentiment analysis capabilities with a Gated Broad Learning System (GBLS) classifier, creating a synergistic framework that outperforms existing approaches across multiple benchmark datasets. The proposed ModifiedDeBERTa + GBLS model achieved good performance on four English datasets: 79.3\% accuracy on HateXplain, 95.41\% accuracy on SOSNet, 91.37\% accuracy on Mendeley-I, and 94.67\% accuracy on Mendeley-II. Beyond performance gains, the framework incorporates comprehensive explainability mechanisms including token-level attribution analysis, LIME-based local interpretations, and confidence calibration, addressing critical transparency requirements in automated content moderation. Ablation studies confirm the meaningful contribution of each architectural component, while failure case analysis reveals specific challenges in detecting implicit bias and sarcastic content, providing valuable insights for future improvements in cyberbullying detection systems.</li>
</ul>

<h3>Title: PAROAttention: Pattern-Aware ReOrdering for Efficient Sparse and Quantized Attention in Visual Generation Models</h3>
<ul>
<li><strong>Authors: </strong>Tianchen Zhao, Ke Hong, Xinhao Yang, Xuefeng Xiao, Huixia Li, Feng Ling, Ruiqi Xie, Siqi Chen, Hongyu Zhu, Yichong Zhang, Yu Wang</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.16054">https://arxiv.org/abs/2506.16054</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.16054">https://arxiv.org/pdf/2506.16054</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.16054]] PAROAttention: Pattern-Aware ReOrdering for Efficient Sparse and Quantized Attention in Visual Generation Models(https://arxiv.org/abs/2506.16054)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction</a></li>
<li><strong>Abstract: </strong>In visual generation, the quadratic complexity of attention mechanisms results in high memory and computational costs, especially for longer token sequences required in high-resolution image or multi-frame video generation. To address this, prior research has explored techniques such as sparsification and quantization. However, these techniques face significant challenges under low density and reduced bitwidths. Through systematic analysis, we identify that the core difficulty stems from the dispersed and irregular characteristics of visual attention patterns. Therefore, instead of introducing specialized sparsification and quantization design to accommodate such patterns, we propose an alternative strategy: *reorganizing* the attention pattern to alleviate the challenges. Inspired by the local aggregation nature of visual feature extraction, we design a novel **Pattern-Aware token ReOrdering (PARO)** technique, which unifies the diverse attention patterns into a hardware-friendly block-wise pattern. This unification substantially simplifies and enhances both sparsification and quantization. We evaluate the performance-efficiency trade-offs of various design choices and finalize a methodology tailored for the unified pattern. Our approach, **PAROAttention**, achieves video and image generation with lossless metrics, and nearly identical results from full-precision (FP) baselines, while operating at notably lower density (~20%-30%) and bitwidth (**INT8/INT4**), achieving a **1.9x** to **2.7x** end-to-end latency speedup.</li>
</ul>

<h3>Title: Knee-Deep in C-RASP: A Transformer Depth Hierarchy</h3>
<ul>
<li><strong>Authors: </strong>Andy Yang, Michaël Cadilhac, David Chiang</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.FL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.16055">https://arxiv.org/abs/2506.16055</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.16055">https://arxiv.org/pdf/2506.16055</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.16055]] Knee-Deep in C-RASP: A Transformer Depth Hierarchy(https://arxiv.org/abs/2506.16055)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>It has been observed that transformers with greater depth (that is, more layers) have more capabilities, but can we establish formally which capabilities are gained with greater depth? We answer this question with a theoretical proof followed by an empirical study. First, we consider transformers that round to fixed precision except inside attention. We show that this subclass of transformers is expressively equivalent to the programming language C-RASP and this equivalence preserves depth. Second, we prove that deeper C-RASP programs are more expressive than shallower C-RASP programs, implying that deeper transformers are more expressive than shallower transformers (within the subclass mentioned above). These results are established by studying a form of temporal logic with counting operators, which was shown equivalent to C-RASP in previous work. Finally, we provide empirical evidence that our theory predicts the depth required for transformers without positional encodings to length-generalize on a family of sequential dependency tasks.</li>
</ul>

<h3>Title: Stepping Out of Similar Semantic Space for Open-Vocabulary Segmentation</h3>
<ul>
<li><strong>Authors: </strong>Yong Liu, SongLi Wu, Sule Bai, Jiahao Wang, Yitong Wang, Yansong Tang</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.16058">https://arxiv.org/abs/2506.16058</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.16058">https://arxiv.org/pdf/2506.16058</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.16058]] Stepping Out of Similar Semantic Space for Open-Vocabulary Segmentation(https://arxiv.org/abs/2506.16058)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>Open-vocabulary segmentation aims to achieve segmentation of arbitrary categories given unlimited text inputs as guidance. To achieve this, recent works have focused on developing various technical routes to exploit the potential of large-scale pre-trained vision-language models and have made significant progress on existing benchmarks. However, we find that existing test sets are limited in measuring the models' comprehension of ``open-vocabulary" concepts, as their semantic space closely resembles the training space, even with many overlapping categories. To this end, we present a new benchmark named OpenBench that differs significantly from the training semantics. It is designed to better assess the model's ability to understand and segment a wide range of real-world concepts. When testing existing methods on OpenBench, we find that their performance diverges from the conclusions drawn on existing test sets. In addition, we propose a method named OVSNet to improve the segmentation performance for diverse and open scenarios. Through elaborate fusion of heterogeneous features and cost-free expansion of the training space, OVSNet achieves state-of-the-art results on both existing datasets and our proposed OpenBench. Corresponding analysis demonstrate the soundness and effectiveness of our proposed benchmark and method.</li>
</ul>

<h3>Title: STAR-Pose: Efficient Low-Resolution Video Human Pose Estimation via Spatial-Temporal Adaptive Super-Resolution</h3>
<ul>
<li><strong>Authors: </strong>Yucheng Jin, Jinyan Chen, Ziyue He, Baojun Han, Furan An</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.16061">https://arxiv.org/abs/2506.16061</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.16061">https://arxiv.org/pdf/2506.16061</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.16061]] STAR-Pose: Efficient Low-Resolution Video Human Pose Estimation via Spatial-Temporal Adaptive Super-Resolution(https://arxiv.org/abs/2506.16061)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Human pose estimation in low-resolution videos presents a fundamental challenge in computer vision. Conventional methods either assume high-quality inputs or employ computationally expensive cascaded processing, which limits their deployment in resource-constrained environments. We propose STAR-Pose, a spatial-temporal adaptive super-resolution framework specifically designed for video-based human pose estimation. Our method features a novel spatial-temporal Transformer with LeakyReLU-modified linear attention, which efficiently captures long-range temporal dependencies. Moreover, it is complemented by an adaptive fusion module that integrates parallel CNN branch for local texture enhancement. We also design a pose-aware compound loss to achieve task-oriented super-resolution. This loss guides the network to reconstruct structural features that are most beneficial for keypoint localization, rather than optimizing purely for visual quality. Extensive experiments on several mainstream video HPE datasets demonstrate that STAR-Pose outperforms existing approaches. It achieves up to 5.2% mAP improvement under extremely low-resolution (64x48) conditions while delivering 2.8x to 4.4x faster inference than cascaded approaches.</li>
</ul>

<h3>Title: Self-Critique-Guided Curiosity Refinement: Enhancing Honesty and Helpfulness in Large Language Models via In-Context Learning</h3>
<ul>
<li><strong>Authors: </strong>Duc Hieu Ho, Chenglin Fan</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.16064">https://arxiv.org/abs/2506.16064</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.16064">https://arxiv.org/pdf/2506.16064</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.16064]] Self-Critique-Guided Curiosity Refinement: Enhancing Honesty and Helpfulness in Large Language Models via In-Context Learning(https://arxiv.org/abs/2506.16064)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, large language model</a></li>
<li><strong>Abstract: </strong>Large language models (LLMs) have demonstrated robust capabilities across various natural language tasks. However, producing outputs that are consistently honest and helpful remains an open challenge. To overcome this challenge, this paper tackles the problem through two complementary directions. It conducts a comprehensive benchmark evaluation of ten widely used large language models, including both proprietary and open-weight models from OpenAI, Meta, and Google. In parallel, it proposes a novel prompting strategy, self-critique-guided curiosity refinement prompting. The key idea behind this strategy is enabling models to self-critique and refine their responses without additional training. The proposed method extends the curiosity-driven prompting strategy by incorporating two lightweight in-context steps including self-critique step and refinement step. The experiment results on the HONESET dataset evaluated using the framework $\mathrm{H}^2$ (honesty and helpfulness), which was executed with GPT-4o as a judge of honesty and helpfulness, show consistent improvements across all models. The approach reduces the number of poor-quality responses, increases high-quality responses, and achieves relative gains in $\mathrm{H}^2$ scores ranging from 1.4% to 4.3% compared to curiosity-driven prompting across evaluated models. These results highlight the effectiveness of structured self-refinement as a scalable and training-free strategy to improve the trustworthiness of LLMs outputs.</li>
</ul>

<h3>Title: Floating-Point Neural Networks Are Provably Robust Universal Approximators</h3>
<ul>
<li><strong>Authors: </strong>Geonho Hwang, Wonyeol Lee, Yeachan Park, Sejun Park, Feras Saad</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.LO, cs.PL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.16065">https://arxiv.org/abs/2506.16065</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.16065">https://arxiv.org/pdf/2506.16065</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.16065]] Floating-Point Neural Networks Are Provably Robust Universal Approximators(https://arxiv.org/abs/2506.16065)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>The classical universal approximation (UA) theorem for neural networks establishes mild conditions under which a feedforward neural network can approximate a continuous function $f$ with arbitrary accuracy. A recent result shows that neural networks also enjoy a more general interval universal approximation (IUA) theorem, in the sense that the abstract interpretation semantics of the network using the interval domain can approximate the direct image map of $f$ (i.e., the result of applying $f$ to a set of inputs) with arbitrary accuracy. These theorems, however, rest on the unrealistic assumption that the neural network computes over infinitely precise real numbers, whereas their software implementations in practice compute over finite-precision floating-point numbers. An open question is whether the IUA theorem still holds in the floating-point setting. This paper introduces the first IUA theorem for floating-point neural networks that proves their remarkable ability to perfectly capture the direct image map of any rounded target function $f$, showing no limits exist on their expressiveness. Our IUA theorem in the floating-point setting exhibits material differences from the real-valued setting, which reflects the fundamental distinctions between these two computational models. This theorem also implies surprising corollaries, which include (i) the existence of provably robust floating-point neural networks; and (ii) the computational completeness of the class of straight-line programs that use only floating-point additions and multiplications for the class of all floating-point programs that halt.</li>
</ul>

<h3>Title: Cyberbullying Detection in Hinglish Text Using MURIL and Explainable AI</h3>
<ul>
<li><strong>Authors: </strong>Devesh Kumar</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.16066">https://arxiv.org/abs/2506.16066</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.16066">https://arxiv.org/pdf/2506.16066</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.16066]] Cyberbullying Detection in Hinglish Text Using MURIL and Explainable AI(https://arxiv.org/abs/2506.16066)</code><input type="text"></li>
<li><strong>Keywords: </strong>protect, explainability</a></li>
<li><strong>Abstract: </strong>The growth of digital communication platforms has led to increased cyberbullying incidents worldwide, creating a need for automated detection systems to protect users. The rise of code-mixed Hindi-English (Hinglish) communication on digital platforms poses challenges for existing cyberbullying detection systems, which were designed primarily for monolingual text. This paper presents a framework for cyberbullying detection in Hinglish text using the Multilingual Representations for Indian Languages (MURIL) architecture to address limitations in current approaches. Evaluation across six benchmark datasets -- Bohra \textit{et al.}, BullyExplain, BullySentemo, Kumar \textit{et al.}, HASOC 2021, and Mendeley Indo-HateSpeech -- shows that the MURIL-based approach outperforms existing multilingual models including RoBERTa and IndicBERT, with improvements of 1.36 to 13.07 percentage points and accuracies of 86.97\% on Bohra, 84.62\% on BullyExplain, 86.03\% on BullySentemo, 75.41\% on Kumar datasets, 83.92\% on HASOC 2021, and 94.63\% on Mendeley dataset. The framework includes explainability features through attribution analysis and cross-linguistic pattern recognition. Ablation studies show that selective layer freezing, appropriate classification head design, and specialized preprocessing for code-mixed content improve detection performance, while failure analysis identifies challenges including context-dependent interpretation, cultural understanding, and cross-linguistic sarcasm detection, providing directions for future research in multilingual cyberbullying detection.</li>
</ul>

<h3>Title: A Lightweight RL-Driven Deep Unfolding Network for Robust WMMSE Precoding in Massive MU-MIMO-OFDM Systems</h3>
<ul>
<li><strong>Authors: </strong>Kexuan Wang, An Liu</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.16072">https://arxiv.org/abs/2506.16072</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.16072">https://arxiv.org/pdf/2506.16072</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.16072]] A Lightweight RL-Driven Deep Unfolding Network for Robust WMMSE Precoding in Massive MU-MIMO-OFDM Systems(https://arxiv.org/abs/2506.16072)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Weighted Minimum Mean Square Error (WMMSE) precoding is widely recognized for its near-optimal weighted sum rate performance. However, its practical deployment in massive multi-user (MU) multiple-input multiple-output (MIMO) orthogonal frequency-division multiplexing (OFDM) systems is hindered by the assumption of perfect channel state information (CSI) and high computational complexity. To address these issues, we first develop a wideband stochastic WMMSE (SWMMSE) algorithm that iteratively maximizes the ergodic weighted sum-rate (EWSR) under imperfect CSI. Building on this, we propose a lightweight reinforcement learning (RL)-driven deep unfolding (DU) network (RLDDU-Net), where each SWMMSE iteration is mapped to a network layer. Specifically, its DU module integrates approximation techniques and leverages beam-domain sparsity as well as frequency-domain subcarrier correlation, significantly accelerating convergence and reducing computational overhead. Furthermore, the RL module adaptively adjusts the network depth and generates compensation matrices to mitigate approximation errors. Simulation results under imperfect CSI demonstrate that RLDDU-Net outperforms existing baselines in EWSR performance while offering superior computational and convergence efficiency.</li>
</ul>

<h3>Title: Probing the Robustness of Large Language Models Safety to Latent Perturbations</h3>
<ul>
<li><strong>Authors: </strong>Tianle Gu, Kexin Huang, Zongqi Wang, Yixu Wang, Jie Li, Yuanqi Yao, Yang Yao, Yujiu Yang, Yan Teng, Yingchun Wang</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CL, cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.16078">https://arxiv.org/abs/2506.16078</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.16078">https://arxiv.org/pdf/2506.16078</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.16078]] Probing the Robustness of Large Language Models Safety to Latent Perturbations(https://arxiv.org/abs/2506.16078)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack, robust, large language model</a></li>
<li><strong>Abstract: </strong>Safety alignment is a key requirement for building reliable Artificial General Intelligence. Despite significant advances in safety alignment, we observe that minor latent shifts can still trigger unsafe responses in aligned models. We argue that this stems from the shallow nature of existing alignment methods, which focus on surface-level refusal behaviors without sufficiently altering internal representations. Consequently, small shifts in hidden activations can re-trigger harmful behaviors embedded in the latent space. To explore the robustness of safety alignment to latent perturbations, we introduce a probing method that measures the Negative Log-Likelihood of the original response generated by the model. This probe quantifies local sensitivity in the latent space, serving as a diagnostic tool for identifying vulnerable directions. Based on this signal, we construct effective jailbreak trajectories, giving rise to the Activation Steering Attack (ASA). More importantly, these insights offer a principled foundation for improving alignment robustness. To this end, we introduce Layer-wise Adversarial Patch Training~(LAPT), a fine-tuning strategy that inject controlled perturbations into hidden representations during training. Experimental results highlight that LAPT strengthen alignment robustness without compromising general capabilities. Our findings reveal fundamental flaws in current alignment paradigms and call for representation-level training strategies that move beyond surface-level behavior supervision. Codes and results are available at this https URL.</li>
</ul>

<h3>Title: PR-DETR: Injecting Position and Relation Prior for Dense Video Captioning</h3>
<ul>
<li><strong>Authors: </strong>Yizhe Li, Sanping Zhou, Zheng Qin, Le Wang</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.16082">https://arxiv.org/abs/2506.16082</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.16082">https://arxiv.org/pdf/2506.16082</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.16082]] PR-DETR: Injecting Position and Relation Prior for Dense Video Captioning(https://arxiv.org/abs/2506.16082)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Dense video captioning is a challenging task that aims to localize and caption multiple events in an untrimmed video. Recent studies mainly follow the transformer-based architecture to jointly perform the two sub-tasks, i.e., event localization and caption generation, in an end-to-end manner. Based on the general philosophy of detection transformer, these methods implicitly learn the event locations and event semantics, which requires a large amount of training data and limits the model's performance in practice. In this paper, we propose a novel dense video captioning framework, named PR-DETR, which injects the explicit position and relation prior into the detection transformer to improve the localization accuracy and caption quality, simultaneously. On the one hand, we first generate a set of position-anchored queries to provide the scene-specific position and semantic information about potential events as position prior, which serves as the initial event search regions to eliminate the implausible event proposals. On the other hand, we further design an event relation encoder to explicitly calculate the relationship between event boundaries as relation prior to guide the event interaction to improve the semantic coherence of the captions. Extensive ablation studies are conducted to verify the effectiveness of the position and relation prior. Experimental results also show the competitive performance of our method on ActivityNet Captions and YouCook2 datasets.</li>
</ul>

<h3>Title: A Brain-to-Population Graph Learning Framework for Diagnosing Brain Disorders</h3>
<ul>
<li><strong>Authors: </strong>Qianqian Liao, Wuque Cai, Hongze Sun, Dongze Liu, Duo Chen, Dezhong Yao, Daqing Guo</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.16096">https://arxiv.org/abs/2506.16096</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.16096">https://arxiv.org/pdf/2506.16096</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.16096]] A Brain-to-Population Graph Learning Framework for Diagnosing Brain Disorders(https://arxiv.org/abs/2506.16096)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability</a></li>
<li><strong>Abstract: </strong>Recent developed graph-based methods for diagnosing brain disorders using functional connectivity highly rely on predefined brain atlases, but overlook the rich information embedded within atlases and the confounding effects of site and phenotype variability. To address these challenges, we propose a two-stage Brain-to-Population Graph Learning (B2P-GL) framework that integrates the semantic similarity of brain regions and condition-based population graph modeling. In the first stage, termed brain representation learning, we leverage brain atlas knowledge from GPT-4 to enrich the graph representation and refine the brain graph through an adaptive node reassignment graph attention network. In the second stage, termed population disorder diagnosis, phenotypic data is incorporated into population graph construction and feature fusion to mitigate confounding effects and enhance diagnosis performance. Experiments on the ABIDE I, ADHD-200, and Rest-meta-MDD datasets show that B2P-GL outperforms state-of-the-art methods in prediction accuracy while enhancing interpretability. Overall, our proposed framework offers a reliable and personalized approach to brain disorder diagnosis, advancing clinical applicability.</li>
</ul>

<h3>Title: AutoV: Learning to Retrieve Visual Prompt for Large Vision-Language Models</h3>
<ul>
<li><strong>Authors: </strong>Yuan Zhang, Chun-Kai Fan, Tao Huang, Ming Lu, Sicheng Yu, Junwen Pan, Kuan Cheng, Qi She, Shanghang Zhang</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.16112">https://arxiv.org/abs/2506.16112</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.16112">https://arxiv.org/pdf/2506.16112</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.16112]] AutoV: Learning to Retrieve Visual Prompt for Large Vision-Language Models(https://arxiv.org/abs/2506.16112)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Inspired by text prompts in large language models (LLMs), visual prompts have been explored to enhance the reasoning capabilities of large vision-language models (LVLMs). Current methods design heuristic visual prompts, such as overlaying a text-query-guided attention heatmap on the original input image. However, designing effective prompts manually is challenging and time-consuming, and it often fails to explore the benefits of different visual prompts, leading to sub-optimal performance. To this end, we propose \textbf{AutoV} that learns to automatically select the optimal visual prompt from various candidates based on given textual queries and the input image. To train AutoV, we developed an automatic data collection and labeling pipeline that evaluates various visual prompts with a pre-trained LVLM. We input a set of visual prompts into the LVLM and rank them according to the prediction losses generated by the model. Using the ranking as a supervision signal, we train AutoV to automatically choose the optimal visual prompt from various visual prompts for LVLMs. Experimental results indicate that AutoV enhances the performance of various LVLMs across multiple popular image understanding tasks. For instance, LLaVA-OV with AutoV achieves $\textbf{1.7}\%$ accuracy gain on LLaVA$^{\text{Wild}}$, and AutoV boosts Qwen2.5-VL by $\textbf{1.9}\%$ on MMMU, highlighting its potential as an optimal visual prompting method for LVLMs.</li>
</ul>

<h3>Title: FastInit: Fast Noise Initialization for Temporally Consistent Video Generation</h3>
<ul>
<li><strong>Authors: </strong>Chengyu Bai, Yuming Li, Zhongyu Zhao, Jintao Chen, Peidong Jia, Qi She, Ming Lu, Shanghang Zhang</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.16119">https://arxiv.org/abs/2506.16119</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.16119">https://arxiv.org/pdf/2506.16119</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.16119]] FastInit: Fast Noise Initialization for Temporally Consistent Video Generation(https://arxiv.org/abs/2506.16119)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>Video generation has made significant strides with the development of diffusion models; however, achieving high temporal consistency remains a challenging task. Recently, FreeInit identified a training-inference gap and introduced a method to iteratively refine the initial noise during inference. However, iterative refinement significantly increases the computational cost associated with video generation. In this paper, we introduce FastInit, a fast noise initialization method that eliminates the need for iterative refinement. FastInit learns a Video Noise Prediction Network (VNPNet) that takes random noise and a text prompt as input, generating refined noise in a single forward pass. Therefore, FastInit greatly enhances the efficiency of video generation while achieving high temporal consistency across frames. To train the VNPNet, we create a large-scale dataset consisting of pairs of text prompts, random noise, and refined noise. Extensive experiments with various text-to-video models show that our method consistently improves the quality and temporal consistency of the generated videos. FastInit not only provides a substantial improvement in video generation but also offers a practical solution that can be applied directly during inference. The code and dataset will be released.</li>
</ul>

<h3>Title: FinCoT: Grounding Chain-of-Thought in Expert Financial Reasoning</h3>
<ul>
<li><strong>Authors: </strong>Natapong Nitarach, Warit Sirichotedumrong, Panop Pitchayarthorn, Pittawat Taveekitworachai, Potsawee Manakul, Kunat Pipatanakul</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.16123">https://arxiv.org/abs/2506.16123</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.16123">https://arxiv.org/pdf/2506.16123</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.16123]] FinCoT: Grounding Chain-of-Thought in Expert Financial Reasoning(https://arxiv.org/abs/2506.16123)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>This paper presents FinCoT, a structured chain-of-thought (CoT) prompting approach that incorporates insights from domain-specific expert financial reasoning to guide the reasoning traces of large language models. We investigate that there are three main prompting styles in FinNLP: (1) standard prompting--zero-shot prompting; (2) unstructured CoT--CoT prompting without an explicit reasoning structure, such as the use of tags; and (3) structured CoT prompting--CoT prompting with explicit instructions or examples that define structured reasoning steps. Previously, FinNLP has primarily focused on prompt engineering with either standard or unstructured CoT prompting. However, structured CoT prompting has received limited attention in prior work. Furthermore, the design of reasoning structures in structured CoT prompting is often based on heuristics from non-domain experts. In this study, we investigate each prompting approach in FinNLP. We evaluate the three main prompting styles and FinCoT on CFA-style questions spanning ten financial domains. We observe that FinCoT improves performance from 63.2% to 80.5% and Qwen-2.5-7B-Instruct from 69.7% to 74.2%, while reducing generated tokens eight-fold compared to structured CoT prompting. Our findings show that domain-aligned structured prompts not only improve performance and reduce inference costs but also yield more interpretable and expert-aligned reasoning traces.</li>
</ul>

<h3>Title: GRPO-CARE: Consistency-Aware Reinforcement Learning for Multimodal Reasoning</h3>
<ul>
<li><strong>Authors: </strong>Yi Chen, Yuying Ge, Rui Wang, Yixiao Ge, Junhao Cheng, Ying Shan, Xihui Liu</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI, cs.CL, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.16141">https://arxiv.org/abs/2506.16141</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.16141">https://arxiv.org/pdf/2506.16141</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.16141]] GRPO-CARE: Consistency-Aware Reinforcement Learning for Multimodal Reasoning(https://arxiv.org/abs/2506.16141)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, large language model</a></li>
<li><strong>Abstract: </strong>Recent reinforcement learning approaches, such as outcome-supervised GRPO, have advanced Chain-of-Thought reasoning in large language models (LLMs), yet their adaptation to multimodal LLMs (MLLMs) is unexplored. To address the lack of rigorous evaluation for MLLM post-training methods, we introduce SEED-Bench-R1, a benchmark with complex real-world videos requiring balanced perception and reasoning. It offers a large training set and evaluates generalization across three escalating challenges: in-distribution, cross-environment, and cross-environment-task scenarios. Using SEED-Bench-R1, we find that standard GRPO, while improving answer accuracy, often reduces logical coherence between reasoning steps and answers, with only a 57.9% consistency rate. This stems from reward signals focusing solely on final answers, encouraging shortcuts, and strict KL penalties limiting this http URL address this, we propose GRPO-CARE, a consistency-aware RL framework optimizing both answer correctness and reasoning coherence without explicit supervision. GRPO-CARE introduces a two-tiered reward: (1) a base reward for answer correctness, and (2) an adaptive consistency bonus, computed by comparing the model's reasoning-to-answer likelihood (via a slowly-evolving reference model) against group this http URL dual mechanism amplifies rewards for reasoning paths that are both correct and logically consistent. Replacing KL penalties with this adaptive bonus, GRPO-CARE outperforms standard GRPO on SEED-Bench-R1, achieving a 6.7% performance gain on the hardest evaluation level and a 24.5% improvement in consistency. It also shows strong transferability, improving model performance across diverse video understanding benchmarks. Our work contributes a systematically designed benchmark and a generalizable post-training framework, advancing the development of more interpretable and robust MLLMs.</li>
</ul>

<h3>Title: PRISON: Unmasking the Criminal Potential of Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Xinyi Wu, Geng Hong, Pei Chen, Yueyue Chen, Xudong Pan, Min Yang</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.16150">https://arxiv.org/abs/2506.16150</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.16150">https://arxiv.org/pdf/2506.16150</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.16150]] PRISON: Unmasking the Criminal Potential of Large Language Models(https://arxiv.org/abs/2506.16150)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, large language model</a></li>
<li><strong>Abstract: </strong>As large language models (LLMs) advance, concerns about their misconduct in complex social contexts intensify. Existing research overlooked the systematic understanding and assessment of their criminal capability in realistic interactions. We propose a unified framework PRISON, to quantify LLMs' criminal potential across five dimensions: False Statements, Frame-Up, Psychological Manipulation, Emotional Disguise, and Moral Disengagement. Using structured crime scenarios adapted from classic films, we evaluate both criminal potential and anti-crime ability of LLMs via role-play. Results show that state-of-the-art LLMs frequently exhibit emergent criminal tendencies, such as proposing misleading statements or evasion tactics, even without explicit instructions. Moreover, when placed in a detective role, models recognize deceptive behavior with only 41% accuracy on average, revealing a striking mismatch between conducting and detecting criminal behavior. These findings underscore the urgent need for adversarial robustness, behavioral alignment, and safety mechanisms before broader LLM deployment.</li>
</ul>

<h3>Title: Under the Shadow of Babel: How Language Shapes Reasoning in LLMs</h3>
<ul>
<li><strong>Authors: </strong>Chenxi Wang, Yixuan Zhang, Lang Gao, Zixiang Xu, Zirui Song, Yanbo Wang, Xiuying Chen</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.16151">https://arxiv.org/abs/2506.16151</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.16151">https://arxiv.org/pdf/2506.16151</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.16151]] Under the Shadow of Babel: How Language Shapes Reasoning in LLMs(https://arxiv.org/abs/2506.16151)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Language is not only a tool for communication but also a medium for human cognition and reasoning. If, as linguistic relativity suggests, the structure of language shapes cognitive patterns, then large language models (LLMs) trained on human language may also internalize the habitual logical structures embedded in different languages. To examine this hypothesis, we introduce BICAUSE, a structured bilingual dataset for causal reasoning, which includes semantically aligned Chinese and English samples in both forward and reversed causal forms. Our study reveals three key findings: (1) LLMs exhibit typologically aligned attention patterns, focusing more on causes and sentence-initial connectives in Chinese, while showing a more balanced distribution in English. (2) Models internalize language-specific preferences for causal word order and often rigidly apply them to atypical inputs, leading to degraded performance, especially in Chinese. (3) When causal reasoning succeeds, model representations converge toward semantically aligned abstractions across languages, indicating a shared understanding beyond surface form. Overall, these results suggest that LLMs not only mimic surface linguistic forms but also internalize the reasoning biases shaped by language. Rooted in cognitive linguistic theory, this phenomenon is for the first time empirically verified through structural analysis of model internals.</li>
</ul>

<h3>Title: MBA: Multimodal Bidirectional Attack for Referring Expression Segmentation Models</h3>
<ul>
<li><strong>Authors: </strong>Xingbai Chen, Tingchao Fu, Renyang Liu, Wei Zhou, Chao Yi</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.16157">https://arxiv.org/abs/2506.16157</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.16157">https://arxiv.org/pdf/2506.16157</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.16157]] MBA: Multimodal Bidirectional Attack for Referring Expression Segmentation Models(https://arxiv.org/abs/2506.16157)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack, robust, segmentation</a></li>
<li><strong>Abstract: </strong>Referring Expression Segmentation (RES) enables precise object segmentation in images based on natural language descriptions, offering high flexibility and broad applicability in real-world vision tasks. Despite its impressive performance, the robustness of RES models against adversarial examples remains largely unexplored. While prior adversarial attack methods have explored adversarial robustness on conventional segmentation models, they perform poorly when directly applied to RES, failing to expose vulnerabilities in its multimodal structure. Moreover, in practical open-world scenarios, users typically issue multiple, diverse referring expressions to interact with the same image, highlighting the need for adversarial examples that generalize across varied textual inputs. To address these multimodal challenges, we propose a novel adversarial attack strategy termed \textbf{Multimodal Bidirectional Attack}, tailored for RES models. Our method introduces learnable proxy textual embedding perturbation and jointly performs visual-aligned optimization on the image modality and textual-adversarial optimization on the textual modality during attack generation. This dual optimization framework encourages adversarial images to actively adapt to more challenging text embedding during optimization, thereby enhancing their cross-text transferability, which refers to the ability of adversarial examples to remain effective under a variety of unseen or semantically diverse textual inputs. Extensive experiments conducted on multiple RES models and benchmark datasets demonstrate the superior effectiveness of our method compared to existing methods.</li>
</ul>

<h3>Title: Align the GAP: Prior-based Unified Multi-Task Remote Physiological Measurement Framework For Domain Generalization and Personalization</h3>
<ul>
<li><strong>Authors: </strong>Jiyao Wang, Xiao Yang, Hao Lu, Dengbo He, Kaishun Wu</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.16160">https://arxiv.org/abs/2506.16160</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.16160">https://arxiv.org/pdf/2506.16160</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.16160]] Align the GAP: Prior-based Unified Multi-Task Remote Physiological Measurement Framework For Domain Generalization and Personalization(https://arxiv.org/abs/2506.16160)</code><input type="text"></li>
<li><strong>Keywords: </strong>biometric</a></li>
<li><strong>Abstract: </strong>Multi-source synsemantic domain generalization (MSSDG) for multi-task remote physiological measurement seeks to enhance the generalizability of these metrics and attracts increasing attention. However, challenges like partial labeling and environmental noise may disrupt task-specific accuracy. Meanwhile, given that real-time adaptation is necessary for personalized products, the test-time personalized adaptation (TTPA) after MSSDG is also worth exploring, while the gap between previous generalization and personalization methods is significant and hard to fuse. Thus, we proposed a unified framework for MSSD\textbf{G} and TTP\textbf{A} employing \textbf{P}riors (\textbf{GAP}) in biometrics and remote photoplethysmography (rPPG). We first disentangled information from face videos into invariant semantics, individual bias, and noise. Then, multiple modules incorporating priors and our observations were applied in different stages and for different facial information. Then, based on the different principles of achieving generalization and personalization, our framework could simultaneously address MSSDG and TTPA under multi-task remote physiological estimation with minimal adjustments. We expanded the MSSDG benchmark to the TTPA protocol on six publicly available datasets and introduced a new real-world driving dataset with complete labeling. Extensive experiments that validated our approach, and the codes along with the new dataset will be released.</li>
</ul>

<h3>Title: From Teacher to Student: Tracking Memorization Through Model Distillation</h3>
<ul>
<li><strong>Authors: </strong>Simardeep Singh</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.16170">https://arxiv.org/abs/2506.16170</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.16170">https://arxiv.org/pdf/2506.16170</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.16170]] From Teacher to Student: Tracking Memorization Through Model Distillation(https://arxiv.org/abs/2506.16170)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, privacy, large language model</a></li>
<li><strong>Abstract: </strong>Large language models (LLMs) are known to memorize parts of their training data, raising important concerns around privacy and security. While previous research has focused on studying memorization in pre-trained models, much less is known about how knowledge distillation (KD) affects this http URL this study, we explore how different KD methods influence the memorization of fine-tuned task data when a large teacher model is distilled into smaller student this http URL study demonstrates that distilling a larger teacher model, fine-tuned on a dataset, into a smaller variant not only lowers computational costs and model size but also significantly reduces the memorization risks compared to standard fine-tuning approaches.</li>
</ul>

<h3>Title: SGIC: A Self-Guided Iterative Calibration Framework for RAG</h3>
<ul>
<li><strong>Authors: </strong>Guanhua Chen, Yutong Yao, Lidia S. Chao, Xuebo Liu, Derek F. Wong</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.16172">https://arxiv.org/abs/2506.16172</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.16172">https://arxiv.org/pdf/2506.16172</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.16172]] SGIC: A Self-Guided Iterative Calibration Framework for RAG(https://arxiv.org/abs/2506.16172)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, large language model</a></li>
<li><strong>Abstract: </strong>Recent research in retrieval-augmented generation (RAG) has concentrated on retrieving useful information from candidate documents. However, numerous methodologies frequently neglect the calibration capabilities of large language models (LLMs), which capitalize on their robust in-context reasoning prowess. This work illustrates that providing LLMs with specific cues substantially improves their calibration efficacy, especially in multi-round calibrations. We present a new SGIC: Self-Guided Iterative Calibration Framework that employs uncertainty scores as a tool. Initially, this framework calculates uncertainty scores to determine both the relevance of each document to the query and the confidence level in the responses produced by the LLMs. Subsequently, it reevaluates these scores iteratively, amalgamating them with prior responses to refine calibration. Furthermore, we introduce an innovative approach for constructing an iterative self-calibration training set, which optimizes LLMs to efficiently harness uncertainty scores for capturing critical information and enhancing response accuracy. Our proposed framework significantly improves performance on both closed-source and open-weight LLMs.</li>
</ul>

<h3>Title: Hallucination Level of Artificial Intelligence Whisperer: Case Speech Recognizing Pantterinousut Rap Song</h3>
<ul>
<li><strong>Authors: </strong>Ismo Horppu, Frederick Ayala, Erlin Gulbenkoglu</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.16174">https://arxiv.org/abs/2506.16174</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.16174">https://arxiv.org/pdf/2506.16174</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.16174]] Hallucination Level of Artificial Intelligence Whisperer: Case Speech Recognizing Pantterinousut Rap Song(https://arxiv.org/abs/2506.16174)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction</a></li>
<li><strong>Abstract: </strong>All languages are peculiar. Some of them are considered more challenging to understand than others. The Finnish Language is known to be a complex language. Also, when languages are used by artists, the pronunciation and meaning might be more tricky to understand. Therefore, we are putting AI to a fun, yet challenging trial: translating a Finnish rap song to text. We will compare the Faster Whisperer algorithm and YouTube's internal speech-to-text functionality. The reference truth will be Finnish rap lyrics, which the main author's little brother, Mc Timo, has written. Transcribing the lyrics will be challenging because the artist raps over synth music player by Syntikka Janne. The hallucination level and mishearing of AI speech-to-text extractions will be measured by comparing errors made against the original Finnish lyrics. The error function is informal but still works for our case.</li>
</ul>

<h3>Title: Integrating Generative Adversarial Networks and Convolutional Neural Networks for Enhanced Traffic Accidents Detection and Analysis</h3>
<ul>
<li><strong>Authors: </strong>Zhenghao Xi, Xiang Liu, Yaqi Liu, Yitong Cai, Yangyu Zheng</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.16186">https://arxiv.org/abs/2506.16186</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.16186">https://arxiv.org/pdf/2506.16186</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.16186]] Integrating Generative Adversarial Networks and Convolutional Neural Networks for Enhanced Traffic Accidents Detection and Analysis(https://arxiv.org/abs/2506.16186)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer, generative</a></li>
<li><strong>Abstract: </strong>Accident detection using Closed Circuit Television (CCTV) footage is one of the most imperative features for enhancing transport safety and efficient traffic control. To this end, this research addresses the issues of supervised monitoring and data deficiency in accident detection systems by adapting excellent deep learning technologies. The motivation arises from rising statistics in the number of car accidents worldwide; this calls for innovation and the establishment of a smart, efficient and automated way of identifying accidents and calling for help to save lives. Addressing the problem of the scarcity of data, the presented framework joins Generative Adversarial Networks (GANs) for synthesizing data and Convolutional Neural Networks (CNN) for model training. Video frames for accidents and non-accidents are collected from YouTube videos, and we perform resizing, image enhancement and image normalisation pixel range adjustments. Three models are used: CNN, Fine-tuned Convolutional Neural Network (FTCNN) and Vision Transformer (VIT) worked best for detecting accidents from CCTV, obtaining an accuracy rate of 94% and 95%, while the CNN model obtained 88%. Such results show that the proposed framework suits traffic safety applications due to its high real-time accident detection capabilities and broad-scale applicability. This work lays the foundation for intelligent surveillance systems in the future for real-time traffic monitoring, smart city framework, and integration of intelligent surveillance systems into emergency management systems.</li>
</ul>

<h3>Title: JETHICS: Japanese Ethics Understanding Evaluation Dataset</h3>
<ul>
<li><strong>Authors: </strong>Masashi Takeshita, Rafal Rzepka</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.16187">https://arxiv.org/abs/2506.16187</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.16187">https://arxiv.org/pdf/2506.16187</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.16187]] JETHICS: Japanese Ethics Understanding Evaluation Dataset(https://arxiv.org/abs/2506.16187)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>In this work, we propose JETHICS, a Japanese dataset for evaluating ethics understanding of AI models. JETHICS contains 78K examples and is built by following the construction methods of the existing English ETHICS dataset. It includes four categories based normative theories and concepts from ethics and political philosophy; and one representing commonsense morality. Our evaluation experiments on non-proprietary large language models (LLMs) and on GPT-4o reveal that even GPT-4o achieves only an average score of about 0.7, while the best-performing Japanese LLM attains around 0.5, indicating a relatively large room for improvement in current LLMs.</li>
</ul>

<h3>Title: Efficient and Privacy-Preserving Soft Prompt Transfer for LLMs</h3>
<ul>
<li><strong>Authors: </strong>Xun Wang, Jing Xu, Franziska Boenisch, Michael Backes, Christopher A. Choquette-Choo, Adam Dziedzic</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.16196">https://arxiv.org/abs/2506.16196</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.16196">https://arxiv.org/pdf/2506.16196</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.16196]] Efficient and Privacy-Preserving Soft Prompt Transfer for LLMs(https://arxiv.org/abs/2506.16196)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, interpretability, large language model</a></li>
<li><strong>Abstract: </strong>Prompting has become a dominant paradigm for adapting large language models (LLMs). While discrete (textual) prompts are widely used for their interpretability, soft (parameter) prompts have recently gained traction in APIs. This is because they can encode information from more training samples while minimizing the user's token usage, leaving more space in the context window for task-specific input. However, soft prompts are tightly coupled to the LLM they are tuned on, limiting their generalization to other LLMs. This constraint is particularly problematic for efficiency and privacy: (1) tuning prompts on each LLM incurs high computational costs, especially as LLMs continue to grow in size. Additionally, (2) when the LLM is hosted externally, soft prompt tuning often requires sharing private data with the LLM provider. For instance, this is the case with the NVIDIA NeMo API. To address these issues, we propose POST (Privacy Of Soft prompt Transfer), a framework that enables private tuning of soft prompts on a small model and subsequently transfers these prompts to a larger LLM. POST uses knowledge distillation to derive a small model directly from the large LLM to improve prompt transferability, tunes the soft prompt locally, optionally with differential privacy guarantees, and transfers it back to the larger LLM using a small public dataset. Our experiments show that POST reduces computational costs, preserves privacy, and effectively transfers high-utility soft prompts.</li>
</ul>

<h3>Title: VideoGAN-based Trajectory Proposal for Automated Vehicles</h3>
<ul>
<li><strong>Authors: </strong>Annajoyce Mariani, Kira Maag, Hanno Gottschalk</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.16209">https://arxiv.org/abs/2506.16209</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.16209">https://arxiv.org/pdf/2506.16209</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.16209]] VideoGAN-based Trajectory Proposal for Automated Vehicles(https://arxiv.org/abs/2506.16209)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, generative</a></li>
<li><strong>Abstract: </strong>Being able to generate realistic trajectory options is at the core of increasing the degree of automation of road vehicles. While model-driven, rule-based, and classical learning-based methods are widely used to tackle these tasks at present, they can struggle to effectively capture the complex, multimodal distributions of future trajectories. In this paper we investigate whether a generative adversarial network (GAN) trained on videos of bird's-eye view (BEV) traffic scenarios can generate statistically accurate trajectories that correctly capture spatial relationships between the agents. To this end, we propose a pipeline that uses low-resolution BEV occupancy grid videos as training data for a video generative model. From the generated videos of traffic scenarios we extract abstract trajectory data using single-frame object detection and frame-to-frame object matching. We particularly choose a GAN architecture for the fast training and inference times with respect to diffusion models. We obtain our best results within 100 GPU hours of training, with inference times under 20\,ms. We demonstrate the physical realism of the proposed trajectories in terms of distribution alignment of spatial and dynamic parameters with respect to the ground truth videos from the Waymo Open Motion Dataset.</li>
</ul>

<h3>Title: FOCoOp: Enhancing Out-of-Distribution Robustness in Federated Prompt Learning for Vision-Language Models</h3>
<ul>
<li><strong>Authors: </strong>Xinting Liao, Weiming Liu, Jiaming Qian, Pengyang Zhou, Jiahe Xu, Wenjie Wang, Chaochao Chen, Xiaolin Zheng, Tat-Seng Chua</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.16218">https://arxiv.org/abs/2506.16218</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.16218">https://arxiv.org/pdf/2506.16218</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.16218]] FOCoOp: Enhancing Out-of-Distribution Robustness in Federated Prompt Learning for Vision-Language Models(https://arxiv.org/abs/2506.16218)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, robust, federate</a></li>
<li><strong>Abstract: </strong>Federated prompt learning (FPL) for vision-language models is a powerful approach to collaboratively adapt models across distributed clients while preserving data privacy. However, existing FPL approaches suffer from a trade-off between performance and robustness, particularly in out-of-distribution (OOD) shifts, limiting their reliability in real-world scenarios. The inherent in-distribution (ID) data heterogeneity among different clients makes it more challenging to maintain this trade-off. To fill this gap, we introduce a Federated OOD-aware Context Optimization (FOCoOp) framework, which captures diverse distributions among clients using ID global prompts, local prompts, and OOD prompts. Specifically, FOCoOp leverages three sets of prompts to create both class-level and distribution-level separations, which adapt to OOD shifts through bi-level distributionally robust optimization. Additionally, FOCoOp improves the discrimination consistency among clients, i.e., calibrating global prompts, seemingly OOD prompts, and OOD prompts by semi-unbalanced optimal transport. The extensive experiments on real-world datasets demonstrate that FOCoOp effectively captures decentralized heterogeneous distributions and enhances robustness of different OOD shifts. The project is available at GitHub.</li>
</ul>

<h3>Title: Think Global, Act Local: Bayesian Causal Discovery with Language Models in Sequential Data</h3>
<ul>
<li><strong>Authors: </strong>Prakhar Verma, David Arbour, Sunav Choudhary, Harshita Chopra, Arno Solin, Atanu R. Sinha</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.16234">https://arxiv.org/abs/2506.16234</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.16234">https://arxiv.org/pdf/2506.16234</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.16234]] Think Global, Act Local: Bayesian Causal Discovery with Language Models in Sequential Data(https://arxiv.org/abs/2506.16234)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Causal discovery from observational data typically assumes full access to data and availability of domain experts. In practice, data often arrive in batches, and expert knowledge is scarce. Language Models (LMs) offer a surrogate but come with their own issues-hallucinations, inconsistencies, and bias. We present BLANCE (Bayesian LM-Augmented Causal Estimation)-a hybrid Bayesian framework that bridges these gaps by adaptively integrating sequential batch data with LM-derived noisy, expert knowledge while accounting for both data-induced and LM-induced biases. Our proposed representation shift from Directed Acyclic Graph (DAG) to Partial Ancestral Graph (PAG) accommodates ambiguities within a coherent Bayesian framework, allowing grounding the global LM knowledge in local observational data. To guide LM interaction, we use a sequential optimization scheme that adaptively queries the most informative edges. Across varied datasets, BLANCE outperforms prior work in structural accuracy and extends to Bayesian parameter estimation, showing robustness to LM noise.</li>
</ul>

<h3>Title: Active MRI Acquisition with Diffusion Guided Bayesian Experimental Design</h3>
<ul>
<li><strong>Authors: </strong>Jacopo Iollo, Geoffroy Oudoumanessah, Carole Lartizien, Michel Dojat, Florence Forbes</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.16237">https://arxiv.org/abs/2506.16237</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.16237">https://arxiv.org/pdf/2506.16237</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.16237]] Active MRI Acquisition with Diffusion Guided Bayesian Experimental Design(https://arxiv.org/abs/2506.16237)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, generative</a></li>
<li><strong>Abstract: </strong>A key challenge in maximizing the benefits of Magnetic Resonance Imaging (MRI) in clinical settings is to accelerate acquisition times without significantly degrading image quality. This objective requires a balance between under-sampling the raw k-space measurements for faster acquisitions and gathering sufficient raw information for high-fidelity image reconstruction and analysis tasks. To achieve this balance, we propose to use sequential Bayesian experimental design (BED) to provide an adaptive and task-dependent selection of the most informative measurements. Measurements are sequentially augmented with new samples selected to maximize information gain on a posterior distribution over target images. Selection is performed via a gradient-based optimization of a design parameter that defines a subsampling pattern. In this work, we introduce a new active BED procedure that leverages diffusion-based generative models to handle the high dimensionality of the images and employs stochastic optimization to select among a variety of patterns while meeting the acquisition process constraints and budget. So doing, we show how our setting can optimize, not only standard image reconstruction, but also any associated image analysis task. The versatility and performance of our approach are demonstrated on several MRI acquisitions.</li>
</ul>

<h3>Title: Synthetic ALS-EEG Data Augmentation for ALS Diagnosis Using Conditional WGAN with Weight Clipping</h3>
<ul>
<li><strong>Authors: </strong>Abdulvahap Mutlu, Şengül Doğan, Türker Tuncer</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.16243">https://arxiv.org/abs/2506.16243</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.16243">https://arxiv.org/pdf/2506.16243</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.16243]] Synthetic ALS-EEG Data Augmentation for ALS Diagnosis Using Conditional WGAN with Weight Clipping(https://arxiv.org/abs/2506.16243)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>Amyotrophic Lateral Sclerosis (ALS) is a rare neurodegenerative disease, and high-quality EEG data from ALS patients are scarce. This data scarcity, coupled with severe class imbalance between ALS and healthy control recordings, poses a challenge for training reliable machine learning classifiers. In this work, we address these issues by generating synthetic EEG signals for ALS patients using a Conditional Wasserstein Generative Adversarial Network (CWGAN). We train CWGAN on a private EEG dataset (ALS vs. non-ALS) to learn the distribution of ALS EEG signals and produce realistic synthetic samples. We preprocess and normalize EEG recordings, and train a CWGAN model to generate synthetic ALS signals. The CWGAN architecture and training routine are detailed, with key hyperparameters chosen for stable training. Qualitative evaluation of generated signals shows that they closely mimic real ALS EEG patterns. The CWGAN training converged with generator and discriminator loss curves stabilizing, indicating successful learning. The synthetic EEG signals appear realistic and have potential use as augmented data for training classifiers, helping to mitigate class imbalance and improve ALS detection accuracy. We discuss how this approach can facilitate data sharing and enhance diagnostic models.</li>
</ul>

<h3>Title: Comparative Analysis of Abstractive Summarization Models for Clinical Radiology Reports</h3>
<ul>
<li><strong>Authors: </strong>Anindita Bhattacharya, Tohida Rehman, Debarshi Kumar Sanyal, Samiran Chattopadhyay</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.16247">https://arxiv.org/abs/2506.16247</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.16247">https://arxiv.org/pdf/2506.16247</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.16247]] Comparative Analysis of Abstractive Summarization Models for Clinical Radiology Reports(https://arxiv.org/abs/2506.16247)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>The findings section of a radiology report is often detailed and lengthy, whereas the impression section is comparatively more compact and captures key diagnostic conclusions. This research explores the use of advanced abstractive summarization models to generate the concise impression from the findings section of a radiology report. We have used the publicly available MIMIC-CXR dataset. A comparative analysis is conducted on leading pre-trained and open-source large language models, including T5-base, BART-base, PEGASUS-x-base, ChatGPT-4, LLaMA-3-8B, and a custom Pointer Generator Network with a coverage mechanism. To ensure a thorough assessment, multiple evaluation metrics are employed, including ROUGE-1, ROUGE-2, ROUGE-L, METEOR, and BERTScore. By analyzing the performance of these models, this study identifies their respective strengths and limitations in the summarization of medical text. The findings of this paper provide helpful information for medical professionals who need automated summarization solutions in the healthcare sector.</li>
</ul>

<h3>Title: Optimal Online Bookmaking for Any Number of Outcomes</h3>
<ul>
<li><strong>Authors: </strong>Hadar Tal, Oron Sabag</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.GT, cs.IT, math.OC</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.16253">https://arxiv.org/abs/2506.16253</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.16253">https://arxiv.org/pdf/2506.16253</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.16253]] Optimal Online Bookmaking for Any Number of Outcomes(https://arxiv.org/abs/2506.16253)</code><input type="text"></li>
<li><strong>Keywords: </strong>fair</a></li>
<li><strong>Abstract: </strong>We study the Online Bookmaking problem, where a bookmaker dynamically updates betting odds on the possible outcomes of an event. In each betting round, the bookmaker can adjust the odds based on the cumulative betting behavior of gamblers, aiming to maximize profit while mitigating potential loss. We show that for any event and any number of betting rounds, in a worst-case setting over all possible gamblers and outcome realizations, the bookmaker's optimal loss is the largest root of a simple polynomial. Our solution shows that bookmakers can be as fair as desired while avoiding financial risk, and the explicit characterization reveals an intriguing relation between the bookmaker's regret and Hermite polynomials. We develop an efficient algorithm that computes the optimal bookmaking strategy: when facing an optimal gambler, the algorithm achieves the optimal loss, and in rounds where the gambler is suboptimal, it reduces the achieved loss to the optimal opportunistic loss, a notion that is related to subgame perfect Nash equilibrium. The key technical contribution to achieve these results is an explicit characterization of the Bellman-Pareto frontier, which unifies the dynamic programming updates for Bellman's value function with the multi-criteria optimization framework of the Pareto frontier in the context of vector repeated games.</li>
</ul>

<h3>Title: R3eVision: A Survey on Robust Rendering, Restoration, and Enhancement for 3D Low-Level Vision</h3>
<ul>
<li><strong>Authors: </strong>Weeyoung Kwon, Jeahun Sung, Minkyu Jeon, Chanho Eom, Jihyong Oh</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.16262">https://arxiv.org/abs/2506.16262</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.16262">https://arxiv.org/pdf/2506.16262</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.16262]] R3eVision: A Survey on Robust Rendering, Restoration, and Enhancement for 3D Low-Level Vision(https://arxiv.org/abs/2506.16262)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Neural rendering methods such as Neural Radiance Fields (NeRF) and 3D Gaussian Splatting (3DGS) have achieved significant progress in photorealistic 3D scene reconstruction and novel view synthesis. However, most existing models assume clean and high-resolution (HR) multi-view inputs, which limits their robustness under real-world degradations such as noise, blur, low-resolution (LR), and weather-induced artifacts. To address these limitations, the emerging field of 3D Low-Level Vision (3D LLV) extends classical 2D Low-Level Vision tasks including super-resolution (SR), deblurring, weather degradation removal, restoration, and enhancement into the 3D spatial domain. This survey, referred to as R\textsuperscript{3}eVision, provides a comprehensive overview of robust rendering, restoration, and enhancement for 3D LLV by formalizing the degradation-aware rendering problem and identifying key challenges related to spatio-temporal consistency and ill-posed optimization. Recent methods that integrate LLV into neural rendering frameworks are categorized to illustrate how they enable high-fidelity 3D reconstruction under adverse conditions. Application domains such as autonomous driving, AR/VR, and robotics are also discussed, where reliable 3D perception from degraded inputs is critical. By reviewing representative methods, datasets, and evaluation protocols, this work positions 3D LLV as a fundamental direction for robust 3D content generation and scene-level reconstruction in real-world environments.</li>
</ul>

<h3>Title: Next-Token Prediction Should be Ambiguity-Sensitive: A Meta-Learning Perspective</h3>
<ul>
<li><strong>Authors: </strong>Leo Gagnon, Eric Elmoznino, Sarthak Mittal, Tom Marty, Tejas Kasetty, Dhanya Sridhar, Guillaume Lajoie</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.16288">https://arxiv.org/abs/2506.16288</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.16288">https://arxiv.org/pdf/2506.16288</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.16288]] Next-Token Prediction Should be Ambiguity-Sensitive: A Meta-Learning Perspective(https://arxiv.org/abs/2506.16288)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>The rapid adaptation ability of auto-regressive foundation models is often attributed to the diversity of their pre-training data. This is because, from a Bayesian standpoint, minimizing prediction error in such settings requires integrating over all plausible latent hypotheses consistent with observations. While this behavior is desirable in principle, it often proves too ambitious in practice: under high ambiguity, the number of plausible latent alternatives makes Bayes-optimal prediction computationally intractable. Cognitive science has long recognized this limitation, suggesting that under such conditions, heuristics or information-seeking strategies are preferable to exhaustive inference. Translating this insight to next-token prediction, we hypothesize that low- and high-ambiguity predictions pose different computational demands, making ambiguity-agnostic next-token prediction a detrimental inductive bias. To test this, we introduce MetaHMM, a synthetic sequence meta-learning benchmark with rich compositional structure and a tractable Bayesian oracle. We show that Transformers indeed struggle with high-ambiguity predictions across model sizes. Motivated by cognitive theories, we propose a method to convert pre-trained models into Monte Carlo predictors that decouple task inference from token prediction. Preliminary results show substantial gains in ambiguous contexts through improved capacity allocation and test-time scalable inference, though challenges remain.</li>
</ul>

<h3>Title: SycnMapV2: Robust and Adaptive Unsupervised Segmentation</h3>
<ul>
<li><strong>Authors: </strong>Heng Zhang, Zikang Wan, Danilo Vasconcellos Vargas</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.16297">https://arxiv.org/abs/2506.16297</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.16297">https://arxiv.org/pdf/2506.16297</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.16297]] SycnMapV2: Robust and Adaptive Unsupervised Segmentation(https://arxiv.org/abs/2506.16297)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, segmentation</a></li>
<li><strong>Abstract: </strong>Human vision excels at segmenting visual cues without the need for explicit training, and it remains remarkably robust even as noise severity increases. In contrast, existing AI algorithms struggle to maintain accuracy under similar conditions. Here, we present SyncMapV2, the first to solve unsupervised segmentation with state-of-the-art robustness. SyncMapV2 exhibits a minimal drop in mIoU, only 0.01%, under digital corruption, compared to a 23.8% drop observed in SOTA this http URL superior performance extends across various types of corruption: noise (7.3% vs. 37.7%), weather (7.5% vs. 33.8%), and blur (7.0% vs. 29.5%). Notably, SyncMapV2 accomplishes this without any robust training, supervision, or loss functions. It is based on a learning paradigm that uses self-organizing dynamical equations combined with concepts from random networks. Moreover,unlike conventional methods that require re-initialization for each new input, SyncMapV2 adapts online, mimicking the continuous adaptability of human vision. Thus, we go beyond the accurate and robust results, and present the first algorithm that can do all the above online, adapting to input rather than re-initializing. In adaptability tests, SyncMapV2 demonstrates near-zero performance degradation, which motivates and fosters a new generation of robust and adaptive intelligence in the near future.</li>
</ul>

<h3>Title: Signatures to help interpretability of anomalies</h3>
<ul>
<li><strong>Authors: </strong>Emmanuel Gangler (1), Emille E. O. Ishida (1), Matwey V. Kornilov (2 and 3), Vladimir Korolev, Anastasia Lavrukhina (3), Konstantin Malanchev (4), Maria V. Pruzhinskaya (1 and 3), Etienne Russeil (1 and 5), Timofey Semenikhin (3 and 6), Sreevarsha Sreejith (7), Alina A. Volnova (8) ((1) Université Clermont Auvergne CNRS LPCA, Clermont-Ferrand, France, (2) National Research University Higher School of Economics, Moscow, Russia, (3) Sternberg Astronomical Institute Lomonosov Moscow State University, Moscow, Russia, (4) McWilliams Center for Cosmology and Astrophysics, Department of Physics, Carnegie Mellon University, Pittsburgh, PA, USA, (5) The Oskar Klein Centre Department of Astronomy, Stockholm University AlbaNova, Stockholm, Sweden, (6) Faculty of Physics, Lomonosov Moscow State University, Moscow, Russia, (7) Physics department, University of Surrey, Guildford, UK, (8) Space Research Institute of the Russian Academy of Sciences, Moscow, Russia)</a></li>
<li><strong>Subjects: </strong>cs.LG, astro-ph.IM</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.16314">https://arxiv.org/abs/2506.16314</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.16314">https://arxiv.org/pdf/2506.16314</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.16314]] Signatures to help interpretability of anomalies(https://arxiv.org/abs/2506.16314)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability</a></li>
<li><strong>Abstract: </strong>Machine learning is often viewed as a black box when it comes to understanding its output, be it a decision or a score. Automatic anomaly detection is no exception to this rule, and quite often the astronomer is left to independently analyze the data in order to understand why a given event is tagged as an anomaly. We introduce here idea of anomaly signature, whose aim is to help the interpretability of anomalies by highlighting which features contributed to the decision.</li>
</ul>

<h3>Title: Bayesian Optimization over Bounded Domains with the Beta Product Kernel</h3>
<ul>
<li><strong>Authors: </strong>Huy Hoang Nguyen, Han Zhou, Matthew B. Blaschko, Aleksei Tiulpin</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.16316">https://arxiv.org/abs/2506.16316</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.16316">https://arxiv.org/pdf/2506.16316</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.16316]] Bayesian Optimization over Bounded Domains with the Beta Product Kernel(https://arxiv.org/abs/2506.16316)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Bayesian optimization with Gaussian processes (GP) is commonly used to optimize black-box functions. The Matérn and the Radial Basis Function (RBF) covariance functions are used frequently, but they do not make any assumptions about the domain of the function, which may limit their applicability in bounded domains. To address the limitation, we introduce the Beta kernel, a non-stationary kernel induced by a product of Beta distribution density functions. Such a formulation allows our kernel to naturally model functions on bounded domains. We present statistical evidence supporting the hypothesis that the kernel exhibits an exponential eigendecay rate, based on empirical analyses of its spectral properties across different settings. Our experimental results demonstrate the robustness of the Beta kernel in modeling functions with optima located near the faces or vertices of the unit hypercube. The experiments show that our kernel consistently outperforms a wide range of kernels, including the well-known Matérn and RBF, in different problems, including synthetic function optimization and the compression of vision and language models.</li>
</ul>

<h3>Title: Segment Anything for Satellite Imagery: A Strong Baseline and a Regional Dataset for Automatic Field Delineation</h3>
<ul>
<li><strong>Authors: </strong>Carmelo Scribano, Elena Govi, Paolo bertellini, Simone Parisi, Giorgia Franchini, Marko Bertogna</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.16318">https://arxiv.org/abs/2506.16318</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.16318">https://arxiv.org/pdf/2506.16318</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.16318]] Segment Anything for Satellite Imagery: A Strong Baseline and a Regional Dataset for Automatic Field Delineation(https://arxiv.org/abs/2506.16318)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, extraction, segmentation</a></li>
<li><strong>Abstract: </strong>Accurate mapping of agricultural field boundaries is essential for the efficient operation of agriculture. Automatic extraction from high-resolution satellite imagery, supported by computer vision techniques, can avoid costly ground surveys. In this paper, we present a pipeline for field delineation based on the Segment Anything Model (SAM), introducing a fine-tuning strategy to adapt SAM to this task. In addition to using published datasets, we describe a method for acquiring a complementary regional dataset that covers areas beyond current sources. Extensive experiments assess segmentation accuracy and evaluate the generalization capabilities. Our approach provides a robust baseline for automated field delineation. The new regional dataset, known as ERAS, is now publicly available.</li>
</ul>

<h3>Title: PL-Guard: Benchmarking Language Model Safety for Polish</h3>
<ul>
<li><strong>Authors: </strong>Aleksandra Krasnodębska, Karolina Seweryn, Szymon Łukasik, Wojciech Kusa</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.16322">https://arxiv.org/abs/2506.16322</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.16322">https://arxiv.org/pdf/2506.16322</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.16322]] PL-Guard: Benchmarking Language Model Safety for Polish(https://arxiv.org/abs/2506.16322)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, large language model</a></li>
<li><strong>Abstract: </strong>Despite increasing efforts to ensure the safety of large language models (LLMs), most existing safety assessments and moderation tools remain heavily biased toward English and other high-resource languages, leaving majority of global languages underexamined. To address this gap, we introduce a manually annotated benchmark dataset for language model safety classification in Polish. We also create adversarially perturbed variants of these samples designed to challenge model robustness. We conduct a series of experiments to evaluate LLM-based and classifier-based models of varying sizes and architectures. Specifically, we fine-tune three models: Llama-Guard-3-8B, a HerBERT-based classifier (a Polish BERT derivative), and PLLuM, a Polish-adapted Llama-8B model. We train these models using different combinations of annotated data and evaluate their performance, comparing it against publicly available guard models. Results demonstrate that the HerBERT-based classifier achieves the highest overall performance, particularly under adversarial conditions.</li>
</ul>

<h3>Title: Reliable Few-shot Learning under Dual Noises</h3>
<ul>
<li><strong>Authors: </strong>Ji Zhang, Jingkuan Song, Lianli Gao, Nicu Sebe, Heng Tao Shen</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.16330">https://arxiv.org/abs/2506.16330</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.16330">https://arxiv.org/pdf/2506.16330</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.16330]] Reliable Few-shot Learning under Dual Noises(https://arxiv.org/abs/2506.16330)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Recent advances in model pre-training give rise to task adaptation-based few-shot learning (FSL), where the goal is to adapt a pre-trained task-agnostic model for capturing task-specific knowledge with a few-labeled support samples of the target this http URL, existing approaches may still fail in the open world due to the inevitable in-distribution (ID) and out-of-distribution (OOD) noise from both support and query samples of the target task. With limited support samples available, i) the adverse effect of the dual noises can be severely amplified during task adaptation, and ii) the adapted model can produce unreliable predictions on query samples in the presence of the dual noises. In this work, we propose DEnoised Task Adaptation (DETA++) for reliable FSL. DETA++ uses a Contrastive Relevance Aggregation (CoRA) module to calculate image and region weights for support samples, based on which a clean prototype loss and a noise entropy maximization loss are proposed to achieve noise-robust task adaptation. Additionally,DETA++ employs a memory bank to store and refine clean regions for each inner-task class, based on which a Local Nearest Centroid Classifier (LocalNCC) is devised to yield noise-robust predictions on query samples. Moreover, DETA++ utilizes an Intra-class Region Swapping (IntraSwap) strategy to rectify ID class prototypes during task adaptation, enhancing the model's robustness to the dual noises. Extensive experiments demonstrate the effectiveness and flexibility of DETA++.</li>
</ul>

<h3>Title: Analyzing the Influence of Knowledge Graph Information on Relation Extraction</h3>
<ul>
<li><strong>Authors: </strong>Cedric Möller, Ricardo Usbeck</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.IR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.16343">https://arxiv.org/abs/2506.16343</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.16343">https://arxiv.org/pdf/2506.16343</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.16343]] Analyzing the Influence of Knowledge Graph Information on Relation Extraction(https://arxiv.org/abs/2506.16343)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction</a></li>
<li><strong>Abstract: </strong>We examine the impact of incorporating knowledge graph information on the performance of relation extraction models across a range of datasets. Our hypothesis is that the positions of entities within a knowledge graph provide important insights for relation extraction tasks. We conduct experiments on multiple datasets, each varying in the number of relations, training examples, and underlying knowledge graphs. Our results demonstrate that integrating knowledge graph information significantly enhances performance, especially when dealing with an imbalance in the number of training examples for each relation. We evaluate the contribution of knowledge graph-based features by combining established relation extraction methods with graph-aware Neural Bellman-Ford networks. These features are tested in both supervised and zero-shot settings, demonstrating consistent performance improvements across various datasets.</li>
</ul>

<h3>Title: Emission Impossible: privacy-preserving carbon emissions claims</h3>
<ul>
<li><strong>Authors: </strong>Jessica Man, Sadiq Jaffer, Patrick Ferris, Martin Kleppmann, Anil Madhavapeddy</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.16347">https://arxiv.org/abs/2506.16347</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.16347">https://arxiv.org/pdf/2506.16347</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.16347]] Emission Impossible: privacy-preserving carbon emissions claims(https://arxiv.org/abs/2506.16347)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy</a></li>
<li><strong>Abstract: </strong>Information and Communication Technologies (ICT) have a significant climate impact, and data centres account for a large proportion of the carbon emissions from ICT. To achieve sustainability goals, it is important that all parties involved in ICT supply chains can track and share accurate carbon emissions data with their customers, investors, and the authorities. However, businesses have strong incentives to make their numbers look good, whilst less so to publish their accounting methods along with all the input data, due to the risk of revealing sensitive information. It would be uneconomical to use a trusted third party to verify the data for every report for each party in the chain. As a result, carbon emissions reporting in supply chains currently relies on unverified data. This paper proposes a methodology that applies cryptography and zero-knowledge proofs for carbon emissions claims that can be subsequently verified without the knowledge of the private input data. The proposed system is based on a zero-knowledge Succinct Non-interactive ARguments of Knowledge (zk-SNARK) protocol, which enables verifiable emissions reporting mechanisms across a chain of energy suppliers, cloud data centres, cloud services providers, and customers, without any company needing to disclose commercially sensitive information. This allows customers of cloud services to accurately account for the emissions generated by their activities, improving data quality for their own regulatory reporting. Cloud services providers would also be held accountable for producing accurate carbon emissions data.</li>
</ul>

<h3>Title: DISCIE -- Discriminative Closed Information Extraction</h3>
<ul>
<li><strong>Authors: </strong>Cedric Möller, Ricardo Usbeck</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.16348">https://arxiv.org/abs/2506.16348</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.16348">https://arxiv.org/pdf/2506.16348</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.16348]] DISCIE -- Discriminative Closed Information Extraction(https://arxiv.org/abs/2506.16348)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction, generative</a></li>
<li><strong>Abstract: </strong>This paper introduces a novel method for closed information extraction. The method employs a discriminative approach that incorporates type and entity-specific information to improve relation extraction accuracy, particularly benefiting long-tail relations. Notably, this method demonstrates superior performance compared to state-of-the-art end-to-end generative models. This is especially evident for the problem of large-scale closed information extraction where we are confronted with millions of entities and hundreds of relations. Furthermore, we emphasize the efficiency aspect by leveraging smaller models. In particular, the integration of type-information proves instrumental in achieving performance levels on par with or surpassing those of a larger generative model. This advancement holds promise for more accurate and efficient information extraction techniques.</li>
</ul>

<h3>Title: Watermarking Autoregressive Image Generation</h3>
<ul>
<li><strong>Authors: </strong>Nikola Jovanović, Ismail Labiad, Tomáš Souček, Martin Vechev, Pierre Fernandez</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CR, cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.16349">https://arxiv.org/abs/2506.16349</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.16349">https://arxiv.org/pdf/2506.16349</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.16349]] Watermarking Autoregressive Image Generation(https://arxiv.org/abs/2506.16349)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack, robust, watermark, generative</a></li>
<li><strong>Abstract: </strong>Watermarking the outputs of generative models has emerged as a promising approach for tracking their provenance. Despite significant interest in autoregressive image generation models and their potential for misuse, no prior work has attempted to watermark their outputs at the token level. In this work, we present the first such approach by adapting language model watermarking techniques to this setting. We identify a key challenge: the lack of reverse cycle-consistency (RCC), wherein re-tokenizing generated image tokens significantly alters the token sequence, effectively erasing the watermark. To address this and to make our method robust to common image transformations, neural compression, and removal attacks, we introduce (i) a custom tokenizer-detokenizer finetuning procedure that improves RCC, and (ii) a complementary watermark synchronization layer. As our experiments demonstrate, our approach enables reliable and robust watermark detection with theoretically grounded p-values.</li>
</ul>

<h3>Title: Data-Driven Policy Mapping for Safe RL-based Energy Management Systems</h3>
<ul>
<li><strong>Authors: </strong>Theo Zangato, Aomar Osmani, Pegah Alizadeh</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.16352">https://arxiv.org/abs/2506.16352</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.16352">https://arxiv.org/pdf/2506.16352</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.16352]] Data-Driven Policy Mapping for Safe RL-based Energy Management Systems(https://arxiv.org/abs/2506.16352)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Increasing global energy demand and renewable integration complexity have placed buildings at the center of sustainable energy management. We present a three-step reinforcement learning(RL)-based Building Energy Management System (BEMS) that combines clustering, forecasting, and constrained policy learning to address scalability, adaptability, and safety challenges. First, we cluster non-shiftable load profiles to identify common consumption patterns, enabling policy generalization and transfer without retraining for each new building. Next, we integrate an LSTM based forecasting module to anticipate future states, improving the RL agents' responsiveness to dynamic conditions. Lastly, domain-informed action masking ensures safe exploration and operation, preventing harmful decisions. Evaluated on real-world data, our approach reduces operating costs by up to 15% for certain building types, maintains stable environmental performance, and quickly classifies and optimizes new buildings with limited data. It also adapts to stochastic tariff changes without retraining. Overall, this framework delivers scalable, robust, and cost-effective building energy management.</li>
</ul>

<h3>Title: Prompt-based Dynamic Token Pruning to Guide Transformer Attention in Efficient Segmentation</h3>
<ul>
<li><strong>Authors: </strong>Pallabi Dutta, Anubhab Maity, Sushmita Mitra</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.16369">https://arxiv.org/abs/2506.16369</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.16369">https://arxiv.org/pdf/2506.16369</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.16369]] Prompt-based Dynamic Token Pruning to Guide Transformer Attention in Efficient Segmentation(https://arxiv.org/abs/2506.16369)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer, segmentation</a></li>
<li><strong>Abstract: </strong>The high computational demands of Vision Transformers (ViTs), in processing a huge number of tokens, often constrain their practical application in analyzing medical images. This research proposes an adaptive prompt-guided pruning method to selectively reduce the processing of irrelevant tokens in the segmentation pipeline. The prompt-based spatial prior helps to rank the tokens according to their relevance. Tokens with low-relevance scores are down-weighted, ensuring that only the relevant ones are propagated for processing across subsequent stages. This data-driven pruning strategy facilitates end-to-end training, maintains gradient flow, and improves segmentation accuracy by focusing computational resources on essential regions. The proposed framework is integrated with several state-of-the-art models to facilitate the elimination of irrelevant tokens; thereby, enhancing computational efficiency while preserving segmentation accuracy. The experimental results show a reduction of $\sim$ 35-55\% tokens; thus reducing the computational costs relative to the baselines. Cost-effective medical image processing, using our framework, facilitates real-time diagnosis by expanding its applicability in resource-constrained environments.</li>
</ul>

<h3>Title: Can structural correspondences ground real world representational content in Large Language Models?</h3>
<ul>
<li><strong>Authors: </strong>Iwan Williams</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.16370">https://arxiv.org/abs/2506.16370</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.16370">https://arxiv.org/pdf/2506.16370</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.16370]] Can structural correspondences ground real world representational content in Large Language Models?(https://arxiv.org/abs/2506.16370)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large Language Models (LLMs) such as GPT-4 produce compelling responses to a wide range of prompts. But their representational capacities are uncertain. Many LLMs have no direct contact with extra-linguistic reality: their inputs, outputs and training data consist solely of text, raising the questions (1) can LLMs represent anything and (2) if so, what? In this paper, I explore what it would take to answer these questions according to a structural-correspondence based account of representation, and make an initial survey of this evidence. I argue that the mere existence of structural correspondences between LLMs and worldly entities is insufficient to ground representation of those entities. However, if these structural correspondences play an appropriate role - they are exploited in a way that explains successful task performance - then they could ground real world contents. This requires overcoming a challenge: the text-boundedness of LLMs appears, on the face of it, to prevent them engaging in the right sorts of tasks.</li>
</ul>

<h3>Title: Large Language Models in Argument Mining: A Survey</h3>
<ul>
<li><strong>Authors: </strong>Hao Li, Viktor Schlegel, Yizheng Sun, Riza Batista-Navarro, Goran Nenadic</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.16383">https://arxiv.org/abs/2506.16383</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.16383">https://arxiv.org/pdf/2506.16383</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.16383]] Large Language Models in Argument Mining: A Survey(https://arxiv.org/abs/2506.16383)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, interpretability, large language model</a></li>
<li><strong>Abstract: </strong>Argument Mining (AM), a critical subfield of Natural Language Processing (NLP), focuses on extracting argumentative structures from text. The advent of Large Language Models (LLMs) has profoundly transformed AM, enabling advanced in-context learning, prompt-based generation, and robust cross-domain adaptability. This survey systematically synthesizes recent advancements in LLM-driven AM. We provide a concise review of foundational theories and annotation frameworks, alongside a meticulously curated catalog of datasets. A key contribution is our comprehensive taxonomy of AM subtasks, elucidating how contemporary LLM techniques -- such as prompting, chain-of-thought reasoning, and retrieval augmentation -- have reconfigured their execution. We further detail current LLM architectures and methodologies, critically assess evaluation practices, and delineate pivotal challenges including long-context reasoning, interpretability, and annotation bottlenecks. Conclusively, we highlight emerging trends and propose a forward-looking research agenda for LLM-based computational argumentation, aiming to strategically guide researchers in this rapidly evolving domain.</li>
</ul>

<h3>Title: HausaNLP at SemEval-2025 Task 11: Advancing Hausa Text-based Emotion Detection</h3>
<ul>
<li><strong>Authors: </strong>Sani Abdullahi Sani, Salim Abubakar, Falalu Ibrahim Lawan, Abdulhamid Abubakar, Maryam Bala</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.16388">https://arxiv.org/abs/2506.16388</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.16388">https://arxiv.org/pdf/2506.16388</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.16388]] HausaNLP at SemEval-2025 Task 11: Advancing Hausa Text-based Emotion Detection(https://arxiv.org/abs/2506.16388)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>This paper presents our approach to multi-label emotion detection in Hausa, a low-resource African language, as part of SemEval Track A. We fine-tuned AfriBERTa, a transformer-based model pre-trained on African languages, to classify Hausa text into six emotions: anger, disgust, fear, joy, sadness, and surprise. Our methodology involved data preprocessing, tokenization, and model fine-tuning using the Hugging Face Trainer API. The system achieved a validation accuracy of 74.00%, with an F1-score of 73.50%, demonstrating the effectiveness of transformer-based models for emotion detection in low-resource languages.</li>
</ul>

<h3>Title: RiOT: Efficient Prompt Refinement with Residual Optimization Tree</h3>
<ul>
<li><strong>Authors: </strong>Chenyi Zhou, Zhengyan Shi, Yuan Yao, Lei Liang, Huajun Chen, Qiang Zhang</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.16389">https://arxiv.org/abs/2506.16389</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.16389">https://arxiv.org/pdf/2506.16389</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.16389]] RiOT: Efficient Prompt Refinement with Residual Optimization Tree(https://arxiv.org/abs/2506.16389)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Recent advancements in large language models (LLMs) have highlighted their potential across a variety of tasks, but their performance still heavily relies on the design of effective prompts. Existing methods for automatic prompt optimization face two challenges: lack of diversity, limiting the exploration of valuable and innovative directions and semantic drift, where optimizations for one task can degrade performance in others. To address these issues, we propose Residual Optimization Tree (RiOT), a novel framework for automatic prompt optimization. RiOT iteratively refines prompts through text gradients, generating multiple semantically diverse candidates at each step, and selects the best prompt using perplexity. Additionally, RiOT incorporates the text residual connection to mitigate semantic drift by selectively retaining beneficial content across optimization iterations. A tree structure efficiently manages the optimization process, ensuring scalability and flexibility. Extensive experiments across five benchmarks, covering commonsense, mathematical, logical, temporal, and semantic reasoning, demonstrate that RiOT outperforms both previous prompt optimization methods and manual prompting.</li>
</ul>

<h3>Title: State-Space Kolmogorov Arnold Networks for Interpretable Nonlinear System Identification</h3>
<ul>
<li><strong>Authors: </strong>Gonçalo Granjal Cruz, Balazs Renczes, Mark C Runacres, Jan Decuyper</a></li>
<li><strong>Subjects: </strong>cs.LG, eess.SY</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.16392">https://arxiv.org/abs/2506.16392</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.16392">https://arxiv.org/pdf/2506.16392</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.16392]] State-Space Kolmogorov Arnold Networks for Interpretable Nonlinear System Identification(https://arxiv.org/abs/2506.16392)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability</a></li>
<li><strong>Abstract: </strong>While accurate, black-box system identification models lack interpretability of the underlying system dynamics. This paper proposes State-Space Kolmogorov-Arnold Networks (SS-KAN) to address this challenge by integrating Kolmogorov-Arnold Networks within a state-space framework. The proposed model is validated on two benchmark systems: the Silverbox and the Wiener-Hammerstein benchmarks. Results show that SS-KAN provides enhanced interpretability due to sparsity-promoting regularization and the direct visualization of its learned univariate functions, which reveal system nonlinearities at the cost of accuracy when compared to state-of-the-art black-box models, highlighting SS-KAN as a promising approach for interpretable nonlinear system identification, balancing accuracy and interpretability of nonlinear system dynamics.</li>
</ul>

<h3>Title: From LLM-anation to LLM-orchestrator: Coordinating Small Models for Data Labeling</h3>
<ul>
<li><strong>Authors: </strong>Yao Lu, Zhaiyuan Ji, Jiawei Du, Yu Shanqing, Qi Xuan, Tianyi Zhou</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.16393">https://arxiv.org/abs/2506.16393</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.16393">https://arxiv.org/pdf/2506.16393</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.16393]] From LLM-anation to LLM-orchestrator: Coordinating Small Models for Data Labeling(https://arxiv.org/abs/2506.16393)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Although the annotation paradigm based on Large Language Models (LLMs) has made significant breakthroughs in recent years, its actual deployment still has two core bottlenecks: first, the cost of calling commercial APIs in large-scale annotation is very expensive; second, in scenarios that require fine-grained semantic understanding, such as sentiment classification and toxicity classification, the annotation accuracy of LLMs is even lower than that of Small Language Models (SLMs) dedicated to this field. To address these problems, we propose a new paradigm of multi-model cooperative annotation and design a fully automatic annotation framework AutoAnnotator based on this. Specifically, AutoAnnotator consists of two layers. The upper-level meta-controller layer uses the generation and reasoning capabilities of LLMs to select SLMs for annotation, automatically generate annotation code and verify difficult samples; the lower-level task-specialist layer consists of multiple SLMs that perform annotation through multi-model voting. In addition, we use the difficult samples obtained by the secondary review of the meta-controller layer as the reinforcement learning set and fine-tune the SLMs in stages through a continual learning strategy, thereby improving the generalization of SLMs. Extensive experiments show that AutoAnnotator outperforms existing open-source/API LLMs in zero-shot, one-shot, CoT, and majority voting settings. Notably, AutoAnnotator reduces the annotation cost by 74.15% compared to directly annotating with GPT-3.5-turbo, while still improving the accuracy by 6.21%. Project page: this https URL.</li>
</ul>

<h3>Title: OJBench: A Competition Level Code Benchmark For Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Zhexu Wang, Yiping Liu, Yejie Wang, Wenyang He, Bofei Gao, Muxi Diao, Yanxu Chen, Kelin Fu, Flood Sung, Zhilin Yang, Tianyu Liu, Weiran Xu</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.16395">https://arxiv.org/abs/2506.16395</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.16395">https://arxiv.org/pdf/2506.16395</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.16395]] OJBench: A Competition Level Code Benchmark For Large Language Models(https://arxiv.org/abs/2506.16395)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Recent advancements in large language models (LLMs) have demonstrated significant progress in math and code reasoning capabilities. However, existing code benchmark are limited in their ability to evaluate the full spectrum of these capabilities, particularly at the competitive level. To bridge this gap, we introduce OJBench, a novel and challenging benchmark designed to assess the competitive-level code reasoning abilities of LLMs. OJBench comprises 232 programming competition problems from NOI and ICPC, providing a more rigorous test of models' reasoning skills. We conducted a comprehensive evaluation using OJBench on 37 models, including both closed-source and open-source models, reasoning-oriented and non-reasoning-oriented models. Our results indicate that even state-of-the-art reasoning-oriented models, such as o4-mini and Gemini-2.5-pro-exp, struggle with highly challenging competition-level problems. This highlights the significant challenges that models face in competitive-level code reasoning.</li>
</ul>

<h3>Title: HyperPath: Knowledge-Guided Hyperbolic Semantic Hierarchy Modeling for WSI Analysis</h3>
<ul>
<li><strong>Authors: </strong>Peixiang Huang, Yanyan Huang, Weiqin Zhao, Junjun He, Lequan Yu</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.16398">https://arxiv.org/abs/2506.16398</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.16398">https://arxiv.org/pdf/2506.16398</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.16398]] HyperPath: Knowledge-Guided Hyperbolic Semantic Hierarchy Modeling for WSI Analysis(https://arxiv.org/abs/2506.16398)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Pathology is essential for cancer diagnosis, with multiple instance learning (MIL) widely used for whole slide image (WSI) analysis. WSIs exhibit a natural hierarchy -- patches, regions, and slides -- with distinct semantic associations. While some methods attempt to leverage this hierarchy for improved representation, they predominantly rely on Euclidean embeddings, which struggle to fully capture semantic hierarchies. To address this limitation, we propose HyperPath, a novel method that integrates knowledge from textual descriptions to guide the modeling of semantic hierarchies of WSIs in hyperbolic space, thereby enhancing WSI classification. Our approach adapts both visual and textual features extracted by pathology vision-language foundation models to the hyperbolic space. We design an Angular Modality Alignment Loss to ensure robust cross-modal alignment, while a Semantic Hierarchy Consistency Loss further refines feature hierarchies through entailment and contradiction relationships and thus enhance semantic coherence. The classification is performed with geodesic distance, which measures the similarity between entities in the hyperbolic semantic hierarchy. This eliminates the need for linear classifiers and enables a geometry-aware approach to WSI analysis. Extensive experiments show that our method achieves superior performance across tasks compared to existing methods, highlighting the potential of hyperbolic embeddings for WSI analysis.</li>
</ul>

<h3>Title: NepaliGPT: A Generative Language Model for the Nepali Language</h3>
<ul>
<li><strong>Authors: </strong>Shushanta Pudasaini, Aman Shakya, Siddhartha Shrestha, Sahil Bhatta, Sunil Thapa, Sushmita Palikhe</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.16399">https://arxiv.org/abs/2506.16399</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.16399">https://arxiv.org/pdf/2506.16399</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.16399]] NepaliGPT: A Generative Language Model for the Nepali Language(https://arxiv.org/abs/2506.16399)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative, large language model</a></li>
<li><strong>Abstract: </strong>After the release of ChatGPT, Large Language Models (LLMs) have gained huge popularity in recent days and thousands of variants of LLMs have been released. However, there is no generative language model for the Nepali language, due to which other downstream tasks, including fine-tuning, have not been explored yet. To fill this research gap in the Nepali NLP space, this research proposes \textit{NepaliGPT}, a generative large language model tailored specifically for the Nepali language. This research introduces an advanced corpus for the Nepali language collected from several sources, called the Devanagari Corpus. Likewise, the research introduces the first NepaliGPT benchmark dataset comprised of 4,296 question-answer pairs in the Nepali language. The proposed LLM NepaliGPT achieves the following metrics in text generation: Perplexity of 26.32245, ROUGE-1 score of 0.2604, causal coherence of 81.25\%, and causal consistency of 85.41\%.</li>
</ul>

<h3>Title: Physical-Layer Signal Injection Attacks on EV Charging Ports: Bypassing Authentication via Electrical-Level Exploits</h3>
<ul>
<li><strong>Authors: </strong>Hetian Shi, Yi He, Shangru Song, Jianwei Zhuge, Jian Mao</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.16400">https://arxiv.org/abs/2506.16400</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.16400">https://arxiv.org/pdf/2506.16400</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.16400]] Physical-Layer Signal Injection Attacks on EV Charging Ports: Bypassing Authentication via Electrical-Level Exploits(https://arxiv.org/abs/2506.16400)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, attack</a></li>
<li><strong>Abstract: </strong>The proliferation of electric vehicles in recent years has significantly expanded the charging infrastructure while introducing new security risks to both vehicles and chargers. In this paper, we investigate the security of major charging protocols such as SAE J1772, CCS, IEC 61851, GB/T 20234, and NACS, uncovering new physical signal spoofing attacks in their authentication mechanisms. By inserting a compact malicious device into the charger connector, attackers can inject fraudulent signals to sabotage the charging process, leading to denial of service, vehicle-induced charger lockout, and damage to the chargers or the vehicle's charge management system. To demonstrate the feasibility of our attacks, we propose PORTulator, a proof-of-concept (PoC) attack hardware, including a charger gun plugin device for injecting physical signals and a wireless controller for remote manipulation. By evaluating PORTulator on multiple real-world chargers, we identify 7 charging standards used by 20 charger piles that are vulnerable to our attacks. The root cause is that chargers use simple physical signals for authentication and control, making them easily spoofed by attackers. To address this issue, we propose enhancing authentication circuits by integrating non-resistive memory components and utilizing dynamic high-frequency Pulse Width Modulation (PWM) signals to counter such physical signal spoofing attacks.</li>
</ul>

<h3>Title: Generating Directed Graphs with Dual Attention and Asymmetric Encoding</h3>
<ul>
<li><strong>Authors: </strong>Alba Carballo-Castro, Manuel Madeira, Yiming Qin, Dorina Thanou, Pascal Frossard</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.16404">https://arxiv.org/abs/2506.16404</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.16404">https://arxiv.org/pdf/2506.16404</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.16404]] Generating Directed Graphs with Dual Attention and Asymmetric Encoding(https://arxiv.org/abs/2506.16404)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, generative</a></li>
<li><strong>Abstract: </strong>Directed graphs naturally model systems with asymmetric, ordered relationships, essential to applications in biology, transportation, social networks, and visual understanding. Generating such graphs enables tasks such as simulation, data augmentation and novel instance discovery; however, directed graph generation remains underexplored. We identify two key factors limiting progress in this direction: first, modeling edge directionality introduces a substantially larger dependency space, making the underlying distribution harder to learn; second, the absence of standardized benchmarks hinders rigorous evaluation. Addressing the former requires more expressive models that are sensitive to directional topologies. We propose Directo, the first generative model for directed graphs built upon the discrete flow matching framework. Our approach combines: (i) principled positional encodings tailored to asymmetric pairwise relations, (ii) a dual-attention mechanism capturing both incoming and outgoing dependencies, and (iii) a robust, discrete generative framework. To support evaluation, we introduce a benchmark suite covering synthetic and real-world datasets. It shows that our method performs strongly across diverse settings and even competes with specialized models for particular classes, such as directed acyclic graphs. Our results highlight the effectiveness and generality of our approach, establishing a solid foundation for future research in directed graph generation.</li>
</ul>

<h3>Title: Drag-and-Drop LLMs: Zero-Shot Prompt-to-Weights</h3>
<ul>
<li><strong>Authors: </strong>Zhiyuan Liang, Dongwen Tang, Yuhao Zhou, Xuanlei Zhao, Mingjia Shi, Wangbo Zhao, Zekai Li, Peihao Wang, Konstantin Schürholt, Damian Borth, Michael M. Bronstein, Yang You, Zhangyang Wang, Kai Wang</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.16406">https://arxiv.org/abs/2506.16406</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.16406">https://arxiv.org/pdf/2506.16406</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.16406]] Drag-and-Drop LLMs: Zero-Shot Prompt-to-Weights(https://arxiv.org/abs/2506.16406)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, large language model</a></li>
<li><strong>Abstract: </strong>Modern Parameter-Efficient Fine-Tuning (PEFT) methods such as low-rank adaptation (LoRA) reduce the cost of customizing large language models (LLMs), yet still require a separate optimization run for every downstream dataset. We introduce \textbf{Drag-and-Drop LLMs (\textit{DnD})}, a prompt-conditioned parameter generator that eliminates per-task training by mapping a handful of unlabeled task prompts directly to LoRA weight updates. A lightweight text encoder distills each prompt batch into condition embeddings, which are then transformed by a cascaded hyper-convolutional decoder into the full set of LoRA matrices. Once trained in a diverse collection of prompt-checkpoint pairs, DnD produces task-specific parameters in seconds, yielding i) up to \textbf{12,000$\times$} lower overhead than full fine-tuning, ii) average gains up to \textbf{30\%} in performance over the strongest training LoRAs on unseen common-sense reasoning, math, coding, and multimodal benchmarks, and iii) robust cross-domain generalization despite never seeing the target data or labels. Our results demonstrate that prompt-conditioned parameter generation is a viable alternative to gradient-based adaptation for rapidly specializing LLMs. Our project is available at \href{this https URL}{this https URL}.</li>
</ul>

<h3>Title: Robustness Evaluation of OCR-based Visual Document Understanding under Multi-Modal Adversarial Attacks</h3>
<ul>
<li><strong>Authors: </strong>Dong Nguyen Tien, Dung D. Le</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.16407">https://arxiv.org/abs/2506.16407</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.16407">https://arxiv.org/pdf/2506.16407</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.16407]] Robustness Evaluation of OCR-based Visual Document Understanding under Multi-Modal Adversarial Attacks(https://arxiv.org/abs/2506.16407)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack, robust, extraction</a></li>
<li><strong>Abstract: </strong>Visual Document Understanding (VDU) systems have achieved strong performance in information extraction by integrating textual, layout, and visual signals. However, their robustness under realistic adversarial perturbations remains insufficiently explored. We introduce the first unified framework for generating and evaluating multi-modal adversarial attacks on OCR-based VDU models. Our method covers six gradient-based layout attack scenarios, incorporating manipulations of OCR bounding boxes, pixels, and texts across both word and line granularities, with constraints on layout perturbation budget (e.g., IoU >= 0.6) to preserve plausibility. Experimental results across four datasets (FUNSD, CORD, SROIE, DocVQA) and six model families demonstrate that line-level attacks and compound perturbations (BBox + Pixel + Text) yield the most severe performance degradation. Projected Gradient Descent (PGD)-based BBox perturbations outperform random-shift baselines in all investigated models. Ablation studies further validate the impact of layout budget, text modification, and adversarial transferability.</li>
</ul>

<h3>Title: When Does Divide and Conquer Work for Long Context LLM? A Noise Decomposition Framework</h3>
<ul>
<li><strong>Authors: </strong>Zhen Xu, Shang Zhu, Jue Wang, Junlin Wang, Ben Athiwaratkun, Chi Wang, James Zou, Ce Zhang</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.16411">https://arxiv.org/abs/2506.16411</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.16411">https://arxiv.org/pdf/2506.16411</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.16411]] When Does Divide and Conquer Work for Long Context LLM? A Noise Decomposition Framework(https://arxiv.org/abs/2506.16411)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>We investigate the challenge of applying Large Language Models (LLMs) to long texts. We propose a theoretical framework that distinguishes the failure modes of long context tasks into three categories: cross-chunk dependence (task noise), confusion that grows with context size (model noise), and the imperfect integration of partial results (aggregator noise). Under this view, we analyze when it is effective to use multi-agent chunking, i.e., dividing a length sequence into smaller chunks and aggregating the processed results of each chunk. Our experiments on tasks such as retrieval, question answering, and summarization confirm both the theoretical analysis and the conditions that favor multi-agent chunking. By exploring superlinear model noise growth with input length, we also explain why, for large inputs, a weaker model configured with chunk-based processing can surpass a more advanced model like GPT4o applied in a single shot. Overall, we present a principled understanding framework and our results highlight a direct pathway to handling long contexts in LLMs with carefully managed chunking and aggregator strategies.</li>
</ul>

<h3>Title: Optimizing MoE Routers: Design, Implementation, and Evaluation in Transformer Models</h3>
<ul>
<li><strong>Authors: </strong>Daniel Fidel Harvey, George Weale, Berk Yilmaz</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.16419">https://arxiv.org/abs/2506.16419</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.16419">https://arxiv.org/pdf/2506.16419</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.16419]] Optimizing MoE Routers: Design, Implementation, and Evaluation in Transformer Models(https://arxiv.org/abs/2506.16419)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer, large language model</a></li>
<li><strong>Abstract: </strong>Mixture of Experts (MoE) architectures increase large language model scalability, yet their performance depends on the router module that moves tokens to specialized experts. Bad routing can load imbalance and reduced accuracy. This project designed and implemented different router architectures within Transformer models to fix these limitations. We experimented with six distinct router variants Linear, Attention, Multi-Layer Perceptron (MLP), Hybrid, Hash, and our new MLP-Hadamard. We characterized these routers using BERT and the Qwen1.5-MoE model, looking at parameter efficiency, inference latency, routing entropy, and expert utilization patterns. Our evaluations showed distinct trade-offs: Linear routers offer speed, while MLP and Attention routers provide greater expressiveness. The MLP-Hadamard router shows a unique capability for structured, sparse routing. We successfully replaced and fine-tuned custom routers within the complex, quantized Qwen1.5-MoE model. This work provides a comparative analysis of MoE router designs and offers insights into optimizing their performance for efficient and effective large-scale model deployment.</li>
</ul>

<h3>Title: Structured Semantic 3D Reconstruction (S23DR) Challenge 2025 -- Winning solution</h3>
<ul>
<li><strong>Authors: </strong>Jan Skvrna, Lukas Neumann</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.16421">https://arxiv.org/abs/2506.16421</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.16421">https://arxiv.org/pdf/2506.16421</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.16421]] Structured Semantic 3D Reconstruction (S23DR) Challenge 2025 -- Winning solution(https://arxiv.org/abs/2506.16421)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>This paper presents the winning solution for the S23DR Challenge 2025, which involves predicting a house's 3D roof wireframe from a sparse point cloud and semantic segmentations. Our method operates directly in 3D, first identifying vertex candidates from the COLMAP point cloud using Gestalt segmentations. We then employ two PointNet-like models: one to refine and classify these candidates by analyzing local cubic patches, and a second to predict edges by processing the cylindrical regions connecting vertex pairs. This two-stage, 3D deep learning approach achieved a winning Hybrid Structure Score (HSS) of 0.43 on the private leaderboard.</li>
</ul>

<h3>Title: EFormer: An Effective Edge-based Transformer for Vehicle Routing Problems</h3>
<ul>
<li><strong>Authors: </strong>Dian Meng, Zhiguang Cao, Yaoxin Wu, Yaqing Hou, Hongwei Ge, Qiang Zhang</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.16428">https://arxiv.org/abs/2506.16428</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.16428">https://arxiv.org/pdf/2506.16428</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.16428]] EFormer: An Effective Edge-based Transformer for Vehicle Routing Problems(https://arxiv.org/abs/2506.16428)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Recent neural heuristics for the Vehicle Routing Problem (VRP) primarily rely on node coordinates as input, which may be less effective in practical scenarios where real cost metrics-such as edge-based distances-are more relevant. To address this limitation, we introduce EFormer, an Edge-based Transformer model that uses edge as the sole input for VRPs. Our approach employs a precoder module with a mixed-score attention mechanism to convert edge information into temporary node embeddings. We also present a parallel encoding strategy characterized by a graph encoder and a node encoder, each responsible for processing graph and node embeddings in distinct feature spaces, respectively. This design yields a more comprehensive representation of the global relationships among edges. In the decoding phase, parallel context embedding and multi-query integration are used to compute separate attention mechanisms over the two encoded embeddings, facilitating efficient path construction. We train EFormer using reinforcement learning in an autoregressive manner. Extensive experiments on the Traveling Salesman Problem (TSP) and Capacitated Vehicle Routing Problem (CVRP) reveal that EFormer outperforms established baselines on synthetic datasets, including large-scale and diverse distributions. Moreover, EFormer demonstrates strong generalization on real-world instances from TSPLib and CVRPLib. These findings confirm the effectiveness of EFormer's core design in solving VRPs.</li>
</ul>

<h3>Title: Leveraging Influence Functions for Resampling Data in Physics-Informed Neural Networks</h3>
<ul>
<li><strong>Authors: </strong>Jonas R. Naujoks, Aleksander Krasowski, Moritz Weckbecker, Galip Ümit Yolcu, Thomas Wiegand, Sebastian Lapuschkin, Wojciech Samek, René P. Klausen</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, physics.comp-ph</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.16443">https://arxiv.org/abs/2506.16443</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.16443">https://arxiv.org/pdf/2506.16443</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.16443]] Leveraging Influence Functions for Resampling Data in Physics-Informed Neural Networks(https://arxiv.org/abs/2506.16443)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability</a></li>
<li><strong>Abstract: </strong>Physics-informed neural networks (PINNs) offer a powerful approach to solving partial differential equations (PDEs), which are ubiquitous in the quantitative sciences. Applied to both forward and inverse problems across various scientific domains, PINNs have recently emerged as a valuable tool in the field of scientific machine learning. A key aspect of their training is that the data -- spatio-temporal points sampled from the PDE's input domain -- are readily available. Influence functions, a tool from the field of explainable AI (XAI), approximate the effect of individual training points on the model, enhancing interpretability. In the present work, we explore the application of influence function-based sampling approaches for the training data. Our results indicate that such targeted resampling based on data attribution methods has the potential to enhance prediction accuracy in physics-informed neural networks, demonstrating a practical application of an XAI method in PINN training.</li>
</ul>

<h3>Title: REIS: A High-Performance and Energy-Efficient Retrieval System with In-Storage Processing</h3>
<ul>
<li><strong>Authors: </strong>Kangqi Chen, Andreas Kosmas Kakolyris, Rakesh Nadig, Manos Frouzakis, Nika Mansouri Ghiasi, Yu Liang, Haiyu Mao, Jisung Park, Mohammad Sadrosadati, Onur Mutlu</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AR, cs.DB</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.16444">https://arxiv.org/abs/2506.16444</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.16444">https://arxiv.org/pdf/2506.16444</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.16444]] REIS: A High-Performance and Energy-Efficient Retrieval System with In-Storage Processing(https://arxiv.org/abs/2506.16444)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large Language Models (LLMs) face an inherent challenge: their knowledge is confined to the data that they have been trained on. To overcome this issue, Retrieval-Augmented Generation (RAG) complements the static training-derived knowledge of LLMs with an external knowledge repository. RAG consists of three stages: indexing, retrieval, and generation. The retrieval stage of RAG becomes a significant bottleneck in inference pipelines. In this stage, a user query is mapped to an embedding vector and an Approximate Nearest Neighbor Search (ANNS) algorithm searches for similar vectors in the database to identify relevant items. Due to the large database sizes, ANNS incurs significant data movement overheads between the host and the storage system. To alleviate these overheads, prior works propose In-Storage Processing (ISP) techniques that accelerate ANNS by performing computations inside storage. However, existing works that leverage ISP for ANNS (i) employ algorithms that are not tailored to ISP systems, (ii) do not accelerate data retrieval operations for data selected by ANNS, and (iii) introduce significant hardware modifications, limiting performance and hindering their adoption. We propose REIS, the first ISP system tailored for RAG that addresses these limitations with three key mechanisms. First, REIS employs a database layout that links database embedding vectors to their associated documents, enabling efficient retrieval. Second, it enables efficient ANNS by introducing an ISP-tailored data placement technique that distributes embeddings across the planes of the storage system and employs a lightweight Flash Translation Layer. Third, REIS leverages an ANNS engine that uses the existing computational resources inside the storage system. Compared to a server-grade system, REIS improves the performance (energy efficiency) of retrieval by an average of 13x (55x).</li>
</ul>

<h3>Title: StoryWriter: A Multi-Agent Framework for Long Story Generation</h3>
<ul>
<li><strong>Authors: </strong>Haotian Xia, Hao Peng, Yunjia Qi, Xiaozhi Wang, Bin Xu, Lei Hou, Juanzi Li</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.16445">https://arxiv.org/abs/2506.16445</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.16445">https://arxiv.org/pdf/2506.16445</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.16445]] StoryWriter: A Multi-Agent Framework for Long Story Generation(https://arxiv.org/abs/2506.16445)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Long story generation remains a challenge for existing large language models (LLMs), primarily due to two main factors: (1) discourse coherence, which requires plot consistency, logical coherence, and completeness in the long-form generation, and (2) narrative complexity, which requires an interwoven and engaging narrative. To address these challenges, we propose StoryWriter, a multi-agent story generation framework, which consists of three main modules: (1) outline agent, which generates event-based outlines containing rich event plots, character, and event-event relationships. (2) planning agent, which further details events and plans which events should be written in each chapter to maintain an interwoven and engaging story. (3) writing agent, which dynamically compresses the story history based on the current event to generate and reflect new plots, ensuring the coherence of the generated story. We conduct both human and automated evaluation, and StoryWriter significantly outperforms existing story generation baselines in both story quality and length. Furthermore, we use StoryWriter to generate a dataset, which contains about $6,000$ high-quality long stories, with an average length of $8,000$ words. We train the model Llama3.1-8B and GLM4-9B using supervised fine-tuning on LongStory and develop StoryWriter_GLM and StoryWriter_GLM, which demonstrates advanced performance in long story generation.</li>
</ul>

<h3>Title: Probe before You Talk: Towards Black-box Defense against Backdoor Unalignment for Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Biao Yi, Tiansheng Huang, Sishuo Chen, Tong Li, Zheli Liu, Zhixuan Chu, Yiming Li</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.16447">https://arxiv.org/abs/2506.16447</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.16447">https://arxiv.org/pdf/2506.16447</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.16447]] Probe before You Talk: Towards Black-box Defense against Backdoor Unalignment for Large Language Models(https://arxiv.org/abs/2506.16447)</code><input type="text"></li>
<li><strong>Keywords: </strong>defense, attack, steal, large language model</a></li>
<li><strong>Abstract: </strong>Backdoor unalignment attacks against Large Language Models (LLMs) enable the stealthy compromise of safety alignment using a hidden trigger while evading normal safety auditing. These attacks pose significant threats to the applications of LLMs in the real-world Large Language Model as a Service (LLMaaS) setting, where the deployed model is a fully black-box system that can only interact through text. Furthermore, the sample-dependent nature of the attack target exacerbates the threat. Instead of outputting a fixed label, the backdoored LLM follows the semantics of any malicious command with the hidden trigger, significantly expanding the target space. In this paper, we introduce BEAT, a black-box defense that detects triggered samples during inference to deactivate the backdoor. It is motivated by an intriguing observation (dubbed the probe concatenate effect), where concatenated triggered samples significantly reduce the refusal rate of the backdoored LLM towards a malicious probe, while non-triggered samples have little effect. Specifically, BEAT identifies whether an input is triggered by measuring the degree of distortion in the output distribution of the probe before and after concatenation with the input. Our method addresses the challenges of sample-dependent targets from an opposite perspective. It captures the impact of the trigger on the refusal signal (which is sample-independent) instead of sample-specific successful attack behaviors. It overcomes black-box access limitations by using multiple sampling to approximate the output distribution. Extensive experiments are conducted on various backdoor attacks and LLMs (including the closed-source GPT-3.5-turbo), verifying the effectiveness and efficiency of our defense. Besides, we also preliminarily verify that BEAT can effectively defend against popular jailbreak attacks, as they can be regarded as 'natural backdoors'.</li>
</ul>

<h3>Title: Consumer-friendly EEG-based Emotion Recognition System: A Multi-scale Convolutional Neural Network Approach</h3>
<ul>
<li><strong>Authors: </strong>Tri Duc Ly, Gia H. Ngo</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.16448">https://arxiv.org/abs/2506.16448</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.16448">https://arxiv.org/pdf/2506.16448</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.16448]] Consumer-friendly EEG-based Emotion Recognition System: A Multi-scale Convolutional Neural Network Approach(https://arxiv.org/abs/2506.16448)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction</a></li>
<li><strong>Abstract: </strong>EEG is a non-invasive, safe, and low-risk method to record electrophysiological signals inside the brain. Especially with recent technology developments like dry electrodes, consumer-grade EEG devices, and rapid advances in machine learning, EEG is commonly used as a resource for automatic emotion recognition. With the aim to develop a deep learning model that can perform EEG-based emotion recognition in a real-life context, we propose a novel approach to utilize multi-scale convolutional neural networks to accomplish such tasks. By implementing feature extraction kernels with many ratio coefficients as well as a new type of kernel that learns key information from four separate areas of the brain, our model consistently outperforms the state-of-the-art TSception model in predicting valence, arousal, and dominance scores across many performance evaluation metrics.</li>
</ul>

<h3>Title: How Far Can Off-the-Shelf Multimodal Large Language Models Go in Online Episodic Memory Question Answering?</h3>
<ul>
<li><strong>Authors: </strong>Giuseppe Lando, Rosario Forte, Giovanni Maria Farinella, Antonino Furnari</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.16450">https://arxiv.org/abs/2506.16450</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.16450">https://arxiv.org/pdf/2506.16450</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.16450]] How Far Can Off-the-Shelf Multimodal Large Language Models Go in Online Episodic Memory Question Answering?(https://arxiv.org/abs/2506.16450)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>We investigate whether off-the-shelf Multimodal Large Language Models (MLLMs) can tackle Online Episodic-Memory Video Question Answering (OEM-VQA) without additional training. Our pipeline converts a streaming egocentric video into a lightweight textual memory, only a few kilobytes per minute, via an MLLM descriptor module, and answers multiple-choice questions by querying this memory with an LLM reasoner module. On the QAEgo4D-Closed benchmark, our best configuration attains 56.0% accuracy with 3.6 kB per minute storage, matching the performance of dedicated state-of-the-art systems while being 10**4/10**5 times more memory-efficient. Extensive ablations provides insights into the role of each component and design choice, and highlight directions of improvement for future research.</li>
</ul>

<h3>Title: SecureFed: A Two-Phase Framework for Detecting Malicious Clients in Federated Learning</h3>
<ul>
<li><strong>Authors: </strong>Likhitha Annapurna Kavuri, Akshay Mhatre, Akarsh K Nair, Deepti Gupta</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.16458">https://arxiv.org/abs/2506.16458</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.16458">https://arxiv.org/pdf/2506.16458</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.16458]] SecureFed: A Two-Phase Framework for Detecting Malicious Clients in Federated Learning(https://arxiv.org/abs/2506.16458)</code><input type="text"></li>
<li><strong>Keywords: </strong>secure, privacy, protect, defense, attack, federate</a></li>
<li><strong>Abstract: </strong>Federated Learning (FL) protects data privacy while providing a decentralized method for training models. However, because of the distributed schema, it is susceptible to adversarial clients that could alter results or sabotage model performance. This study presents SecureFed, a two-phase FL framework for identifying and reducing the impact of such attackers. Phase 1 involves collecting model updates from participating clients and applying a dimensionality reduction approach to identify outlier patterns frequently associated with malicious behavior. Temporary models constructed from the client updates are evaluated on synthetic datasets to compute validation losses and support anomaly scoring. The idea of learning zones is presented in Phase 2, where weights are dynamically routed according to their contribution scores and gradient magnitudes. High-value gradient zones are given greater weight in aggregation and contribute more significantly to the global model, while lower-value gradient zones, which may indicate possible adversarial activity, are gradually removed from training. Until the model converges and a strong defense against poisoning attacks is possible, this training cycle continues Based on the experimental findings, SecureFed considerably improves model resilience without compromising model performance.</li>
</ul>

<h3>Title: Black-Box Privacy Attacks on Shared Representations in Multitask Learning</h3>
<ul>
<li><strong>Authors: </strong>John Abascal, Nicolás Berrios, Alina Oprea, Jonathan Ullman, Adam Smith, Matthew Jagielski</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.16460">https://arxiv.org/abs/2506.16460</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.16460">https://arxiv.org/pdf/2506.16460</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.16460]] Black-Box Privacy Attacks on Shared Representations in Multitask Learning(https://arxiv.org/abs/2506.16460)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, attack</a></li>
<li><strong>Abstract: </strong>Multitask learning (MTL) has emerged as a powerful paradigm that leverages similarities among multiple learning tasks, each with insufficient samples to train a standalone model, to solve them simultaneously while minimizing data sharing across users and organizations. MTL typically accomplishes this goal by learning a shared representation that captures common structure among the tasks by embedding data from all tasks into a common feature space. Despite being designed to be the smallest unit of shared information necessary to effectively learn patterns across multiple tasks, these shared representations can inadvertently leak sensitive information about the particular tasks they were trained on. In this work, we investigate what information is revealed by the shared representations through the lens of inference attacks. Towards this, we propose a novel, black-box task-inference threat model where the adversary, given the embedding vectors produced by querying the shared representation on samples from a particular task, aims to determine whether that task was present when training the shared representation. We develop efficient, purely black-box attacks on machine learning models that exploit the dependencies between embeddings from the same task without requiring shadow models or labeled reference data. We evaluate our attacks across vision and language domains for multiple use cases of MTL and demonstrate that even with access only to fresh task samples rather than training data, a black-box adversary can successfully infer a task's inclusion in training. To complement our experiments, we provide theoretical analysis of a simplified learning setting and show a strict separation between adversaries with training samples and fresh samples from the target task's distribution.</li>
</ul>

<h3>Title: Progressive Inference-Time Annealing of Diffusion Models for Sampling from Boltzmann Densities</h3>
<ul>
<li><strong>Authors: </strong>Tara Akhound-Sadegh, Jungyoon Lee, Avishek Joey Bose, Valentin De Bortoli, Arnaud Doucet, Michael M. Bronstein, Dominique Beaini, Siamak Ravanbakhsh, Kirill Neklyudov, Alexander Tong</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.16471">https://arxiv.org/abs/2506.16471</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.16471">https://arxiv.org/pdf/2506.16471</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.16471]] Progressive Inference-Time Annealing of Diffusion Models for Sampling from Boltzmann Densities(https://arxiv.org/abs/2506.16471)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, generative</a></li>
<li><strong>Abstract: </strong>Sampling efficiently from a target unnormalized probability density remains a core challenge, with relevance across countless high-impact scientific applications. A promising approach towards this challenge is the design of amortized samplers that borrow key ideas, such as probability path design, from state-of-the-art generative diffusion models. However, all existing diffusion-based samplers remain unable to draw samples from distributions at the scale of even simple molecular systems. In this paper, we propose Progressive Inference-Time Annealing (PITA), a novel framework to learn diffusion-based samplers that combines two complementary interpolation techniques: I.) Annealing of the Boltzmann distribution and II.) Diffusion smoothing. PITA trains a sequence of diffusion models from high to low temperatures by sequentially training each model at progressively higher temperatures, leveraging engineered easy access to samples of the temperature-annealed target density. In the subsequent step, PITA enables simulating the trained diffusion model to procure training samples at a lower temperature for the next diffusion model through inference-time annealing using a novel Feynman-Kac PDE combined with Sequential Monte Carlo. Empirically, PITA enables, for the first time, equilibrium sampling of N-body particle systems, Alanine Dipeptide, and tripeptides in Cartesian coordinates with dramatically lower energy function evaluations. Code available at: this https URL</li>
</ul>

<h3>Title: Spotting tell-tale visual artifacts in face swapping videos: strengths and pitfalls of CNN detectors</h3>
<ul>
<li><strong>Authors: </strong>Riccardo Ziglio, Cecilia Pasquini, Silvio Ranise</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI, cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.16497">https://arxiv.org/abs/2506.16497</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.16497">https://arxiv.org/pdf/2506.16497</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.16497]] Spotting tell-tale visual artifacts in face swapping videos: strengths and pitfalls of CNN detectors(https://arxiv.org/abs/2506.16497)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Face swapping manipulations in video streams represents an increasing threat in remote video communications, due to advances in automated and real-time tools. Recent literature proposes to characterize and exploit visual artifacts introduced in video frames by swapping algorithms when dealing with challenging physical scenes, such as face occlusions. This paper investigates the effectiveness of this approach by benchmarking CNN-based data-driven models on two data corpora (including a newly collected one) and analyzing generalization capabilities with respect to different acquisition sources and swapping algorithms. The results confirm excellent performance of general-purpose CNN architectures when operating within the same data source, but a significant difficulty in robustly characterizing occlusion-based visual cues across datasets. This highlights the need for specialized detection strategies to deal with such artifacts.</li>
</ul>

<h3>Title: Relic: Enhancing Reward Model Generalization for Low-Resource Indic Languages with Few-Shot Examples</h3>
<ul>
<li><strong>Authors: </strong>Soumya Suvra Ghosal, Vaibhav Singh, Akash Ghosh, Soumyabrata Pal, Subhadip Baidya, Sriparna Saha, Dinesh Manocha</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.16502">https://arxiv.org/abs/2506.16502</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.16502">https://arxiv.org/pdf/2506.16502</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.16502]] Relic: Enhancing Reward Model Generalization for Low-Resource Indic Languages with Few-Shot Examples(https://arxiv.org/abs/2506.16502)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Reward models are essential for aligning large language models (LLMs) with human preferences. However, most open-source multilingual reward models are primarily trained on preference datasets in high-resource languages, resulting in unreliable reward signals for low-resource Indic languages. Collecting large-scale, high-quality preference data for these languages is prohibitively expensive, making preference-based training approaches impractical. To address this challenge, we propose RELIC, a novel in-context learning framework for reward modeling in low-resource Indic languages. RELIC trains a retriever with a pairwise ranking objective to select in-context examples from auxiliary high-resource languages that most effectively highlight the distinction between preferred and less-preferred responses. Extensive experiments on three preference datasets- PKU-SafeRLHF, WebGPT, and HH-RLHF-using state-of-the-art open-source reward models demonstrate that RELIC significantly improves reward model accuracy for low-resource Indic languages, consistently outperforming existing example selection methods. For example, on Bodo-a low-resource Indic language-using a LLaMA-3.2-3B reward model, RELIC achieves a 12.81% and 10.13% improvement in accuracy over zero-shot prompting and state-of-the-art example selection method, respectively.</li>
</ul>

<h3>Title: Hunyuan3D 2.5: Towards High-Fidelity 3D Assets Generation with Ultimate Details</h3>
<ul>
<li><strong>Authors: </strong>Zeqiang Lai, Yunfei Zhao, Haolin Liu, Zibo Zhao, Qingxiang Lin, Huiwen Shi, Xianghui Yang, Mingxin Yang, Shuhui Yang, Yifei Feng, Sheng Zhang, Xin Huang, Di Luo, Fan Yang, Fang Yang, Lifu Wang, Sicong Liu, Yixuan Tang, Yulin Cai, Zebin He, Tian Liu, Yuhong Liu, Jie Jiang, Linus, Jingwei Huang, Chunchao Guo</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.16504">https://arxiv.org/abs/2506.16504</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.16504">https://arxiv.org/pdf/2506.16504</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.16504]] Hunyuan3D 2.5: Towards High-Fidelity 3D Assets Generation with Ultimate Details(https://arxiv.org/abs/2506.16504)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, diffusion</a></li>
<li><strong>Abstract: </strong>In this report, we present Hunyuan3D 2.5, a robust suite of 3D diffusion models aimed at generating high-fidelity and detailed textured 3D assets. Hunyuan3D 2.5 follows two-stages pipeline of its previous version Hunyuan3D 2.0, while demonstrating substantial advancements in both shape and texture generation. In terms of shape generation, we introduce a new shape foundation model -- LATTICE, which is trained with scaled high-quality datasets, model-size, and compute. Our largest model reaches 10B parameters and generates sharp and detailed 3D shape with precise image-3D following while keeping mesh surface clean and smooth, significantly closing the gap between generated and handcrafted 3D shapes. In terms of texture generation, it is upgraded with phyiscal-based rendering (PBR) via a novel multi-view architecture extended from Hunyuan3D 2.0 Paint model. Our extensive evaluation shows that Hunyuan3D 2.5 significantly outperforms previous methods in both shape and end-to-end texture generation.</li>
</ul>

<h3>Title: Robust Reward Modeling via Causal Rubrics</h3>
<ul>
<li><strong>Authors: </strong>Pragya Srivastava, Harman Singh, Rahul Madhavan, Gandharv Patil, Sravanti Addepalli, Arun Suggala, Rengarajan Aravamudhan, Soumya Sharma, Anirban Laha, Aravindan Raghuveer, Karthikeyan Shanmugam, Doina Precup</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.16507">https://arxiv.org/abs/2506.16507</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.16507">https://arxiv.org/pdf/2506.16507</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.16507]] Robust Reward Modeling via Causal Rubrics(https://arxiv.org/abs/2506.16507)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, large language model</a></li>
<li><strong>Abstract: </strong>Reward models (RMs) are fundamental to aligning Large Language Models (LLMs) via human feedback, yet they often suffer from reward hacking. They tend to latch on to superficial or spurious attributes, such as response length or formatting, mistaking these cues learned from correlations in training data for the true causal drivers of quality (e.g., factuality, relevance). This occurs because standard training objectives struggle to disentangle these factors, leading to brittle RMs and misaligned policies. We introduce Crome (Causally Robust Reward Modeling), a novel framework grounded in an explicit causal model designed to mitigate reward hacking. Crome employs the following synthetic targeted augmentations during training: (1) Causal Augmentations, which are pairs that differ along specific causal attributes, to enforce sensitivity along each causal attribute individually, and (2) Neutral Augmentations, which are tie-label pairs varying primarily in spurious attributes, to enforce invariance along spurious attributes. Notably, our augmentations are produced without any knowledge of spurious factors, via answer interventions only along causal rubrics, that are identified by querying an oracle LLM. Empirically, Crome significantly outperforms standard baselines on RewardBench, improving average accuracy by up to 5.4% and achieving gains of up to 13.2% and 7.2% in specific categories. The robustness of Crome is further testified by the consistent gains obtained in a Best-of-N inference setting across increasing N, across various benchmarks, including the popular RewardBench (covering chat, chat-hard, safety, and reasoning tasks), the safety-focused WildGuardTest, and the reasoning-specific GSM8k.</li>
</ul>

<h3>Title: SAFER-D: A Self-Adaptive Security Framework for Distributed Computing Architectures</h3>
<ul>
<li><strong>Authors: </strong>Marco Stadler, Michael Vierhauser, Michael Riegler, Daniel Waghubinger, Johannes Sametinger</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.NI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.16545">https://arxiv.org/abs/2506.16545</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.16545">https://arxiv.org/pdf/2506.16545</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.16545]] SAFER-D: A Self-Adaptive Security Framework for Distributed Computing Architectures(https://arxiv.org/abs/2506.16545)</code><input type="text"></li>
<li><strong>Keywords: </strong>secure, security, protect, defense, attack, robust</a></li>
<li><strong>Abstract: </strong>The rise of the Internet of Things and Cyber-Physical Systems has introduced new challenges on ensuring secure and robust communication. The growing number of connected devices increases network complexity, leading to higher latency and traffic. Distributed computing architectures (DCAs) have gained prominence to address these issues. This shift has significantly expanded the attack surface, requiring additional security measures to protect all components -- from sensors and actuators to edge nodes and central servers. Recent incidents highlight the difficulty of this task: Cyberattacks, like distributed denial of service attacks, continue to pose severe threats and cause substantial damage. Implementing a holistic defense mechanism remains an open challenge, particularly against attacks that demand both enhanced resilience and rapid response. Addressing this gap requires innovative solutions to enhance the security of DCAs. In this work, we present our holistic self-adaptive security framework which combines different adaptation strategies to create comprehensive and efficient defense mechanisms. We describe how to incorporate the framework into a real-world use case scenario and further evaluate its applicability and efficiency. Our evaluation yields promising results, indicating great potential to further extend the research on our framework.</li>
</ul>

<h3>Title: Mr. Snuffleupagus at SemEval-2025 Task 4: Unlearning Factual Knowledge from LLMs Using Adaptive RMU</h3>
<ul>
<li><strong>Authors: </strong>Arjun Dosajh, Mihika Sanghi</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.16548">https://arxiv.org/abs/2506.16548</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.16548">https://arxiv.org/pdf/2506.16548</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.16548]] Mr. Snuffleupagus at SemEval-2025 Task 4: Unlearning Factual Knowledge from LLMs Using Adaptive RMU(https://arxiv.org/abs/2506.16548)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, privacy, large language model</a></li>
<li><strong>Abstract: </strong>Large Language Models (LLMs) have demonstrated remarkable capabilities in natural language understanding and generation. However, their tendency to memorize training data raises concerns regarding privacy, copyright compliance, and security, particularly in cases involving Personally Identifiable Information (PII). Effective machine unlearning techniques are essential to mitigate these risks, yet existing methods remain underdeveloped for LLMs due to their open-ended output space. In this work, we apply the Adaptive Representation Misdirection Unlearning (RMU) technique to unlearn sensitive information from LLMs. Through extensive experiments, we analyze the effects of unlearning across different decoder layers to determine the most effective regions for sensitive information removal. Our technique ranked 4th on the official leaderboard of both 1B parameter and 7B parameter models.</li>
</ul>

<h3>Title: A Free Probabilistic Framework for Analyzing the Transformer-based Language Models</h3>
<ul>
<li><strong>Authors: </strong>Swagatam Das</a></li>
<li><strong>Subjects: </strong>cs.LG, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.16550">https://arxiv.org/abs/2506.16550</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.16550">https://arxiv.org/pdf/2506.16550</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.16550]] A Free Probabilistic Framework for Analyzing the Transformer-based Language Models(https://arxiv.org/abs/2506.16550)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer, large language model</a></li>
<li><strong>Abstract: </strong>We outline an operator-theoretic framework for analyzing transformer-based language models using the tools of free probability theory. By representing token embeddings and attention mechanisms as self-adjoint operators in a racial probability space, we reinterpret attention as a non-commutative convolution and view the layer-wise propagation of representations as an evolution governed by free additive convolution. This formalism reveals a spectral dynamical system underpinning deep transformer stacks and offers insight into their inductive biases, generalization behavior, and entropy dynamics. We derive a generalization bound based on free entropy and demonstrate that the spectral trace of transformer layers evolves predictably with depth. Our approach bridges neural architecture with non-commutative harmonic analysis, enabling principled analysis of information flow and structural complexity in large language models</li>
</ul>

<h3>Title: One Sample is Enough to Make Conformal Prediction Robust</h3>
<ul>
<li><strong>Authors: </strong>Soroush H. Zargarbashi, Mohammad Sadegh Akhondzadeh, Aleksandar Bojchevski</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.16553">https://arxiv.org/abs/2506.16553</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.16553">https://arxiv.org/pdf/2506.16553</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.16553]] One Sample is Enough to Make Conformal Prediction Robust(https://arxiv.org/abs/2506.16553)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Given any model, conformal prediction (CP) returns prediction sets guaranteed to include the true label with high adjustable probability. Robust CP (RCP) extends this to inputs with worst-case noise. A well-established approach is to use randomized smoothing for RCP since it is applicable to any black-box model and provides smaller sets compared to deterministic methods. However, current smoothing-based RCP requires many model forward passes per each input which is computationally expensive. We show that conformal prediction attains some robustness even with a forward pass on a single randomly perturbed input. Using any binary certificate we propose a single sample robust CP (RCP1). Our approach returns robust sets with smaller average set size compared to SOTA methods which use many (e.g. around 100) passes per input. Our key insight is to certify the conformal prediction procedure itself rather than individual scores. Our approach is agnostic to the setup (classification and regression). We further extend our approach to smoothing-based robust conformal risk control.</li>
</ul>

<h3>Title: From Semantic To Instance: A Semi-Self-Supervised Learning Approach</h3>
<ul>
<li><strong>Authors: </strong>Keyhan Najafian, Farhad Maleki, Lingling Jin, Ian Stavness</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.16563">https://arxiv.org/abs/2506.16563</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.16563">https://arxiv.org/pdf/2506.16563</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.16563]] From Semantic To Instance: A Semi-Self-Supervised Learning Approach(https://arxiv.org/abs/2506.16563)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>Instance segmentation is essential for applications such as automated monitoring of plant health, growth, and yield. However, extensive effort is required to create large-scale datasets with pixel-level annotations of each object instance for developing instance segmentation models that restrict the use of deep learning in these areas. This challenge is more significant in images with densely packed, self-occluded objects, which are common in agriculture. To address this challenge, we propose a semi-self-supervised learning approach that requires minimal manual annotation to develop a high-performing instance segmentation model. We design GLMask, an image-mask representation for the model to focus on shape, texture, and pattern while minimizing its dependence on color features. We develop a pipeline to generate semantic segmentation and then transform it into instance-level segmentation. The proposed approach substantially outperforms the conventional instance segmentation models, establishing a state-of-the-art wheat head instance segmentation model with mAP@50 of 98.5%. Additionally, we assessed the proposed methodology on the general-purpose Microsoft COCO dataset, achieving a significant performance improvement of over 12.6% mAP@50. This highlights that the utility of our proposed approach extends beyond precision agriculture and applies to other domains, specifically those with similar data characteristics.</li>
</ul>

<h3>Title: SafeTriage: Facial Video De-identification for Privacy-Preserving Stroke Triage</h3>
<ul>
<li><strong>Authors: </strong>Tongan Cai, Haomiao Ni, Wenchao Ma, Yuan Xue, Qian Ma, Rachel Leicht, Kelvin Wong, John Volpi, Stephen T.C. Wong, James Z. Wang, Sharon X. Huang</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.16578">https://arxiv.org/abs/2506.16578</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.16578">https://arxiv.org/pdf/2506.16578</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.16578]] SafeTriage: Facial Video De-identification for Privacy-Preserving Stroke Triage(https://arxiv.org/abs/2506.16578)</code><input type="text"></li>
<li><strong>Keywords: </strong>secure, privacy, protect, robust, generative</a></li>
<li><strong>Abstract: </strong>Effective stroke triage in emergency settings often relies on clinicians' ability to identify subtle abnormalities in facial muscle coordination. While recent AI models have shown promise in detecting such patterns from patient facial videos, their reliance on real patient data raises significant ethical and privacy challenges -- especially when training robust and generalizable models across institutions. To address these concerns, we propose SafeTriage, a novel method designed to de-identify patient facial videos while preserving essential motion cues crucial for stroke diagnosis. SafeTriage leverages a pretrained video motion transfer (VMT) model to map the motion characteristics of real patient faces onto synthetic identities. This approach retains diagnostically relevant facial dynamics without revealing the patients' identities. To mitigate the distribution shift between normal population pre-training videos and patient population test videos, we introduce a conditional generative model for visual prompt tuning, which adapts the input space of the VMT model to ensure accurate motion transfer without needing to fine-tune the VMT model backbone. Comprehensive evaluation, including quantitative metrics and clinical expert assessments, demonstrates that SafeTriage-produced synthetic videos effectively preserve stroke-relevant facial patterns, enabling reliable AI-based triage. Our evaluations also show that SafeTriage provides robust privacy protection while maintaining diagnostic accuracy, offering a secure and ethically sound foundation for data sharing and AI-driven clinical analysis in neurological disorders.</li>
</ul>

<h3>Title: Measuring (a Sufficient) World Model in LLMs: A Variance Decomposition Framework</h3>
<ul>
<li><strong>Authors: </strong>Nadav Kunievsky, James A. Evans</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.16584">https://arxiv.org/abs/2506.16584</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.16584">https://arxiv.org/pdf/2506.16584</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.16584]] Measuring (a Sufficient) World Model in LLMs: A Variance Decomposition Framework(https://arxiv.org/abs/2506.16584)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, large language model</a></li>
<li><strong>Abstract: </strong>Understanding whether large language models (LLMs) possess a world model-a structured understanding of the world that supports generalization beyond surface-level patterns-is central to assessing their reliability, especially in high-stakes applications. We propose a formal framework for evaluating whether an LLM exhibits a sufficiently robust world model, defined as producing consistent outputs across semantically equivalent prompts while distinguishing between prompts that express different intents. We introduce a new evaluation approach to measure this that decomposes model response variability into three components: variability due to user purpose, user articulation, and model instability. An LLM with a strong world model should attribute most of the variability in its responses to changes in foundational purpose rather than superficial changes in articulation. This approach allows us to quantify how much of a model's behavior is semantically grounded rather than driven by model instability or alternative wording. We apply this framework to evaluate LLMs across diverse domains. Our results show how larger models attribute a greater share of output variability to changes in user purpose, indicating a more robust world model. This improvement is not uniform, however: larger models do not consistently outperform smaller ones across all domains, and their advantage in robustness is often modest. These findings highlight the importance of moving beyond accuracy-based benchmarks toward semantic diagnostics that more directly assess the structure and stability of a model's internal understanding of the world.</li>
</ul>

<h3>Title: Spatially-Aware Evaluation of Segmentation Uncertainty</h3>
<ul>
<li><strong>Authors: </strong>Tal Zeevi, Eléonore V. Lieffrig, Lawrence H. Staib, John A. Onofrey</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI, cs.PF, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.16589">https://arxiv.org/abs/2506.16589</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.16589">https://arxiv.org/pdf/2506.16589</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.16589]] Spatially-Aware Evaluation of Segmentation Uncertainty(https://arxiv.org/abs/2506.16589)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>Uncertainty maps highlight unreliable regions in segmentation predictions. However, most uncertainty evaluation metrics treat voxels independently, ignoring spatial context and anatomical structure. As a result, they may assign identical scores to qualitatively distinct patterns (e.g., scattered vs. boundary-aligned uncertainty). We propose three spatially aware metrics that incorporate structural and boundary information and conduct a thorough validation on medical imaging data from the prostate zonal segmentation challenge within the Medical Segmentation Decathlon. Our results demonstrate improved alignment with clinically important factors and better discrimination between meaningful and spurious uncertainty patterns.</li>
</ul>

<h3>Title: A Scoping Review of Synthetic Data Generation for Biomedical Research and Applications</h3>
<ul>
<li><strong>Authors: </strong>Hanshu Rao, Weisi Liu, Haohan Wang, I-Chan Huang, Zhe He, Xiaolei Huang</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.16594">https://arxiv.org/abs/2506.16594</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.16594">https://arxiv.org/pdf/2506.16594</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.16594]] A Scoping Review of Synthetic Data Generation for Biomedical Research and Applications(https://arxiv.org/abs/2506.16594)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, large language model</a></li>
<li><strong>Abstract: </strong>Synthetic data generation--mitigating data scarcity, privacy concerns, and data quality challenges in biomedical fields--has been facilitated by rapid advances of large language models (LLMs). This scoping review follows PRISMA-ScR guidelines and synthesizes 59 studies, published between 2020 and 2025 and collected from PubMed, ACM, Web of Science, and Google Scholar. The review systematically examines biomedical research and application trends in synthetic data generation, emphasizing clinical applications, methodologies, and evaluations. Our analysis identifies data modalities of unstructured texts (78.0%), tabular data (13.6%), and multimodal sources (8.4%); generation methods of prompting (72.9%), fine-tuning (22.0%) LLMs and specialized model (5.1%); and heterogeneous evaluations of intrinsic metrics (27.1%), human-in-the-loop assessments (55.9%), and LLM-based evaluations (13.6%). The analysis addresses current limitations in what, where, and how health professionals can leverage synthetic data generation for biomedical domains. Our review also highlights challenges in adaption across clinical domains, resource and model accessibility, and evaluation standardizations.</li>
</ul>

<h3>Title: FLAME: Towards Federated Fine-Tuning Large Language Models Through Adaptive SMoE</h3>
<ul>
<li><strong>Authors: </strong>Khiem Le, Tuan Tran, Ting Hua, Nitesh V. Chawla</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.16600">https://arxiv.org/abs/2506.16600</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.16600">https://arxiv.org/pdf/2506.16600</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.16600]] FLAME: Towards Federated Fine-Tuning Large Language Models Through Adaptive SMoE(https://arxiv.org/abs/2506.16600)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, federate, large language model</a></li>
<li><strong>Abstract: </strong>Existing resource-adaptive LoRA federated fine-tuning methods enable clients to fine-tune models using compressed versions of global LoRA matrices, in order to accommodate various compute resources across clients. This compression requirement will lead to suboptimal performance due to information loss. To address this, we propose FLAME, a novel federated learning framework based on the Sparse Mixture-of-Experts (SMoE) architecture. Unlike prior approaches, FLAME retains full (uncompressed) global LoRA matrices and achieves client-side adaptability by varying the number of activated experts per client. However, incorporating SMoE into federated learning introduces unique challenges, specifically, the mismatch in output magnitude from partial expert activation and the imbalance in expert training quality across clients. FLAME tackles these challenges through a lightweight rescaling mechanism and an activation-aware aggregation scheme. Empirical results across diverse computational settings demonstrate that FLAME consistently outperforms existing methods, providing a robust and effective solution for resource-adaptive federated learning.</li>
</ul>

<h3>Title: MetaQAP -- A Meta-Learning Approach for Quality-Aware Pretraining in Image Quality Assessment</h3>
<ul>
<li><strong>Authors: </strong>Muhammad Azeem Aslam, Muhammad Hamza, Nisar Ahmed, Gulshan Saleem, Zhu Shuangtong, Hu Hongfei, Xu Wei, Saba Aslam, Wang Jun</a></li>
<li><strong>Subjects: </strong>cs.CV, eess.IV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.16601">https://arxiv.org/abs/2506.16601</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.16601">https://arxiv.org/pdf/2506.16601</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.16601]] MetaQAP -- A Meta-Learning Approach for Quality-Aware Pretraining in Image Quality Assessment(https://arxiv.org/abs/2506.16601)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Image Quality Assessment (IQA) is a critical task in a wide range of applications but remains challenging due to the subjective nature of human perception and the complexity of real-world image distortions. This study proposes MetaQAP, a novel no-reference IQA model designed to address these challenges by leveraging quality-aware pre-training and meta-learning. The model performs three key contributions: pre-training Convolutional Neural Networks (CNNs) on a quality-aware dataset, implementing a quality-aware loss function to optimize predictions, and integrating a meta-learner to form an ensemble model that effectively combines predictions from multiple base models. Experimental evaluations were conducted on three benchmark datasets: LiveCD, KonIQ-10K, and BIQ2021. The proposed MetaQAP model achieved exceptional performance with Pearson Linear Correlation Coefficient (PLCC) and Spearman Rank Order Correlation Coefficient (SROCC) scores of 0.9885/0.9812 on LiveCD, 0.9702/0.9658 on KonIQ-10K, and 0.884/0.8765 on BIQ2021, outperforming existing IQA methods. Cross-dataset evaluations further demonstrated the generalizability of the model, with PLCC and SROCC scores ranging from 0.6721 to 0.8023 and 0.6515 to 0.7805, respectively, across diverse datasets. The ablation study confirmed the significance of each model component, revealing substantial performance degradation when critical elements such as the meta-learner or quality-aware loss function were omitted. MetaQAP not only addresses the complexities of authentic distortions but also establishes a robust and generalizable framework for practical IQA applications. By advancing the state-of-the-art in no-reference IQA, this research provides valuable insights and methodologies for future improvements and extensions in the field.</li>
</ul>

<h3>Title: Centre driven Controlled Evolution of Wireless Virtual Networks based on Broadcast Tokens</h3>
<ul>
<li><strong>Authors: </strong>Vignesh Babu, Atishay Jain, Kannan Karthik</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.16615">https://arxiv.org/abs/2506.16615</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.16615">https://arxiv.org/pdf/2506.16615</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.16615]] Centre driven Controlled Evolution of Wireless Virtual Networks based on Broadcast Tokens(https://arxiv.org/abs/2506.16615)</code><input type="text"></li>
<li><strong>Keywords: </strong>secure</a></li>
<li><strong>Abstract: </strong>In a wireless sensor network, the virtual connectivity between nodes is a function of the keys shared between various nodes. Pre-embedding these key configurations in the nodes would make the network inflexible. On the other hand, permitting subsets of nodes to engage in a common key synthesis phase to create secure distributed connections amongst themselves, would decouple and conceal the information flow from the controlling centre. An intermediate solution is the notion of a centre driven key generation process through broadcast tokens, designed to extract different keys in different nodes based on some prior information stored at the nodes. As more tokens arrive, the virtual connectivity of the nodes are altered and the network evolves. This evolution can be distributed and can be controlled to converge to a certain specific connectivity profile. In this paper we present a framework and an algorithm which controls the simultaneous and distributed key release in different nodes, resulting in the creation of parallel virtual multicast groups. The design of the node shares and the supporting broadcast tokens have been discussed in conjunction with the process of balancing the spans of individual groups with spans of several coexistent multicast groups.</li>
</ul>

<h3>Title: Few-Shot Learning-Based Cyber Incident Detection with Augmented Context Intelligence</h3>
<ul>
<li><strong>Authors: </strong>Fei Zuo, Junghwan Rhee, Yung Ryn Choe, Chenglong Fu, Xianshan Qu</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.16626">https://arxiv.org/abs/2506.16626</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.16626">https://arxiv.org/pdf/2506.16626</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.16626]] Few-Shot Learning-Based Cyber Incident Detection with Augmented Context Intelligence(https://arxiv.org/abs/2506.16626)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, protect, attack, robust, extraction</a></li>
<li><strong>Abstract: </strong>In recent years, the adoption of cloud services has been expanding at an unprecedented rate. As more and more organizations migrate or deploy their businesses to the cloud, a multitude of related cybersecurity incidents such as data breaches are on the rise. Many inherent attributes of cloud environments, for example, data sharing, remote access, dynamicity and scalability, pose significant challenges for the protection of cloud security. Even worse, cyber threats are becoming increasingly sophisticated and covert. Attack methods, such as Advanced Persistent Threats (APTs), are continually developed to bypass traditional security measures. Among the emerging technologies for robust threat detection, system provenance analysis is being considered as a promising mechanism, thus attracting widespread attention in the field of incident response. This paper proposes a new few-shot learning-based attack detection with improved data context intelligence. We collect operating system behavior data of cloud systems during realistic attacks and leverage an innovative semiotics extraction method to describe system events. Inspired by the advances in semantic analysis, which is a fruitful area focused on understanding natural languages in computational linguistics, we further convert the anomaly detection problem into a similarity comparison problem. Comprehensive experiments show that the proposed approach is able to generalize over unseen attacks and make accurate predictions, even if the incident detection models are trained with very limited samples.</li>
</ul>

<h3>Title: Initial Investigation of LLM-Assisted Development of Rule-Based Clinical NLP System</h3>
<ul>
<li><strong>Authors: </strong>Jianlin Shi, Brian T. Bucher</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.16628">https://arxiv.org/abs/2506.16628</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.16628">https://arxiv.org/pdf/2506.16628</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.16628]] Initial Investigation of LLM-Assisted Development of Rule-Based Clinical NLP System(https://arxiv.org/abs/2506.16628)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability, large language model</a></li>
<li><strong>Abstract: </strong>Despite advances in machine learning (ML) and large language models (LLMs), rule-based natural language processing (NLP) systems remain active in clinical settings due to their interpretability and operational efficiency. However, their manual development and maintenance are labor-intensive, particularly in tasks with large linguistic variability. To overcome these limitations, we proposed a novel approach employing LLMs solely during the rule-based systems development phase. We conducted the initial experiments focusing on the first two steps of developing a rule-based NLP pipeline: find relevant snippets from the clinical note; extract informative keywords from the snippets for the rule-based named entity recognition (NER) component. Our experiments demonstrated exceptional recall in identifying clinically relevant text snippets (Deepseek: 0.98, Qwen: 0.99) and 1.0 in extracting key terms for NER. This study sheds light on a promising new direction for NLP development, enabling semi-automated or automated development of rule-based systems with significantly faster, more cost-effective, and transparent execution compared with deep learning model-based solutions.</li>
</ul>

<h3>Title: Long-Context Generalization with Sparse Attention</h3>
<ul>
<li><strong>Authors: </strong>Pavlo Vasylenko, Marcos Treviso, André F. T. Martins</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.16640">https://arxiv.org/abs/2506.16640</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.16640">https://arxiv.org/pdf/2506.16640</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.16640]] Long-Context Generalization with Sparse Attention(https://arxiv.org/abs/2506.16640)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Transformer-based architectures traditionally employ softmax to compute attention weights, which produces dense distributions over all tokens in a sequence. While effective in many settings, this density has been shown to be detrimental for tasks that demand precise focus on fixed-size patterns: as sequence length increases, non-informative tokens accumulate attention probability mass, leading to dispersion and representational collapse. We show in this paper that sparse attention mechanisms using $\alpha$-entmax can avoid these issues, due to their ability to assign exact zeros to irrelevant tokens. Furthermore, we introduce Adaptive-Scalable Entmax (ASEntmax), which endows $\alpha$-entmax with a learnable temperature parameter, allowing the attention distribution to interpolate between sparse (pattern-focused) and dense (softmax-like) regimes. Finally, we show that the ability to locate and generalize fixed-size patterns can be further improved through a careful design of position encodings, which impacts both dense and sparse attention methods. By integrating ASEntmax into standard transformer layers alongside proper positional encodings, we show that our models greatly outperform softmax, scalable softmax, and fixed-temperature $\alpha$-entmax baselines on long-context generalization.</li>
</ul>

<h3>Title: Semantic Outlier Removal with Embedding Models and LLMs</h3>
<ul>
<li><strong>Authors: </strong>Eren Akbiyik, João Almeida, Rik Melis, Ritu Sriram, Viviana Petrescu, Vilhjálmur Vilhjálmsson</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.IR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.16644">https://arxiv.org/abs/2506.16644</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.16644">https://arxiv.org/pdf/2506.16644</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.16644]] Semantic Outlier Removal with Embedding Models and LLMs(https://arxiv.org/abs/2506.16644)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, extraction, large language model</a></li>
<li><strong>Abstract: </strong>Modern text processing pipelines demand robust methods to remove extraneous content while preserving a document's core message. Traditional approaches such as HTML boilerplate extraction or keyword filters often fail in multilingual settings and struggle with context-sensitive nuances, whereas Large Language Models (LLMs) offer improved quality at high computational cost. We introduce SORE (Semantic Outlier Removal), a cost-effective, transparent method that leverages multilingual sentence embeddings and approximate nearest-neighbor search to identify and excise unwanted text segments. By first identifying core content via metadata embedding and then flagging segments that either closely match predefined outlier groups or deviate significantly from the core, SORE achieves near-LLM extraction precision at a fraction of the cost. Experiments on HTML datasets demonstrate that SORE outperforms structural methods and yield high precision in diverse scenarios. Our system is currently deployed in production, processing millions of documents daily across multiple languages while maintaining both efficiency and accuracy. To facilitate reproducibility and further research, we release our implementation and evaluation datasets.</li>
</ul>

<h3>Title: Automated Energy Billing with Blockchain and the Prophet Forecasting Model: A Holistic Approach</h3>
<ul>
<li><strong>Authors: </strong>Ajesh Thangaraj Nadar, Soham Chandane, Gabriel Nixon Raj, Nihar Mahesh Pasi, Yash Arvind Patil</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.16649">https://arxiv.org/abs/2506.16649</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.16649">https://arxiv.org/pdf/2506.16649</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.16649]] Automated Energy Billing with Blockchain and the Prophet Forecasting Model: A Holistic Approach(https://arxiv.org/abs/2506.16649)</code><input type="text"></li>
<li><strong>Keywords: </strong>secure</a></li>
<li><strong>Abstract: </strong>This paper presents a comprehensive approach to automated energy billing that leverages IoT-based smart meters, blockchain technology, and the Prophet time series forecasting model. The proposed system facilitates real-time power consumption monitoring via Wi-Fi-enabled ESP32 modules and a mobile application interface. It integrates Firebase and blockchain for secure, transparent billing processes and employs smart contracts for automated payments. The Prophet model is used for energy demand forecasting, with careful data preprocessing, transformation, and parameter tuning to improve prediction accuracy. This holistic solution aims to reduce manual errors, enhance user awareness, and promote sustainable energy use.</li>
</ul>

<h3>Title: Arch-Router: Aligning LLM Routing with Human Preferences</h3>
<ul>
<li><strong>Authors: </strong>Co Tran, Salman Paracha, Adil Hafeez, Shuguang Chen</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.16655">https://arxiv.org/abs/2506.16655</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.16655">https://arxiv.org/pdf/2506.16655</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.16655]] Arch-Router: Aligning LLM Routing with Human Preferences(https://arxiv.org/abs/2506.16655)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>With the rapid proliferation of large language models (LLMs) -- each optimized for different strengths, style, or latency/cost profile -- routing has become an essential technique to operationalize the use of different models. However, existing LLM routing approaches are limited in two key ways: they evaluate performance using benchmarks that often fail to capture human preferences driven by subjective evaluation criteria, and they typically select from a limited pool of models. In this work, we propose a preference-aligned routing framework that guides model selection by matching queries to user-defined domains (e.g., travel) or action types (e.g., image editing) -- offering a practical mechanism to encode preferences in routing decisions. Specifically, we introduce \textbf{Arch-Router}, a compact 1.5B model that learns to map queries to domain-action preferences for model routing decisions. Our approach also supports seamlessly adding new models for routing without requiring retraining or architectural modifications. Experiments on conversational datasets demonstrate that our approach achieves state-of-the-art (SOTA) results in matching queries with human preferences, outperforming top proprietary models. Our approach captures subjective evaluation criteria and makes routing decisions more transparent and flexible. Our model is available at: \texttt{this https URL}.</li>
</ul>

<h3>Title: Mesh-Informed Neural Operator : A Transformer Generative Approach</h3>
<ul>
<li><strong>Authors: </strong>Yaozhong Shi, Zachary E. Ross, Domniki Asimaki, Kamyar Azizzadenesheli</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.16656">https://arxiv.org/abs/2506.16656</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.16656">https://arxiv.org/pdf/2506.16656</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.16656]] Mesh-Informed Neural Operator : A Transformer Generative Approach(https://arxiv.org/abs/2506.16656)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer, generative</a></li>
<li><strong>Abstract: </strong>Generative models in function spaces, situated at the intersection of generative modeling and operator learning, are attracting increasing attention due to their immense potential in diverse scientific and engineering applications. While functional generative models are theoretically domain- and discretization-agnostic, current implementations heavily rely on the Fourier Neural Operator (FNO), limiting their applicability to regular grids and rectangular domains. To overcome these critical limitations, we introduce the Mesh-Informed Neural Operator (MINO). By leveraging graph neural operators and cross-attention mechanisms, MINO offers a principled, domain- and discretization-agnostic backbone for generative modeling in function spaces. This advancement significantly expands the scope of such models to more diverse applications in generative, inverse, and regression tasks. Furthermore, MINO provides a unified perspective on integrating neural operators with general advanced deep learning architectures. Finally, we introduce a suite of standardized evaluation metrics that enable objective comparison of functional generative models, addressing another critical gap in the field.</li>
</ul>

<h3>Title: A Minimalist Optimizer Design for LLM Pretraining</h3>
<ul>
<li><strong>Authors: </strong>Athanasios Glentis, Jiaxiang Li, Andi Han, Mingyi Hong</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, math.OC</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.16659">https://arxiv.org/abs/2506.16659</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.16659">https://arxiv.org/pdf/2506.16659</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.16659]] A Minimalist Optimizer Design for LLM Pretraining(https://arxiv.org/abs/2506.16659)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Training large language models (LLMs) typically relies on adaptive optimizers such as Adam, which require significant memory to maintain first- and second-moment matrices, known as optimizer states. While recent works such as GaLore, Fira, and APOLLO have proposed state-compressed variants to reduce memory consumption, a fundamental question remains: What is the minimal amount of optimizer state that is truly necessary to retain state-of-the-art performance in LLM pretraining? In this work, we systematically investigate this question using a bottom-up approach. We find that two memory- and compute-efficient optimization techniques are particularly effective: (1) column-wise gradient normalization significantly boosts the performance of plain SGD without requiring momentum; and (2) adding first-order momentum only to the output layer - where gradient variance is highest - yields performance competitive with fully adaptive methods such as Muon. Based on these insights, we propose SCALE (Stochastic Column-normalized Last-layer Momentum), a new optimizer that combines column-normalized SGD with last-layer momentum, where column normalization refers to normalizing the gradient along the output dimension. Across multiple LLaMA models (60M-1B), SCALE matches or exceeds the performance of Adam while using only 35-45% of the total memory. It also consistently outperforms memory-efficient optimizers such as GaLore, Fira, and APOLLO, making it a strong candidate for large-scale pretraining under memory constraints. For the LLaMA 7B model, SCALE outperforms the state-of-the-art method APOLLO in terms of both perplexity and memory consumption. In addition, our method serves as a minimalist baseline for more sophisticated optimizer design.</li>
</ul>

<h3>Title: Private Training & Data Generation by Clustering Embeddings</h3>
<ul>
<li><strong>Authors: </strong>Felix Zhou, Samson Zhou, Vahab Mirrokni, Alessandro Epasto, Vincent Cohen-Addad</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CR, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.16661">https://arxiv.org/abs/2506.16661</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.16661">https://arxiv.org/pdf/2506.16661</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.16661]] Private Training & Data Generation by Clustering Embeddings(https://arxiv.org/abs/2506.16661)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, protect, robust</a></li>
<li><strong>Abstract: </strong>Deep neural networks often use large, high-quality datasets to achieve high performance on many machine learning tasks. When training involves potentially sensitive data, this process can raise privacy concerns, as large models have been shown to unintentionally memorize and reveal sensitive information, including reconstructing entire training samples. Differential privacy (DP) provides a robust framework for protecting individual data and in particular, a new approach to privately training deep neural networks is to approximate the input dataset with a privately generated synthetic dataset, before any subsequent training algorithm. We introduce a novel principled method for DP synthetic image embedding generation, based on fitting a Gaussian Mixture Model (GMM) in an appropriate embedding space using DP clustering. Our method provably learns a GMM under separation conditions. Empirically, a simple two-layer neural network trained on synthetically generated embeddings achieves state-of-the-art (SOTA) classification accuracy on standard benchmark datasets. Additionally, we demonstrate that our method can generate realistic synthetic images that achieve downstream classification accuracy comparable to SOTA methods. Our method is quite general, as the encoder and decoder modules can be freely substituted to suit different tasks. It is also highly scalable, consisting only of subroutines that scale linearly with the number of samples and/or can be implemented efficiently in distributed systems.</li>
</ul>

<h3>Title: A Comparative Analysis of Principal Component Analysis (PCA) and Singular Value Decomposition (SVD) as Dimensionality Reduction Techniques</h3>
<ul>
<li><strong>Authors: </strong>Michael Gyimadu, Gregory Bell</a></li>
<li><strong>Subjects: </strong>cs.CV, math.NA</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.16663">https://arxiv.org/abs/2506.16663</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.16663">https://arxiv.org/pdf/2506.16663</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.16663]] A Comparative Analysis of Principal Component Analysis (PCA) and Singular Value Decomposition (SVD) as Dimensionality Reduction Techniques(https://arxiv.org/abs/2506.16663)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability</a></li>
<li><strong>Abstract: </strong>High-dimensional image data often require dimensionality reduction before further analysis. This paper provides a purely analytical comparison of two linear techniques-Principal Component Analysis (PCA) and Singular Value Decomposition (SVD). After the derivation of each algorithm from first principles, we assess their interpretability, numerical stability, and suitability for differing matrix shapes. building on classical and recent numerical literature, We synthesize rule-of-thumb guidelines for choosing one out of the two algorithms without empirical benchmarking, building on classical and recent numerical literature. Limitations and directions for future experimental work are outlined at the end.</li>
</ul>

<h3>Title: The Hitchhiker's Guide to Efficient, End-to-End, and Tight DP Auditing</h3>
<ul>
<li><strong>Authors: </strong>Meenatchi Sundaram Muthu Selva Annamalai, Borja Balle, Jamie Hayes, Georgios Kaissis, Emiliano De Cristofaro</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.16666">https://arxiv.org/abs/2506.16666</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.16666">https://arxiv.org/pdf/2506.16666</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.16666]] The Hitchhiker's Guide to Efficient, End-to-End, and Tight DP Auditing(https://arxiv.org/abs/2506.16666)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, attack</a></li>
<li><strong>Abstract: </strong>This paper systematizes research on auditing Differential Privacy (DP) techniques, aiming to identify key insights into the current state of the art and open challenges. First, we introduce a comprehensive framework for reviewing work in the field and establish three cross-contextual desiderata that DP audits should target--namely, efficiency, end-to-end-ness, and tightness. Then, we systematize the modes of operation of state-of-the-art DP auditing techniques, including threat models, attacks, and evaluation functions. This allows us to highlight key details overlooked by prior work, analyze the limiting factors to achieving the three desiderata, and identify open research problems. Overall, our work provides a reusable and systematic methodology geared to assess progress in the field and identify friction points and future directions for our community to focus on.</li>
</ul>

<h3>Title: Mechanisms vs. Outcomes: Probing for Syntax Fails to Explain Performance on Targeted Syntactic Evaluations</h3>
<ul>
<li><strong>Authors: </strong>Ananth Agarwal, Jasper Jian, Christopher D. Manning, Shikhar Murty</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.16678">https://arxiv.org/abs/2506.16678</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.16678">https://arxiv.org/pdf/2506.16678</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.16678]] Mechanisms vs. Outcomes: Probing for Syntax Fails to Explain Performance on Targeted Syntactic Evaluations(https://arxiv.org/abs/2506.16678)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, interpretability, transformer, large language model</a></li>
<li><strong>Abstract: </strong>Large Language Models (LLMs) exhibit a robust mastery of syntax when processing and generating text. While this suggests internalized understanding of hierarchical syntax and dependency relations, the precise mechanism by which they represent syntactic structure is an open area within interpretability research. Probing provides one way to identify the mechanism of syntax being linearly encoded in activations, however, no comprehensive study has yet established whether a model's probing accuracy reliably predicts its downstream syntactic performance. Adopting a "mechanisms vs. outcomes" framework, we evaluate 32 open-weight transformer models and find that syntactic features extracted via probing fail to predict outcomes of targeted syntax evaluations across English linguistic phenomena. Our results highlight a substantial disconnect between latent syntactic representations found via probing and observable syntactic behaviors in downstream tasks.</li>
</ul>

<h3>Title: Fast and Stable Diffusion Planning through Variational Adaptive Weighting</h3>
<ul>
<li><strong>Authors: </strong>Zhiying Qiu, Tao Lin</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.16688">https://arxiv.org/abs/2506.16688</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.16688">https://arxiv.org/pdf/2506.16688</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.16688]] Fast and Stable Diffusion Planning through Variational Adaptive Weighting(https://arxiv.org/abs/2506.16688)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, transformer, generative</a></li>
<li><strong>Abstract: </strong>Diffusion models have recently shown promise in offline RL. However, these methods often suffer from high training costs and slow convergence, particularly when using transformer-based denoising backbones. While several optimization strategies have been proposed -- such as modified noise schedules, auxiliary prediction targets, and adaptive loss weighting -- challenges remain in achieving stable and efficient training. In particular, existing loss weighting functions typically rely on neural network approximators, which can be ineffective in early training phases due to limited generalization capacity of MLPs when exposed to sparse feedback in the early training stages. In this work, we derive a variationally optimal uncertainty-aware weighting function and introduce a closed-form polynomial approximation method for its online estimation under the flow-based generative modeling framework. We integrate our method into a diffusion planning pipeline and evaluate it on standard offline RL benchmarks. Experimental results on Maze2D and Kitchen tasks show that our method achieves competitive performance with up to 10 times fewer training steps, highlighting its practical effectiveness.</li>
</ul>

<h3>Title: DepthVanish: Optimizing Adversarial Interval Structures for Stereo-Depth-Invisible Patches</h3>
<ul>
<li><strong>Authors: </strong>Yun Xing, Yue Cao, Nhat Chung, Jie Zhang, Ivor Tsang, Ming-Ming Cheng, Yang Liu, Lei Ma, Qing Guo</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.16690">https://arxiv.org/abs/2506.16690</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.16690">https://arxiv.org/pdf/2506.16690</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.16690]] DepthVanish: Optimizing Adversarial Interval Structures for Stereo-Depth-Invisible Patches(https://arxiv.org/abs/2506.16690)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, attack</a></li>
<li><strong>Abstract: </strong>Stereo Depth estimation is a critical task in autonomous driving and robotics, where inaccuracies (such as misidentifying nearby objects as distant) can lead to dangerous situations. Adversarial attacks against stereo depth estimation can help reveal vulnerabilities before deployment. Previous work has shown that repeating optimized textures can effectively mislead stereo depth estimation in digital settings. However, our research reveals that these naively repeated texture structures perform poorly in physical-world implementations, i.e., when deployed as patches, limiting their practical utility for testing stereo depth estimation systems. In this work, for the first time, we discover that introducing regular intervals between repeated textures, creating a striped structure, significantly enhances the patch attack effectiveness. Through extensive experimentation, we analyze how variations of this novel structure influence the performance. Based on these insights, we develop a novel stereo depth attack that jointly optimizes both the striped structure and texture elements. Our generated adversarial patches can be inserted into any scenes and successfully attack state-of-the-art stereo depth estimation methods, i.e., RAFT-Stereo and STTR. Most critically, our patch can also attack commercial RGB-D cameras (Intel RealSense) in real-world conditions, demonstrating their practical relevance for security assessment of stereo systems.</li>
</ul>

<h3>Title: LaVi: Efficient Large Vision-Language Models via Internal Feature Modulation</h3>
<ul>
<li><strong>Authors: </strong>Tongtian Yue, Longteng Guo, Yepeng Tang, Zijia Zhao, Xinxin Zhu, Hua Huang, Jing Liu</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.16691">https://arxiv.org/abs/2506.16691</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.16691">https://arxiv.org/pdf/2506.16691</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.16691]] LaVi: Efficient Large Vision-Language Models via Internal Feature Modulation(https://arxiv.org/abs/2506.16691)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Despite the impressive advancements of Large Vision-Language Models (LVLMs), existing approaches suffer from a fundamental bottleneck: inefficient visual-language integration. Current methods either disrupt the model's inherent structure or introduce severe long-context computational burden, severely limiting scalability and efficiency. In this paper, we rethink multimodal integration and present LaVi, a novel LVLM that enables seamless and efficient vision-language fusion through internal feature modulation within the Large Language Models (LLMs). Unlike dominant LVLMs that rely on visual token concatenation, LaVi bypasses long-context expansion by introducing a lightweight and adaptive transformation, which incorporates visual context by injecting token-wise vision-conditioned deltas into the affine parameters of layer normalization. This mechanism directly modulates linguistic hidden states based on visual input, ensuring precise vision-language alignment while preserving the LLM's linguistic priors and drastically reducing computational costs. Extensive evaluations across 15 image and video benchmarks demonstrate that LaVi not only achieves state-of-the-art multimodal performance but also dramatically enhances efficiency. Compared to LLaVA-OV-7B, LaVi reduces FLOPs by 94.0%, improves inference speed by 3.1 times, and cuts memory usage in half - establishing LaVi as a scalable and practical solution for real-time multimodal reasoning. The code and models will be released soon.</li>
</ul>

<h3>Title: LegiGPT: Party Politics and Transport Policy with Large Language Model</h3>
<ul>
<li><strong>Authors: </strong>Hyunsoo Yun, Eun Hak Lee</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.16692">https://arxiv.org/abs/2506.16692</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.16692">https://arxiv.org/pdf/2506.16692</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.16692]] LegiGPT: Party Politics and Transport Policy with Large Language Model(https://arxiv.org/abs/2506.16692)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Given the significant influence of lawmakers' political ideologies on legislative decision-making, understanding their impact on policymaking is critically important. We introduce a novel framework, LegiGPT, which integrates a large language model (LLM) with explainable artificial intelligence (XAI) to analyze transportation-related legislative proposals. LegiGPT employs a multi-stage filtering and classification pipeline using zero-shot prompting with GPT-4. Using legislative data from South Korea's 21st National Assembly, we identify key factors - including sponsor characteristics, political affiliations, and geographic variables - that significantly influence transportation policymaking. The LLM was used to classify transportation-related bill proposals through a stepwise filtering process based on keywords, phrases, and contextual relevance. XAI techniques were then applied to examine relationships between party affiliation and associated attributes. The results reveal that the number and proportion of conservative and progressive sponsors, along with district size and electoral population, are critical determinants shaping legislative outcomes. These findings suggest that both parties contributed to bipartisan legislation through different forms of engagement, such as initiating or supporting proposals. This integrated approach provides a valuable tool for understanding legislative dynamics and guiding future policy development, with broader implications for infrastructure planning and governance.</li>
</ul>

<h3>Title: Exploring Traffic Simulation and Cybersecurity Strategies Using Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Lu Gao, Yongxin Liu, Hongyun Chen, Dahai Liu, Yunpeng Zhang, Jingran Sun</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.16699">https://arxiv.org/abs/2506.16699</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.16699">https://arxiv.org/pdf/2506.16699</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.16699]] Exploring Traffic Simulation and Cybersecurity Strategies Using Large Language Models(https://arxiv.org/abs/2506.16699)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, defense, attack, large language model</a></li>
<li><strong>Abstract: </strong>Intelligent Transportation Systems (ITS) are increasingly vulnerable to sophisticated cyberattacks due to their complex, interconnected nature. Ensuring the cybersecurity of these systems is paramount to maintaining road safety and minimizing traffic disruptions. This study presents a novel multi-agent framework leveraging Large Language Models (LLMs) to enhance traffic simulation and cybersecurity testing. The framework automates the creation of traffic scenarios, the design of cyberattack strategies, and the development of defense mechanisms. A case study demonstrates the framework's ability to simulate a cyberattack targeting connected vehicle broadcasts, evaluate its impact, and implement a defense mechanism that significantly mitigates traffic delays. Results show a 10.2 percent increase in travel time during an attack, which is reduced by 3.3 percent with the defense strategy. This research highlights the potential of LLM-driven multi-agent systems in advancing transportation cybersecurity and offers a scalable approach for future research in traffic simulation and cyber defense.</li>
</ul>

<h3>Title: ReasonGRM: Enhancing Generative Reward Models through Large Reasoning Models</h3>
<ul>
<li><strong>Authors: </strong>Bin Chen, Xinzge Gao, Chuanrui Hu, Penghang Yu, Hua Zhang, Bing-Kun Bao</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.16712">https://arxiv.org/abs/2506.16712</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.16712">https://arxiv.org/pdf/2506.16712</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.16712]] ReasonGRM: Enhancing Generative Reward Models through Large Reasoning Models(https://arxiv.org/abs/2506.16712)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>Generative Reward Models (GRMs) provide greater flexibility than scalar reward models in capturing human preferences, but their effectiveness is limited by poor reasoning capabilities. This often results in incomplete or overly speculative reasoning paths, leading to hallucinations or missing key information in complex tasks. We address this challenge with ReasonGRM, a three-stage generative reward modeling framework. In the first stage, Zero-RL is used to generate concise, outcome-directed reasoning paths that reduce the likelihood of critical omissions. In the second stage, we introduce a novel evaluation metric, $R^\star$, which scores reasoning paths based on their generation likelihood. This favors paths that reach correct answers with minimal exploration, helping to reduce hallucination-prone data during training. In the final stage, the model is further refined through reinforcement learning on challenging examples to enhance its preference discrimination capabilities. Experiments on three public benchmarks show that ReasonGRM achieves competitive or state-of-the-art performance, outperforming previous best GRMs by 1.8\% on average and surpassing proprietary models such as GPT-4o by up to 5.6\%. These results demonstrate the effectiveness of reasoning-aware training and highlight the importance of high-quality rationale selection for reliable preference modeling.</li>
</ul>

<h3>Title: TriCon-SF: A Triple-Shuffle and Contribution-Aware Serial Federated Learning Framework for Heterogeneous Healthcare Data</h3>
<ul>
<li><strong>Authors: </strong>Yuping Yan, Yizhi Wang, Yuanshuai Li, Yaochu Jin</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.16723">https://arxiv.org/abs/2506.16723</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.16723">https://arxiv.org/pdf/2506.16723</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.16723]] TriCon-SF: A Triple-Shuffle and Contribution-Aware Serial Federated Learning Framework for Heterogeneous Healthcare Data(https://arxiv.org/abs/2506.16723)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, privacy, attack, robust, federate</a></li>
<li><strong>Abstract: </strong>Serial pipeline training is an efficient paradigm for handling data heterogeneity in cross-silo federated learning with low communication overhead. However, even without centralized aggregation, direct transfer of models between clients can violate privacy regulations and remain susceptible to gradient leakage and linkage attacks. Additionally, ensuring resilience against semi-honest or malicious clients who may manipulate or misuse received models remains a grand challenge, particularly in privacy-sensitive domains such as healthcare. To address these challenges, we propose TriCon-SF, a novel serial federated learning framework that integrates triple shuffling and contribution awareness. TriCon-SF introduces three levels of randomization by shuffling model layers, data segments, and training sequences to break deterministic learning patterns and disrupt potential attack vectors, thereby enhancing privacy and robustness. In parallel, it leverages Shapley value methods to dynamically evaluate client contributions during training, enabling the detection of dishonest behavior and enhancing system accountability. Extensive experiments on non-IID healthcare datasets demonstrate that TriCon-SF outperforms standard serial and parallel federated learning in both accuracy and communication efficiency. Security analysis further supports its resilience against client-side privacy attacks.</li>
</ul>

<h3>Title: The Role of Model Confidence on Bias Effects in Measured Uncertainties</h3>
<ul>
<li><strong>Authors: </strong>Xinyi Liu, Weiguang Wang, Hangfeng He</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.16724">https://arxiv.org/abs/2506.16724</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.16724">https://arxiv.org/pdf/2506.16724</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.16724]] The Role of Model Confidence on Bias Effects in Measured Uncertainties(https://arxiv.org/abs/2506.16724)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>With the growing adoption of Large Language Models (LLMs) for open-ended tasks, accurately assessing epistemic uncertainty, which reflects a model's lack of knowledge, has become crucial to ensuring reliable outcomes. However, quantifying epistemic uncertainty in such tasks is challenging due to the presence of aleatoric uncertainty, which arises from multiple valid answers. While bias can introduce noise into epistemic uncertainty estimation, it may also reduce noise from aleatoric uncertainty. To investigate this trade-off, we conduct experiments on Visual Question Answering (VQA) tasks and find that mitigating prompt-introduced bias improves uncertainty quantification in GPT-4o. Building on prior work showing that LLMs tend to copy input information when model confidence is low, we further analyze how these prompt biases affect measured epistemic and aleatoric uncertainty across varying bias-free confidence levels with GPT-4o and Qwen2-VL. We find that all considered biases induce greater changes in both uncertainties when bias-free model confidence is lower. Moreover, lower bias-free model confidence leads to greater underestimation of epistemic uncertainty (i.e. overconfidence) due to bias, whereas it has no significant effect on the direction of changes in aleatoric uncertainty estimation. These distinct effects deepen our understanding of bias mitigation for uncertainty quantification and potentially inform the development of more advanced techniques.</li>
</ul>

<h3>Title: TeSG: Textual Semantic Guidance for Infrared and Visible Image Fusion</h3>
<ul>
<li><strong>Authors: </strong>Mingrui Zhu, Xiru Chen, Xin Wei, Nannan Wang, Xinbo Gao</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.16730">https://arxiv.org/abs/2506.16730</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.16730">https://arxiv.org/pdf/2506.16730</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.16730]] TeSG: Textual Semantic Guidance for Infrared and Visible Image Fusion(https://arxiv.org/abs/2506.16730)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>Infrared and visible image fusion (IVF) aims to combine complementary information from both image modalities, producing more informative and comprehensive outputs. Recently, text-guided IVF has shown great potential due to its flexibility and versatility. However, the effective integration and utilization of textual semantic information remains insufficiently studied. To tackle these challenges, we introduce textual semantics at two levels: the mask semantic level and the text semantic level, both derived from textual descriptions extracted by large Vision-Language Models (VLMs). Building on this, we propose Textual Semantic Guidance for infrared and visible image fusion, termed TeSG, which guides the image synthesis process in a way that is optimized for downstream tasks such as detection and segmentation. Specifically, TeSG consists of three core components: a Semantic Information Generator (SIG), a Mask-Guided Cross-Attention (MGCA) module, and a Text-Driven Attentional Fusion (TDAF) module. The SIG generates mask and text semantics based on textual descriptions. The MGCA module performs initial attention-based fusion of visual features from both infrared and visible images, guided by mask semantics. Finally, the TDAF module refines the fusion process with gated attention driven by text semantics. Extensive experiments demonstrate the competitiveness of our approach, particularly in terms of performance on downstream tasks, compared to existing state-of-the-art methods.</li>
</ul>

<h3>Title: Cross-modal Offset-guided Dynamic Alignment and Fusion for Weakly Aligned UAV Object Detection</h3>
<ul>
<li><strong>Authors: </strong>Liu Zongzhen, Luo Hui, Wang Zhixing, Wei Yuxing, Zuo Haorui, Zhang Jianlin</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.16737">https://arxiv.org/abs/2506.16737</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.16737">https://arxiv.org/pdf/2506.16737</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.16737]] Cross-modal Offset-guided Dynamic Alignment and Fusion for Weakly Aligned UAV Object Detection(https://arxiv.org/abs/2506.16737)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, robust</a></li>
<li><strong>Abstract: </strong>Unmanned aerial vehicle (UAV) object detection plays a vital role in applications such as environmental monitoring and urban security. To improve robustness, recent studies have explored multimodal detection by fusing visible (RGB) and infrared (IR) imagery. However, due to UAV platform motion and asynchronous imaging, spatial misalignment frequently occurs between modalities, leading to weak alignment. This introduces two major challenges: semantic inconsistency at corresponding spatial locations and modality conflict during feature fusion. Existing methods often address these issues in isolation, limiting their effectiveness. In this paper, we propose Cross-modal Offset-guided Dynamic Alignment and Fusion (CoDAF), a unified framework that jointly tackles both challenges in weakly aligned UAV-based object detection. CoDAF comprises two novel modules: the Offset-guided Semantic Alignment (OSA), which estimates attention-based spatial offsets and uses deformable convolution guided by a shared semantic space to align features more precisely; and the Dynamic Attention-guided Fusion Module (DAFM), which adaptively balances modality contributions through gating and refines fused features via spatial-channel dual attention. By integrating alignment and fusion in a unified design, CoDAF enables robust UAV object detection. Experiments on standard benchmarks validate the effectiveness of our approach, with CoDAF achieving a mAP of 78.6% on the DroneVehicle dataset.</li>
</ul>

<h3>Title: Uncertainty-Aware Variational Information Pursuit for Interpretable Medical Image Analysis</h3>
<ul>
<li><strong>Authors: </strong>Md Nahiduzzaman, Ruwan Tennakoon, Steven Korevaar, Zongyuan Ge, Alireza Bab-Hadiashar</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.16742">https://arxiv.org/abs/2506.16742</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.16742">https://arxiv.org/pdf/2506.16742</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.16742]] Uncertainty-Aware Variational Information Pursuit for Interpretable Medical Image Analysis(https://arxiv.org/abs/2506.16742)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, interpretability</a></li>
<li><strong>Abstract: </strong>In medical imaging, AI decision-support systems must balance accuracy and interpretability to build user trust and support effective clinical decision-making. Recently, Variational Information Pursuit (V-IP) and its variants have emerged as interpretable-by-design modeling techniques, aiming to explain AI decisions in terms of human-understandable, clinically relevant concepts. However, existing V-IP methods overlook instance-level uncertainties in query-answer generation, which can arise from model limitations (epistemic uncertainty) or variability in expert responses (aleatoric uncertainty). This paper introduces Uncertainty-Aware V-IP (UAV-IP), a novel framework that integrates uncertainty quantification into the V-IP process. We evaluate UAV-IP across four medical imaging datasets, PH2, Derm7pt, BrEaST, and SkinCon, demonstrating an average AUC improvement of approximately 3.2% while generating 20% more concise explanations compared to baseline V-IP, without sacrificing informativeness. These findings highlight the importance of uncertainty-aware reasoning in interpretable by design models for robust and reliable medical decision-making.</li>
</ul>

<h3>Title: Noise-Informed Diffusion-Generated Image Detection with Anomaly Attention</h3>
<ul>
<li><strong>Authors: </strong>Weinan Guan, Wei Wang, Bo Peng, Ziwen He, Jing Dong, Haonan Cheng</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.16743">https://arxiv.org/abs/2506.16743</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.16743">https://arxiv.org/pdf/2506.16743</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.16743]] Noise-Informed Diffusion-Generated Image Detection with Anomaly Attention(https://arxiv.org/abs/2506.16743)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, diffusion, transformer</a></li>
<li><strong>Abstract: </strong>With the rapid development of image generation technologies, especially the advancement of Diffusion Models, the quality of synthesized images has significantly improved, raising concerns among researchers about information security. To mitigate the malicious abuse of diffusion models, diffusion-generated image detection has proven to be an effective this http URL, a key challenge for forgery detection is generalising to diffusion models not seen during training. In this paper, we address this problem by focusing on image noise. We observe that images from different diffusion models share similar noise patterns, distinct from genuine images. Building upon this insight, we introduce a novel Noise-Aware Self-Attention (NASA) module that focuses on noise regions to capture anomalous patterns. To implement a SOTA detection model, we incorporate NASA into Swin Transformer, forming an novel detection architecture NASA-Swin. Additionally, we employ a cross-modality fusion embedding to combine RGB and noise images, along with a channel mask strategy to enhance feature learning from both modalities. Extensive experiments demonstrate the effectiveness of our approach in enhancing detection capabilities for diffusion-generated images. When encountering unseen generation methods, our approach achieves the state-of-the-art this http URL code is available at this https URL.</li>
</ul>

<h3>Title: IsoNet: Causal Analysis of Multimodal Transformers for Neuromuscular Gesture Classification</h3>
<ul>
<li><strong>Authors: </strong>Eion Tyacke, Kunal Gupta, Jay Patel, Rui Li</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.RO, eess.SP</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.16744">https://arxiv.org/abs/2506.16744</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.16744">https://arxiv.org/pdf/2506.16744</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.16744]] IsoNet: Causal Analysis of Multimodal Transformers for Neuromuscular Gesture Classification(https://arxiv.org/abs/2506.16744)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Hand gestures are a primary output of the human motor system, yet the decoding of their neuromuscular signatures remains a bottleneck for basic neuroscience and assistive technologies such as prosthetics. Traditional human-machine interface pipelines rely on a single biosignal modality, but multimodal fusion can exploit complementary information from sensors. We systematically compare linear and attention-based fusion strategies across three architectures: a Multimodal MLP, a Multimodal Transformer, and a Hierarchical Transformer, evaluating performance on scenarios with unimodal and multimodal inputs. Experiments use two publicly available datasets: NinaPro DB2 (sEMG and accelerometer) and HD-sEMG 65-Gesture (high-density sEMG and force). Across both datasets, the Hierarchical Transformer with attention-based fusion consistently achieved the highest accuracy, surpassing the multimodal and best single-modality linear-fusion MLP baseline by over 10% on NinaPro DB2 and 3.7% on HD-sEMG. To investigate how modalities interact, we introduce an Isolation Network that selectively silences unimodal or cross-modal attention pathways, quantifying each group of token interactions' contribution to downstream decisions. Ablations reveal that cross-modal interactions contribute approximately 30% of the decision signal across transformer layers, highlighting the importance of attention-driven fusion in harnessing complementary modality information. Together, these findings reveal when and how multimodal fusion would enhance biosignal classification and also provides mechanistic insights of human muscle activities. The study would be beneficial in the design of sensor arrays for neurorobotic systems.</li>
</ul>

<h3>Title: Off-Policy Actor-Critic for Adversarial Observation Robustness: Virtual Alternative Training via Symmetric Policy Evaluation</h3>
<ul>
<li><strong>Authors: </strong>Kosuke Nakanishi, Akihiro Kubo, Yuji Yasui, Shin Ishii</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.RO</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.16753">https://arxiv.org/abs/2506.16753</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.16753">https://arxiv.org/pdf/2506.16753</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.16753]] Off-Policy Actor-Critic for Adversarial Observation Robustness: Virtual Alternative Training via Symmetric Policy Evaluation(https://arxiv.org/abs/2506.16753)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Recently, robust reinforcement learning (RL) methods designed to handle adversarial input observations have received significant attention, motivated by RL's inherent vulnerabilities. While existing approaches have demonstrated reasonable success, addressing worst-case scenarios over long time horizons requires both minimizing the agent's cumulative rewards for adversaries and training agents to counteract them through alternating learning. However, this process introduces mutual dependencies between the agent and the adversary, making interactions with the environment inefficient and hindering the development of off-policy methods. In this work, we propose a novel off-policy method that eliminates the need for additional environmental interactions by reformulating adversarial learning as a soft-constrained optimization problem. Our approach is theoretically supported by the symmetric property of policy evaluation between the agent and the adversary. The implementation is available at this https URL.</li>
</ul>

<h3>Title: SocialSim: Towards Socialized Simulation of Emotional Support Conversation</h3>
<ul>
<li><strong>Authors: </strong>Zhuang Chen, Yaru Cao, Guanqun Bi, Jincenzi Wu, Jinfeng Zhou, Xiyao Xiao, Si Chen, Hongning Wang, Minlie Huang</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.16756">https://arxiv.org/abs/2506.16756</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.16756">https://arxiv.org/pdf/2506.16756</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.16756]] SocialSim: Towards Socialized Simulation of Emotional Support Conversation(https://arxiv.org/abs/2506.16756)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Emotional support conversation (ESC) helps reduce people's psychological stress and provide emotional value through interactive dialogues. Due to the high cost of crowdsourcing a large ESC corpus, recent attempts use large language models for dialogue augmentation. However, existing approaches largely overlook the social dynamics inherent in ESC, leading to less effective simulations. In this paper, we introduce SocialSim, a novel framework that simulates ESC by integrating key aspects of social interactions: social disclosure and social awareness. On the seeker side, we facilitate social disclosure by constructing a comprehensive persona bank that captures diverse and authentic help-seeking scenarios. On the supporter side, we enhance social awareness by eliciting cognitive reasoning to generate logical and supportive responses. Building upon SocialSim, we construct SSConv, a large-scale synthetic ESC corpus of which quality can even surpass crowdsourced ESC data. We further train a chatbot on SSConv and demonstrate its state-of-the-art performance in both automatic and human evaluations. We believe SocialSim offers a scalable way to synthesize ESC, making emotional care more accessible and practical.</li>
</ul>

<h3>Title: Cross-Modal Obfuscation for Jailbreak Attacks on Large Vision-Language Models</h3>
<ul>
<li><strong>Authors: </strong>Lei Jiang, Zixun Zhang, Zizhou Wang, Xiaobing Sun, Zhen Li, Liangli Zhen, Xiaohua Xu</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.16760">https://arxiv.org/abs/2506.16760</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.16760">https://arxiv.org/pdf/2506.16760</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.16760]] Cross-Modal Obfuscation for Jailbreak Attacks on Large Vision-Language Models(https://arxiv.org/abs/2506.16760)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, attack, robust, steal</a></li>
<li><strong>Abstract: </strong>Large Vision-Language Models (LVLMs) demonstrate exceptional performance across multimodal tasks, yet remain vulnerable to jailbreak attacks that bypass built-in safety mechanisms to elicit restricted content generation. Existing black-box jailbreak methods primarily rely on adversarial textual prompts or image perturbations, yet these approaches are highly detectable by standard content filtering systems and exhibit low query and computational efficiency. In this work, we present Cross-modal Adversarial Multimodal Obfuscation (CAMO), a novel black-box jailbreak attack framework that decomposes malicious prompts into semantically benign visual and textual fragments. By leveraging LVLMs' cross-modal reasoning abilities, CAMO covertly reconstructs harmful instructions through multi-step reasoning, evading conventional detection mechanisms. Our approach supports adjustable reasoning complexity and requires significantly fewer queries than prior attacks, enabling both stealth and efficiency. Comprehensive evaluations conducted on leading LVLMs validate CAMO's effectiveness, showcasing robust performance and strong cross-model transferability. These results underscore significant vulnerabilities in current built-in safety mechanisms, emphasizing an urgent need for advanced, alignment-aware security and safety solutions in vision-language systems.</li>
</ul>

<h3>Title: PQCAD-DM: Progressive Quantization and Calibration-Assisted Distillation for Extremely Efficient Diffusion Model</h3>
<ul>
<li><strong>Authors: </strong>Beomseok Ko, Hyeryung Jang</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.16776">https://arxiv.org/abs/2506.16776</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.16776">https://arxiv.org/pdf/2506.16776</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.16776]] PQCAD-DM: Progressive Quantization and Calibration-Assisted Distillation for Extremely Efficient Diffusion Model(https://arxiv.org/abs/2506.16776)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, generative</a></li>
<li><strong>Abstract: </strong>Diffusion models excel in image generation but are computational and resource-intensive due to their reliance on iterative Markov chain processes, leading to error accumulation and limiting the effectiveness of naive compression techniques. In this paper, we propose PQCAD-DM, a novel hybrid compression framework combining Progressive Quantization (PQ) and Calibration-Assisted Distillation (CAD) to address these challenges. PQ employs a two-stage quantization with adaptive bit-width transitions guided by a momentum-based mechanism, reducing excessive weight perturbations in low-precision. CAD leverages full-precision calibration datasets during distillation, enabling the student to match full-precision performance even with a quantized teacher. As a result, PQCAD-DM achieves a balance between computational efficiency and generative quality, halving inference time while maintaining competitive performance. Extensive experiments validate PQCAD-DM's superior generative capabilities and efficiency across diverse datasets, outperforming fixed-bit quantization methods.</li>
</ul>

<h3>Title: DistillNote: LLM-based clinical note summaries improve heart failure diagnosis</h3>
<ul>
<li><strong>Authors: </strong>Heloisa Oss Boll, Antonio Oss Boll, Leticia Puttlitz Boll, Ameen Abu Hanna, Iacer Calixto</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.16777">https://arxiv.org/abs/2506.16777</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.16777">https://arxiv.org/pdf/2506.16777</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.16777]] DistillNote: LLM-based clinical note summaries improve heart failure diagnosis(https://arxiv.org/abs/2506.16777)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large language models (LLMs) offer unprecedented opportunities to generate concise summaries of patient information and alleviate the burden of clinical documentation that overwhelms healthcare providers. We present Distillnote, a framework for LLM-based clinical note summarization, and generate over 64,000 admission note summaries through three techniques: (1) One-step, direct summarization, and a divide-and-conquer approach involving (2) Structured summarization focused on independent clinical insights, and (3) Distilled summarization that further condenses the Structured summaries. We test how useful are the summaries by using them to predict heart failure compared to a model trained on the original notes. Distilled summaries achieve 79% text compression and up to 18.2% improvement in AUPRC compared to an LLM trained on the full notes. We also evaluate the quality of the generated summaries in an LLM-as-judge evaluation as well as through blinded pairwise comparisons with clinicians. Evaluations indicate that one-step summaries are favoured by clinicians according to relevance and clinical actionability, while distilled summaries offer optimal efficiency (avg. 6.9x compression-to-performance ratio) and significantly reduce hallucinations. We release our summaries on PhysioNet to encourage future research.</li>
</ul>

<h3>Title: What Is the Point of Equality in Machine Learning Fairness? Beyond Equality of Opportunity</h3>
<ul>
<li><strong>Authors: </strong>Youjin Kong</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CY</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.16782">https://arxiv.org/abs/2506.16782</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.16782">https://arxiv.org/pdf/2506.16782</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.16782]] What Is the Point of Equality in Machine Learning Fairness? Beyond Equality of Opportunity(https://arxiv.org/abs/2506.16782)</code><input type="text"></li>
<li><strong>Keywords: </strong>fair</a></li>
<li><strong>Abstract: </strong>Fairness in machine learning (ML) has become a rapidly growing area of research. But why, in the first place, is unfairness in ML morally wrong? And why should we care about improving fairness? Most fair-ML research implicitly appeals to distributive equality: the idea that desirable goods and benefits, such as opportunities (e.g., Barocas et al., 2023), should be equally distributed across society. Unfair ML models, then, are seen as wrong because they unequally distribute such benefits. This paper argues that this exclusive focus on distributive equality offers an incomplete and potentially misleading ethical foundation. Grounding ML fairness in egalitarianism -- the view that equality is a fundamental moral and social ideal -- requires challenging structural inequality: systematic, institutional, and durable arrangements that privilege some groups while disadvantaging others. Structural inequality manifests through ML systems in two primary forms: allocative harms (e.g., economic loss) and representational harms (e.g., stereotypes, erasure). While distributive equality helps address allocative harms, it fails to explain why representational harms are wrong -- why it is wrong for ML systems to reinforce social hierarchies that stratify people into superior and inferior groups -- and why ML systems should aim to foster a society where people relate as equals (i.e., relational equality). To address these limitations, the paper proposes a multifaceted egalitarian framework for ML fairness that integrates both distributive and relational equality. Drawing on critical social and political philosophy, this framework offers a more comprehensive ethical foundation for tackling the full spectrum of harms perpetuated by ML systems. The paper also outlines practical pathways for implementing the framework across the ML pipeline.</li>
</ul>

<h3>Title: TextBraTS: Text-Guided Volumetric Brain Tumor Segmentation with Innovative Dataset Development and Fusion Module Exploration</h3>
<ul>
<li><strong>Authors: </strong>Xiaoyu Shi, Rahul Kumar Jain, Yinhao Li, Ruibo Hou, Jingliang Cheng, Jie Bai, Guohua Zhao, Lanfen Lin, Rui Xu, Yen-wei Chen</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.MM</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.16784">https://arxiv.org/abs/2506.16784</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.16784">https://arxiv.org/pdf/2506.16784</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.16784]] TextBraTS: Text-Guided Volumetric Brain Tumor Segmentation with Innovative Dataset Development and Fusion Module Exploration(https://arxiv.org/abs/2506.16784)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>Deep learning has demonstrated remarkable success in medical image segmentation and computer-aided diagnosis. In particular, numerous advanced methods have achieved state-of-the-art performance in brain tumor segmentation from MRI scans. While recent studies in other medical imaging domains have revealed that integrating textual reports with visual data can enhance segmentation accuracy, the field of brain tumor analysis lacks a comprehensive dataset that combines radiological images with corresponding textual annotations. This limitation has hindered the exploration of multimodal approaches that leverage both imaging and textual data. To bridge this critical gap, we introduce the TextBraTS dataset, the first publicly available volume-level multimodal dataset that contains paired MRI volumes and rich textual annotations, derived from the widely adopted BraTS2020 benchmark. Building upon this novel dataset, we propose a novel baseline framework and sequential cross-attention method for text-guided volumetric medical image segmentation. Through extensive experiments with various text-image fusion strategies and templated text formulations, our approach demonstrates significant improvements in brain tumor segmentation accuracy, offering valuable insights into effective multimodal integration techniques. Our dataset, implementation code, and pre-trained models are publicly available at this https URL.</li>
</ul>

<h3>Title: Revisiting LoRA through the Lens of Parameter Redundancy: Spectral Encoding Helps</h3>
<ul>
<li><strong>Authors: </strong>Jiashun Cheng, Aochuan Chen, Nuo Chen, Ziqi Gao, Yuhan Li, Jia Li, Fugee Tsung</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.16787">https://arxiv.org/abs/2506.16787</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.16787">https://arxiv.org/pdf/2506.16787</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.16787]] Revisiting LoRA through the Lens of Parameter Redundancy: Spectral Encoding Helps(https://arxiv.org/abs/2506.16787)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Low-Rank Adaptation (LoRA) has emerged as a prominent technique for fine-tuning large foundation models. Despite its successes, the substantial parameter redundancy, which limits the capacity and efficiency of LoRA, has been recognized as a bottleneck. In this work, we systematically investigate the impact of redundancy in fine-tuning LoRA and reveal that reducing density redundancy does not degrade expressiveness. Based on this insight, we introduce \underline{S}pectral-\underline{e}ncoding \underline{L}ow-\underline{R}ank \underline{A}daptation (SeLoRA), which harnesses the robust expressiveness of spectral bases to re-parameterize LoRA from a sparse spectral subspace. Designed with simplicity, SeLoRA enables seamless integration with various LoRA variants for performance boosting, serving as a scalable plug-and-play framework. Extensive experiments substantiate that SeLoRA achieves greater efficiency with fewer parameters, delivering superior performance enhancements over strong baselines on various downstream tasks, including commonsense reasoning, math reasoning, and code generation.</li>
</ul>

<h3>Title: MIST: Jailbreaking Black-box Large Language Models via Iterative Semantic Tuning</h3>
<ul>
<li><strong>Authors: </strong>Muyang Zheng, Yuanzhi Yao, Changting Lin, Rui Wang, Meng Han</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.16792">https://arxiv.org/abs/2506.16792</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.16792">https://arxiv.org/pdf/2506.16792</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.16792]] MIST: Jailbreaking Black-box Large Language Models via Iterative Semantic Tuning(https://arxiv.org/abs/2506.16792)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack, large language model</a></li>
<li><strong>Abstract: </strong>Despite efforts to align large language models (LLMs) with societal and moral values, these models remain susceptible to jailbreak attacks--methods designed to elicit harmful responses. Jailbreaking black-box LLMs is considered challenging due to the discrete nature of token inputs, restricted access to the target LLM, and limited query budget. To address the issues above, we propose an effective method for jailbreaking black-box large language Models via Iterative Semantic Tuning, named MIST. MIST enables attackers to iteratively refine prompts that preserve the original semantic intent while inducing harmful content. Specifically, to balance semantic similarity with computational efficiency, MIST incorporates two key strategies: sequential synonym search, and its advanced version--order-determining optimization. Extensive experiments across two open-source models and four closed-source models demonstrate that MIST achieves competitive attack success rates and attack transferability compared with other state-of-the-art white-box and black-box jailbreak methods. Additionally, we conduct experiments on computational efficiency to validate the practical viability of MIST.</li>
</ul>

<h3>Title: RealSR-R1: Reinforcement Learning for Real-World Image Super-Resolution with Vision-Language Chain-of-Thought</h3>
<ul>
<li><strong>Authors: </strong>Junbo Qiao, Miaomiao Cai, Wei Li, Yutong Liu, Xudong Huang, Gaoqi He, Jiao Xie, Jie Hu, Xinghao Chen, Shaohui Lin</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.16796">https://arxiv.org/abs/2506.16796</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.16796">https://arxiv.org/pdf/2506.16796</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.16796]] RealSR-R1: Reinforcement Learning for Real-World Image Super-Resolution with Vision-Language Chain-of-Thought(https://arxiv.org/abs/2506.16796)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Real-World Image Super-Resolution is one of the most challenging task in image restoration. However, existing methods struggle with an accurate understanding of degraded image content, leading to reconstructed results that are both low-fidelity and unnatural. We present RealSR-R1 in this work, which empowers the RealSR models with understanding and reasoning capabilities. Inspired by the success of Chain of Thought (CoT) in large language models (LLMs), we simulate the human process of handling degraded images and propose the VLCoT framework, which integrates vision and language reasoning. The framework aims to precisely restore image details by progressively generating more comprehensive text and higher-resolution images. To overcome the challenge of traditional supervised learning CoT failing to generalize to real-world scenarios, we introduce, for the first time, Group Relative Policy Optimization (GRPO) into the Real-World Image Super-Resolution task. We propose VLCoT-GRPO as a solution, which designs four reward functions: (1) Format reward, used to standardize the CoT process; (2) Degradation reward, to incentivize accurate degradation estimation; (3) Understanding reward, to ensure the accuracy of the generated content; and (4) Generation reward, where we propose using a visual expert model to evaluate the quality of generated images, encouraging the model to generate more realistic images. Extensive experiments demonstrate that our proposed RealSR-R1 can generate realistic details and accurately understand image content, particularly in semantically rich scenes or images with severe degradation.</li>
</ul>

<h3>Title: Seeing What Matters: Generalizable AI-generated Video Detection with Forensic-Oriented Augmentation</h3>
<ul>
<li><strong>Authors: </strong>Riccardo Corvi, Davide Cozzolino, Ekta Prashnani, Shalini De Mello, Koki Nagano, Luisa Verdoliva</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.16802">https://arxiv.org/abs/2506.16802</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.16802">https://arxiv.org/pdf/2506.16802</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.16802]] Seeing What Matters: Generalizable AI-generated Video Detection with Forensic-Oriented Augmentation(https://arxiv.org/abs/2506.16802)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, generative</a></li>
<li><strong>Abstract: </strong>Synthetic video generation is progressing very rapidly. The latest models can produce very realistic high-resolution videos that are virtually indistinguishable from real ones. Although several video forensic detectors have been recently proposed, they often exhibit poor generalization, which limits their applicability in a real-world scenario. Our key insight to overcome this issue is to guide the detector towards seeing what really matters. In fact, a well-designed forensic classifier should focus on identifying intrinsic low-level artifacts introduced by a generative architecture rather than relying on high-level semantic flaws that characterize a specific model. In this work, first, we study different generative architectures, searching and identifying discriminative features that are unbiased, robust to impairments, and shared across models. Then, we introduce a novel forensic-oriented data augmentation strategy based on the wavelet decomposition and replace specific frequency-related bands to drive the model to exploit more relevant forensic cues. Our novel training paradigm improves the generalizability of AI-generated video detectors, without the need for complex algorithms and large datasets that include multiple synthetic generators. To evaluate our approach, we train the detector using data from a single generative model and test it against videos produced by a wide range of other models. Despite its simplicity, our method achieves a significant accuracy improvement over state-of-the-art detectors and obtains excellent results even on very recent generative models, such as NOVA and FLUX. Code and data will be made publicly available.</li>
</ul>

<h3>Title: Co-VisiON: Co-Visibility ReasONing on Sparse Image Sets of Indoor Scenes</h3>
<ul>
<li><strong>Authors: </strong>Chao Chen, Nobel Dang, Juexiao Zhang, Wenkai Sun, Pengfei Zheng, Xuhang He, Yimeng Ye, Taarun Srinivas, Chen Feng</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.16805">https://arxiv.org/abs/2506.16805</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.16805">https://arxiv.org/pdf/2506.16805</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.16805]] Co-VisiON: Co-Visibility ReasONing on Sparse Image Sets of Indoor Scenes(https://arxiv.org/abs/2506.16805)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Humans exhibit a remarkable ability to recognize co-visibility-the overlapping regions visible in multiple images-even when these images are sparsely distributed across a complex scene. This capability is foundational in 3D vision and robotic perception. Despite significant progress in vision learning, it remains unclear whether current vision models have reached human-level proficiency in co-visibility analysis. In this work, we introduce the Co-Visibility reasONing (Co-VisiON) benchmark, designed to directly evaluate co-visibility reasoning on sparse image sets across over 1000 indoor scenarios. Our experiments reveal that while co-visibility is typically treated as a low-level feature matching task, it poses a significant challenge for existing vision models under sparse conditions. Notably, a proprietary vision-language model outperforms all purely vision-based approaches, with all models lagging substantially behind human performance. This gap underscores the need for more than basic pairwise vision processing-it calls for a comprehensive spatial understanding through high-level reasoning across multiple views. Inspired by human visual cognition, we propose a novel multi-view baseline, Covis, which achieves top performance among pure vision models and narrows the gap to the proprietary VLM. We hope our benchmark and findings will spur further advancements in developing vision models capable of robust, high-level reasoning in challenging, sparse environments. Our dataset and source code can be found at: this https URL</li>
</ul>

<h3>Title: FOCUS: Unified Vision-Language Modeling for Interactive Editing Driven by Referential Segmentation</h3>
<ul>
<li><strong>Authors: </strong>Fan Yang, Yousong Zhu, Xin Li, Yufei Zhan, Hongyin Zhao, Shurong Zheng, Yaowei Wang, Ming Tang, Jinqiao Wang</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.16806">https://arxiv.org/abs/2506.16806</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.16806">https://arxiv.org/pdf/2506.16806</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.16806]] FOCUS: Unified Vision-Language Modeling for Interactive Editing Driven by Referential Segmentation(https://arxiv.org/abs/2506.16806)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, generative, segmentation</a></li>
<li><strong>Abstract: </strong>Recent Large Vision Language Models (LVLMs) demonstrate promising capabilities in unifying visual understanding and generative modeling, enabling both accurate content understanding and flexible editing. However, current approaches treat "what to see" and "how to edit" separately: they either perform isolated object segmentation or utilize segmentation masks merely as conditional prompts for local edit generation tasks, often relying on multiple disjointed models. To bridge these gaps, we introduce FOCUS, a unified LVLM that integrates segmentation-aware perception and controllable object-centric generation within an end-to-end framework. FOCUS employs a dual-branch visual encoder to simultaneously capture global semantic context and fine-grained spatial details. In addition, we leverage a MoVQGAN-based visual tokenizer to produce discrete visual tokens that enhance generation quality. To enable accurate and controllable image editing, we propose a progressive multi-stage training pipeline, where segmentation masks are jointly optimized and used as spatial condition prompts to guide the diffusion decoder. This strategy aligns visual encoding, segmentation, and generation modules, effectively bridging segmentation-aware perception with fine-grained visual synthesis. Extensive experiments across three core tasks, including multimodal understanding, referring segmentation accuracy, and controllable image generation, demonstrate that FOCUS achieves strong performance by jointly optimizing visual perception and generative capabilities.</li>
</ul>

<h3>Title: Zero-Knowledge Proof-of-Location Protocols for Vehicle Subsidies and Taxation Compliance</h3>
<ul>
<li><strong>Authors: </strong>Dan Bogdanov, Eduardo Brito, Annika Jaakson, Peeter Laud, Raul-Martin Rebane</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.16812">https://arxiv.org/abs/2506.16812</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.16812">https://arxiv.org/pdf/2506.16812</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.16812]] Zero-Knowledge Proof-of-Location Protocols for Vehicle Subsidies and Taxation Compliance(https://arxiv.org/abs/2506.16812)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy</a></li>
<li><strong>Abstract: </strong>This paper introduces a new set of privacy-preserving mechanisms for verifying compliance with location-based policies for vehicle taxation, or for (electric) vehicle (EV) subsidies, using Zero-Knowledge Proofs (ZKPs). We present the design and evaluation of a Zero-Knowledge Proof-of-Location (ZK-PoL) system that ensures a vehicle's adherence to territorial driving requirements without disclosing specific location data, hence maintaining user privacy. Our findings suggest a promising approach to apply ZK-PoL protocols in large-scale governmental subsidy or taxation programs.</li>
</ul>

<h3>Title: Robust Group Anomaly Detection for Quasi-Periodic Network Time Series</h3>
<ul>
<li><strong>Authors: </strong>Kai Yang, Shaoyu Dou, Pan Luo, Xin Wang, H. Vincent Poor</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.16815">https://arxiv.org/abs/2506.16815</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.16815">https://arxiv.org/pdf/2506.16815</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.16815]] Robust Group Anomaly Detection for Quasi-Periodic Network Time Series(https://arxiv.org/abs/2506.16815)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Many real-world multivariate time series are collected from a network of physical objects embedded with software, electronics, and sensors. The quasi-periodic signals generated by these objects often follow a similar repetitive and periodic pattern, but have variations in the period, and come in different lengths caused by timing (synchronization) errors. Given a multitude of such quasi-periodic time series, can we build machine learning models to identify those time series that behave differently from the majority of the observations? In addition, can the models help human experts to understand how the decision was made? We propose a sequence to Gaussian Mixture Model (seq2GMM) framework. The overarching goal of this framework is to identify unusual and interesting time series within a network time series database. We further develop a surrogate-based optimization algorithm that can efficiently train the seq2GMM model. Seq2GMM exhibits strong empirical performance on a plurality of public benchmark datasets, outperforming state-of-the-art anomaly detection techniques by a significant margin. We also theoretically analyze the convergence property of the proposed training algorithm and provide numerical results to substantiate our theoretical claims.</li>
</ul>

<h3>Title: Loupe: A Generalizable and Adaptive Framework for Image Forgery Detection</h3>
<ul>
<li><strong>Authors: </strong>Yuchu Jiang, Jiaming Chu, Jian Zhao, Xin Zhang, Xu Yang, Lei Jin, Chi Zhang, Xuelong Li</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.16819">https://arxiv.org/abs/2506.16819</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.16819">https://arxiv.org/pdf/2506.16819</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.16819]] Loupe: A Generalizable and Adaptive Framework for Image Forgery Detection(https://arxiv.org/abs/2506.16819)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, generative, segmentation</a></li>
<li><strong>Abstract: </strong>The proliferation of generative models has raised serious concerns about visual content forgery. Existing deepfake detection methods primarily target either image-level classification or pixel-wise localization. While some achieve high accuracy, they often suffer from limited generalization across manipulation types or rely on complex architectures. In this paper, we propose Loupe, a lightweight yet effective framework for joint deepfake detection and localization. Loupe integrates a patch-aware classifier and a segmentation module with conditional queries, allowing simultaneous global authenticity classification and fine-grained mask prediction. To enhance robustness against distribution shifts of test set, Loupe introduces a pseudo-label-guided test-time adaptation mechanism by leveraging patch-level predictions to supervise the segmentation head. Extensive experiments on the DDL dataset demonstrate that Loupe achieves state-of-the-art performance, securing the first place in the IJCAI 2025 Deepfake Detection and Localization Challenge with an overall score of 0.846. Our results validate the effectiveness of the proposed patch-level fusion and conditional query design in improving both classification accuracy and spatial localization under diverse forgery patterns. The code is available at this https URL.</li>
</ul>

<h3>Title: Self-supervised Feature Extraction for Enhanced Ball Detection on Soccer Robots</h3>
<ul>
<li><strong>Authors: </strong>Can Lin, Daniele Affinita, Marco E. P. Zimmatore, Daniele Nardi, Domenico D. Bloisi, Vincenzo Suriani</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.16821">https://arxiv.org/abs/2506.16821</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.16821">https://arxiv.org/pdf/2506.16821</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.16821]] Self-supervised Feature Extraction for Enhanced Ball Detection on Soccer Robots(https://arxiv.org/abs/2506.16821)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, extraction</a></li>
<li><strong>Abstract: </strong>Robust and accurate ball detection is a critical component for autonomous humanoid soccer robots, particularly in dynamic and challenging environments such as RoboCup outdoor fields. However, traditional supervised approaches require extensive manual annotation, which is costly and time-intensive. To overcome this problem, we present a self-supervised learning framework for domain-adaptive feature extraction to enhance ball detection performance. The proposed approach leverages a general-purpose pretrained model to generate pseudo-labels, which are then used in a suite of self-supervised pretext tasks -- including colorization, edge detection, and triplet loss -- to learn robust visual features without relying on manual annotations. Additionally, a model-agnostic meta-learning (MAML) strategy is incorporated to ensure rapid adaptation to new deployment scenarios with minimal supervision. A new dataset comprising 10,000 labeled images from outdoor RoboCup SPL matches is introduced, used to validate the method, and made available to the community. Experimental results demonstrate that the proposed pipeline outperforms baseline models in terms of accuracy, F1 score, and IoU, while also exhibiting faster convergence.</li>
</ul>

<h3>Title: Predicting New Research Directions in Materials Science using Large Language Models and Concept Graphs</h3>
<ul>
<li><strong>Authors: </strong>Thomas Marwitz, Alexander Colsmann, Ben Breitung, Christoph Brabec, Christoph Kirchlechner, Eva Blasco, Gabriel Cadilha Marques, Horst Hahn, Michael Hirtz, Pavel A. Levkin, Yolita M. Eggeler, Tobias Schlöder, Pascal Friederich</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.16824">https://arxiv.org/abs/2506.16824</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.16824">https://arxiv.org/pdf/2506.16824</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.16824]] Predicting New Research Directions in Materials Science using Large Language Models and Concept Graphs(https://arxiv.org/abs/2506.16824)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction, large language model</a></li>
<li><strong>Abstract: </strong>Due to an exponential increase in published research articles, it is impossible for individual scientists to read all publications, even within their own research field. In this work, we investigate the use of large language models (LLMs) for the purpose of extracting the main concepts and semantic information from scientific abstracts in the domain of materials science to find links that were not noticed by humans and thus to suggest inspiring near/mid-term future research directions. We show that LLMs can extract concepts more efficiently than automated keyword extraction methods to build a concept graph as an abstraction of the scientific literature. A machine learning model is trained to predict emerging combinations of concepts, i.e. new research ideas, based on historical data. We demonstrate that integrating semantic concept information leads to an increased prediction performance. The applicability of our model is demonstrated in qualitative interviews with domain experts based on individualized model suggestions. We show that the model can inspire materials scientists in their creative thinking process by predicting innovative combinations of topics that have not yet been investigated.</li>
</ul>

<h3>Title: AnyTraverse: An off-road traversability framework with VLM and human operator in the loop</h3>
<ul>
<li><strong>Authors: </strong>Sattwik Sahu, Agamdeep Singh, Karthik Nambiar, Srikanth Saripalli, P.B. Sujit</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI, cs.RO</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.16826">https://arxiv.org/abs/2506.16826</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.16826">https://arxiv.org/pdf/2506.16826</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.16826]] AnyTraverse: An off-road traversability framework with VLM and human operator in the loop(https://arxiv.org/abs/2506.16826)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>Off-road traversability segmentation enables autonomous navigation with applications in search-and-rescue, military operations, wildlife exploration, and agriculture. Current frameworks struggle due to significant variations in unstructured environments and uncertain scene changes, and are not adaptive to be used for different robot types. We present AnyTraverse, a framework combining natural language-based prompts with human-operator assistance to determine navigable regions for diverse robotic vehicles. The system segments scenes for a given set of prompts and calls the operator only when encountering previously unexplored scenery or unknown class not part of the prompt in its region-of-interest, thus reducing active supervision load while adapting to varying outdoor scenes. Our zero-shot learning approach eliminates the need for extensive data collection or retraining. Our experimental validation includes testing on RELLIS-3D, Freiburg Forest, and RUGD datasets and demonstrate real-world deployment on multiple robot platforms. The results show that AnyTraverse performs better than GA-NAV and Off-seg while offering a vehicle-agnostic approach to off-road traversability that balances automation with targeted human supervision.</li>
</ul>

<h3>Title: FedFitTech: A Baseline in Federated Learning for Fitness Tracking</h3>
<ul>
<li><strong>Authors: </strong>Zeyneddin Oz, Shreyas Korde, Marius Bock, Kristof Van Laerhoven</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.16840">https://arxiv.org/abs/2506.16840</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.16840">https://arxiv.org/pdf/2506.16840</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.16840]] FedFitTech: A Baseline in Federated Learning for Fitness Tracking(https://arxiv.org/abs/2506.16840)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, federate</a></li>
<li><strong>Abstract: </strong>Rapid evolution of sensors and resource-efficient machine learning models have spurred the widespread adoption of wearable fitness tracking devices. Equipped with inertial sensors, such devices can continuously capture physical movements for fitness technology (FitTech), enabling applications from sports optimization to preventive healthcare. Traditional centralized learning approaches to detect fitness activities struggle with privacy concerns, regulatory constraints, and communication inefficiencies. In contrast, Federated Learning (FL) enables a decentralized model training by communicating model updates rather than private wearable sensor data. Applying FL to FitTech presents unique challenges, such as data imbalance, lack of labelled data, heterogeneous user activity patterns, and trade-offs between personalization and generalization. To simplify research on FitTech in FL, we present the FedFitTech baseline, under the Flower framework, which is publicly available and widely used by both industry and academic researchers. Additionally, to illustrate its usage, this paper presents a case study that implements a system based on the FedFitTech baseline, incorporating a client-side early stopping strategy and comparing the results. For instance, this system allows wearable devices to optimize the trade-off between capturing common fitness activity patterns and preserving individuals' nuances, thereby enhancing both the scalability and efficiency of privacy-aware fitness tracking applications. Results show that this reduces overall redundant communications by 13 percent, while maintaining the overall recognition performance at a negligible recognition cost by 1 percent. Thus, FedFitTech baseline creates a foundation for a wide range of new research and development opportunities in FitTech, and it is available as open-source at: this https URL</li>
</ul>

<h3>Title: Camera Calibration via Circular Patterns: A Comprehensive Framework with Measurement Uncertainty and Unbiased Projection Model</h3>
<ul>
<li><strong>Authors: </strong>Chaehyeon Song, Dongjae Lee, Jongwoo Lim, Ayoung Kim</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.RO</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.16842">https://arxiv.org/abs/2506.16842</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.16842">https://arxiv.org/pdf/2506.16842</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.16842]] Camera Calibration via Circular Patterns: A Comprehensive Framework with Measurement Uncertainty and Unbiased Projection Model(https://arxiv.org/abs/2506.16842)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Camera calibration using planar targets has been widely favored, and two types of control points have been mainly considered as measurements: the corners of the checkerboard and the centroid of circles. Since a centroid is derived from numerous pixels, the circular pattern provides more precise measurements than the checkerboard. However, the existing projection model of circle centroids is biased under lens distortion, resulting in low performance. To surmount this limitation, we propose an unbiased projection model of the circular pattern and demonstrate its superior accuracy compared to the checkerboard. Complementing this, we introduce uncertainty into circular patterns to enhance calibration robustness and completeness. Defining centroid uncertainty improves the performance of calibration components, including pattern detection, optimization, and evaluation metrics. We also provide guidelines for performing good camera calibration based on the evaluation metric. The core concept of this approach is to model the boundary points of a two-dimensional shape as a Markov random field, considering its connectivity. The shape distribution is propagated to the centroid uncertainty through an appropriate shape representation based on the Green theorem. Consequently, the resulting framework achieves marked gains in calibration accuracy and robustness. The complete source code and demonstration video are available at this https URL.</li>
</ul>

<h3>Title: Bandwidth Selectors on Semiparametric Bayesian Networks</h3>
<ul>
<li><strong>Authors: </strong>Victor Alejandre (1), Concha Bielza (1), Pedro Larrañaga (1) ((1) Universidad Politecnica de Madrid, Spain)</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.16844">https://arxiv.org/abs/2506.16844</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.16844">https://arxiv.org/pdf/2506.16844</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.16844]] Bandwidth Selectors on Semiparametric Bayesian Networks(https://arxiv.org/abs/2506.16844)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Semiparametric Bayesian networks (SPBNs) integrate parametric and non-parametric probabilistic models, offering flexibility in learning complex data distributions from samples. In particular, kernel density estimators (KDEs) are employed for the non-parametric component. Under the assumption of data normality, the normal rule is used to learn the bandwidth matrix for the KDEs in SPBNs. This matrix is the key hyperparameter that controls the trade-off between bias and variance. However, real-world data often deviates from normality, potentially leading to suboptimal density estimation and reduced predictive performance. This paper first establishes the theoretical framework for the application of state-of-the-art bandwidth selectors and subsequently evaluates their impact on SPBN performance. We explore the approaches of cross-validation and plug-in selectors, assessing their effectiveness in enhancing the learning capability and applicability of SPBNs. To support this investigation, we have extended the open-source package PyBNesian for SPBNs with the additional bandwidth selection techniques and conducted extensive experimental analyses. Our results demonstrate that the proposed bandwidth selectors leverage increasing information more effectively than the normal rule, which, despite its robustness, stagnates with more data. In particular, unbiased cross-validation generally outperforms the normal rule, highlighting its advantage in high sample size scenarios.</li>
</ul>

<h3>Title: Soft decision trees for survival analysis</h3>
<ul>
<li><strong>Authors: </strong>Antonio Consoloa, Edoardo Amaldi, Emilio Carrizosa</a></li>
<li><strong>Subjects: </strong>cs.LG, math.OC</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.16846">https://arxiv.org/abs/2506.16846</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.16846">https://arxiv.org/pdf/2506.16846</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.16846]] Soft decision trees for survival analysis(https://arxiv.org/abs/2506.16846)</code><input type="text"></li>
<li><strong>Keywords: </strong>fair, interpretability</a></li>
<li><strong>Abstract: </strong>Decision trees are popular in survival analysis for their interpretability and ability to model complex relationships. Survival trees, which predict the timing of singular events using censored historical data, are typically built through heuristic approaches. Recently, there has been growing interest in globally optimized trees, where the overall tree is trained by minimizing the error function over all its parameters. We propose a new soft survival tree model (SST), with a soft splitting rule at each branch node, trained via a nonlinear optimization formulation amenable to decomposition. Since SSTs provide for every input vector a specific survival function associated to a single leaf node, they satisfy the conditional computation property and inherit the related benefits. SST and the training formulation combine flexibility with interpretability: any smooth survival function (parametric, semiparametric, or nonparametric) estimated through maximum likelihood can be used, and each leaf node of an SST yields a cluster of distinct survival functions which are associated to the data points routed to it. Numerical experiments on 15 well-known datasets show that SSTs, with parametric and spline-based semiparametric survival functions, trained using an adaptation of the node-based decomposition algorithm proposed by Consolo et al. (2024) for soft regression trees, outperform three benchmark survival trees in terms of four widely-used discrimination and calibration measures. SSTs can also be extended to consider group fairness.</li>
</ul>

<h3>Title: Controllable and Expressive One-Shot Video Head Swapping</h3>
<ul>
<li><strong>Authors: </strong>Chaonan Ji, Jinwei Qi, Peng Zhang, Bang Zhang, Liefeng Bo</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.16852">https://arxiv.org/abs/2506.16852</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.16852">https://arxiv.org/pdf/2506.16852</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.16852]] Controllable and Expressive One-Shot Video Head Swapping(https://arxiv.org/abs/2506.16852)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, diffusion</a></li>
<li><strong>Abstract: </strong>In this paper, we propose a novel diffusion-based multi-condition controllable framework for video head swapping, which seamlessly transplant a human head from a static image into a dynamic video, while preserving the original body and background of target video, and further allowing to tweak head expressions and movements during swapping as needed. Existing face-swapping methods mainly focus on localized facial replacement neglecting holistic head morphology, while head-swapping approaches struggling with hairstyle diversity and complex backgrounds, and none of these methods allow users to modify the transplanted head expressions after swapping. To tackle these challenges, our method incorporates several innovative strategies through a unified latent diffusion paradigm. 1) Identity-preserving context fusion: We propose a shape-agnostic mask strategy to explicitly disentangle foreground head identity features from background/body contexts, combining hair enhancement strategy to achieve robust holistic head identity preservation across diverse hair types and complex backgrounds. 2) Expression-aware landmark retargeting and editing: We propose a disentangled 3DMM-driven retargeting module that decouples identity, expression, and head poses, minimizing the impact of original expressions in input images and supporting expression editing. While a scale-aware retargeting strategy is further employed to minimize cross-identity expression distortion for higher transfer precision. Experimental results demonstrate that our method excels in seamless background integration while preserving the identity of the source portrait, as well as showcasing superior expression transfer capabilities applicable to both real and virtual characters.</li>
</ul>

<h3>Title: Reward-Agnostic Prompt Optimization for Text-to-Image Diffusion Models</h3>
<ul>
<li><strong>Authors: </strong>Semin Kim, Yeonwoo Cha, Jaehoon Yoo, Seunghoon Hong</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.16853">https://arxiv.org/abs/2506.16853</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.16853">https://arxiv.org/pdf/2506.16853</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.16853]] Reward-Agnostic Prompt Optimization for Text-to-Image Diffusion Models(https://arxiv.org/abs/2506.16853)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, large language model</a></li>
<li><strong>Abstract: </strong>We investigate a general approach for improving user prompts in text-to-image (T2I) diffusion models by finding prompts that maximize a reward function specified at test-time. Although diverse reward models are used for evaluating image generation, existing automated prompt engineering methods typically target specific reward configurations. Consequently, these specialized designs exhibit suboptimal performance when applied to new prompt engineering scenarios involving different reward models. To address this limitation, we introduce RATTPO (Reward-Agnostic Test-Time Prompt Optimization), a flexible test-time optimization method applicable across various reward scenarios without modification. RATTPO iteratively searches for optimized prompts by querying large language models (LLMs) \textit{without} requiring reward-specific task descriptions. Instead, it uses the optimization trajectory and a novel reward-aware feedback signal (termed a "hint") as context. Empirical results demonstrate the versatility of RATTPO, effectively enhancing user prompts across diverse reward setups that assess various generation aspects, such as aesthetics, general human preference, or spatial relationships between objects. RATTPO surpasses other test-time search baselines in search efficiency, using up to 3.5 times less inference budget, and, given sufficient inference budget, achieves performance comparable to learning-based baselines that require reward-specific fine-tuning. The code is available at this https URL.</li>
</ul>

<h3>Title: Anomaly Detection in Event-triggered Traffic Time Series via Similarity Learning</h3>
<ul>
<li><strong>Authors: </strong>Shaoyu Dou, Kai Yang, Yang Jiao, Chengbo Qiu, Kui Ren</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.16855">https://arxiv.org/abs/2506.16855</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.16855">https://arxiv.org/pdf/2506.16855</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.16855]] Anomaly Detection in Event-triggered Traffic Time Series via Similarity Learning(https://arxiv.org/abs/2506.16855)</code><input type="text"></li>
<li><strong>Keywords: </strong>security</a></li>
<li><strong>Abstract: </strong>Time series analysis has achieved great success in cyber security such as intrusion detection and device identification. Learning similarities among multiple time series is a crucial problem since it serves as the foundation for downstream analysis. Due to the complex temporal dynamics of the event-triggered time series, it often remains unclear which similarity metric is appropriate for security-related tasks, such as anomaly detection and clustering. The overarching goal of this paper is to develop an unsupervised learning framework that is capable of learning similarities among a set of event-triggered time series. From the machine learning vantage point, the proposed framework harnesses the power of both hierarchical multi-resolution sequential autoencoders and the Gaussian Mixture Model (GMM) to effectively learn the low-dimensional representations from the time series. Finally, the obtained similarity measure can be easily visualized for the explanation. The proposed framework aspires to offer a stepping stone that gives rise to a systematic approach to model and learn similarities among a multitude of event-triggered time series. Through extensive qualitative and quantitative experiments, it is revealed that the proposed method outperforms state-of-the-art methods considerably.</li>
</ul>

<h3>Title: ParkFormer: A Transformer-Based Parking Policy with Goal Embedding and Pedestrian-Aware Control</h3>
<ul>
<li><strong>Authors: </strong>Jun Fu, Bin Tian, Haonan Chen, Shi Meng, Tingting Yao</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.16856">https://arxiv.org/abs/2506.16856</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.16856">https://arxiv.org/pdf/2506.16856</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.16856]] ParkFormer: A Transformer-Based Parking Policy with Goal Embedding and Pedestrian-Aware Control(https://arxiv.org/abs/2506.16856)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Autonomous parking plays a vital role in intelligent vehicle systems, particularly in constrained urban environments where high-precision control is required. While traditional rule-based parking systems struggle with environmental uncertainties and lack adaptability in crowded or dynamic scenes, human drivers demonstrate the ability to park intuitively without explicit modeling. Inspired by this observation, we propose a Transformer-based end-to-end framework for autonomous parking that learns from expert demonstrations. The network takes as input surround-view camera images, goal-point representations, ego vehicle motion, and pedestrian trajectories. It outputs discrete control sequences including throttle, braking, steering, and gear selection. A novel cross-attention module integrates BEV features with target points, and a GRU-based pedestrian predictor enhances safety by modeling dynamic obstacles. We validate our method on the CARLA 0.9.14 simulator in both vertical and parallel parking scenarios. Experiments show our model achieves a high success rate of 96.57\%, with average positional and orientation errors of 0.21 meters and 0.41 degrees, respectively. The ablation studies further demonstrate the effectiveness of key modules such as pedestrian prediction and goal-point attention fusion. The code and dataset will be released at: this https URL.</li>
</ul>

<h3>Title: Optimal Depth of Neural Networks</h3>
<ul>
<li><strong>Authors: </strong>Qian Qi</a></li>
<li><strong>Subjects: </strong>cs.LG, math.OC</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.16862">https://arxiv.org/abs/2506.16862</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.16862">https://arxiv.org/pdf/2506.16862</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.16862]] Optimal Depth of Neural Networks(https://arxiv.org/abs/2506.16862)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Determining the optimal depth of a neural network is a fundamental yet challenging problem, typically resolved through resource-intensive experimentation. This paper introduces a formal theoretical framework to address this question by recasting the forward pass of a deep network, specifically a Residual Network (ResNet), as an optimal stopping problem. We model the layer-by-layer evolution of hidden representations as a sequential decision process where, at each layer, a choice is made between halting computation to make a prediction or continuing to a deeper layer for a potentially more refined representation. This formulation captures the intrinsic trade-off between accuracy and computational cost. Our primary theoretical contribution is a proof that, under a plausible condition of diminishing returns on the residual functions, the expected optimal stopping depth is provably finite, even in an infinite-horizon setting. We leverage this insight to propose a novel and practical regularization term, $\mathcal{L}_{\rm depth}$, that encourages the network to learn representations amenable to efficient, early exiting. We demonstrate the generality of our framework by extending it to the Transformer architecture and exploring its connection to continuous-depth models via free-boundary problems. Empirical validation on ImageNet confirms that our regularizer successfully induces the theoretically predicted behavior, leading to significant gains in computational efficiency without compromising, and in some cases improving, final model accuracy.</li>
</ul>

<h3>Title: From Lab to Factory: Pitfalls and Guidelines for Self-/Unsupervised Defect Detection on Low-Quality Industrial Images</h3>
<ul>
<li><strong>Authors: </strong>Sebastian Hönel, Jonas Nordqvist</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CV, stat.AP</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.16890">https://arxiv.org/abs/2506.16890</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.16890">https://arxiv.org/pdf/2506.16890</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.16890]] From Lab to Factory: Pitfalls and Guidelines for Self-/Unsupervised Defect Detection on Low-Quality Industrial Images(https://arxiv.org/abs/2506.16890)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>The detection and localization of quality-related problems in industrially mass-produced products has historically relied on manual inspection, which is costly and error-prone. Machine learning has the potential to replace manual handling. As such, the desire is to facilitate an unsupervised (or self-supervised) approach, as it is often impossible to specify all conceivable defects ahead of time. A plethora of prior works have demonstrated the aptitude of common reconstruction-, embedding-, and synthesis-based methods in laboratory settings. However, in practice, we observe that most methods do not handle low data quality well or exude low robustness in unfavorable, but typical real-world settings. For practitioners it may be very difficult to identify the actual underlying problem when such methods underperform. Worse, often-reported metrics (e.g., AUROC) are rarely suitable in practice and may give misleading results. In our setting, we attempt to identify subtle anomalies on the surface of blasted forged metal parts, using rather low-quality RGB imagery only, which is a common industrial setting. We specifically evaluate two types of state-of-the-art models that allow us to identify and improve quality issues in production data, without having to obtain new data. Our contribution is to provide guardrails for practitioners that allow them to identify problems related to, e.g., (lack of) robustness or invariance, in either the chosen model or the data reliably in similar scenarios. Furthermore, we exemplify common pitfalls in and shortcomings of likelihood-based approaches and outline a framework for proper empirical risk estimation that is more suitable for real-world scenarios.</li>
</ul>

<h3>Title: Tracker Installations Are Not Created Equal: Understanding Tracker Configuration of Form Data Collection</h3>
<ul>
<li><strong>Authors: </strong>Julia B. Kieserman, Athanasios Andreou, Chris Geeng, Tobias Lauinger, Damon McCoy</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.16891">https://arxiv.org/abs/2506.16891</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.16891">https://arxiv.org/pdf/2506.16891</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.16891]] Tracker Installations Are Not Created Equal: Understanding Tracker Configuration of Form Data Collection(https://arxiv.org/abs/2506.16891)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy</a></li>
<li><strong>Abstract: </strong>Targeted advertising is fueled by the comprehensive tracking of users' online activity. As a result, advertising companies, such as Google and Meta, encourage website administrators to not only install tracking scripts on their websites but configure them to automatically collect users' Personally Identifying Information (PII). In this study, we aim to characterize how Google and Meta's trackers can be configured to collect PII data from web forms. We first perform a qualitative analysis of how third parties present form data collection to website administrators in the documentation and user interface. We then perform a measurement study of 40,150 websites to quantify the prevalence and configuration of Google and Meta trackers. Our results reveal that both Meta and Google encourage the use of form data collection and include inaccurate statements about hashing PII as a privacy-preserving method. Additionally, we find that Meta includes configuring form data collection as part of the basic setup flow. Our large-scale measurement study reveals that while Google trackers are more prevalent than Meta trackers (72.6% vs. 28.2% of websites), Meta trackers are configured to collect form data more frequently (11.6% vs. 62.3%). Finally, we identify sensitive finance and health websites that have installed trackers that are likely configured to collect form data PII in violation of Meta and Google policies. Our study highlights how tracker documentation and interfaces can potentially play a role in users' privacy through the configuration choices made by the website administrators who install trackers.</li>
</ul>

<h3>Title: Towards Effective Complementary Security Analysis using Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Jonas Wagner, Simon Müller, Christian Näther, Jan-Philipp Steghöfer, Andreas Both</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.16899">https://arxiv.org/abs/2506.16899</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.16899">https://arxiv.org/pdf/2506.16899</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.16899]] Towards Effective Complementary Security Analysis using Large Language Models(https://arxiv.org/abs/2506.16899)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, large language model</a></li>
<li><strong>Abstract: </strong>A key challenge in security analysis is the manual evaluation of potential security weaknesses generated by static application security testing (SAST) tools. Numerous false positives (FPs) in these reports reduce the effectiveness of security analysis. We propose using Large Language Models (LLMs) to improve the assessment of SAST findings. We investigate the ability of LLMs to reduce FPs while trying to maintain a perfect true positive rate, using datasets extracted from the OWASP Benchmark (v1.2) and a real-world software project. Our results indicate that advanced prompting techniques, such as Chain-of-Thought and Self-Consistency, substantially improve FP detection. Notably, some LLMs identified approximately 62.5% of FPs in the OWASP Benchmark dataset without missing genuine weaknesses. Combining detections from different LLMs would increase this FP detection to approximately 78.9%. Additionally, we demonstrate our approach's generalizability using a real-world dataset covering five SAST tools, three programming languages, and infrastructure files. The best LLM detected 33.85% of all FPs without missing genuine weaknesses, while combining detections from different LLMs would increase this detection to 38.46%. Our findings highlight the potential of LLMs to complement traditional SAST tools, enhancing automation and reducing resources spent addressing false alarms.</li>
</ul>

<h3>Title: LunarLoc: Segment-Based Global Localization on the Moon</h3>
<ul>
<li><strong>Authors: </strong>Annika Thomas, Robaire Galliath, Aleksander Garbuz, Luke Anger, Cormac O'Neill, Trevor Johst, Dami Thomas, George Lordos, Jonathan P. How</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.16940">https://arxiv.org/abs/2506.16940</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.16940">https://arxiv.org/pdf/2506.16940</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.16940]] LunarLoc: Segment-Based Global Localization on the Moon(https://arxiv.org/abs/2506.16940)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction, segmentation</a></li>
<li><strong>Abstract: </strong>Global localization is necessary for autonomous operations on the lunar surface where traditional Earth-based navigation infrastructure, such as GPS, is unavailable. As NASA advances toward sustained lunar presence under the Artemis program, autonomous operations will be an essential component of tasks such as robotic exploration and infrastructure deployment. Tasks such as excavation and transport of regolith require precise pose estimation, but proposed approaches such as visual-inertial odometry (VIO) accumulate odometry drift over long traverses. Precise pose estimation is particularly important for upcoming missions such as the ISRU Pilot Excavator (IPEx) that rely on autonomous agents to operate over extended timescales and varied terrain. To help overcome odometry drift over long traverses, we propose LunarLoc, an approach to global localization that leverages instance segmentation for zero-shot extraction of boulder landmarks from onboard stereo imagery. Segment detections are used to construct a graph-based representation of the terrain, which is then aligned with a reference map of the environment captured during a previous session using graph-theoretic data association. This method enables accurate and drift-free global localization in visually ambiguous settings. LunarLoc achieves sub-cm level accuracy in multi-session global localization experiments, significantly outperforming the state of the art in lunar global localization. To encourage the development of further methods for global localization on the Moon, we release our datasets publicly with a playback module: this https URL.</li>
</ul>

<h3>Title: LAION-C: An Out-of-Distribution Benchmark for Web-Scale Vision Models</h3>
<ul>
<li><strong>Authors: </strong>Fanfei Li, Thomas Klein, Wieland Brendel, Robert Geirhos, Roland S. Zimmermann</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.16950">https://arxiv.org/abs/2506.16950</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.16950">https://arxiv.org/pdf/2506.16950</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.16950]] LAION-C: An Out-of-Distribution Benchmark for Web-Scale Vision Models(https://arxiv.org/abs/2506.16950)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Out-of-distribution (OOD) robustness is a desired property of computer vision models. Improving model robustness requires high-quality signals from robustness benchmarks to quantify progress. While various benchmark datasets such as ImageNet-C were proposed in the ImageNet era, most ImageNet-C corruption types are no longer OOD relative to today's large, web-scraped datasets, which already contain common corruptions such as blur or JPEG compression artifacts. Consequently, these benchmarks are no longer well-suited for evaluating OOD robustness in the era of web-scale datasets. Indeed, recent models show saturating scores on ImageNet-era OOD benchmarks, indicating that it is unclear whether models trained on web-scale datasets truly become better at OOD generalization or whether they have simply been exposed to the test distortions during training. To address this, we introduce LAION-C as a benchmark alternative for ImageNet-C. LAION-C consists of six novel distortion types specifically designed to be OOD, even for web-scale datasets such as LAION. In a comprehensive evaluation of state-of-the-art models, we find that the LAION-C dataset poses significant challenges to contemporary models, including MLLMs such as Gemini and GPT-4o. We additionally conducted a psychophysical experiment to evaluate the difficulty of our corruptions for human observers, enabling a comparison of models to lab-quality human robustness data. We observe a paradigm shift in OOD generalization: from humans outperforming models, to the best models now matching or outperforming the best human observers.</li>
</ul>

<h3>Title: Visual-Instructed Degradation Diffusion for All-in-One Image Restoration</h3>
<ul>
<li><strong>Authors: </strong>Wenyang Luo, Haina Qin, Zewen Chen, Libin Wang, Dandan Zheng, Yuming Li, Yufan Liu, Bing Li, Weiming Hu</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.16960">https://arxiv.org/abs/2506.16960</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.16960">https://arxiv.org/pdf/2506.16960</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.16960]] Visual-Instructed Degradation Diffusion for All-in-One Image Restoration(https://arxiv.org/abs/2506.16960)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>Image restoration tasks like deblurring, denoising, and dehazing usually need distinct models for each degradation type, restricting their generalization in real-world scenarios with mixed or unknown degradations. In this work, we propose \textbf{Defusion}, a novel all-in-one image restoration framework that utilizes visual instruction-guided degradation diffusion. Unlike existing methods that rely on task-specific models or ambiguous text-based priors, Defusion constructs explicit \textbf{visual instructions} that align with the visual degradation patterns. These instructions are grounded by applying degradations to standardized visual elements, capturing intrinsic degradation features while agnostic to image semantics. Defusion then uses these visual instructions to guide a diffusion-based model that operates directly in the degradation space, where it reconstructs high-quality images by denoising the degradation effects with enhanced stability and generalizability. Comprehensive experiments demonstrate that Defusion outperforms state-of-the-art methods across diverse image restoration tasks, including complex and real-world degradations.</li>
</ul>

<h3>Title: Reversing Flow for Image Restoration</h3>
<ul>
<li><strong>Authors: </strong>Haina Qin, Wenyang Luo, Libin Wang, Dandan Zheng, Jingdong Chen, Ming Yang, Bing Li, Weiming Hu</a></li>
<li><strong>Subjects: </strong>cs.CV, eess.IV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.16961">https://arxiv.org/abs/2506.16961</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.16961">https://arxiv.org/pdf/2506.16961</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.16961]] Reversing Flow for Image Restoration(https://arxiv.org/abs/2506.16961)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, generative</a></li>
<li><strong>Abstract: </strong>Image restoration aims to recover high-quality (HQ) images from degraded low-quality (LQ) ones by reversing the effects of degradation. Existing generative models for image restoration, including diffusion and score-based models, often treat the degradation process as a stochastic transformation, which introduces inefficiency and complexity. In this work, we propose ResFlow, a novel image restoration framework that models the degradation process as a deterministic path using continuous normalizing flows. ResFlow augments the degradation process with an auxiliary process that disambiguates the uncertainty in HQ prediction to enable reversible modeling of the degradation process. ResFlow adopts entropy-preserving flow paths and learns the augmented degradation flow by matching the velocity field. ResFlow significantly improves the performance and speed of image restoration, completing the task in fewer than four sampling steps. Extensive experiments demonstrate that ResFlow achieves state-of-the-art results across various image restoration benchmarks, offering a practical and efficient solution for real-world applications.</li>
</ul>

<h3>Title: Enhancing Step-by-Step and Verifiable Medical Reasoning in MLLMs</h3>
<ul>
<li><strong>Authors: </strong>Haoran Sun, Yankai Jiang, Wenjie Lou, Yujie Zhang, Wenjie Li, Lilong Wang, Mianxin Liu, Lei Liu, Xiaosong Wang</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.16962">https://arxiv.org/abs/2506.16962</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.16962">https://arxiv.org/pdf/2506.16962</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.16962]] Enhancing Step-by-Step and Verifiable Medical Reasoning in MLLMs(https://arxiv.org/abs/2506.16962)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, large language model</a></li>
<li><strong>Abstract: </strong>Multimodal large language models (MLLMs) have begun to demonstrate robust reasoning capabilities on general tasks, yet their application in the medical domain remains in its early stages. Constructing chain-of-thought (CoT) training data is essential for bolstering the reasoning abilities of medical MLLMs. However, existing approaches exhibit a deficiency in offering a comprehensive framework for searching and evaluating effective reasoning paths towards critical diagnosis. To address this challenge, we propose Mentor-Intern Collaborative Search (MICS), a novel reasoning-path searching scheme to generate rigorous and effective medical CoT data. MICS first leverages mentor models to initialize the reasoning, one step at a time, then prompts each intern model to continue the thinking along those initiated paths, and finally selects the optimal reasoning path according to the overall reasoning performance of multiple intern models. The reasoning performance is determined by an MICS-Score, which assesses the quality of generated reasoning paths. Eventually, we construct MMRP, a multi-task medical reasoning dataset with ranked difficulty, and Chiron-o1, a new medical MLLM devised via a curriculum learning strategy, with robust visual question-answering and generalizable reasoning capabilities. Extensive experiments demonstrate that Chiron-o1, trained on our CoT dataset constructed using MICS, achieves state-of-the-art performance across a list of medical visual question answering and reasoning benchmarks. Codes are available at GitHub - manglu097/Chiron-o1: Enhancing Step-by-Step and Verifiable Medical Reasoning in MLLMs</li>
</ul>

<h3>Title: MM-AttacKG: A Multimodal Approach to Attack Graph Construction with Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Yongheng Zhang, Xinyun Zhao, Yunshan Ma, Haokai Ma, Yingxiao Guan, Guozheng Yang, Yuliang Lu, Xiang Wang</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.CY</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.16968">https://arxiv.org/abs/2506.16968</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.16968">https://arxiv.org/pdf/2506.16968</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.16968]] MM-AttacKG: A Multimodal Approach to Attack Graph Construction with Large Language Models(https://arxiv.org/abs/2506.16968)</code><input type="text"></li>
<li><strong>Keywords: </strong>defense, attack, extraction, large language model</a></li>
<li><strong>Abstract: </strong>Cyber Threat Intelligence (CTI) parsing aims to extract key threat information from massive data, transform it into actionable intelligence, enhance threat detection and defense efficiency, including attack graph construction, intelligence fusion and indicator extraction. Among these research topics, Attack Graph Construction (AGC) is essential for visualizing and understanding the potential attack paths of threat events from CTI reports. Existing approaches primarily construct the attack graphs purely from the textual data to reveal the logical threat relationships between entities within the attack behavioral sequence. However, they typically overlook the specific threat information inherent in visual modalities, which preserves the key threat details from inherently-multimodal CTI report. Therefore, we enhance the effectiveness of attack graph construction by analyzing visual information through Multimodal Large Language Models (MLLMs). Specifically, we propose a novel framework, MM-AttacKG, which can effectively extract key information from threat images and integrate it into attack graph construction, thereby enhancing the comprehensiveness and accuracy of attack graphs. It first employs a threat image parsing module to extract critical threat information from images and generate descriptions using MLLMs. Subsequently, it builds an iterative question-answering pipeline tailored for image parsing to refine the understanding of threat images. Finally, it achieves content-level integration between attack graphs and image-based answers through MLLMs, completing threat information enhancement. The experimental results demonstrate that MM-AttacKG can accurately identify key information in threat images and significantly improve the quality of multimodal attack graph construction, effectively addressing the shortcomings of existing methods in utilizing image-based threat information.</li>
</ul>

<h3>Title: Latent Concept Disentanglement in Transformer-based Language Models</h3>
<ul>
<li><strong>Authors: </strong>Guan Zhe Hong, Bhavya Vasudeva, Vatsal Sharan, Cyrus Rashtchian, Prabhakar Raghavan, Rina Panigrahy</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.16975">https://arxiv.org/abs/2506.16975</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.16975">https://arxiv.org/pdf/2506.16975</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.16975]] Latent Concept Disentanglement in Transformer-based Language Models(https://arxiv.org/abs/2506.16975)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer, large language model</a></li>
<li><strong>Abstract: </strong>When large language models (LLMs) use in-context learning (ICL) to solve a new task, they seem to grasp not only the goal of the task but also core, latent concepts in the demonstration examples. This begs the question of whether transformers represent latent structures as part of their computation or whether they take shortcuts to solve the problem. Prior mechanistic work on ICL does not address this question because it does not sufficiently examine the relationship between the learned representation and the latent concept, and the considered problem settings often involve only single-step reasoning. In this work, we examine how transformers disentangle and use latent concepts. We show that in 2-hop reasoning tasks with a latent, discrete concept, the model successfully identifies the latent concept and does step-by-step concept composition. In tasks parameterized by a continuous latent concept, we find low-dimensional subspaces in the representation space where the geometry mimics the underlying parameterization. Together, these results refine our understanding of ICL and the representation of transformers, and they provide evidence for highly localized structures in the model that disentangle latent concepts in ICL tasks.</li>
</ul>

<h3>Title: SmartGuard: Leveraging Large Language Models for Network Attack Detection through Audit Log Analysis and Summarization</h3>
<ul>
<li><strong>Authors: </strong>Hao Zhang, Shuo Shao, Song Li, Zhenyu Zhong, Yan Liu, Zhan Qin, Kui Ren</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.16981">https://arxiv.org/abs/2506.16981</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.16981">https://arxiv.org/pdf/2506.16981</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.16981]] SmartGuard: Leveraging Large Language Models for Network Attack Detection through Audit Log Analysis and Summarization(https://arxiv.org/abs/2506.16981)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, attack, large language model</a></li>
<li><strong>Abstract: </strong>End-point monitoring solutions are widely deployed in today's enterprise environments to support advanced attack detection and investigation. These monitors continuously record system-level activities as audit logs and provide deep visibility into security events. Unfortunately, existing methods of semantic analysis based on audit logs have low granularity, only reaching the system call level, making it difficult to effectively classify highly covert behaviors. Additionally, existing works mainly match audit log streams with rule knowledge bases describing behaviors, which heavily rely on expertise and lack the ability to detect unknown attacks and provide interpretive descriptions. In this paper, we propose SmartGuard, an automated method that combines abstracted behaviors from audit event semantics with large language models. SmartGuard extracts specific behaviors (function level) from incoming system logs and constructs a knowledge graph, divides events by threads, and combines event summaries with graph embeddings to achieve information diagnosis and provide explanatory narratives through large language models. Our evaluation shows that SmartGuard achieves an average F1 score of 96\% in assessing malicious behaviors and demonstrates good scalability across multiple models and unknown attacks. It also possesses excellent fine-tuning capabilities, allowing experts to assist in timely system updates.</li>
</ul>

<h3>Title: Language Bottleneck Models: A Framework for Interpretable Knowledge Tracing and Beyond</h3>
<ul>
<li><strong>Authors: </strong>Antonin Berthon, Mihaela van der Schaar</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.16982">https://arxiv.org/abs/2506.16982</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.16982">https://arxiv.org/pdf/2506.16982</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.16982]] Language Bottleneck Models: A Framework for Interpretable Knowledge Tracing and Beyond(https://arxiv.org/abs/2506.16982)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability</a></li>
<li><strong>Abstract: </strong>Accurately assessing student knowledge is critical for effective education, yet traditional Knowledge Tracing (KT) methods rely on opaque latent embeddings, limiting interpretability. Even LLM-based approaches generate direct predictions or summaries that may hallucinate without any accuracy guarantees. We recast KT as an inverse problem: learning the minimum natural-language summary that makes past answers explainable and future answers predictable. Our Language Bottleneck Model (LBM) consists of an encoder LLM that writes an interpretable knowledge summary and a frozen decoder LLM that must reconstruct and predict student responses using only that summary text. By constraining all predictive information to pass through a short natural-language bottleneck, LBMs ensure that the summary contains accurate information while remaining human-interpretable. Experiments on synthetic arithmetic benchmarks and the large-scale Eedi dataset show that LBMs rival the accuracy of state-of-the-art KT and direct LLM methods while requiring orders-of-magnitude fewer student trajectories. We demonstrate that training the encoder with group-relative policy optimization, using downstream decoding accuracy as a reward signal, effectively improves summary quality.</li>
</ul>

<h3>Title: TeXpert: A Multi-Level Benchmark for Evaluating LaTeX Code Generation by LLMs</h3>
<ul>
<li><strong>Authors: </strong>Sahil Kale, Vijaykant Nadadur</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.16990">https://arxiv.org/abs/2506.16990</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.16990">https://arxiv.org/pdf/2506.16990</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.16990]] TeXpert: A Multi-Level Benchmark for Evaluating LaTeX Code Generation by LLMs(https://arxiv.org/abs/2506.16990)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>LaTeX's precision and flexibility in typesetting have made it the gold standard for the preparation of scientific documentation. Large Language Models (LLMs) present a promising opportunity for researchers to produce publication-ready material using LaTeX with natural language instructions, yet current benchmarks completely lack evaluation of this ability. By introducing TeXpert, our benchmark dataset with natural language prompts for generating LaTeX code focused on components of scientific documents across multiple difficulty levels, we conduct an in-depth analysis of LLM performance in this regard and identify frequent error types. Our evaluation across open and closed-source LLMs highlights multiple key findings: LLMs excelling on standard benchmarks perform poorly in LaTeX generation with a significant accuracy drop-off as the complexity of tasks increases; open-source models like DeepSeek v3 and DeepSeek Coder strongly rival closed-source counterparts in LaTeX tasks; and formatting and package errors are unexpectedly prevalent, suggesting a lack of diverse LaTeX examples in the training datasets of most LLMs. Our dataset, code, and model evaluations are available at this https URL.</li>
</ul>

<h3>Title: ForestFormer3D: A Unified Framework for End-to-End Segmentation of Forest LiDAR 3D Point Clouds</h3>
<ul>
<li><strong>Authors: </strong>Binbin Xiang, Maciej Wielgosz, Stefano Puliti, Kamil Král, Martin Krůček, Azim Missarov, Rasmus Astrup</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.16991">https://arxiv.org/abs/2506.16991</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.16991">https://arxiv.org/pdf/2506.16991</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.16991]] ForestFormer3D: A Unified Framework for End-to-End Segmentation of Forest LiDAR 3D Point Clouds(https://arxiv.org/abs/2506.16991)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, segmentation</a></li>
<li><strong>Abstract: </strong>The segmentation of forest LiDAR 3D point clouds, including both individual tree and semantic segmentation, is fundamental for advancing forest management and ecological research. However, current approaches often struggle with the complexity and variability of natural forest environments. We present ForestFormer3D, a new unified and end-to-end framework designed for precise individual tree and semantic segmentation. ForestFormer3D incorporates ISA-guided query point selection, a score-based block merging strategy during inference, and a one-to-many association mechanism for effective training. By combining these new components, our model achieves state-of-the-art performance for individual tree segmentation on the newly introduced FOR-instanceV2 dataset, which spans diverse forest types and regions. Additionally, ForestFormer3D generalizes well to unseen test sets (Wytham woods and LAUTx), showcasing its robustness across different forest conditions and sensor modalities. The FOR-instanceV2 dataset and the ForestFormer3D code will be released soon.</li>
</ul>

<h3>Title: PersonalAI: Towards digital twins in the graph form</h3>
<ul>
<li><strong>Authors: </strong>Mikhail Menschikov, Dmitry Evseev, Ruslan Kostoev, Ilya Perepechkin, Ilnaz Salimov, Victoria Dochkina, Petr Anokhin, Evgeny Burnaev, Nikita Semenov</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.IR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.17001">https://arxiv.org/abs/2506.17001</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.17001">https://arxiv.org/pdf/2506.17001</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.17001]] PersonalAI: Towards digital twins in the graph form(https://arxiv.org/abs/2506.17001)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, extraction, large language model</a></li>
<li><strong>Abstract: </strong>The challenge of personalizing language models, specifically the ability to account for a user's history during interactions, is of significant interest. Despite recent advancements in large language models (LLMs) and Retrieval Augmented Generation that have enhanced the factual base of LLMs, the task of retaining extensive personal information and using it to generate personalized responses remains pertinent. To address this, we propose utilizing external memory in the form of knowledge graphs, which are constructed and updated by the LLM itself. We have expanded upon ideas of AriGraph architecture and for the first time introduced a combined graph featuring both standard edges and two types of hyperedges. Experiments conducted on the TriviaQA, HotpotQA and DiaASQ benchmarks indicates that this approach aids in making the process of graph construction and knowledge extraction unified and robust. Furthermore, we augmented the DiaASQ benchmark by incorporating parameters such as time into dialogues and introducing contradictory statements made by the same speaker at different times. Despite these modifications, the performance of the question-answering system remained robust, demonstrating the proposed architecture's ability to maintain and utilize temporal dependencies.</li>
</ul>

<h3>Title: LLM-Generated Feedback Supports Learning If Learners Choose to Use It</h3>
<ul>
<li><strong>Authors: </strong>Danielle R. Thomas, Conrad Borchers, Shambhavi Bhushan, Erin Gatz, Shivang Gupta, Kenneth R. Koedinger</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.CY</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.17006">https://arxiv.org/abs/2506.17006</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.17006">https://arxiv.org/pdf/2506.17006</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.17006]] LLM-Generated Feedback Supports Learning If Learners Choose to Use It(https://arxiv.org/abs/2506.17006)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large language models (LLMs) are increasingly used to generate feedback, yet their impact on learning remains underexplored, especially compared to existing feedback methods. This study investigates how on-demand LLM-generated explanatory feedback influences learning in seven scenario-based tutor training lessons. Analyzing over 2,600 lesson completions from 885 tutor learners, we compare posttest performance among learners across three groups: learners who received feedback generated by gpt-3.5-turbo, those who declined it, and those without access. All groups received non-LLM corrective feedback. To address potential selection bias-where higher-performing learners may be more inclined to use LLM feedback-we applied propensity scoring. Learners with a higher predicted likelihood of engaging with LLM feedback scored significantly higher at posttest than those with lower propensity. After adjusting for this effect, two out of seven lessons showed statistically significant learning benefits from LLM feedback with standardized effect sizes of 0.28 and 0.33. These moderate effects suggest that the effectiveness of LLM feedback depends on the learners' tendency to seek support. Importantly, LLM feedback did not significantly increase completion time, and learners overwhelmingly rated it as helpful. These findings highlight LLM feedback's potential as a low-cost and scalable way to improve learning on open-ended tasks, particularly in existing systems already providing feedback without LLMs. This work contributes open datasets, LLM prompts, and rubrics to support reproducibility.</li>
</ul>

<h3>Title: Robust Reinforcement Learning for Discrete Compositional Generation via General Soft Operators</h3>
<ul>
<li><strong>Authors: </strong>Marco Jiralerspong, Esther Derman, Danilo Vucetic, Nikolay Malkin, Bilun Sun, Tianyu Zhang, Pierre-Luc Bacon, Gauthier Gidel</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.17007">https://arxiv.org/abs/2506.17007</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.17007">https://arxiv.org/pdf/2506.17007</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.17007]] Robust Reinforcement Learning for Discrete Compositional Generation via General Soft Operators(https://arxiv.org/abs/2506.17007)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>A major bottleneck in scientific discovery involves narrowing a large combinatorial set of objects, such as proteins or molecules, to a small set of promising candidates. While this process largely relies on expert knowledge, recent methods leverage reinforcement learning (RL) to enhance this filtering. They achieve this by estimating proxy reward functions from available datasets and using regularization to generate more diverse candidates. These reward functions are inherently uncertain, raising a particularly salient challenge for scientific discovery. In this work, we show that existing methods, often framed as sampling proportional to a reward function, are inadequate and yield suboptimal candidates, especially in large search spaces. To remedy this issue, we take a robust RL approach and introduce a unified operator that seeks robustness to the uncertainty of the proxy reward function. This general operator targets peakier sampling distributions while encompassing known soft RL operators. It also leads us to a novel algorithm that identifies higher-quality, diverse candidates in both synthetic and real-world tasks. Ultimately, our work offers a new, flexible perspective on discrete compositional generation tasks. Code: this https URL.</li>
</ul>

<h3>Title: A Novel Approach to Differential Privacy with Alpha Divergence</h3>
<ul>
<li><strong>Authors: </strong>Yifeng Liu, Zehua Wang</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.17012">https://arxiv.org/abs/2506.17012</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.17012">https://arxiv.org/pdf/2506.17012</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.17012]] A Novel Approach to Differential Privacy with Alpha Divergence(https://arxiv.org/abs/2506.17012)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy</a></li>
<li><strong>Abstract: </strong>As data-driven technologies advance swiftly, maintaining strong privacy measures becomes progressively difficult. Conventional $(\epsilon, \delta)$-differential privacy, while prevalent, exhibits limited adaptability for many applications. To mitigate these constraints, we present alpha differential privacy (ADP), an innovative privacy framework grounded in alpha divergence, which provides a more flexible assessment of privacy consumption. This study delineates the theoretical underpinnings of ADP and contrasts its performance with competing privacy frameworks across many scenarios. Empirical assessments demonstrate that ADP offers enhanced privacy guarantees in small to moderate iteration contexts, particularly where severe privacy requirements are necessary. The suggested method markedly improves privacy-preserving methods, providing a flexible solution for contemporary data analysis issues in a data-centric environment.</li>
</ul>

<h3>Title: The Hidden Cost of an Image: Quantifying the Energy Consumption of AI Image Generation</h3>
<ul>
<li><strong>Authors: </strong>Giulia Bertazzini, Chiara Albisani, Daniele Baracchi, Dasara Shullani, Roberto Verdecchia</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.MM</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.17016">https://arxiv.org/abs/2506.17016</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.17016">https://arxiv.org/pdf/2506.17016</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.17016]] The Hidden Cost of an Image: Quantifying the Energy Consumption of AI Image Generation(https://arxiv.org/abs/2506.17016)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>With the growing adoption of AI image generation, in conjunction with the ever-increasing environmental resources demanded by AI, we are urged to answer a fundamental question: What is the environmental impact hidden behind each image we generate? In this research, we present a comprehensive empirical experiment designed to assess the energy consumption of AI image generation. Our experiment compares 17 state-of-the-art image generation models by considering multiple factors that could affect their energy consumption, such as model quantization, image resolution, and prompt length. Additionally, we consider established image quality metrics to study potential trade-offs between energy consumption and generated image quality. Results show that image generation models vary drastically in terms of the energy they consume, with up to a 46x difference. Image resolution affects energy consumption inconsistently, ranging from a 1.3x to 4.7x increase when doubling resolution. U-Net-based models tend to consume less than Transformer-based one. Model quantization instead results to deteriorate the energy efficiency of most models, while prompt length and content have no statistically significant impact. Improving image quality does not always come at the cost of a higher energy consumption, with some of the models producing the highest quality images also being among the most energy efficient ones.</li>
</ul>

<h3>Title: Unsupervised Image Super-Resolution Reconstruction Based on Real-World Degradation Patterns</h3>
<ul>
<li><strong>Authors: </strong>Yiyang Tie, Hong Zhu, Yunyun Luo, Jing Shi</a></li>
<li><strong>Subjects: </strong>cs.CV, eess.IV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.17027">https://arxiv.org/abs/2506.17027</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.17027">https://arxiv.org/pdf/2506.17027</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.17027]] Unsupervised Image Super-Resolution Reconstruction Based on Real-World Degradation Patterns(https://arxiv.org/abs/2506.17027)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction</a></li>
<li><strong>Abstract: </strong>The training of real-world super-resolution reconstruction models heavily relies on datasets that reflect real-world degradation patterns. Extracting and modeling degradation patterns for super-resolution reconstruction using only real-world low-resolution (LR) images remains a challenging task. When synthesizing datasets to simulate real-world degradation, relying solely on degradation extraction methods fails to capture both blur and diverse noise characteristics across varying LR distributions, as well as more implicit degradations such as color gamut shifts. Conversely, domain translation alone cannot accurately approximate real-world blur characteristics due to the significant degradation domain gap between synthetic and real data. To address these challenges, we propose a novel TripleGAN framework comprising two strategically designed components: The FirstGAN primarily focuses on narrowing the domain gap in blur characteristics, while the SecondGAN performs domain-specific translation to approximate target-domain blur properties and learn additional degradation patterns. The ThirdGAN is trained on pseudo-real data generated by the FirstGAN and SecondGAN to reconstruct real-world LR images. Extensive experiments on the RealSR and DRealSR datasets demonstrate that our method exhibits clear advantages in quantitative metrics while maintaining sharp reconstructions without over-smoothing artifacts. The proposed framework effectively learns real-world degradation patterns from LR observations and synthesizes aligned datasets with corresponding degradation characteristics, thereby enabling the trained network to achieve superior performance in reconstructing high-quality SR images from real-world LR inputs.</li>
</ul>

<h3>Title: Critical Appraisal of Fairness Metrics in Clinical Predictive AI</h3>
<ul>
<li><strong>Authors: </strong>João Matos, Ben Van Calster, Leo Anthony Celi, Paula Dhiman, Judy Wawira Gichoya, Richard D. Riley, Chris Russell, Sara Khalid, Gary S. Collins</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.17035">https://arxiv.org/abs/2506.17035</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.17035">https://arxiv.org/pdf/2506.17035</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.17035]] Critical Appraisal of Fairness Metrics in Clinical Predictive AI(https://arxiv.org/abs/2506.17035)</code><input type="text"></li>
<li><strong>Keywords: </strong>fair</a></li>
<li><strong>Abstract: </strong>Predictive artificial intelligence (AI) offers an opportunity to improve clinical practice and patient outcomes, but risks perpetuating biases if fairness is inadequately addressed. However, the definition of "fairness" remains unclear. We conducted a scoping review to identify and critically appraise fairness metrics for clinical predictive AI. We defined a "fairness metric" as a measure quantifying whether a model discriminates (societally) against individuals or groups defined by sensitive attributes. We searched five databases (2014-2024), screening 820 records, to include 41 studies, and extracted 62 fairness metrics. Metrics were classified by performance-dependency, model output level, and base performance metric, revealing a fragmented landscape with limited clinical validation and overreliance on threshold-dependent measures. Eighteen metrics were explicitly developed for healthcare, including only one clinical utility metric. Our findings highlight conceptual challenges in defining and quantifying fairness and identify gaps in uncertainty quantification, intersectionality, and real-world applicability. Future work should prioritise clinically meaningful metrics.</li>
</ul>

<h3>Title: LSCD: Lomb-Scargle Conditioned Diffusion for Time series Imputation</h3>
<ul>
<li><strong>Authors: </strong>Elizabeth Fons, Alejandro Sztrajman, Yousef El-Laham, Luciana Ferrer, Svitlana Vyetrenko, Manuela Veloso</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.17039">https://arxiv.org/abs/2506.17039</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.17039">https://arxiv.org/pdf/2506.17039</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.17039]] LSCD: Lomb-Scargle Conditioned Diffusion for Time series Imputation(https://arxiv.org/abs/2506.17039)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>Time series with missing or irregularly sampled data are a persistent challenge in machine learning. Many methods operate on the frequency-domain, relying on the Fast Fourier Transform (FFT) which assumes uniform sampling, therefore requiring prior interpolation that can distort the spectra. To address this limitation, we introduce a differentiable Lomb--Scargle layer that enables a reliable computation of the power spectrum of irregularly sampled data. We integrate this layer into a novel score-based diffusion model (LSCD) for time series imputation conditioned on the entire signal spectrum. Experiments on synthetic and real-world benchmarks demonstrate that our method recovers missing data more accurately than purely time-domain baselines, while simultaneously producing consistent frequency estimates. Crucially, our method can be easily integrated into learning frameworks, enabling broader adoption of spectral guidance in machine learning approaches involving incomplete or irregular data.</li>
</ul>

<h3>Title: Stretching Beyond the Obvious: A Gradient-Free Framework to Unveil the Hidden Landscape of Visual Invariance</h3>
<ul>
<li><strong>Authors: </strong>Lorenzo Tausani, Paolo Muratore, Morgan B. Talbot, Giacomo Amerio, Gabriel Kreiman, Davide Zoccolan</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.NE</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.17040">https://arxiv.org/abs/2506.17040</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.17040">https://arxiv.org/pdf/2506.17040</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.17040]] Stretching Beyond the Obvious: A Gradient-Free Framework to Unveil the Hidden Landscape of Visual Invariance(https://arxiv.org/abs/2506.17040)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Uncovering which features' combinations high-level visual units encode is critical to understand how images are transformed into representations that support recognition. While existing feature visualization approaches typically infer a unit's most exciting images, this is insufficient to reveal the manifold of transformations under which responses remain invariant, which is key to generalization in vision. Here we introduce Stretch-and-Squeeze (SnS), an unbiased, model-agnostic, and gradient-free framework to systematically characterize a unit's invariance landscape and its vulnerability to adversarial perturbations in both biological and artificial visual systems. SnS frames these transformations as bi-objective optimization problems. To probe invariance, SnS seeks image perturbations that maximally alter the representation of a reference stimulus in a given processing stage while preserving unit activation. To probe adversarial sensitivity, SnS seeks perturbations that minimally alter the stimulus while suppressing unit activation. Applied to convolutional neural networks (CNNs), SnS revealed image variations that were further from a reference image in pixel-space than those produced by affine transformations, while more strongly preserving the target unit's response. The discovered invariant images differed dramatically depending on the choice of image representation used for optimization: pixel-level changes primarily affected luminance and contrast, while stretching mid- and late-layer CNN representations altered texture and pose respectively. Notably, the invariant images from robust networks were more recognizable by human subjects than those from standard networks, supporting the higher fidelity of robust CNNs as models of the visual system.</li>
</ul>

<h3>Title: MUCAR: Benchmarking Multilingual Cross-Modal Ambiguity Resolution for Multimodal Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Xiaolong Wang, Zhaolu Kang, Wangyuxuan Zhai, Xinyue Lou, Yunghwei Lai, Ziyue Wang, Yawen Wang, Kaiyu Huang, Yile Wang, Peng Li, Yang Liu</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.17046">https://arxiv.org/abs/2506.17046</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.17046">https://arxiv.org/pdf/2506.17046</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.17046]] MUCAR: Benchmarking Multilingual Cross-Modal Ambiguity Resolution for Multimodal Large Language Models(https://arxiv.org/abs/2506.17046)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Multimodal Large Language Models (MLLMs) have demonstrated significant advances across numerous vision-language tasks. Due to their strong image-text alignment capability, MLLMs can effectively understand image-text pairs with clear meanings. However, effectively resolving the inherent ambiguities in natural language and visual contexts remains challenging. Existing multimodal benchmarks typically overlook linguistic and visual ambiguities, relying mainly on unimodal context for disambiguation and thus failing to exploit the mutual clarification potential between modalities. To bridge this gap, we introduce MUCAR, a novel and challenging benchmark designed explicitly for evaluating multimodal ambiguity resolution across multilingual and cross-modal scenarios. MUCAR includes: (1) a multilingual dataset where ambiguous textual expressions are uniquely resolved by corresponding visual contexts, and (2) a dual-ambiguity dataset that systematically pairs ambiguous images with ambiguous textual contexts, with each combination carefully constructed to yield a single, clear interpretation through mutual disambiguation. Extensive evaluations involving 19 state-of-the-art multimodal models--encompassing both open-source and proprietary architectures--reveal substantial gaps compared to human-level performance, highlighting the need for future research into more sophisticated cross-modal ambiguity comprehension methods, further pushing the boundaries of multimodal reasoning.</li>
</ul>

<h3>Title: Navigating the Deep: Signature Extraction on Deep Neural Networks</h3>
<ul>
<li><strong>Authors: </strong>Haolin Liu, Adrien Siproudhis, Samuel Experton, Peter Lorenz, Christina Boura, Thomas Peyrin</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.17047">https://arxiv.org/abs/2506.17047</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.17047">https://arxiv.org/pdf/2506.17047</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.17047]] Navigating the Deep: Signature Extraction on Deep Neural Networks(https://arxiv.org/abs/2506.17047)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, attack, extraction</a></li>
<li><strong>Abstract: </strong>Neural network model extraction has emerged in recent years as an important security concern, as adversaries attempt to recover a network's parameters via black-box queries. A key step in this process is signature extraction, which aims to recover the absolute values of the network's weights layer by layer. Prior work, notably by Carlini et al. (2020), introduced a technique inspired by differential cryptanalysis to extract neural network parameters. However, their method suffers from several limitations that restrict its applicability to networks with a few layers only. Later works focused on improving sign extraction, but largely relied on the assumption that signature extraction itself was feasible. In this work, we revisit and refine the signature extraction process by systematically identifying and addressing for the first time critical limitations of Carlini et al.'s signature extraction method. These limitations include rank deficiency and noise propagation from deeper layers. To overcome these challenges, we propose efficient algorithmic solutions for each of the identified issues, greatly improving the efficiency of signature extraction. Our approach permits the extraction of much deeper networks than was previously possible. We validate our method through extensive experiments on ReLU-based neural networks, demonstrating significant improvements in extraction depth and accuracy. For instance, our extracted network matches the target network on at least 95% of the input space for each of the eight layers of a neural network trained on the CIFAR-10 dataset, while previous works could barely extract the first three layers. Our results represent a crucial step toward practical attacks on larger and more complex neural network architectures.</li>
</ul>

<h3>Title: Relaxed syntax modeling in Transformers for future-proof license plate recognition</h3>
<ul>
<li><strong>Authors: </strong>Florent Meyer, Laurent Guichard, Denis Coquenet, Guillaume Gravier, Yann Soullard, Bertrand Coüasnon</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.17051">https://arxiv.org/abs/2506.17051</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.17051">https://arxiv.org/pdf/2506.17051</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.17051]] Relaxed syntax modeling in Transformers for future-proof license plate recognition(https://arxiv.org/abs/2506.17051)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, transformer</a></li>
<li><strong>Abstract: </strong>Effective license plate recognition systems are required to be resilient to constant change, as new license plates are released into traffic daily. While Transformer-based networks excel in their recognition at first sight, we observe significant performance drop over time which proves them unsuitable for tense production environments. Indeed, such systems obtain state-of-the-art results on plates whose syntax is seen during training. Yet, we show they perform similarly to random guessing on future plates where legible characters are wrongly recognized due to a shift in their syntax. After highlighting the flows of positional and contextual information in Transformer encoder-decoders, we identify several causes for their over-reliance on past syntax. Following, we devise architectural cut-offs and replacements which we integrate into SaLT, an attempt at a Syntax-Less Transformer for syntax-agnostic modeling of license plate representations. Experiments on both real and synthetic datasets show that our approach reaches top accuracy on past syntax and most importantly nearly maintains performance on future license plates. We further demonstrate the robustness of our architecture enhancements by way of various ablations.</li>
</ul>

<h3>Title: From Concepts to Components: Concept-Agnostic Attention Module Discovery in Transformers</h3>
<ul>
<li><strong>Authors: </strong>Jingtong Su, Julia Kempe, Karen Ullrich</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.17052">https://arxiv.org/abs/2506.17052</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.17052">https://arxiv.org/pdf/2506.17052</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.17052]] From Concepts to Components: Concept-Agnostic Attention Module Discovery in Transformers(https://arxiv.org/abs/2506.17052)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability, transformer</a></li>
<li><strong>Abstract: </strong>Transformers have achieved state-of-the-art performance across language and vision tasks. This success drives the imperative to interpret their internal mechanisms with the dual goals of enhancing performance and improving behavioral control. Attribution methods help advance interpretability by assigning model outputs associated with a target concept to specific model components. Current attribution research primarily studies multi-layer perceptron neurons and addresses relatively simple concepts such as factual associations (e.g., Paris is located in France). This focus tends to overlook the impact of the attention mechanism and lacks a unified approach for analyzing more complex concepts. To fill these gaps, we introduce Scalable Attention Module Discovery (SAMD), a concept-agnostic method for mapping arbitrary, complex concepts to specific attention heads of general transformer models. We accomplish this by representing each concept as a vector, calculating its cosine similarity with each attention head, and selecting the TopK-scoring heads to construct the concept-associated attention module. We then propose Scalar Attention Module Intervention (SAMI), a simple strategy to diminish or amplify the effects of a concept by adjusting the attention module using only a single scalar parameter. Empirically, we demonstrate SAMD on concepts of varying complexity, and visualize the locations of their corresponding modules. Our results demonstrate that module locations remain stable before and after LLM post-training, and confirm prior work on the mechanics of LLM multilingualism. Through SAMI, we facilitate jailbreaking on HarmBench (+72.7%) by diminishing "safety" and improve performance on the GSM8K benchmark (+1.6%) by amplifying "reasoning". Lastly, we highlight the domain-agnostic nature of our approach by suppressing the image classification accuracy of vision transformers on ImageNet.</li>
</ul>

<h3>Title: Empowering Near-Field Communications in Low-Altitude Economy with LLM: Fundamentals, Potentials, Solutions, and Future Directions</h3>
<ul>
<li><strong>Authors: </strong>Zhuo Xu, Tianyue Zheng, Linglong Dai</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.IT</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.17067">https://arxiv.org/abs/2506.17067</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.17067">https://arxiv.org/pdf/2506.17067</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.17067]] Empowering Near-Field Communications in Low-Altitude Economy with LLM: Fundamentals, Potentials, Solutions, and Future Directions(https://arxiv.org/abs/2506.17067)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>The low-altitude economy (LAE) is gaining significant attention from academia and industry. Fortunately, LAE naturally aligns with near-field communications in extremely large-scale MIMO (XL-MIMO) systems. By leveraging near-field beamfocusing, LAE can precisely direct beam energy to unmanned aerial vehicles, while the additional distance dimension boosts overall spectrum efficiency. However, near-field communications in LAE still face several challenges, such as the increase in signal processing complexity and the necessity of distinguishing between far and near-field users. Inspired by the large language models (LLM) with powerful ability to handle complex problems, we apply LLM to solve challenges of near-field communications in LAE. The objective of this article is to provide a comprehensive analysis and discussion on LLM-empowered near-field communications in LAE. Specifically, we first introduce fundamentals of LLM and near-field communications, including the key advantages of LLM and key characteristics of near-field communications. Then, we reveal the opportunities and challenges of near-field communications in LAE. To address these challenges, we present a LLM-based scheme for near-field communications in LAE, and provide a case study which jointly distinguishes far and near-field users and designs multi-user precoding matrix. Finally, we outline and highlight several future research directions and open issues.</li>
</ul>

<h3>Title: Assembler: Scalable 3D Part Assembly via Anchor Point Diffusion</h3>
<ul>
<li><strong>Authors: </strong>Wang Zhao, Yan-Pei Cao, Jiale Xu, Yuejiang Dong, Ying Shan</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.17074">https://arxiv.org/abs/2506.17074</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.17074">https://arxiv.org/pdf/2506.17074</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.17074]] Assembler: Scalable 3D Part Assembly via Anchor Point Diffusion(https://arxiv.org/abs/2506.17074)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, generative</a></li>
<li><strong>Abstract: </strong>We present Assembler, a scalable and generalizable framework for 3D part assembly that reconstructs complete objects from input part meshes and a reference image. Unlike prior approaches that mostly rely on deterministic part pose prediction and category-specific training, Assembler is designed to handle diverse, in-the-wild objects with varying part counts, geometries, and structures. It addresses the core challenges of scaling to general 3D part assembly through innovations in task formulation, representation, and data. First, Assembler casts part assembly as a generative problem and employs diffusion models to sample plausible configurations, effectively capturing ambiguities arising from symmetry, repeated parts, and multiple valid assemblies. Second, we introduce a novel shape-centric representation based on sparse anchor point clouds, enabling scalable generation in Euclidean space rather than SE(3) pose prediction. Third, we construct a large-scale dataset of over 320K diverse part-object assemblies using a synthesis and filtering pipeline built on existing 3D shape repositories. Assembler achieves state-of-the-art performance on PartNet and is the first to demonstrate high-quality assembly for complex, real-world objects. Based on Assembler, we further introduce an interesting part-aware 3D modeling system that generates high-resolution, editable objects from images, demonstrating potential for interactive and compositional design. Project page: this https URL</li>
</ul>

<h3>Title: Chain-of-Thought Prompting Obscures Hallucination Cues in Large Language Models: An Empirical Evaluation</h3>
<ul>
<li><strong>Authors: </strong>Jiahao Cheng, Tiancheng Su, Jia Yuan, Guoxiu He, Jiawei Liu, Xinqi Tao, Jingwen Xie, Huaxia Li</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.17088">https://arxiv.org/abs/2506.17088</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.17088">https://arxiv.org/pdf/2506.17088</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.17088]] Chain-of-Thought Prompting Obscures Hallucination Cues in Large Language Models: An Empirical Evaluation(https://arxiv.org/abs/2506.17088)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large Language Models (LLMs) often exhibit \textit{hallucinations}, generating factually incorrect or semantically irrelevant content in response to prompts. Chain-of-Thought (CoT) prompting can mitigate hallucinations by encouraging step-by-step reasoning, but its impact on hallucination detection remains underexplored. To bridge this gap, we conduct a systematic empirical evaluation. We begin with a pilot experiment, revealing that CoT reasoning significantly affects the LLM's internal states and token probability distributions. Building on this, we evaluate the impact of various CoT prompting methods on mainstream hallucination detection methods across both instruction-tuned and reasoning-oriented LLMs. Specifically, we examine three key dimensions: changes in hallucination score distributions, variations in detection accuracy, and shifts in detection confidence. Our findings show that while CoT prompting helps reduce hallucination frequency, it also tends to obscure critical signals used for detection, impairing the effectiveness of various detection methods. Our study highlights an overlooked trade-off in the use of reasoning. Code is publicly available at: this https URL.</li>
</ul>

<h3>Title: Better Language Model Inversion by Compactly Representing Next-Token Distributions</h3>
<ul>
<li><strong>Authors: </strong>Murtaza Nazir, Matthew Finlayson, John X. Morris, Xiang Ren, Swabha Swayamdipta</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.17090">https://arxiv.org/abs/2506.17090</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.17090">https://arxiv.org/pdf/2506.17090</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.17090]] Better Language Model Inversion by Compactly Representing Next-Token Distributions(https://arxiv.org/abs/2506.17090)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, protect, attack</a></li>
<li><strong>Abstract: </strong>Language model inversion seeks to recover hidden prompts using only language model outputs. This capability has implications for security and accountability in language model deployments, such as leaking private information from an API-protected language model's system message. We propose a new method -- prompt inversion from logprob sequences (PILS) -- that recovers hidden prompts by gleaning clues from the model's next-token probabilities over the course of multiple generation steps. Our method is enabled by a key insight: The vector-valued outputs of a language model occupy a low-dimensional subspace. This enables us to losslessly compress the full next-token probability distribution over multiple generation steps using a linear map, allowing more output information to be used for inversion. Our approach yields massive gains over previous state-of-the-art methods for recovering hidden prompts, achieving 2--3.5 times higher exact recovery rates across test sets, in one case increasing the recovery rate from 17% to 60%. Our method also exhibits surprisingly good generalization behavior; for instance, an inverter trained on 16 generations steps gets 5--27 points higher prompt recovery when we increase the number of steps to 32 at test time. Furthermore, we demonstrate strong performance of our method on the more challenging task of recovering hidden system messages. We also analyze the role of verbatim repetition in prompt recovery and propose a new method for cross-family model transfer for logit-based inverters. Our findings show that next-token probabilities are a considerably more vulnerable attack surface for inversion attacks than previously known.</li>
</ul>

<h3>Title: Identifiability of Deep Polynomial Neural Networks</h3>
<ul>
<li><strong>Authors: </strong>Konstantin Usevich, Clara Dérand, Ricardo Borsoi, Marianne Clausel</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, math.AG, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.17093">https://arxiv.org/abs/2506.17093</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.17093">https://arxiv.org/pdf/2506.17093</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.17093]] Identifiability of Deep Polynomial Neural Networks(https://arxiv.org/abs/2506.17093)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability</a></li>
<li><strong>Abstract: </strong>Polynomial Neural Networks (PNNs) possess a rich algebraic and geometric structure. However, their identifiability -- a key property for ensuring interpretability -- remains poorly understood. In this work, we present a comprehensive analysis of the identifiability of deep PNNs, including architectures with and without bias terms. Our results reveal an intricate interplay between activation degrees and layer widths in achieving identifiability. As special cases, we show that architectures with non-increasing layer widths are generically identifiable under mild conditions, while encoder-decoder networks are identifiable when the decoder widths do not grow too rapidly. Our proofs are constructive and center on a connection between deep PNNs and low-rank tensor decompositions, and Kruskal-type uniqueness theorems. This yields both generic conditions determined by the architecture, and effective conditions that depend on the network's parameters. We also settle an open conjecture on the expected dimension of PNN's neurovarieties, and provide new bounds on the activation degrees required for it to reach its maximum.</li>
</ul>

<h3>Title: TransDreamerV3: Implanting Transformer In DreamerV3</h3>
<ul>
<li><strong>Authors: </strong>Shruti Sadanand Dongare, Amun Kharel, Jonathan Samuel, Xiaona Zhou</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.17103">https://arxiv.org/abs/2506.17103</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.17103">https://arxiv.org/pdf/2506.17103</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.17103]] TransDreamerV3: Implanting Transformer In DreamerV3(https://arxiv.org/abs/2506.17103)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>This paper introduces TransDreamerV3, a reinforcement learning model that enhances the DreamerV3 architecture by integrating a transformer encoder. The model is designed to improve memory and decision-making capabilities in complex environments. We conducted experiments on Atari-Boxing, Atari-Freeway, Atari-Pong, and Crafter tasks, where TransDreamerV3 demonstrated improved performance over DreamerV3, particularly in the Atari-Freeway and Crafter tasks. While issues in the Minecraft task and limited training across all tasks were noted, TransDreamerV3 displays advancement in world model-based reinforcement learning, leveraging transformer architectures.</li>
</ul>

<h3>Title: RGBTrack: Fast, Robust Depth-Free 6D Pose Estimation and Tracking</h3>
<ul>
<li><strong>Authors: </strong>Teng Guo, Jingjin Yu</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.RO</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.17119">https://arxiv.org/abs/2506.17119</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.17119">https://arxiv.org/pdf/2506.17119</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.17119]] RGBTrack: Fast, Robust Depth-Free 6D Pose Estimation and Tracking(https://arxiv.org/abs/2506.17119)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, generative</a></li>
<li><strong>Abstract: </strong>We introduce a robust framework, RGBTrack, for real-time 6D pose estimation and tracking that operates solely on RGB data, thereby eliminating the need for depth input for such dynamic and precise object pose tracking tasks. Building on the FoundationPose architecture, we devise a novel binary search strategy combined with a render-and-compare mechanism to efficiently infer depth and generate robust pose hypotheses from true-scale CAD models. To maintain stable tracking in dynamic scenarios, including rapid movements and occlusions, RGBTrack integrates state-of-the-art 2D object tracking (XMem) with a Kalman filter and a state machine for proactive object pose recovery. In addition, RGBTrack's scale recovery module dynamically adapts CAD models of unknown scale using an initial depth estimate, enabling seamless integration with modern generative reconstruction techniques. Extensive evaluations on benchmark datasets demonstrate that RGBTrack's novel depth-free approach achieves competitive accuracy and real-time performance, making it a promising practical solution candidate for application areas including robotics, augmented reality, and computer vision. The source code for our implementation will be made publicly available at this https URL.</li>
</ul>

<h3>Title: Cache Me If You Can: How Many KVs Do You Need for Effective Long-Context LMs?</h3>
<ul>
<li><strong>Authors: </strong>Adithya Bhaskar, Alexander Wettig, Tianyu Gao, Yihe Dong, Danqi Chen</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.17121">https://arxiv.org/abs/2506.17121</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.17121">https://arxiv.org/pdf/2506.17121</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.17121]] Cache Me If You Can: How Many KVs Do You Need for Effective Long-Context LMs?(https://arxiv.org/abs/2506.17121)</code><input type="text"></li>
<li><strong>Keywords: </strong>fair</a></li>
<li><strong>Abstract: </strong>Language models handle increasingly long contexts for tasks such as book summarization, but this leads to growing memory costs for the key-value (KV) cache. Many prior works have proposed ways of discarding KVs from memory, but their approaches are tailored to favorable settings, obscuring caveats like high peak memory and performance degradation, and a fair comparison between methods is difficult. In this paper, we propose the *KV footprint* as a unified metric, which accounts for both the amount of KV entries stored and their lifespan in memory. We evaluate methods based on the smallest footprint they attain while preserving performance in both long-context understanding and generation, with context lengths of up to 128K tokens. This metric reveals the high peak memory of prior KV eviction methods. One class of methods -- *post-fill eviction* -- has a high footprint due to being incompatible with eviction during pre-filling. We adapt these methods to be able to evict KVs during pre-filling, achieving substantially lower KV footprints. We then turn to *recency eviction* methods, wherein we propose PruLong, an end-to-end optimization method for learning which attention heads need to retain the full KV cache and which do not. PruLong saves memory while preserving long-context performance, achieving 12% smaller KV footprint than prior methods while retaining performance in challenging recall tasks. Our paper clarifies the complex tangle of long-context inference methods and paves the way for future development to minimize the KV footprint.</li>
</ul>

<h3>Title: Dynamic Watermark Generation for Digital Images using Perimeter Gated SPAD Imager PUFs</h3>
<ul>
<li><strong>Authors: </strong>Md Sakibur Sajal, Marc Dandin</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.17134">https://arxiv.org/abs/2506.17134</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.17134">https://arxiv.org/pdf/2506.17134</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.17134]] Dynamic Watermark Generation for Digital Images using Perimeter Gated SPAD Imager PUFs(https://arxiv.org/abs/2506.17134)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, robust, watermark</a></li>
<li><strong>Abstract: </strong>Digital image watermarks as a security feature can be derived from the imager's physically unclonable functions (PUFs) by utilizing the manufacturing variations, i.e., the dark signal non-uniformity (DSNU). While a few demonstrations focused on the CMOS image sensors (CIS) and active pixel sensors (APS), single photon avalanche diode (SPAD) imagers have never been investigated for this purpose. In this work, we have proposed a novel watermarking technique using perimeter gated SPAD (pgSPAD) imagers. We utilized the DSNU of three 64 x 64 pgSPAD imager chips, fabricated in a 0.35 {\mu}m standard CMOS process and analyzed the simulated watermarks for standard test images from publicly available database. Our observation shows that both source identification and tamper detection can be achieved using the proposed source-scene-specific dynamic watermarks with a controllable sensitivity-robustness trade-off.</li>
</ul>

<h3>Title: Semi-Supervised Multi-Modal Medical Image Segmentation for Complex Situations</h3>
<ul>
<li><strong>Authors: </strong>Dongdong Meng, Sheng Li, Hao Wu, Guoping Wang, Xueqing Yan</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.17136">https://arxiv.org/abs/2506.17136</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.17136">https://arxiv.org/pdf/2506.17136</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.17136]] Semi-Supervised Multi-Modal Medical Image Segmentation for Complex Situations(https://arxiv.org/abs/2506.17136)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, segmentation</a></li>
<li><strong>Abstract: </strong>Semi-supervised learning addresses the issue of limited annotations in medical images effectively, but its performance is often inadequate for complex backgrounds and challenging tasks. Multi-modal fusion methods can significantly improve the accuracy of medical image segmentation by providing complementary information. However, they face challenges in achieving significant improvements under semi-supervised conditions due to the challenge of effectively leveraging unlabeled data. There is a significant need to create an effective and reliable multi-modal learning strategy for leveraging unlabeled data in semi-supervised segmentation. To address these issues, we propose a novel semi-supervised multi-modal medical image segmentation approach, which leverages complementary multi-modal information to enhance performance with limited labeled data. Our approach employs a multi-stage multi-modal fusion and enhancement strategy to fully utilize complementary multi-modal information, while reducing feature discrepancies and enhancing feature sharing and alignment. Furthermore, we effectively introduce contrastive mutual learning to constrain prediction consistency across modalities, thereby facilitating the robustness of segmentation results in semi-supervised tasks. Experimental results on two multi-modal datasets demonstrate the superior performance and robustness of the proposed framework, establishing its valuable potential for solving medical image segmentation tasks in complex scenarios.</li>
</ul>

<h3>Title: Consistent Sampling and Simulation: Molecular Dynamics with Energy-Based Diffusion Models</h3>
<ul>
<li><strong>Authors: </strong>Michael Plainer, Hao Wu, Leon Klein, Stephan Günnemann, Frank Noé</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, physics.chem-ph, physics.comp-ph, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.17139">https://arxiv.org/abs/2506.17139</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.17139">https://arxiv.org/pdf/2506.17139</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.17139]] Consistent Sampling and Simulation: Molecular Dynamics with Energy-Based Diffusion Models(https://arxiv.org/abs/2506.17139)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, generative</a></li>
<li><strong>Abstract: </strong>Diffusion models have recently gained significant attention due to their effectiveness in various scientific domains, including biochemistry. When trained on equilibrium molecular distributions, diffusion models provide both: a generative procedure to sample equilibrium conformations and associated forces derived from the model's scores. However, using the forces for coarse-grained molecular dynamics simulations uncovers inconsistencies in the samples generated via classical diffusion inference and simulation, despite both originating from the same model. Particularly at the small diffusion timesteps required for simulations, diffusion models fail to satisfy the Fokker-Planck equation, which governs how the score should evolve over time. We interpret this deviation as an indication of the observed inconsistencies and propose an energy-based diffusion model with a Fokker-Planck-derived regularization term enforcing consistency. We demonstrate the effectiveness of our approach on toy systems, alanine dipeptide, and introduce a state-of-the-art transferable Boltzmann emulator for dipeptides that supports simulation and demonstrates enhanced consistency and efficient sampling.</li>
</ul>

<h3>Title: Do We Need Large VLMs for Spotting Soccer Actions?</h3>
<ul>
<li><strong>Authors: </strong>Ritabrata Chakraborty, Rajatsubhra Chakraborty, Avijit Dasgupta, Sandeep Chaurasia</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.17144">https://arxiv.org/abs/2506.17144</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.17144">https://arxiv.org/pdf/2506.17144</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.17144]] Do We Need Large VLMs for Spotting Soccer Actions?(https://arxiv.org/abs/2506.17144)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Traditional video-based tasks like soccer action spotting rely heavily on visual inputs, often requiring complex and computationally expensive models to process dense video data. In this work, we propose a shift from this video-centric approach to a text-based task, making it lightweight and scalable by utilizing Large Language Models (LLMs) instead of Vision-Language Models (VLMs). We posit that expert commentary, which provides rich, fine-grained descriptions and contextual cues such as excitement and tactical insights, contains enough information to reliably spot key actions in a match. To demonstrate this, we use the SoccerNet Echoes dataset, which provides timestamped commentary, and employ a system of three LLMs acting as judges specializing in outcome, excitement, and tactics. Each LLM evaluates sliding windows of commentary to identify actions like goals, cards, and substitutions, generating accurate timestamps for these events. Our experiments show that this language-centric approach performs effectively in detecting critical match events, providing a lightweight and training-free alternative to traditional video-based methods for action spotting.</li>
</ul>

<h3>Title: Global Microprocessor Correctness in the Presence of Transient Execution</h3>
<ul>
<li><strong>Authors: </strong>Andrew T. Walter, Konstantinos Athanasiou, Panagiotis Manolios</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.17154">https://arxiv.org/abs/2506.17154</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.17154">https://arxiv.org/pdf/2506.17154</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.17154]] Global Microprocessor Correctness in the Presence of Transient Execution(https://arxiv.org/abs/2506.17154)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack</a></li>
<li><strong>Abstract: </strong>Correctness for microprocessors is generally understood to be conformance with the associated instruction set architecture (ISA). This is the basis for one of the most important abstractions in computer science, allowing hardware designers to develop highly-optimized processors that are functionally "equivalent" to an ideal processor that executes instructions atomically. This specification is almost always informal, e.g., commercial microprocessors generally do not come with conformance specifications. In this paper, we advocate for the use of formal specifications, using the theory of refinement. We introduce notions of correctness that can be used to deal with transient execution attacks, including Meltdown and Spectre. Such attacks have shown that ubiquitous microprocessor optimizations, appearing in numerous processors for decades, are inherently buggy. Unlike alternative approaches that use non-interference properties, our notion of correctness is global, meaning it is single specification that: formalizes conformance, includes functional correctness and is parameterized by an microarchitecture. We introduce action skipping refinement, a new type of refinement and we describe how our notions of refinement can be decomposed into properties that are more amenable to automated verification using the the concept of shared-resource commitment refinement maps. We do this in the context of formal, fully executable bit- and cycle-accurate models of an ISA and a microprocessor. Finally, we show how light-weight formal methods based on property-based testing can be used to identify transient execution bugs.</li>
</ul>

<h3>Title: Co-Seg++: Mutual Prompt-Guided Collaborative Learning for Versatile Medical Segmentation</h3>
<ul>
<li><strong>Authors: </strong>Qing Xu, Yuxiang Luo, Wenting Duan, Zhen Chen</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.17159">https://arxiv.org/abs/2506.17159</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.17159">https://arxiv.org/pdf/2506.17159</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.17159]] Co-Seg++: Mutual Prompt-Guided Collaborative Learning for Versatile Medical Segmentation(https://arxiv.org/abs/2506.17159)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>Medical image analysis is critical yet challenged by the need of jointly segmenting organs or tissues, and numerous instances for anatomical structures and tumor microenvironment analysis. Existing studies typically formulated different segmentation tasks in isolation, which overlooks the fundamental interdependencies between these tasks, leading to suboptimal segmentation performance and insufficient medical image understanding. To address this issue, we propose a Co-Seg++ framework for versatile medical segmentation. Specifically, we introduce a novel co-segmentation paradigm, allowing semantic and instance segmentation tasks to mutually enhance each other. We first devise a spatio-temporal prompt encoder (STP-Encoder) to capture long-range spatial and temporal relationships between segmentation regions and image embeddings as prior spatial constraints. Moreover, we devise a multi-task collaborative decoder (MTC-Decoder) that leverages cross-guidance to strengthen the contextual consistency of both tasks, jointly computing semantic and instance segmentation masks. Extensive experiments on diverse CT and histopathology datasets demonstrate that the proposed Co-Seg++ outperforms state-of-the-arts in the semantic, instance, and panoptic segmentation of dental anatomical structures, histopathology tissues, and nuclei instances. The source code is available at this https URL.</li>
</ul>

<h3>Title: Analyzing PDFs like Binaries: Adversarially Robust PDF Malware Analysis via Intermediate Representation and Language Model</h3>
<ul>
<li><strong>Authors: </strong>Side Liu, Jiang Ming, Guodong Zhou, Xinyi Liu, Jianming Fu, Guojun Peng</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.17162">https://arxiv.org/abs/2506.17162</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.17162">https://arxiv.org/pdf/2506.17162</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.17162]] Analyzing PDFs like Binaries: Adversarially Robust PDF Malware Analysis via Intermediate Representation and Language Model(https://arxiv.org/abs/2506.17162)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack, robust, extraction</a></li>
<li><strong>Abstract: </strong>Malicious PDF files have emerged as a persistent threat and become a popular attack vector in web-based attacks. While machine learning-based PDF malware classifiers have shown promise, these classifiers are often susceptible to adversarial attacks, undermining their reliability. To address this issue, recent studies have aimed to enhance the robustness of PDF classifiers. Despite these efforts, the feature engineering underlying these studies remains outdated. Consequently, even with the application of cutting-edge machine learning techniques, these approaches fail to fundamentally resolve the issue of feature instability. To tackle this, we propose a novel approach for PDF feature extraction and PDF malware detection. We introduce the PDFObj IR (PDF Object Intermediate Representation), an assembly-like language framework for PDF objects, from which we extract semantic features using a pretrained language model. Additionally, we construct an Object Reference Graph to capture structural features, drawing inspiration from program analysis. This dual approach enables us to analyze and detect PDF malware based on both semantic and structural features. Experimental results demonstrate that our proposed classifier achieves strong adversarial robustness while maintaining an exceptionally low false positive rate of only 0.07% on baseline dataset compared to state-of-the-art PDF malware classifiers.</li>
</ul>

<h3>Title: Deep generative models as the probability transformation functions</h3>
<ul>
<li><strong>Authors: </strong>Vitalii Bondar, Vira Babenko, Roman Trembovetskyi, Yurii Korobeinyk, Viktoriya Dzyuba</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.17171">https://arxiv.org/abs/2506.17171</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.17171">https://arxiv.org/pdf/2506.17171</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.17171]] Deep generative models as the probability transformation functions(https://arxiv.org/abs/2506.17171)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, generative</a></li>
<li><strong>Abstract: </strong>This paper introduces a unified theoretical perspective that views deep generative models as probability transformation functions. Despite the apparent differences in architecture and training methodologies among various types of generative models - autoencoders, autoregressive models, generative adversarial networks, normalizing flows, diffusion models, and flow matching - we demonstrate that they all fundamentally operate by transforming simple predefined distributions into complex target data distributions. This unifying perspective facilitates the transfer of methodological improvements between model architectures and provides a foundation for developing universal theoretical approaches, potentially leading to more efficient and effective generative modeling techniques.</li>
</ul>

<h3>Title: A Common Pool of Privacy Problems: Legal and Technical Lessons from a Large-Scale Web-Scraped Machine Learning Dataset</h3>
<ul>
<li><strong>Authors: </strong>Rachel Hong, Jevan Hutson, William Agnew, Imaad Huda, Tadayoshi Kohno, Jamie Morgenstern</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.CY</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.17185">https://arxiv.org/abs/2506.17185</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.17185">https://arxiv.org/pdf/2506.17185</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.17185]] A Common Pool of Privacy Problems: Legal and Technical Lessons from a Large-Scale Web-Scraped Machine Learning Dataset(https://arxiv.org/abs/2506.17185)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, protect</a></li>
<li><strong>Abstract: </strong>We investigate the contents of web-scraped data for training AI systems, at sizes where human dataset curators and compilers no longer manually annotate every sample. Building off of prior privacy concerns in machine learning models, we ask: What are the legal privacy implications of web-scraped machine learning datasets? In an empirical study of a popular training dataset, we find significant presence of personally identifiable information despite sanitization efforts. Our audit provides concrete evidence to support the concern that any large-scale web-scraped dataset may contain personal data. We use these findings of a real-world dataset to inform our legal analysis with respect to existing privacy and data protection laws. We surface various privacy risks of current data curation practices that may propagate personal information to downstream models. From our findings, we argue for reorientation of current frameworks of "publicly available" information to meaningfully limit the development of AI built upon indiscriminate scraping of the internet.</li>
</ul>

<h3>Title: Towards AI Search Paradigm</h3>
<ul>
<li><strong>Authors: </strong>Yuchen Li, Hengyi Cai, Rui Kong, Xinran Chen, Jiamin Chen, Jun Yang, Haojie Zhang, Jiayi Li, Jiayi Wu, Yiqun Chen, Changle Qu, Keyi Kong, Wenwen Ye, Lixin Su, Xinyu Ma, Long Xia, Daiting Shi, Jiashu Zhao, Haoyi Xiong, Shuaiqiang Wang, Dawei Yin</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.IR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.17188">https://arxiv.org/abs/2506.17188</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.17188">https://arxiv.org/pdf/2506.17188</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.17188]] Towards AI Search Paradigm(https://arxiv.org/abs/2506.17188)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>In this paper, we introduce the AI Search Paradigm, a comprehensive blueprint for next-generation search systems capable of emulating human information processing and decision-making. The paradigm employs a modular architecture of four LLM-powered agents (Master, Planner, Executor and Writer) that dynamically adapt to the full spectrum of information needs, from simple factual queries to complex multi-stage reasoning tasks. These agents collaborate dynamically through coordinated workflows to evaluate query complexity, decompose problems into executable plans, and orchestrate tool usage, task execution, and content synthesis. We systematically present key methodologies for realizing this paradigm, including task planning and tool integration, execution strategies, aligned and robust retrieval-augmented generation, and efficient LLM inference, spanning both algorithmic techniques and infrastructure-level optimizations. By providing an in-depth guide to these foundational components, this work aims to inform the development of trustworthy, adaptive, and scalable AI search systems.</li>
</ul>

<h3>Title: Hunyuan-GameCraft: High-dynamic Interactive Game Video Generation with Hybrid History Condition</h3>
<ul>
<li><strong>Authors: </strong>Jiaqi Li, Junshu Tang, Zhiyong Xu, Longhuang Wu, Yuan Zhou, Shuai Shao, Tianbao Yu, Zhiguo Cao, Qinglin Lu</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.17201">https://arxiv.org/abs/2506.17201</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.17201">https://arxiv.org/pdf/2506.17201</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.17201]] Hunyuan-GameCraft: High-dynamic Interactive Game Video Generation with Hybrid History Condition(https://arxiv.org/abs/2506.17201)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>Recent advances in diffusion-based and controllable video generation have enabled high-quality and temporally coherent video synthesis, laying the groundwork for immersive interactive gaming experiences. However, current methods face limitations in dynamics, generality, long-term consistency, and efficiency, which limit the ability to create various gameplay videos. To address these gaps, we introduce Hunyuan-GameCraft, a novel framework for high-dynamic interactive video generation in game environments. To achieve fine-grained action control, we unify standard keyboard and mouse inputs into a shared camera representation space, facilitating smooth interpolation between various camera and movement operations. Then we propose a hybrid history-conditioned training strategy that extends video sequences autoregressively while preserving game scene information. Additionally, to enhance inference efficiency and playability, we achieve model distillation to reduce computational overhead while maintaining consistency across long temporal sequences, making it suitable for real-time deployment in complex interactive environments. The model is trained on a large-scale dataset comprising over one million gameplay recordings across over 100 AAA games, ensuring broad coverage and diversity, then fine-tuned on a carefully annotated synthetic dataset to enhance precision and control. The curated game scene data significantly improves the visual fidelity, realism and action controllability. Extensive experiments demonstrate that Hunyuan-GameCraft significantly outperforms existing models, advancing the realism and playability of interactive game video generation.</li>
</ul>

<h3>Title: UniFork: Exploring Modality Alignment for Unified Multimodal Understanding and Generation</h3>
<ul>
<li><strong>Authors: </strong>Teng Li, Quanfeng Lu, Lirui Zhao, Hao Li, Xizhou Zhu, Yu Qiao, Jun Zhang, Wenqi Shao</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.17202">https://arxiv.org/abs/2506.17202</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.17202">https://arxiv.org/pdf/2506.17202</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.17202]] UniFork: Exploring Modality Alignment for Unified Multimodal Understanding and Generation(https://arxiv.org/abs/2506.17202)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Unified image understanding and generation has emerged as a promising paradigm in multimodal artificial intelligence. Despite recent progress, the optimal architectural design for such unified models remains an open challenge. In this work, we start by analyzing the modality alignment behaviors of task-specific expert models for understanding and generation, as well as current unified models. Our analysis reveals a crucial observation: understanding tasks benefit from a progressively increasing modality alignment across network depth, which helps build up semantic information for better comprehension; In contrast, generation tasks follow a different trend: modality alignment increases in the early layers but decreases in the deep layers to recover spatial details. These divergent alignment patterns create a fundamental conflict in fully shared Transformer backbones, where a uniform representational flow often leads to performance compromises across two tasks. Motivated by this finding, we introduce UniFork, a novel Y-shaped architecture that shares the shallow layers for cross-task representation learning, while employing task-specific branches in deeper layers to avoid task interference. This design effectively balances shared learning and task specialization. Through extensive ablation experiments, we demonstrate that Unifork consistently outperforms conventional fully shared Transformer architectures, and achieves performance on par with or better than task-specific models.</li>
</ul>

<h3>Title: Fine-Tuning Lowers Safety and Disrupts Evaluation Consistency</h3>
<ul>
<li><strong>Authors: </strong>Kathleen C. Fraser, Hillary Dawkins, Isar Nejadgholi, Svetlana Kiritchenko</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.17209">https://arxiv.org/abs/2506.17209</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.17209">https://arxiv.org/pdf/2506.17209</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.17209]] Fine-Tuning Lowers Safety and Disrupts Evaluation Consistency(https://arxiv.org/abs/2506.17209)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack, robust, large language model</a></li>
<li><strong>Abstract: </strong>Fine-tuning a general-purpose large language model (LLM) for a specific domain or task has become a routine procedure for ordinary users. However, fine-tuning is known to remove the safety alignment features of the model, even when the fine-tuning data does not contain any harmful content. We consider this to be a critical failure mode of LLMs due to the widespread uptake of fine-tuning, combined with the benign nature of the "attack". Most well-intentioned developers are likely unaware that they are deploying an LLM with reduced safety. On the other hand, this known vulnerability can be easily exploited by malicious actors intending to bypass safety guardrails. To make any meaningful progress in mitigating this issue, we first need reliable and reproducible safety evaluations. In this work, we investigate how robust a safety benchmark is to trivial variations in the experimental procedure, and the stochastic nature of LLMs. Our initial experiments expose surprising variance in the results of the safety evaluation, even when seemingly inconsequential changes are made to the fine-tuning setup. Our observations have serious implications for how researchers in this field should report results to enable meaningful comparisons in the future.</li>
</ul>

<h3>Title: No Free Lunch: Rethinking Internal Feedback for LLM Reasoning</h3>
<ul>
<li><strong>Authors: </strong>Yanzhi Zhang, Zhaoxi Zhang, Haoxiang Guan, Yilin Cheng, Yitong Duan, Chen Wang, Yue Wang, Shuxin Zheng, Jiyan He</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.17219">https://arxiv.org/abs/2506.17219</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.17219">https://arxiv.org/pdf/2506.17219</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.17219]] No Free Lunch: Rethinking Internal Feedback for LLM Reasoning(https://arxiv.org/abs/2506.17219)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Reinforcement learning has emerged as a powerful paradigm for post-training large language models (LLMs) to improve reasoning. Approaches like Reinforcement Learning from Human Feedback (RLHF) and Reinforcement Learning with Verifiable Rewards (RLVR) have shown strong results, but they require extensive external supervision. We investigate an alternative class of methods, Reinforcement Learning from Internal Feedback (RLIF), which relies solely on intrinsic model-derived signals instead of external rewards. In particular, we leverage unsupervised reward proxies such as token-level entropy, trajectory-level entropy, and self-certainty. Our theoretical analysis shows these internal objectives are partially equivalent, and we empirically evaluate various RLIF strategies on challenging math reasoning benchmarks. Experimental results demonstrate that RLIF can boost the reasoning performance of base LLMs at the beginning phase of the training, matching or surpassing RLVR techniques on these tasks. However, when training progresses, performance degrades even below the model before training. Moreover, we find that RLIF yields little improvement for instruction-tuned models, indicating diminishing returns of intrinsic feedback once an LLM is already instruction-tuned. We further analyze this limitation by mixing model weights and explain the reason of RLIF's training behaviors, providing practical guidelines for integrating internal feedback signals into LLM training. We hope our analysis of internal feedback will inform more principled and effective strategies for LLM post-training.</li>
</ul>

<h3>Title: Emergent Temporal Correspondences from Video Diffusion Transformers</h3>
<ul>
<li><strong>Authors: </strong>Jisu Nam, Soowon Son, Dahyun Chung, Jiyoung Kim, Siyoon Jin, Junhwa Hur, Seungryong Kim</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.17220">https://arxiv.org/abs/2506.17220</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.17220">https://arxiv.org/pdf/2506.17220</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.17220]] Emergent Temporal Correspondences from Video Diffusion Transformers(https://arxiv.org/abs/2506.17220)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, transformer</a></li>
<li><strong>Abstract: </strong>Recent advancements in video diffusion models based on Diffusion Transformers (DiTs) have achieved remarkable success in generating temporally coherent videos. Yet, a fundamental question persists: how do these models internally establish and represent temporal correspondences across frames? We introduce DiffTrack, the first quantitative analysis framework designed to answer this question. DiffTrack constructs a dataset of prompt-generated video with pseudo ground-truth tracking annotations and proposes novel evaluation metrics to systematically analyze how each component within the full 3D attention mechanism of DiTs (e.g., representations, layers, and timesteps) contributes to establishing temporal correspondences. Our analysis reveals that query-key similarities in specific, but not all, layers play a critical role in temporal matching, and that this matching becomes increasingly prominent during the denoising process. We demonstrate practical applications of DiffTrack in zero-shot point tracking, where it achieves state-of-the-art performance compared to existing vision foundation and self-supervised video models. Further, we extend our findings to motion-enhanced video generation with a novel guidance method that improves temporal consistency of generated videos without additional training. We believe our work offers crucial insights into the inner workings of video DiTs and establishes a foundation for further research and applications leveraging their temporal understanding.</li>
</ul>

<h3>Title: VLN-R1: Vision-Language Navigation via Reinforcement Fine-Tuning</h3>
<ul>
<li><strong>Authors: </strong>Zhangyang Qi, Zhixiong Zhang, Yizhou Yu, Jiaqi Wang, Hengshuang Zhao</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.17221">https://arxiv.org/abs/2506.17221</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.17221">https://arxiv.org/pdf/2506.17221</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.17221]] VLN-R1: Vision-Language Navigation via Reinforcement Fine-Tuning(https://arxiv.org/abs/2506.17221)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Vision-Language Navigation (VLN) is a core challenge in embodied AI, requiring agents to navigate real-world environments using natural language instructions. Current language model-based navigation systems operate on discrete topological graphs, limiting path planning to predefined node connections. We propose VLN-R1, an end-to-end framework that leverages Large Vision-Language Models (LVLM) to directly translate egocentric video streams into continuous navigation actions, adopting GRPO-based training inspired by DeepSeek-R1. To enable effective training, we first construct the VLN-Ego dataset using a 3D simulator, Habitat, and propose Long-Short Memory Sampling to balance historical and current observations. While large language models can supervise complete textual instructions, they lack fine-grained action-level control. Our framework employs a two-stage training approach: a) Supervised fine-tuning (SFT) to align the model's action sequence text predictions with expert demonstrations, followed by b) Reinforcement fine-tuning (RFT) enhanced with a Time-Decayed Reward (TDR) mechanism that strategically weights multi-step future actions. Experimental results show VLN-R1 achieves strong performance on VLN-CE benchmark. VLN-R1 proves LVLMs can drive embodied navigation and enhance task-specific reasoning through data-efficient, reward-driven post-training.</li>
</ul>

<button id="copy">Copy All</button>
</article>
<script src="../../javascript/clipboard.min.js"></script>
<script src="../../javascript/clipboard.js"></script>
