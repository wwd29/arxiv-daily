<link rel="stylesheet" href="../../css/markdown.css" />
<article class="markdown-body">
<h2>secure</h2>
<h3>Title: Harnessing the Potential of Blockchain in DevOps: A Framework for Distributed Integration and Development. (arXiv:2306.00462v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.00462">http://arxiv.org/abs/2306.00462</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.00462] Harnessing the Potential of Blockchain in DevOps: A Framework for Distributed Integration and Development](http://arxiv.org/abs/2306.00462) #secure</code></li>
<li>Summary: <p>As the use of DevOps practices continues to grow, organizations are seeking
ways to improve collaboration, speed up development cycles, and increase
security, transparency, and traceability. Blockchain technology has the
potential to support these goals by providing a secure, decentralized platform
for distributed integration and development. In this paper, we propose a
framework for distributed DevOps that utilizes the benefits of blockchain
technology that can eliminate the shortcomings of DevOps. We demonstrate the
feasibility and potential benefits of the proposed framework that involves
developing and deploying applications in a distributed environment. We present
a benchmark result demonstrating the effectiveness of our framework in a
real-world scenario, highlighting its ability to improve collaboration, reduce
costs, and enhance the security of the DevOps pipeline. Conclusively, our
research contributes to the growing body of literature on the intersection of
blockchain and DevOps, providing a practical framework for organizations
looking to leverage blockchain technology to improve their development
processes.
</p></li>
</ul>

<h2>security</h2>
<h3>Title: The Canadian Cropland Dataset: A New Land Cover Dataset for Multitemporal Deep Learning Classification in Agriculture. (arXiv:2306.00114v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.00114">http://arxiv.org/abs/2306.00114</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.00114] The Canadian Cropland Dataset: A New Land Cover Dataset for Multitemporal Deep Learning Classification in Agriculture](http://arxiv.org/abs/2306.00114) #security</code></li>
<li>Summary: <p>Monitoring land cover using remote sensing is vital for studying
environmental changes and ensuring global food security through crop yield
forecasting. Specifically, multitemporal remote sensing imagery provides
relevant information about the dynamics of a scene, which has proven to lead to
better land cover classification results. Nevertheless, few studies have
benefited from high spatial and temporal resolution data due to the difficulty
of accessing reliable, fine-grained and high-quality annotated samples to
support their hypotheses. Therefore, we introduce a temporal patch-based
dataset of Canadian croplands, enriched with labels retrieved from the Canadian
Annual Crop Inventory. The dataset contains 78,536 manually verified and
curated high-resolution (10 m/pixel, 640 x 640 m) geo-referenced images from 10
crop classes collected over four crop production years (2017-2020) and five
months (June-October). Each instance contains 12 spectral bands, an RGB image,
and additional vegetation index bands. Individually, each category contains at
least 4,800 images. Moreover, as a benchmark, we provide models and source code
that allow a user to predict the crop class using a single image (ResNet,
DenseNet, EfficientNet) or a sequence of images (LRCN, 3D-CNN) from the same
location. In perspective, we expect this evolving dataset to propel the
creation of robust agro-environmental models that can accelerate the
comprehension of complex agricultural regions by providing accurate and
continuous monitoring of land cover.
</p></li>
</ul>

<h3>Title: Autism Disease Detection Using Transfer Learning Techniques: Performance Comparison Between Central Processing Unit vs Graphics Processing Unit Functions for Neural Networks. (arXiv:2306.00283v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.00283">http://arxiv.org/abs/2306.00283</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.00283] Autism Disease Detection Using Transfer Learning Techniques: Performance Comparison Between Central Processing Unit vs Graphics Processing Unit Functions for Neural Networks](http://arxiv.org/abs/2306.00283) #security</code></li>
<li>Summary: <p>Neural network approaches are machine learning methods that are widely used
in various domains, such as healthcare and cybersecurity. Neural networks are
especially renowned for their ability to deal with image datasets. During the
training process with images, various fundamental mathematical operations are
performed in the neural network. These operations include several algebraic and
mathematical functions, such as derivatives, convolutions, and matrix
inversions and transpositions. Such operations demand higher processing power
than what is typically required for regular computer usage. Since CPUs are
built with serial processing, they are not appropriate for handling large image
datasets. On the other hand, GPUs have parallel processing capabilities and can
provide higher speed. This paper utilizes advanced neural network techniques,
such as VGG16, Resnet50, Densenet, Inceptionv3, Xception, Mobilenet, XGBOOST
VGG16, and our proposed models, to compare CPU and GPU resources. We
implemented a system for classifying Autism disease using face images of
autistic and non-autistic children to compare performance during testing. We
used evaluation matrices such as Accuracy, F1 score, Precision, Recall, and
Execution time. It was observed that GPU outperformed CPU in all tests
conducted. Moreover, the performance of the neural network models in terms of
accuracy increased on GPU compared to CPU.
</p></li>
</ul>

<h3>Title: Developing and Building Ontologies in Cyber Security. (arXiv:2306.00377v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.00377">http://arxiv.org/abs/2306.00377</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.00377] Developing and Building Ontologies in Cyber Security](http://arxiv.org/abs/2306.00377) #security</code></li>
<li>Summary: <p>Cyber Security is one of the most arising disciplines in our modern society.
We work on Cybersecurity domain and in this the topic we chose is Cyber
Security Ontologies. In this we gather all latest and previous ontologies and
compare them on the basis of different analyzing factors to get best of them.
Reason to select this topic is to assemble different ontologies from different
era of time. Because, researches that included in this SLR is mostly studied
single ontology. If any researcher wants to study ontologies, he has to study
every single ontology and select which one is best for his research. So, we
assemble different types of ontology and compare them against each other to get
best of them. A total 24 papers between years 2010-2020 are carefully selected
through systematic process and classified accordingly. Lastly, this SLR have
been presented to provide the researchers promising future directions in the
domain of cybersecurity ontologies.
</p></li>
</ul>

<h3>Title: A Holistic Framework for Safeguarding of SMEs-A Case Study. (arXiv:2306.00136v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.00136">http://arxiv.org/abs/2306.00136</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.00136] A Holistic Framework for Safeguarding of SMEs-A Case Study](http://arxiv.org/abs/2306.00136) #security</code></li>
<li>Summary: <p>The rapid digitalisation of SMEs, further expedited as a business continuity
measure against Covid19 impact, has brought along major cybersecurity
challenges, as it creates a fertile landscape for malicious actors, that want
to capitalise on the insufficient cybersecurity planning and preparedness of
SMEs to conduct low-effort, lucrative attacks. This paper constitutes a case
study on the cybersecurity challenges, specificities and the safeguarding of
the ATracker, a real-life data collection and analytics engine developed by the
SME Suite5. The ATracker has been successfully protected against attacks in
conjunction with the PUZZLE Framework, a holistic policy-based cybersecurity
solution, addressing major cybersecurity pillars and leveraging on the latest
scientific advancements in cybersecurity research.
</p></li>
</ul>

<h3>Title: Case Study-Based Approach of Quantum Machine Learning in Cybersecurity: Quantum Support Vector Machine for Malware Classification and Protection. (arXiv:2306.00284v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.00284">http://arxiv.org/abs/2306.00284</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.00284] Case Study-Based Approach of Quantum Machine Learning in Cybersecurity: Quantum Support Vector Machine for Malware Classification and Protection](http://arxiv.org/abs/2306.00284) #security</code></li>
<li>Summary: <p>Quantum machine learning (QML) is an emerging field of research that
leverages quantum computing to improve the classical machine learning approach
to solve complex real world problems. QML has the potential to address
cybersecurity related challenges. Considering the novelty and complex
architecture of QML, resources are not yet explicitly available that can pave
cybersecurity learners to instill efficient knowledge of this emerging
technology. In this research, we design and develop QML-based ten learning
modules covering various cybersecurity topics by adopting student centering
case-study based learning approach. We apply one subtopic of QML on a
cybersecurity topic comprised of pre-lab, lab, and post-lab activities towards
providing learners with hands-on QML experiences in solving real-world security
problems. In order to engage and motivate students in a learning environment
that encourages all students to learn, pre-lab offers a brief introduction to
both the QML subtopic and cybersecurity problem. In this paper, we utilize
quantum support vector machine (QSVM) for malware classification and protection
where we use open source Pennylane QML framework on the drebin215 dataset. We
demonstrate our QSVM model and achieve an accuracy of 95% in malware
classification and protection. We will develop all the modules and introduce
them to the cybersecurity community in the coming days.
</p></li>
</ul>

<h3>Title: Challenges and Remedies to Privacy and Security in AIGC: Exploring the Potential of Privacy Computing, Blockchain, and Beyond. (arXiv:2306.00419v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.00419">http://arxiv.org/abs/2306.00419</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.00419] Challenges and Remedies to Privacy and Security in AIGC: Exploring the Potential of Privacy Computing, Blockchain, and Beyond](http://arxiv.org/abs/2306.00419) #security</code></li>
<li>Summary: <p>Artificial Intelligence Generated Content (AIGC) is one of the latest
achievements in AI development. The content generated by related applications,
such as text, images and audio, has sparked a heated discussion. Various
derived AIGC applications are also gradually entering all walks of life,
bringing unimaginable impact to people's daily lives. However, the rapid
development of such generative tools has also raised concerns about privacy and
security issues, and even copyright issues in AIGC. We note that advanced
technologies such as blockchain and privacy computing can be combined with AIGC
tools, but no work has yet been done to investigate their relevance and
prospect in a systematic and detailed way. Therefore it is necessary to
investigate how they can be used to protect the privacy and security of data in
AIGC by fully exploring the aforementioned technologies. In this paper, we
first systematically review the concept, classification and underlying
technologies of AIGC. Then, we discuss the privacy and security challenges
faced by AIGC from multiple perspectives and purposefully list the
countermeasures that currently exist. We hope our survey will help researchers
and industry to build a more secure and robust AIGC system.
</p></li>
</ul>

<h2>privacy</h2>
<h3>Title: A Note On Interpreting Canary Exposure. (arXiv:2306.00133v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.00133">http://arxiv.org/abs/2306.00133</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.00133] A Note On Interpreting Canary Exposure](http://arxiv.org/abs/2306.00133) #privacy</code></li>
<li>Summary: <p>Canary exposure, introduced in Carlini et al. is frequently used to
empirically evaluate, or audit, the privacy of machine learning model training.
The goal of this note is to provide some intuition on how to interpret canary
exposure, including by relating it to membership inference attacks and
differential privacy.
</p></li>
</ul>

<h2>protect</h2>
<h3>Title: Edge-guided Representation Learning for Underwater Object Detection. (arXiv:2306.00440v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.00440">http://arxiv.org/abs/2306.00440</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.00440] Edge-guided Representation Learning for Underwater Object Detection](http://arxiv.org/abs/2306.00440) #protect</code></li>
<li>Summary: <p>Underwater object detection (UOD) is crucial for marine economic development,
environmental protection, and the planet's sustainable development. The main
challenges of this task arise from low-contrast, small objects, and mimicry of
aquatic organisms. The key to addressing these challenges is to focus the model
on obtaining more discriminative information. We observe that the edges of
underwater objects are highly unique and can be distinguished from low-contrast
or mimicry environments based on their edges. Motivated by this observation, we
propose an Edge-guided Representation Learning Network, termed ERL-Net, that
aims to achieve discriminative representation learning and aggregation under
the guidance of edge cues. Firstly, we introduce an edge-guided attention
module to model the explicit boundary information, which generates more
discriminative features. Secondly, a feature aggregation module is proposed to
aggregate the multi-scale discriminative features by regrouping them into three
levels, effectively aggregating global and local information for locating and
recognizing underwater objects. Finally, we propose a wide and asymmetric
receptive field block to enable features to have a wider receptive field,
allowing the model to focus on more small object information. Comprehensive
experiments on three challenging underwater datasets show that our method
achieves superior performance on the UOD task.
</p></li>
</ul>

<h2>defense</h2>
<h3>Title: Adversarial-Aware Deep Learning System based on a Secondary Classical Machine Learning Verification Approach. (arXiv:2306.00314v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.00314">http://arxiv.org/abs/2306.00314</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.00314] Adversarial-Aware Deep Learning System based on a Secondary Classical Machine Learning Verification Approach](http://arxiv.org/abs/2306.00314) #defense</code></li>
<li>Summary: <p>Deep learning models have been used in creating various effective image
classification applications. However, they are vulnerable to adversarial
attacks that seek to misguide the models into predicting incorrect classes. Our
study of major adversarial attack models shows that they all specifically
target and exploit the neural networking structures in their designs. This
understanding makes us develop a hypothesis that most classical machine
learning models, such as Random Forest (RF), are immune to adversarial attack
models because they do not rely on neural network design at all. Our
experimental study of classical machine learning models against popular
adversarial attacks supports this hypothesis. Based on this hypothesis, we
propose a new adversarial-aware deep learning system by using a classical
machine learning model as the secondary verification system to complement the
primary deep learning model in image classification. Although the secondary
classical machine learning model has less accurate output, it is only used for
verification purposes, which does not impact the output accuracy of the primary
deep learning model, and at the same time, can effectively detect an
adversarial attack when a clear mismatch occurs. Our experiments based on
CIFAR-100 dataset show that our proposed approach outperforms current
state-of-the-art adversarial defense systems.
</p></li>
</ul>

<h2>attack</h2>
<h3>Title: Graph-based methods coupled with specific distributional distances for adversarial attack detection. (arXiv:2306.00042v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.00042">http://arxiv.org/abs/2306.00042</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.00042] Graph-based methods coupled with specific distributional distances for adversarial attack detection](http://arxiv.org/abs/2306.00042) #attack</code></li>
<li>Summary: <p>Artificial neural networks are prone to being fooled by carefully perturbed
inputs which cause an egregious misclassification. These \textit{adversarial}
attacks have been the focus of extensive research. Likewise, there has been an
abundance of research in ways to detect and defend against them. We introduce a
novel approach of detection and interpretation of adversarial attacks from a
graph perspective. For an image, benign or adversarial, we study how a neural
network's architecture can induce an associated graph. We study this graph and
introduce specific measures used to predict and interpret adversarial attacks.
We show that graphs-based approaches help to investigate the inner workings of
adversarial attacks.
</p></li>
</ul>

<h3>Title: CALICO: Self-Supervised Camera-LiDAR Contrastive Pre-training for BEV Perception. (arXiv:2306.00349v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.00349">http://arxiv.org/abs/2306.00349</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.00349] CALICO: Self-Supervised Camera-LiDAR Contrastive Pre-training for BEV Perception](http://arxiv.org/abs/2306.00349) #attack</code></li>
<li>Summary: <p>Perception is crucial in the realm of autonomous driving systems, where
bird's eye view (BEV)-based architectures have recently reached
state-of-the-art performance. The desirability of self-supervised
representation learning stems from the expensive and laborious process of
annotating 2D and 3D data. Although previous research has investigated
pretraining methods for both LiDAR and camera-based 3D object detection, a
unified pretraining framework for multimodal BEV perception is missing. In this
study, we introduce CALICO, a novel framework that applies contrastive
objectives to both LiDAR and camera backbones. Specifically, CALICO
incorporates two stages: point-region contrast (PRC) and region-aware
distillation (RAD). PRC better balances the region- and scene-level
representation learning on the LiDAR modality and offers significant
performance improvement compared to existing methods. RAD effectively achieves
contrastive distillation on our self-trained teacher model. CALICO's efficacy
is substantiated by extensive evaluations on 3D object detection and BEV map
segmentation tasks, where it delivers significant performance improvements.
Notably, CALICO outperforms the baseline method by 10.5% and 8.6% on NDS and
mAP. Moreover, CALICO boosts the robustness of multimodal 3D object detection
against adversarial attacks and corruption. Additionally, our framework can be
tailored to different backbones and heads, positioning it as a promising
approach for multimodal BEV perception.
</p></li>
</ul>

<h3>Title: Out-of-distribution forgetting: vulnerability of continual learning to intra-class distribution shift. (arXiv:2306.00427v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.00427">http://arxiv.org/abs/2306.00427</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.00427] Out-of-distribution forgetting: vulnerability of continual learning to intra-class distribution shift](http://arxiv.org/abs/2306.00427) #attack</code></li>
<li>Summary: <p>Continual learning (CL) is an important technique to allow artificial neural
networks to work in open environments. CL enables a system to learn new tasks
without severe interference to its performance on old tasks, i.e., overcome the
problems of catastrophic forgetting. In joint learning, it is well known that
the out-of-distribution (OOD) problem caused by intentional attacks or
environmental perturbations will severely impair the ability of networks to
generalize. In this work, we reported a special form of catastrophic forgetting
raised by the OOD problem in continual learning settings, and we named it
out-of-distribution forgetting (OODF). In continual image classification tasks,
we found that for a given category, introducing an intra-class distribution
shift significantly impaired the recognition accuracy of CL methods for that
category during subsequent learning. Interestingly, this phenomenon is special
for CL as the same level of distribution shift had only negligible effects in
the joint learning scenario. We verified that CL methods without dedicating
subnetworks for individual tasks are all vulnerable to OODF. Moreover, OODF
does not depend on any specific way of shifting the distribution, suggesting it
is a risk for CL in a wide range of circumstances. Taken together, our work
identified an under-attended risk during CL, highlighting the importance of
developing approaches that can overcome OODF.
</p></li>
</ul>

<h3>Title: Side-Channel VoIP Profiling Attack against Customer Service Automated Phone System. (arXiv:2306.00095v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.00095">http://arxiv.org/abs/2306.00095</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.00095] Side-Channel VoIP Profiling Attack against Customer Service Automated Phone System](http://arxiv.org/abs/2306.00095) #attack</code></li>
<li>Summary: <p>In many VoIP systems, Voice Activity Detection (VAD) is often used on VoIP
traffic to suppress packets of silence in order to reduce the bandwidth
consumption of phone calls. Unfortunately, although VoIP traffic is fully
encrypted and secured, traffic analysis of this suppression can reveal
identifying information about calls made to customer service automated phone
systems. Because different customer service phone systems have distinct, but
fixed (pre-recorded) automated voice messages sent to customers, VAD silence
suppression used in VoIP will enable an eavesdropper to profile and identify
these automated voice messages. In this paper, we will use a popular enterprise
VoIP system (Cisco CallManager), running the default Session Initiation
Protocol (SIP) protocol, to demonstrate that an attacker can reliably use the
silence suppression to profile calls to such VoIP systems. Our real-world
experiments demonstrate that this side-channel profiling attack can be used to
accurately identify not only what customer service phone number a customer
calls, but also what following options are subsequently chosen by the caller in
the phone conversation.
</p></li>
</ul>

<h3>Title: Surrogate Model Extension (SME): A Fast and Accurate Weight Update Attack on Federated Learning. (arXiv:2306.00127v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.00127">http://arxiv.org/abs/2306.00127</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.00127] Surrogate Model Extension (SME): A Fast and Accurate Weight Update Attack on Federated Learning](http://arxiv.org/abs/2306.00127) #attack</code></li>
<li>Summary: <p>In Federated Learning (FL) and many other distributed training frameworks,
collaborators can hold their private data locally and only share the network
weights trained with the local data after multiple iterations. Gradient
inversion is a family of privacy attacks that recovers data from its generated
gradients. Seemingly, FL can provide a degree of protection against gradient
inversion attacks on weight updates, since the gradient of a single step is
concealed by the accumulation of gradients over multiple local iterations. In
this work, we propose a principled way to extend gradient inversion attacks to
weight updates in FL, thereby better exposing weaknesses in the presumed
privacy protection inherent in FL. In particular, we propose a surrogate model
method based on the characteristic of two-dimensional gradient flow and
low-rank property of local updates. Our method largely boosts the ability of
gradient inversion attacks on weight updates containing many iterations and
achieves state-of-the-art (SOTA) performance. Additionally, our method runs up
to $100\times$ faster than the SOTA baseline in the common FL scenario. Our
work re-evaluates and highlights the privacy risk of sharing network weights.
Our code is available at
https://github.com/JunyiZhu-AI/surrogate_model_extension.
</p></li>
</ul>

<h3>Title: Implementing Man-in-the-Middle Attack to Investigate Network Vulnerabilities in Smart Grid Test-bed. (arXiv:2306.00234v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.00234">http://arxiv.org/abs/2306.00234</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.00234] Implementing Man-in-the-Middle Attack to Investigate Network Vulnerabilities in Smart Grid Test-bed](http://arxiv.org/abs/2306.00234) #attack</code></li>
<li>Summary: <p>The smart-grid introduces several new data-gathering, communication, and
information-sharing capabilities into the electrical system, as well as
additional privacy threats, vulnerabilities, and cyber-attacks. In this study,
Modbus is regarded as one of the most prevalent interfaces for control systems
in power plants. Modern control interfaces are vulnerable to cyber-attacks,
posing a risk to the entire energy infrastructure. In order to strengthen
resistance to cyber-attacks, this study introduces a test bed for
cyber-physical systems that operate in real-time. To investigate the network
vulnerabilities of smart power grids, Modbus protocol has been examined
combining a real-time power system simulator with a communication system
simulator and the effects of the system presented and analyzed. The goal is to
detect the vulnerability in Modbus protocol and perform the Man-in-the-middle
attack with its impact on the system. This proposed testbed can be evaluated as
a research model for vulnerability assessment as well as a tool for evaluating
cyber-attacks and enquire into any detection mechanism for safeguarding and
defending smart grid systems from a variety of cyberattacks. We present here
the preliminary findings on using the testbed to identify a particular MiTM
attack and the effects on system performance. Finally, we suggest a cyber
security strategy as a solution to address such network vulnerabilities and
deploy appropriate countermeasures.
</p></li>
</ul>

<h2>robust</h2>
<h3>Title: Neural Textured Deformable Meshes for Robust Analysis-by-Synthesis. (arXiv:2306.00118v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.00118">http://arxiv.org/abs/2306.00118</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.00118] Neural Textured Deformable Meshes for Robust Analysis-by-Synthesis](http://arxiv.org/abs/2306.00118) #robust</code></li>
<li>Summary: <p>Human vision demonstrates higher robustness than current AI algorithms under
out-of-distribution scenarios. It has been conjectured such robustness benefits
from performing analysis-by-synthesis. Our paper formulates triple vision tasks
in a consistent manner using approximate analysis-by-synthesis by
render-and-compare algorithms on neural features. In this work, we introduce
Neural Textured Deformable Meshes, which involve the object model with
deformable geometry that allows optimization on both camera parameters and
object geometries. The deformable mesh is parameterized as a neural field, and
covered by whole-surface neural texture maps, which are trained to have spatial
discriminability. During inference, we extract the feature map of the test
image and subsequently optimize the 3D pose and shape parameters of our model
using differentiable rendering to best reconstruct the target feature map. We
show that our analysis-by-synthesis is much more robust than conventional
neural networks when evaluated on real-world images and even in challenging
out-of-distribution scenarios, such as occlusion and domain shift. Our
algorithms are competitive with standard algorithms when tested on conventional
performance measures.
</p></li>
</ul>

<h3>Title: FlowCam: Training Generalizable 3D Radiance Fields without Camera Poses via Pixel-Aligned Scene Flow. (arXiv:2306.00180v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.00180">http://arxiv.org/abs/2306.00180</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.00180] FlowCam: Training Generalizable 3D Radiance Fields without Camera Poses via Pixel-Aligned Scene Flow](http://arxiv.org/abs/2306.00180) #robust</code></li>
<li>Summary: <p>Reconstruction of 3D neural fields from posed images has emerged as a
promising method for self-supervised representation learning. The key challenge
preventing the deployment of these 3D scene learners on large-scale video data
is their dependence on precise camera poses from structure-from-motion, which
is prohibitively expensive to run at scale. We propose a method that jointly
reconstructs camera poses and 3D neural scene representations online and in a
single forward pass. We estimate poses by first lifting frame-to-frame optical
flow to 3D scene flow via differentiable rendering, preserving locality and
shift-equivariance of the image processing backbone. SE(3) camera pose
estimation is then performed via a weighted least-squares fit to the scene flow
field. This formulation enables us to jointly supervise pose estimation and a
generalizable neural scene representation via re-rendering the input video, and
thus, train end-to-end and fully self-supervised on real-world video datasets.
We demonstrate that our method performs robustly on diverse, real-world video,
notably on sequences traditionally challenging to optimization-based pose
estimation techniques.
</p></li>
</ul>

<h3>Title: Using Visual Cropping to Enhance Fine-Detail Question Answering of BLIP-Family Models. (arXiv:2306.00228v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.00228">http://arxiv.org/abs/2306.00228</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.00228] Using Visual Cropping to Enhance Fine-Detail Question Answering of BLIP-Family Models](http://arxiv.org/abs/2306.00228) #robust</code></li>
<li>Summary: <p>Visual Question Answering is a challenging task, as it requires seamless
interaction between perceptual, linguistic, and background knowledge systems.
While the recent progress of visual and natural language models like BLIP has
led to improved performance on this task, we lack understanding of the ability
of such models to perform on different kinds of questions and reasoning types.
As our initial analysis of BLIP-family models revealed difficulty with
answering fine-detail questions, we investigate the following question: Can
visual cropping be employed to improve the performance of state-of-the-art
visual question answering models on fine-detail questions? Given the recent
success of the BLIP-family models, we study a zero-shot and a fine-tuned BLIP
model. We define three controlled subsets of the popular VQA-v2 benchmark to
measure whether cropping can help model performance. Besides human cropping, we
devise two automatic cropping strategies based on multi-modal embedding by CLIP
and BLIP visual QA model gradients. Our experiments demonstrate that the
performance of BLIP model variants can be significantly improved through human
cropping, and automatic cropping methods can produce comparable benefits. A
deeper dive into our findings indicates that the performance enhancement is
more pronounced in zero-shot models than in fine-tuned models and more salient
with smaller bounding boxes than larger ones. We perform case studies to
connect quantitative differences with qualitative observations across question
types and datasets. Finally, we see that the cropping enhancement is robust, as
we gain an improvement of 4.59% (absolute) in the general VQA-random task by
simply inputting a concatenation of the original and gradient-based cropped
images. We make our code available to facilitate further innovation on visual
cropping methods for question answering.
</p></li>
</ul>

<h3>Title: Doubly Robust Self-Training. (arXiv:2306.00265v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.00265">http://arxiv.org/abs/2306.00265</a></li>
<li>Code URL: <a href="https://github.com/dingmyu/doubly-robust-self-training">https://github.com/dingmyu/doubly-robust-self-training</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2306.00265] Doubly Robust Self-Training](http://arxiv.org/abs/2306.00265) #robust</code></li>
<li>Summary: <p>Self-training is an important technique for solving semi-supervised learning
problems. It leverages unlabeled data by generating pseudo-labels and combining
them with a limited labeled dataset for training. The effectiveness of
self-training heavily relies on the accuracy of these pseudo-labels. In this
paper, we introduce doubly robust self-training, a novel semi-supervised
algorithm that provably balances between two extremes. When the pseudo-labels
are entirely incorrect, our method reduces to a training process solely using
labeled data. Conversely, when the pseudo-labels are completely accurate, our
method transforms into a training process utilizing all pseudo-labeled data and
labeled data, thus increasing the effective sample size. Through empirical
evaluations on both the ImageNet dataset for image classification and the
nuScenes autonomous driving dataset for 3D object detection, we demonstrate the
superiority of the doubly robust loss over the standard self-training baseline.
</p></li>
</ul>

<h3>Title: Accelerated Fingerprint Enhancement: A GPU-Optimized Mixed Architecture Approach. (arXiv:2306.00272v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.00272">http://arxiv.org/abs/2306.00272</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.00272] Accelerated Fingerprint Enhancement: A GPU-Optimized Mixed Architecture Approach](http://arxiv.org/abs/2306.00272) #robust</code></li>
<li>Summary: <p>This document presents a preliminary approach to latent fingerprint
enhancement, fundamentally designed around a mixed Unet architecture. It
combines the capabilities of the Resnet-101 network and Unet encoder, aiming to
form a potentially powerful composite. This combination, enhanced with
attention mechanisms and forward skip connections, is intended to optimize the
enhancement of ridge and minutiae features in fingerprints. One innovative
element of this approach includes a novel Fingerprint Enhancement Gabor layer,
specifically designed for GPU computations. This illustrates how modern
computational resources might be harnessed to expedite enhancement. Given its
potential functionality as either a CNN or Transformer layer, this Gabor layer
could offer improved agility and processing speed to the system. However, it is
important to note that this approach is still in the early stages of
development and has not yet been fully validated through rigorous experiments.
As such, it may require additional time and testing to establish its robustness
and usability in the field of latent fingerprint enhancement. This includes
improvements in processing speed, enhancement adaptability with distinct latent
fingerprint types, and full validation in experimental approaches such as
open-set (identification 1:N) and open-set validation, fingerprint quality
evaluation, among others.
</p></li>
</ul>

<h3>Title: Teacher Agent: A Non-Knowledge Distillation Method for Rehearsal-based Video Incremental Learning. (arXiv:2306.00393v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.00393">http://arxiv.org/abs/2306.00393</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.00393] Teacher Agent: A Non-Knowledge Distillation Method for Rehearsal-based Video Incremental Learning](http://arxiv.org/abs/2306.00393) #robust</code></li>
<li>Summary: <p>With the rise in popularity of video-based social media, new categories of
videos are constantly being generated, creating an urgent need for robust
incremental learning techniques for video understanding. One of the biggest
challenges in this task is catastrophic forgetting, where the network tends to
forget previously learned data while learning new categories. To overcome this
issue, knowledge distillation is a widely used technique for rehearsal-based
video incremental learning that involves transferring important information on
similarities among different categories to enhance the student model.
Therefore, it is preferable to have a strong teacher model to guide the
students. However, the limited performance of the network itself and the
occurrence of catastrophic forgetting can result in the teacher network making
inaccurate predictions for some memory exemplars, ultimately limiting the
student network's performance. Based on these observations, we propose a
teacher agent capable of generating stable and accurate soft labels to replace
the output of the teacher model. This method circumvents the problem of
knowledge misleading caused by inaccurate predictions of the teacher model and
avoids the computational overhead of loading the teacher model for knowledge
distillation. Extensive experiments demonstrate the advantages of our method,
yielding significant performance improvements while utilizing only half the
resolution of video clips in the incremental phases as input compared to recent
state-of-the-art methods. Moreover, our method surpasses the performance of
joint training when employing four times the number of samples in episodic
memory.
</p></li>
</ul>

<h3>Title: Towards Interactive Image Inpainting via Sketch Refinement. (arXiv:2306.00407v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.00407">http://arxiv.org/abs/2306.00407</a></li>
<li>Code URL: <a href="https://github.com/alonzoleeeooo/sketchrefiner">https://github.com/alonzoleeeooo/sketchrefiner</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2306.00407] Towards Interactive Image Inpainting via Sketch Refinement](http://arxiv.org/abs/2306.00407) #robust</code></li>
<li>Summary: <p>One tough problem of image inpainting is to restore complex structures in the
corrupted regions. It motivates interactive image inpainting which leverages
additional hints, e.g., sketches, to assist the inpainting process. Sketch is
simple and intuitive to end users, but meanwhile has free forms with much
randomness. Such randomness may confuse the inpainting models, and incur severe
artifacts in completed images. To address this problem, we propose a two-stage
image inpainting method termed SketchRefiner. In the first stage, we propose
using a cross-correlation loss function to robustly calibrate and refine the
user-provided sketches in a coarse-to-fine fashion. In the second stage, we
learn to extract informative features from the abstracted sketches in the
feature space and modulate the inpainting process. We also propose an algorithm
to simulate real sketches automatically and build a test protocol with
different applications. Experimental results on public datasets demonstrate
that SketchRefiner effectively utilizes sketch information and eliminates the
artifacts due to the free-form sketches. Our method consistently outperforms
the state-of-the-art ones both qualitatively and quantitatively, meanwhile
revealing great potential in real-world applications. Our code and dataset are
available.
</p></li>
</ul>

<h3>Title: Measuring the Robustness of Natural Language Processing Models to Domain Shifts. (arXiv:2306.00168v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.00168">http://arxiv.org/abs/2306.00168</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.00168] Measuring the Robustness of Natural Language Processing Models to Domain Shifts](http://arxiv.org/abs/2306.00168) #robust</code></li>
<li>Summary: <p>Large Language Models have shown promising performance on various tasks,
including fine-tuning, few-shot learning, and zero-shot learning. However,
their performance on domains without labeled data still lags behind those with
labeled data, which we refer as the Domain Robustness (DR) challenge. Existing
research on DR suffers from disparate setups, lack of evaluation task variety,
and reliance on challenge sets. In this paper, we explore the DR challenge of
both fine-tuned and few-shot learning models in natural domain shift settings.
We introduce a DR benchmark comprising diverse NLP tasks, including sentence
and token-level classification, QA, and generation, each task consists of
several domains. We propose two views of the DR challenge: Source Drop (SD) and
Target Drop (TD), which alternate between the source and target in-domain
performance as reference points. We find that in significant proportions of
domain shifts, either SD or TD is positive, but not both, emphasizing the
importance of considering both measures as diagnostic tools. Our experimental
results demonstrate the persistent existence of the DR challenge in both
fine-tuning and few-shot learning models, though it is less pronounced in the
latter. We also find that increasing the fine-tuned model size improves
performance, particularly in classification.
</p></li>
</ul>

<h3>Title: Towards hate speech detection in low-resource languages: Comparing ASR to acoustic word embeddings on Wolof and Swahili. (arXiv:2306.00410v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.00410">http://arxiv.org/abs/2306.00410</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.00410] Towards hate speech detection in low-resource languages: Comparing ASR to acoustic word embeddings on Wolof and Swahili](http://arxiv.org/abs/2306.00410) #robust</code></li>
<li>Summary: <p>We consider hate speech detection through keyword spotting on radio
broadcasts. One approach is to build an automatic speech recognition (ASR)
system for the target low-resource language. We compare this to using acoustic
word embedding (AWE) models that map speech segments to a space where matching
words have similar vectors. We specifically use a multilingual AWE model
trained on labelled data from well-resourced languages to spot keywords in data
in the unseen target language. In contrast to ASR, the AWE approach only
requires a few keyword exemplars. In controlled experiments on Wolof and
Swahili where training and test data are from the same domain, an ASR model
trained on just five minutes of data outperforms the AWE approach. But in an
in-the-wild test on Swahili radio broadcasts with actual hate speech keywords,
the AWE model (using one minute of template data) is more robust, giving
similar performance to an ASR system trained on 30 hours of labelled data.
</p></li>
</ul>

<h3>Title: Divide, Conquer, and Combine: Mixture of Semantic-Independent Experts for Zero-Shot Dialogue State Tracking. (arXiv:2306.00434v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.00434">http://arxiv.org/abs/2306.00434</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.00434] Divide, Conquer, and Combine: Mixture of Semantic-Independent Experts for Zero-Shot Dialogue State Tracking](http://arxiv.org/abs/2306.00434) #robust</code></li>
<li>Summary: <p>Zero-shot transfer learning for Dialogue State Tracking (DST) helps to handle
a variety of task-oriented dialogue domains without the cost of collecting
in-domain data. Existing works mainly study common data- or model-level
augmentation methods to enhance the generalization but fail to effectively
decouple the semantics of samples, limiting the zero-shot performance of DST.
In this paper, we present a simple and effective "divide, conquer and combine"
solution, which explicitly disentangles the semantics of seen data, and
leverages the performance and robustness with the mixture-of-experts mechanism.
Specifically, we divide the seen data into semantically independent subsets and
train corresponding experts, the newly unseen samples are mapped and inferred
with mixture-of-experts with our designed ensemble inference. Extensive
experiments on MultiWOZ2.1 upon the T5-Adapter show our schema significantly
and consistently improves the zero-shot performance, achieving the SOTA on
settings without external knowledge, with only 10M trainable parameters1.
</p></li>
</ul>

<h3>Title: Predicting Heart Disease and Reducing Survey Time Using Machine Learning Algorithms. (arXiv:2306.00023v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.00023">http://arxiv.org/abs/2306.00023</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.00023] Predicting Heart Disease and Reducing Survey Time Using Machine Learning Algorithms](http://arxiv.org/abs/2306.00023) #robust</code></li>
<li>Summary: <p>Currently, many researchers and analysts are working toward medical diagnosis
enhancement for various diseases. Heart disease is one of the common diseases
that can be considered a significant cause of mortality worldwide. Early
detection of heart disease significantly helps in reducing the risk of heart
failure. Consequently, the Centers for Disease Control and Prevention (CDC)
conducts a health-related telephone survey yearly from over 400,000
participants. However, several concerns arise regarding the reliability of the
data in predicting heart disease and whether all of the survey questions are
strongly related. This study aims to utilize several machine learning
techniques, such as support vector machines and logistic regression, to
investigate the accuracy of the CDC's heart disease survey in the United
States. Furthermore, we use various feature selection methods to identify the
most relevant subset of questions that can be utilized to forecast heart
conditions. To reach a robust conclusion, we perform stability analysis by
randomly sampling the data 300 times. The experimental results show that the
survey data can be useful up to 80% in terms of predicting heart disease, which
significantly improves the diagnostic process before bloodwork and tests. In
addition, the amount of time spent conducting the survey can be reduced by 77%
while maintaining the same level of performance.
</p></li>
</ul>

<h3>Title: Learning for Edge-Weighted Online Bipartite Matching with Robustness Guarantees. (arXiv:2306.00172v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.00172">http://arxiv.org/abs/2306.00172</a></li>
<li>Code URL: <a href="https://github.com/ren-research/lomar">https://github.com/ren-research/lomar</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2306.00172] Learning for Edge-Weighted Online Bipartite Matching with Robustness Guarantees](http://arxiv.org/abs/2306.00172) #robust</code></li>
<li>Summary: <p>Many problems, such as online ad display, can be formulated as online
bipartite matching. The crucial challenge lies in the nature of
sequentially-revealed online item information, based on which we make
irreversible matching decisions at each step. While numerous expert online
algorithms have been proposed with bounded worst-case competitive ratios, they
may not offer satisfactory performance in average cases. On the other hand,
reinforcement learning (RL) has been applied to improve the average
performance, but it lacks robustness and can perform arbitrarily poorly. In
this paper, we propose a novel RL-based approach to edge-weighted online
bipartite matching with robustness guarantees (LOMAR), achieving both good
average-case and worst-case performance. The key novelty of LOMAR is a new
online switching operation which, based on a judicious condition to hedge
against future uncertainties, decides whether to follow the expert's decision
or the RL decision for each online item. We prove that for any $\rho\in[0,1]$,
LOMAR is $\rho$-competitive against any given expert online algorithm. To
improve the average performance, we train the RL policy by explicitly
considering the online switching operation. Finally, we run empirical
experiments to demonstrate the advantages of LOMAR compared to existing
baselines. Our code is available at: https://github.com/Ren-Research/LOMAR
</p></li>
</ul>

<h3>Title: Faster Robust Tensor Power Method for Arbitrary Order. (arXiv:2306.00406v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.00406">http://arxiv.org/abs/2306.00406</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.00406] Faster Robust Tensor Power Method for Arbitrary Order](http://arxiv.org/abs/2306.00406) #robust</code></li>
<li>Summary: <p>Tensor decomposition is a fundamental method used in various areas to deal
with high-dimensional data. \emph{Tensor power method} (TPM) is one of the
widely-used techniques in the decomposition of tensors. This paper presents a
novel tensor power method for decomposing arbitrary order tensors, which
overcomes limitations of existing approaches that are often restricted to
lower-order (less than $3$) tensors or require strong assumptions about the
underlying data structure. We apply sketching method, and we are able to
achieve the running time of $\widetilde{O}(n^{p-1})$, on the power $p$ and
dimension $n$ tensor. We provide a detailed analysis for any $p$-th order
tensor, which is never given in previous works.
</p></li>
</ul>

<h2>biometric</h2>
<h2>steal</h2>
<h2>extraction</h2>
<h3>Title: Sea Ice Extraction via Remote Sensed Imagery: Algorithms, Datasets, Applications and Challenges. (arXiv:2306.00303v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.00303">http://arxiv.org/abs/2306.00303</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.00303] Sea Ice Extraction via Remote Sensed Imagery: Algorithms, Datasets, Applications and Challenges](http://arxiv.org/abs/2306.00303) #extraction</code></li>
<li>Summary: <p>The deep learning, which is a dominating technique in artificial
intelligence, has completely changed the image understanding over the past
decade. As a consequence, the sea ice extraction (SIE) problem has reached a
new era. We present a comprehensive review of four important aspects of SIE,
including algorithms, datasets, applications, and the future trends. Our review
focuses on researches published from 2016 to the present, with a specific focus
on deep learning-based approaches in the last five years. We divided all
relegated algorithms into 3 categories, including classical image segmentation
approach, machine learning-based approach and deep learning-based methods. We
reviewed the accessible ice datasets including SAR-based datasets, the
optical-based datasets and others. The applications are presented in 4 aspects
including climate research, navigation, geographic information systems (GIS)
production and others. It also provides insightful observations and inspiring
future research directions.
</p></li>
</ul>

<h3>Title: Large Scale Generative Multimodal Attribute Extraction for E-commerce Attributes. (arXiv:2306.00379v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.00379">http://arxiv.org/abs/2306.00379</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.00379] Large Scale Generative Multimodal Attribute Extraction for E-commerce Attributes](http://arxiv.org/abs/2306.00379) #extraction</code></li>
<li>Summary: <p>E-commerce websites (e.g. Amazon) have a plethora of structured and
unstructured information (text and images) present on the product pages.
Sellers often either don't label or mislabel values of the attributes (e.g.
color, size etc.) for their products. Automatically identifying these attribute
values from an eCommerce product page that contains both text and images is a
challenging task, especially when the attribute value is not explicitly
mentioned in the catalog. In this paper, we present a scalable solution for
this problem where we pose attribute extraction problem as a question-answering
task, which we solve using \textbf{MXT}, consisting of three key components:
(i) \textbf{M}AG (Multimodal Adaptation Gate), (ii) \textbf{X}ception network,
and (iii) \textbf{T}5 encoder-decoder. Our system consists of a generative
model that \emph{generates} attribute-values for a given product by using both
textual and visual characteristics (e.g. images) of the product. We show that
our system is capable of handling zero-shot attribute prediction (when
attribute value is not seen in training data) and value-absent prediction (when
attribute value is not mentioned in the text) which are missing in traditional
classification-based and NER-based models respectively. We have trained our
models using distant supervision, removing dependency on human labeling, thus
making them practical for real-world applications. With this framework, we are
able to train a single model for 1000s of (product-type, attribute) pairs, thus
reducing the overhead of training and maintaining separate models. Extensive
experiments on two real world datasets show that our framework improves the
absolute recall@90P by 10.16\% and 6.9\% from the existing state of the art
models. In a popular e-commerce store, we have deployed our models for 1000s of
(product-type, attribute) pairs.
</p></li>
</ul>

<h3>Title: Utilization of Multinomial Naive Bayes Algorithm and Term Frequency Inverse Document Frequency (TF-IDF Vectorizer) in Checking the Credibility of News Tweet in the Philippines. (arXiv:2306.00018v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.00018">http://arxiv.org/abs/2306.00018</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.00018] Utilization of Multinomial Naive Bayes Algorithm and Term Frequency Inverse Document Frequency (TF-IDF Vectorizer) in Checking the Credibility of News Tweet in the Philippines](http://arxiv.org/abs/2306.00018) #extraction</code></li>
<li>Summary: <p>The digitalization of news media become a good indicator of progress and
signal to more threats. Media disinformation or fake news is one of these
threats, and it is necessary to take any action in fighting disinformation.
This paper utilizes ground truth-based annotations and TF-IDF as feature
extraction for the news articles which is then used as a training data set for
Multinomial Naive Bayes. The model has an accuracy of 99.46% in training and
88.98% in predicting unseen data. Tagging fake news as real news is a
concerning point on the prediction that is indicated in the F1 score of 89.68%.
This could lead to a negative impact. To prevent this to happen it is suggested
to further improve the corpus collection, and use an ensemble machine learning
to reinforce the prediction
</p></li>
</ul>

<h3>Title: Self-Verification Improves Few-Shot Clinical Information Extraction. (arXiv:2306.00024v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.00024">http://arxiv.org/abs/2306.00024</a></li>
<li>Code URL: <a href="https://github.com/microsoft/clinical-self-verification">https://github.com/microsoft/clinical-self-verification</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2306.00024] Self-Verification Improves Few-Shot Clinical Information Extraction](http://arxiv.org/abs/2306.00024) #extraction</code></li>
<li>Summary: <p>Extracting patient information from unstructured text is a critical task in
health decision-support and clinical research. Large language models (LLMs)
have shown the potential to accelerate clinical curation via few-shot
in-context learning, in contrast to supervised learning which requires much
more costly human annotations. However, despite drastic advances in modern LLMs
such as GPT-4, they still struggle with issues regarding accuracy and
interpretability, especially in mission-critical domains such as health. Here,
we explore a general mitigation framework using self-verification, which
leverages the LLM to provide provenance for its own extraction and check its
own outputs. This is made possible by the asymmetry between verification and
generation, where the latter is often much easier than the former. Experimental
results show that our method consistently improves accuracy for various LLMs in
standard clinical information extraction tasks. Additionally, self-verification
yields interpretations in the form of a short text span corresponding to each
output, which makes it very efficient for human experts to audit the results,
paving the way towards trustworthy extraction of clinical information in
resource-constrained scenarios. To facilitate future research in this
direction, we release our code and prompts.
</p></li>
</ul>

<h2>membership infer</h2>
<h2>federate</h2>
<h3>Title: Towards Bias Correction of FedAvg over Nonuniform and Time-Varying Communications. (arXiv:2306.00280v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.00280">http://arxiv.org/abs/2306.00280</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.00280] Towards Bias Correction of FedAvg over Nonuniform and Time-Varying Communications](http://arxiv.org/abs/2306.00280) #federate</code></li>
<li>Summary: <p>Federated learning (FL) is a decentralized learning framework wherein a
parameter server (PS) and a collection of clients collaboratively train a model
via minimizing a global objective. Communication bandwidth is a scarce
resource; in each round, the PS aggregates the updates from a subset of clients
only. In this paper, we focus on non-convex minimization that is vulnerable to
non-uniform and time-varying communication failures between the PS and the
clients. Specifically, in each round $t$, the link between the PS and client
$i$ is active with probability $p_i^t$, which is $\textit{unknown}$ to both the
PS and the clients. This arises when the channel conditions are heterogeneous
across clients and are changing over time.
</p></li>
</ul>

<p>We show that when the $p_i^t$'s are not uniform, $\textit{Federated Average}$
(FedAvg) -- the most widely adopted FL algorithm -- fails to minimize the
global objective. Observing this, we propose $\textit{Federated Postponed
Broadcast}$ (FedPBC) which is a simple variant of FedAvg. It differs from
FedAvg in that the PS postpones broadcasting the global model till the end of
each round. We show that FedPBC converges to a stationary point of the original
objective. The introduced staleness is mild and there is no noticeable
slowdown. Both theoretical analysis and numerical results are provided. On the
technical front, postponing the global model broadcasts enables implicit
gossiping among the clients with active links at round $t$. Despite $p_i^t$'s
are time-varying, we are able to bound the perturbation of the global model
dynamics via the techniques of controlling the gossip-type information mixing
errors.
</p>

<h2>fair</h2>
<h3>Title: Enrichment of the NLST and NSCLC-Radiomics computed tomography collections with AI-derived annotations. (arXiv:2306.00150v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.00150">http://arxiv.org/abs/2306.00150</a></li>
<li>Code URL: <a href="https://github.com/imagingdatacommons/ai_medima_misc">https://github.com/imagingdatacommons/ai_medima_misc</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2306.00150] Enrichment of the NLST and NSCLC-Radiomics computed tomography collections with AI-derived annotations](http://arxiv.org/abs/2306.00150) #fair</code></li>
<li>Summary: <p>Public imaging datasets are critical for the development and evaluation of
automated tools in cancer imaging. Unfortunately, many do not include
annotations or image-derived features, complicating their downstream analysis.
Artificial intelligence-based annotation tools have been shown to achieve
acceptable performance and thus can be used to automatically annotate large
datasets. As part of the effort to enrich public data available within NCI
Imaging Data Commons (IDC), here we introduce AI-generated annotations for two
collections of computed tomography images of the chest, NSCLC-Radiomics, and
the National Lung Screening Trial. Using publicly available AI algorithms we
derived volumetric annotations of thoracic organs at risk, their corresponding
radiomics features, and slice-level annotations of anatomical landmarks and
regions. The resulting annotations are publicly available within IDC, where the
DICOM format is used to harmonize the data and achieve FAIR principles. The
annotations are accompanied by cloud-enabled notebooks demonstrating their use.
This study reinforces the need for large, publicly accessible curated datasets
and demonstrates how AI can be used to aid in cancer imaging.
</p></li>
</ul>

<h3>Title: CFL: Causally Fair Language Models Through Token-level Attribute Controlled Generation. (arXiv:2306.00374v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.00374">http://arxiv.org/abs/2306.00374</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.00374] CFL: Causally Fair Language Models Through Token-level Attribute Controlled Generation](http://arxiv.org/abs/2306.00374) #fair</code></li>
<li>Summary: <p>We propose a method to control the attributes of Language Models (LMs) for
the text generation task using Causal Average Treatment Effect (ATE) scores and
counterfactual augmentation. We explore this method, in the context of LM
detoxification, and propose the Causally Fair Language (CFL) architecture for
detoxifying pre-trained LMs in a plug-and-play manner. Our architecture is
based on a Structural Causal Model (SCM) that is mathematically transparent and
computationally efficient as compared with many existing detoxification
techniques. We also propose several new metrics that aim to better understand
the behaviour of LMs in the context of toxic text generation. Further, we
achieve state of the art performance for toxic degeneration, which are computed
using \RTP (RTP) benchmark. Our experiments show that CFL achieves such a
detoxification without much impact on the model perplexity. We also show that
CFL mitigates the unintended bias problem through experiments on the BOLD
dataset.
</p></li>
</ul>

<h3>Title: Achieving Fairness in Multi-Agent Markov Decision Processes Using Reinforcement Learning. (arXiv:2306.00324v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.00324">http://arxiv.org/abs/2306.00324</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.00324] Achieving Fairness in Multi-Agent Markov Decision Processes Using Reinforcement Learning](http://arxiv.org/abs/2306.00324) #fair</code></li>
<li>Summary: <p>Fairness plays a crucial role in various multi-agent systems (e.g.,
communication networks, financial markets, etc.). Many multi-agent dynamical
interactions can be cast as Markov Decision Processes (MDPs). While existing
research has focused on studying fairness in known environments, the
exploration of fairness in such systems for unknown environments remains open.
In this paper, we propose a Reinforcement Learning (RL) approach to achieve
fairness in multi-agent finite-horizon episodic MDPs. Instead of maximizing the
sum of individual agents' value functions, we introduce a fairness function
that ensures equitable rewards across agents. Since the classical Bellman's
equation does not hold when the sum of individual value functions is not
maximized, we cannot use traditional approaches. Instead, in order to explore,
we maintain a confidence bound of the unknown environment and then propose an
online convex optimization based approach to obtain a policy constrained to
this confidence region. We show that such an approach achieves sub-linear
regret in terms of the number of episodes. Additionally, we provide a probably
approximately correct (PAC) guarantee based on the obtained regret bound. We
also propose an offline RL algorithm and bound the optimality gap with respect
to the optimal fair solution. To mitigate computational complexity, we
introduce a policy-gradient type method for the fair objective. Simulation
experiments also demonstrate the efficacy of our approach.
</p></li>
</ul>

<h2>interpretability</h2>
<h3>Title: Explaining Hate Speech Classification with Model Agnostic Methods. (arXiv:2306.00021v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.00021">http://arxiv.org/abs/2306.00021</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.00021] Explaining Hate Speech Classification with Model Agnostic Methods](http://arxiv.org/abs/2306.00021) #interpretability</code></li>
<li>Summary: <p>There have been remarkable breakthroughs in Machine Learning and Artificial
Intelligence, notably in the areas of Natural Language Processing and Deep
Learning. Additionally, hate speech detection in dialogues has been gaining
popularity among Natural Language Processing researchers with the increased use
of social media. However, as evidenced by the recent trends, the need for the
dimensions of explainability and interpretability in AI models has been deeply
realised. Taking note of the factors above, the research goal of this paper is
to bridge the gap between hate speech prediction and the explanations generated
by the system to support its decision. This has been achieved by first
predicting the classification of a text and then providing a posthoc, model
agnostic and surrogate interpretability approach for explainability and to
prevent model bias. The bidirectional transformer model BERT has been used for
prediction because of its state of the art efficiency over other Machine
Learning models. The model agnostic algorithm LIME generates explanations for
the output of a trained classifier and predicts the features that influence the
model decision. The predictions generated from the model were evaluated
manually, and after thorough evaluation, we observed that the model performs
efficiently in predicting and explaining its prediction. Lastly, we suggest
further directions for the expansion of the provided research work.
</p></li>
</ul>

<h3>Title: Incorporating Domain Knowledge in Deep Neural Networks for Discrete Choice Models. (arXiv:2306.00016v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.00016">http://arxiv.org/abs/2306.00016</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.00016] Incorporating Domain Knowledge in Deep Neural Networks for Discrete Choice Models](http://arxiv.org/abs/2306.00016) #interpretability</code></li>
<li>Summary: <p>Discrete choice models (DCM) are widely employed in travel demand analysis as
a powerful theoretical econometric framework for understanding and predicting
choice behaviors. DCMs are formed as random utility models (RUM), with their
key advantage of interpretability. However, a core requirement for the
estimation of these models is a priori specification of the associated utility
functions, making them sensitive to modelers' subjective beliefs. Recently,
machine learning (ML) approaches have emerged as a promising avenue for
learning unobserved non-linear relationships in DCMs. However, ML models are
considered "black box" and may not correspond with expected relationships. This
paper proposes a framework that expands the potential of data-driven approaches
for DCM by supporting the development of interpretable models that incorporate
domain knowledge and prior beliefs through constraints. The proposed framework
includes pseudo data samples that represent required relationships and a loss
function that measures their fulfillment, along with observed data, for model
training. The developed framework aims to improve model interpretability by
combining ML's specification flexibility with econometrics and interpretable
behavioral analysis. A case study demonstrates the potential of this framework
for discrete choice analysis.
</p></li>
</ul>

<h3>Title: Information Fusion via Symbolic Regression: A Tutorial in the Context of Human Health. (arXiv:2306.00153v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.00153">http://arxiv.org/abs/2306.00153</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.00153] Information Fusion via Symbolic Regression: A Tutorial in the Context of Human Health](http://arxiv.org/abs/2306.00153) #interpretability</code></li>
<li>Summary: <p>This tutorial paper provides a general overview of symbolic regression (SR)
with specific focus on standards of interpretability. We posit that
interpretable modeling, although its definition is still disputed in the
literature, is a practical way to support the evaluation of successful
information fusion. In order to convey the benefits of SR as a modeling
technique, we demonstrate an application within the field of health and
nutrition using publicly available National Health and Nutrition Examination
Survey (NHANES) data from the Centers for Disease Control and Prevention (CDC),
fusing together anthropometric markers into a simple mathematical expression to
estimate body fat percentage. We discuss the advantages and challenges
associated with SR modeling and provide qualitative and quantitative analyses
of the learned models.
</p></li>
</ul>

<h2>explainability</h2>
<h3>Title: Discriminative Deep Feature Visualization for Explainable Face Recognition. (arXiv:2306.00402v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.00402">http://arxiv.org/abs/2306.00402</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.00402] Discriminative Deep Feature Visualization for Explainable Face Recognition](http://arxiv.org/abs/2306.00402) #explainability</code></li>
<li>Summary: <p>Despite the huge success of deep convolutional neural networks in face
recognition (FR) tasks, current methods lack explainability for their
predictions because of their "black-box" nature. In recent years, studies have
been carried out to give an interpretation of the decision of a deep FR system.
However, the affinity between the input facial image and the extracted deep
features has not been explored. This paper contributes to the problem of
explainable face recognition by first conceiving a face reconstruction-based
explanation module, which reveals the correspondence between the deep feature
and the facial regions. To further interpret the decision of an FR model, a
novel visual saliency explanation algorithm has been proposed. It provides
insightful explanation by producing visual saliency maps that represent similar
and dissimilar regions between input faces. A detailed analysis has been
presented for the generated visual explanation to show the effectiveness of the
proposed method.
</p></li>
</ul>

<h3>Title: Explainability in Simplicial Map Neural Networks. (arXiv:2306.00010v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.00010">http://arxiv.org/abs/2306.00010</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.00010] Explainability in Simplicial Map Neural Networks](http://arxiv.org/abs/2306.00010) #explainability</code></li>
<li>Summary: <p>Simplicial map neural networks (SMNNs) are topology-based neural networks
with interesting properties such as universal approximation capability and
robustness to adversarial examples under appropriate conditions. However, SMNNs
present some bottlenecks for their possible application in high dimensions.
First, no SMNN training process has been defined so far. Second, SMNNs require
the construction of a convex polytope surrounding the input dataset. In this
paper, we propose a SMNN training procedure based on a support subset of the
given dataset and a method based on projection to a hypersphere as a
replacement for the convex polytope construction. In addition, the
explainability capacity of SMNNs is also introduced for the first time in this
paper.
</p></li>
</ul>

<h2>watermark</h2>
<h2>diffusion</h2>
<h3>Title: Diffusion Brush: A Latent Diffusion Model-based Editing Tool for AI-generated Images. (arXiv:2306.00219v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.00219">http://arxiv.org/abs/2306.00219</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.00219] Diffusion Brush: A Latent Diffusion Model-based Editing Tool for AI-generated Images](http://arxiv.org/abs/2306.00219) #diffusion</code></li>
<li>Summary: <p>Text-to-image generative models have made remarkable advancements in
generating high-quality images. However, generated images often contain
undesirable artifacts or other errors due to model limitations. Existing
techniques to fine-tune generated images are time-consuming (manual editing),
produce poorly-integrated results (inpainting), or result in unexpected changes
across the entire image (variation selection and prompt fine-tuning). In this
work, we present Diffusion Brush, a Latent Diffusion Model-based (LDM) tool to
efficiently fine-tune desired regions within an AI-synthesized image. Our
method introduces new random noise patterns at targeted regions during the
reverse diffusion process, enabling the model to efficiently make changes to
the specified regions while preserving the original context for the rest of the
image. We evaluate our method's usability and effectiveness through a user
study with artists, comparing our technique against other state-of-the-art
image inpainting techniques and editing software for fine-tuning AI-generated
imagery.
</p></li>
</ul>

<h3>Title: Low-Light Image Enhancement with Wavelet-based Diffusion Models. (arXiv:2306.00306v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.00306">http://arxiv.org/abs/2306.00306</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.00306] Low-Light Image Enhancement with Wavelet-based Diffusion Models](http://arxiv.org/abs/2306.00306) #diffusion</code></li>
<li>Summary: <p>Diffusion models have achieved promising results in image restoration tasks,
yet suffer from time-consuming, excessive computational resource consumption,
and unstable restoration. To address these issues, we propose a robust and
efficient Diffusion-based Low-Light image enhancement approach, dubbed DiffLL.
Specifically, we present a wavelet-based conditional diffusion model (WCDM)
that leverages the generative power of diffusion models to produce results with
satisfactory perceptual fidelity. Additionally, it also takes advantage of the
strengths of wavelet transformation to greatly accelerate inference and reduce
computational resource usage without sacrificing information. To avoid chaotic
content and diversity, we perform both forward diffusion and reverse denoising
in the training phase of WCDM, enabling the model to achieve stable denoising
and reduce randomness during inference. Moreover, we further design a
high-frequency restoration module (HFRM) that utilizes the vertical and
horizontal details of the image to complement the diagonal information for
better fine-grained restoration. Extensive experiments on publicly available
real-world benchmarks demonstrate that our method outperforms the existing
state-of-the-art methods both quantitatively and visually, and it achieves
remarkable improvements in efficiency compared to previous diffusion-based
methods. In addition, we empirically show that the application for low-light
face detection also reveals the latent practical values of our method.
</p></li>
</ul>

<h3>Title: Addressing Negative Transfer in Diffusion Models. (arXiv:2306.00354v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.00354">http://arxiv.org/abs/2306.00354</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.00354] Addressing Negative Transfer in Diffusion Models](http://arxiv.org/abs/2306.00354) #diffusion</code></li>
<li>Summary: <p>Diffusion-based generative models have achieved remarkable success in various
domains. It trains a model on denoising tasks that encompass different noise
levels simultaneously, representing a form of multi-task learning (MTL).
However, analyzing and improving diffusion models from an MTL perspective
remains under-explored. In particular, MTL can sometimes lead to the well-known
phenomenon of $\textit{negative transfer}$, which results in the performance
degradation of certain tasks due to conflicts between tasks. In this paper, we
aim to analyze diffusion training from an MTL standpoint, presenting two key
observations: $\textbf{(O1)}$ the task affinity between denoising tasks
diminishes as the gap between noise levels widens, and $\textbf{(O2)}$ negative
transfer can arise even in the context of diffusion training. Building upon
these observations, our objective is to enhance diffusion training by
mitigating negative transfer. To achieve this, we propose leveraging existing
MTL methods, but the presence of a huge number of denoising tasks makes this
computationally expensive to calculate the necessary per-task loss or gradient.
To address this challenge, we propose clustering the denoising tasks into small
task clusters and applying MTL methods to them. Specifically, based on
$\textbf{(O2)}$, we employ interval clustering to enforce temporal proximity
among denoising tasks within clusters. We show that interval clustering can be
solved with dynamic programming and utilize signal-to-noise ratio, timestep,
and task affinity for clustering objectives. Through this, our approach
addresses the issue of negative transfer in diffusion models by allowing for
efficient computation of MTL methods. We validate the proposed clustering and
its integration with MTL methods through various experiments, demonstrating
improved sample quality of diffusion models.
</p></li>
</ul>

<h3>Title: Controllable Motion Diffusion Model. (arXiv:2306.00416v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.00416">http://arxiv.org/abs/2306.00416</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.00416] Controllable Motion Diffusion Model](http://arxiv.org/abs/2306.00416) #diffusion</code></li>
<li>Summary: <p>Generating realistic and controllable motions for virtual characters is a
challenging task in computer animation, and its implications extend to games,
simulations, and virtual reality. Recent studies have drawn inspiration from
the success of diffusion models in image generation, demonstrating the
potential for addressing this task. However, the majority of these studies have
been limited to offline applications that target at sequence-level generation
that generates all steps simultaneously. To enable real-time motion synthesis
with diffusion models in response to time-varying control signals, we propose
the framework of the Controllable Motion Diffusion Model (COMODO). Our
framework begins with an auto-regressive motion diffusion model (A-MDM), which
generates motion sequences step by step. In this way, simply using the standard
DDPM algorithm without any additional complexity, our framework is able to
generate high-fidelity motion sequences over extended periods with different
types of control signals. Then, we propose our reinforcement learning-based
controller and controlling strategies on top of the A-MDM model, so that our
framework can steer the motion synthesis process across multiple tasks,
including target reaching, joystick-based control, goal-oriented control, and
trajectory following. The proposed framework enables the real-time generation
of diverse motions that react adaptively to user commands on-the-fly, thereby
enhancing the overall user experience. Besides, it is compatible with the
inpainting-based editing methods and can predict much more diverse motions
without additional fine-tuning of the basic motion generation models. We
conduct comprehensive experiments to evaluate the effectiveness of our
framework in performing various tasks and compare its performance against
state-of-the-art methods.
</p></li>
</ul>

<h3>Title: SafeDiffuser: Safe Planning with Diffusion Probabilistic Models. (arXiv:2306.00148v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.00148">http://arxiv.org/abs/2306.00148</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.00148] SafeDiffuser: Safe Planning with Diffusion Probabilistic Models](http://arxiv.org/abs/2306.00148) #diffusion</code></li>
<li>Summary: <p>Diffusion model-based approaches have shown promise in data-driven planning,
but there are no safety guarantees, thus making it hard to be applied for
safety-critical applications. To address these challenges, we propose a new
method, called SafeDiffuser, to ensure diffusion probabilistic models satisfy
specifications by using a class of control barrier functions. The key idea of
our approach is to embed the proposed finite-time diffusion invariance into the
denoising diffusion procedure, which enables trustworthy diffusion data
generation. Moreover, we demonstrate that our finite-time diffusion invariance
method through generative models not only maintains generalization performance
but also creates robustness in safe data generation. We test our method on a
series of safe planning tasks, including maze path generation, legged robot
locomotion, and 3D space manipulation, with results showing the advantages of
robustness and guarantees over vanilla diffusion models.
</p></li>
</ul>

<h2>noise learning</h2>
<h2>data-free</h2>
<h2>transformer</h2>
<h3>Title: Self-supervised Vision Transformers for 3D Pose Estimation of Novel Objects. (arXiv:2306.00129v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.00129">http://arxiv.org/abs/2306.00129</a></li>
<li>Code URL: <a href="https://github.com/sthalham/tram3d">https://github.com/sthalham/tram3d</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2306.00129] Self-supervised Vision Transformers for 3D Pose Estimation of Novel Objects](http://arxiv.org/abs/2306.00129) #transformer</code></li>
<li>Summary: <p>Object pose estimation is important for object manipulation and scene
understanding. In order to improve the general applicability of pose
estimators, recent research focuses on providing estimates for novel objects,
that is objects unseen during training. Such works use deep template matching
strategies to retrieve the closest template connected to a query image. This
template retrieval implicitly provides object class and pose. Despite the
recent success and improvements of Vision Transformers over CNNs for many
vision tasks, the state of the art uses CNN-based approaches for novel object
pose estimation. This work evaluates and demonstrates the differences between
self-supervised CNNs and Vision Transformers for deep template matching. In
detail, both types of approaches are trained using contrastive learning to
match training images against rendered templates of isolated objects. At test
time, such templates are matched against query images of known and novel
objects under challenging settings, such as clutter, occlusion and object
symmetries, using masked cosine similarity. The presented results not only
demonstrate that Vision Transformers improve in matching accuracy over CNNs,
but also that for some cases pre-trained Vision Transformers do not need
fine-tuning to do so. Furthermore, we highlight the differences in optimization
and network architecture when comparing these two types of network for deep
template matching.
</p></li>
</ul>

<h3>Title: A Universal Latent Fingerprint Enhancer Using Transformers. (arXiv:2306.00231v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.00231">http://arxiv.org/abs/2306.00231</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.00231] A Universal Latent Fingerprint Enhancer Using Transformers](http://arxiv.org/abs/2306.00231) #transformer</code></li>
<li>Summary: <p>Forensic science heavily relies on analyzing latent fingerprints, which are
crucial for criminal investigations. However, various challenges, such as
background noise, overlapping prints, and contamination, make the
identification process difficult. Moreover, limited access to real crime scene
and laboratory-generated databases hinders the development of efficient
recognition algorithms. This study aims to develop a fast method, which we call
ULPrint, to enhance various latent fingerprint types, including those obtained
from real crime scenes and laboratory-created samples, to boost fingerprint
recognition system performance. In closed-set identification accuracy
experiments, the enhanced image was able to improve the performance of the
MSU-AFIS from 61.56\% to 75.19\% in the NIST SD27 database, from 67.63\% to
77.02\% in the MSP Latent database, and from 46.90\% to 52.12\% in the NIST
SD302 database. Our contributions include (1) the development of a two-step
latent fingerprint enhancement method that combines Ridge Segmentation with
UNet and Mix Visual Transformer (MiT) SegFormer-B5 encoder architecture, (2)
the implementation of multiple dilated convolutions in the UNet architecture to
capture intricate, non-local patterns better and enhance ridge segmentation,
and (3) the guided blending of the predicted ridge mask with the latent
fingerprint. This novel approach, ULPrint, streamlines the enhancement process,
addressing challenges across diverse latent fingerprint types to improve
forensic investigations and criminal justice outcomes.
</p></li>
</ul>

<h3>Title: Bytes Are All You Need: Transformers Operating Directly On File Bytes. (arXiv:2306.00238v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.00238">http://arxiv.org/abs/2306.00238</a></li>
<li>Code URL: <a href="https://github.com/apple/ml-cvnets">https://github.com/apple/ml-cvnets</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2306.00238] Bytes Are All You Need: Transformers Operating Directly On File Bytes](http://arxiv.org/abs/2306.00238) #transformer</code></li>
<li>Summary: <p>Modern deep learning approaches usually transform inputs into a
modality-specific form. For example, the most common deep learning approach to
image classification involves decoding image file bytes into an RGB tensor
which is passed into a neural network. Instead, we investigate performing
classification directly on file bytes, without the need for decoding files at
inference time. Using file bytes as model inputs enables the development of
models which can operate on multiple input modalities. Our model,
\emph{ByteFormer}, achieves an ImageNet Top-1 classification accuracy of
$77.33\%$ when training and testing directly on TIFF file bytes using a
transformer backbone with configuration similar to DeiT-Ti ($72.2\%$ accuracy
when operating on RGB images). Without modifications or hyperparameter tuning,
ByteFormer achieves $95.42\%$ classification accuracy when operating on WAV
files from the Speech Commands v2 dataset (compared to state-of-the-art
accuracy of $98.7\%$). Additionally, we demonstrate that ByteFormer has
applications in privacy-preserving inference. ByteFormer is capable of
performing inference on particular obfuscated input representations with no
loss of accuracy. We also demonstrate ByteFormer's ability to perform inference
with a hypothetical privacy-preserving camera which avoids forming full images
by consistently masking $90\%$ of pixel channels, while still achieving
$71.35\%$ accuracy on ImageNet. Our code will be made available at
https://github.com/apple/ml-cvnets/tree/main/examples/byteformer.
</p></li>
</ul>

<h3>Title: Affinity-based Attention in Self-supervised Transformers Predicts Dynamics of Object Grouping in Humans. (arXiv:2306.00294v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.00294">http://arxiv.org/abs/2306.00294</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.00294] Affinity-based Attention in Self-supervised Transformers Predicts Dynamics of Object Grouping in Humans](http://arxiv.org/abs/2306.00294) #transformer</code></li>
<li>Summary: <p>The spreading of attention has been proposed as a mechanism for how humans
group features to segment objects. However, such a mechanism has not yet been
implemented and tested in naturalistic images. Here, we leverage the feature
maps from self-supervised vision Transformers and propose a model of human
object-based attention spreading and segmentation. Attention spreads within an
object through the feature affinity signal between different patches of the
image. We also collected behavioral data on people grouping objects in natural
images by judging whether two dots are on the same object or on two different
objects. We found that our models of affinity spread that were built on feature
maps from the self-supervised Transformers showed significant improvement over
baseline and CNN based models on predicting reaction time patterns of humans,
despite not being trained on the task or with any other object labels. Our work
provides new benchmarks for evaluating models of visual representation learning
including Transformers.
</p></li>
</ul>

<h3>Title: Lightweight Vision Transformer with Bidirectional Interaction. (arXiv:2306.00396v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.00396">http://arxiv.org/abs/2306.00396</a></li>
<li>Code URL: <a href="https://github.com/qhfan/fat">https://github.com/qhfan/fat</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2306.00396] Lightweight Vision Transformer with Bidirectional Interaction](http://arxiv.org/abs/2306.00396) #transformer</code></li>
<li>Summary: <p>Recent advancements in vision backbones have significantly improved their
performance by simultaneously modeling images' local and global contexts.
However, the bidirectional interaction between these two contexts has not been
well explored and exploited, which is important in the human visual system.
This paper proposes a Fully Adaptive Self-Attention (FASA) mechanism for vision
transformer to model the local and global information as well as the
bidirectional interaction between them in context-aware ways. Specifically,
FASA employs self-modulated convolutions to adaptively extract local
representation while utilizing self-attention in down-sampled space to extract
global representation. Subsequently, it conducts a bidirectional adaptation
process between local and global representation to model their interaction. In
addition, we introduce a fine-grained downsampling strategy to enhance the
down-sampled self-attention mechanism for finer-grained global perception
capability. Based on FASA, we develop a family of lightweight vision backbones,
Fully Adaptive Transformer (FAT) family. Extensive experiments on multiple
vision tasks demonstrate that FAT achieves impressive performance. Notably, FAT
accomplishes a 77.6% accuracy on ImageNet-1K using only 4.5M parameters and
0.7G FLOPs, which surpasses the most advanced ConvNets and Transformers with
similar model size and computational costs. Moreover, our model exhibits faster
speed on modern GPU compared to other models. Code will be available at
https://github.com/qhfan/FAT.
</p></li>
</ul>

<h3>Title: Brainformers: Trading Simplicity for Efficiency. (arXiv:2306.00008v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.00008">http://arxiv.org/abs/2306.00008</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.00008] Brainformers: Trading Simplicity for Efficiency](http://arxiv.org/abs/2306.00008) #transformer</code></li>
<li>Summary: <p>Transformers are central to recent successes in natural language processing
and computer vision. Transformers have a mostly uniform backbone where layers
alternate between feed-forward and self-attention in order to build a deep
network. Here we investigate this design choice and find that more complex
blocks that have different permutations of layer primitives can be more
efficient. Using this insight, we develop a complex block, named Brainformer,
that consists of a diverse sets of layers such as sparsely gated feed-forward
layers, dense feed-forward layers, attention layers, and various forms of layer
normalization and activation functions. Brainformer consistently outperforms
the state-of-the-art dense and sparse Transformers, in terms of both quality
and efficiency. A Brainformer model with 8 billion activated parameters per
token demonstrates 2x faster training convergence and 5x faster step time
compared to its GLaM counterpart. In downstream task evaluation, Brainformer
also demonstrates a 3% higher SuperGLUE score with fine-tuning compared to GLaM
with a similar number of activated parameters. Finally, Brainformer largely
outperforms a Primer dense model derived with NAS with similar computation per
token on fewshot evaluations.
</p></li>
</ul>

<h3>Title: PreQuant: A Task-agnostic Quantization Approach for Pre-trained Language Models. (arXiv:2306.00014v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.00014">http://arxiv.org/abs/2306.00014</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.00014] PreQuant: A Task-agnostic Quantization Approach for Pre-trained Language Models](http://arxiv.org/abs/2306.00014) #transformer</code></li>
<li>Summary: <p>While transformer-based pre-trained language models (PLMs) have dominated a
number of NLP applications, these models are heavy to deploy and expensive to
use. Therefore, effectively compressing large-scale PLMs becomes an
increasingly important problem. Quantization, which represents high-precision
tensors with low-bit fix-point format, is a viable solution. However, most
existing quantization methods are task-specific, requiring customized training
and quantization with a large number of trainable parameters on each individual
task. Inspired by the observation that the over-parameterization nature of PLMs
makes it possible to freeze most of the parameters during the fine-tuning
stage, in this work, we propose a novel ``quantize before fine-tuning''
framework, PreQuant, that differs from both quantization-aware training and
post-training quantization. PreQuant is compatible with various quantization
strategies, with outlier-aware parameter-efficient fine-tuning incorporated to
correct the induced quantization error. We demonstrate the effectiveness of
PreQuant on the GLUE benchmark using BERT, RoBERTa, and T5. We also provide an
empirical investigation into the workflow of PreQuant, which sheds light on its
efficacy.
</p></li>
</ul>

<h3>Title: FEED PETs: Further Experimentation and Expansion on the Disambiguation of Potentially Euphemistic Terms. (arXiv:2306.00217v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.00217">http://arxiv.org/abs/2306.00217</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.00217] FEED PETs: Further Experimentation and Expansion on the Disambiguation of Potentially Euphemistic Terms](http://arxiv.org/abs/2306.00217) #transformer</code></li>
<li>Summary: <p>Transformers have been shown to work well for the task of English euphemism
disambiguation, in which a potentially euphemistic term (PET) is classified as
euphemistic or non-euphemistic in a particular context. In this study, we
expand on the task in two ways. First, we annotate PETs for vagueness, a
linguistic property associated with euphemisms, and find that transformers are
generally better at classifying vague PETs, suggesting linguistic differences
in the data that impact performance. Second, we present novel euphemism corpora
in three different languages: Yoruba, Spanish, and Mandarin Chinese. We perform
euphemism disambiguation experiments in each language using multilingual
transformer models mBERT and XLM-RoBERTa, establishing preliminary results from
which to launch future work.
</p></li>
</ul>

<h3>Title: Training-free Neural Architecture Search for RNNs and Transformers. (arXiv:2306.00288v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.00288">http://arxiv.org/abs/2306.00288</a></li>
<li>Code URL: <a href="https://github.com/aaronserianni/training-free-nas">https://github.com/aaronserianni/training-free-nas</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2306.00288] Training-free Neural Architecture Search for RNNs and Transformers](http://arxiv.org/abs/2306.00288) #transformer</code></li>
<li>Summary: <p>Neural architecture search (NAS) has allowed for the automatic creation of
new and effective neural network architectures, offering an alternative to the
laborious process of manually designing complex architectures. However,
traditional NAS algorithms are slow and require immense amounts of computing
power. Recent research has investigated training-free NAS metrics for image
classification architectures, drastically speeding up search algorithms. In
this paper, we investigate training-free NAS metrics for recurrent neural
network (RNN) and BERT-based transformer architectures, targeted towards
language modeling tasks. First, we develop a new training-free metric, named
hidden covariance, that predicts the trained performance of an RNN architecture
and significantly outperforms existing training-free metrics. We experimentally
evaluate the effectiveness of the hidden covariance metric on the NAS-Bench-NLP
benchmark. Second, we find that the current search space paradigm for
transformer architectures is not optimized for training-free neural
architecture search. Instead, a simple qualitative analysis can effectively
shrink the search space to the best performing architectures. This conclusion
is based on our investigation of existing training-free metrics and new metrics
developed from recent transformer pruning literature, evaluated on our own
benchmark of trained BERT architectures. Ultimately, our analysis shows that
the architecture search space and the training-free metric must be developed
together in order to achieve effective results.
</p></li>
</ul>

<h3>Title: Exploring Anisotropy and Outliers in Multilingual Language Models for Cross-Lingual Semantic Sentence Similarity. (arXiv:2306.00458v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.00458">http://arxiv.org/abs/2306.00458</a></li>
<li>Code URL: <a href="https://github.com/kathyhaem/outliers">https://github.com/kathyhaem/outliers</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2306.00458] Exploring Anisotropy and Outliers in Multilingual Language Models for Cross-Lingual Semantic Sentence Similarity](http://arxiv.org/abs/2306.00458) #transformer</code></li>
<li>Summary: <p>Previous work has shown that the representations output by contextual
language models are more anisotropic than static type embeddings, and typically
display outlier dimensions. This seems to be true for both monolingual and
multilingual models, although much less work has been done on the multilingual
context. Why these outliers occur and how they affect the representations is
still an active area of research. We investigate outlier dimensions and their
relationship to anisotropy in multiple pre-trained multilingual language
models. We focus on cross-lingual semantic similarity tasks, as these are
natural tasks for evaluating multilingual representations. Specifically, we
examine sentence representations. Sentence transformers which are fine-tuned on
parallel resources (that are not always available) perform better on this task,
and we show that their representations are more isotropic. However, we aim to
improve multilingual representations in general. We investigate how much of the
performance difference can be made up by only transforming the embedding space
without fine-tuning, and visualise the resulting spaces. We test different
operations: Removing individual outlier dimensions, cluster-based isotropy
enhancement, and ZCA whitening. We publish our code for reproducibility.
</p></li>
</ul>

<h3>Title: Diffused Redundancy in Pre-trained Representations. (arXiv:2306.00183v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.00183">http://arxiv.org/abs/2306.00183</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.00183] Diffused Redundancy in Pre-trained Representations](http://arxiv.org/abs/2306.00183) #transformer</code></li>
<li>Summary: <p>Representations learned by pre-training a neural network on a large dataset
are increasingly used successfully to perform a variety of downstream tasks. In
this work, we take a closer look at how features are encoded in such
pre-trained representations. We find that learned representations in a given
layer exhibit a degree of diffuse redundancy, i.e., any randomly chosen subset
of neurons in the layer that is larger than a threshold size shares a large
degree of similarity with the full layer and is able to perform similarly as
the whole layer on a variety of downstream tasks. For example, a linear probe
trained on $20\%$ of randomly picked neurons from a ResNet50 pre-trained on
ImageNet1k achieves an accuracy within $5\%$ of a linear probe trained on the
full layer of neurons for downstream CIFAR10 classification. We conduct
experiments on different neural architectures (including CNNs and Transformers)
pre-trained on both ImageNet1k and ImageNet21k and evaluate a variety of
downstream tasks taken from the VTAB benchmark. We find that the loss &amp; dataset
used during pre-training largely govern the degree of diffuse redundancy and
the "critical mass" of neurons needed often depends on the downstream task,
suggesting that there is a task-inherent redundancy-performance Pareto
frontier. Our findings shed light on the nature of representations learned by
pre-trained deep neural networks and suggest that entire layers might not be
necessary to perform many downstream tasks. We investigate the potential for
exploiting this redundancy to achieve efficient generalization for downstream
tasks and also draw caution to certain possible unintended consequences.
</p></li>
</ul>

<h3>Title: Toward Understanding Why Adam Converges Faster Than SGD for Transformers. (arXiv:2306.00204v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.00204">http://arxiv.org/abs/2306.00204</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.00204] Toward Understanding Why Adam Converges Faster Than SGD for Transformers](http://arxiv.org/abs/2306.00204) #transformer</code></li>
<li>Summary: <p>While stochastic gradient descent (SGD) is still the most popular
optimization algorithm in deep learning, adaptive algorithms such as Adam have
established empirical advantages over SGD in some deep learning applications
such as training transformers. However, it remains a question that why Adam
converges significantly faster than SGD in these scenarios. In this paper, we
propose one explanation of why Adam converges faster than SGD using a new
concept directional sharpness. We argue that the performance of optimization
algorithms is closely related to the directional sharpness of the update steps,
and show SGD has much worse directional sharpness compared to adaptive
algorithms. We further observe that only a small fraction of the coordinates
causes the bad sharpness and slow convergence of SGD, and propose to use
coordinate-wise clipping as a solution to SGD and other optimization
algorithms. We demonstrate the effect of coordinate-wise clipping on sharpness
reduction and speeding up the convergence of optimization algorithms under
various settings. We show that coordinate-wise clipping improves the local loss
reduction when only a small fraction of the coordinates has bad sharpness. We
conclude that the sharpness reduction effect of adaptive coordinate-wise
scaling is the reason for Adam's success in practice and suggest the use of
coordinate-wise clipping as a universal technique to speed up deep learning
optimization.
</p></li>
</ul>

<h3>Title: Transformers learn to implement preconditioned gradient descent for in-context learning. (arXiv:2306.00297v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.00297">http://arxiv.org/abs/2306.00297</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.00297] Transformers learn to implement preconditioned gradient descent for in-context learning](http://arxiv.org/abs/2306.00297) #transformer</code></li>
<li>Summary: <p>Motivated by the striking ability of transformers for in-context learning,
several works demonstrate that transformers can implement algorithms like
gradient descent. By a careful construction of weights, these works show that
multiple layers of transformers are expressive enough to simulate gradient
descent iterations. Going beyond the question of expressivity, we ask: Can
transformers learn to implement such algorithms by training over random problem
instances? To our knowledge, we make the first theoretical progress toward this
question via analysis of the loss landscape for linear transformers trained
over random instances of linear regression. For a single attention layer, we
prove the global minimum of the training objective implements a single
iteration of preconditioned gradient descent. Notably, the preconditioning
matrix not only adapts to the input distribution but also to the variance
induced by data inadequacy. For a transformer with $k$ attention layers, we
prove certain critical points of the training objective implement $k$
iterations of preconditioned gradient descent. Our results call for future
theoretical studies on learning algorithms by training transformers.
</p></li>
</ul>

<h3>Title: Coneheads: Hierarchy Aware Attention. (arXiv:2306.00392v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.00392">http://arxiv.org/abs/2306.00392</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.00392] Coneheads: Hierarchy Aware Attention](http://arxiv.org/abs/2306.00392) #transformer</code></li>
<li>Summary: <p>Attention networks such as transformers have achieved state-of-the-art
performance in many domains. These networks rely heavily on the dot product
attention operator, which computes the similarity between two points by taking
their inner product. However, the inner product does not explicitly model the
complex structural properties of real world datasets, such as hierarchies
between data points. To remedy this, we introduce cone attention, a drop-in
replacement for dot product attention based on hyperbolic entailment cones.
Cone attention associates two points by the depth of their lowest common
ancestor in a hierarchy defined by hyperbolic cones, which intuitively measures
the divergence of two points and gives a hierarchy aware similarity score. We
test cone attention on a wide variety of models and tasks and show that it
improves task-level performance over dot product attention and other baselines,
and is able to match dot-product attention with significantly fewer parameters.
Our results suggest that cone attention is an effective way to capture
hierarchical relationships when calculating attention.
</p></li>
</ul>

<h2>generative</h2>
<h3>Title: Automated Annotation with Generative AI Requires Validation. (arXiv:2306.00176v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.00176">http://arxiv.org/abs/2306.00176</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.00176] Automated Annotation with Generative AI Requires Validation](http://arxiv.org/abs/2306.00176) #generative</code></li>
<li>Summary: <p>Generative large language models (LLMs) can be a powerful tool for augmenting
text annotation procedures, but their performance varies across annotation
tasks due to prompt quality, text data idiosyncrasies, and conceptual
difficulty. Because these challenges will persist even as LLM technology
improves, we argue that any automated annotation process using an LLM must
validate the LLM's performance against labels generated by humans. To this end,
we outline a workflow to harness the annotation potential of LLMs in a
principled, efficient way. Using GPT-4, we validate this approach by
replicating 27 annotation tasks across 11 datasets from recent social science
articles in high-impact journals. We find that LLM performance for text
annotation is promising but highly contingent on both the dataset and the type
of annotation task, which reinforces the necessity to validate on a
task-by-task basis. We make available easy-to-use software designed to
implement our workflow and streamline the deployment of LLMs for automated
annotation.
</p></li>
</ul>

<h3>Title: Uncertainty-Aware Unlikelihood Learning Improves Generative Aspect Sentiment Quad Prediction. (arXiv:2306.00418v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.00418">http://arxiv.org/abs/2306.00418</a></li>
<li>Code URL: <a href="https://github.com/byinhao/uaul">https://github.com/byinhao/uaul</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2306.00418] Uncertainty-Aware Unlikelihood Learning Improves Generative Aspect Sentiment Quad Prediction](http://arxiv.org/abs/2306.00418) #generative</code></li>
<li>Summary: <p>Recently, aspect sentiment quad prediction has received widespread attention
in the field of aspect-based sentiment analysis. Existing studies extract
quadruplets via pre-trained generative language models to paraphrase the
original sentence into a templated target sequence. However, previous works
only focus on what to generate but ignore what not to generate. We argue that
considering the negative samples also leads to potential benefits. In this
work, we propose a template-agnostic method to control the token-level
generation, which boosts original learning and reduces mistakes simultaneously.
Specifically, we introduce Monte Carlo dropout to understand the built-in
uncertainty of pre-trained language models, acquiring the noises and errors. We
further propose marginalized unlikelihood learning to suppress the
uncertainty-aware mistake tokens. Finally, we introduce minimization entropy to
balance the effects of marginalized unlikelihood learning. Extensive
experiments on four public datasets demonstrate the effectiveness of our
approach on various generation templates1.
</p></li>
</ul>

<h3>Title: Transfer Learning for Underrepresented Music Generation. (arXiv:2306.00281v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.00281">http://arxiv.org/abs/2306.00281</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.00281] Transfer Learning for Underrepresented Music Generation](http://arxiv.org/abs/2306.00281) #generative</code></li>
<li>Summary: <p>This paper investigates a combinational creativity approach to transfer
learning to improve the performance of deep neural network-based models for
music generation on out-of-distribution (OOD) genres. We identify Iranian folk
music as an example of such an OOD genre for MusicVAE, a large generative music
model. We find that a combinational creativity transfer learning approach can
efficiently adapt MusicVAE to an Iranian folk music dataset, indicating
potential for generating underrepresented music genres in the future.
</p></li>
</ul>

<h2>large language model</h2>
<h3>Title: Towards Explainable and Language-Agnostic LLMs: Symbolic Reverse Engineering of Language at Scale. (arXiv:2306.00017v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.00017">http://arxiv.org/abs/2306.00017</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.00017] Towards Explainable and Language-Agnostic LLMs: Symbolic Reverse Engineering of Language at Scale](http://arxiv.org/abs/2306.00017) #large language model</code></li>
<li>Summary: <p>Large language models (LLMs) have achieved a milestone that undenia-bly
changed many held beliefs in artificial intelligence (AI). However, there
remains many limitations of these LLMs when it comes to true language
understanding, limitations that are a byproduct of the under-lying architecture
of deep neural networks. Moreover, and due to their subsymbolic nature,
whatever knowledge these models acquire about how language works will always be
buried in billions of microfeatures (weights), none of which is meaningful on
its own, making such models hopelessly unexplainable. To address these
limitations, we suggest com-bining the strength of symbolic representations
with what we believe to be the key to the success of LLMs, namely a successful
bottom-up re-verse engineering of language at scale. As such we argue for a
bottom-up reverse engineering of language in a symbolic setting. Hints on what
this project amounts to have been suggested by several authors, and we discuss
in some detail here how this project could be accomplished.
</p></li>
</ul>

<h3>Title: GPT4GEO: How a Language Model Sees the World's Geography. (arXiv:2306.00020v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.00020">http://arxiv.org/abs/2306.00020</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.00020] GPT4GEO: How a Language Model Sees the World's Geography](http://arxiv.org/abs/2306.00020) #large language model</code></li>
<li>Summary: <p>Large language models (LLMs) have shown remarkable capabilities across a
broad range of tasks involving question answering and the generation of
coherent text and code. Comprehensively understanding the strengths and
weaknesses of LLMs is beneficial for safety, downstream applications and
improving performance. In this work, we investigate the degree to which GPT-4
has acquired factual geographic knowledge and is capable of using this
knowledge for interpretative reasoning, which is especially important for
applications that involve geographic data, such as geospatial analysis, supply
chain management, and disaster response. To this end, we design and conduct a
series of diverse experiments, starting from factual tasks such as location,
distance and elevation estimation to more complex questions such as generating
country outlines and travel networks, route finding under constraints and
supply chain analysis. We provide a broad characterisation of what GPT-4
(without plugins or Internet access) knows about the world, highlighting both
potentially surprising capabilities but also limitations.
</p></li>
</ul>

<h3>Title: An Invariant Learning Characterization of Controlled Text Generation. (arXiv:2306.00198v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.00198">http://arxiv.org/abs/2306.00198</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.00198] An Invariant Learning Characterization of Controlled Text Generation](http://arxiv.org/abs/2306.00198) #large language model</code></li>
<li>Summary: <p>Controlled generation refers to the problem of creating text that contains
stylistic or semantic attributes of interest. Many approaches reduce this
problem to training a predictor of the desired attribute. For example,
researchers hoping to deploy a large language model to produce non-toxic
content may use a toxicity classifier to filter generated text. In practice,
the generated text to classify, which is determined by user prompts, may come
from a wide range of distributions. In this paper, we show that the performance
of controlled generation may be poor if the distributions of text in response
to user prompts differ from the distribution the predictor was trained on. To
address this problem, we cast controlled generation under distribution shift as
an invariant learning problem: the most effective predictor should be invariant
across multiple text environments. We then discuss a natural solution that
arises from this characterization and propose heuristics for selecting natural
environments. We study this characterization and the proposed method
empirically using both synthetic and real data. Experiments demonstrate both
the challenge of distribution shift in controlled generation and the potential
of invariance methods in this setting.
</p></li>
</ul>

<h3>Title: CapText: Large Language Model-based Caption Generation From Image Context and Description. (arXiv:2306.00301v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.00301">http://arxiv.org/abs/2306.00301</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.00301] CapText: Large Language Model-based Caption Generation From Image Context and Description](http://arxiv.org/abs/2306.00301) #large language model</code></li>
<li>Summary: <p>While deep-learning models have been shown to perform well on image-to-text
datasets, it is difficult to use them in practice for captioning images. This
is because \textit{captions} traditionally tend to be context-dependent and
offer complementary information about an image, while models tend to produce
\textit{descriptions} that describe the visual features of the image. Prior
research in caption generation has explored the use of models that generate
captions when provided with the images alongside their respective descriptions
or contexts. We propose and evaluate a new approach, which leverages existing
large language models to generate captions from textual descriptions and
context alone, without ever processing the image directly. We demonstrate that
after fine-tuning, our approach outperforms current state-of-the-art image-text
alignment models like OSCAR-VinVL on this task on the CIDEr metric.
</p></li>
</ul>

<h3>Title: FlexRound: Learnable Rounding based on Element-wise Division for Post-Training Quantization. (arXiv:2306.00317v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.00317">http://arxiv.org/abs/2306.00317</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.00317] FlexRound: Learnable Rounding based on Element-wise Division for Post-Training Quantization](http://arxiv.org/abs/2306.00317) #large language model</code></li>
<li>Summary: <p>Post-training quantization (PTQ) has been gaining popularity for the
deployment of deep neural networks on resource-limited devices since unlike
quantization-aware training, neither a full training dataset nor end-to-end
training is required at all. As PTQ schemes based on reconstructing each layer
or block output turn out to be effective to enhance quantized model
performance, recent works have developed algorithms to devise and learn a new
weight-rounding scheme so as to better reconstruct each layer or block output.
In this work, we propose a simple yet effective new weight-rounding mechanism
for PTQ, coined FlexRound, based on element-wise division instead of typical
element-wise addition such that FlexRound enables jointly learning a common
quantization grid size as well as a different scale for each pre-trained
weight. Thanks to the reciprocal rule of derivatives induced by element-wise
division, FlexRound is inherently able to exploit pre-trained weights when
updating their corresponding scales, and thus, flexibly quantize pre-trained
weights depending on their magnitudes. We empirically validate the efficacy of
FlexRound on a wide range of models and tasks. To the best of our knowledge,
our work is the first to carry out comprehensive experiments on not only image
classification and natural language understanding but also natural language
generation, assuming a per-tensor uniform PTQ setting. Moreover, we
demonstrate, for the first time, that large language models can be efficiently
quantized, with only a negligible impact on performance compared to
half-precision baselines, achieved by reconstructing the output in a
block-by-block manner.
</p></li>
</ul>

<h2>segmentation</h2>
<h3>Title: SSL-CPCD: Self-supervised learning with composite pretext-class discrimination for improved generalisability in endoscopic image analysis. (arXiv:2306.00197v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.00197">http://arxiv.org/abs/2306.00197</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.00197] SSL-CPCD: Self-supervised learning with composite pretext-class discrimination for improved generalisability in endoscopic image analysis](http://arxiv.org/abs/2306.00197) #segmentation</code></li>
<li>Summary: <p>Data-driven methods have shown tremendous progress in medical image analysis.
In this context, deep learning-based supervised methods are widely popular.
However, they require a large amount of training data and face issues in
generalisability to unseen datasets that hinder clinical translation.
Endoscopic imaging data incorporates large inter- and intra-patient variability
that makes these models more challenging to learn representative features for
downstream tasks. Thus, despite the publicly available datasets and datasets
that can be generated within hospitals, most supervised models still
underperform. While self-supervised learning has addressed this problem to some
extent in natural scene data, there is a considerable performance gap in the
medical image domain. In this paper, we propose to explore patch-level
instance-group discrimination and penalisation of inter-class variation using
additive angular margin within the cosine similarity metrics. Our novel
approach enables models to learn to cluster similar representative patches,
thereby improving their ability to provide better separation between different
classes. Our results demonstrate significant improvement on all metrics over
the state-of-the-art (SOTA) methods on the test set from the same and diverse
datasets. We evaluated our approach for classification, detection, and
segmentation. SSL-CPCD achieves 79.77% on Top 1 accuracy for ulcerative colitis
classification, 88.62% on mAP for polyp detection, and 82.32% on dice
similarity coefficient for segmentation tasks are nearly over 4%, 2%, and 3%,
respectively, compared to the baseline architectures. We also demonstrate that
our method generalises better than all SOTA methods to unseen datasets,
reporting nearly 7% improvement in our generalisability assessment.
</p></li>
</ul>

<h3>Title: Exploring Open-Vocabulary Semantic Segmentation without Human Labels. (arXiv:2306.00450v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.00450">http://arxiv.org/abs/2306.00450</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.00450] Exploring Open-Vocabulary Semantic Segmentation without Human Labels](http://arxiv.org/abs/2306.00450) #segmentation</code></li>
<li>Summary: <p>Semantic segmentation is a crucial task in computer vision that involves
segmenting images into semantically meaningful regions at the pixel level.
However, existing approaches often rely on expensive human annotations as
supervision for model training, limiting their scalability to large, unlabeled
datasets. To address this challenge, we present ZeroSeg, a novel method that
leverages the existing pretrained vision-language (VL) model (e.g. CLIP) to
train open-vocabulary zero-shot semantic segmentation models. Although acquired
extensive knowledge of visual concepts, it is non-trivial to exploit knowledge
from these VL models to the task of semantic segmentation, as they are usually
trained at an image level. ZeroSeg overcomes this by distilling the visual
concepts learned by VL models into a set of segment tokens, each summarizing a
localized region of the target image. We evaluate ZeroSeg on multiple popular
segmentation benchmarks, including PASCAL VOC 2012, PASCAL Context, and COCO,
in a zero-shot manner (i.e., no training or adaption on target segmentation
datasets). Our approach achieves state-of-the-art performance when compared to
other zero-shot segmentation methods under the same training data, while also
performing competitively compared to strongly supervised methods. Finally, we
also demonstrated the effectiveness of ZeroSeg on open-vocabulary segmentation,
through both human studies and qualitative visualizations.
</p></li>
</ul>

<button id="copy">Copy All</button>
</article>
<script src="https://cdn.staticfile.org/clipboard.js/2.0.4/clipboard.min.js"></script>
<script src="../../javascript/clipboard.js"></script>
