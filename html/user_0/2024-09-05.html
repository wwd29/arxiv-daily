<link rel="stylesheet" href="../../css/markdown.css" />
<article class="markdown-body">
<h1>2024-09-05</h1>
<h3>Title: Toward Large-scale Spiking Neural Networks: A Comprehensive Survey and Future Directions</h3>
<ul>
<li><strong>Authors: </strong>Yangfan Hu, Qian Zheng, Guoqi Li, Huajin Tang, Gang Pan</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2409.02111">https://arxiv.org/abs/2409.02111</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2409.02111">https://arxiv.org/pdf/2409.02111</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2409.02111]] Toward Large-scale Spiking Neural Networks: A Comprehensive Survey and Future Directions(https://arxiv.org/abs/2409.02111)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer, large language model</a></li>
<li><strong>Abstract: </strong>Deep learning has revolutionized artificial intelligence (AI), achieving remarkable progress in fields such as computer vision, speech recognition, and natural language processing. Moreover, the recent success of large language models (LLMs) has fueled a surge in research on large-scale neural networks. However, the escalating demand for computing resources and energy consumption has prompted the search for energy-efficient alternatives. Inspired by the human brain, spiking neural networks (SNNs) promise energy-efficient computation with event-driven spikes. To provide future directions toward building energy-efficient large SNN models, we present a survey of existing methods for developing deep spiking neural networks, with a focus on emerging Spiking Transformers. Our main contributions are as follows: (1) an overview of learning methods for deep spiking neural networks, categorized by ANN-to-SNN conversion and direct training with surrogate gradients; (2) an overview of network architectures for deep spiking neural networks, categorized by deep convolutional neural networks (DCNNs) and Transformer architecture; and (3) a comprehensive comparison of state-of-the-art deep SNNs with a focus on emerging Spiking Transformers. We then further discuss and outline future directions toward large-scale SNNs.</li>
</ul>

<h3>Title: Tiny-Toxic-Detector: A compact transformer-based model for toxic content detection</h3>
<ul>
<li><strong>Authors: </strong>Michiel Kamphuis</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2409.02114">https://arxiv.org/abs/2409.02114</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2409.02114">https://arxiv.org/pdf/2409.02114</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2409.02114]] Tiny-Toxic-Detector: A compact transformer-based model for toxic content detection(https://arxiv.org/abs/2409.02114)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>This paper presents Tiny-toxic-detector, a compact transformer-based model designed for toxic content detection. Despite having only 2.1 million parameters, Tiny-toxic-detector achieves competitive performance on benchmark datasets, with 90.97% accuracy on ToxiGen and 86.98% accuracy on the Jigsaw dataset, rivaling models over 50 times its size. This efficiency enables deployment in resource-constrained environments, addressing the need for effective content moderation tools that balance performance with computational efficiency. The model architecture features 4 transformer encoder layers, each with 2 attention heads, an embedding dimension of 64, and a feedforward dimension of 128. Trained on both public and private datasets, Tiny-toxic-detector demonstrates the potential of efficient, task-specific models for addressing online toxicity. The paper covers the model architecture, training process, performance benchmarks, and limitations, underscoring its suitability for applications such as social media monitoring and content moderation. By achieving results comparable to much larger models while significantly reducing computational demands, Tiny-toxic-detector represents progress toward more sustainable and scalable AI-driven content moderation solutions.</li>
</ul>

<h3>Title: TSO: Self-Training with Scaled Preference Optimization</h3>
<ul>
<li><strong>Authors: </strong>Kaihui Chen, Hao Yi, Qingyang Li, Tianyu Qi, Yulan Hu, Fuzheng Zhang, Yong Liu</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2409.02118">https://arxiv.org/abs/2409.02118</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2409.02118">https://arxiv.org/pdf/2409.02118</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2409.02118]] TSO: Self-Training with Scaled Preference Optimization(https://arxiv.org/abs/2409.02118)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Enhancing the conformity of large language models (LLMs) to human preferences remains an ongoing research challenge. Recently, offline approaches such as Direct Preference Optimization (DPO) have gained prominence as attractive options due to offering effective improvement in simple, efficient, and stable without interactions with reward models. However, these offline preference optimization methods highly rely on the quality of pairwise preference samples. Meanwhile, numerous iterative methods require additional training of reward models to select positive and negative samples from the model's own generated responses for preference learning. Furthermore, as LLMs' capabilities advance, it is quite challenging to continuously construct high-quality positive and negative preference instances from the model's outputs due to the lack of diversity. To tackle these challenges, we propose TSO, or Self-Training with Scaled Preference Optimization, a framework for preference optimization that conducts self-training preference learning without training an additional reward model. TSO enhances the diversity of responses by constructing a model matrix and incorporating human preference responses. Furthermore, TSO introduces corrections for model preference errors through human and AI feedback. Finally, TSO adopts iterative and dual clip reward strategies to update the reference model and its responses, adaptively adjusting preference data and balancing the optimization process. Experimental results demonstrate that TSO outperforms existing mainstream methods on various alignment evaluation benchmarks, providing practical insight into preference data construction and model training strategies in the alignment domain.</li>
</ul>

<h3>Title: CoRA: Optimizing Low-Rank Adaptation with Common Subspace of Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Xiaojun Xiao, Sen Shen, Qiming Bao, Hongfei Rong, Kairui Liu, Zhongsheng Wang, Jiamou Liu</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2409.02119">https://arxiv.org/abs/2409.02119</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2409.02119">https://arxiv.org/pdf/2409.02119</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2409.02119]] CoRA: Optimizing Low-Rank Adaptation with Common Subspace of Large Language Models(https://arxiv.org/abs/2409.02119)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>In fine-tuning large language models (LLMs), conserving computational resources while maintaining effectiveness and improving outcomes within the same computational constraints is crucial. The Low-Rank Adaptation (LoRA) strategy balances efficiency and performance in fine-tuning large models by reducing the number of trainable parameters and computational costs. However, current advancements in LoRA might be focused on its fine-tuning methodologies, with not as much exploration as might be expected into further compression of LoRA. Since most of LoRA's parameters might still be superfluous, this may lead to unnecessary wastage of computational resources. In this paper, we propose \textbf{CoRA}: leveraging shared knowledge to optimize LoRA training by substituting its matrix $B$ with a common subspace from large models. Our two-fold method includes (1) Freezing the substitute matrix $B$ to halve parameters while training matrix $A$ for specific tasks and (2) Using the substitute matrix $B$ as an enhanced initial state for the original matrix $B$, achieving improved results with the same parameters. Our experiments show that the first approach achieves the same efficacy as the original LoRA fine-tuning while being more efficient than halving parameters. At the same time, the second approach has some improvements compared to LoRA's original fine-tuning performance. They generally attest to the effectiveness of our work.</li>
</ul>

<h3>Title: Deep Knowledge-Infusion For Explainable Depression Detection</h3>
<ul>
<li><strong>Authors: </strong>Sumit Dalal, Sarika Jain, Mayank Dave</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2409.02122">https://arxiv.org/abs/2409.02122</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2409.02122">https://arxiv.org/pdf/2409.02122</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2409.02122]] Deep Knowledge-Infusion For Explainable Depression Detection(https://arxiv.org/abs/2409.02122)</code><input type="text"></li>
<li><strong>Keywords: </strong>explainability, transformer</a></li>
<li><strong>Abstract: </strong>Discovering individuals depression on social media has become increasingly important. Researchers employed ML/DL or lexicon-based methods for automated depression detection. Lexicon based methods, explainable and easy to implement, match words from user posts in a depression dictionary without considering contexts. While the DL models can leverage contextual information, their black-box nature limits their adoption in the domain. Though surrogate models like LIME and SHAP can produce explanations for DL models, the explanations are suitable for the developer and of limited use to the end user. We propose a Knolwedge-infused Neural Network (KiNN) incorporating domain-specific knowledge from DepressionFeature ontology (DFO) in a neural network to endow the model with user-level explainability regarding concepts and processes the clinician understands. Further, commonsense knowledge from the Commonsense Transformer (COMET) trained on ATOMIC is also infused to consider the generic emotional aspects of user posts in depression detection. The model is evaluated on three expertly curated datasets related to depression. We observed the model to have a statistically significant (p<0.1) boost in performance over the best domain-specific model, MentalBERT, across CLEF e-Risk (25% MCC increase, 12% F1 increase). A similar trend is observed across the PRIMATE dataset, where the proposed model performed better than MentalBERT (2.5% MCC increase, 19% F1 increase). The observations confirm the generated explanations to be informative for MHPs compared to post hoc model explanations. Results demonstrated that the user-level explainability of KiNN also surpasses the performance of baseline models and can provide explanations where other baselines fall short. Infusing the domain and commonsense knowledge in KiNN enhances the ability of models like GPT-3.5 to generate application-relevant explanations.</li>
</ul>

<h3>Title: TrajWeaver: Trajectory Recovery with State Propagation Diffusion Model</h3>
<ul>
<li><strong>Authors: </strong>Jinming Wang, Hai Wang, Hongkai Wen, Geyong Min, Man Luo</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2409.02124">https://arxiv.org/abs/2409.02124</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2409.02124">https://arxiv.org/pdf/2409.02124</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2409.02124]] TrajWeaver: Trajectory Recovery with State Propagation Diffusion Model(https://arxiv.org/abs/2409.02124)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>With the proliferation of location-aware devices, large amount of trajectories have been generated when agents such as people, vehicles and goods flow around the urban environment. These raw trajectories, typically collected from various sources such as GPS in cars, personal mobile devices, and public transport, are often sparse and fragmented due to limited sampling rates, infrastructure coverage and data loss. In this context, trajectory recovery aims to reconstruct such sparse raw trajectories into their dense and continuous counterparts, so that fine-grained movement of agents across space and time can be captured faithfully. Existing trajectory recovery approaches typically rely on the prior knowledge of travel mode or motion patterns, and often fail in densely populated urban areas where accurate maps are absent. In this paper, we present a new recovery framework called TrajWeaver based on probabilistic diffusion models, which is able to recover dense and refined trajectories from the sparse raw ones, conditioned on various auxiliary features such as Areas of Interest along the way, user identity and waybill information. The core of TrajWeaver is a novel State Propagation Diffusion Model (SPDM), which introduces a new state propagation mechanism on top of the standard diffusion models, so that knowledge computed in earlier diffusion steps can be reused later, improving the recovery performance while reducing the number of steps needed. Extensive experiments show that the proposed TrajWeaver can recover from raw trajectories of various lengths, sparsity levels and heterogeneous travel modes, and outperform the state-of-the-art baselines significantly in recovery accuracy. Our code is available at: https://anonymous.4open.science/r/TrajWeaver/</li>
</ul>

<h3>Title: Enabling Trustworthy Federated Learning in Industrial IoT: Bridging the Gap Between Interpretability and Robustness</h3>
<ul>
<li><strong>Authors: </strong>Senthil Kumar Jagatheesaperumal, Mohamed Rahouti, Ali Alfatemi, Nasir Ghani, Vu Khanh Quy, Abdellah Chehri</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2409.02127">https://arxiv.org/abs/2409.02127</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2409.02127">https://arxiv.org/pdf/2409.02127</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2409.02127]] Enabling Trustworthy Federated Learning in Industrial IoT: Bridging the Gap Between Interpretability and Robustness(https://arxiv.org/abs/2409.02127)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, privacy, robust, federate, interpretability</a></li>
<li><strong>Abstract: </strong>Federated Learning (FL) represents a paradigm shift in machine learning, allowing collaborative model training while keeping data localized. This approach is particularly pertinent in the Industrial Internet of Things (IIoT) context, where data privacy, security, and efficient utilization of distributed resources are paramount. The essence of FL in IIoT lies in its ability to learn from diverse, distributed data sources without requiring central data storage, thus enhancing privacy and reducing communication overheads. However, despite its potential, several challenges impede the widespread adoption of FL in IIoT, notably in ensuring interpretability and robustness. This article focuses on enabling trustworthy FL in IIoT by bridging the gap between interpretability and robustness, which is crucial for enhancing trust, improving decision-making, and ensuring compliance with regulations. Moreover, the design strategies summarized in this article ensure that FL systems in IIoT are transparent and reliable, vital in industrial settings where decisions have significant safety and economic impacts. The case studies in the IIoT environment driven by trustworthy FL models are provided, wherein the practical insights of trustworthy communications between IIoT systems and their end users are highlighted.</li>
</ul>

<h3>Title: Large Language Models versus Classical Machine Learning: Performance in COVID-19 Mortality Prediction Using High-Dimensional Tabular Data</h3>
<ul>
<li><strong>Authors: </strong>Mohammadreza Ghaffarzadeh-Esfahani, Mahdi Ghaffarzadeh-Esfahani, Arian Salahi-Niri, Hossein Toreyhi, Zahra Atf, Amirali Mohsenzadeh-Kermani, Mahshad Sarikhani, Zohreh Tajabadi, Fatemeh Shojaeian, Mohammad Hassan Bagheri, Aydin Feyzi, Mohammadamin Tarighatpayma, Narges Gazmeh, Fateme Heydari, Hossein Afshar, Amirreza Allahgholipour, Farid Alimardani, Ameneh Salehi, Naghmeh Asadimanesh, Mohammad Amin Khalafi, Hadis Shabanipour, Ali Moradi, Sajjad Hossein Zadeh, Omid Yazdani, Romina Esbati, Moozhan Maleki, Danial Samiei Nasr, Amirali Soheili, Hossein Majlesi, Saba Shahsavan, Alireza Soheilipour, Nooshin Goudarzi, Erfan Taherifard, Hamidreza Hatamabadi, Jamil S Samaan, Thomas Savage, Ankit Sakhuja, Ali Soroush, Girish Nadkarni, Ilad Alavi Darazam, Mohamad Amin Pourhoseingholi, Seyed Amir Ahmad Safavi-Naini</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2409.02136">https://arxiv.org/abs/2409.02136</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2409.02136">https://arxiv.org/pdf/2409.02136</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2409.02136]] Large Language Models versus Classical Machine Learning: Performance in COVID-19 Mortality Prediction Using High-Dimensional Tabular Data(https://arxiv.org/abs/2409.02136)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Background: This study aimed to evaluate and compare the performance of classical machine learning models (CMLs) and large language models (LLMs) in predicting mortality associated with COVID-19 by utilizing a high-dimensional tabular dataset. Materials and Methods: We analyzed data from 9,134 COVID-19 patients collected across four hospitals. Seven CML models, including XGBoost and random forest (RF), were trained and evaluated. The structured data was converted into text for zero-shot classification by eight LLMs, including GPT-4 and Mistral-7b. Additionally, Mistral-7b was fine-tuned using the QLoRA approach to enhance its predictive capabilities. Results: Among the CML models, XGBoost and RF achieved the highest accuracy, with F1 scores of 0.87 for internal validation and 0.83 for external validation. In the LLM category, GPT-4 was the top performer with an F1 score of 0.43. Fine-tuning Mistral-7b significantly improved its recall from 1% to 79%, resulting in an F1 score of 0.74, which was stable during external validation. Conclusion: While LLMs show moderate performance in zero-shot classification, fine-tuning can significantly enhance their effectiveness, potentially aligning them closer to CML models. However, CMLs still outperform LLMs in high-dimensional tabular data tasks.</li>
</ul>

<h3>Title: A Financial Time Series Denoiser Based on Diffusion Model</h3>
<ul>
<li><strong>Authors: </strong>Zhuohan Wang, Carmine Ventre</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, q-fin.CP, q-fin.TR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2409.02138">https://arxiv.org/abs/2409.02138</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2409.02138">https://arxiv.org/pdf/2409.02138</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2409.02138]] A Financial Time Series Denoiser Based on Diffusion Model(https://arxiv.org/abs/2409.02138)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, generative</a></li>
<li><strong>Abstract: </strong>Financial time series often exhibit low signal-to-noise ratio, posing significant challenges for accurate data interpretation and prediction and ultimately decision making. Generative models have gained attention as powerful tools for simulating and predicting intricate data patterns, with the diffusion model emerging as a particularly effective method. This paper introduces a novel approach utilizing the diffusion model as a denoiser for financial time series in order to improve data predictability and trading performance. By leveraging the forward and reverse processes of the conditional diffusion model to add and remove noise progressively, we reconstruct original data from noisy inputs. Our extensive experiments demonstrate that diffusion model-based denoised time series significantly enhance the performance on downstream future return classification tasks. Moreover, trading signals derived from the denoised data yield more profitable trades with fewer transactions, thereby minimizing transaction costs and increasing overall trading efficiency. Finally, we show that by using classifiers trained on denoised time series, we can recognize the noising state of the market and obtain excess return.</li>
</ul>

<h3>Title: The Role of Transformer Models in Advancing Blockchain Technology: A Systematic Review</h3>
<ul>
<li><strong>Authors: </strong>Tianxu Liu, Yanbin Wang, Jianguo Sun, Ye Tian, Yanyu Huang, Tao Xue, Peiyue Li, Yiwei Liu</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2409.02139">https://arxiv.org/abs/2409.02139</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2409.02139">https://arxiv.org/pdf/2409.02139</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2409.02139]] The Role of Transformer Models in Advancing Blockchain Technology: A Systematic Review(https://arxiv.org/abs/2409.02139)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, privacy, transformer</a></li>
<li><strong>Abstract: </strong>As blockchain technology rapidly evolves, the demand for enhanced efficiency, security, and scalability grows.Transformer models, as powerful deep learning architectures,have shown unprecedented potential in addressing various blockchain challenges. However, a systematic review of Transformer applications in blockchain is lacking. This paper aims to fill this research gap by surveying over 200 relevant papers, comprehensively reviewing practical cases and research progress of Transformers in blockchain applications. Our survey covers key areas including anomaly detection, smart contract security analysis, cryptocurrency prediction and trend analysis, and code summary generation. To clearly articulate the advancements of Transformers across various blockchain domains, we adopt a domain-oriented classification system, organizing and introducing representative methods based on major challenges in current blockchain research. For each research domain,we first introduce its background and objectives, then review previous representative methods and analyze their limitations,and finally introduce the advancements brought by Transformer models. Furthermore, we explore the challenges of utilizing Transformer, such as data privacy, model complexity, and real-time processing requirements. Finally, this article proposes future research directions, emphasizing the importance of exploring the Transformer architecture in depth to adapt it to specific blockchain applications, and discusses its potential role in promoting the development of blockchain technology. This review aims to provide new perspectives and a research foundation for the integrated development of blockchain technology and machine learning, supporting further innovation and application expansion of blockchain technology.</li>
</ul>

<h3>Title: Efficient and Scalable Estimation of Tool Representations in Vector Space</h3>
<ul>
<li><strong>Authors: </strong>Suhong Moon, Siddharth Jha, Lutfi Eren Erdogan, Sehoon Kim, Woosang Lim, Kurt Keutzer, Amir Gholami</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2409.02141">https://arxiv.org/abs/2409.02141</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2409.02141">https://arxiv.org/pdf/2409.02141</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2409.02141]] Efficient and Scalable Estimation of Tool Representations in Vector Space(https://arxiv.org/abs/2409.02141)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Recent advancements in function calling and tool use have significantly enhanced the capabilities of large language models (LLMs) by enabling them to interact with external information sources and execute complex tasks. However, the limited context window of LLMs presents challenges when a large number of tools are available, necessitating efficient methods to manage prompt length and maintain accuracy. Existing approaches, such as fine-tuning LLMs or leveraging their reasoning capabilities, either require frequent retraining or incur significant latency overhead. A more efficient solution involves training smaller models to retrieve the most relevant tools for a given query, although this requires high quality, domain-specific data. To address those challenges, we present a novel framework for generating synthetic data for tool retrieval applications and an efficient data-driven tool retrieval strategy using small encoder models. Empowered by LLMs, we create ToolBank, a new tool retrieval dataset that reflects real human user usages. For tool retrieval methodologies, we propose novel approaches: (1) Tool2Vec: usage-driven tool embedding generation for tool retrieval, (2) ToolRefiner: a staged retrieval method that iteratively improves the quality of retrieved tools, and (3) MLC: framing tool retrieval as a multi-label classification problem. With these new methods, we achieve improvements of up to 27.28 in Recall@K on the ToolBench dataset and 30.5 in Recall@K on ToolBank. Additionally, we present further experimental results to rigorously validate our methods. Our code is available at \url{this https URL}</li>
</ul>

<h3>Title: Brain-Inspired Online Adaptation for Remote Sensing with Spiking Neural Network</h3>
<ul>
<li><strong>Authors: </strong>Dexin Duan, Peilin liu, Fei Wen</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CV, cs.NE</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2409.02146">https://arxiv.org/abs/2409.02146</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2409.02146">https://arxiv.org/pdf/2409.02146</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2409.02146]] Brain-Inspired Online Adaptation for Remote Sensing with Spiking Neural Network(https://arxiv.org/abs/2409.02146)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>On-device computing, or edge computing, is becoming increasingly important for remote sensing, particularly in applications like deep network-based perception on on-orbit satellites and unmanned aerial vehicles (UAVs). In these scenarios, two brain-like capabilities are crucial for remote sensing models: (1) high energy efficiency, allowing the model to operate on edge devices with limited computing resources, and (2) online adaptation, enabling the model to quickly adapt to environmental variations, weather changes, and sensor drift. This work addresses these needs by proposing an online adaptation framework based on spiking neural networks (SNNs) for remote sensing. Starting with a pretrained SNN model, we design an efficient, unsupervised online adaptation algorithm, which adopts an approximation of the BPTT algorithm and only involves forward-in-time computation that significantly reduces the computational complexity of SNN adaptation learning. Besides, we propose an adaptive activation scaling scheme to boost online SNN adaptation performance, particularly in low time-steps. Furthermore, for the more challenging remote sensing detection task, we propose a confidence-based instance weighting scheme, which substantially improves adaptation performance in the detection task. To our knowledge, this work is the first to address the online adaptation of SNNs. Extensive experiments on seven benchmark datasets across classification, segmentation, and detection tasks demonstrate that our proposed method significantly outperforms existing domain adaptation and domain generalization approaches under varying weather conditions. The proposed method enables energy-efficient and fast online adaptation on edge devices, and has much potential in applications such as remote perception on on-orbit satellites and UAV.</li>
</ul>

<h3>Title: Collaboratively Learning Federated Models from Noisy Decentralized Data</h3>
<ul>
<li><strong>Authors: </strong>Haoyuan Li, Mathias Funk, Nezihe Merve Gürel, Aaqib Saeed</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2409.02189">https://arxiv.org/abs/2409.02189</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2409.02189">https://arxiv.org/pdf/2409.02189</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2409.02189]] Collaboratively Learning Federated Models from Noisy Decentralized Data(https://arxiv.org/abs/2409.02189)</code><input type="text"></li>
<li><strong>Keywords: </strong>federate</a></li>
<li><strong>Abstract: </strong>Federated learning (FL) has emerged as a prominent method for collaboratively training machine learning models using local data from edge devices, all while keeping data decentralized. However, accounting for the quality of data contributed by local clients remains a critical challenge in FL, as local data are often susceptible to corruption by various forms of noise and perturbations, which compromise the aggregation process and lead to a subpar global model. In this work, we focus on addressing the problem of noisy data in the input space, an under-explored area compared to the label noise. We propose a comprehensive assessment of client input in the gradient space, inspired by the distinct disparity observed between the density of gradient norm distributions of models trained on noisy and clean input data. Based on this observation, we introduce a straightforward yet effective approach to identify clients with low-quality data at the initial stage of FL. Furthermore, we propose a noise-aware FL aggregation method, namely Federated Noise-Sifting (FedNS), which can be used as a plug-in approach in conjunction with widely used FL strategies. Our extensive evaluation on diverse benchmark datasets under different federated settings demonstrates the efficacy of FedNS. Our method effortlessly integrates with existing FL strategies, enhancing the global model's performance by up to 13.68% in IID and 15.85% in non-IID settings when learning from noisy decentralized data.</li>
</ul>

<h3>Title: A Digital signature scheme based on Module-LWE and Module-SIS</h3>
<ul>
<li><strong>Authors: </strong>Huda Naeem Hleeb Al-Jabbari, Ali Rajaei, Abbas Maarefparvar</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2409.02222">https://arxiv.org/abs/2409.02222</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2409.02222">https://arxiv.org/pdf/2409.02222</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2409.02222]] A Digital signature scheme based on Module-LWE and Module-SIS(https://arxiv.org/abs/2409.02222)</code><input type="text"></li>
<li><strong>Keywords: </strong>security</a></li>
<li><strong>Abstract: </strong>In this paper, we present an improved version of the digital signature scheme proposed by Sharafi and Daghigh based on Module-LWE and Module-SIS problems. Our proposed signature scheme has a notably higher security level and smaller decoding failure probability, than the ones in the Sharaf-Daghigh scheme, at the expense of enlarging the module of the underlying basic ring.</li>
</ul>

<h3>Title: Unforgettable Generalization in Language Models</h3>
<ul>
<li><strong>Authors: </strong>Eric Zhang, Leshem Chosen, Jacob Andreas</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2409.02228">https://arxiv.org/abs/2409.02228</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2409.02228">https://arxiv.org/pdf/2409.02228</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2409.02228]] Unforgettable Generalization in Language Models(https://arxiv.org/abs/2409.02228)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, transformer</a></li>
<li><strong>Abstract: </strong>When language models (LMs) are trained to forget (or "unlearn'') a skill, how precisely does their behavior change? We study the behavior of transformer LMs in which tasks have been forgotten via fine-tuning on randomized labels. Such LMs learn to generate near-random predictions for individual examples in the "training'' set used for forgetting. Across tasks, however, LMs exhibit extreme variability in whether LM predictions change on examples outside the training set. In some tasks (like entailment classification), forgetting generalizes robustly, and causes models to produce uninformative predictions on new task instances; in other tasks (like physical commonsense reasoning and scientific question answering) forgetting affects only the training examples, and models continue to perform the "forgotten'' task accurately even for examples very similar to those that appeared in the training set. Dataset difficulty is not predictive of whether a behavior can be forgotten; instead, generalization in forgetting is (weakly) predicted by the confidence of LMs' initial task predictions and the variability of LM representations of training data, with low confidence and low variability both associated with greater generalization. Perhaps most surprisingly, random-label forgetting appears to be somewhat insensitive to the contents of the training set: for example, models trained on science questions with random labels continue to answer other science questions accurately, but begin to produce random labels on entailment classification tasks. Finally, we show that even generalizable forgetting is shallow: linear probes trained on LMs' representations can still perform tasks reliably after forgetting. Our results highlight the difficulty and unpredictability of performing targeted skill removal from models via fine-tuning.</li>
</ul>

<h3>Title: NoiseAttack: An Evasive Sample-Specific Multi-Targeted Backdoor Attack Through White Gaussian Noise</h3>
<ul>
<li><strong>Authors: </strong>Abdullah Arafat Miah, Kaan Icer, Resit Sendag, Yu Bi</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI, cs.CR, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2409.02251">https://arxiv.org/abs/2409.02251</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2409.02251">https://arxiv.org/pdf/2409.02251</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2409.02251]] NoiseAttack: An Evasive Sample-Specific Multi-Targeted Backdoor Attack Through White Gaussian Noise(https://arxiv.org/abs/2409.02251)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack</a></li>
<li><strong>Abstract: </strong>Backdoor attacks pose a significant threat when using third-party data for deep learning development. In these attacks, data can be manipulated to cause a trained model to behave improperly when a specific trigger pattern is applied, providing the adversary with unauthorized advantages. While most existing works focus on designing trigger patterns in both visible and invisible to poison the victim class, they typically result in a single targeted class upon the success of the backdoor attack, meaning that the victim class can only be converted to another class based on the adversary predefined value. In this paper, we address this issue by introducing a novel sample-specific multi-targeted backdoor attack, namely NoiseAttack. Specifically, we adopt White Gaussian Noise (WGN) with various Power Spectral Densities (PSD) as our underlying triggers, coupled with a unique training strategy to execute the backdoor attack. This work is the first of its kind to launch a vision backdoor attack with the intent to generate multiple targeted classes with minimal input configuration. Furthermore, our extensive experimental results demonstrate that NoiseAttack can achieve a high attack success rate against popular network architectures and datasets, as well as bypass state-of-the-art backdoor detection methods. Our source code and experiments are available at this https URL.</li>
</ul>

<h3>Title: MMLU-Pro+: Evaluating Higher-Order Reasoning and Shortcut Learning in LLMs</h3>
<ul>
<li><strong>Authors: </strong>Saeid Asgari Taghanaki, Aliasgahr Khani, Amir Khasahmadi</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2409.02257">https://arxiv.org/abs/2409.02257</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2409.02257">https://arxiv.org/pdf/2409.02257</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2409.02257]] MMLU-Pro+: Evaluating Higher-Order Reasoning and Shortcut Learning in LLMs(https://arxiv.org/abs/2409.02257)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Existing benchmarks for large language models (LLMs) increasingly struggle to differentiate between top-performing models, underscoring the need for more challenging evaluation frameworks. We introduce MMLU-Pro+, an enhanced benchmark building upon MMLU-Pro to assess shortcut learning and higher-order reasoning in LLMs. By incorporating questions with multiple correct answers across diverse domains, MMLU-Pro+ tests LLMs' ability to engage in complex reasoning and resist simplistic problem-solving strategies. Our results show that MMLU-Pro+ maintains MMLU-Pro's difficulty while providing a more rigorous test of model discrimination, particularly in multi-correct answer scenarios. We introduce novel metrics like shortcut selection ratio and correct pair identification ratio, offering deeper insights into model behavior and anchoring bias. Evaluations of five state-of-the-art LLMs reveal significant performance gaps, highlighting variations in reasoning abilities and bias susceptibility. We release the dataset and evaluation codes at \url{this https URL}.</li>
</ul>

<h3>Title: K-Origins: Better Colour Quantification for Neural Networks</h3>
<ul>
<li><strong>Authors: </strong>Lewis Mason, Mark Martinez</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2409.02281">https://arxiv.org/abs/2409.02281</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2409.02281">https://arxiv.org/pdf/2409.02281</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2409.02281]] K-Origins: Better Colour Quantification for Neural Networks(https://arxiv.org/abs/2409.02281)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>K-Origins is a neural network layer designed to improve image-based network performances when learning colour, or intensities, is beneficial. Over 250 encoder-decoder convolutional networks are trained and tested on 16-bit synthetic data, demonstrating that K-Origins improves semantic segmentation accuracy in two scenarios: object detection with low signal-to-noise ratios, and segmenting multiple objects that are identical in shape but vary in colour. K-Origins generates output features from the input features, $\textbf{X}$, by the equation $\textbf{Y}_k = \textbf{X}-\textbf{J}\cdot w_k$ for each trainable parameter $w_k$, where $\textbf{J}$ is a matrix of ones. Additionally, networks with varying receptive fields were trained to determine optimal network depths based on the dimensions of target classes, suggesting that receptive field lengths should exceed object sizes. By ensuring a sufficient receptive field length and incorporating K-Origins, we can achieve better semantic network performance.</li>
</ul>

<h3>Title: RAMBO: Leaking Secrets from Air-Gap Computers by Spelling Covert Radio Signals from Computer RAM</h3>
<ul>
<li><strong>Authors: </strong>Mordechai Guri</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2409.02292">https://arxiv.org/abs/2409.02292</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2409.02292">https://arxiv.org/pdf/2409.02292</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2409.02292]] RAMBO: Leaking Secrets from Air-Gap Computers by Spelling Covert Radio Signals from Computer RAM(https://arxiv.org/abs/2409.02292)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, attack, biometric</a></li>
<li><strong>Abstract: </strong>Air-gapped systems are physically separated from external networks, including the Internet. This isolation is achieved by keeping the air-gap computers disconnected from wired or wireless networks, preventing direct or remote communication with other devices or networks. Air-gap measures may be used in sensitive environments where security and isolation are critical to prevent private and confidential information leakage. In this paper, we present an attack allowing adversaries to leak information from air-gapped computers. We show that malware on a compromised computer can generate radio signals from memory buses (RAM). Using software-generated radio signals, malware can encode sensitive information such as files, images, keylogging, biometric information, and encryption keys. With software-defined radio (SDR) hardware, and a simple off-the-shelf antenna, an attacker can intercept transmitted raw radio signals from a distance. The signals can then be decoded and translated back into binary information. We discuss the design and implementation and present related work and evaluation results. This paper presents fast modification methods to leak data from air-gapped computers at 1000 bits per second. Finally, we propose countermeasures to mitigate this out-of-band air-gap threat.</li>
</ul>

<h3>Title: On the Benefits of Memory for Modeling Time-Dependent PDEs</h3>
<ul>
<li><strong>Authors: </strong>Ricardo Buitrago Ruiz, Tanya Marwah, Albert Gu, Andrej Risteski</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2409.02313">https://arxiv.org/abs/2409.02313</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2409.02313">https://arxiv.org/pdf/2409.02313</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2409.02313]] On the Benefits of Memory for Modeling Time-Dependent PDEs(https://arxiv.org/abs/2409.02313)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Data-driven techniques have emerged as a promising alternative to traditional numerical methods for solving partial differential equations (PDEs). These techniques frequently offer a better trade-off between computational cost and accuracy for many PDE families of interest. For time-dependent PDEs, existing methodologies typically treat PDEs as Markovian systems, i.e., the evolution of the system only depends on the ``current state'', and not the past states. However, distortion of the input signals -- e.g., due to discretization or low-pass filtering -- can render the evolution of the distorted signals non-Markovian. In this work, motivated by the Mori-Zwanzig theory of model reduction, we investigate the impact of architectures with memory for modeling PDEs: that is, when past states are explicitly used to predict the future. We introduce Memory Neural Operator (MemNO), a network based on the recent SSM architectures and Fourier Neural Operator (FNO). We empirically demonstrate on a variety of PDE families of interest that when the input is given on a low-resolution grid, MemNO significantly outperforms the baselines without memory, achieving more than 6 times less error on unseen PDEs. Via a combination of theory and experiments, we show that the effect of memory is particularly significant when the solution of the PDE has high frequency Fourier components (e.g., low-viscosity fluid dynamics), and it also increases robustness to observation noise.</li>
</ul>

<h3>Title: TimeDiT: General-purpose Diffusion Transformers for Time Series Foundation Model</h3>
<ul>
<li><strong>Authors: </strong>Defu Cao, Wen Ye, Yizhou Zhang, Yan Liu</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2409.02322">https://arxiv.org/abs/2409.02322</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2409.02322">https://arxiv.org/pdf/2409.02322</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2409.02322]] TimeDiT: General-purpose Diffusion Transformers for Time Series Foundation Model(https://arxiv.org/abs/2409.02322)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, transformer, generative, large language model</a></li>
<li><strong>Abstract: </strong>With recent advances in building foundation models for texts and video data, there is a surge of interest in foundation models for time series. A family of models have been developed, utilizing a temporal auto-regressive generative Transformer architecture, whose effectiveness has been proven in Large Language Models. While the empirical results are promising, almost all existing time series foundation models have only been tested on well-curated ``benchmark'' datasets very similar to texts. However, real-world time series exhibit unique challenges, such as variable channel sizes across domains, missing values, and varying signal sampling intervals due to the multi-resolution nature of real-world data. Additionally, the uni-directional nature of temporally auto-regressive decoding limits the incorporation of domain knowledge, such as physical laws expressed as partial differential equations (PDEs). To address these challenges, we introduce the Time Diffusion Transformer (TimeDiT), a general foundation model for time series that employs a denoising diffusion paradigm instead of temporal auto-regressive generation. TimeDiT leverages the Transformer architecture to capture temporal dependencies and employs diffusion processes to generate high-quality candidate samples without imposing stringent assumptions on the target distribution via novel masking schemes and a channel alignment strategy. Furthermore, we propose a finetuning-free model editing strategy that allows the seamless integration of external knowledge during the sampling process without updating any model parameters. Extensive experiments conducted on a varity of tasks such as forecasting, imputation, and anomaly detection, demonstrate the effectiveness of TimeDiT.</li>
</ul>

<h3>Title: Robust Federated Finetuning of Foundation Models via Alternating Minimization of LoRA</h3>
<ul>
<li><strong>Authors: </strong>Shuangyi Chen, Yue Ju, Hardik Dalal, Zhongwen Zhu, Ashish Khisti</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.DC</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2409.02346">https://arxiv.org/abs/2409.02346</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2409.02346">https://arxiv.org/pdf/2409.02346</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2409.02346]] Robust Federated Finetuning of Foundation Models via Alternating Minimization of LoRA(https://arxiv.org/abs/2409.02346)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, federate</a></li>
<li><strong>Abstract: </strong>Parameter-Efficient Fine-Tuning (PEFT) has risen as an innovative training strategy that updates only a select few model parameters, significantly lowering both computational and memory demands. PEFT also helps to decrease data transfer in federated learning settings, where communication depends on the size of updates. In this work, we explore the constraints of previous studies that integrate a well-known PEFT method named LoRA with federated fine-tuning, then introduce RoLoRA, a robust federated fine-tuning framework that utilizes an alternating minimization approach for LoRA, providing greater robustness against decreasing fine-tuning parameters and increasing data heterogeneity. Our results indicate that RoLoRA not only presents the communication benefits but also substantially enhances the robustness and effectiveness in multiple federated fine-tuning scenarios.</li>
</ul>

<h3>Title: Diversify-verify-adapt: Efficient and Robust Retrieval-Augmented Ambiguous Question Answering</h3>
<ul>
<li><strong>Authors: </strong>Yeonjun In, Sungchul Kim, Ryan A. Rossi, Md Mehrab Tanjim, Tong Yu, Ritwik Sinha, Chanyoung Park</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2409.02361">https://arxiv.org/abs/2409.02361</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2409.02361">https://arxiv.org/pdf/2409.02361</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2409.02361]] Diversify-verify-adapt: Efficient and Robust Retrieval-Augmented Ambiguous Question Answering(https://arxiv.org/abs/2409.02361)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>The retrieval augmented generation (RAG) framework addresses an ambiguity in user queries in QA systems by retrieving passages that cover all plausible interpretations and generating comprehensive responses based on the passages. However, our preliminary studies reveal that a single retrieval process often suffers from low quality results, as the retrieved passages frequently fail to capture all plausible interpretations. Although the iterative RAG approach has been proposed to address this problem, it comes at the cost of significantly reduced efficiency. To address these issues, we propose the diversify-verify-adapt (DIVA) framework. DIVA first diversifies the retrieved passages to encompass diverse interpretations. Subsequently, DIVA verifies the quality of the passages and adapts the most suitable approach tailored to their quality. This approach improves the QA systems accuracy and robustness by handling low quality retrieval issue in ambiguous questions, while enhancing efficiency.</li>
</ul>

<h3>Title: Pluralistic Salient Object Detection</h3>
<ul>
<li><strong>Authors: </strong>Xuelu Feng, Yunsheng Li, Dongdong Chen, Chunming Qiao, Junsong Yuan, Lu Yuan, Gang Hua</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2409.02368">https://arxiv.org/abs/2409.02368</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2409.02368">https://arxiv.org/pdf/2409.02368</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2409.02368]] Pluralistic Salient Object Detection(https://arxiv.org/abs/2409.02368)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>We introduce pluralistic salient object detection (PSOD), a novel task aimed at generating multiple plausible salient segmentation results for a given input image. Unlike conventional SOD methods that produce a single segmentation mask for salient objects, this new setting recognizes the inherent complexity of real-world images, comprising multiple objects, and the ambiguity in defining salient objects due to different user intentions. To study this task, we present two new SOD datasets "DUTS-MM" and "DUS-MQ", along with newly designed evaluation metrics. DUTS-MM builds upon the DUTS dataset but enriches the ground-truth mask annotations from three aspects which 1) improves the mask quality especially for boundary and fine-grained structures; 2) alleviates the annotation inconsistency issue; and 3) provides multiple ground-truth masks for images with saliency ambiguity. DUTS-MQ consists of approximately 100K image-mask pairs with human-annotated preference scores, enabling the learning of real human preferences in measuring mask quality. Building upon these two datasets, we propose a simple yet effective pluralistic SOD baseline based on a Mixture-of-Experts (MOE) design. Equipped with two prediction heads, it simultaneously predicts multiple masks using different query prompts and predicts human preference scores for each mask candidate. Extensive experiments and analyses underscore the significance of our proposed datasets and affirm the effectiveness of our PSOD framework.</li>
</ul>

<h3>Title: Do Large Language Models Possess Sensitive to Sentiment?</h3>
<ul>
<li><strong>Authors: </strong>Yang Liu, Xichou Zhu, Zhou Shen, Yi Liu, Min Li, Yujun Chen, Benzi John, Zhenzhen Ma, Tao Hu, Zhiyang Xu, Wei Luo, Junhui Wang</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2409.02370">https://arxiv.org/abs/2409.02370</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2409.02370">https://arxiv.org/pdf/2409.02370</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2409.02370]] Do Large Language Models Possess Sensitive to Sentiment?(https://arxiv.org/abs/2409.02370)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large Language Models (LLMs) have recently displayed their extraordinary capabilities in language understanding. However, how to comprehensively assess the sentiment capabilities of LLMs continues to be a challenge. This paper investigates the ability of LLMs to detect and react to sentiment in text modal. As the integration of LLMs into diverse applications is on the rise, it becomes highly critical to comprehend their sensitivity to emotional tone, as it can influence the user experience and the efficacy of sentiment-driven tasks. We conduct a series of experiments to evaluate the performance of several prominent LLMs in identifying and responding appropriately to sentiments like positive, negative, and neutral emotions. The models' outputs are analyzed across various sentiment benchmarks, and their responses are compared with human evaluations. Our discoveries indicate that although LLMs show a basic sensitivity to sentiment, there are substantial variations in their accuracy and consistency, emphasizing the requirement for further enhancements in their training processes to better capture subtle emotional cues. Take an example in our findings, in some cases, the models might wrongly classify a strongly positive sentiment as neutral, or fail to recognize sarcasm or irony in the text. Such misclassifications highlight the complexity of sentiment analysis and the areas where the models need to be refined. Another aspect is that different LLMs might perform differently on the same set of data, depending on their architecture and training datasets. This variance calls for a more in-depth study of the factors that contribute to the performance differences and how they can be optimized.</li>
</ul>

<h3>Title: Exploring Low-Dimensional Subspaces in Diffusion Models for Controllable Image Editing</h3>
<ul>
<li><strong>Authors: </strong>Siyi Chen, Huijie Zhang, Minzhe Guo, Yifu Lu, Peng Wang, Qing Qu</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2409.02374">https://arxiv.org/abs/2409.02374</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2409.02374">https://arxiv.org/pdf/2409.02374</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2409.02374]] Exploring Low-Dimensional Subspaces in Diffusion Models for Controllable Image Editing(https://arxiv.org/abs/2409.02374)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, generative</a></li>
<li><strong>Abstract: </strong>Recently, diffusion models have emerged as a powerful class of generative models. Despite their success, there is still limited understanding of their semantic spaces. This makes it challenging to achieve precise and disentangled image generation without additional training, especially in an unsupervised way. In this work, we improve the understanding of their semantic spaces from intriguing observations: among a certain range of noise levels, (1) the learned posterior mean predictor (PMP) in the diffusion model is locally linear, and (2) the singular vectors of its Jacobian lie in low-dimensional semantic subspaces. We provide a solid theoretical basis to justify the linearity and low-rankness in the PMP. These insights allow us to propose an unsupervised, single-step, training-free LOw-rank COntrollable image editing (LOCO Edit) method for precise local editing in diffusion models. LOCO Edit identified editing directions with nice properties: homogeneity, transferability, composability, and linearity. These properties of LOCO Edit benefit greatly from the low-dimensional semantic subspace. Our method can further be extended to unsupervised or text-supervised editing in various text-to-image diffusion models (T-LOCO Edit). Finally, extensive empirical experiments demonstrate the effectiveness and efficiency of LOCO Edit. The codes will be released at this https URL.</li>
</ul>

<h3>Title: How Privacy-Savvy Are Large Language Models? A Case Study on Compliance and Privacy Technical Review</h3>
<ul>
<li><strong>Authors: </strong>Xichou Zhu, Yang Liu, Zhou Shen, Yi Liu, Min Li, Yujun Chen, Benzi John, Zhenzhen Ma, Tao Hu, Bolong Yang, Manman Wang, Zongxing Xie, Peng Liu, Dan Cai, Junhui Wang</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2409.02375">https://arxiv.org/abs/2409.02375</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2409.02375">https://arxiv.org/pdf/2409.02375</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2409.02375]] How Privacy-Savvy Are Large Language Models? A Case Study on Compliance and Privacy Technical Review(https://arxiv.org/abs/2409.02375)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, protect, robust, extraction, large language model</a></li>
<li><strong>Abstract: </strong>The recent advances in large language models (LLMs) have significantly expanded their applications across various fields such as language generation, summarization, and complex question answering. However, their application to privacy compliance and technical privacy reviews remains under-explored, raising critical concerns about their ability to adhere to global privacy standards and protect sensitive user data. This paper seeks to address this gap by providing a comprehensive case study evaluating LLMs' performance in privacy-related tasks such as privacy information extraction (PIE), legal and regulatory key point detection (KPD), and question answering (QA) with respect to privacy policies and data protection regulations. We introduce a Privacy Technical Review (PTR) framework, highlighting its role in mitigating privacy risks during the software development life-cycle. Through an empirical assessment, we investigate the capacity of several prominent LLMs, including BERT, GPT-3.5, GPT-4, and custom models, in executing privacy compliance checks and technical privacy reviews. Our experiments benchmark the models across multiple dimensions, focusing on their precision, recall, and F1-scores in extracting privacy-sensitive information and detecting key regulatory compliance points. While LLMs show promise in automating privacy reviews and identifying regulatory discrepancies, significant gaps persist in their ability to fully comply with evolving legal standards. We provide actionable recommendations for enhancing LLMs' capabilities in privacy compliance, emphasizing the need for robust model improvements and better integration with legal and regulatory requirements. This study underscores the growing importance of developing privacy-aware LLMs that can both support businesses in compliance efforts and safeguard user privacy rights.</li>
</ul>

<h3>Title: Coral Model Generation from Single Images for Virtual Reality Applications</h3>
<ul>
<li><strong>Authors: </strong>Jie Fu (University of the Arts London, Creative Computing Institute, London, United Kingdom), Shun Fu (Bloks Technology Company, Shanghai, China), Mick Grierson (University of the Arts London, Creative Computing Institute, London, United Kingdom)</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI, cs.GR, cs.HC, cs.MM</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2409.02376">https://arxiv.org/abs/2409.02376</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2409.02376">https://arxiv.org/pdf/2409.02376</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2409.02376]] Coral Model Generation from Single Images for Virtual Reality Applications(https://arxiv.org/abs/2409.02376)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability</a></li>
<li><strong>Abstract: </strong>With the rapid development of VR technology, the demand for high-quality 3D models is increasing. Traditional methods struggle with efficiency and quality in large-scale customization. This paper introduces a deep-learning framework that generates high-precision 3D coral models from a single image. Using the Coral dataset, the framework extracts geometric and texture features, performs 3D reconstruction, and optimizes design and material blending. Advanced optimization and polygon count control ensure shape accuracy, detail retention, and flexible output for various complexities, catering to high-quality rendering and real-time interaction needs.The project incorporates Explainable AI (XAI) to transform AI-generated models into interactive "artworks," best viewed in VR and XR. This enhances model interpretability and human-machine collaboration. Real-time feedback in VR interactions displays information like coral species and habitat, enriching user experience. The generated models surpass traditional methods in detail, visual quality, and efficiency. This research offers an intelligent approach to 3D content creation for VR, lowering production barriers, and promoting widespread VR applications. Additionally, integrating XAI provides new insights into AI-generated visual content and advances research in 3D vision interpretability.</li>
</ul>

<h3>Title: GGS: Generalizable Gaussian Splatting for Lane Switching in Autonomous Driving</h3>
<ul>
<li><strong>Authors: </strong>Huasong Han, Kaixuan Zhou, Xiaoxiao Long, Yusen Wang, Chunxia Xiao</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2409.02382">https://arxiv.org/abs/2409.02382</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2409.02382">https://arxiv.org/pdf/2409.02382</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2409.02382]] GGS: Generalizable Gaussian Splatting for Lane Switching in Autonomous Driving(https://arxiv.org/abs/2409.02382)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>We propose GGS, a Generalizable Gaussian Splatting method for Autonomous Driving which can achieve realistic rendering under large viewpoint changes. Previous generalizable 3D gaussian splatting methods are limited to rendering novel views that are very close to the original pair of images, which cannot handle large differences in viewpoint. Especially in autonomous driving scenarios, images are typically collected from a single lane. The limited training perspective makes rendering images of a different lane very challenging. To further improve the rendering capability of GGS under large viewpoint changes, we introduces a novel virtual lane generation module into GSS method to enables high-quality lane switching even without a multi-lane dataset. Besides, we design a diffusion loss to supervise the generation of virtual lane image to further address the problem of lack of data in the virtual lanes. Finally, we also propose a depth refinement module to optimize depth estimation in the GSS model. Extensive validation of our method, compared to existing approaches, demonstrates state-of-the-art performance.</li>
</ul>

<h3>Title: STAB: Speech Tokenizer Assessment Benchmark</h3>
<ul>
<li><strong>Authors: </strong>Shikhar Vashishth, Harman Singh, Shikhar Bharadwaj, Sriram Ganapathy, Chulayuth Asawaroengchai, Kartik Audhkhasi, Andrew Rosenberg, Ankur Bapna, Bhuvana Ramabhadran</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.SD, eess.AS</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2409.02384">https://arxiv.org/abs/2409.02384</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2409.02384">https://arxiv.org/pdf/2409.02384</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2409.02384]] STAB: Speech Tokenizer Assessment Benchmark(https://arxiv.org/abs/2409.02384)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Representing speech as discrete tokens provides a framework for transforming speech into a format that closely resembles text, thus enabling the use of speech as an input to the widely successful large language models (LLMs). Currently, while several speech tokenizers have been proposed, there is ambiguity regarding the properties that are desired from a tokenizer for specific downstream tasks and its overall generalizability. Evaluating the performance of tokenizers across different downstream tasks is a computationally intensive effort that poses challenges for scalability. To circumvent this requirement, we present STAB (Speech Tokenizer Assessment Benchmark), a systematic evaluation framework designed to assess speech tokenizers comprehensively and shed light on their inherent characteristics. This framework provides a deeper understanding of the underlying mechanisms of speech tokenization, thereby offering a valuable resource for expediting the advancement of future tokenizer models and enabling comparative analysis using a standardized benchmark. We evaluate the STAB metrics and correlate this with downstream task performance across a range of speech tasks and tokenizer choices.</li>
</ul>

<h3>Title: Unified Framework with Consistency across Modalities for Human Activity Recognition</h3>
<ul>
<li><strong>Authors: </strong>Tuyen Tran, Thao Minh Le, Hung Tran, Truyen Tran</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2409.02385">https://arxiv.org/abs/2409.02385</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2409.02385">https://arxiv.org/pdf/2409.02385</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2409.02385]] Unified Framework with Consistency across Modalities for Human Activity Recognition(https://arxiv.org/abs/2409.02385)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Recognizing human activities in videos is challenging due to the spatio-temporal complexity and context-dependence of human interactions. Prior studies often rely on single input modalities, such as RGB or skeletal data, limiting their ability to exploit the complementary advantages across modalities. Recent studies focus on combining these two modalities using simple feature fusion techniques. However, due to the inherent disparities in representation between these input modalities, designing a unified neural network architecture to effectively leverage their complementary information remains a significant challenge. To address this, we propose a comprehensive multimodal framework for robust video-based human activity recognition. Our key contribution is the introduction of a novel compositional query machine, called COMPUTER ($\textbf{COMP}ositional h\textbf{U}man-cen\textbf{T}ric qu\textbf{ER}y$ machine), a generic neural architecture that models the interactions between a human of interest and its surroundings in both space and time. Thanks to its versatile design, COMPUTER can be leveraged to distill distinctive representations for various input modalities. Additionally, we introduce a consistency loss that enforces agreement in prediction between modalities, exploiting the complementary information from multimodal inputs for robust human movement recognition. Through extensive experiments on action localization and group activity recognition tasks, our approach demonstrates superior performance when compared with state-of-the-art methods. Our code is available at: this https URL.</li>
</ul>

<h3>Title: Building Math Agents with Multi-Turn Iterative Preference Learning</h3>
<ul>
<li><strong>Authors: </strong>Wei Xiong, Chengshuai Shi, Jiaming Shen, Aviv Rosenberg, Zhen Qin, Daniele Calandriello, Misha Khalman, Rishabh Joshi, Bilal Piot, Mohammad Saleh, Chi Jin, Tong Zhang, Tianqi Liu</a></li>
<li><strong>Subjects: </strong>cs.LG, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2409.02392">https://arxiv.org/abs/2409.02392</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2409.02392">https://arxiv.org/pdf/2409.02392</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2409.02392]] Building Math Agents with Multi-Turn Iterative Preference Learning(https://arxiv.org/abs/2409.02392)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Recent studies have shown that large language models' (LLMs) mathematical problem-solving capabilities can be enhanced by integrating external tools, such as code interpreters, and employing multi-turn Chain-of-Thought (CoT) reasoning. While current methods focus on synthetic data generation and Supervised Fine-Tuning (SFT), this paper studies the complementary direct preference learning approach to further improve model performance. However, existing direct preference learning algorithms are originally designed for the single-turn chat task, and do not fully address the complexities of multi-turn reasoning and external tool integration required for tool-integrated mathematical reasoning tasks. To fill in this gap, we introduce a multi-turn direct preference learning framework, tailored for this context, that leverages feedback from code interpreters and optimizes trajectory-level preferences. This framework includes multi-turn DPO and multi-turn KTO as specific implementations. The effectiveness of our framework is validated through training of various language models using an augmented prompt set from the GSM8K and MATH datasets. Our results demonstrate substantial improvements: a supervised fine-tuned Gemma-1.1-it-7B model's performance increased from 77.5% to 83.9% on GSM8K and from 46.1% to 51.2% on MATH. Similarly, a Gemma-2-it-9B model improved from 84.1% to 86.3% on GSM8K and from 51.0% to 54.5% on MATH.</li>
</ul>

<h3>Title: Determination of language families using deep learning</h3>
<ul>
<li><strong>Authors: </strong>Peter B. Lerner</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2409.02393">https://arxiv.org/abs/2409.02393</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2409.02393">https://arxiv.org/pdf/2409.02393</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2409.02393]] Determination of language families using deep learning(https://arxiv.org/abs/2409.02393)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>We use a c-GAN (convolutional generative adversarial) neural network to analyze transliterated text fragments of extant, dead comprehensible, and one dead non-deciphered (Cypro-Minoan) language to establish linguistic affinities. The paper is agnostic with respect to translation and/or deciphering. However, there is hope that the proposed approach can be useful for decipherment with more sophisticated neural network techniques.</li>
</ul>

<h3>Title: Learning Privacy-Preserving Student Networks via Discriminative-Generative Distillation</h3>
<ul>
<li><strong>Authors: </strong>Shiming Ge, Bochao Liu, Pengju Wang, Yong Li, Dan Zeng</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2409.02404">https://arxiv.org/abs/2409.02404</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2409.02404">https://arxiv.org/pdf/2409.02404</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2409.02404]] Learning Privacy-Preserving Student Networks via Discriminative-Generative Distillation(https://arxiv.org/abs/2409.02404)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, data-free, generative</a></li>
<li><strong>Abstract: </strong>While deep models have proved successful in learning rich knowledge from massive well-annotated data, they may pose a privacy leakage risk in practical deployment. It is necessary to find an effective trade-off between high utility and strong privacy. In this work, we propose a discriminative-generative distillation approach to learn privacy-preserving deep models. Our key idea is taking models as bridge to distill knowledge from private data and then transfer it to learn a student network via two streams. First, discriminative stream trains a baseline classifier on private data and an ensemble of teachers on multiple disjoint private subsets, respectively. Then, generative stream takes the classifier as a fixed discriminator and trains a generator in a data-free manner. After that, the generator is used to generate massive synthetic data which are further applied to train a variational autoencoder (VAE). Among these synthetic data, a few of them are fed into the teacher ensemble to query labels via differentially private aggregation, while most of them are embedded to the trained VAE for reconstructing synthetic data. Finally, a semi-supervised student learning is performed to simultaneously handle two tasks: knowledge transfer from the teachers with distillation on few privately labeled synthetic data, and knowledge enhancement with tangent-normal adversarial regularization on many triples of reconstructed synthetic data. In this way, our approach can control query cost over private data and mitigate accuracy degradation in a unified manner, leading to a privacy-preserving student model. Extensive experiments and analysis clearly show the effectiveness of the proposed approach.</li>
</ul>

<h3>Title: Adaptive Class Emergence Training: Enhancing Neural Network Stability and Generalization through Progressive Target Evolution</h3>
<ul>
<li><strong>Authors: </strong>Jaouad Dabounou</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2409.02410">https://arxiv.org/abs/2409.02410</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2409.02410">https://arxiv.org/pdf/2409.02410</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2409.02410]] Adaptive Class Emergence Training: Enhancing Neural Network Stability and Generalization through Progressive Target Evolution(https://arxiv.org/abs/2409.02410)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Recent advancements in artificial intelligence, particularly deep neural networks, have pushed the boundaries of what is achievable in complex tasks. Traditional methods for training neural networks in classification problems often rely on static target outputs, such as one-hot encoded vectors, which can lead to unstable optimization and difficulties in handling non-linearities within data. In this paper, we propose a novel training methodology that progressively evolves the target outputs from a null vector to one-hot encoded vectors throughout the training process. This gradual transition allows the network to adapt more smoothly to the increasing complexity of the classification task, maintaining an equilibrium state that reduces the risk of overfitting and enhances generalization. Our approach, inspired by concepts from structural equilibrium in finite element analysis, has been validated through extensive experiments on both synthetic and real-world datasets. The results demonstrate that our method achieves faster convergence, improved accuracy, and better generalization, especially in scenarios with high data complexity and noise. This progressive training framework offers a robust alternative to classical methods, opening new perspectives for more efficient and stable neural network training.</li>
</ul>

<h3>Title: Abstractive Text Summarization: State of the Art, Challenges, and Improvements</h3>
<ul>
<li><strong>Authors: </strong>Hassan Shakil, Ahmad Farooq, Jugal Kalita</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2409.02413">https://arxiv.org/abs/2409.02413</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2409.02413">https://arxiv.org/pdf/2409.02413</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2409.02413]] Abstractive Text Summarization: State of the Art, Challenges, and Improvements(https://arxiv.org/abs/2409.02413)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Specifically focusing on the landscape of abstractive text summarization, as opposed to extractive techniques, this survey presents a comprehensive overview, delving into state-of-the-art techniques, prevailing challenges, and prospective research directions. We categorize the techniques into traditional sequence-to-sequence models, pre-trained large language models, reinforcement learning, hierarchical methods, and multi-modal summarization. Unlike prior works that did not examine complexities, scalability and comparisons of techniques in detail, this review takes a comprehensive approach encompassing state-of-the-art methods, challenges, solutions, comparisons, limitations and charts out future improvements - providing researchers an extensive overview to advance abstractive summarization research. We provide vital comparison tables across techniques categorized - offering insights into model complexity, scalability and appropriate applications. The paper highlights challenges such as inadequate meaning representation, factual consistency, controllable text summarization, cross-lingual summarization, and evaluation metrics, among others. Solutions leveraging knowledge incorporation and other innovative strategies are proposed to address these challenges. The paper concludes by highlighting emerging research areas like factual inconsistency, domain-specific, cross-lingual, multilingual, and long-document summarization, as well as handling noisy data. Our objective is to provide researchers and practitioners with a structured overview of the domain, enabling them to better understand the current landscape and identify potential areas for further research and improvement.</li>
</ul>

<h3>Title: Relative-Translation Invariant Wasserstein Distance</h3>
<ul>
<li><strong>Authors: </strong>Binshuai Wang, Qiwei Di, Ming Yin, Mengdi Wang, Quanquan Gu, Peng Wei</a></li>
<li><strong>Subjects: </strong>cs.LG, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2409.02416">https://arxiv.org/abs/2409.02416</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2409.02416">https://arxiv.org/pdf/2409.02416</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2409.02416]] Relative-Translation Invariant Wasserstein Distance(https://arxiv.org/abs/2409.02416)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>We introduce a new family of distances, relative-translation invariant Wasserstein distances ($RW_p$), for measuring the similarity of two probability distributions under distribution shift. Generalizing it from the classical optimal transport model, we show that $RW_p$ distances are also real distance metrics defined on the quotient set $\mathcal{P}_p(\mathbb{R}^n)/\sim$ and invariant to distribution translations. When $p=2$, the $RW_2$ distance enjoys more exciting properties, including decomposability of the optimal transport model, translation-invariance of the $RW_2$ distance, and a Pythagorean relationship between $RW_2$ and the classical quadratic Wasserstein distance ($W_2$). Based on these properties, we show that a distribution shift, measured by $W_2$ distance, can be explained in the bias-variance perspective. In addition, we propose a variant of the Sinkhorn algorithm, named $RW_2$ Sinkhorn algorithm, for efficiently calculating $RW_2$ distance, coupling solutions, as well as $W_2$ distance. We also provide the analysis of numerical stability and time complexity for the proposed algorithm. Finally, we validate the $RW_2$ distance metric and the algorithm performance with three experiments. We conduct one numerical validation for the $RW_2$ Sinkhorn algorithm and show two real-world applications demonstrating the effectiveness of using $RW_2$ under distribution shift: digits recognition and similar thunderstorm detection. The experimental results report that our proposed algorithm significantly improves the computational efficiency of Sinkhorn in certain practical applications, and the $RW_2$ distance is robust to distribution translations compared with baselines.</li>
</ul>

<h3>Title: MOSMOS: Multi-organ segmentation facilitated by medical report supervision</h3>
<ul>
<li><strong>Authors: </strong>Weiwei Tian, Xinyu Huang, Junlin Hou, Caiyue Ren, Longquan Jiang, Rui-Wei Zhao, Gang Jin, Yuejie Zhang, Daoying Geng</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2409.02418">https://arxiv.org/abs/2409.02418</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2409.02418">https://arxiv.org/pdf/2409.02418</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2409.02418]] MOSMOS: Multi-organ segmentation facilitated by medical report supervision(https://arxiv.org/abs/2409.02418)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>Owing to a large amount of multi-modal data in modern medical systems, such as medical images and reports, Medical Vision-Language Pre-training (Med-VLP) has demonstrated incredible achievements in coarse-grained downstream tasks (i.e., medical classification, retrieval, and visual question answering). However, the problem of transferring knowledge learned from Med-VLP to fine-grained multi-organ segmentation tasks has barely been investigated. Multi-organ segmentation is challenging mainly due to the lack of large-scale fully annotated datasets and the wide variation in the shape and size of the same organ between individuals with different diseases. In this paper, we propose a novel pre-training & fine-tuning framework for Multi-Organ Segmentation by harnessing Medical repOrt Supervision (MOSMOS). Specifically, we first introduce global contrastive learning to maximally align the medical image-report pairs in the pre-training stage. To remedy the granularity discrepancy, we further leverage multi-label recognition to implicitly learn the semantic correspondence between image pixels and organ tags. More importantly, our pre-trained models can be transferred to any segmentation model by introducing the pixel-tag attention maps. Different network settings, i.e., 2D U-Net and 3D UNETR, are utilized to validate the generalization. We have extensively evaluated our approach using different diseases and modalities on BTCV, AMOS, MMWHS, and BRATS datasets. Experimental results in various settings demonstrate the effectiveness of our framework. This framework can serve as the foundation to facilitate future research on automatic annotation tasks under the supervision of medical reports.</li>
</ul>

<h3>Title: Diffusion Models Learn Low-Dimensional Distributions via Subspace Clustering</h3>
<ul>
<li><strong>Authors: </strong>Peng Wang, Huijie Zhang, Zekai Zhang, Siyi Chen, Yi Ma, Qing Qu</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2409.02426">https://arxiv.org/abs/2409.02426</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2409.02426">https://arxiv.org/pdf/2409.02426</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2409.02426]] Diffusion Models Learn Low-Dimensional Distributions via Subspace Clustering(https://arxiv.org/abs/2409.02426)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>Recent empirical studies have demonstrated that diffusion models can effectively learn the image distribution and generate new samples. Remarkably, these models can achieve this even with a small number of training samples despite a large image dimension, circumventing the curse of dimensionality. In this work, we provide theoretical insights into this phenomenon by leveraging key empirical observations: (i) the low intrinsic dimensionality of image data, (ii) a union of manifold structure of image data, and (iii) the low-rank property of the denoising autoencoder in trained diffusion models. These observations motivate us to assume the underlying data distribution of image data as a mixture of low-rank Gaussians and to parameterize the denoising autoencoder as a low-rank model according to the score function of the assumed distribution. With these setups, we rigorously show that optimizing the training loss of diffusion models is equivalent to solving the canonical subspace clustering problem over the training samples. Based on this equivalence, we further show that the minimal number of samples required to learn the underlying distribution scales linearly with the intrinsic dimensions under the above data and model assumptions. This insight sheds light on why diffusion models can break the curse of dimensionality and exhibit the phase transition in learning distributions. Moreover, we empirically establish a correspondence between the subspaces and the semantic representations of image data, facilitating image editing. We validate these results with corroborated experimental results on both simulated distributions and image datasets.</li>
</ul>

<h3>Title: Large Language Models as Efficient Reward Function Searchers for Custom-Environment Multi-Objective Reinforcement Learning</h3>
<ul>
<li><strong>Authors: </strong>Guanwen Xie, Jingzehua Xu, Yiyuan Yang, Shuai Zhang</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CL, eess.SY</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2409.02428">https://arxiv.org/abs/2409.02428</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2409.02428">https://arxiv.org/pdf/2409.02428</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2409.02428]] Large Language Models as Efficient Reward Function Searchers for Custom-Environment Multi-Objective Reinforcement Learning(https://arxiv.org/abs/2409.02428)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Leveraging large language models (LLMs) for designing reward functions demonstrates significant potential. However, achieving effective design and improvement of reward functions in reinforcement learning (RL) tasks with complex custom environments and multiple requirements presents considerable challenges. In this paper, we enable LLMs to be effective white-box searchers, highlighting their advanced semantic understanding capabilities. Specifically, we generate reward components for each explicit user requirement and employ the reward critic to identify the correct code form. Then, LLMs assign weights to the reward components to balance their values and iteratively search and optimize these weights based on the context provided by the training log analyzer, while adaptively determining the search step size. We applied the framework to an underwater information collection RL task without direct human feedback or reward examples (zero-shot). The reward critic successfully correct the reward code with only one feedback for each requirement, effectively preventing irreparable errors that can occur when reward function feedback is provided in aggregate. The effective initialization of weights enables the acquisition of different reward functions within the Pareto solution set without weight search. Even in the case where a weight is 100 times off, fewer than four iterations are needed to obtain solutions that meet user requirements. The framework also works well with most prompts utilizing GPT-3.5 Turbo, since it does not require advanced numerical understanding or calculation.</li>
</ul>

<h3>Title: Training-free Color-Style Disentanglement for Constrained Text-to-Image Synthesis</h3>
<ul>
<li><strong>Authors: </strong>Aishwarya Agarwal, Srikrishna Karanam, Balaji Vasan Srinivasan</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2409.02429">https://arxiv.org/abs/2409.02429</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2409.02429">https://arxiv.org/pdf/2409.02429</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2409.02429]] Training-free Color-Style Disentanglement for Constrained Text-to-Image Synthesis(https://arxiv.org/abs/2409.02429)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>We consider the problem of independently, in a disentangled fashion, controlling the outputs of text-to-image diffusion models with color and style attributes of a user-supplied reference image. We present the first training-free, test-time-only method to disentangle and condition text-to-image models on color and style attributes from reference image. To realize this, we propose two key innovations. Our first contribution is to transform the latent codes at inference time using feature transformations that make the covariance matrix of current generation follow that of the reference image, helping meaningfully transfer color. Next, we observe that there exists a natural disentanglement between color and style in the LAB image space, which we exploit to transform the self-attention feature maps of the image being generated with respect to those of the reference computed from its L channel. Both these operations happen purely at test time and can be done independently or merged. This results in a flexible method where color and style information can come from the same reference image or two different sources, and a new generation can seamlessly fuse them in either scenario.</li>
</ul>

<h3>Title: Adversarial Learning for Neural PDE Solvers with Sparse Data</h3>
<ul>
<li><strong>Authors: </strong>Yunpeng Gong, Yongjie Hou, Zhenzhong Wang, Zexin Lin, Min Jiang</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2409.02431">https://arxiv.org/abs/2409.02431</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2409.02431">https://arxiv.org/pdf/2409.02431</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2409.02431]] Adversarial Learning for Neural PDE Solvers with Sparse Data(https://arxiv.org/abs/2409.02431)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Neural network solvers for partial differential equations (PDEs) have made significant progress, yet they continue to face challenges related to data scarcity and model robustness. Traditional data augmentation methods, which leverage symmetry or invariance, impose strong assumptions on physical systems that often do not hold in dynamic and complex real-world applications. To address this research gap, this study introduces a universal learning strategy for neural network PDEs, named Systematic Model Augmentation for Robust Training (SMART). By focusing on challenging and improving the model's weaknesses, SMART reduces generalization error during training under data-scarce conditions, leading to significant improvements in prediction accuracy across various PDE scenarios. The effectiveness of the proposed method is demonstrated through both theoretical analysis and extensive experimentation. The code will be available.</li>
</ul>

<h3>Title: What is lost in Normalization? Exploring Pitfalls in Multilingual ASR Model Evaluations</h3>
<ul>
<li><strong>Authors: </strong>Kavya Manohar, Leena G Pillai</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.HC</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2409.02449">https://arxiv.org/abs/2409.02449</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2409.02449">https://arxiv.org/pdf/2409.02449</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2409.02449]] What is lost in Normalization? Exploring Pitfalls in Multilingual ASR Model Evaluations(https://arxiv.org/abs/2409.02449)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, fair</a></li>
<li><strong>Abstract: </strong>This paper explores the pitfalls in evaluating multilingual automatic speech recognition (ASR) models, with a particular focus on Indic language scripts. We investigate the text normalization routine employed by leading ASR models, including OpenAI Whisper, Meta's MMS, Seamless, and Assembly AI's Conformer, and their unintended consequences on performance metrics. Our research reveals that current text normalization practices, while aiming to standardize ASR outputs for fair comparison, by removing inconsistencies such as variations in spelling, punctuation, and special characters, are fundamentally flawed when applied to Indic scripts. Through empirical analysis using text similarity scores and in-depth linguistic examination, we demonstrate that these flaws lead to artificially inflated performance metrics for Indic languages. We conclude by proposing a shift towards developing normalization routines that leverage native linguistic expertise, ensuring more robust and accurate evaluations of multilingual ASR models.</li>
</ul>

<h3>Title: DetectiveQA: Evaluating Long-Context Reasoning on Detective Novels</h3>
<ul>
<li><strong>Authors: </strong>Zhe Xu, Jiasheng Ye, Xiangyang Liu, Tianxiang Sun, Xiaoran Liu, Qipeng Guo, Linlin Li, Qun Liu, Xuanjing Huang, Xipeng Qiu</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2409.02465">https://arxiv.org/abs/2409.02465</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2409.02465">https://arxiv.org/pdf/2409.02465</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2409.02465]] DetectiveQA: Evaluating Long-Context Reasoning on Detective Novels(https://arxiv.org/abs/2409.02465)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>With the rapid advancement of Large Language Models (LLMs), long-context information understanding and processing have become a hot topic in academia and industry. However, benchmarks for evaluating the ability of LLMs to handle long-context information do not seem to have kept pace with the development of LLMs. Despite the emergence of various long-context evaluation benchmarks, the types of capability assessed are still limited, without new capability dimensions. In this paper, we introduce DetectiveQA, a narrative reasoning benchmark featured with an average context length of over 100K tokens. DetectiveQA focuses on evaluating the long-context reasoning ability of LLMs, which not only requires a full understanding of context but also requires extracting important evidences from the context and reasoning according to extracted evidences to answer the given questions. This is a new dimension of capability evaluation, which is more in line with the current intelligence level of LLMs. We use detective novels as data sources, which naturally have various reasoning elements. Finally, we manually annotated 600 questions in Chinese and then also provided an English edition of the context information and questions. We evaluate many long-context LLMs on DetectiveQA, including commercial and open-sourced models, and the results indicate that existing long-context LLMs still require significant advancements to effectively process true long-context dependency questions.</li>
</ul>

<h3>Title: TASAR: Transferable Attack on Skeletal Action Recognition</h3>
<ul>
<li><strong>Authors: </strong>Yunfeng Diao, Baiqi Wu, Ruixuan Zhang, Ajian Liu, Xingxing Wei, Meng Wang, He Wang</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2409.02483">https://arxiv.org/abs/2409.02483</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2409.02483">https://arxiv.org/pdf/2409.02483</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2409.02483]] TASAR: Transferable Attack on Skeletal Action Recognition(https://arxiv.org/abs/2409.02483)</code><input type="text"></li>
<li><strong>Keywords: </strong>defense, attack, robust</a></li>
<li><strong>Abstract: </strong>Skeletal sequences, as well-structured representations of human behaviors, are crucial in Human Activity Recognition (HAR). The transferability of adversarial skeletal sequences enables attacks in real-world HAR scenarios, such as autonomous driving, intelligent surveillance, and human-computer interactions. However, existing Skeleton-based HAR (S-HAR) attacks exhibit weak adversarial transferability and, therefore, cannot be considered true transfer-based S-HAR attacks. More importantly, the reason for this failure remains unclear. In this paper, we study this phenomenon through the lens of loss surface, and find that its sharpness contributes to the poor transferability in S-HAR. Inspired by this observation, we assume and empirically validate that smoothening the rugged loss landscape could potentially improve adversarial transferability in S-HAR. To this end, we propose the first Transfer-based Attack on Skeletal Action Recognition, TASAR. TASAR explores the smoothed model posterior without re-training the pre-trained surrogates, which is achieved by a new post-train Dual Bayesian optimization strategy. Furthermore, unlike previous transfer-based attacks that treat each frame independently and overlook temporal coherence within sequences, TASAR incorporates motion dynamics into the Bayesian attack gradient, effectively disrupting the spatial-temporal coherence of S-HARs. To exhaustively evaluate the effectiveness of existing methods and our method, we build the first large-scale robust S-HAR benchmark, comprising 7 S-HAR models, 10 attack methods, 3 S-HAR datasets and 2 defense models. Extensive results demonstrate the superiority of TASAR. Our benchmark enables easy comparisons for future studies, with the code available in the supplementary material.</li>
</ul>

<h3>Title: Adversarial Attacks on Machine Learning-Aided Visualizations</h3>
<ul>
<li><strong>Authors: </strong>Takanori Fujiwara, Kostiantyn Kucher, Junpeng Wang, Rafael M. Martins, Andreas Kerren, Anders Ynnerman</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.AI, cs.HC, cs.LG, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2409.02485">https://arxiv.org/abs/2409.02485</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2409.02485">https://arxiv.org/pdf/2409.02485</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2409.02485]] Adversarial Attacks on Machine Learning-Aided Visualizations(https://arxiv.org/abs/2409.02485)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, defense, attack</a></li>
<li><strong>Abstract: </strong>Research in ML4VIS investigates how to use machine learning (ML) techniques to generate visualizations, and the field is rapidly growing with high societal impact. However, as with any computational pipeline that employs ML processes, ML4VIS approaches are susceptible to a range of ML-specific adversarial attacks. These attacks can manipulate visualization generations, causing analysts to be tricked and their judgments to be impaired. Due to a lack of synthesis from both visualization and ML perspectives, this security aspect is largely overlooked by the current ML4VIS literature. To bridge this gap, we investigate the potential vulnerabilities of ML-aided visualizations from adversarial attacks using a holistic lens of both visualization and ML perspectives. We first identify the attack surface (i.e., attack entry points) that is unique in ML-aided visualizations. We then exemplify five different adversarial attacks. These examples highlight the range of possible attacks when considering the attack surface and multiple different adversary capabilities. Our results show that adversaries can induce various attacks, such as creating arbitrary and deceptive visualizations, by systematically identifying input attributes that are influential in ML inferences. Based on our observations of the attack surface characteristics and the attack examples, we underline the importance of comprehensive studies of security issues and defense mechanisms as a call of urgency for the ML4VIS community.</li>
</ul>

<h3>Title: Boosting Generalizability towards Zero-Shot Cross-Dataset Single-Image Indoor Depth by Meta-Initialization</h3>
<ul>
<li><strong>Authors: </strong>Cho-Ying Wu, Yiqi Zhong, Junying Wang, Ulrich Neumann</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2409.02486">https://arxiv.org/abs/2409.02486</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2409.02486">https://arxiv.org/pdf/2409.02486</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2409.02486]] Boosting Generalizability towards Zero-Shot Cross-Dataset Single-Image Indoor Depth by Meta-Initialization(https://arxiv.org/abs/2409.02486)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Indoor robots rely on depth to perform tasks like navigation or obstacle detection, and single-image depth estimation is widely used to assist perception. Most indoor single-image depth prediction focuses less on model generalizability to unseen datasets, concerned with in-the-wild robustness for system deployment. This work leverages gradient-based meta-learning to gain higher generalizability on zero-shot cross-dataset inference. Unlike the most-studied meta-learning of image classification associated with explicit class labels, no explicit task boundaries exist for continuous depth values tied to highly varying indoor environments regarding object arrangement and scene composition. We propose fine-grained task that treats each RGB-D mini-batch as a task in our meta-learning formulation. We first show that our method on limited data induces a much better prior (max 27.8% in RMSE). Then, finetuning on meta-learned initialization consistently outperforms baselines without the meta approach. Aiming at generalization, we propose zero-shot cross-dataset protocols and validate higher generalizability induced by our meta-initialization, as a simple and useful plugin to many existing depth estimation methods. The work at the intersection of depth and meta-learning potentially drives both research to step closer to practical robotic and machine perception usage.</li>
</ul>

<h3>Title: Reliable Deep Diffusion Tensor Estimation: Rethinking the Power of Data-Driven Optimization Routine</h3>
<ul>
<li><strong>Authors: </strong>Jialong Li, Zhicheng Zhang, Yunwei Chen, Qiqi Lu, Ye Wu, Xiaoming Liu, QianJin Feng, Yanqiu Feng, Xinyuan Zhang</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.LG, eess.IV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2409.02492">https://arxiv.org/abs/2409.02492</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2409.02492">https://arxiv.org/pdf/2409.02492</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2409.02492]] Reliable Deep Diffusion Tensor Estimation: Rethinking the Power of Data-Driven Optimization Routine(https://arxiv.org/abs/2409.02492)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>Diffusion tensor imaging (DTI) holds significant importance in clinical diagnosis and neuroscience research. However, conventional model-based fitting methods often suffer from sensitivity to noise, leading to decreased accuracy in estimating DTI parameters. While traditional data-driven deep learning methods have shown potential in terms of accuracy and efficiency, their limited generalization to out-of-training-distribution data impedes their broader application due to the diverse scan protocols used across centers, scanners, and studies. This work aims to tackle these challenges and promote the use of DTI by introducing a data-driven optimization-based method termed DoDTI. DoDTI combines the weighted linear least squares fitting algorithm and regularization by denoising technique. The former fits DW images from diverse acquisition settings into diffusion tensor field, while the latter applies a deep learning-based denoiser to regularize the diffusion tensor field instead of the DW images, which is free from the limitation of fixed-channel assignment of the network. The optimization object is solved using the alternating direction method of multipliers and then unrolled to construct a deep neural network, leveraging a data-driven strategy to learn network parameters. Extensive validation experiments are conducted utilizing both internally simulated datasets and externally obtained in-vivo datasets. The results, encompassing both qualitative and quantitative analyses, showcase that the proposed method attains state-of-the-art performance in DTI parameter estimation. Notably, it demonstrates superior generalization, accuracy, and efficiency, rendering it highly reliable for widespread application in the field.</li>
</ul>

<h3>Title: CoAst: Validation-Free Contribution Assessment for Federated Learning based on Cross-Round Valuation</h3>
<ul>
<li><strong>Authors: </strong>Hao Wu, Likun Zhang, Shucheng Li, Fengyuan Xu, Sheng Zhong</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2409.02495">https://arxiv.org/abs/2409.02495</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2409.02495">https://arxiv.org/pdf/2409.02495</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2409.02495]] CoAst: Validation-Free Contribution Assessment for Federated Learning based on Cross-Round Valuation(https://arxiv.org/abs/2409.02495)</code><input type="text"></li>
<li><strong>Keywords: </strong>federate</a></li>
<li><strong>Abstract: </strong>In the federated learning (FL) process, since the data held by each participant is different, it is necessary to figure out which participant has a higher contribution to the model performance. Effective contribution assessment can help motivate data owners to participate in the FL training. Research works in this field can be divided into two directions based on whether a validation dataset is required. Validation-based methods need to use representative validation data to measure the model accuracy, which is difficult to obtain in practical FL scenarios. Existing validation-free methods assess the contribution based on the parameters and gradients of local models and the global model in a single training round, which is easily compromised by the stochasticity of model training. In this work, we propose CoAst, a practical method to assess the FL participants' contribution without access to any validation data. The core idea of CoAst involves two aspects: one is to only count the most important part of model parameters through a weights quantization, and the other is a cross-round valuation based on the similarity between the current local parameters and the global parameter updates in several subsequent communication rounds. Extensive experiments show that CoAst has comparable assessment reliability to existing validation-based methods and outperforms existing validation-free methods.</li>
</ul>

<h3>Title: Continual Diffuser (CoD): Mastering Continual Offline Reinforcement Learning with Experience Rehearsal</h3>
<ul>
<li><strong>Authors: </strong>Jifeng Hu, Li Shen, Sili Huang, Zhejian Yang, Hechang Chen, Lichao Sun, Yi Chang, Dacheng Tao</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2409.02512">https://arxiv.org/abs/2409.02512</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2409.02512">https://arxiv.org/pdf/2409.02512</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2409.02512]] Continual Diffuser (CoD): Mastering Continual Offline Reinforcement Learning with Experience Rehearsal(https://arxiv.org/abs/2409.02512)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>Artificial neural networks, especially recent diffusion-based models, have shown remarkable superiority in gaming, control, and QA systems, where the training tasks' datasets are usually static. However, in real-world applications, such as robotic control of reinforcement learning (RL), the tasks are changing, and new tasks arise in a sequential order. This situation poses the new challenge of plasticity-stability trade-off for training an agent who can adapt to task changes and retain acquired knowledge. In view of this, we propose a rehearsal-based continual diffusion model, called Continual Diffuser (CoD), to endow the diffuser with the capabilities of quick adaptation (plasticity) and lasting retention (stability). Specifically, we first construct an offline benchmark that contains 90 tasks from multiple domains. Then, we train the CoD on each task with sequential modeling and conditional generation for making decisions. Next, we preserve a small portion of previous datasets as the rehearsal buffer and replay it to retain the acquired knowledge. Extensive experiments on a series of tasks show CoD can achieve a promising plasticity-stability trade-off and outperform existing diffusion-based methods and other representative baselines on most tasks.</li>
</ul>

<h3>Title: SG-MIM: Structured Knowledge Guided Efficient Pre-training for Dense Prediction</h3>
<ul>
<li><strong>Authors: </strong>Sumin Son, Hyesong Choi, Dongbo Min</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2409.02513">https://arxiv.org/abs/2409.02513</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2409.02513">https://arxiv.org/pdf/2409.02513</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2409.02513]] SG-MIM: Structured Knowledge Guided Efficient Pre-training for Dense Prediction(https://arxiv.org/abs/2409.02513)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>Masked Image Modeling (MIM) techniques have redefined the landscape of computer vision, enabling pre-trained models to achieve exceptional performance across a broad spectrum of tasks. Despite their success, the full potential of MIM-based methods in dense prediction tasks, particularly in depth estimation, remains untapped. Existing MIM approaches primarily rely on single-image inputs, which makes it challenging to capture the crucial structured information, leading to suboptimal performance in tasks requiring fine-grained feature representation. To address these limitations, we propose SG-MIM, a novel Structured knowledge Guided Masked Image Modeling framework designed to enhance dense prediction tasks by utilizing structured knowledge alongside images. SG-MIM employs a lightweight relational guidance framework, allowing it to guide structured knowledge individually at the feature level rather than naively combining at the pixel level within the same architecture, as is common in traditional multi-modal pre-training methods. This approach enables the model to efficiently capture essential information while minimizing discrepancies between pre-training and downstream tasks. Furthermore, SG-MIM employs a selective masking strategy to incorporate structured knowledge, maximizing the synergy between general representation learning and structured knowledge-specific learning. Our method requires no additional annotations, making it a versatile and efficient solution for a wide range of applications. Our evaluations on the KITTI, NYU-v2, and ADE20k datasets demonstrate SG-MIM's superiority in monocular depth estimation and semantic segmentation.</li>
</ul>

<h3>Title: Language is Scary when Over-Analyzed: Unpacking Implied Misogynistic Reasoning with Argumentation Theory-Driven Prompts</h3>
<ul>
<li><strong>Authors: </strong>Arianna Muti, Federico Ruggeri, Khalid Al-Khatib, Alberto Barrón-Cedeño, Tommaso Caselli</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.SI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2409.02519">https://arxiv.org/abs/2409.02519</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2409.02519">https://arxiv.org/pdf/2409.02519</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2409.02519]] Language is Scary when Over-Analyzed: Unpacking Implied Misogynistic Reasoning with Argumentation Theory-Driven Prompts(https://arxiv.org/abs/2409.02519)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>We propose misogyny detection as an Argumentative Reasoning task and we investigate the capacity of large language models (LLMs) to understand the implicit reasoning used to convey misogyny in both Italian and English. The central aim is to generate the missing reasoning link between a message and the implied meanings encoding the misogyny. Our study uses argumentation theory as a foundation to form a collection of prompts in both zero-shot and few-shot settings. These prompts integrate different techniques, including chain-of-thought reasoning and augmented knowledge. Our findings show that LLMs fall short on reasoning capabilities about misogynistic comments and that they mostly rely on their implicit knowledge derived from internalized common stereotypes about women to generate implied assumptions, rather than on inductive reasoning.</li>
</ul>

<h3>Title: Sample what you cant compress</h3>
<ul>
<li><strong>Authors: </strong>Vighnesh Birodkar, Gabriel Barcik, James Lyon, Sergey Ioffe, David Minnen, Joshua V. Dillon</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2409.02529">https://arxiv.org/abs/2409.02529</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2409.02529">https://arxiv.org/pdf/2409.02529</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2409.02529]] Sample what you cant compress(https://arxiv.org/abs/2409.02529)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, generative</a></li>
<li><strong>Abstract: </strong>For learned image representations, basic autoencoders often produce blurry results. Reconstruction quality can be improved by incorporating additional penalties such as adversarial (GAN) and perceptual losses. Arguably, these approaches lack a principled interpretation. Concurrently, in generative settings diffusion has demonstrated a remarkable ability to create crisp, high quality results and has solid theoretical underpinnings (from variational inference to direct study as the Fisher Divergence). Our work combines autoencoder representation learning with diffusion and is, to our knowledge, the first to demonstrate the efficacy of jointly learning a continuous encoder and decoder under a diffusion-based loss. We demonstrate that this approach yields better reconstruction quality as compared to GAN-based autoencoders while being easier to tune. We also show that the resulting representation is easier to model with a latent diffusion model as compared to the representation obtained from a state-of-the-art GAN-based loss. Since our decoder is stochastic, it can generate details not encoded in the otherwise deterministic latent representation; we therefore name our approach "Sample what you can't compress", or SWYCC for short.</li>
</ul>

<h3>Title: Understanding eGFR Trajectories and Kidney Function Decline via Large Multimodal Models</h3>
<ul>
<li><strong>Authors: </strong>Chih-Yuan Li, Jun-Ting Wu, Chan Hsu, Ming-Yen Lin, Yihuang Kang</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2409.02530">https://arxiv.org/abs/2409.02530</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2409.02530">https://arxiv.org/pdf/2409.02530</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2409.02530]] Understanding eGFR Trajectories and Kidney Function Decline via Large Multimodal Models(https://arxiv.org/abs/2409.02530)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, large language model</a></li>
<li><strong>Abstract: </strong>The estimated Glomerular Filtration Rate (eGFR) is an essential indicator of kidney function in clinical practice. Although traditional equations and Machine Learning (ML) models using clinical and laboratory data can estimate eGFR, accurately predicting future eGFR levels remains a significant challenge for nephrologists and ML researchers. Recent advances demonstrate that Large Language Models (LLMs) and Large Multimodal Models (LMMs) can serve as robust foundation models for diverse applications. This study investigates the potential of LMMs to predict future eGFR levels with a dataset consisting of laboratory and clinical values from 50 patients. By integrating various prompting techniques and ensembles of LMMs, our findings suggest that these models, when combined with precise prompts and visual representations of eGFR trajectories, offer predictive performance comparable to existing ML models. This research extends the application of foundation models and suggests avenues for future studies to harness these models in addressing complex medical forecasting challenges.</li>
</ul>

<h3>Title: StyleTokenizer: Defining Image Style by a Single Instance for Controlling Diffusion Models</h3>
<ul>
<li><strong>Authors: </strong>Wen Li, Muyuan Fang, Cheng Zou, Biao Gong, Ruobing Zheng, Meng Wang, Jingdong Chen, Ming Yang</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2409.02543">https://arxiv.org/abs/2409.02543</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2409.02543">https://arxiv.org/pdf/2409.02543</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2409.02543]] StyleTokenizer: Defining Image Style by a Single Instance for Controlling Diffusion Models(https://arxiv.org/abs/2409.02543)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>Despite the burst of innovative methods for controlling the diffusion process, effectively controlling image styles in text-to-image generation remains a challenging task. Many adapter-based methods impose image representation conditions on the denoising process to accomplish image control. However these conditions are not aligned with the word embedding space, leading to interference between image and text control conditions and the potential loss of semantic information from the text prompt. Addressing this issue involves two key challenges. Firstly, how to inject the style representation without compromising the effectiveness of text representation in control. Secondly, how to obtain the accurate style representation from a single reference image. To tackle these challenges, we introduce StyleTokenizer, a zero-shot style control image generation method that aligns style representation with text representation using a style tokenizer. This alignment effectively minimizes the impact on the effectiveness of text prompts. Furthermore, we collect a well-labeled style dataset named Style30k to train a style feature extractor capable of accurately representing style while excluding other content information. Experimental results demonstrate that our method fully grasps the style characteristics of the reference image, generating appealing images that are consistent with both the target image style and text prompt. The code and dataset are available at this https URL.</li>
</ul>

<h3>Title: UniTT-Stereo: Unified Training of Transformer for Enhanced Stereo Matching</h3>
<ul>
<li><strong>Authors: </strong>Soomin Kim, Hyesong Choi, Jihye Ahn, Dongbo Min</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2409.02545">https://arxiv.org/abs/2409.02545</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2409.02545">https://arxiv.org/pdf/2409.02545</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2409.02545]] UniTT-Stereo: Unified Training of Transformer for Enhanced Stereo Matching(https://arxiv.org/abs/2409.02545)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Unlike other vision tasks where Transformer-based approaches are becoming increasingly common, stereo depth estimation is still dominated by convolution-based approaches. This is mainly due to the limited availability of real-world ground truth for stereo matching, which is a limiting factor in improving the performance of Transformer-based stereo approaches. In this paper, we propose UniTT-Stereo, a method to maximize the potential of Transformer-based stereo architectures by unifying self-supervised learning used for pre-training with stereo matching framework based on supervised learning. To be specific, we explore the effectiveness of reconstructing features of masked portions in an input image and at the same time predicting corresponding points in another image from the perspective of locality inductive bias, which is crucial in training models with limited training data. Moreover, to address these challenging tasks of reconstruction-and-prediction, we present a new strategy to vary a masking ratio when training the stereo model with stereo-tailored losses. State-of-the-art performance of UniTT-Stereo is validated on various benchmarks such as ETH3D, KITTI 2012, and KITTI 2015 datasets. Lastly, to investigate the advantages of the proposed approach, we provide a frequency analysis of feature maps and the analysis of locality inductive bias based on attention maps.</li>
</ul>

<h3>Title: Real-Time Dynamic Scale-Aware Fusion Detection Network: Take Road Damage Detection as an example</h3>
<ul>
<li><strong>Authors: </strong>Weichao Pan, Xu Wang, Wenqing Huan</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2409.02546">https://arxiv.org/abs/2409.02546</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2409.02546">https://arxiv.org/pdf/2409.02546</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2409.02546]] Real-Time Dynamic Scale-Aware Fusion Detection Network: Take Road Damage Detection as an example(https://arxiv.org/abs/2409.02546)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction</a></li>
<li><strong>Abstract: </strong>Unmanned Aerial Vehicle (UAV)-based Road Damage Detection (RDD) is important for daily maintenance and safety in cities, especially in terms of significantly reducing labor costs. However, current UAV-based RDD research is still faces many challenges. For example, the damage with irregular size and direction, the masking of damage by the background, and the difficulty of distinguishing damage from the background significantly affect the ability of UAV to detect road damage in daily inspection. To solve these problems and improve the performance of UAV in real-time road damage detection, we design and propose three corresponding modules: a feature extraction module that flexibly adapts to shape and background; a module that fuses multiscale perception and adapts to shape and background ; an efficient downsampling module. Based on these modules, we designed a multi-scale, adaptive road damage detection model with the ability to automatically remove background interference, called Dynamic Scale-Aware Fusion Detection Model (RT-DSAFDet). Experimental results on the UAV-PDD2023 public dataset show that our model RT-DSAFDet achieves a mAP50 of 54.2%, which is 11.1% higher than that of YOLOv10-m, an efficient variant of the latest real-time object detection model YOLOv10, while the amount of parameters is reduced to 1.8M and FLOPs to 4.6G, with a decreased by 88% and 93%, respectively. Furthermore, on the large generalized object detection public dataset MS COCO2017 also shows the superiority of our model with mAP50-95 is the same as YOLOv9-t, but with 0.5% higher mAP50, 10% less parameters volume, and 40% less FLOPs.</li>
</ul>

<h3>Title: ResiLogic: Leveraging Composability and Diversity to Design Fault and Intrusion Resilient Chips</h3>
<ul>
<li><strong>Authors: </strong>Ahmad T. Sheikh, Ali Shoker, Suhaib A. Fahmy, Paulo Esteves-Verissimo</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.AR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2409.02553">https://arxiv.org/abs/2409.02553</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2409.02553">https://arxiv.org/pdf/2409.02553</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2409.02553]] ResiLogic: Leveraging Composability and Diversity to Design Fault and Intrusion Resilient Chips(https://arxiv.org/abs/2409.02553)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack</a></li>
<li><strong>Abstract: </strong>A long-standing challenge is the design of chips resilient to faults and glitches. Both fine-grained gate diversity and coarse-grained modular redundancy have been used in the past. However, these approaches have not been well-studied under other threat models where some stakeholders in the supply chain are untrusted. Increasing digital sovereignty tensions raise concerns regarding the use of foreign off-the-shelf tools and IPs, or off-sourcing fabrication, driving research into the design of resilient chips under this threat model. This paper addresses a threat model considering three pertinent attacks to resilience: distribution, zonal, and compound attacks. To mitigate these attacks, we introduce the \texttt{ResiLogic} framework that exploits \textit{Diversity by Composability}: constructing diverse circuits composed of smaller diverse ones by design. This gives designer the capability to create circuits at design time without requiring extra redundancy in space or cost. Using this approach at different levels of granularity is shown to improve the resilience of circuit design in \texttt{ResiLogic} against the three considered attacks by a factor of five. Additionally, we also make a case to show how E-Graphs can be utilized to generate diverse circuits under given rewrite rules.</li>
</ul>

<h3>Title: Evaluation Study on SAM 2 for Class-agnostic Instance-level Segmentation</h3>
<ul>
<li><strong>Authors: </strong>Tiantian Zhang, Zhangjun Zhou, Jialun Pei</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2409.02567">https://arxiv.org/abs/2409.02567</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2409.02567">https://arxiv.org/pdf/2409.02567</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2409.02567]] Evaluation Study on SAM 2 for Class-agnostic Instance-level Segmentation(https://arxiv.org/abs/2409.02567)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>Segment Anything Model (SAM) has demonstrated powerful zero-shot segmentation performance in natural scenes. The recently released Segment Anything Model 2 (SAM2) has further heightened researchers' expectations towards image segmentation capabilities. To evaluate the performance of SAM2 on class-agnostic instance-level segmentation tasks, we adopt different prompt strategies for SAM2 to cope with instance-level tasks for three relevant scenarios: Salient Instance Segmentation (SIS), Camouflaged Instance Segmentation (CIS), and Shadow Instance Detection (SID). In addition, to further explore the effectiveness of SAM2 in segmenting granular object structures, we also conduct detailed tests on the high-resolution Dichotomous Image Segmentation (DIS) benchmark to assess the fine-grained segmentation capability. Qualitative and quantitative experimental results indicate that the performance of SAM2 varies significantly across different scenarios. Besides, SAM2 is not particularly sensitive to segmenting high-resolution fine details. We hope this technique report can drive the emergence of SAM2-based adapters, aiming to enhance the performance ceiling of large vision models on class-agnostic instance segmentation tasks.</li>
</ul>

<h3>Title: More is More: Addition Bias in Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Luca Santagata, Cristiano De Nobili</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.CY, cs.HC</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2409.02569">https://arxiv.org/abs/2409.02569</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2409.02569">https://arxiv.org/pdf/2409.02569</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2409.02569]] More is More: Addition Bias in Large Language Models(https://arxiv.org/abs/2409.02569)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>In this paper, we investigate the presence of additive bias in Large Language Models (LLMs), drawing a parallel to the cognitive bias observed in humans where individuals tend to favor additive over subtractive changes. Using a series of controlled experiments, we tested various LLMs, including GPT-3.5 Turbo, Claude 3.5 Sonnet, Mistral, Math$\Sigma$tral, and Llama 3.1, on tasks designed to measure their propensity for additive versus subtractive modifications. Our findings demonstrate a significant preference for additive changes across all tested models. For example, in a palindrome creation task, Llama 3.1 favored adding letters 97.85% of the time over removing them. Similarly, in a Lego tower balancing task, GPT-3.5 Turbo chose to add a brick 76.38% of the time rather than remove one. In a text summarization task, Mistral 7B produced longer summaries in 59.40% to 75.10% of cases when asked to improve its own or others' writing. These results indicate that, similar to humans, LLMs exhibit a marked additive bias, which might have implications when LLMs are used on a large scale. Addittive bias might increase resource use and environmental impact, leading to higher economic costs due to overconsumption and waste. This bias should be considered in the development and application of LLMs to ensure balanced and efficient problem-solving approaches.</li>
</ul>

<h3>Title: Advancing Cyber Incident Timeline Analysis Through Rule Based AI and Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Fatma Yasmine Loumachi, Mohamed Chahine Ghanem</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.AI, cs.ET, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2409.02572">https://arxiv.org/abs/2409.02572</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2409.02572">https://arxiv.org/pdf/2409.02572</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2409.02572]] Advancing Cyber Incident Timeline Analysis Through Rule Based AI and Large Language Models(https://arxiv.org/abs/2409.02572)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative, large language model</a></li>
<li><strong>Abstract: </strong>Timeline Analysis (TA) is a key part of Timeline Forensics (TF) in Digital Forensics (DF), focusing primarily on examining and analysing temporal digital artefacts such as timestamps, derived from event logs, file metadata, and other related data to correlate events resulting from cyber incidents and reconstruct their chronological timeline. Traditional tools often struggle to efficiently process the vast volume and variety of data acquired during DF investigations and Incident Response (IR) processes. This paper presents a novel framework, GenDFIR, that combines Rule-Based Artificial Intelligence (R-BAI) algorithms with Large Language Models (LLMs) to advance and automate the TA process. Our approach consists of two main stages (1) We use R-BAI to identify and select anomalous digital artefacts based on predefined rules. (2) The selected artefacts are then converted into embeddings for processing by an LLM with the help of a Retrieval-Augmented Generation (RAG) agent. The LLM consequently leverages its capabilities to perform automated TA on the artefacts and predict potential incident scenarios. To validate our framework, we evaluate GenDFIR performance, efficiency, and reliability using various metrics across synthetic cyber incident simulation scenarios. This paper presents a proof of concept, where the findings demonstrate the significant potential of integrating R-BAI and LLMs for TA. This novel approach highlights the power of Generative AI (GenAI), specifically LLMs, and opens new avenues for advanced threat detection and incident reconstruction, representing a significant step forward in the field.</li>
</ul>

<h3>Title: Solving Video Inverse Problems Using Image Diffusion Models</h3>
<ul>
<li><strong>Authors: </strong>Taesung Kwon, Jong Chul Ye</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2409.02574">https://arxiv.org/abs/2409.02574</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2409.02574">https://arxiv.org/pdf/2409.02574</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2409.02574]] Solving Video Inverse Problems Using Image Diffusion Models(https://arxiv.org/abs/2409.02574)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>Recently, diffusion model-based inverse problem solvers (DIS) have emerged as state-of-the-art approaches for addressing inverse problems, including image super-resolution, deblurring, inpainting, etc. However, their application to video inverse problems arising from spatio-temporal degradation remains largely unexplored due to the challenges in training video diffusion models. To address this issue, here we introduce an innovative video inverse solver that leverages only image diffusion models. Specifically, by drawing inspiration from the success of the recent decomposed diffusion sampler (DDS), our method treats the time dimension of a video as the batch dimension of image diffusion models and solves spatio-temporal optimization problems within denoised spatio-temporal batches derived from each image diffusion model. Moreover, we introduce a batch-consistent diffusion sampling strategy that encourages consistency across batches by synchronizing the stochastic noise components in image diffusion models. Our approach synergistically combines batch-consistent sampling with simultaneous optimization of denoised spatio-temporal batches at each reverse diffusion step, resulting in a novel and efficient diffusion sampling strategy for video inverse problems. Experimental results demonstrate that our method effectively addresses various spatio-temporal degradations in video inverse problems, achieving state-of-the-art reconstructions. Project page: this https URL</li>
</ul>

<h3>Title: SurgTrack: CAD-Free 3D Tracking of Real-world Surgical Instruments</h3>
<ul>
<li><strong>Authors: </strong>Wenwu Guo, Jinlin Wu, Zhen Chen, Qingxiang Zhao, Miao Xu, Zhen Lei, Hongbin Liu</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI, cs.RO</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2409.02598">https://arxiv.org/abs/2409.02598</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2409.02598">https://arxiv.org/pdf/2409.02598</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2409.02598]] SurgTrack: CAD-Free 3D Tracking of Real-world Surgical Instruments(https://arxiv.org/abs/2409.02598)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Vision-based surgical navigation has received increasing attention due to its non-invasive, cost-effective, and flexible advantages. In particular, a critical element of the vision-based navigation system is tracking surgical instruments. Compared with 2D instrument tracking methods, 3D instrument tracking has broader value in clinical practice, but is also more challenging due to weak texture, occlusion, and lack of Computer-Aided Design (CAD) models for 3D registration. To solve these challenges, we propose the SurgTrack, a two-stage 3D instrument tracking method for CAD-free and robust real-world applications. In the first registration stage, we incorporate an Instrument Signed Distance Field (SDF) modeling the 3D representation of instruments, achieving CAD-freed 3D registration. Due to this, we can obtain the location and orientation of instruments in the 3D space by matching the video stream with the registered SDF model. In the second tracking stage, we devise a posture graph optimization module, leveraging the historical tracking results of the posture memory pool to optimize the tracking results and improve the occlusion robustness. Furthermore, we collect the Instrument3D dataset to comprehensively evaluate the 3D tracking of surgical instruments. The extensive experiments validate the superiority and scalability of our SurgTrack, by outperforming the state-of-the-arts with a remarkable improvement. The code and dataset are available at this https URL.</li>
</ul>

<h3>Title: Hypothesizing Missing Causal Variables with LLMs</h3>
<ul>
<li><strong>Authors: </strong>Ivaxi Sheth, Sahar Abdelnabi, Mario Fritz</a></li>
<li><strong>Subjects: </strong>cs.LG, stat.ME</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2409.02604">https://arxiv.org/abs/2409.02604</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2409.02604">https://arxiv.org/pdf/2409.02604</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2409.02604]] Hypothesizing Missing Causal Variables with LLMs(https://arxiv.org/abs/2409.02604)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Scientific discovery is a catalyst for human intellectual advances, driven by the cycle of hypothesis generation, experimental design, data evaluation, and iterative assumption refinement. This process, while crucial, is expensive and heavily dependent on the domain knowledge of scientists to generate hypotheses and navigate the scientific cycle. Central to this is causality, the ability to establish the relationship between the cause and the effect. Motivated by the scientific discovery process, in this work, we formulate a novel task where the input is a partial causal graph with missing variables, and the output is a hypothesis about the missing variables to complete the partial graph. We design a benchmark with varying difficulty levels and knowledge assumptions about the causal graph. With the growing interest in using Large Language Models (LLMs) to assist in scientific discovery, we benchmark open-source and closed models on our testbed. We show the strong ability of LLMs to hypothesize the mediation variables between a cause and its effect. In contrast, they underperform in hypothesizing the cause and effect variables themselves. We also observe surprising results where some of the open-source models outperform the closed GPT-4 model.</li>
</ul>

<h3>Title: A Medical Multimodal Large Language Model for Pediatric Pneumonia</h3>
<ul>
<li><strong>Authors: </strong>Weiwei Tian, Xinyu Huang, Tianhao Cheng, Wen He, Jinwu Fang, Rui Feng, Daoying Geng, Xiaobo Zhang</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2409.02608">https://arxiv.org/abs/2409.02608</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2409.02608">https://arxiv.org/pdf/2409.02608</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2409.02608]] A Medical Multimodal Large Language Model for Pediatric Pneumonia(https://arxiv.org/abs/2409.02608)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Pediatric pneumonia is the leading cause of death among children under five years worldwide, imposing a substantial burden on affected families. Currently, there are three significant hurdles in diagnosing and treating pediatric pneumonia. Firstly, pediatric pneumonia shares similar symptoms with other respiratory diseases, making rapid and accurate differential diagnosis challenging. Secondly, primary hospitals often lack sufficient medical resources and experienced doctors. Lastly, providing personalized diagnostic reports and treatment recommendations is labor-intensive and time-consuming. To tackle these challenges, we proposed a Medical Multimodal Large Language Model for Pediatric Pneumonia (P2Med-MLLM). It was capable of handling diverse clinical tasks, such as generating free-text radiology reports and medical records within a unified framework. Specifically, P2Med-MLLM can process both pure text and image-text data, trained on an extensive and large-scale dataset (P2Med-MD), including real clinical information from 163,999 outpatient and 8,684 inpatient cases. This dataset comprised 2D chest X-ray images, 3D chest CT images, corresponding radiology reports, and outpatient and inpatient records. We designed a three-stage training strategy to enable P2Med-MLLM to comprehend medical knowledge and follow instructions for various clinical tasks. To rigorously evaluate P2Med-MLLM's performance, we developed P2Med-MBench, a benchmark consisting of 642 meticulously verified samples by pediatric pulmonology specialists, covering six clinical decision-support tasks and a balanced variety of diseases. The automated scoring results demonstrated the superiority of P2Med-MLLM. This work plays a crucial role in assisting primary care doctors with prompt disease diagnosis and treatment planning, reducing severe symptom mortality rates, and optimizing the allocation of medical resources.</li>
</ul>

<h3>Title: PUB: Plot Understanding Benchmark and Dataset for Evaluating Large Language Models on Synthetic Visual Data Interpretation</h3>
<ul>
<li><strong>Authors: </strong>Aneta Pawelec, Victoria Sara Wesołowska, Zuzanna Bączek, Piotr Sankowski</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2409.02617">https://arxiv.org/abs/2409.02617</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2409.02617">https://arxiv.org/pdf/2409.02617</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2409.02617]] PUB: Plot Understanding Benchmark and Dataset for Evaluating Large Language Models on Synthetic Visual Data Interpretation(https://arxiv.org/abs/2409.02617)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, large language model</a></li>
<li><strong>Abstract: </strong>The ability of large language models (LLMs) to interpret visual representations of data is crucial for advancing their application in data analysis and decision-making processes. This paper presents a novel synthetic dataset designed to evaluate the proficiency of LLMs in interpreting various forms of data visualizations, including plots like time series, histograms, violins, boxplots, and clusters. Our dataset is generated using controlled parameters to ensure comprehensive coverage of potential real-world scenarios. We employ multimodal text prompts with questions related to visual data in images to benchmark several state-of-the-art models like ChatGPT or Gemini, assessing their understanding and interpretative accuracy. To ensure data integrity, our benchmark dataset is generated automatically, making it entirely new and free from prior exposure to the models being tested. This strategy allows us to evaluate the models' ability to truly interpret and understand the data, eliminating possibility of pre-learned responses, and allowing for an unbiased evaluation of the models' capabilities. We also introduce quantitative metrics to assess the performance of the models, providing a robust and comprehensive evaluation tool. Benchmarking several state-of-the-art LLMs with this dataset reveals varying degrees of success, highlighting specific strengths and weaknesses in interpreting diverse types of visual data. The results provide valuable insights into the current capabilities of LLMs and identify key areas for improvement. This work establishes a foundational benchmark for future research and development aimed at enhancing the visual interpretative abilities of language models. In the future, improved LLMs with robust visual interpretation skills can significantly aid in automated data analysis, scientific research, educational tools, and business intelligence applications.</li>
</ul>

<h3>Title: (Implicit) Ensembles of Ensembles: Epistemic Uncertainty Collapse in Large Models</h3>
<ul>
<li><strong>Authors: </strong>Andreas Kirsch</a></li>
<li><strong>Subjects: </strong>cs.LG, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2409.02628">https://arxiv.org/abs/2409.02628</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2409.02628">https://arxiv.org/pdf/2409.02628</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2409.02628]] (Implicit) Ensembles of Ensembles: Epistemic Uncertainty Collapse in Large Models(https://arxiv.org/abs/2409.02628)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction, transformer</a></li>
<li><strong>Abstract: </strong>Epistemic uncertainty is crucial for safety-critical applications and out-of-distribution detection tasks. Yet, we uncover a paradoxical phenomenon in deep learning models: an epistemic uncertainty collapse as model complexity increases, challenging the assumption that larger models invariably offer better uncertainty quantification. We propose that this stems from implicit ensembling within large models. To support this hypothesis, we demonstrate epistemic uncertainty collapse empirically across various architectures, from explicit ensembles of ensembles and simple MLPs to state-of-the-art vision models, including ResNets and Vision Transformers -- for the latter, we examine implicit ensemble extraction and decompose larger models into diverse sub-models, recovering epistemic uncertainty. We provide theoretical justification for these phenomena and explore their implications for uncertainty estimation.</li>
</ul>

<h3>Title: AdvSecureNet: A Python Toolkit for Adversarial Machine Learning</h3>
<ul>
<li><strong>Authors: </strong>Melih Catal, Manuel Günther</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI, cs.CR, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2409.02629">https://arxiv.org/abs/2409.02629</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2409.02629">https://arxiv.org/pdf/2409.02629</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2409.02629]] AdvSecureNet: A Python Toolkit for Adversarial Machine Learning(https://arxiv.org/abs/2409.02629)</code><input type="text"></li>
<li><strong>Keywords: </strong>secure, defense, attack</a></li>
<li><strong>Abstract: </strong>Machine learning models are vulnerable to adversarial attacks. Several tools have been developed to research these vulnerabilities, but they often lack comprehensive features and flexibility. We introduce AdvSecureNet, a PyTorch based toolkit for adversarial machine learning that is the first to natively support multi-GPU setups for attacks, defenses, and evaluation. It is the first toolkit that supports both CLI and API interfaces and external YAML configuration files to enhance versatility and reproducibility. The toolkit includes multiple attacks, defenses and evaluation metrics. Rigiorous software engineering practices are followed to ensure high code quality and maintainability. The project is available as an open-source project on GitHub at this https URL and installable via PyPI.</li>
</ul>

<h3>Title: Loopy: Taming Audio-Driven Portrait Avatar with Long-Term Motion Dependency</h3>
<ul>
<li><strong>Authors: </strong>Jianwen Jiang, Chao Liang, Jiaqi Yang, Gaojie Lin, Tianyun Zhong, Yanbo Zheng</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2409.02634">https://arxiv.org/abs/2409.02634</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2409.02634">https://arxiv.org/pdf/2409.02634</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2409.02634]] Loopy: Taming Audio-Driven Portrait Avatar with Long-Term Motion Dependency(https://arxiv.org/abs/2409.02634)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>With the introduction of diffusion-based video generation techniques, audio-conditioned human video generation has recently achieved significant breakthroughs in both the naturalness of motion and the synthesis of portrait details. Due to the limited control of audio signals in driving human motion, existing methods often add auxiliary spatial signals to stabilize movements, which may compromise the naturalness and freedom of motion. In this paper, we propose an end-to-end audio-only conditioned video diffusion model named Loopy. Specifically, we designed an inter- and intra-clip temporal module and an audio-to-latents module, enabling the model to leverage long-term motion information from the data to learn natural motion patterns and improving audio-portrait movement correlation. This method removes the need for manually specified spatial motion templates used in existing methods to constrain motion during inference. Extensive experiments show that Loopy outperforms recent audio-driven portrait diffusion models, delivering more lifelike and high-quality results across various scenarios.</li>
</ul>

<h3>Title: MADiff: Motion-Aware Mamba Diffusion Models for Hand Trajectory Prediction on Egocentric Videos</h3>
<ul>
<li><strong>Authors: </strong>Junyi Ma, Xieyuanli Chen, Wentao Bao, Jingyi Xu, Hesheng Wang</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2409.02638">https://arxiv.org/abs/2409.02638</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2409.02638">https://arxiv.org/pdf/2409.02638</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2409.02638]] MADiff: Motion-Aware Mamba Diffusion Models for Hand Trajectory Prediction on Egocentric Videos(https://arxiv.org/abs/2409.02638)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>Understanding human intentions and actions through egocentric videos is important on the path to embodied artificial intelligence. As a branch of egocentric vision techniques, hand trajectory prediction plays a vital role in comprehending human motion patterns, benefiting downstream tasks in extended reality and robot manipulation. However, capturing high-level human intentions consistent with reasonable temporal causality is challenging when only egocentric videos are available. This difficulty is exacerbated under camera egomotion interference and the absence of affordance labels to explicitly guide the optimization of hand waypoint distribution. In this work, we propose a novel hand trajectory prediction method dubbed MADiff, which forecasts future hand waypoints with diffusion models. The devised denoising operation in the latent space is achieved by our proposed motion-aware Mamba, where the camera wearer's egomotion is integrated to achieve motion-driven selective scan (MDSS). To discern the relationship between hands and scenarios without explicit affordance supervision, we leverage a foundation model that fuses visual and language features to capture high-level semantics from video clips. Comprehensive experiments conducted on five public datasets with the existing and our proposed new evaluation metrics demonstrate that MADiff predicts comparably reasonable hand trajectories compared to the state-of-the-art baselines, and achieves real-time performance. We will release our code and pretrained models of MADiff at the project page: this https URL.</li>
</ul>

<h3>Title: OpenFact at CheckThat! 2024: Combining Multiple Attack Methods for Effective Adversarial Text Generation</h3>
<ul>
<li><strong>Authors: </strong>Włodzimierz Lewoniewski, Piotr Stolarski, Milena Stróżyna, Elzbieta Lewańska, Aleksandra Wojewoda, Ewelina Księżniak, Marcin Sawiński</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2409.02649">https://arxiv.org/abs/2409.02649</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2409.02649">https://arxiv.org/pdf/2409.02649</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2409.02649]] OpenFact at CheckThat! 2024: Combining Multiple Attack Methods for Effective Adversarial Text Generation(https://arxiv.org/abs/2409.02649)</code><input type="text"></li>
<li><strong>Keywords: </strong>secure, attack, robust</a></li>
<li><strong>Abstract: </strong>This paper presents the experiments and results for the CheckThat! Lab at CLEF 2024 Task 6: Robustness of Credibility Assessment with Adversarial Examples (InCrediblAE). The primary objective of this task was to generate adversarial examples in five problem domains in order to evaluate the robustness of widely used text classification methods (fine-tuned BERT, BiLSTM, and RoBERTa) when applied to credibility assessment issues. This study explores the application of ensemble learning to enhance adversarial attacks on natural language processing (NLP) models. We systematically tested and refined several adversarial attack methods, including BERT-Attack, Genetic algorithms, TextFooler, and CLARE, on five datasets across various misinformation tasks. By developing modified versions of BERT-Attack and hybrid methods, we achieved significant improvements in attack effectiveness. Our results demonstrate the potential of modification and combining multiple methods to create more sophisticated and effective adversarial attack strategies, contributing to the development of more robust and secure systems.</li>
</ul>

<h3>Title: SoK: Bitcoin Layer Two (L2)</h3>
<ul>
<li><strong>Authors: </strong>Minfeng Qi, Qin Wang, Zhipeng Wang, Manvir Schneider, Tianqing Zhu, Shiping Chen, William Knottenbelt, Thomas Hardjono</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.ET</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2409.02650">https://arxiv.org/abs/2409.02650</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2409.02650">https://arxiv.org/pdf/2409.02650</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2409.02650]] SoK: Bitcoin Layer Two (L2)(https://arxiv.org/abs/2409.02650)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, attack</a></li>
<li><strong>Abstract: </strong>We present the first Systematization of Knowledge (SoK) on constructing Layer Two (L2) solutions for Bitcoin. We carefully examine a representative subset of ongoing Bitcoin L2 solutions (40 out of 335 extensively investigated cases) and provide a concise yet impactful identification of six classic design patterns through two approaches (i.e., modifying transactions \& creating proofs). Notably, we are the first to incorporate the inscription technology (emerged in mid-2023), along with a series of related innovations. We further establish a reference framework that serves as a baseline criterion ideally suited for evaluating the security aspects of Bitcoin L2 solutions, and which can also be extended to broader L2 applications. We apply this framework to evaluate each of the projects we investigated. We find that the inscription-based approaches introduce new functionality (i.e., programability) to Bitcoin systems, whereas existing proof-based solutions primarily address scalability challenges. Our security analysis reveals new attack vectors targeting data/state (availability, verification), assets (withdrawal, recovery), and users (disputes, censorship).</li>
</ul>

<h3>Title: Skip-and-Play: Depth-Driven Pose-Preserved Image Generation for Any Objects</h3>
<ul>
<li><strong>Authors: </strong>Kyungmin Jo, Jaegul Choo</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2409.02653">https://arxiv.org/abs/2409.02653</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2409.02653">https://arxiv.org/pdf/2409.02653</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2409.02653]] Skip-and-Play: Depth-Driven Pose-Preserved Image Generation for Any Objects(https://arxiv.org/abs/2409.02653)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>The emergence of diffusion models has enabled the generation of diverse high-quality images solely from text, prompting subsequent efforts to enhance the controllability of these models. Despite the improvement in controllability, pose control remains limited to specific objects (e.g., humans) or poses (e.g., frontal view) due to the fact that pose is generally controlled via camera parameters (e.g., rotation angle) or keypoints (e.g., eyes, nose). Specifically, camera parameters-conditional pose control models generate unrealistic images depending on the object, owing to the small size of 3D datasets for training. Also, keypoint-based approaches encounter challenges in acquiring reliable keypoints for various objects (e.g., church) or poses (e.g., back view). To address these limitations, we propose depth-based pose control, as depth maps are easily obtainable from a single depth estimation model regardless of objects and poses, unlike camera parameters and keypoints. However, depth-based pose control confronts issues of shape dependency, as depth maps influence not only the pose but also the shape of the generated images. To tackle this issue, we propose Skip-and-Play (SnP), designed via analysis of the impact of three components of depth-conditional ControlNet on the pose and the shape of the generated images. To be specific, based on the analysis, we selectively skip parts of the components to mitigate shape dependency on the depth map while preserving the pose. Through various experiments, we demonstrate the superiority of SnP over baselines and showcase the ability of SnP to generate images of diverse objects and poses. Remarkably, SnP exhibits the ability to generate images even when the objects in the condition (e.g., a horse) and the prompt (e.g., a hedgehog) differ from each other.</li>
</ul>

<h3>Title: PoseTalk: Text-and-Audio-based Pose Control and Motion Refinement for One-Shot Talking Head Generation</h3>
<ul>
<li><strong>Authors: </strong>Jun Ling, Yiwen Wang, Han Xue, Rong Xie, Li Song</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI, cs.MM</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2409.02657">https://arxiv.org/abs/2409.02657</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2409.02657">https://arxiv.org/pdf/2409.02657</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2409.02657]] PoseTalk: Text-and-Audio-based Pose Control and Motion Refinement for One-Shot Talking Head Generation(https://arxiv.org/abs/2409.02657)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>While previous audio-driven talking head generation (THG) methods generate head poses from driving audio, the generated poses or lips cannot match the audio well or are not editable. In this study, we propose \textbf{PoseTalk}, a THG system that can freely generate lip-synchronized talking head videos with free head poses conditioned on text prompts and audio. The core insight of our method is using head pose to connect visual, linguistic, and audio signals. First, we propose to generate poses from both audio and text prompts, where the audio offers short-term variations and rhythm correspondence of the head movements and the text prompts describe the long-term semantics of head motions. To achieve this goal, we devise a Pose Latent Diffusion (PLD) model to generate motion latent from text prompts and audio cues in a pose latent space. Second, we observe a loss-imbalance problem: the loss for the lip region contributes less than 4\% of the total reconstruction loss caused by both pose and lip, making optimization lean towards head movements rather than lip shapes. To address this issue, we propose a refinement-based learning strategy to synthesize natural talking videos using two cascaded networks, i.e., CoarseNet, and RefineNet. The CoarseNet estimates coarse motions to produce animated images in novel poses and the RefineNet focuses on learning finer lip motions by progressively estimating lip motions from low-to-high resolutions, yielding improved lip-synchronization performance. Experiments demonstrate our pose prediction strategy achieves better pose diversity and realness compared to text-only or audio-only, and our video generator model outperforms state-of-the-art methods in synthesizing talking videos with natural head motions. Project: this https URL.</li>
</ul>

<h3>Title: Standing on the Shoulders of Giants: Reprogramming Visual-Language Model for General Deepfake Detection</h3>
<ul>
<li><strong>Authors: </strong>Kaiqing Lin, Yuzhen Lin, Weixiang Li, Taiping Yao, Bin Li</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2409.02664">https://arxiv.org/abs/2409.02664</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2409.02664">https://arxiv.org/pdf/2409.02664</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2409.02664]] Standing on the Shoulders of Giants: Reprogramming Visual-Language Model for General Deepfake Detection(https://arxiv.org/abs/2409.02664)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>The proliferation of deepfake faces poses huge potential negative impacts on our daily lives. Despite substantial advancements in deepfake detection over these years, the generalizability of existing methods against forgeries from unseen datasets or created by emerging generative models remains constrained. In this paper, inspired by the zero-shot advantages of Vision-Language Models (VLMs), we propose a novel approach that repurposes a well-trained VLM for general deepfake detection. Motivated by the model reprogramming paradigm that manipulates the model prediction via data perturbations, our method can reprogram a pretrained VLM model (e.g., CLIP) solely based on manipulating its input without tuning the inner parameters. Furthermore, we insert a pseudo-word guided by facial identity into the text prompt. Extensive experiments on several popular benchmarks demonstrate that (1) the cross-dataset and cross-manipulation performances of deepfake detection can be significantly and consistently improved (e.g., over 88% AUC in cross-dataset setting from FF++ to WildDeepfake) using a pre-trained CLIP model with our proposed reprogramming method; (2) our superior performances are at less cost of trainable parameters, making it a promising approach for real-world applications.</li>
</ul>

<h3>Title: Creating Domain-Specific Translation Memories for Machine Translation Fine-tuning: The TRENCARD Bilingual Cardiology Corpus</h3>
<ul>
<li><strong>Authors: </strong>Gokhan Dogru</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2409.02667">https://arxiv.org/abs/2409.02667</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2409.02667">https://arxiv.org/pdf/2409.02667</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2409.02667]] Creating Domain-Specific Translation Memories for Machine Translation Fine-tuning: The TRENCARD Bilingual Cardiology Corpus(https://arxiv.org/abs/2409.02667)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>This article investigates how translation memories (TM) can be created by translators or other language professionals in order to compile domain-specific parallel corpora , which can then be used in different scenarios, such as machine translation training and fine-tuning, TM leveraging, and/or large language model fine-tuning. The article introduces a semi-automatic TM preparation methodology leveraging primarily translation tools used by translators in favor of data quality and control by the translators. This semi-automatic methodology is then used to build a cardiology-based Turkish -> English corpus from bilingual abstracts of Turkish cardiology journals. The resulting corpus called TRENCARD Corpus has approximately 800,000 source words and 50,000 sentences. Using this methodology, translators can build their custom TMs in a reasonable time and use them in their bilingual data requiring tasks.</li>
</ul>

<h3>Title: Independence Constrained Disentangled Representation Learning from Epistemological Perspective</h3>
<ul>
<li><strong>Authors: </strong>Ruoyu Wang, Lina Yao</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2409.02672">https://arxiv.org/abs/2409.02672</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2409.02672">https://arxiv.org/pdf/2409.02672</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2409.02672]] Independence Constrained Disentangled Representation Learning from Epistemological Perspective(https://arxiv.org/abs/2409.02672)</code><input type="text"></li>
<li><strong>Keywords: </strong>explainability, generative</a></li>
<li><strong>Abstract: </strong>Disentangled Representation Learning aims to improve the explainability of deep learning methods by training a data encoder that identifies semantically meaningful latent variables in the data generation process. Nevertheless, there is no consensus regarding a universally accepted definition for the objective of disentangled representation learning. In particular, there is a considerable amount of discourse regarding whether should the latent variables be mutually independent or not. In this paper, we first investigate these arguments on the interrelationships between latent variables by establishing a conceptual bridge between Epistemology and Disentangled Representation Learning. Then, inspired by these interdisciplinary concepts, we introduce a two-level latent space framework to provide a general solution to the prior arguments on this issue. Finally, we propose a novel method for disentangled representation learning by employing an integration of mutual information constraint and independence constraint within the Generative Adversarial Network (GAN) framework. Experimental results demonstrate that our proposed method consistently outperforms baseline approaches in both quantitative and qualitative evaluations. The method exhibits strong performance across multiple commonly used metrics and demonstrates a great capability in disentangling various semantic factors, leading to an improved quality of controllable generation, which consequently benefits the explainability of the algorithm.</li>
</ul>

<h3>Title: Rethinking HTG Evaluation: Bridging Generation and Recognition</h3>
<ul>
<li><strong>Authors: </strong>Konstantina Nikolaidou, George Retsinas, Giorgos Sfikas, Marcus Liwicki</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2409.02683">https://arxiv.org/abs/2409.02683</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2409.02683">https://arxiv.org/pdf/2409.02683</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2409.02683]] Rethinking HTG Evaluation: Bridging Generation and Recognition(https://arxiv.org/abs/2409.02683)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, generative</a></li>
<li><strong>Abstract: </strong>The evaluation of generative models for natural image tasks has been extensively studied. Similar protocols and metrics are used in cases with unique particularities, such as Handwriting Generation, even if they might not be completely appropriate. In this work, we introduce three measures tailored for HTG evaluation, $ \text{HTG}_{\text{HTR}} $, $ \text{HTG}_{\text{style}} $, and $ \text{HTG}_{\text{OOV}} $, and argue that they are more expedient to evaluate the quality of generated handwritten images. The metrics rely on the recognition error/accuracy of Handwriting Text Recognition and Writer Identification models and emphasize writing style, textual content, and diversity as the main aspects that adhere to the content of handwritten images. We conduct comprehensive experiments on the IAM handwriting database, showcasing that widely used metrics such as FID fail to properly quantify the diversity and the practical utility of generated handwriting samples. Our findings show that our metrics are richer in information and underscore the necessity of standardized evaluation protocols in HTG. The proposed metrics provide a more robust and informative protocol for assessing HTG quality, contributing to improved performance in HTR. Code for the evaluation protocol is available at: this https URL.</li>
</ul>

<h3>Title: Deconfounded Causality-aware Parameter-Efficient Fine-Tuning for Problem-Solving Improvement of LLMs</h3>
<ul>
<li><strong>Authors: </strong>Ruoyu Wang, Xiaoxuan Li, Lina Yao</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2409.02686">https://arxiv.org/abs/2409.02686</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2409.02686">https://arxiv.org/pdf/2409.02686</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2409.02686]] Deconfounded Causality-aware Parameter-Efficient Fine-Tuning for Problem-Solving Improvement of LLMs(https://arxiv.org/abs/2409.02686)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large Language Models (LLMs) have demonstrated remarkable efficiency in tackling various tasks based on human instructions, but recent studies reveal that these models often fail to achieve satisfactory results on questions involving reasoning, such as mathematics or physics questions. This phenomenon is usually attributed to the uncertainty regarding whether these models could genuinely comprehend the knowledge embedded in the text or merely learn to replicate the token distribution without a true understanding of the content. In this paper, we delve into this problem and aim to enhance the reasoning capabilities of LLMs. First, we investigate if the model has genuine reasoning capabilities by visualizing the text generation process at the attention and representation level. Then, we formulate the reasoning process of LLMs into a causal framework, which provides a formal explanation of the problems we observe in the visualization. Finally, building upon this causal framework, we propose Deconfounded Causal Adaptation (DCA), a novel parameter-efficient fine-tuning (PEFT) method to enhance the model's reasoning capabilities by encouraging the model to extract the general problem-solving skills and apply these skills to different questions. Experiments show that our method outperforms the baseline consistently across multiple benchmarks, and with only 1.2M tunable parameters, we achieve better or comparable results to other fine-tuning methods. This demonstrates the effectiveness and efficiency of our method in improving the overall accuracy and reliability of LLMs.</li>
</ul>

<h3>Title: CLDA: Collaborative Learning for Enhanced Unsupervised Domain Adaptation</h3>
<ul>
<li><strong>Authors: </strong>Minhee Cho, Hyesong Choi, Hayeon Jo, Dongbo Min</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2409.02699">https://arxiv.org/abs/2409.02699</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2409.02699">https://arxiv.org/pdf/2409.02699</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2409.02699]] CLDA: Collaborative Learning for Enhanced Unsupervised Domain Adaptation(https://arxiv.org/abs/2409.02699)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>Unsupervised Domain Adaptation (UDA) endeavors to bridge the gap between a model trained on a labeled source domain and its deployment in an unlabeled target domain. However, current high-performance models demand significant resources, resulting in prohibitive deployment costs and highlighting the need for small yet effective models. For UDA of lightweight models, Knowledge Distillation (KD) in a Teacher-Student framework can be a common approach, but we find that domain shift in UDA leads to a significant increase in non-salient parameters in the teacher model, degrading model's generalization ability and transferring misleading information to the student model. Interestingly, we observed that this phenomenon occurs considerably less in the student model. Driven by this insight, we introduce Collaborative Learning, a method that updates the teacher's non-salient parameters using the student model and at the same time enhance the student's performance using the updated teacher model. Experiments across various tasks and datasets show consistent performance improvements for both student and teacher models. For example, in semantic segmentation, CLDA achieves an improvement of +0.7% mIoU for teacher and +1.4% mIoU for student compared to the baseline model in the GTA to Cityscapes. In the Synthia to Cityscapes, it achieves an improvement of +0.8% mIoU for teacher and +2.0% mIoU for student.</li>
</ul>

<h3>Title: Recoverable Anonymization for Pose Estimation: A Privacy-Enhancing Approach</h3>
<ul>
<li><strong>Authors: </strong>Wenjun Huang, Yang Ni, Arghavan Rezvani, SungHeon Jeong, Hanning Chen, Yezi Liu, Fei Wen, Mohsen Imani</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.CR, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2409.02715">https://arxiv.org/abs/2409.02715</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2409.02715">https://arxiv.org/pdf/2409.02715</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2409.02715]] Recoverable Anonymization for Pose Estimation: A Privacy-Enhancing Approach(https://arxiv.org/abs/2409.02715)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, protect, robust</a></li>
<li><strong>Abstract: </strong>Human pose estimation (HPE) is crucial for various applications. However, deploying HPE algorithms in surveillance contexts raises significant privacy concerns due to the potential leakage of sensitive personal information (SPI) such as facial features, and ethnicity. Existing privacy-enhancing methods often compromise either privacy or performance, or they require costly additional modalities. We propose a novel privacy-enhancing system that generates privacy-enhanced portraits while maintaining high HPE performance. Our key innovations include the reversible recovery of SPI for authorized personnel and the preservation of contextual information. By jointly optimizing a privacy-enhancing module, a privacy recovery module, and a pose estimator, our system ensures robust privacy protection, efficient SPI recovery, and high-performance HPE. Experimental results demonstrate the system's robust performance in privacy enhancement, SPI recovery, and HPE.</li>
</ul>

<h3>Title: Alignment-Aware Model Extraction Attacks on Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Zi Liang, Qingqing Ye, Yanyun Wang, Sen Zhang, Yaxin Xiao, Ronghua Li, Jianliang Xu, Haibo Hu</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2409.02718">https://arxiv.org/abs/2409.02718</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2409.02718">https://arxiv.org/pdf/2409.02718</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2409.02718]] Alignment-Aware Model Extraction Attacks on Large Language Models(https://arxiv.org/abs/2409.02718)</code><input type="text"></li>
<li><strong>Keywords: </strong>protect, attack, steal, extraction, watermark, large language model</a></li>
<li><strong>Abstract: </strong>Model extraction attacks (MEAs) on large language models (LLMs) have received increasing research attention lately. Existing attack methods on LLMs inherit the extraction strategies from those designed for deep neural networks (DNNs) yet neglect the inconsistency of training tasks between MEA and LLMs' alignments. As such, they result in poor attack performances. To tackle this issue, we present Locality Reinforced Distillation (LoRD), a novel model extraction attack algorithm specifically for LLMs. In particular, we design a policy-gradient-style training task, which utilizes victim models' responses as a signal to guide the crafting of preference for the local model. Theoretical analysis has shown that i) LoRD's convergence procedure in MEAs is consistent with the alignments of LLMs, and ii) LoRD can reduce query complexity while mitigating watermark protection through exploration-based stealing. Extensive experiments on domain-specific extractions demonstrate the superiority of our method by examining the extraction of various state-of-the-art commercial LLMs.</li>
</ul>

<h3>Title: GET-UP: GEomeTric-aware Depth Estimation with Radar Points UPsampling</h3>
<ul>
<li><strong>Authors: </strong>Huawei Sun, Zixu Wang, Hao Feng, Julius Ott, Lorenzo Servadei, Robert Wille</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI, eess.SP</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2409.02720">https://arxiv.org/abs/2409.02720</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2409.02720">https://arxiv.org/pdf/2409.02720</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2409.02720]] GET-UP: GEomeTric-aware Depth Estimation with Radar Points UPsampling(https://arxiv.org/abs/2409.02720)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, extraction</a></li>
<li><strong>Abstract: </strong>Depth estimation plays a pivotal role in autonomous driving, facilitating a comprehensive understanding of the vehicle's 3D surroundings. Radar, with its robustness to adverse weather conditions and capability to measure distances, has drawn significant interest for radar-camera depth estimation. However, existing algorithms process the inherently noisy and sparse radar data by projecting 3D points onto the image plane for pixel-level feature extraction, overlooking the valuable geometric information contained within the radar point cloud. To address this gap, we propose GET-UP, leveraging attention-enhanced Graph Neural Networks (GNN) to exchange and aggregate both 2D and 3D information from radar data. This approach effectively enriches the feature representation by incorporating spatial relationships compared to traditional methods that rely only on 2D feature extraction. Furthermore, we incorporate a point cloud upsampling task to densify the radar point cloud, rectify point positions, and derive additional 3D features under the guidance of lidar data. Finally, we fuse radar and camera features during the decoding phase for depth estimation. We benchmark our proposed GET-UP on the nuScenes dataset, achieving state-of-the-art performance with a 15.3% and 14.7% improvement in MAE and RMSE over the previously best-performing model.</li>
</ul>

<h3>Title: Pooling And Attention: What Are Effective Designs For LLm-Based Embedding Models?</h3>
<ul>
<li><strong>Authors: </strong>Yixuan Tang, Yi Yang</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.IR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2409.02727">https://arxiv.org/abs/2409.02727</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2409.02727">https://arxiv.org/pdf/2409.02727</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2409.02727]] Pooling And Attention: What Are Effective Designs For LLm-Based Embedding Models?(https://arxiv.org/abs/2409.02727)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative, large language model</a></li>
<li><strong>Abstract: </strong>The significant advancements of Large Language Models (LLMs) in generative tasks have led to a growing body of work exploring LLM-based embedding models. While these models, employing different pooling and attention strategies, have achieved state-of-the-art performance on public embedding benchmarks, questions still arise about what constitutes an effective design for LLM-based embedding models. However, these models are often trained on different datasets, using different LLM base models or training settings. Moreover, evaluations on public embedding benchmarks often fail to report statistical significance, making it difficult to determine which designs truly contribute to final performance. This complicates the process for practitioners seeking optimal training recipes for LLM-based embedding models. In this study, we conduct a large-scale experiment by training a series of LLM-based embedding models using the same training data and base model but differing in their pooling and attention strategies. The results show that there is no one-size-fits-all solution: while bidirectional attention and an additional trainable pooling layer outperform in text similarity and information retrieval tasks, they do not significantly surpass simpler designs like EOS-last token pooling and default causal attention in clustering and classification tasks. Furthermore, we propose a new pooling strategy, Multi-Layers Trainable Pooling, which transforms the outputs of all hidden layers, rather than just the last layer, using a cross-attention network. This method proves to be statistically superior in text similarity and retrieval tasks compared to existing pooling methods. Overall, this paper sheds light on effective training strategies for LLM-based embedding models.</li>
</ul>

<h3>Title: Task-Oriented Communication for Graph Data: A Graph Information Bottleneck Approach</h3>
<ul>
<li><strong>Authors: </strong>Shujing Li, Yanhu Wang, Shuaishuai Guo, Chenyuan Feng</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.SI, eess.SP</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2409.02728">https://arxiv.org/abs/2409.02728</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2409.02728">https://arxiv.org/pdf/2409.02728</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2409.02728]] Task-Oriented Communication for Graph Data: A Graph Information Bottleneck Approach(https://arxiv.org/abs/2409.02728)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Graph data, essential in fields like knowledge representation and social networks, often involves large networks with many nodes and edges. Transmitting these graphs can be highly inefficient due to their size and redundancy for specific tasks. This paper introduces a method to extract a smaller, task-focused subgraph that maintains key information while reducing communication overhead. Our approach utilizes graph neural networks (GNNs) and the graph information bottleneck (GIB) principle to create a compact, informative, and robust graph representation suitable for transmission. The challenge lies in the irregular structure of graph data, making GIB optimization complex. We address this by deriving a tractable variational upper bound for the objective function. Additionally, we propose the VQ-GIB mechanism, integrating vector quantization (VQ) to convert subgraph representations into a discrete codebook sequence, compatible with existing digital communication systems. Our experiments show that this GIB-based method significantly lowers communication costs while preserving essential task-related information. The approach demonstrates robust performance across various communication channels, suitable for both continuous and discrete systems.</li>
</ul>

<h3>Title: MedUnA: Language guided Unsupervised Adaptation of Vision-Language Models for Medical Image Classification</h3>
<ul>
<li><strong>Authors: </strong>Umaima Rahman, Raza Imam, Dwarikanath Mahapatra, Boulbaba Ben Amor</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2409.02729">https://arxiv.org/abs/2409.02729</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2409.02729">https://arxiv.org/pdf/2409.02729</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2409.02729]] MedUnA: Language guided Unsupervised Adaptation of Vision-Language Models for Medical Image Classification(https://arxiv.org/abs/2409.02729)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>In medical image classification, supervised learning is challenging due to the lack of labeled medical images. Contrary to the traditional \textit{modus operandi} of pre-training followed by fine-tuning, this work leverages the visual-textual alignment within Vision-Language models (\texttt{VLMs}) to facilitate the unsupervised learning. Specifically, we propose \underline{Med}ical \underline{Un}supervised \underline{A}daptation (\texttt{MedUnA}), constituting two-stage training: Adapter Pre-training, and Unsupervised Learning. In the first stage, we use descriptions generated by a Large Language Model (\texttt{LLM}) corresponding to class labels, which are passed through the text encoder \texttt{BioBERT}. The resulting text embeddings are then aligned with the class labels by training a lightweight \texttt{adapter}. We choose \texttt{\texttt{LLMs}} because of their capability to generate detailed, contextually relevant descriptions to obtain enhanced text embeddings. In the second stage, the trained \texttt{adapter} is integrated with the visual encoder of \texttt{MedCLIP}. This stage employs a contrastive entropy-based loss and prompt tuning to align visual embeddings. We incorporate self-entropy minimization into the overall training objective to ensure more confident embeddings, which are crucial for effective unsupervised learning and alignment. We evaluate the performance of \texttt{MedUnA} on three different kinds of data modalities - chest X-rays, eye fundus and skin lesion images. The results demonstrate significant accuracy gain on average compared to the baselines across different datasets, highlighting the efficacy of our approach.</li>
</ul>

<h3>Title: RTFM: How hard are IoT platform providers making it for their developers?</h3>
<ul>
<li><strong>Authors: </strong>Andrew Baldrian, Joseph Hallett</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2409.02735">https://arxiv.org/abs/2409.02735</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2409.02735">https://arxiv.org/pdf/2409.02735</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2409.02735]] RTFM: How hard are IoT platform providers making it for their developers?(https://arxiv.org/abs/2409.02735)</code><input type="text"></li>
<li><strong>Keywords: </strong>secure, security</a></li>
<li><strong>Abstract: </strong>Internet of Things (IoT) devices routinely have security issues, but are the platform designers providing enough support to IoT developers for them to easily implement security features for their platforms? We surveyed the documentation, code and guidance from nine IoT manufacturers to look at what guidance they provided for implementing three security features required by several security standards (secure boot, device identity keys and unique per device passwords). We find that more needs to be done to support developers if we want them to adopt security features -- especially in the face of incoming legislation that will require developers to implement them.</li>
</ul>

<h3>Title: Unifying Causal Representation Learning with the Invariance Principle</h3>
<ul>
<li><strong>Authors: </strong>Dingling Yao, Dario Rancati, Riccardo Cadei, Marco Fumero, Francesco Locatello</a></li>
<li><strong>Subjects: </strong>cs.LG, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2409.02772">https://arxiv.org/abs/2409.02772</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2409.02772">https://arxiv.org/pdf/2409.02772</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2409.02772]] Unifying Causal Representation Learning with the Invariance Principle(https://arxiv.org/abs/2409.02772)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Causal representation learning aims at recovering latent causal variables from high-dimensional observations to solve causal downstream tasks, such as predicting the effect of new interventions or more robust classification. A plethora of methods have been developed, each tackling carefully crafted problem settings that lead to different types of identifiability. The folklore is that these different settings are important, as they are often linked to different rungs of Pearl's causal hierarchy, although not all neatly fit. Our main contribution is to show that many existing causal representation learning approaches methodologically align the representation to known data symmetries. Identification of the variables is guided by equivalence classes across different data pockets that are not necessarily causal. This result suggests important implications, allowing us to unify many existing approaches in a single method that can mix and match different assumptions, including non-causal ones, based on the invariances relevant to our application. It also significantly benefits applicability, which we demonstrate by improving treatment effect estimation on real-world high-dimensional ecological data. Overall, this paper clarifies the role of causality assumptions in the discovery of causal variables and shifts the focus to preserving data symmetries.</li>
</ul>

<h3>Title: UnLearning from Experience to Avoid Spurious Correlations</h3>
<ul>
<li><strong>Authors: </strong>Jeff Mitchell, Jesús Martínez del Rincón, Niall McLaughlin</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2409.02792">https://arxiv.org/abs/2409.02792</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2409.02792">https://arxiv.org/pdf/2409.02792</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2409.02792]] UnLearning from Experience to Avoid Spurious Correlations(https://arxiv.org/abs/2409.02792)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>While deep neural networks can achieve state-of-the-art performance in many tasks, these models are more fragile than they appear. They are prone to learning spurious correlations in their training data, leading to surprising failure cases. In this paper, we propose a new approach that addresses the issue of spurious correlations: UnLearning from Experience (ULE). Our method is based on using two classification models trained in parallel: student and teacher models. Both models receive the same batches of training data. The student model is trained with no constraints and pursues the spurious correlations in the data. The teacher model is trained to solve the same classification problem while avoiding the mistakes of the student model. As training is done in parallel, the better the student model learns the spurious correlations, the more robust the teacher model becomes. The teacher model uses the gradient of the student's output with respect to its input to unlearn mistakes made by the student. We show that our method is effective on the Waterbirds, CelebA, Spawrious and UrbanCars datasets.</li>
</ul>

<h3>Title: Towards a Unified View of Preference Learning for Large Language Models: A Survey</h3>
<ul>
<li><strong>Authors: </strong>Bofei Gao, Feifan Song, Yibo Miao, Zefan Cai, Zhe Yang, Liang Chen, Helan Hu, Runxin Xu, Qingxiu Dong, Ce Zheng, Wen Xiao, Ge Zhang, Daoguang Zan, Keming Lu, Bowen Yu, Dayiheng Liu, Zeyu Cui, Jian Yang, Lei Sha, Houfeng Wang, Zhifang Sui, Peiyi Wang, Tianyu Liu, Baobao Chang</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2409.02795">https://arxiv.org/abs/2409.02795</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2409.02795">https://arxiv.org/pdf/2409.02795</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2409.02795]] Towards a Unified View of Preference Learning for Large Language Models: A Survey(https://arxiv.org/abs/2409.02795)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large Language Models (LLMs) exhibit remarkably powerful capabilities. One of the crucial factors to achieve success is aligning the LLM's output with human preferences. This alignment process often requires only a small amount of data to efficiently enhance the LLM's performance. While effective, research in this area spans multiple domains, and the methods involved are relatively complex to understand. The relationships between different methods have been under-explored, limiting the development of the preference alignment. In light of this, we break down the existing popular alignment strategies into different components and provide a unified framework to study the current alignment strategies, thereby establishing connections among them. In this survey, we decompose all the strategies in preference learning into four components: model, data, feedback, and algorithm. This unified view offers an in-depth understanding of existing alignment algorithms and also opens up possibilities to synergize the strengths of different strategies. Furthermore, we present detailed working examples of prevalent existing algorithms to facilitate a comprehensive understanding for the readers. Finally, based on our unified perspective, we explore the challenges and future research directions for aligning large language models with human preferences.</li>
</ul>

<h3>Title: Boosting Certificate Robustness for Time Series Classification with Efficient Self-Ensemble</h3>
<ul>
<li><strong>Authors: </strong>Chang Dong, Zhengyang Li, Liangwei Zheng, Weitong Chen, Wei Emma Zhang</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CR, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2409.02802">https://arxiv.org/abs/2409.02802</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2409.02802">https://arxiv.org/pdf/2409.02802</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2409.02802]] Boosting Certificate Robustness for Time Series Classification with Efficient Self-Ensemble(https://arxiv.org/abs/2409.02802)</code><input type="text"></li>
<li><strong>Keywords: </strong>defense, attack, robust</a></li>
<li><strong>Abstract: </strong>Recently, the issue of adversarial robustness in the time series domain has garnered significant attention. However, the available defense mechanisms remain limited, with adversarial training being the predominant approach, though it does not provide theoretical guarantees. Randomized Smoothing has emerged as a standout method due to its ability to certify a provable lower bound on robustness radius under $\ell_p$-ball attacks. Recognizing its success, research in the time series domain has started focusing on these aspects. However, existing research predominantly focuses on time series forecasting, or under the non-$\ell_p$ robustness in statistic feature augmentation for time series classification~(TSC). Our review found that Randomized Smoothing performs modestly in TSC, struggling to provide effective assurances on datasets with poor robustness. Therefore, we propose a self-ensemble method to enhance the lower bound of the probability confidence of predicted labels by reducing the variance of classification margins, thereby certifying a larger radius. This approach also addresses the computational overhead issue of Deep Ensemble~(DE) while remaining competitive and, in some cases, outperforming it in terms of robustness. Both theoretical analysis and experimental results validate the effectiveness of our method, demonstrating superior performance in robustness testing compared to baseline approaches.</li>
</ul>

<h3>Title: MMMU-Pro: A More Robust Multi-discipline Multimodal Understanding Benchmark</h3>
<ul>
<li><strong>Authors: </strong>Xiang Yue, Tianyu Zheng, Yuansheng Ni, Yubo Wang, Kai Zhang, Shengbang Tong, Yuxuan Sun, Ming Yin, Botao Yu, Ge Zhang, Huan Sun, Yu Su, Wenhu Chen, Graham Neubig</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2409.02813">https://arxiv.org/abs/2409.02813</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2409.02813">https://arxiv.org/pdf/2409.02813</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2409.02813]] MMMU-Pro: A More Robust Multi-discipline Multimodal Understanding Benchmark(https://arxiv.org/abs/2409.02813)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>This paper introduces MMMU-Pro, a robust version of the Massive Multi-discipline Multimodal Understanding and Reasoning (MMMU) benchmark. MMMU-Pro rigorously assesses multimodal models' true understanding and reasoning capabilities through a three-step process based on MMMU: (1) filtering out questions answerable by text-only models, (2) augmenting candidate options, and (3) introducing a vision-only input setting where questions are embedded within images. This setting challenges AI to truly "see" and "read" simultaneously, testing a fundamental human cognitive skill of seamlessly integrating visual and textual information. Results show that model performance is substantially lower on MMMU-Pro than on MMMU, ranging from 16.8% to 26.9% across models. We explore the impact of OCR prompts and Chain of Thought (CoT) reasoning, finding that OCR prompts have minimal effect while CoT generally improves performance. MMMU-Pro provides a more rigorous evaluation tool, closely mimicking real-world scenarios and offering valuable directions for future research in multimodal AI.</li>
</ul>

<h3>Title: Obsidian: Cooperative State-Space Exploration for Performant Inference on Secure ML Accelerators</h3>
<ul>
<li><strong>Authors: </strong>Sarbartha Banerjee, Shijia Wei, Prakash Ramrakhyani, Mohit Tiwari</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2409.02817">https://arxiv.org/abs/2409.02817</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2409.02817">https://arxiv.org/pdf/2409.02817</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2409.02817]] Obsidian: Cooperative State-Space Exploration for Performant Inference on Secure ML Accelerators(https://arxiv.org/abs/2409.02817)</code><input type="text"></li>
<li><strong>Keywords: </strong>secure, security</a></li>
<li><strong>Abstract: </strong>Trusted execution environments (TEEs) for machine learning accelerators are indispensable in secure and efficient ML inference. Optimizing workloads through state-space exploration for the accelerator architectures improves performance and energy consumption. However, such explorations are expensive and slow due to the large search space. Current research has to use fast analytical models that forego critical hardware details and cross-layer opportunities unique to the hardware security primitives. While cycle-accurate models can theoretically reach better designs, their high runtime cost restricts them to a smaller state space. We present Obsidian, an optimization framework for finding the optimal mapping from ML kernels to a secure ML accelerator. Obsidian addresses the above challenge by exploring the state space using analytical and cycle-accurate models cooperatively. The two main exploration components include: (1) A secure accelerator analytical model, that includes the effect of secure hardware while traversing the large mapping state space and produce the best m model mappings; (2) A compiler profiling step on a cycle-accurate model, that captures runtime bottlenecks to further improve execution runtime, energy and resource utilization and find the optimal model mapping. We compare our results to a baseline secure accelerator, comprising of the state-of-the-art security schemes obtained from guardnn [ 33 ] and sesame [11]. The analytical model reduces the inference latency by 20.5% for a cloud and 8.4% for an edge deployment with an energy improvement of 24% and 19% respectively. The cycle-accurate model, further reduces the latency by 9.1% for a cloud and 12.2% for an edge with an energy improvement of 13.8% and 13.1%.</li>
</ul>

<h3>Title: Deep Learning Meets Satellite Images -- An Evaluation on Handcrafted and Learning-based Features for Multi-date Satellite Stereo Images</h3>
<ul>
<li><strong>Authors: </strong>Shuang Song, Luca Morelli, Xinyi Wu, Rongjun Qin, Hessah Albanwan, Fabio Remondino</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2409.02825">https://arxiv.org/abs/2409.02825</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2409.02825">https://arxiv.org/pdf/2409.02825</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2409.02825]] Deep Learning Meets Satellite Images -- An Evaluation on Handcrafted and Learning-based Features for Multi-date Satellite Stereo Images(https://arxiv.org/abs/2409.02825)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction</a></li>
<li><strong>Abstract: </strong>A critical step in the digital surface models(DSM) generation is feature matching. Off-track (or multi-date) satellite stereo images, in particular, can challenge the performance of feature matching due to spectral distortions between images, long baseline, and wide intersection angles. Feature matching methods have evolved over the years from handcrafted methods (e.g., SIFT) to learning-based methods (e.g., SuperPoint and SuperGlue). In this paper, we compare the performance of different features, also known as feature extraction and matching methods, applied to satellite imagery. A wide range of stereo pairs(~500) covering two separate study sites are used. SIFT, as a widely used classic feature extraction and matching algorithm, is compared with seven deep-learning matching methods: SuperGlue, LightGlue, LoFTR, ASpanFormer, DKM, GIM-LightGlue, and GIM-DKM. Results demonstrate that traditional matching methods are still competitive in this age of deep learning, although for particular scenarios learning-based methods are very promising.</li>
</ul>

<h3>Title: ExpLLM: Towards Chain of Thought for Facial Expression Recognition</h3>
<ul>
<li><strong>Authors: </strong>Xing Lan, Jian Xue, Ji Qi, Dongmei Jiang, Ke Lu, Tat-Seng Chua</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.MM</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2409.02828">https://arxiv.org/abs/2409.02828</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2409.02828">https://arxiv.org/pdf/2409.02828</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2409.02828]] ExpLLM: Towards Chain of Thought for Facial Expression Recognition(https://arxiv.org/abs/2409.02828)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Facial expression recognition (FER) is a critical task in multimedia with significant implications across various domains. However, analyzing the causes of facial expressions is essential for accurately recognizing them. Current approaches, such as those based on facial action units (AUs), typically provide AU names and intensities but lack insight into the interactions and relationships between AUs and the overall expression. In this paper, we propose a novel method called ExpLLM, which leverages large language models to generate an accurate chain of thought (CoT) for facial expression recognition. Specifically, we have designed the CoT mechanism from three key perspectives: key observations, overall emotional interpretation, and conclusion. The key observations describe the AU's name, intensity, and associated emotions. The overall emotional interpretation provides an analysis based on multiple AUs and their interactions, identifying the dominant emotions and their relationships. Finally, the conclusion presents the final expression label derived from the preceding analysis. Furthermore, we also introduce the Exp-CoT Engine, designed to construct this expression CoT and generate instruction-description data for training our ExpLLM. Extensive experiments on the RAF-DB and AffectNet datasets demonstrate that ExpLLM outperforms current state-of-the-art FER methods. ExpLLM also surpasses the latest GPT-4o in expression CoT generation, particularly in recognizing micro-expressions where GPT-4o frequently fails.</li>
</ul>

<h3>Title: CMM-Math: A Chinese Multimodal Math Dataset To Evaluate and Enhance the Mathematics Reasoning of Large Multimodal Models</h3>
<ul>
<li><strong>Authors: </strong>Wentao Liu, Qianjun Pan, Yi Zhang, Zhuo Liu, Ji Wu, Jie Zhou, Aimin Zhou, Qin Chen, Bo Jiang, Liang He</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2409.02834">https://arxiv.org/abs/2409.02834</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2409.02834">https://arxiv.org/pdf/2409.02834</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2409.02834]] CMM-Math: A Chinese Multimodal Math Dataset To Evaluate and Enhance the Mathematics Reasoning of Large Multimodal Models(https://arxiv.org/abs/2409.02834)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large language models (LLMs) have obtained promising results in mathematical reasoning, which is a foundational skill for human intelligence. Most previous studies focus on improving and measuring the performance of LLMs based on textual math reasoning datasets (e.g., MATH, GSM8K). Recently, a few researchers have released English multimodal math datasets (e.g., MATHVISTA and MATH-V) to evaluate the effectiveness of large multimodal models (LMMs). In this paper, we release a Chinese multimodal math (CMM-Math) dataset, including benchmark and training parts, to evaluate and enhance the mathematical reasoning of LMMs. CMM-Math contains over 28,000 high-quality samples, featuring a variety of problem types (e.g., multiple-choice, fill-in-the-blank, and so on) with detailed solutions across 12 grade levels from elementary to high school in China. Specifically, the visual context may be present in the questions or opinions, which makes this dataset more challenging. Through comprehensive analysis, we discover that state-of-the-art LMMs on the CMM-Math dataset face challenges, emphasizing the necessity for further improvements in LMM development. We also propose a Multimodal Mathematical LMM (Math-LMM) to handle the problems with mixed input of multiple images and text segments. We train our model using three stages, including foundational pre-training, foundational fine-tuning, and mathematical fine-tuning. The extensive experiments indicate that our model effectively improves math reasoning performance by comparing it with the SOTA LMMs over three multimodal mathematical datasets.</li>
</ul>

<h3>Title: Exploring Sentiment Dynamics and Predictive Behaviors in Cryptocurrency Discussions by Few-Shot Learning with Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Moein Shahiki Tash, Zahra Ahani, Mohim Tash, Olga Kolesnikova, Grigori Sidorov</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.CE, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2409.02836">https://arxiv.org/abs/2409.02836</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2409.02836">https://arxiv.org/pdf/2409.02836</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2409.02836]] Exploring Sentiment Dynamics and Predictive Behaviors in Cryptocurrency Discussions by Few-Shot Learning with Large Language Models(https://arxiv.org/abs/2409.02836)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>This study performs analysis of Predictive statements, Hope speech, and Regret Detection behaviors within cryptocurrency-related discussions, leveraging advanced natural language processing techniques. We introduce a novel classification scheme named "Prediction statements," categorizing comments into Predictive Incremental, Predictive Decremental, Predictive Neutral, or Non-Predictive categories. Employing GPT-4o, a cutting-edge large language model, we explore sentiment dynamics across five prominent cryptocurrencies: Cardano, Binance, Matic, Fantom, and Ripple. Our analysis reveals distinct patterns in predictive sentiments, with Matic demonstrating a notably higher propensity for optimistic predictions. Additionally, we investigate hope and regret sentiments, uncovering nuanced interplay between these emotions and predictive behaviors. Despite encountering limitations related to data volume and resource availability, our study reports valuable discoveries concerning investor behavior and sentiment trends within the cryptocurrency market, informing strategic decision-making and future research endeavors.</li>
</ul>

<h3>Title: iConFormer: Dynamic Parameter-Efficient Tuning with Input-Conditioned Adaptation</h3>
<ul>
<li><strong>Authors: </strong>Hayeon Jo, Hyesong Choi, Minhee Cho, Dongbo Min</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2409.02838">https://arxiv.org/abs/2409.02838</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2409.02838">https://arxiv.org/pdf/2409.02838</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2409.02838]] iConFormer: Dynamic Parameter-Efficient Tuning with Input-Conditioned Adaptation(https://arxiv.org/abs/2409.02838)</code><input type="text"></li>
<li><strong>Keywords: </strong>secure, transformer, segmentation</a></li>
<li><strong>Abstract: </strong>Transfer learning based on full fine-tuning (FFT) of the pre-trained encoder and task-specific decoder becomes increasingly complex as deep models grow exponentially. Parameter efficient fine-tuning (PEFT) approaches using adapters consisting of small learnable layers have emerged as an alternative to FFT, achieving comparable performance while maintaining high training efficiency. However, the inflexibility of the adapter with respect to input instances limits its capability of learning task-specific information in diverse downstream tasks. In this paper, we propose a novel PEFT approach, input-Conditioned transFormer, termed iConFormer, that leverages a dynamic adapter conditioned on the input instances. To secure flexible learning ability on input instances in various downstream tasks, we introduce an input-Conditioned Network (iCoN) in the dynamic adapter that enables instance-level feature transformation. To be specific, iCoN generates channel-wise convolutional kernels for each feature and transform it using adaptive convolution process to effectively capture task-specific and fine-grained details tailor to downstream tasks. Experimental results demonstrate that by tuning just 1.6% to 2.8% of the Transformer backbone parameters, iConFormer achieves performance comparable to FFT in monocular depth estimation and semantic segmentation, while outperforming it in image classification and instance segmentation. Also, the proposed method consistently outperforms recent PEFT methods for all the tasks mentioned above.</li>
</ul>

<h3>Title: J\"ager: Automated Telephone Call Traceback</h3>
<ul>
<li><strong>Authors: </strong>David Adei, Varun Madathil, Sathvik Prasad, Bradley Reaves, Alessandra Scafuro</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.CY, cs.NI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2409.02839">https://arxiv.org/abs/2409.02839</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2409.02839">https://arxiv.org/pdf/2409.02839</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2409.02839]] J\"ager: Automated Telephone Call Traceback(https://arxiv.org/abs/2409.02839)</code><input type="text"></li>
<li><strong>Keywords: </strong>secure, privacy</a></li>
<li><strong>Abstract: </strong>Unsolicited telephone calls that facilitate fraud or unlawful telemarketing continue to overwhelm network users and the regulators who prosecute them. The first step in prosecuting phone abuse is traceback -- identifying the call originator. This fundamental investigative task currently requires hours of manual effort per call. In this paper, we introduce Jäger, a distributed secure call traceback system. Jäger can trace a call in a few seconds, even with partial deployment, while cryptographically preserving the privacy of call parties, carrier trade secrets like peers and call volume, and limiting the threat of bulk analysis. We establish definitions and requirements of secure traceback, then develop a suite of protocols that meet these requirements using witness encryption, oblivious pseudorandom functions, and group signatures. We prove these protocols secure in the universal composibility framework. We then demonstrate that Jäger has low compute and bandwidth costs per call, and these costs scale linearly with call volume. Jäger provides an efficient, secure, privacy-preserving system to revolutionize telephone abuse investigation with minimal costs to operators.</li>
</ul>

<h3>Title: Historical German Text Normalization Using Type- and Token-Based Language Modeling</h3>
<ul>
<li><strong>Authors: </strong>Anton Ehrmanntraut</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2409.02841">https://arxiv.org/abs/2409.02841</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2409.02841">https://arxiv.org/pdf/2409.02841</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2409.02841]] Historical German Text Normalization Using Type- and Token-Based Language Modeling(https://arxiv.org/abs/2409.02841)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer, large language model</a></li>
<li><strong>Abstract: </strong>Historic variations of spelling poses a challenge for full-text search or natural language processing on historical digitized texts. To minimize the gap between the historic orthography and contemporary spelling, usually an automatic orthographic normalization of the historical source material is pursued. This report proposes a normalization system for German literary texts from c. 1700-1900, trained on a parallel corpus. The proposed system makes use of a machine learning approach using Transformer language models, combining an encoder-decoder model to normalize individual word types, and a pre-trained causal language model to adjust these normalizations within their context. An extensive evaluation shows that the proposed system provides state-of-the-art accuracy, comparable with a much larger fully end-to-end sentence-based normalization system, fine-tuning a pre-trained Transformer large language model. However, the normalization of historical text remains a challenge due to difficulties for models to generalize, and the lack of extensive high-quality parallel data.</li>
</ul>

<h3>Title: MaDis-Stereo: Enhanced Stereo Matching via Distilled Masked Image Modeling</h3>
<ul>
<li><strong>Authors: </strong>Jihye Ahn, Hyesong Choi, Soomin Kim, Dongbo Min</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2409.02846">https://arxiv.org/abs/2409.02846</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2409.02846">https://arxiv.org/pdf/2409.02846</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2409.02846]] MaDis-Stereo: Enhanced Stereo Matching via Distilled Masked Image Modeling(https://arxiv.org/abs/2409.02846)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>In stereo matching, CNNs have traditionally served as the predominant architectures. Although Transformer-based stereo models have been studied recently, their performance still lags behind CNN-based stereo models due to the inherent data scarcity issue in the stereo matching task. In this paper, we propose Masked Image Modeling Distilled Stereo matching model, termed MaDis-Stereo, that enhances locality inductive bias by leveraging Masked Image Modeling (MIM) in training Transformer-based stereo model. Given randomly masked stereo images as inputs, our method attempts to conduct both image reconstruction and depth prediction tasks. While this strategy is beneficial to resolving the data scarcity issue, the dual challenge of reconstructing masked tokens and subsequently performing stereo matching poses significant challenges, particularly in terms of training stability. To address this, we propose to use an auxiliary network (teacher), updated via Exponential Moving Average (EMA), along with the original stereo model (student), where teacher predictions serve as pseudo supervisory signals to effectively distill knowledge into the student model. State-of-the-arts performance is achieved with the proposed method on several stereo matching such as ETH3D and KITTI 2015. Additionally, to demonstrate that our model effectively leverages locality inductive bias, we provide the attention distance measurement.</li>
</ul>

<h3>Title: Human-VDM: Learning Single-Image 3D Human Gaussian Splatting from Video Diffusion Models</h3>
<ul>
<li><strong>Authors: </strong>Zhibin Liu, Haoye Dong, Aviral Chharia, Hefeng Wu</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2409.02851">https://arxiv.org/abs/2409.02851</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2409.02851">https://arxiv.org/pdf/2409.02851</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2409.02851]] Human-VDM: Learning Single-Image 3D Human Gaussian Splatting from Video Diffusion Models(https://arxiv.org/abs/2409.02851)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>Generating lifelike 3D humans from a single RGB image remains a challenging task in computer vision, as it requires accurate modeling of geometry, high-quality texture, and plausible unseen parts. Existing methods typically use multi-view diffusion models for 3D generation, but they often face inconsistent view issues, which hinder high-quality 3D human generation. To address this, we propose Human-VDM, a novel method for generating 3D human from a single RGB image using Video Diffusion Models. Human-VDM provides temporally consistent views for 3D human generation using Gaussian Splatting. It consists of three modules: a view-consistent human video diffusion module, a video augmentation module, and a Gaussian Splatting module. First, a single image is fed into a human video diffusion module to generate a coherent human video. Next, the video augmentation module applies super-resolution and video interpolation to enhance the textures and geometric smoothness of the generated video. Finally, the 3D Human Gaussian Splatting module learns lifelike humans under the guidance of these high-resolution and view-consistent images. Experiments demonstrate that Human-VDM achieves high-quality 3D human from a single image, outperforming state-of-the-art methods in both generation quality and quantity. Project page: this https URL</li>
</ul>

<h3>Title: Hybrid-Segmentor: A Hybrid Approach to Automated Fine-Grained Crack Segmentation in Civil Infrastructure</h3>
<ul>
<li><strong>Authors: </strong>June Moh Goo, Xenios Milidonis, Alessandro Artusi, Jan Boehm, Carlo Ciliberto</a></li>
<li><strong>Subjects: </strong>cs.CV, eess.SP</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2409.02866">https://arxiv.org/abs/2409.02866</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2409.02866">https://arxiv.org/pdf/2409.02866</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2409.02866]] Hybrid-Segmentor: A Hybrid Approach to Automated Fine-Grained Crack Segmentation in Civil Infrastructure(https://arxiv.org/abs/2409.02866)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>Detecting and segmenting cracks in infrastructure, such as roads and buildings, is crucial for safety and cost-effective maintenance. In spite of the potential of deep learning, there are challenges in achieving precise results and handling diverse crack types. With the proposed dataset and model, we aim to enhance crack detection and infrastructure maintenance. We introduce Hybrid-Segmentor, an encoder-decoder based approach that is capable of extracting both fine-grained local and global crack features. This allows the model to improve its generalization capabilities in distinguish various type of shapes, surfaces and sizes of cracks. To keep the computational performances low for practical purposes, while maintaining the high the generalization capabilities of the model, we incorporate a self-attention model at the encoder level, while reducing the complexity of the decoder component. The proposed model outperforms existing benchmark models across 5 quantitative metrics (accuracy 0.971, precision 0.804, recall 0.744, F1-score 0.770, and IoU score 0.630), achieving state-of-the-art status.</li>
</ul>

<h3>Title: The Impact of Balancing Real and Synthetic Data on Accuracy and Fairness in Face Recognition</h3>
<ul>
<li><strong>Authors: </strong>Andrea Atzori, Pietro Cosseddu, Gianni Fenu, Mirko Marras</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2409.02867">https://arxiv.org/abs/2409.02867</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2409.02867">https://arxiv.org/pdf/2409.02867</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2409.02867]] The Impact of Balancing Real and Synthetic Data on Accuracy and Fairness in Face Recognition(https://arxiv.org/abs/2409.02867)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, fair, diffusion, generative</a></li>
<li><strong>Abstract: </strong>Over the recent years, the advancements in deep face recognition have fueled an increasing demand for large and diverse datasets. Nevertheless, the authentic data acquired to create those datasets is typically sourced from the web, which, in many cases, can lead to significant privacy issues due to the lack of explicit user consent. Furthermore, obtaining a demographically balanced, large dataset is even more difficult because of the natural imbalance in the distribution of images from different demographic groups. In this paper, we investigate the impact of demographically balanced authentic and synthetic data, both individually and in combination, on the accuracy and fairness of face recognition models. Initially, several generative methods were used to balance the demographic representations of the corresponding synthetic datasets. Then a state-of-the-art face encoder was trained and evaluated using (combinations of) synthetic and authentic images. Our findings emphasized two main points: (i) the increased effectiveness of training data generated by diffusion-based models in enhancing accuracy, whether used alone or combined with subsets of authentic data, and (ii) the minimal impact of incorporating balanced data from pre-trained generative methods on fairness (in nearly all tested scenarios using combined datasets, fairness scores remained either unchanged or worsened, even when compared to unbalanced authentic datasets). Source code and data are available at \url{this https URL} for reproducibility.</li>
</ul>

<h3>Title: Look Into the LITE in Deep Learning for Time Series Classification</h3>
<ul>
<li><strong>Authors: </strong>Ali Ismail-Fawaz, Maxime Devanne, Stefano Berretti, Jonathan Weber, Germain Forestier</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2409.02869">https://arxiv.org/abs/2409.02869</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2409.02869">https://arxiv.org/pdf/2409.02869</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2409.02869]] Look Into the LITE in Deep Learning for Time Series Classification(https://arxiv.org/abs/2409.02869)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability</a></li>
<li><strong>Abstract: </strong>Deep learning models have been shown to be a powerful solution for Time Series Classification (TSC). State-of-the-art architectures, while producing promising results on the UCR and the UEA archives , present a high number of trainable parameters. This can lead to long training with high CO2 emission, power consumption and possible increase in the number of FLoating-point Operation Per Second (FLOPS). In this paper, we present a new architecture for TSC, the Light Inception with boosTing tEchnique (LITE) with only 2.34% of the number of parameters of the state-of-the-art InceptionTime model, while preserving performance. This architecture, with only 9, 814 trainable parameters due to the usage of DepthWise Separable Convolutions (DWSC), is boosted by three techniques: multiplexing, custom filters, and dilated convolution. The LITE architecture, trained on the UCR, is 2.78 times faster than InceptionTime and consumes 2.79 times less CO2 and power. To evaluate the performance of the proposed architecture on multivariate time series data, we adapt LITE to handle multivariate time series, we call this version LITEMV. To bring theory into application, we also conducted experiments using LITEMV on multivariate time series representing human rehabilitation movements, showing that LITEMV not only is the most efficient model but also the best performing for this application on the Kimore dataset, a skeleton based human rehabilitation exercises dataset. Moreover, to address the interpretability of LITEMV, we present a study using Class Activation Maps to understand the classification decision taken by the model during evaluation.</li>
</ul>

<h3>Title: Benchmarking Spurious Bias in Few-Shot Image Classifiers</h3>
<ul>
<li><strong>Authors: </strong>Guangtao Zheng, Wenqian Ye, Aidong Zhang</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2409.02882">https://arxiv.org/abs/2409.02882</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2409.02882">https://arxiv.org/pdf/2409.02882</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2409.02882]] Benchmarking Spurious Bias in Few-Shot Image Classifiers(https://arxiv.org/abs/2409.02882)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, fair</a></li>
<li><strong>Abstract: </strong>Few-shot image classifiers are designed to recognize and classify new data with minimal supervision and limited data but often show reliance on spurious correlations between classes and spurious attributes, known as spurious bias. Spurious correlations commonly hold in certain samples and few-shot classifiers can suffer from spurious bias induced from them. There is an absence of an automatic benchmarking system to assess the robustness of few-shot classifiers against spurious bias. In this paper, we propose a systematic and rigorous benchmark framework, termed FewSTAB, to fairly demonstrate and quantify varied degrees of robustness of few-shot classifiers to spurious bias. FewSTAB creates few-shot evaluation tasks with biased attributes so that using them for predictions can demonstrate poor performance. To construct these tasks, we propose attribute-based sample selection strategies based on a pre-trained vision-language model, eliminating the need for manual dataset curation. This allows FewSTAB to automatically benchmark spurious bias using any existing test data. FewSTAB offers evaluation results in a new dimension along with a new design guideline for building robust classifiers. Moreover, it can benchmark spurious bias in varied degrees and enable designs for varied degrees of robustness. Its effectiveness is demonstrated through experiments on ten few-shot learning methods across three datasets. We hope our framework can inspire new designs of robust few-shot classifiers. Our code is available at this https URL.</li>
</ul>

<h3>Title: Multi-stream deep learning framework to predict mild cognitive impairment with Rey Complex Figure Test</h3>
<ul>
<li><strong>Authors: </strong>Junyoung Park, Eun Hyun Seo, Sunjun Kim, SangHak Yi, Kun Ho Lee, Sungho Won</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2409.02883">https://arxiv.org/abs/2409.02883</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2409.02883">https://arxiv.org/pdf/2409.02883</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2409.02883]] Multi-stream deep learning framework to predict mild cognitive impairment with Rey Complex Figure Test(https://arxiv.org/abs/2409.02883)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Drawing tests like the Rey Complex Figure Test (RCFT) are widely used to assess cognitive functions such as visuospatial skills and memory, making them valuable tools for detecting mild cognitive impairment (MCI). Despite their utility, existing predictive models based on these tests often suffer from limitations like small sample sizes and lack of external validation, which undermine their reliability. We developed a multi-stream deep learning framework that integrates two distinct processing streams: a multi-head self-attention based spatial stream using raw RCFT images and a scoring stream employing a previously developed automated scoring system. Our model was trained on data from 1,740 subjects in the Korean cohort and validated on an external hospital dataset of 222 subjects from Korea. The proposed multi-stream model demonstrated superior performance over baseline models (AUC = 0.872, Accuracy = 0.781) in external validation. The integration of both spatial and scoring streams enables the model to capture intricate visual details from the raw images while also incorporating structured scoring data, which together enhance its ability to detect subtle cognitive impairments. This dual approach not only improves predictive accuracy but also increases the robustness of the model, making it more reliable in diverse clinical settings. Our model has practical implications for clinical settings, where it could serve as a cost-effective tool for early MCI screening.</li>
</ul>

<h3>Title: LongLLaVA: Scaling Multi-modal LLMs to 1000 Images Efficiently via Hybrid Architecture</h3>
<ul>
<li><strong>Authors: </strong>Xidong Wang, Dingjie Song, Shunian Chen, Chen Zhang, Benyou Wang</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.CV, cs.MM</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2409.02889">https://arxiv.org/abs/2409.02889</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2409.02889">https://arxiv.org/pdf/2409.02889</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2409.02889]] LongLLaVA: Scaling Multi-modal LLMs to 1000 Images Efficiently via Hybrid Architecture(https://arxiv.org/abs/2409.02889)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer, large language model</a></li>
<li><strong>Abstract: </strong>Expanding the long-context capabilities of Multi-modal Large Language Models~(MLLMs) is crucial for video understanding, high-resolution image understanding, and multi-modal agents. This involves a series of systematic optimizations, including model architecture, data construction and training strategy, particularly addressing challenges such as \textit{degraded performance with more images} and \textit{high computational costs}. In this paper, we adapt the model architecture to a hybrid of Mamba and Transformer blocks, approach data construction with both temporal and spatial dependencies among multiple images and employ a progressive training strategy. The released model \textbf{LongLLaVA}~(\textbf{Long}-Context \textbf{L}arge \textbf{L}anguage \textbf{a}nd \textbf{V}ision \textbf{A}ssistant) is the first hybrid MLLM, which achieved a better balance between efficiency and effectiveness. LongLLaVA not only achieves competitive results across various benchmarks, but also maintains high throughput and low memory consumption. Especially, it could process nearly a thousand images on a single A100 80GB GPU, showing promising application prospects for a wide range of tasks.</li>
</ul>

<h3>Title: LongCite: Enabling LLMs to Generate Fine-grained Citations in Long-context QA</h3>
<ul>
<li><strong>Authors: </strong>jiajie Zhang, Yushi Bai, Xin Lv, Wanjun Gu, Danqing Liu, Minhao Zou, Shulin Cao, Lei Hou, Yuxiao Dong, Ling Feng, Juanzi Li</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2409.02897">https://arxiv.org/abs/2409.02897</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2409.02897">https://arxiv.org/pdf/2409.02897</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2409.02897]] LongCite: Enabling LLMs to Generate Fine-grained Citations in Long-context QA(https://arxiv.org/abs/2409.02897)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Though current long-context large language models (LLMs) have demonstrated impressive capacities in answering user questions based on extensive text, the lack of citations in their responses makes user verification difficult, leading to concerns about their trustworthiness due to their potential hallucinations. In this work, we aim to enable long-context LLMs to generate responses with fine-grained sentence-level citations, improving their faithfulness and verifiability. We first introduce LongBench-Cite, an automated benchmark for assessing current LLMs' performance in Long-Context Question Answering with Citations (LQAC), revealing considerable room for improvement. To this end, we propose CoF (Coarse to Fine), a novel pipeline that utilizes off-the-shelf LLMs to automatically generate long-context QA instances with precise sentence-level citations, and leverage this pipeline to construct LongCite-45k, a large-scale SFT dataset for LQAC. Finally, we train LongCite-8B and LongCite-9B using the LongCite-45k dataset, successfully enabling their generation of accurate responses and fine-grained sentence-level citations in a single output. The evaluation results on LongBench-Cite show that our trained models achieve state-of-the-art citation quality, surpassing advanced proprietary models including GPT-4o.</li>
</ul>

<h3>Title: Masked Diffusion Models are Secretly Time-Agnostic Masked Models and Exploit Inaccurate Categorical Sampling</h3>
<ul>
<li><strong>Authors: </strong>Kaiwen Zheng, Yongxin Chen, Hanzi Mao, Ming-Yu Liu, Jun Zhu, Qinsheng Zhang</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2409.02908">https://arxiv.org/abs/2409.02908</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2409.02908">https://arxiv.org/pdf/2409.02908</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2409.02908]] Masked Diffusion Models are Secretly Time-Agnostic Masked Models and Exploit Inaccurate Categorical Sampling(https://arxiv.org/abs/2409.02908)</code><input type="text"></li>
<li><strong>Keywords: </strong>fair, diffusion, generative</a></li>
<li><strong>Abstract: </strong>Masked diffusion models (MDMs) have emerged as a popular research topic for generative modeling of discrete data, thanks to their superior performance over other discrete diffusion models, and are rivaling the auto-regressive models (ARMs) for language modeling tasks. The recent effort in simplifying the masked diffusion framework further leads to alignment with continuous-space diffusion models and more principled training and sampling recipes. In this paper, however, we reveal that both training and sampling of MDMs are theoretically free from the time variable, arguably the key signature of diffusion models, and are instead equivalent to masked models. The connection on the sampling aspect is drawn by our proposed first-hitting sampler (FHS). Specifically, we show that the FHS is theoretically equivalent to MDMs' original generation process while significantly alleviating the time-consuming categorical sampling and achieving a 20$\times$ speedup. In addition, our investigation challenges previous claims that MDMs can surpass ARMs in generative perplexity. We identify, for the first time, an underlying numerical issue, even with the 32-bit floating-point precision, which results in inaccurate categorical sampling. We show that the numerical issue lowers the effective temperature both theoretically and empirically, leading to unfair assessments of MDMs' generation results in the previous literature.</li>
</ul>

<h3>Title: SITAR: Semi-supervised Image Transformer for Action Recognition</h3>
<ul>
<li><strong>Authors: </strong>Owais Iqbal, Omprakash Chakraborty, Aftab Hussain, Rameswar Panda, Abir Das</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2409.02910">https://arxiv.org/abs/2409.02910</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2409.02910">https://arxiv.org/pdf/2409.02910</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2409.02910]] SITAR: Semi-supervised Image Transformer for Action Recognition(https://arxiv.org/abs/2409.02910)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Recognizing actions from a limited set of labeled videos remains a challenge as annotating visual data is not only tedious but also can be expensive due to classified nature. Moreover, handling spatio-temporal data using deep $3$D transformers for this can introduce significant computational complexity. In this paper, our objective is to address video action recognition in a semi-supervised setting by leveraging only a handful of labeled videos along with a collection of unlabeled videos in a compute efficient manner. Specifically, we rearrange multiple frames from the input videos in row-column form to construct super images. Subsequently, we capitalize on the vast pool of unlabeled samples and employ contrastive learning on the encoded super images. Our proposed approach employs two pathways to generate representations for temporally augmented super images originating from the same video. Specifically, we utilize a 2D image-transformer to generate representations and apply a contrastive loss function to minimize the similarity between representations from different videos while maximizing the representations of identical videos. Our method demonstrates superior performance compared to existing state-of-the-art approaches for semi-supervised action recognition across various benchmark datasets, all while significantly reducing computational costs.</li>
</ul>

<h3>Title: Can LVLMs Obtain a Driver's License? A Benchmark Towards Reliable AGI for Autonomous Driving</h3>
<ul>
<li><strong>Authors: </strong>Yuhang Lu, Yichen Yao, Jiadong Tu, Jiangnan Shao, Yuexin Ma, Xinge Zhu</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2409.02914">https://arxiv.org/abs/2409.02914</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2409.02914">https://arxiv.org/pdf/2409.02914</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2409.02914]] Can LVLMs Obtain a Driver's License? A Benchmark Towards Reliable AGI for Autonomous Driving(https://arxiv.org/abs/2409.02914)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, interpretability</a></li>
<li><strong>Abstract: </strong>Large Vision-Language Models (LVLMs) have recently garnered significant attention, with many efforts aimed at harnessing their general knowledge to enhance the interpretability and robustness of autonomous driving models. However, LVLMs typically rely on large, general-purpose datasets and lack the specialized expertise required for professional and safe driving. Existing vision-language driving datasets focus primarily on scene understanding and decision-making, without providing explicit guidance on traffic rules and driving skills, which are critical aspects directly related to driving safety. To bridge this gap, we propose IDKB, a large-scale dataset containing over one million data items collected from various countries, including driving handbooks, theory test data, and simulated road test data. Much like the process of obtaining a driver's license, IDKB encompasses nearly all the explicit knowledge needed for driving from theory to practice. In particular, we conducted comprehensive tests on 15 LVLMs using IDKB to assess their reliability in the context of autonomous driving and provided extensive analysis. We also fine-tuned popular models, achieving notable performance improvements, which further validate the significance of our dataset. The project page can be found at: \url{this https URL}</li>
</ul>

<h3>Title: SpecMon: Modular Black-Box Runtime Monitoring of Security Protocols</h3>
<ul>
<li><strong>Authors: </strong>Kevin Morio, Robert Künnemann</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2409.02918">https://arxiv.org/abs/2409.02918</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2409.02918">https://arxiv.org/pdf/2409.02918</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2409.02918]] SpecMon: Modular Black-Box Runtime Monitoring of Security Protocols(https://arxiv.org/abs/2409.02918)</code><input type="text"></li>
<li><strong>Keywords: </strong>security</a></li>
<li><strong>Abstract: </strong>There exists a verification gap between formal protocol specifications and their actual implementations, which this work aims to bridge via monitoring for compliance to the formal specification. We instrument the networking and cryptographic library the application uses to obtain a stream of events. This is possible even without source code access. We then use an efficient algorithm to match these observations to traces that are valid in the specification model. In contrast to prior work, our algorithm can handle non-determinism and thus, multiple sessions. It also achieves a low overhead, which we demonstrate on the WireGuard reference implementation and a case study from prior work. We find that the reference Tamarin model for WireGuard can be used with little change: We only need to specify wire formats and correct some small inaccuracies that we discovered while conducting the case study. We also provide a soundness result for our algorithm that ensures it accepts only event streams that are valid according to the specification model.</li>
</ul>

<h3>Title: HiPrompt: Tuning-free Higher-Resolution Generation with Hierarchical MLLM Prompts</h3>
<ul>
<li><strong>Authors: </strong>Xinyu Liu, Yingqing He, Lanqing Guo, Xiang Li, Bu Jin, Peng Li, Yan Li, Chi-Min Chan, Qifeng Chen, Wei Xue, Wenhan Luo, Qingfeng Liu, Yike Guo</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2409.02919">https://arxiv.org/abs/2409.02919</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2409.02919">https://arxiv.org/pdf/2409.02919</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2409.02919]] HiPrompt: Tuning-free Higher-Resolution Generation with Hierarchical MLLM Prompts(https://arxiv.org/abs/2409.02919)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>The potential for higher-resolution image generation using pretrained diffusion models is immense, yet these models often struggle with issues of object repetition and structural artifacts especially when scaling to 4K resolution and higher. We figure out that the problem is caused by that, a single prompt for the generation of multiple scales provides insufficient efficacy. In response, we propose HiPrompt, a new tuning-free solution that tackles the above problems by introducing hierarchical prompts. The hierarchical prompts offer both global and local guidance. Specifically, the global guidance comes from the user input that describes the overall content, while the local guidance utilizes patch-wise descriptions from MLLMs to elaborately guide the regional structure and texture generation. Furthermore, during the inverse denoising process, the generated noise is decomposed into low- and high-frequency spatial components. These components are conditioned on multiple prompt levels, including detailed patch-wise descriptions and broader image-level prompts, facilitating prompt-guided denoising under hierarchical semantic guidance. It further allows the generation to focus more on local spatial regions and ensures the generated images maintain coherent local and global semantics, structures, and textures with high definition. Extensive experiments demonstrate that HiPrompt outperforms state-of-the-art works in higher-resolution image generation, significantly reducing object repetition and enhancing structural quality.</li>
</ul>

<button id="copy">Copy All</button>
</article>
<script src="../../javascript/clipboard.min.js"></script>
<script src="../../javascript/clipboard.js"></script>
