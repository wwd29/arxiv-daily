<link rel="stylesheet" href="../../css/markdown.css" />
<article class="markdown-body">
<h2>secure</h2>
<h3>Title: Secure system based on UAV and BLE for improving SAR missions. (arXiv:2208.07700v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2208.07700">http://arxiv.org/abs/2208.07700</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2208.07700] Secure system based on UAV and BLE for improving SAR missions](http://arxiv.org/abs/2208.07700)</code></li>
<li>Summary: <p>This work describes an integrated solution to face a civil security problem
in the area of Search And Rescue (SAR) of missing people. This proposal is
based on the use of emerging technologies such as Unmanned Aerial Vehicles
(UAV), also known as drones, and the use of simulated beacons on smartphones.
In particular, in the presented tool, drones fly synchronously in a specific
area so that each drone uses on-board sensors to scan and detect any signal
emitted by Bluetooth Low Energy (BLE) beacons from smartphones of missing
people. This technique allows getting the GPS position of any detected missing
person. This work also includes some security issues related to possible
attacks focused on the perimeter and physical security.
</p></li>
</ul>

<h3>Title: Role of Data Augmentation in Unsupervised Anomaly Detection. (arXiv:2208.07734v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2208.07734">http://arxiv.org/abs/2208.07734</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2208.07734] Role of Data Augmentation in Unsupervised Anomaly Detection](http://arxiv.org/abs/2208.07734)</code></li>
<li>Summary: <p>Self-supervised learning (SSL) has emerged as a promising alternative to
create supervisory signals to real-world tasks, avoiding extensive cost of
careful labeling. SSL is particularly attractive for unsupervised problems such
as anomaly detection (AD), where labeled anomalies are costly to secure,
difficult to simulate, or even nonexistent. A large catalog of augmentation
functions have been used for SSL-based AD (SSAD), and recent works have
observed that the type of augmentation has a significant impact on performance.
Motivated by those, this work sets out to put SSAD under a larger lens and
carefully investigate the role of data augmentation in AD through extensive
experiments on many testbeds. Our main finding is that self-supervision acts as
a yet-another model hyperparameter, and should be chosen carefully in regards
to the nature of true anomalies in the data. That is, the alignment between the
augmentation and the underlying anomaly-generating mechanism is the key for the
success of SSAD, and in the lack thereof, SSL can even impair (!) detection
performance. Moving beyond proposing another SSAD method, our study contributes
to the better understanding of this growing area and lays out new directions
for future research.
</p></li>
</ul>

<h2>security</h2>
<h3>Title: TexPrax: A Messaging Application for Ethical, Real-time Data Collection and Annotation. (arXiv:2208.07846v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2208.07846">http://arxiv.org/abs/2208.07846</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2208.07846] TexPrax: A Messaging Application for Ethical, Real-time Data Collection and Annotation](http://arxiv.org/abs/2208.07846)</code></li>
<li>Summary: <p>Collecting and annotating task-oriented dialog data is difficult, especially
for highly specific domains that require expert knowledge. At the same time,
informal communication channels such as instant messengers are increasingly
being used at work. This has led to a lot of work-relevant information that is
disseminated through those channels and needs to be post-processed manually by
the employees. To alleviate this problem, we present TexPrax, a messaging
system to collect and annotate problems, causes, and solutions that occur in
work-related chats. TexPrax uses a chatbot to directly engage the employees to
provide lightweight annotations on their conversation and ease their
documentation work. To comply with data privacy and security regulations, we
use an end-to-end message encryption and give our users full control over their
data which has various advantages over conventional annotation tools. We
evaluate TexPrax in a user-study with German factory employees who ask their
colleagues for solutions on problems that arise during their daily work.
Overall, we collect 201 task-oriented German dialogues containing 1,027
sentences with sentence-level expert annotations. Our data analysis also
reveals that real-world conversations frequently contain instances with
code-switching, varying abbreviations for the same entity, and dialects which
NLP systems should be able to handle.
</p></li>
</ul>

<h3>Title: CTI4AI: Threat Intelligence Generation and Sharing after Red Teaming AI Models. (arXiv:2208.07476v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2208.07476">http://arxiv.org/abs/2208.07476</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2208.07476] CTI4AI: Threat Intelligence Generation and Sharing after Red Teaming AI Models](http://arxiv.org/abs/2208.07476)</code></li>
<li>Summary: <p>As the practicality of Artificial Intelligence (AI) and Machine Learning (ML)
based techniques grow, there is an ever increasing threat of adversarial
attacks. There is a need to red team this ecosystem to identify system
vulnerabilities, potential threats, characterize properties that will enhance
system robustness, and encourage the creation of effective defenses. A
secondary need is to share this AI security threat intelligence between
different stakeholders like, model developers, users, and AI/ML security
professionals. In this paper, we create and describe a prototype system CTI4AI,
to overcome the need to methodically identify and share AI/ML specific
vulnerabilities and threat intelligence.
</p></li>
</ul>

<h3>Title: Inhale: Enabling High-Performance and Energy-Efficient In-SRAM Cryptographic Hash for IoT. (arXiv:2208.07570v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2208.07570">http://arxiv.org/abs/2208.07570</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2208.07570] Inhale: Enabling High-Performance and Energy-Efficient In-SRAM Cryptographic Hash for IoT](http://arxiv.org/abs/2208.07570)</code></li>
<li>Summary: <p>In the age of big data, information security has become a major issue of
debate, especially with the rise of the Internet of Things (IoT), where
attackers can effortlessly obtain physical access to edge devices. The hash
algorithm is the current foundation for data integrity and authentication.
However, it is challenging to provide a high-performance, high-throughput, and
energy-efficient solution on resource-constrained edge devices. In this paper,
we propose Inhale, an in-SRAM architecture to effectively compute hash
algorithms with innovative data alignment and efficient read/write strategies
to implicitly execute data shift operations through the in-situ controller. We
present two variations of Inhale: Inhale-Opt, which is optimized for latency,
throughput, and area-overhead; and Inhale-Flex, which offers flexibility in
repurposing a part of last-level caches for hash computation. We thoroughly
evaluate our proposed architectures on both SRAM and ReRAM memories and compare
them with the state-of-the-art in-memory and ASIC accelerators. Our performance
evaluation confirms that Inhale can achieve 1.4x - 14.5x higher
throughput-per-area and about two-orders-of-magnitude higher
throughput-per-area-per-energy compared to the state-of-the-art solutions.
</p></li>
</ul>

<h3>Title: Achieve Fully Decentralized End to End Encryption Meeting via Blockchain. (arXiv:2208.07604v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2208.07604">http://arxiv.org/abs/2208.07604</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2208.07604] Achieve Fully Decentralized End to End Encryption Meeting via Blockchain](http://arxiv.org/abs/2208.07604)</code></li>
<li>Summary: <p>Zoom Meeting is an enterprise online video conferencing solution with
real-time messaging and content sharing. However, it's lack of privacy
protection since centralized Zoom servers are capable of monitoring user's
messages. Thereby, to solve the privacy problem, in May 2020, Zoom acquired
Keybase so that Keybase's team can help it to build end-to-end encryption
meeting while remaining Zoom's current scalability and high-performance.
Nonetheless, according to the latest released Zoom's whitepaper, even with the
new design of E2E (end to end) encryption meeting, the security threats can't
be erased completely since the new design is not fully decentralized.
</p></li>
</ul>

<p>In this paper, we introduce a fully decentralized design of E2E encryption
meeting via blockchain technology. With this new design, Zoom's E2E meeting
privacy can be further improved.
</p>

<h3>Title: Using blockchain in the follow-up of emergency situations related to events. (arXiv:2208.07701v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2208.07701">http://arxiv.org/abs/2208.07701</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2208.07701] Using blockchain in the follow-up of emergency situations related to events](http://arxiv.org/abs/2208.07701)</code></li>
<li>Summary: <p>This paper describes a decentralized low-cost system designed to reinforce
personal security in big events in case of emergency. The proposal consists of
using smart contracts supported by blockchain in the management of events. An
alternative communication channel that does not require any cloud service is
also provided with the aim of improving the coordination of emergency services.
Peers may use this emergency support tool to interact with each other through a
chat when additional support is required. Since information security is
mandatory in this scenario, Identity-Based Signcryption schemes are here used
in order to guarantee communication confidentiality, authenticity and
integrity. Depending on the communication mode (peer-to-peer or broadcast),
different signcryption methods are used. A first implementation of the proposal
has produced promising results.
</p></li>
</ul>

<h3>Title: Designing an Artificial Immune System inspired Intrusion Detection System. (arXiv:2208.07801v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2208.07801">http://arxiv.org/abs/2208.07801</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2208.07801] Designing an Artificial Immune System inspired Intrusion Detection System](http://arxiv.org/abs/2208.07801)</code></li>
<li>Summary: <p>The Human Immune System (HIS) works to protect a body from infection,
illness, and disease. This system can inspire cybersecurity professionals to
design an Artificial Immune System (AIS) based Intrusion Detection System
(IDS). These biologically inspired algorithms using Self/Nonself and Danger
Theory can directly augmentIDS designs and implementations. In this paper, we
include an examination into the elements of design necessary for building an
AIS-IDS framework and present an architecture to create such systems.
</p></li>
</ul>

<h3>Title: An Adaptive Image Encryption Scheme Guided by Fuzzy Models. (arXiv:2208.07825v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2208.07825">http://arxiv.org/abs/2208.07825</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2208.07825] An Adaptive Image Encryption Scheme Guided by Fuzzy Models](http://arxiv.org/abs/2208.07825)</code></li>
<li>Summary: <p>A new image encryption scheme using the advanced encryption standard (AES), a
chaotic map, a genetic operator, and a fuzzy inference system is proposed in
this paper. In this work, plain images were used as input, and the required
security level was achieved. Security criteria were computed after running a
proposed encryption process. Then an adaptive fuzzy system decided whether to
repeat the encryption process, terminate it, or run the next stage based on the
achieved results and user demand. The SHA-512 hash function was employed to
increase key sensitivity. Security analysis was conducted to evaluate the
security of the proposed scheme, which showed it had high security and all the
criteria necessary for a good and efficient encryption algorithm were met.
Simulation results and the comparison of similar works showed the proposed
encryptor had a pseudo-noise output and was strongly dependent upon the
changing key and plain image.
</p></li>
</ul>

<h2>privacy</h2>
<h3>Title: Towards Inclusive HRI: Using Sim2Real to Address Underrepresentation in Emotion Expression Recognition. (arXiv:2208.07472v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2208.07472">http://arxiv.org/abs/2208.07472</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2208.07472] Towards Inclusive HRI: Using Sim2Real to Address Underrepresentation in Emotion Expression Recognition](http://arxiv.org/abs/2208.07472)</code></li>
<li>Summary: <p>Robots and artificial agents that interact with humans should be able to do
so without bias and inequity, but facial perception systems have notoriously
been found to work more poorly for certain groups of people than others. In our
work, we aim to build a system that can perceive humans in a more transparent
and inclusive manner. Specifically, we focus on dynamic expressions on the
human face, which are difficult to collect for a broad set of people due to
privacy concerns and the fact that faces are inherently identifiable.
Furthermore, datasets collected from the Internet are not necessarily
representative of the general population. We address this problem by offering a
Sim2Real approach in which we use a suite of 3D simulated human models that
enables us to create an auditable synthetic dataset covering 1)
underrepresented facial expressions, outside of the six basic emotions, such as
confusion; 2) ethnic or gender minority groups; and 3) a wide range of viewing
angles that a robot may encounter a human in the real world. By augmenting a
small dynamic emotional expression dataset containing 123 samples with a
synthetic dataset containing 4536 samples, we achieved an improvement in
accuracy of 15% on our own dataset and 11% on an external benchmark dataset,
compared to the performance of the same model architecture without synthetic
training data. We also show that this additional step improves accuracy
specifically for racial minorities when the architecture's feature extraction
weights are trained from scratch.
</p></li>
</ul>

<h3>Title: Unsupervised Domain Adaptation for Segmentation with Black-box Source Model. (arXiv:2208.07769v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2208.07769">http://arxiv.org/abs/2208.07769</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2208.07769] Unsupervised Domain Adaptation for Segmentation with Black-box Source Model](http://arxiv.org/abs/2208.07769)</code></li>
<li>Summary: <p>Unsupervised domain adaptation (UDA) has been widely used to transfer
knowledge from a labeled source domain to an unlabeled target domain to counter
the difficulty of labeling in a new domain. The training of conventional
solutions usually relies on the existence of both source and target domain
data. However, privacy of the large-scale and well-labeled data in the source
domain and trained model parameters can become the major concern of cross
center/domain collaborations. In this work, to address this, we propose a
practical solution to UDA for segmentation with a black-box segmentation model
trained in the source domain only, rather than original source data or a
white-box source model. Specifically, we resort to a knowledge distillation
scheme with exponential mixup decay (EMD) to gradually learn target-specific
representations. In addition, unsupervised entropy minimization is further
applied to regularization of the target domain confidence. We evaluated our
framework on the BraTS 2018 database, achieving performance on par with
white-box source model adaptation approaches.
</p></li>
</ul>

<h3>Title: pyCANON: A Python library to check the level of anonymity of a dataset. (arXiv:2208.07556v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2208.07556">http://arxiv.org/abs/2208.07556</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2208.07556] pyCANON: A Python library to check the level of anonymity of a dataset](http://arxiv.org/abs/2208.07556)</code></li>
<li>Summary: <p>Openly sharing data with sensitive attributes and privacy restrictions is a
challenging task. In this document we present the implementation of pyCANON, a
Python library and command line interface (CLI) to check and assess the level
of anonymity of a dataset through some of the most common anonymization
techniques: k-anonymity, ($\alpha$,k)-anonymity, $\ell$-diversity, entropy
$\ell$-diversity, recursive (c,$\ell$)-diversity, basic $\beta$-likeness,
enhanced $\beta$-likeness, t-closeness and $\delta$-disclosure privacy. For the
case of more than one sensitive attributes, two approaches are proposed for
evaluating this techniques. The main strength of this library is to obtain a
full report of the parameters that are fulfilled for each of the techniques
mentioned above, with the unique requirement of the set of quasi-identifiers
and that of sensitive attributes. We present the methods implemented together
with the attacks they prevent, the description of the library, use examples of
the different functions, as well as the impact and the possible applications
that can be developed. Finally, some possible aspects to be incorporated in
future updates are proposed.
</p></li>
</ul>

<h3>Title: Priority and collision avoidance system for traffic lights. (arXiv:2208.07702v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2208.07702">http://arxiv.org/abs/2208.07702</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2208.07702] Priority and collision avoidance system for traffic lights](http://arxiv.org/abs/2208.07702)</code></li>
<li>Summary: <p>In this paper, a collision avoidance system is presented to detect red light
running and warn nearby vehicles and pedestrians in real time in order to
prevent possible accidents. No complex infrastructure-based solution such as
those based on radars or cameras is here required. Instead, a new solution
based on smartphones carried by drivers and pedestrians is proposed so that it
is the device inside the vehicle violating a traffic light, the one that
self-reports the offence in order to generate alerts and warn nearby vehicles
and pedestrians to prevent accidents. The proposal could also be used by road
authorities to collect data on traffic lights that are most frequently violated
in order to define an action plan to investigate causes and look for solutions.
It includes a classifier for learning and estimating driver behaviour based on
collected data, which is used to predict whether he/she is about to run a red
light or detect whether that has already happened. In the first case, the
system broadcasts warnings directly to close vehicles and pedestrians through
Wi-Fi, while in the second case, the proposal warns vehicles and pedestrians in
the neighbourhood through a server. The solution also includes a prioritization
system based on changing traffic lights at intersections according to the needs
and characteristics of the traffic at all times, giving the top priority to
emergency vehicles. Furthermore, the proposal involves the use of cryptographic
schemes to protect authenticity and integrity of messages sent from traffic
lights, smartphones and servers, and privacy and anonymity to promote the use
of the system. A beta version with some parts of the proposal has been
implemented and the obtained results are promising.
</p></li>
</ul>

<h3>Title: FedMR: Fedreated Learning via Model Recombination. (arXiv:2208.07677v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2208.07677">http://arxiv.org/abs/2208.07677</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2208.07677] FedMR: Fedreated Learning via Model Recombination](http://arxiv.org/abs/2208.07677)</code></li>
<li>Summary: <p>As a promising privacy-preserving machine learning method, Federated Learning
(FL) enables global model training across clients without compromising their
confidential local data. However, existing FL methods suffer from the problem
of low inference performance for unevenly distributed data, since most of them
rely on Federated Averaging (FedAvg)-based aggregation. By averaging model
parameters in a coarse manner, FedAvg eclipses the individual characteristics
of local models, which strongly limits the inference capability of FL. Worse
still, in each round of FL training, FedAvg dispatches the same initial local
models to clients, which can easily result in stuck-at-local-search for optimal
global models. To address the above issues, this paper proposes a novel and
effective FL paradigm named FedMR (Federating Model Recombination). Unlike
conventional FedAvg-based methods, the cloud server of FedMR shuffles each
layer of collected local models and recombines them to achieve new models for
local training on clients. Due to the fine-grained model recombination and
local training in each FL round, FedMR can quickly figure out one globally
optimal model for all the clients. Comprehensive experimental results
demonstrate that, compared with state-of-the-art FL methods, FedMR can
significantly improve the inference accuracy without causing extra
communication overhead.
</p></li>
</ul>

<h2>protect</h2>
<h3>Title: Reliable Decision from Multiple Subtasks through Threshold Optimization: Content Moderation in the Wild. (arXiv:2208.07522v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2208.07522">http://arxiv.org/abs/2208.07522</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2208.07522] Reliable Decision from Multiple Subtasks through Threshold Optimization: Content Moderation in the Wild](http://arxiv.org/abs/2208.07522)</code></li>
<li>Summary: <p>Social media platforms struggle to protect users from harmful content through
content moderation. These platforms have recently leveraged machine learning
models to cope with the vast amount of user-generated content daily. Since
moderation policies vary depending on countries and types of products, it is
common to train and deploy the models per policy. However, this approach is
highly inefficient, especially when the policies change, requiring dataset
re-labeling and model re-training on the shifted data distribution. To
alleviate this cost inefficiency, social media platforms often employ
third-party content moderation services that provide prediction scores of
multiple subtasks, such as predicting the existence of underage personnel, rude
gestures, or weapons, instead of directly providing final moderation decisions.
However, making a reliable automated moderation decision from the prediction
scores of the multiple subtasks for a specific target policy has not been
widely explored yet. In this study, we formulate real-world scenarios of
content moderation and introduce a simple yet effective threshold optimization
method that searches the optimal thresholds of the multiple subtasks to make a
reliable moderation decision in a cost-effective way. Extensive experiments
demonstrate that our approach shows better performance in content moderation
compared to existing threshold optimization methods and heuristics.
</p></li>
</ul>

<h2>defense</h2>
<h3>Title: Reproduction and Replication of an Adversarial Stylometry Experiment. (arXiv:2208.07395v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2208.07395">http://arxiv.org/abs/2208.07395</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2208.07395] Reproduction and Replication of an Adversarial Stylometry Experiment](http://arxiv.org/abs/2208.07395)</code></li>
<li>Summary: <p>Maintaining anonymity while communicating using natural language remains a
challenge. Standard authorship attribution techniques that analyze candidate
authors' writing styles achieve uncomfortably high accuracy even when the
number of candidate authors is high. Adversarial stylometry defends against
authorship attribution with the goal of preventing unwanted deanonymization.
This paper reproduces and replicates experiments in a seminal study of defenses
against authorship attribution (Brennan et al., 2012). We are able to
successfully reproduce and replicate the original results, although we conclude
that the effectiveness of the defenses studied is overstated due to a lack of a
control group in the original study. In our replication, we find new evidence
suggesting that an entirely automatic method, round-trip translation, merits
re-examination as it appears to reduce the effectiveness of established
authorship attribution methods.
</p></li>
</ul>

<h2>attack</h2>
<h3>Title: Learning Facial Liveness Representation for Domain Generalized Face Anti-spoofing. (arXiv:2208.07828v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2208.07828">http://arxiv.org/abs/2208.07828</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2208.07828] Learning Facial Liveness Representation for Domain Generalized Face Anti-spoofing](http://arxiv.org/abs/2208.07828)</code></li>
<li>Summary: <p>Face anti-spoofing (FAS) aims at distinguishing face spoof attacks from the
authentic ones, which is typically approached by learning proper models for
performing the associated classification task. In practice, one would expect
such models to be generalized to FAS in different image domains. Moreover, it
is not practical to assume that the type of spoof attacks would be known in
advance. In this paper, we propose a deep learning model for addressing the
aforementioned domain-generalized face anti-spoofing task. In particular, our
proposed network is able to disentangle facial liveness representation from the
irrelevant ones (i.e., facial content and image domain features). The resulting
liveness representation exhibits sufficient domain invariant properties, and
thus it can be applied for performing domain-generalized FAS. In our
experiments, we conduct experiments on five benchmark datasets with various
settings, and we verify that our model performs favorably against
state-of-the-art approaches in identifying novel types of spoof attacks in
unseen image domains.
</p></li>
</ul>

<h3>Title: OrthoMAD: Morphing Attack Detection Through Orthogonal Identity Disentanglement. (arXiv:2208.07841v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2208.07841">http://arxiv.org/abs/2208.07841</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2208.07841] OrthoMAD: Morphing Attack Detection Through Orthogonal Identity Disentanglement](http://arxiv.org/abs/2208.07841)</code></li>
<li>Summary: <p>Morphing attacks are one of the many threats that are constantly affecting
deep face recognition systems. It consists of selecting two faces from
different individuals and fusing them into a final image that contains the
identity information of both. In this work, we propose a novel regularisation
term that takes into account the existent identity information in both and
promotes the creation of two orthogonal latent vectors. We evaluate our
proposed method (OrthoMAD) in five different types of morphing in the FRLL
dataset and evaluate the performance of our model when trained on five distinct
datasets. With a small ResNet-18 as the backbone, we achieve state-of-the-art
results in the majority of the experiments, and competitive results in the
others. The code of this paper will be publicly available.
</p></li>
</ul>

<h2>robust</h2>
<h3>Title: Color Image Edge Detection using Multi-scale and Multi-directional Gabor filter. (arXiv:2208.07503v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2208.07503">http://arxiv.org/abs/2208.07503</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2208.07503] Color Image Edge Detection using Multi-scale and Multi-directional Gabor filter](http://arxiv.org/abs/2208.07503)</code></li>
<li>Summary: <p>In this paper, a color edge detection method is proposed where the
multi-scale Gabor filter are used to obtain edges from input color images. The
main advantage of the proposed method is that high edge detection accuracy is
attained while maintaining good noise robustness. The proposed method consists
of three aspects: First, the RGB color image is converted to CIE L<em>a</em>b* space
because of its wide coloring area and uniform color distribution. Second, a set
of Gabor filters are used to smooth the input images and the color edge
strength maps are extracted, which are fused into a new ESM with the noise
robustness and accurate edge extraction. Third, Embedding the fused ESM in the
route of the Canny detector yields a noise-robust color edge detector. The
results show that the proposed detector has the better experience in detection
accuracy and noise-robustness.
</p></li>
</ul>

<h3>Title: Multi-level Contrast Network for Wearables-based Joint Activity Segmentation and Recognition. (arXiv:2208.07547v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2208.07547">http://arxiv.org/abs/2208.07547</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2208.07547] Multi-level Contrast Network for Wearables-based Joint Activity Segmentation and Recognition](http://arxiv.org/abs/2208.07547)</code></li>
<li>Summary: <p>Human activity recognition (HAR) with wearables is promising research that
can be widely adopted in many smart healthcare applications. In recent years,
the deep learning-based HAR models have achieved impressive recognition
performance. However, most HAR algorithms are susceptible to the multi-class
windows problem that is essential yet rarely exploited. In this paper, we
propose to relieve this challenging problem by introducing the segmentation
technology into HAR, yielding joint activity segmentation and recognition.
Especially, we introduce the Multi-Stage Temporal Convolutional Network
(MS-TCN) architecture for sample-level activity prediction to joint segment and
recognize the activity sequence. Furthermore, to enhance the robustness of HAR
against the inter-class similarity and intra-class heterogeneity, a multi-level
contrastive loss, containing the sample-level and segment-level contrast, has
been proposed to learn a well-structured embedding space for better activity
segmentation and recognition performance. Finally, with comprehensive
experiments, we verify the effectiveness of the proposed method on two public
HAR datasets, achieving significant improvements in the various evaluation
metrics.
</p></li>
</ul>

<h3>Title: Efficient Multimodal Transformer with Dual-Level Feature Restoration for Robust Multimodal Sentiment Analysis. (arXiv:2208.07589v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2208.07589">http://arxiv.org/abs/2208.07589</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2208.07589] Efficient Multimodal Transformer with Dual-Level Feature Restoration for Robust Multimodal Sentiment Analysis](http://arxiv.org/abs/2208.07589)</code></li>
<li>Summary: <p>With the proliferation of user-generated online videos, Multimodal Sentiment
Analysis (MSA) has attracted increasing attention recently. Despite significant
progress, there are still two major challenges on the way towards robust MSA:
1) inefficiency when modeling cross-modal interactions in unaligned multimodal
data; and 2) vulnerability to random modality feature missing which typically
occurs in realistic settings. In this paper, we propose a generic and unified
framework to address them, named Efficient Multimodal Transformer with
Dual-Level Feature Restoration (EMT-DLFR). Concretely, EMT employs
utterance-level representations from each modality as the global multimodal
context to interact with local unimodal features and mutually promote each
other. It not only avoids the quadratic scaling cost of previous local-local
cross-modal interaction methods but also leads to better performance. To
improve model robustness in the incomplete modality setting, on the one hand,
DLFR performs low-level feature reconstruction to implicitly encourage the
model to learn semantic information from incomplete data. On the other hand, it
innovatively regards complete and incomplete data as two different views of one
sample and utilizes siamese representation learning to explicitly attract their
high-level representations. Comprehensive experiments on three popular datasets
demonstrate that our method achieves superior performance in both complete and
incomplete modality settings.
</p></li>
</ul>

<h3>Title: Uncertainty-guided Source-free Domain Adaptation. (arXiv:2208.07591v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2208.07591">http://arxiv.org/abs/2208.07591</a></li>
<li>Code URL: <a href="https://github.com/roysubhankar/uncertainty-sfda">https://github.com/roysubhankar/uncertainty-sfda</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2208.07591] Uncertainty-guided Source-free Domain Adaptation](http://arxiv.org/abs/2208.07591)</code></li>
<li>Summary: <p>Source-free domain adaptation (SFDA) aims to adapt a classifier to an
unlabelled target data set by only using a pre-trained source model. However,
the absence of the source data and the domain shift makes the predictions on
the target data unreliable. We propose quantifying the uncertainty in the
source model predictions and utilizing it to guide the target adaptation. For
this, we construct a probabilistic source model by incorporating priors on the
network parameters inducing a distribution over the model predictions.
Uncertainties are estimated by employing a Laplace approximation and
incorporated to identify target data points that do not lie in the source
manifold and to down-weight them when maximizing the mutual information on the
target data. Unlike recent works, our probabilistic treatment is
computationally lightweight, decouples source training and target adaptation,
and requires no specialized source training or changes of the model
architecture. We show the advantages of uncertainty-guided SFDA over
traditional SFDA in the closed-set and open-set settings and provide empirical
evidence that our approach is more robust to strong domain shifts even without
tuning.
</p></li>
</ul>

<h3>Title: BERTifying Sinhala -- A Comprehensive Analysis of Pre-trained Language Models for Sinhala Text Classification. (arXiv:2208.07864v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2208.07864">http://arxiv.org/abs/2208.07864</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2208.07864] BERTifying Sinhala -- A Comprehensive Analysis of Pre-trained Language Models for Sinhala Text Classification](http://arxiv.org/abs/2208.07864)</code></li>
<li>Summary: <p>This research provides the first comprehensive analysis of the performance of
pre-trained language models for Sinhala text classification. We test on a set
of different Sinhala text classification tasks and our analysis shows that out
of the pre-trained multilingual models that include Sinhala (XLM-R, LaBSE, and
LASER), XLM-R is the best model by far for Sinhala text classification. We also
pre-train two RoBERTa-based monolingual Sinhala models, which are far superior
to the existing pre-trained language models for Sinhala. We show that when
fine-tuned, these pre-trained language models set a very strong baseline for
Sinhala text classification and are robust in situations where labeled data is
insufficient for fine-tuning. We further provide a set of recommendations for
using pre-trained models for Sinhala text classification. We also introduce new
annotated datasets useful for future research in Sinhala text classification
and publicly release our pre-trained models.
</p></li>
</ul>

<h3>Title: KRACL: Contrastive Learning with Graph Context Modeling for Sparse Knowledge Graph Completion. (arXiv:2208.07622v1 [cs.AI])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2208.07622">http://arxiv.org/abs/2208.07622</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2208.07622] KRACL: Contrastive Learning with Graph Context Modeling for Sparse Knowledge Graph Completion](http://arxiv.org/abs/2208.07622)</code></li>
<li>Summary: <p>Knowledge Graph Embeddings (KGE) aim to map entities and relations to low
dimensional spaces and have become the \textit{de-facto} standard for knowledge
graph completion. Most existing KGE methods suffer from the sparsity challenge,
where it is harder to predict entities that appear less frequently in knowledge
graphs. In this work, we propose a novel framework KRACL to alleviate the
widespread sparsity in KGs with graph context and contrastive learning.
Firstly, we propose the Knowledge Relational Attention Network (KRAT) to
leverage the graph context by simultaneously projecting neighboring triples to
different latent spaces and jointly aggregating messages with the attention
mechanism. KRAT is capable of capturing the subtle semantic information and
importance of different context triples as well as leveraging multi-hop
information in knowledge graphs. Secondly, we propose the knowledge contrastive
loss by combining the contrastive loss with cross entropy loss, which
introduces more negative samples and thus enriches the feedback to sparse
entities. Our experiments demonstrate that KRACL achieves superior results
across various standard knowledge graph benchmarks, especially on WN18RR and
NELL-995 which have large numbers of low in-degree entities. Extensive
experiments also bear out KRACL's effectiveness in handling sparse knowledge
graphs and robustness against noisy triples.
</p></li>
</ul>

<h3>Title: A Review of the Convergence of 5G/6G Architecture and Deep Learning. (arXiv:2208.07643v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2208.07643">http://arxiv.org/abs/2208.07643</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2208.07643] A Review of the Convergence of 5G/6G Architecture and Deep Learning](http://arxiv.org/abs/2208.07643)</code></li>
<li>Summary: <p>The convergence of 5G architecture and deep learning has gained a lot of
research interests in both the fields of wireless communication and artificial
intelligence. This is because deep learning technologies have been identified
to be the potential driver of the 5G technologies, that make up the 5G
architecture. Hence, there have been extensive surveys on the convergence of 5G
architecture and deep learning. However, most of the existing survey papers
mainly focused on how deep learning can converge with a specific 5G technology,
thus, not covering the full spectrum of the 5G architecture. Although there is
a recent survey paper that appears to be robust, a review of that paper shows
that it is not well structured to specifically cover the convergence of deep
learning and the 5G technologies. Hence, this paper provides a robust overview
of the convergence of the key 5G technologies and deep learning. The challenges
faced by such convergence are discussed. In addition, a brief overview of the
future 6G architecture, and how it can converge with deep learning is also
discussed.
</p></li>
</ul>

<h3>Title: An Overview and Prospective Outlook on Robust Training and Certification of Machine Learning Models. (arXiv:2208.07464v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2208.07464">http://arxiv.org/abs/2208.07464</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2208.07464] An Overview and Prospective Outlook on Robust Training and Certification of Machine Learning Models](http://arxiv.org/abs/2208.07464)</code></li>
<li>Summary: <p>In this discussion paper, we survey recent research surrounding robustness of
machine learning models. As learning algorithms become increasingly more
popular in data-driven control systems, their robustness to data uncertainty
must be ensured in order to maintain reliable safety-critical operations. We
begin by reviewing common formalisms for such robustness, and then move on to
discuss popular and state-of-the-art techniques for training robust machine
learning models as well as methods for provably certifying such robustness.
From this unification of robust machine learning, we identify and discuss
pressing directions for future research in the area.
</p></li>
</ul>

<h2>biometric</h2>
<h2>steal</h2>
<h2>extraction</h2>
<h3>Title: BERT(s) to Detect Multiword Expressions. (arXiv:2208.07832v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2208.07832">http://arxiv.org/abs/2208.07832</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2208.07832] BERT(s) to Detect Multiword Expressions](http://arxiv.org/abs/2208.07832)</code></li>
<li>Summary: <p>Multiword expressions (MWEs) present groups of words in which the meaning of
the whole is not derived from the meaning of its parts. The task of processing
MWEs is crucial in many natural language processing (NLP) applications,
including machine translation and terminology extraction. Therefore, detecting
MWEs is a popular research theme. In this paper, we explore state-of-the-art
neural transformers in the task of detecting MWEs.We empirically evaluate
several transformer models in the dataset for SemEval-2016 Task 10: Detecting
Minimal Semantic Units and their Meanings (DiMSUM). We show that transformer
models outperform the previous neural models based on long short-term memory
(LSTM). The code and pre-trained model will be made freely available to the
community.
</p></li>
</ul>

<h2>membership infer</h2>
<h2>federate</h2>
<h3>Title: Knowledge-Injected Federated Learning. (arXiv:2208.07530v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2208.07530">http://arxiv.org/abs/2208.07530</a></li>
<li>Code URL: <a href="https://github.com/zhenanfanubc/fedmech.jl">https://github.com/zhenanfanubc/fedmech.jl</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2208.07530] Knowledge-Injected Federated Learning](http://arxiv.org/abs/2208.07530)</code></li>
<li>Summary: <p>Federated learning is an emerging technique for training models from
decentralized data sets. In many applications, data owners participating in the
federated learning system hold not only the data but also a set of domain
knowledge. Such knowledge includes human know-how and craftsmanship that can be
extremely helpful to the federated learning task. In this work, we propose a
federated learning framework that allows the injection of participants' domain
knowledge, where the key idea is to refine the global model with knowledge
locally. The scenario we consider is motivated by a real industry-level
application, and we demonstrate the effectiveness of our approach to this
application.
</p></li>
</ul>

<h2>fair</h2>
<h3>Title: QuickSkill: Novice Skill Estimation in Online Multiplayer Games. (arXiv:2208.07704v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2208.07704">http://arxiv.org/abs/2208.07704</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2208.07704] QuickSkill: Novice Skill Estimation in Online Multiplayer Games](http://arxiv.org/abs/2208.07704)</code></li>
<li>Summary: <p>Matchmaking systems are vital for creating fair matches in online multiplayer
games, which directly affects players' satisfactions and game experience. Most
of the matchmaking systems largely rely on precise estimation of players' game
skills to construct equitable games. However, the skill rating of a novice is
usually inaccurate, as current matchmaking rating algorithms require
considerable amount of games for learning the true skill of a new player. Using
these unreliable skill scores at early stages for matchmaking usually leads to
disparities in terms of team performance, which causes negative game
experience. This is known as the ''cold-start'' problem for matchmaking rating
algorithms.
</p></li>
</ul>

<p>To overcome this conundrum, this paper proposes QuickSKill, a deep learning
based novice skill estimation framework to quickly probe abilities of new
players in online multiplayer games. QuickSKill extracts sequential performance
features from initial few games of a player to predict his/her future skill
rating with a dedicated neural network, thus delivering accurate skill
estimation at the player's early game stage. By employing QuickSKill for
matchmaking, game fairness can be dramatically improved in the initial
cold-start period. We conduct experiments in a popular mobile multiplayer game
in both offline and online scenarios. Results obtained with two real-world
anonymized gaming datasets demonstrate that proposed QuickSKill delivers
precise estimation of game skills for novices, leading to significantly lower
team skill disparities and better player game experience. To the best of our
knowledge, proposed QuickSKill is the first framework that tackles the
cold-start problem for traditional skill rating algorithms.
</p>

<h2>interpretability</h2>
<h2>exlainability</h2>
<h2>watermark</h2>
<h3>Title: Neural network fragile watermarking with no model performance degradation. (arXiv:2208.07585v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2208.07585">http://arxiv.org/abs/2208.07585</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2208.07585] Neural network fragile watermarking with no model performance degradation](http://arxiv.org/abs/2208.07585)</code></li>
<li>Summary: <p>Deep neural networks are vulnerable to malicious fine-tuning attacks such as
data poisoning and backdoor attacks. Therefore, in recent research, it is
proposed how to detect malicious fine-tuning of neural network models. However,
it usually negatively affects the performance of the protected model. Thus, we
propose a novel neural network fragile watermarking with no model performance
degradation. In the process of watermarking, we train a generative model with
the specific loss function and secret key to generate triggers that are
sensitive to the fine-tuning of the target classifier. In the process of
verifying, we adopt the watermarked classifier to get labels of each fragile
trigger. Then, malicious fine-tuning can be detected by comparing secret keys
and labels. Experiments on classic datasets and classifiers show that the
proposed method can effectively detect model malicious fine-tuning with no
model performance degradation.
</p></li>
</ul>

<button id="copy">Copy All</button>
</article>
<script src="../../javascript/clipboard.min.js"></script>
<script src="../../javascript/clipboard.js"></script>
