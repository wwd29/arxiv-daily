<link rel="stylesheet" href="../../css/markdown.css" />
<article class="markdown-body">
<h1>2024-03-13</h1>
<h3>Title: Guiding LLMs The Right Way: Fast, Non-Invasive Constrained Generation</h3>
<ul>
<li><strong>Authors: </strong>Luca Beurer-Kellner, Marc Fischer, Martin Vechev</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2403.06988">https://arxiv.org/abs/2403.06988</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2403.06988">https://arxiv.org/pdf/2403.06988</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2403.06988]] Guiding LLMs The Right Way: Fast, Non-Invasive Constrained Generation(https://arxiv.org/abs/2403.06988)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>To ensure that text generated by large language models (LLMs) is in an expected format, constrained decoding proposes to enforce strict formal language constraints during generation. However, as we show in this work, not only do such methods incur performance overhead during generation, but many of them also significantly impair task accuracy, if they do not correctly align the underlying LLM sub-word vocabularies with external constraints. To address this, we present a novel decoding algorithm, DOMINO, that can enforce constraints in a fully subword-aligned fashion, while leveraging pre-computation and speculative decoding to achieve virtually no overhead and in some cases even almost 2$\times$ speedup over unconstrained decoding -- thereby outperforming existing approaches by a wide margin.</li>
</ul>

<h3>Title: Survival modeling using deep learning, machine learning and statistical  methods: A comparative analysis for predicting mortality after hospital  admission</h3>
<ul>
<li><strong>Authors: </strong>Ziwen Wang, Jin Wee Lee, Tanujit Chakraborty, Yilin Ning, Mingxuan Liu, Feng Xie, Marcus Eng Hock Ong, Nan Liu</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CY</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2403.06999">https://arxiv.org/abs/2403.06999</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2403.06999">https://arxiv.org/pdf/2403.06999</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2403.06999]] Survival modeling using deep learning, machine learning and statistical  methods: A comparative analysis for predicting mortality after hospital  admission(https://arxiv.org/abs/2403.06999)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability</a></li>
<li><strong>Abstract: </strong>Survival analysis is essential for studying time-to-event outcomes and providing a dynamic understanding of the probability of an event occurring over time. Various survival analysis techniques, from traditional statistical models to state-of-the-art machine learning algorithms, support healthcare intervention and policy decisions. However, there remains ongoing discussion about their comparative performance. We conducted a comparative study of several survival analysis methods, including Cox proportional hazards (CoxPH), stepwise CoxPH, elastic net penalized Cox model, Random Survival Forests (RSF), Gradient Boosting machine (GBM) learning, AutoScore-Survival, DeepSurv, time-dependent Cox model based on neural network (CoxTime), and DeepHit survival neural network. We applied the concordance index (C-index) for model goodness-of-fit, and integral Brier scores (IBS) for calibration, and considered the model interpretability. As a case study, we performed a retrospective analysis of patients admitted through the emergency department of a tertiary hospital from 2017 to 2019, predicting 90-day all-cause mortality based on patient demographics, clinicopathological features, and historical data. The results of the C-index indicate that deep learning achieved comparable performance, with DeepSurv producing the best discrimination (DeepSurv: 0.893; CoxTime: 0.892; DeepHit: 0.891). The calibration of DeepSurv (IBS: 0.041) performed the best, followed by RSF (IBS: 0.042) and GBM (IBS: 0.0421), all using the full variables. Moreover, AutoScore-Survival, using a minimal variable subset, is easy to interpret, and can achieve good discrimination and calibration (C-index: 0.867; IBS: 0.044). While all models were satisfactory, DeepSurv exhibited the best discrimination and calibration. In addition, AutoScore-Survival offers a more parsimonious model and excellent interpretability.</li>
</ul>

<h3>Title: Adaptive Hyperparameter Optimization for Continual Learning Scenarios</h3>
<ul>
<li><strong>Authors: </strong>Rudy Semola, Julio Hurtado, Vincenzo Lomonaco, Davide Bacciu</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2403.07015">https://arxiv.org/abs/2403.07015</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2403.07015">https://arxiv.org/pdf/2403.07015</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2403.07015]] Adaptive Hyperparameter Optimization for Continual Learning Scenarios(https://arxiv.org/abs/2403.07015)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Hyperparameter selection in continual learning scenarios is a challenging and underexplored aspect, especially in practical non-stationary environments. Traditional approaches, such as grid searches with held-out validation data from all tasks, are unrealistic for building accurate lifelong learning systems. This paper aims to explore the role of hyperparameter selection in continual learning and the necessity of continually and automatically tuning them according to the complexity of the task at hand. Hence, we propose leveraging the nature of sequence task learning to improve Hyperparameter Optimization efficiency. By using the functional analysis of variance-based techniques, we identify the most crucial hyperparameters that have an impact on performance. We demonstrate empirically that this approach, agnostic to continual scenarios and strategies, allows us to speed up hyperparameters optimization continually across tasks and exhibit robustness even in the face of varying sequential task orders. We believe that our findings can contribute to the advancement of continual learning methodologies towards more efficient, robust and adaptable models for real-world applications.</li>
</ul>

<h3>Title: Contemplating Secure and Optimal Design Practices for Information  Infrastructure From a Human Factors Perspective</h3>
<ul>
<li><strong>Authors: </strong>Niroop Sugunaraj</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2403.07018">https://arxiv.org/abs/2403.07018</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2403.07018">https://arxiv.org/pdf/2403.07018</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2403.07018]] Contemplating Secure and Optimal Design Practices for Information  Infrastructure From a Human Factors Perspective(https://arxiv.org/abs/2403.07018)</code><input type="text"></li>
<li><strong>Keywords: </strong>secure, security</a></li>
<li><strong>Abstract: </strong>Designing secure information infrastructure is a function of design and usability. However, security is seldom given priority when systems are being developed. Secure design practices should balance between functionality (i.e., proper design) to meet minimum requirements and user-friendliness. Design recommendations such as those with a user-centric approach (i.e., inclusive of only relevant information, user liberty) and presenting information within its proper context in a clear and engaging manner has been scientifically shown to improve user response and experience.</li>
</ul>

<h3>Title: FWin transformer for dengue prediction under climate and ocean influence</h3>
<ul>
<li><strong>Authors: </strong>Nhat Thanh Tran, Jack Xin, Guofa Zhou</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2403.07027">https://arxiv.org/abs/2403.07027</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2403.07027">https://arxiv.org/pdf/2403.07027</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2403.07027]] FWin transformer for dengue prediction under climate and ocean influence(https://arxiv.org/abs/2403.07027)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Dengue fever is one of the most deadly mosquito-born tropical infectious diseases. Detailed long range forecast model is vital in controlling the spread of disease and making mitigation efforts. In this study, we examine methods used to forecast dengue cases for long range predictions. The dataset consists of local climate/weather in addition to global climate indicators of Singapore from 2000 to 2019. We utilize newly developed deep neural networks to learn the intricate relationship between the features. The baseline models in this study are in the class of recent transformers for long sequence forecasting tasks. We found that a Fourier mixed window attention (FWin) based transformer performed the best in terms of both the mean square error and the maximum absolute error on the long range dengue forecast up to 60 weeks.</li>
</ul>

<h3>Title: An Efficient Learning-based Solver Comparable to Metaheuristics for the  Capacitated Arc Routing Problem</h3>
<ul>
<li><strong>Authors: </strong>Runze Guo, Feng Xue, Anlong Ming, Nicu Sebe</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, math.OC</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2403.07028">https://arxiv.org/abs/2403.07028</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2403.07028">https://arxiv.org/pdf/2403.07028</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2403.07028]] An Efficient Learning-based Solver Comparable to Metaheuristics for the  Capacitated Arc Routing Problem(https://arxiv.org/abs/2403.07028)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Recently, neural networks (NN) have made great strides in combinatorial optimization. However, they face challenges when solving the capacitated arc routing problem (CARP) which is to find the minimum-cost tour covering all required edges on a graph, while within capacity constraints. In tackling CARP, NN-based approaches tend to lag behind advanced metaheuristics, since they lack directed arc modeling and efficient learning methods tailored for complex CARP. In this paper, we introduce an NN-based solver to significantly narrow the gap with advanced metaheuristics while exhibiting superior efficiency. First, we propose the direction-aware attention model (DaAM) to incorporate directionality into the embedding process, facilitating more effective one-stage decision-making. Second, we design a supervised reinforcement learning scheme that involves supervised pre-training to establish a robust initial policy for subsequent reinforcement fine-tuning. It proves particularly valuable for solving CARP that has a higher complexity than the node routing problems (NRPs). Finally, a path optimization method is proposed to adjust the depot return positions within the path generated by DaAM. Experiments illustrate that our approach surpasses heuristics and achieves decision quality comparable to state-of-the-art metaheuristics for the first time while maintaining superior efficiency.</li>
</ul>

<h3>Title: A Model for Assessing Network Asset Vulnerability Using QPSO-LightGBM</h3>
<ul>
<li><strong>Authors: </strong>Xinyu Li, Yu Gu, Chenwei Wang, Peng Zhao</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2403.07029">https://arxiv.org/abs/2403.07029</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2403.07029">https://arxiv.org/pdf/2403.07029</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2403.07029]] A Model for Assessing Network Asset Vulnerability Using QPSO-LightGBM(https://arxiv.org/abs/2403.07029)</code><input type="text"></li>
<li><strong>Keywords: </strong>security</a></li>
<li><strong>Abstract: </strong>With the continuous development of computer technology and network technology, the scale of the network continues to expand, the network space tends to be complex, and the application of computers and networks has been deeply into politics, the military, finance, electricity, and other important fields. When security events do not occur, the vulnerability assessment of these high-risk network assets can be actively carried out to prepare for rainy days, to effectively reduce the loss caused by security events. Therefore, this paper proposes a multi-classification prediction model of network asset vulnerability based on quantum particle swarm algorithm-Lightweight Gradient Elevator (QPSO-LightGBM). In this model, based on using the Synthetic minority oversampling technique (SMOTE) to balance the data, quantum particle swarm optimization (QPSO) was used for automatic parameter optimization, and LightGBM was used for modeling. Realize multi-classification prediction of network asset vulnerability. To verify the rationality of the model, the proposed model is compared with the model constructed by other algorithms. The results show that the proposed model is better in various predictive performance indexes.</li>
</ul>

<h3>Title: AuG-KD: Anchor-Based Mixup Generation for Out-of-Domain Knowledge  Distillation</h3>
<ul>
<li><strong>Authors: </strong>Zihao Tang, Zheqi Lv, Shengyu Zhang, Yifan Zhou, Xinyu Duan, Fei Wu, Kun Kuang</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2403.07030">https://arxiv.org/abs/2403.07030</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2403.07030">https://arxiv.org/pdf/2403.07030</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2403.07030]] AuG-KD: Anchor-Based Mixup Generation for Out-of-Domain Knowledge  Distillation(https://arxiv.org/abs/2403.07030)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, data-free, generative</a></li>
<li><strong>Abstract: </strong>Due to privacy or patent concerns, a growing number of large models are released without granting access to their training data, making transferring their knowledge inefficient and problematic. In response, Data-Free Knowledge Distillation (DFKD) methods have emerged as direct solutions. However, simply adopting models derived from DFKD for real-world applications suffers significant performance degradation, due to the discrepancy between teachers' training data and real-world scenarios (student domain). The degradation stems from the portions of teachers' knowledge that are not applicable to the student domain. They are specific to the teacher domain and would undermine students' performance. Hence, selectively transferring teachers' appropriate knowledge becomes the primary challenge in DFKD. In this work, we propose a simple but effective method AuG-KD. It utilizes an uncertainty-guided and sample-specific anchor to align student-domain data with the teacher domain and leverages a generative method to progressively trade off the learning process between OOD knowledge distillation and domain-specific information learning via mixup learning. Extensive experiments in 3 datasets and 8 settings demonstrate the stability and superiority of our approach. Code available at https://github.com/IshiKura-a/AuG-KD .</li>
</ul>

<h3>Title: Interpreting What Typical Fault Signals Look Like via Prototype-matching</h3>
<ul>
<li><strong>Authors: </strong>Qian Chen, Xingjian Dong, Zhike Peng</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2403.07033">https://arxiv.org/abs/2403.07033</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2403.07033">https://arxiv.org/pdf/2403.07033</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2403.07033]] Interpreting What Typical Fault Signals Look Like via Prototype-matching(https://arxiv.org/abs/2403.07033)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability</a></li>
<li><strong>Abstract: </strong>Neural networks, with powerful nonlinear mapping and classification capabilities, are widely applied in mechanical fault diagnosis to ensure safety. However, being typical black-box models, their application is limited in high-reliability-required scenarios. To understand the classification logic and explain what typical fault signals look like, the prototype matching network (PMN) is proposed by combining the human-inherent prototype-matching with autoencoder (AE). The PMN matches AE-extracted feature with each prototype and selects the most similar prototype as the prediction result. It has three interpreting paths on classification logic, fault prototypes, and matching contributions. Conventional diagnosis and domain generalization experiments demonstrate its competitive diagnostic performance and distinguished advantages in representation learning. Besides, the learned typical fault signals (i.e., sample-level prototypes) showcase the ability for denoising and extracting subtle key features that experts find challenging to capture. This ability broadens human understanding and provides a promising solution from interpretability research to AI-for-Science.</li>
</ul>

<h3>Title: Ant Colony Sampling with GFlowNets for Combinatorial Optimization</h3>
<ul>
<li><strong>Authors: </strong>Minsu Kim, Sanghyeok Choi, Jiwoo Son, Hyeonah Kim, Jinkyoo Park, Yoshua Bengio</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.NE</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2403.07041">https://arxiv.org/abs/2403.07041</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2403.07041">https://arxiv.org/pdf/2403.07041</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2403.07041]] Ant Colony Sampling with GFlowNets for Combinatorial Optimization(https://arxiv.org/abs/2403.07041)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>This paper introduces the Generative Flow Ant Colony Sampler (GFACS), a novel neural-guided meta-heuristic algorithm for combinatorial optimization. GFACS integrates generative flow networks (GFlowNets) with the ant colony optimization (ACO) methodology. GFlowNets, a generative model that learns a constructive policy in combinatorial spaces, enhance ACO by providing an informed prior distribution of decision variables conditioned on input graph instances. Furthermore, we introduce a novel combination of training tricks, including search-guided local exploration, energy normalization, and energy shaping to improve GFACS. Our experimental results demonstrate that GFACS outperforms baseline ACO algorithms in seven CO tasks and is competitive with problem-specific heuristics for vehicle routing problems. The source code is available at \url{https://github.com/ai4co/gfacs}.</li>
</ul>

<h3>Title: Explainable Learning with Gaussian Processes</h3>
<ul>
<li><strong>Authors: </strong>Kurt Butler, Guanchao Feng, Petar M. Djuric</a></li>
<li><strong>Subjects: </strong>cs.LG, eess.SP</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2403.07072">https://arxiv.org/abs/2403.07072</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2403.07072">https://arxiv.org/pdf/2403.07072</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2403.07072]] Explainable Learning with Gaussian Processes(https://arxiv.org/abs/2403.07072)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>The field of explainable artificial intelligence (XAI) attempts to develop methods that provide insight into how complicated machine learning methods make predictions. Many methods of explanation have focused on the concept of feature attribution, a decomposition of the model's prediction into individual contributions corresponding to each input feature. In this work, we explore the problem of feature attribution in the context of Gaussian process regression (GPR). We take a principled approach to defining attributions under model uncertainty, extending the existing literature. We show that although GPR is a highly flexible and non-parametric approach, we can derive interpretable, closed-form expressions for the feature attributions. When using integrated gradients as an attribution method, we show that the attributions of a GPR model also follow a Gaussian process distribution, which quantifies the uncertainty in attribution arising from uncertainty in the model. We demonstrate, both through theory and experimentation, the versatility and robustness of this approach. We also show that, when applicable, the exact expressions for GPR attributions are both more accurate and less computationally expensive than the approximations currently used in practice. The source code for this project is freely available under MIT license at https://github.com/KurtButler/2024_attributions_paper.</li>
</ul>

<h3>Title: Improving deep learning with prior knowledge and cognitive models: A  survey on enhancing explainability, adversarial robustness and zero-shot  learning</h3>
<ul>
<li><strong>Authors: </strong>Fuseinin Mumuni, Alhassan Mumuni</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2403.07078">https://arxiv.org/abs/2403.07078</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2403.07078">https://arxiv.org/pdf/2403.07078</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2403.07078]] Improving deep learning with prior knowledge and cognitive models: A  survey on enhancing explainability, adversarial robustness and zero-shot  learning(https://arxiv.org/abs/2403.07078)</code><input type="text"></li>
<li><strong>Keywords: </strong>defense, attack, robust, interpretability, explainability</a></li>
<li><strong>Abstract: </strong>We review current and emerging knowledge-informed and brain-inspired cognitive systems for realizing adversarial defenses, eXplainable Artificial Intelligence (XAI), and zero-shot or few-short learning. Data-driven deep learning models have achieved remarkable performance and demonstrated capabilities surpassing human experts in many applications. Yet, their inability to exploit domain knowledge leads to serious performance limitations in practical applications. In particular, deep learning systems are exposed to adversarial attacks, which can trick them into making glaringly incorrect decisions. Moreover, complex data-driven models typically lack interpretability or explainability, i.e., their decisions cannot be understood by human subjects. Furthermore, models are usually trained on standard datasets with a closed-world assumption. Hence, they struggle to generalize to unseen cases during inference in practical open-world environments, thus, raising the zero- or few-shot generalization problem. Although many conventional solutions exist, explicit domain knowledge, brain-inspired neural network and cognitive architectures offer powerful new dimensions towards alleviating these problems. Prior knowledge is represented in appropriate forms and incorporated in deep learning frameworks to improve performance. Brain-inspired cognition methods use computational models that mimic the human mind to enhance intelligent behavior in artificial agents and autonomous robots. Ultimately, these models achieve better explainability, higher adversarial robustness and data-efficient learning, and can, in turn, provide insights for cognitive science and neuroscience-that is, to deepen human understanding on how the brain works in general, and how it handles these problems.</li>
</ul>

<h3>Title: SPA: Towards A Computational Friendly Cloud-Base and On-Devices  Collaboration Seq2seq Personalized Generation</h3>
<ul>
<li><strong>Authors: </strong>Yanming Liu, Xinyue Peng, Jiannan Cao, Le Dai, Xingzu Liu, Weihao Liu, Mingbang Wang</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2403.07088">https://arxiv.org/abs/2403.07088</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2403.07088">https://arxiv.org/pdf/2403.07088</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2403.07088]] SPA: Towards A Computational Friendly Cloud-Base and On-Devices  Collaboration Seq2seq Personalized Generation(https://arxiv.org/abs/2403.07088)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, large language model</a></li>
<li><strong>Abstract: </strong>Large language models(LLMs) have shown its outperforming ability on various tasks and question answering. However, LLMs require high computation cost and large memory cost. At the same time, LLMs may cause privacy leakage when training or prediction procedure contains sensitive information. In this paper, we propose SPA(Side Plugin Adaption), a lightweight architecture for fast on-devices inference and privacy retaining on the constraints of strict on-devices computation and memory constraints. Compared with other on-devices seq2seq generation, SPA could make a fast and stable inference on low-resource constraints, allowing it to obtain cost effiency. Our method establish an interaction between a pretrained LLMs on-cloud and additive parameters on-devices, which could provide the knowledge on both pretrained LLMs and private personal feature.Further more, SPA provides a framework to keep feature-base parameters on private guaranteed but low computational devices while leave the parameters containing general information on the high computational devices.</li>
</ul>

<h3>Title: Overcoming the Paradox of Certified Training with Gaussian Smoothing</h3>
<ul>
<li><strong>Authors: </strong>Stefan Balauca, Mark Niklas MÃ¼ller, Yuhao Mao, Maximilian Baader, Marc Fischer, Martin Vechev</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2403.07095">https://arxiv.org/abs/2403.07095</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2403.07095">https://arxiv.org/pdf/2403.07095</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2403.07095]] Overcoming the Paradox of Certified Training with Gaussian Smoothing(https://arxiv.org/abs/2403.07095)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Training neural networks with high certified accuracy against adversarial examples remains an open problem despite significant efforts. While certification methods can effectively leverage tight convex relaxations for bound computation, in training, these methods perform worse than looser relaxations. Prior work hypothesized that this is caused by the discontinuity and perturbation sensitivity of the loss surface induced by these tighter relaxations. In this work, we show theoretically that Gaussian Loss Smoothing can alleviate both of these issues. We confirm this empirically by proposing a certified training method combining PGPE, an algorithm computing gradients of a smoothed loss, with different convex relaxations. When using this training method, we observe that tighter bounds indeed lead to strictly better networks that can outperform state-of-the-art methods on the same network. While scaling PGPE-based training remains challenging due to high computational cost, our results clearly demonstrate the promise of Gaussian Loss Smoothing for training certifiably robust neural networks.</li>
</ul>

<h3>Title: Narrating Causal Graphs with Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Atharva Phatak, Vijay K. Mago, Ameeta Agrawal, Aravind Inbasekaran, Philippe J. Giabbanelli</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2403.07118">https://arxiv.org/abs/2403.07118</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2403.07118">https://arxiv.org/pdf/2403.07118</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2403.07118]] Narrating Causal Graphs with Large Language Models(https://arxiv.org/abs/2403.07118)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative, large language model</a></li>
<li><strong>Abstract: </strong>The use of generative AI to create text descriptions from graphs has mostly focused on knowledge graphs, which connect concepts using facts. In this work we explore the capability of large pretrained language models to generate text from causal graphs, where salient concepts are represented as nodes and causality is represented via directed, typed edges. The causal reasoning encoded in these graphs can support applications as diverse as healthcare or marketing. Using two publicly available causal graph datasets, we empirically investigate the performance of four GPT-3 models under various settings. Our results indicate that while causal text descriptions improve with training data, compared to fact-based graphs, they are harder to generate under zero-shot settings. Results further suggest that users of generative AI can deploy future applications faster since similar performances are obtained when training a model with only a few examples as compared to fine-tuning via a large curated dataset.</li>
</ul>

<h3>Title: COMQ: A Backpropagation-Free Algorithm for Post-Training Quantization</h3>
<ul>
<li><strong>Authors: </strong>Aozhong Zhang, Zi Yang, Naigang Wang, Yingyong Qin, Jack Xin, Xin Li, Penghang Yin</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2403.07134">https://arxiv.org/abs/2403.07134</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2403.07134">https://arxiv.org/pdf/2403.07134</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2403.07134]] COMQ: A Backpropagation-Free Algorithm for Post-Training Quantization(https://arxiv.org/abs/2403.07134)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Post-training quantization (PTQ) has emerged as a practical approach to compress large neural networks, making them highly efficient for deployment. However, effectively reducing these models to their low-bit counterparts without compromising the original accuracy remains a key challenge. In this paper, we propose an innovative PTQ algorithm termed COMQ, which sequentially conducts coordinate-wise minimization of the layer-wise reconstruction errors. We consider the widely used integer quantization, where every quantized weight can be decomposed into a shared floating-point scalar and an integer bit-code. Within a fixed layer, COMQ treats all the scaling factor(s) and bit-codes as the variables of the reconstruction error. Every iteration improves this error along a single coordinate while keeping all other variables constant. COMQ is easy to use and requires no hyper-parameter tuning. It instead involves only dot products and rounding operations. We update these variables in a carefully designed greedy order, significantly enhancing the accuracy. COMQ achieves remarkable results in quantizing 4-bit Vision Transformers, with a negligible loss of less than 1% in Top-1 accuracy. In 4-bit INT quantization of convolutional neural networks, COMQ maintains near-lossless accuracy with a minimal drop of merely 0.3% in Top-1 accuracy.</li>
</ul>

<h3>Title: One Category One Prompt: Dataset Distillation using Diffusion Models</h3>
<ul>
<li><strong>Authors: </strong>Ali Abbasi, Ashkan Shahbazi, Hamed Pirsiavash, Soheil Kolouri</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.CL, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2403.07142">https://arxiv.org/abs/2403.07142</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2403.07142">https://arxiv.org/pdf/2403.07142</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2403.07142]] One Category One Prompt: Dataset Distillation using Diffusion Models(https://arxiv.org/abs/2403.07142)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, generative</a></li>
<li><strong>Abstract: </strong>The extensive amounts of data required for training deep neural networks pose significant challenges on storage and transmission fronts. Dataset distillation has emerged as a promising technique to condense the information of massive datasets into a much smaller yet representative set of synthetic samples. However, traditional dataset distillation approaches often struggle to scale effectively with high-resolution images and more complex architectures due to the limitations in bi-level optimization. Recently, several works have proposed exploiting knowledge distillation with decoupled optimization schemes to scale up dataset distillation. Although these methods effectively address the scalability issue, they rely on extensive image augmentations requiring the storage of soft labels for augmented images. In this paper, we introduce Dataset Distillation using Diffusion Models (D3M) as a novel paradigm for dataset distillation, leveraging recent advancements in generative text-to-image foundation models. Our approach utilizes textual inversion, a technique for fine-tuning text-to-image generative models, to create concise and informative representations for large datasets. By employing these learned text prompts, we can efficiently store and infer new samples for introducing data variability within a fixed memory budget. We show the effectiveness of our method through extensive experiments across various computer vision benchmark datasets with different memory budgets.</li>
</ul>

<h3>Title: Don't Forget What I did?: Assessing Client Contributions in Federated  Learning</h3>
<ul>
<li><strong>Authors: </strong>Bishwamittra Ghosh, Debabrota Basu, Fu Huazhu, Wang Yuan, Renuga Kanagavelu, Jiang Jin Peng, Liu Yong, Goh Siow Mong Rick, Wei Qingsong</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2403.07151">https://arxiv.org/abs/2403.07151</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2403.07151">https://arxiv.org/pdf/2403.07151</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2403.07151]] Don't Forget What I did?: Assessing Client Contributions in Federated  Learning(https://arxiv.org/abs/2403.07151)</code><input type="text"></li>
<li><strong>Keywords: </strong>federate, fair</a></li>
<li><strong>Abstract: </strong>Federated Learning (FL) is a collaborative machine learning (ML) approach, where multiple clients participate in training an ML model without exposing the private data. Fair and accurate assessment of client contributions is an important problem in FL to facilitate incentive allocation and encouraging diverse clients to participate in a unified model training. Existing methods for assessing client contribution adopts co-operative game-theoretic concepts, such as Shapley values, but under simplified assumptions. In this paper, we propose a history-aware game-theoretic framework, called FLContrib, to assess client contributions when a subset of (potentially non-i.i.d.) clients participate in each epoch of FL training. By exploiting the FL training process and linearity of Shapley value, we develop FLContrib that yields a historical timeline of client contributions as FL training progresses over epochs. Additionally, to assess client contribution under limited computational budget, we propose a scheduling procedure that considers a two-sided fairness criteria to perform expensive Shapley value computation only in a subset of training epochs. In experiments, we demonstrate a controlled trade-off between the correctness and efficiency of client contributions assessed via FLContrib. To demonstrate the benefits of history-aware client contributions, we apply FLContrib to detect dishonest clients conducting data poisoning in FL training.</li>
</ul>

<h3>Title: 2023 Low-Power Computer Vision Challenge (LPCVC) Summary</h3>
<ul>
<li><strong>Authors: </strong>Leo Chen, Benjamin Boardley, Ping Hu, Yiru Wang, Yifan Pu, Xin Jin, Yongqiang Yao, Ruihao Gong, Bo Li, Gao Huang, Xianglong Liu, Zifu Wan, Xinwang Chen, Ning Liu, Ziyi Zhang, Dongping Liu, Ruijie Shan, Zhengping Che, Fachao Zhang, Xiaofeng Mou, Jian Tang, Maxim Chuprov, Ivan Malofeev, Alexander Goncharenko, Andrey Shcherbin, Arseny Yanchenko, Sergey Alyamkin, Xiao Hu, George K. Thiruvathukal, Yung Hsiang Lu</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2403.07153">https://arxiv.org/abs/2403.07153</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2403.07153">https://arxiv.org/pdf/2403.07153</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2403.07153]] 2023 Low-Power Computer Vision Challenge (LPCVC) Summary(https://arxiv.org/abs/2403.07153)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>This article describes the 2023 IEEE Low-Power Computer Vision Challenge (LPCVC). Since 2015, LPCVC has been an international competition devoted to tackling the challenge of computer vision (CV) on edge devices. Most CV researchers focus on improving accuracy, at the expense of ever-growing sizes of machine models. LPCVC balances accuracy with resource requirements. Winners must achieve high accuracy with short execution time when their CV solutions run on an embedded device, such as Raspberry PI or Nvidia Jetson Nano. The vision problem for 2023 LPCVC is segmentation of images acquired by Unmanned Aerial Vehicles (UAVs, also called drones) after disasters. The 2023 LPCVC attracted 60 international teams that submitted 676 solutions during the submission window of one month. This article explains the setup of the competition and highlights the winners' methods that improve accuracy and shorten execution time.</li>
</ul>

<h3>Title: 3M-Diffusion: Latent Multi-Modal Diffusion for Text-Guided Generation of  Molecular Graphs</h3>
<ul>
<li><strong>Authors: </strong>Huaisheng Zhu, Teng Xiao, Vasant G Honavar</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CL, q-bio.BM</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2403.07179">https://arxiv.org/abs/2403.07179</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2403.07179">https://arxiv.org/pdf/2403.07179</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2403.07179]] 3M-Diffusion: Latent Multi-Modal Diffusion for Text-Guided Generation of  Molecular Graphs(https://arxiv.org/abs/2403.07179)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, large language model</a></li>
<li><strong>Abstract: </strong>Generating molecules with desired properties is a critical task with broad applications in drug discovery and materials design. Inspired by recent advances in large language models, there is a growing interest in using natural language descriptions of molecules to generate molecules with the desired properties. Most existing methods focus on generating molecules that precisely match the text description. However, practical applications call for methods that generate diverse, and ideally novel, molecules with the desired properties. We propose 3M-Diffusion, a novel multi-modal molecular graph generation method, to address this challenge. 3M-Diffusion first encodes molecular graphs into a graph latent space aligned with text descriptions. It then reconstructs the molecular structure and atomic attributes based on the given text descriptions using the molecule decoder. It then learns a probabilistic mapping from the text space to the latent molecular graph space using a diffusion model. The results of our extensive experiments on several datasets demonstrate that 3M-Diffusion can generate high-quality, novel and diverse molecular graphs that semantically match the textual description provided.</li>
</ul>

<h3>Title: Monitoring AI-Modified Content at Scale: A Case Study on the Impact of  ChatGPT on AI Conference Peer Reviews</h3>
<ul>
<li><strong>Authors: </strong>Weixin Liang, Zachary Izzo, Yaohui Zhang, Haley Lepp, Hancheng Cao, Xuandong Zhao, Lingjiao Chen, Haotian Ye, Sheng Liu, Zhi Huang, Daniel A. McFarland, James Y. Zou</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.LG, cs.SI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2403.07183">https://arxiv.org/abs/2403.07183</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2403.07183">https://arxiv.org/pdf/2403.07183</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2403.07183]] Monitoring AI-Modified Content at Scale: A Case Study on the Impact of  ChatGPT on AI Conference Peer Reviews(https://arxiv.org/abs/2403.07183)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>We present an approach for estimating the fraction of text in a large corpus which is likely to be substantially modified or produced by a large language model (LLM). Our maximum likelihood model leverages expert-written and AI-generated reference texts to accurately and efficiently examine real-world LLM-use at the corpus level. We apply this approach to a case study of scientific peer review in AI conferences that took place after the release of ChatGPT: ICLR 2024, NeurIPS 2023, CoRL 2023 and EMNLP 2023. Our results suggest that between 6.5% and 16.9% of text submitted as peer reviews to these conferences could have been substantially modified by LLMs, i.e. beyond spell-checking or minor writing updates. The circumstances in which generated text occurs offer insight into user behavior: the estimated fraction of LLM-generated text is higher in reviews which report lower confidence, were submitted close to the deadline, and from reviewers who are less likely to respond to author rebuttals. We also observe corpus-level trends in generated text which may be too subtle to detect at the individual level, and discuss the implications of such trends on peer review. We call for future interdisciplinary work to examine how LLM use is changing our information and knowledge practices.</li>
</ul>

<h3>Title: $\mathbf{(N,K)}$-Puzzle: A Cost-Efficient Testbed for Benchmarking  Reinforcement Learning Algorithms in Generative Language Model</h3>
<ul>
<li><strong>Authors: </strong>Yufeng Zhang, Liyu Chen, Boyi Liu, Yingxiang Yang, Qiwen Cui, Yunzhe Tao, Hongxia Yang</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2403.07191">https://arxiv.org/abs/2403.07191</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2403.07191">https://arxiv.org/pdf/2403.07191</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2403.07191]] $\mathbf{(N,K)}$-Puzzle: A Cost-Efficient Testbed for Benchmarking  Reinforcement Learning Algorithms in Generative Language Model(https://arxiv.org/abs/2403.07191)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>Recent advances in reinforcement learning (RL) algorithms aim to enhance the performance of language models at scale. Yet, there is a noticeable absence of a cost-effective and standardized testbed tailored to evaluating and comparing these algorithms. To bridge this gap, we present a generalized version of the 24-Puzzle: the $(N,K)$-Puzzle, which challenges language models to reach a target value $K$ with $N$ integers. We evaluate the effectiveness of established RL algorithms such as Proximal Policy Optimization (PPO), alongside novel approaches like Identity Policy Optimization (IPO) and Direct Policy Optimization (DPO).</li>
</ul>

<h3>Title: A multi-cohort study on prediction of acute brain dysfunction states  using selective state space models</h3>
<ul>
<li><strong>Authors: </strong>Brandon Silva, Miguel Contreras, Sabyasachi Bandyopadhyay, Yuanfang Ren, Ziyuan Guan, Jeremy Balch, Kia Khezeli, Tezcan Ozrazgat Baslanti, Ben Shickel, Azra Bihorac, Parisa Rashidi</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, stat.AP</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2403.07201">https://arxiv.org/abs/2403.07201</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2403.07201">https://arxiv.org/pdf/2403.07201</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2403.07201]] A multi-cohort study on prediction of acute brain dysfunction states  using selective state space models(https://arxiv.org/abs/2403.07201)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, transformer</a></li>
<li><strong>Abstract: </strong>Assessing acute brain dysfunction (ABD), including delirium and coma in the intensive care unit (ICU), is a critical challenge due to its prevalence and severe implications for patient outcomes. Current diagnostic methods rely on infrequent clinical observations, which can only determine a patient's ABD status after onset. Our research attempts to solve these problems by harnessing Electronic Health Records (EHR) data to develop automated methods for ABD prediction for patients in the ICU. Existing models solely predict a single state (e.g., either delirium or coma), require at least 24 hours of observation data to make predictions, do not dynamically predict fluctuating ABD conditions during ICU stay (typically a one-time prediction), and use small sample size, proprietary single-hospital datasets. Our research fills these gaps in the existing literature by dynamically predicting delirium, coma, and mortality for 12-hour intervals throughout an ICU stay and validating on two public datasets. Our research also introduces the concept of dynamically predicting critical transitions from non-ABD to ABD and between different ABD states in real time, which could be clinically more informative for the hospital staff. We compared the predictive performance of two state-of-the-art neural network models, the MAMBA selective state space model and the Longformer Transformer model. Using the MAMBA model, we achieved a mean area under the receiving operator characteristic curve (AUROC) of 0.95 on outcome prediction of ABD for 12-hour intervals. The model achieves a mean AUROC of 0.79 when predicting transitions between ABD states. Our study uses a curated dataset from the University of Florida Health Shands Hospital for internal validation and two publicly available datasets, MIMIC-IV and eICU, for external validation, demonstrating robustness across ICU stays from 203 hospitals and 140,945 patients.</li>
</ul>

<h3>Title: Text-to-Image Diffusion Models are Great Sketch-Photo Matchmakers</h3>
<ul>
<li><strong>Authors: </strong>Subhadeep Koley, Ayan Kumar Bhunia, Aneeshan Sain, Pinaki Nath Chowdhury, Tao Xiang, Yi-Zhe Song</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2403.07214">https://arxiv.org/abs/2403.07214</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2403.07214">https://arxiv.org/pdf/2403.07214</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2403.07214]] Text-to-Image Diffusion Models are Great Sketch-Photo Matchmakers(https://arxiv.org/abs/2403.07214)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, extraction, diffusion</a></li>
<li><strong>Abstract: </strong>This paper, for the first time, explores text-to-image diffusion models for Zero-Shot Sketch-based Image Retrieval (ZS-SBIR). We highlight a pivotal discovery: the capacity of text-to-image diffusion models to seamlessly bridge the gap between sketches and photos. This proficiency is underpinned by their robust cross-modal capabilities and shape bias, findings that are substantiated through our pilot studies. In order to harness pre-trained diffusion models effectively, we introduce a straightforward yet powerful strategy focused on two key aspects: selecting optimal feature layers and utilising visual and textual prompts. For the former, we identify which layers are most enriched with information and are best suited for the specific retrieval requirements (category-level or fine-grained). Then we employ visual and textual prompts to guide the model's feature extraction process, enabling it to generate more discriminative and contextually relevant cross-modal representations. Extensive experiments on several benchmark datasets validate significant performance improvements.</li>
</ul>

<h3>Title: SoK: Can Trajectory Generation Combine Privacy and Utility?</h3>
<ul>
<li><strong>Authors: </strong>Erik Buchholz, Alsharif Abuadbba, Shuo Wang, Surya Nepal, Salil S. Kanhere</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2403.07218">https://arxiv.org/abs/2403.07218</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2403.07218">https://arxiv.org/pdf/2403.07218</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2403.07218]] SoK: Can Trajectory Generation Combine Privacy and Utility?(https://arxiv.org/abs/2403.07218)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, protect, attack, generative</a></li>
<li><strong>Abstract: </strong>While location trajectories represent a valuable data source for analyses and location-based services, they can reveal sensitive information, such as political and religious preferences. Differentially private publication mechanisms have been proposed to allow for analyses under rigorous privacy guarantees. However, the traditional protection schemes suffer from a limiting privacy-utility trade-off and are vulnerable to correlation and reconstruction attacks. Synthetic trajectory data generation and release represent a promising alternative to protection algorithms. While initial proposals achieve remarkable utility, they fail to provide rigorous privacy guarantees. This paper proposes a framework for designing a privacy-preserving trajectory publication approach by defining five design goals, particularly stressing the importance of choosing an appropriate Unit of Privacy. Based on this framework, we briefly discuss the existing trajectory protection approaches, emphasising their shortcomings. This work focuses on the systematisation of the state-of-the-art generative models for trajectories in the context of the proposed framework. We find that no existing solution satisfies all requirements. Thus, we perform an experimental study evaluating the applicability of six sequential generative models to the trajectory domain. Finally, we conclude that a generative trajectory model providing semantic guarantees remains an open research question and propose concrete next steps for future research.</li>
</ul>

<h3>Title: Monocular Microscope to CT Registration using Pose Estimation of the  Incus for Augmented Reality Cochlear Implant Surgery</h3>
<ul>
<li><strong>Authors: </strong>Yike Zhang, Eduardo Davalos, Dingjie Su, Ange Lou, Jack H. Noble</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2403.07219">https://arxiv.org/abs/2403.07219</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2403.07219">https://arxiv.org/pdf/2403.07219</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2403.07219]] Monocular Microscope to CT Registration using Pose Estimation of the  Incus for Augmented Reality Cochlear Implant Surgery(https://arxiv.org/abs/2403.07219)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>For those experiencing severe-to-profound sensorineural hearing loss, the cochlear implant (CI) is the preferred treatment. Augmented reality (AR) aided surgery can potentially improve CI procedures and hearing outcomes. Typically, AR solutions for image-guided surgery rely on optical tracking systems to register pre-operative planning information to the display so that hidden anatomy or other important information can be overlayed and co-registered with the view of the surgical scene. In this paper, our goal is to develop a method that permits direct 2D-to-3D registration of the microscope video to the pre-operative Computed Tomography (CT) scan without the need for external tracking equipment. Our proposed solution involves using surface mapping of a portion of the incus in surgical recordings and determining the pose of this structure relative to the surgical microscope by performing pose estimation via the perspective-n-point (PnP) algorithm. This registration can then be applied to pre-operative segmentations of other anatomy-of-interest, as well as the planned electrode insertion trajectory to co-register this information for the AR display. Our results demonstrate the accuracy with an average rotation error of less than 25 degrees and a translation error of less than 2 mm, 3 mm, and 0.55% for the x, y, and z axes, respectively. Our proposed method has the potential to be applicable and generalized to other surgical procedures while only needing a monocular microscope during intra-operation.</li>
</ul>

<h3>Title: LookupFFN: Making Transformers Compute-lite for CPU inference</h3>
<ul>
<li><strong>Authors: </strong>Zhanpeng Zeng, Michael Davies, Pranav Pulijala, Karthikeyan Sankaralingam, Vikas Singh</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2403.07221">https://arxiv.org/abs/2403.07221</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2403.07221">https://arxiv.org/pdf/2403.07221</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2403.07221]] LookupFFN: Making Transformers Compute-lite for CPU inference(https://arxiv.org/abs/2403.07221)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, transformer</a></li>
<li><strong>Abstract: </strong>While GPU clusters are the de facto choice for training large deep neural network (DNN) models today, several reasons including ease of workflow, security and cost have led to efforts investigating whether CPUs may be viable for inference in routine use in many sectors of the industry. But the imbalance between the compute capabilities of GPUs and CPUs is huge. Motivated by these considerations, we study a module which is a workhorse within modern DNN architectures, GEMM based Feed Forward Networks (FFNs), and assess the extent to which it can be made compute- (or FLOP-) lite. Specifically, we propose an alternative formulation (we call it LookupFFN) to GEMM based FFNs inspired by the recent studies of using Locality Sensitive Hashing (LSH) to approximate FFNs. Our formulation recasts most essential operations as a memory look-up, leveraging the trade-off between the two resources on any platform: compute and memory (since CPUs offer it in abundance). For RoBERTa language model pretraining, our formulation achieves similar performance compared to GEMM based FFNs, while dramatically reducing the required FLOP. Our development is complemented with a detailed hardware profiling of strategies that will maximize efficiency -- not just on contemporary hardware but on products that will be offered in the near/medium term future. Code is avaiable at \url{https://github.com/mlpen/LookupFFN}.</li>
</ul>

<h3>Title: The order-theoretical foundation for data flow security</h3>
<ul>
<li><strong>Authors: </strong>Luigi Logrippo</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2403.07226">https://arxiv.org/abs/2403.07226</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2403.07226">https://arxiv.org/pdf/2403.07226</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2403.07226]] The order-theoretical foundation for data flow security(https://arxiv.org/abs/2403.07226)</code><input type="text"></li>
<li><strong>Keywords: </strong>security</a></li>
<li><strong>Abstract: </strong>Some theories on data flow security are based on order-theoretical concepts, most commonly on lattice concepts. This paper presents a correspondence between security concepts and partial order concepts, by which the former become an application of the latter. The formalization involves concepts of data flow, equivalence classes of entities that can access the same data, and labels. Efficient, well-known algorithms to obtain one of these from one of the others are presented. Security concepts such as secrecy (also called confidentiality), integrity and conflict can be expressed in this theory. Further, it is shown that complex tuple labels used in the literature to express security levels can be translated into equivalent set labels. A consequence is that any network's data flow or access control relationships can be defined by assigning simple set labels to the entities. Finally, it is shown how several partial orders can be combined when different data flows must coexist.</li>
</ul>

<h3>Title: Learn and Search: An Elegant Technique for Object Lookup using  Contrastive Learning</h3>
<ul>
<li><strong>Authors: </strong>Chandan Kumar, Jansel Herrera-Gerena, John Just, Matthew Darr, Ali Jannesari</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2403.07231">https://arxiv.org/abs/2403.07231</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2403.07231">https://arxiv.org/pdf/2403.07231</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2403.07231]] Learn and Search: An Elegant Technique for Object Lookup using  Contrastive Learning(https://arxiv.org/abs/2403.07231)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>The rapid proliferation of digital content and the ever-growing need for precise object recognition and segmentation have driven the advancement of cutting-edge techniques in the field of object classification and segmentation. This paper introduces "Learn and Search", a novel approach for object lookup that leverages the power of contrastive learning to enhance the efficiency and effectiveness of retrieval systems. In this study, we present an elegant and innovative methodology that integrates deep learning principles and contrastive learning to tackle the challenges of object search. Our extensive experimentation reveals compelling results, with "Learn and Search" achieving superior Similarity Grid Accuracy, showcasing its efficacy in discerning regions of utmost similarity within an image relative to a cropped image. The seamless fusion of deep learning and contrastive learning to address the intricacies of object identification not only promises transformative applications in image recognition, recommendation systems, and content tagging but also revolutionizes content-based search and retrieval. The amalgamation of these techniques, as exemplified by "Learn and Search," represents a significant stride in the ongoing evolution of methodologies in the dynamic realm of object classification and segmentation.</li>
</ul>

<h3>Title: It's All About Your Sketch: Democratising Sketch Control in Diffusion  Models</h3>
<ul>
<li><strong>Authors: </strong>Subhadeep Koley, Ayan Kumar Bhunia, Deeptanshu Sekhri, Aneeshan Sain, Pinaki Nath Chowdhury, Tao Xiang, Yi-Zhe Song</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2403.07234">https://arxiv.org/abs/2403.07234</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2403.07234">https://arxiv.org/pdf/2403.07234</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2403.07234]] It's All About Your Sketch: Democratising Sketch Control in Diffusion  Models(https://arxiv.org/abs/2403.07234)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, generative</a></li>
<li><strong>Abstract: </strong>This paper unravels the potential of sketches for diffusion models, addressing the deceptive promise of direct sketch control in generative AI. We importantly democratise the process, enabling amateur sketches to generate precise images, living up to the commitment of "what you sketch is what you get". A pilot study underscores the necessity, revealing that deformities in existing models stem from spatial-conditioning. To rectify this, we propose an abstraction-aware framework, utilising a sketch adapter, adaptive time-step sampling, and discriminative guidance from a pre-trained fine-grained sketch-based image retrieval model, working synergistically to reinforce fine-grained sketch-photo association. Our approach operates seamlessly during inference without the need for textual prompts; a simple, rough sketch akin to what you and I can create suffices! We welcome everyone to examine results presented in the paper and its supplementary. Contributions include democratising sketch control, introducing an abstraction-aware framework, and leveraging discriminative guidance, validated through extensive experiments.</li>
</ul>

<h3>Title: Calibrating Multi-modal Representations: A Pursuit of Group Robustness  without Annotations</h3>
<ul>
<li><strong>Authors: </strong>Chenyu You, Yifei Min, Weicheng Dai, Jasjeet S. Sekhon, Lawrence Staib, James S. Duncan</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2403.07241">https://arxiv.org/abs/2403.07241</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2403.07241">https://arxiv.org/pdf/2403.07241</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2403.07241]] Calibrating Multi-modal Representations: A Pursuit of Group Robustness  without Annotations(https://arxiv.org/abs/2403.07241)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Fine-tuning pre-trained vision-language models, like CLIP, has yielded success on diverse downstream tasks. However, several pain points persist for this paradigm: (i) directly tuning entire pre-trained models becomes both time-intensive and computationally costly. Additionally, these tuned models tend to become highly specialized, limiting their practicality for real-world deployment; (ii) recent studies indicate that pre-trained vision-language classifiers may overly depend on spurious features -- patterns that correlate with the target in training data, but are not related to the true labeling function; and (iii) existing studies on mitigating the reliance on spurious features, largely based on the assumption that we can identify such features, does not provide definitive assurance for real-world applications. As a piloting study, this work focuses on exploring mitigating the reliance on spurious features for CLIP without using any group annotation. To this end, we systematically study the existence of spurious correlation on CLIP and CILP+ERM. We first, following recent work on Deep Feature Reweighting (DFR), verify that last-layer retraining can greatly improve group robustness on pretrained CLIP. In view of them, we advocate a lightweight representation calibration method for fine-tuning CLIP, by first generating a calibration set using the pretrained CLIP, and then calibrating representations of samples within this set through contrastive learning, all without the need for group labels. Extensive experiments and in-depth visualizations on several benchmarks validate the effectiveness of our proposals, largely reducing reliance and significantly boosting the model generalization.</li>
</ul>

<h3>Title: Towards Zero-shot Human-Object Interaction Detection via Vision-Language  Integration</h3>
<ul>
<li><strong>Authors: </strong>Weiying Xue, Qi Liu, Qiwei Xiong, Yuxiao Wang, Zhenao Wei, Xiaofen Xing, Xiangmin Xu</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2403.07246">https://arxiv.org/abs/2403.07246</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2403.07246">https://arxiv.org/pdf/2403.07246</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2403.07246]] Towards Zero-shot Human-Object Interaction Detection via Vision-Language  Integration(https://arxiv.org/abs/2403.07246)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction</a></li>
<li><strong>Abstract: </strong>Human-object interaction (HOI) detection aims to locate human-object pairs and identify their interaction categories in images. Most existing methods primarily focus on supervised learning, which relies on extensive manual HOI annotations. In this paper, we propose a novel framework, termed Knowledge Integration to HOI (KI2HOI), that effectively integrates the knowledge of visual-language model to improve zero-shot HOI detection. Specifically, the verb feature learning module is designed based on visual semantics, by employing the verb extraction decoder to convert corresponding verb queries into interaction-specific category representations. We develop an effective additive self-attention mechanism to generate more comprehensive visual representations. Moreover, the innovative interaction representation decoder effectively extracts informative regions by integrating spatial and visual feature information through a cross-attention mechanism. To deal with zero-shot learning in low-data, we leverage a priori knowledge from the CLIP text encoder to initialize the linear classifier for enhanced interaction understanding. Extensive experiments conducted on the mainstream HICO-DET and V-COCO datasets demonstrate that our model outperforms the previous methods in various zero-shot and full-supervised settings.</li>
</ul>

<h3>Title: Atomicity and Abstraction for Cross-Blockchain Interactions</h3>
<ul>
<li><strong>Authors: </strong>Huaixi Lu, Akshay Jajoo, Kedar S. Namjoshi</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.DC</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2403.07248">https://arxiv.org/abs/2403.07248</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2403.07248">https://arxiv.org/pdf/2403.07248</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2403.07248]] Atomicity and Abstraction for Cross-Blockchain Interactions(https://arxiv.org/abs/2403.07248)</code><input type="text"></li>
<li><strong>Keywords: </strong>secure, security</a></li>
<li><strong>Abstract: </strong>A blockchain facilitates secure and atomic transactions between mutually untrusting parties on that chain. Today, there are multiple blockchains with differing interfaces and security properties. Programming in this multi-blockchain world is hindered by the lack of general and convenient abstractions for cross-chain communication and computation. Current cross-chain communication bridges have varied and low-level interfaces, making it difficult to develop portable applications. Current methods for multi-chain atomic transactions are limited in scope to cryptocurrency swaps. This work addresses these issues. We first define a uniform, high-level interface for communication between chains. Building on this interface, we formulate a protocol that guarantees atomicity for general transactions whose operations may span several chains. We formulate and prove the desired correctness and security properties of these protocols. Our prototype implementation is built using the LayerZero cross-chain bridge. Experience with this implementation shows that the new abstractions considerably simplify the design and implementation of multi-chain transactions. Experimental evaluation with multi-chain swap transactions demonstrates performance comparable to that of custom-built implementations.</li>
</ul>

<h3>Title: CKERC : Joint Large Language Models with Commonsense Knowledge for  Emotion Recognition in Conversation</h3>
<ul>
<li><strong>Authors: </strong>Yumeng Fu</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2403.07260">https://arxiv.org/abs/2403.07260</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2403.07260">https://arxiv.org/pdf/2403.07260</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2403.07260]] CKERC : Joint Large Language Models with Commonsense Knowledge for  Emotion Recognition in Conversation(https://arxiv.org/abs/2403.07260)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Emotion recognition in conversation (ERC) is a task which predicts the emotion of an utterance in the context of a conversation. It tightly depends on dialogue context, speaker identity information, multiparty dialogue scenario and so on. However, the state-of-the-art method (instructERC) solely identifying speaker, and ignores commonsense knowledge(i.e., reaction of the listeners and intention of the speaker, etc.) behind speakers during a conversation, which can deeply mine speaker information. To this end, we propose a novel joint large language models with commonsense knowledge framework for emotion recognition in conversation, namely CKERC.We design prompts to generate interlocutors' commonsense based on historical utterances with large language model. And we use the interlocutor commonsense identification task for LLM pre-training to fine-tune speaker implicit clues information.By solving above challenge, our method achieve state-of-the-art.We extensive experiment on three widely-used datasets, i.e., IEMOCAP, MELD, EmoryNLP, demonstrate our method superiority. Also, we conduct in-depth analysis and further demonstrate the effectiveness of commonsense knowledge in ERC task in large language model.</li>
</ul>

<h3>Title: Disentangling Policy from Offline Task Representation Learning via  Adversarial Data Augmentation</h3>
<ul>
<li><strong>Authors: </strong>Chengxing Jia, Fuxiang Zhang, Yi-Chen Li, Chen-Xiao Gao, Xu-Hui Liu, Lei Yuan, Zongzhang Zhang, Yang Yu</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2403.07261">https://arxiv.org/abs/2403.07261</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2403.07261">https://arxiv.org/pdf/2403.07261</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2403.07261]] Disentangling Policy from Offline Task Representation Learning via  Adversarial Data Augmentation(https://arxiv.org/abs/2403.07261)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Offline meta-reinforcement learning (OMRL) proficiently allows an agent to tackle novel tasks while solely relying on a static dataset. For precise and efficient task identification, existing OMRL research suggests learning separate task representations that be incorporated with policy input, thus forming a context-based meta-policy. A major approach to train task representations is to adopt contrastive learning using multi-task offline data. The dataset typically encompasses interactions from various policies (i.e., the behavior policies), thus providing a plethora of contextual information regarding different tasks. Nonetheless, amassing data from a substantial number of policies is not only impractical but also often unattainable in realistic settings. Instead, we resort to a more constrained yet practical scenario, where multi-task data collection occurs with a limited number of policies. We observed that learned task representations from previous OMRL methods tend to correlate spuriously with the behavior policy instead of reflecting the essential characteristics of the task, resulting in unfavorable out-of-distribution generalization. To alleviate this issue, we introduce a novel algorithm to disentangle the impact of behavior policy from task representation learning through a process called adversarial data augmentation. Specifically, the objective of adversarial data augmentation is not merely to generate data analogous to offline data distribution; instead, it aims to create adversarial examples designed to confound learned task representations and lead to incorrect task identification. Our experiments show that learning from such adversarial samples significantly enhances the robustness and effectiveness of the task identification process and realizes satisfactory out-of-distribution generalization.</li>
</ul>

<h3>Title: A Bayesian Approach to OOD Robustness in Image Classification</h3>
<ul>
<li><strong>Authors: </strong>Prakhar Kaushik, Adam Kortylewski, Alan Yuille</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2403.07277">https://arxiv.org/abs/2403.07277</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2403.07277">https://arxiv.org/pdf/2403.07277</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2403.07277]] A Bayesian Approach to OOD Robustness in Image Classification(https://arxiv.org/abs/2403.07277)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, generative</a></li>
<li><strong>Abstract: </strong>An important and unsolved problem in computer vision is to ensure that the algorithms are robust to changes in image domains. We address this problem in the scenario where we have access to images from the target domains but no annotations. Motivated by the challenges of the OOD-CV benchmark where we encounter real world Out-of-Domain (OOD) nuisances and occlusion, we introduce a novel Bayesian approach to OOD robustness for object classification. Our work extends Compositional Neural Networks (CompNets), which have been shown to be robust to occlusion but degrade badly when tested on OOD data. We exploit the fact that CompNets contain a generative head defined over feature vectors represented by von Mises-Fisher (vMF) kernels, which correspond roughly to object parts, and can be learned without supervision. We obverse that some vMF kernels are similar between different domains, while others are not. This enables us to learn a transitional dictionary of vMF kernels that are intermediate between the source and target domains and train the generative model on this dictionary using the annotations on the source domain, followed by iterative refinement. This approach, termed Unsupervised Generative Transition (UGT), performs very well in OOD scenarios even when occlusion is present. UGT is evaluated on different OOD benchmarks including the OOD-CV dataset, several popular datasets (e.g., ImageNet-C [9]), artificial image corruptions (including adding occluders), and synthetic-to-real domain transfer, and does well in all scenarios outperforming SOTA alternatives (e.g. up to 10% top-1 accuracy on Occluded OOD-CV dataset).</li>
</ul>

<h3>Title: A Survey of Explainable Knowledge Tracing</h3>
<ul>
<li><strong>Authors: </strong>Yanhong Bai, Jiabao Zhao, Tingjiang Wei, Qing Cai, Liang He</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2403.07279">https://arxiv.org/abs/2403.07279</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2403.07279">https://arxiv.org/pdf/2403.07279</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2403.07279]] A Survey of Explainable Knowledge Tracing(https://arxiv.org/abs/2403.07279)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability</a></li>
<li><strong>Abstract: </strong>With the long term accumulation of high quality educational data, artificial intelligence has shown excellent performance in knowledge tracing. However, due to the lack of interpretability and transparency of some algorithms, this approach will result in reduced stakeholder trust and a decreased acceptance of intelligent decisions. Therefore, algorithms need to achieve high accuracy, and users need to understand the internal operating mechanism and provide reliable explanations for decisions. This paper thoroughly analyzes the interpretability of KT algorithms. First, the concepts and common methods of explainable artificial intelligence and knowledge tracing are introduced. Next, explainable knowledge tracing models are classified into two categories: transparent models and black box models. Then, the interpretable methods used are reviewed from three stages: ante hoc interpretable methods, post hoc interpretable methods, and other dimensions. It is worth noting that current evaluation methods for explainable knowledge tracing are lacking. Hence, contrast and deletion experiments are conducted to explain the prediction results of the deep knowledge tracing model on the ASSISTment2009 by using three XAI methods. Moreover, this paper offers some insights into evaluation methods from the perspective of educational stakeholders. This paper provides a detailed and comprehensive review of the research on explainable knowledge tracing, aiming to offer some basis and inspiration for researchers interested in the interpretability of knowledge tracing.</li>
</ul>

<h3>Title: A Framework for Cost-Effective and Self-Adaptive LLM Shaking and  Recovery Mechanism</h3>
<ul>
<li><strong>Authors: </strong>Zhiyu Chen, Yu Li, Suochao Zhang, Jingbo Zhou, Jiwen Zhou, Chenfu Bao, Dianhai Yu</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.CL, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2403.07283">https://arxiv.org/abs/2403.07283</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2403.07283">https://arxiv.org/pdf/2403.07283</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2403.07283]] A Framework for Cost-Effective and Self-Adaptive LLM Shaking and  Recovery Mechanism(https://arxiv.org/abs/2403.07283)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, large language model</a></li>
<li><strong>Abstract: </strong>As Large Language Models (LLMs) gain great success in real-world applications, an increasing number of users are seeking to develop and deploy their customized LLMs through cloud services. Nonetheless, in some specific domains, there are still concerns regarding cost and trade-offs between privacy issues and accuracy. In this study, we introduce a cost-effective and self-adaptive LLM shaking tuning and recovery mechanism, named CypherTalk. With carefully designed horizontal and vertical shaking operators, we can achieve comparable accuracy results with SOTA privacy-preserving LLM schemes using Cryptography-based or Differential Privacy-based methods. Experiments also show that with the CypherTalk framework, users can achieve reliable accuracy when using optimized shaking operator settings. To our best knowledge, this is the first work that considers cost, and trade-off between model utility and privacy in LLM scenarios.</li>
</ul>

<h3>Title: SparseLIF: High-Performance Sparse LiDAR-Camera Fusion for 3D Object  Detection</h3>
<ul>
<li><strong>Authors: </strong>Hongcheng Zhang, Liu Liang, Pengxin Zeng, Xiao Song, Zhe Wang</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2403.07284">https://arxiv.org/abs/2403.07284</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2403.07284">https://arxiv.org/pdf/2403.07284</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2403.07284]] SparseLIF: High-Performance Sparse LiDAR-Camera Fusion for 3D Object  Detection(https://arxiv.org/abs/2403.07284)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Sparse 3D detectors have received significant attention since the query-based paradigm embraces low latency without explicit dense BEV feature construction. However, these detectors achieve worse performance than their dense counterparts. In this paper, we find the key to bridging the performance gap is to enhance the awareness of rich representations in two modalities. Here, we present a high-performance fully sparse detector for end-to-end multi-modality 3D object detection. The detector, termed SparseLIF, contains three key designs, which are (1) Perspective-Aware Query Generation (PAQG) to generate high-quality 3D queries with perspective priors, (2) RoI-Aware Sampling (RIAS) to further refine prior queries by sampling RoI features from each modality, (3) Uncertainty-Aware Fusion (UAF) to precisely quantify the uncertainty of each sensor modality and adaptively conduct final multi-modality fusion, thus achieving great robustness against sensor noises. By the time of submission (2024/03/08), SparseLIF achieves state-of-the-art performance on the nuScenes dataset, ranking 1st on both validation set and test benchmark, outperforming all state-of-the-art 3D object detectors by a notable margin. The source code will be released upon acceptance.</li>
</ul>

<h3>Title: Rediscovering BCE Loss for Uniform Classification</h3>
<ul>
<li><strong>Authors: </strong>Qiufu Li, Xi Jia, Jiancan Zhou, Linlin Shen, Jinming Duan</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2403.07289">https://arxiv.org/abs/2403.07289</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2403.07289">https://arxiv.org/pdf/2403.07289</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2403.07289]] Rediscovering BCE Loss for Uniform Classification(https://arxiv.org/abs/2403.07289)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction</a></li>
<li><strong>Abstract: </strong>This paper introduces the concept of uniform classification, which employs a unified threshold to classify all samples rather than adaptive threshold classifying each individual sample. We also propose the uniform classification accuracy as a metric to measure the model's performance in uniform classification. Furthermore, begin with a naive loss, we mathematically derive a loss function suitable for the uniform classification, which is the BCE function integrated with a unified bias. We demonstrate the unified threshold could be learned via the bias. The extensive experiments on six classification datasets and three feature extraction models show that, compared to the SoftMax loss, the models trained with the BCE loss not only exhibit higher uniform classification accuracy but also higher sample-wise classification accuracy. In addition, the learned bias from BCE loss is very close to the unified threshold used in the uniform classification. The features extracted by the models trained with BCE loss not only possess uniformity but also demonstrate better intra-class compactness and inter-class distinctiveness, yielding superior performance on open-set tasks such as face recognition.</li>
</ul>

<h3>Title: Taming Pre-trained LLMs for Generalised Time Series Forecasting via  Cross-modal Knowledge Distillation</h3>
<ul>
<li><strong>Authors: </strong>Peiyuan Liu, Hang Guo, Tao Dai, Naiqi Li, Jigang Bao, Xudong Ren, Yong Jiang, Shu-Tao Xia</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2403.07300">https://arxiv.org/abs/2403.07300</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2403.07300">https://arxiv.org/pdf/2403.07300</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2403.07300]] Taming Pre-trained LLMs for Generalised Time Series Forecasting via  Cross-modal Knowledge Distillation(https://arxiv.org/abs/2403.07300)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Multivariate time series forecasting has recently gained great success with the rapid growth of deep learning models. However, existing approaches usually train models from scratch using limited temporal data, preventing their generalization. Recently, with the surge of the Large Language Models (LLMs), several works have attempted to introduce LLMs into time series forecasting. Despite promising results, these methods directly take time series as the input to LLMs, ignoring the inherent modality gap between temporal and text data. In this work, we propose a novel Large Language Models and time series alignment framework, dubbed LLaTA, to fully unleash the potentials of LLMs in the time series forecasting challenge. Based on cross-modal knowledge distillation, the proposed method exploits both input-agnostic static knowledge and input-dependent dynamic knowledge in pre-trained LLMs. In this way, it empowers the forecasting model with favorable performance as well as strong generalization abilities. Extensive experiments demonstrate the proposed method establishes a new state of the art for both long- and short-term forecasting. Code is available at \url{https://github.com/Hank0626/LLaTA}.</li>
</ul>

<h3>Title: Reinforced Sequential Decision-Making for Sepsis Treatment: The POSNEGDM  Framework with Mortality Classifier and Transformer</h3>
<ul>
<li><strong>Authors: </strong>Dipesh Tamboli, Jiayu Chen, Kiran Pranesh Jotheeswaran, Denny Yu, Vaneet Aggarwal</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CY</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2403.07309">https://arxiv.org/abs/2403.07309</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2403.07309">https://arxiv.org/pdf/2403.07309</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2403.07309]] Reinforced Sequential Decision-Making for Sepsis Treatment: The POSNEGDM  Framework with Mortality Classifier and Transformer(https://arxiv.org/abs/2403.07309)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Sepsis, a life-threatening condition triggered by the body's exaggerated response to infection, demands urgent intervention to prevent severe complications. Existing machine learning methods for managing sepsis struggle in offline scenarios, exhibiting suboptimal performance with survival rates below 50%. This paper introduces the POSNEGDM -- ``Reinforcement Learning with Positive and Negative Demonstrations for Sequential Decision-Making" framework utilizing an innovative transformer-based model and a feedback reinforcer to replicate expert actions while considering individual patient characteristics. A mortality classifier with 96.7\% accuracy guides treatment decisions towards positive outcomes. The POSNEGDM framework significantly improves patient survival, saving 97.39% of patients, outperforming established machine learning algorithms (Decision Transformer and Behavioral Cloning) with survival rates of 33.4% and 43.5%, respectively. Additionally, ablation studies underscore the critical role of the transformer-based decision maker and the integration of a mortality classifier in enhancing overall survival rates. In summary, our proposed approach presents a promising avenue for enhancing sepsis treatment outcomes, contributing to improved patient care and reduced healthcare costs.</li>
</ul>

<h3>Title: Knowledge Graph Large Language Model (KG-LLM) for Link Prediction</h3>
<ul>
<li><strong>Authors: </strong>Dong Shu, Tianle Chen, Mingyu Jin, Yiting Zhang, Mengnan Du, Yongfeng Zhang</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2403.07311">https://arxiv.org/abs/2403.07311</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2403.07311">https://arxiv.org/pdf/2403.07311</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2403.07311]] Knowledge Graph Large Language Model (KG-LLM) for Link Prediction(https://arxiv.org/abs/2403.07311)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>The task of predicting multiple links within knowledge graphs (KGs) stands as a challenge in the field of knowledge graph analysis, a challenge increasingly resolvable due to advancements in natural language processing (NLP) and KG embedding techniques. This paper introduces a novel methodology, the Knowledge Graph Large Language Model Framework (KG-LLM), which leverages pivotal NLP paradigms, including chain-of-thought (CoT) prompting and in-context learning (ICL), to enhance multi-hop link prediction in KGs. By converting the KG to a CoT prompt, our framework is designed to discern and learn the latent representations of entities and their interrelations. To show the efficacy of the KG-LLM Framework, we fine-tune three leading Large Language Models (LLMs) within this framework, employing both non-ICL and ICL tasks for a comprehensive evaluation. Further, we explore the framework's potential to provide LLMs with zero-shot capabilities for handling previously unseen prompts. Our experimental findings discover that integrating ICL and CoT not only augments the performance of our approach but also significantly boosts the models' generalization capacity, thereby ensuring more precise predictions in unfamiliar scenarios.</li>
</ul>

<h3>Title: Efficient Diffusion Model for Image Restoration by Residual Shifting</h3>
<ul>
<li><strong>Authors: </strong>Zongsheng Yue, Jianyi Wang, Chen Change Loy</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2403.07319">https://arxiv.org/abs/2403.07319</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2403.07319">https://arxiv.org/pdf/2403.07319</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2403.07319]] Efficient Diffusion Model for Image Restoration by Residual Shifting(https://arxiv.org/abs/2403.07319)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>While diffusion-based image restoration (IR) methods have achieved remarkable success, they are still limited by the low inference speed attributed to the necessity of executing hundreds or even thousands of sampling steps. Existing acceleration sampling techniques, though seeking to expedite the process, inevitably sacrifice performance to some extent, resulting in over-blurry restored outcomes. To address this issue, this study proposes a novel and efficient diffusion model for IR that significantly reduces the required number of diffusion steps. Our method avoids the need for post-acceleration during inference, thereby avoiding the associated performance deterioration. Specifically, our proposed method establishes a Markov chain that facilitates the transitions between the high-quality and low-quality images by shifting their residuals, substantially improving the transition efficiency. A carefully formulated noise schedule is devised to flexibly control the shifting speed and the noise strength during the diffusion process. Extensive experimental evaluations demonstrate that the proposed method achieves superior or comparable performance to current state-of-the-art methods on three classical IR tasks, namely image super-resolution, image inpainting, and blind face restoration, \textit{\textbf{even only with four sampling steps}}. Our code and model are publicly available at \url{https://github.com/zsyOAOA/ResShift}.</li>
</ul>

<h3>Title: GPT-generated Text Detection: Benchmark Dataset and Tensor-based  Detection Method</h3>
<ul>
<li><strong>Authors: </strong>Zubair Qazi, William Shiao, Evangelos E. Papalexakis</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2403.07321">https://arxiv.org/abs/2403.07321</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2403.07321">https://arxiv.org/pdf/2403.07321</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2403.07321]] GPT-generated Text Detection: Benchmark Dataset and Tensor-based  Detection Method(https://arxiv.org/abs/2403.07321)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, transformer, generative</a></li>
<li><strong>Abstract: </strong>As natural language models like ChatGPT become increasingly prevalent in applications and services, the need for robust and accurate methods to detect their output is of paramount importance. In this paper, we present GPT Reddit Dataset (GRiD), a novel Generative Pretrained Transformer (GPT)-generated text detection dataset designed to assess the performance of detection models in identifying generated responses from ChatGPT. The dataset consists of a diverse collection of context-prompt pairs based on Reddit, with human-generated and ChatGPT-generated responses. We provide an analysis of the dataset's characteristics, including linguistic diversity, context complexity, and response quality. To showcase the dataset's utility, we benchmark several detection methods on it, demonstrating their efficacy in distinguishing between human and ChatGPT-generated responses. This dataset serves as a resource for evaluating and advancing detection techniques in the context of ChatGPT and contributes to the ongoing efforts to ensure responsible and trustworthy AI-driven communication on the internet. Finally, we propose GpTen, a novel tensor-based GPT text detection method that is semi-supervised in nature since it only has access to human-generated text and performs on par with fully-supervised baselines.</li>
</ul>

<h3>Title: Large Window-based Mamba UNet for Medical Image Segmentation: Beyond  Convolution and Self-attention</h3>
<ul>
<li><strong>Authors: </strong>Jinhong Wang, Jintai Chen, Danny Chen, Jian Wu</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2403.07332">https://arxiv.org/abs/2403.07332</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2403.07332">https://arxiv.org/pdf/2403.07332</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2403.07332]] Large Window-based Mamba UNet for Medical Image Segmentation: Beyond  Convolution and Self-attention(https://arxiv.org/abs/2403.07332)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer, segmentation</a></li>
<li><strong>Abstract: </strong>In clinical practice, medical image segmentation provides useful information on the contours and dimensions of target organs or tissues, facilitating improved diagnosis, analysis, and treatment. In the past few years, convolutional neural networks (CNNs) and Transformers have dominated this area, but they still suffer from either limited receptive fields or costly long-range modeling. Mamba, a State Space Sequence Model (SSM), recently emerged as a promising paradigm for long-range dependency modeling with linear complexity. In this paper, we introduce a Large Window-based Mamba U}-shape Network, or LMa-UNet, for 2D and 3D medical image segmentation. A distinguishing feature of our LMa-UNet is its utilization of large windows, excelling in locally spatial modeling compared to small kernel-based CNNs and small window-based Transformers, while maintaining superior efficiency in global modeling compared to self-attention with quadratic complexity. Additionally, we design a novel hierarchical and bidirectional Mamba block to further enhance the global and neighborhood spatial modeling capability of Mamba. Comprehensive experiments demonstrate the effectiveness and efficiency of our method and the feasibility of using large window size to achieve large receptive fields. Codes are available at https://github.com/wjh892521292/LMa-UNet.</li>
</ul>

<h3>Title: IM-Unpack: Training and Inference with Arbitrarily Low Precision  Integers</h3>
<ul>
<li><strong>Authors: </strong>Zhanpeng Zeng, Karthikeyan Sankaralingam, Vikas Singh</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CL, cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2403.07339">https://arxiv.org/abs/2403.07339</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2403.07339">https://arxiv.org/pdf/2403.07339</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2403.07339]] IM-Unpack: Training and Inference with Arbitrarily Low Precision  Integers(https://arxiv.org/abs/2403.07339)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>GEneral Matrix Multiply (GEMM) is a central operation in deep learning and corresponds to the largest chunk of the compute footprint. Therefore, improving its efficiency is an active topic of ongoing research. A popular strategy is the use of low bit-width integers to approximate the original entries in a matrix. This allows efficiency gains, but often requires sophisticated techniques to control the rounding error incurred. In this work, we first verify/check that when the low bit-width restriction is removed, for a variety of Transformer-based models, whether integers are sufficient for all GEMMs need -- for {\em both} training and inference stages, and can achieve parity with floating point counterparts. No sophisticated techniques are needed. We find that while a large majority of entries in matrices (encountered in such models) can be easily represented by {\em low} bit-width integers, the existence of a few heavy hitter entries make it difficult to achieve efficiency gains via the exclusive use of low bit-width GEMMs alone. To address this issue, we develop a simple algorithm, Integer Matrix Unpacking (IM-Unpack), to {\em unpack} a matrix with large integer entries into a larger matrix whose entries all lie within the representable range of arbitrarily low bit-width integers. This allows {\em equivalence} with the original GEMM, i.e., the exact result can be obtained using purely low bit-width integer GEMMs. This comes at the cost of additional operations -- we show that for many popular models, this overhead is quite small.</li>
</ul>

<h3>Title: Rethinking ASTE: A Minimalist Tagging Scheme Alongside Contrastive  Learning</h3>
<ul>
<li><strong>Authors: </strong>Qiao Sun, Liujia Yang, Minghao Ma, Nanyang Ye, Qinying Gu</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2403.07342">https://arxiv.org/abs/2403.07342</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2403.07342">https://arxiv.org/pdf/2403.07342</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2403.07342]] Rethinking ASTE: A Minimalist Tagging Scheme Alongside Contrastive  Learning(https://arxiv.org/abs/2403.07342)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction, large language model</a></li>
<li><strong>Abstract: </strong>Aspect Sentiment Triplet Extraction (ASTE) is a burgeoning subtask of fine-grained sentiment analysis, aiming to extract structured sentiment triplets from unstructured textual data. Existing approaches to ASTE often complicate the task with additional structures or external data. In this research, we propose a novel tagging scheme and employ a contrastive learning approach to mitigate these challenges. The proposed approach demonstrates comparable or superior performance in comparison to state-of-the-art techniques, while featuring a more compact design and reduced computational overhead. Notably, even in the era of Large Language Models (LLMs), our method exhibits superior efficacy compared to GPT 3.5 and GPT 4 in a few-shot learning scenarios. This study also provides valuable insights for the advancement of ASTE techniques within the paradigm of large language models.</li>
</ul>

<h3>Title: BID: Boundary-Interior Decoding for Unsupervised Temporal Action  Localization Pre-Trainin</h3>
<ul>
<li><strong>Authors: </strong>Qihang Fang, Chengcheng Tang, Shugao Ma, Yanchao Yang</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2403.07354">https://arxiv.org/abs/2403.07354</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2403.07354">https://arxiv.org/pdf/2403.07354</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2403.07354]] BID: Boundary-Interior Decoding for Unsupervised Temporal Action  Localization Pre-Trainin(https://arxiv.org/abs/2403.07354)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Skeleton-based motion representations are robust for action localization and understanding for their invariance to perspective, lighting, and occlusion, compared with images. Yet, they are often ambiguous and incomplete when taken out of context, even for human annotators. As infants discern gestures before associating them with words, actions can be conceptualized before being grounded with labels. Therefore, we propose the first unsupervised pre-training framework, Boundary-Interior Decoding (BID), that partitions a skeleton-based motion sequence into discovered semantically meaningful pre-action segments. By fine-tuning our pre-training network with a small number of annotated data, we show results out-performing SOTA methods by a large margin.</li>
</ul>

<h3>Title: Premonition: Using Generative Models to Preempt Future Data Changes in  Continual Learning</h3>
<ul>
<li><strong>Authors: </strong>Mark D. McDonnell, Dong Gong, Ehsan Abbasnejad, Anton van den Hengel</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2403.07356">https://arxiv.org/abs/2403.07356</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2403.07356">https://arxiv.org/pdf/2403.07356</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2403.07356]] Premonition: Using Generative Models to Preempt Future Data Changes in  Continual Learning(https://arxiv.org/abs/2403.07356)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, generative, large language model</a></li>
<li><strong>Abstract: </strong>Continual learning requires a model to adapt to ongoing changes in the data distribution, and often to the set of tasks to be performed. It is rare, however, that the data and task changes are completely unpredictable. Given a description of an overarching goal or data theme, which we call a realm, humans can often guess what concepts are associated with it. We show here that the combination of a large language model and an image generation model can similarly provide useful premonitions as to how a continual learning challenge might develop over time. We use the large language model to generate text descriptions of semantically related classes that might potentially appear in the data stream in future. These descriptions are then rendered using Stable Diffusion to generate new labelled image samples. The resulting synthetic dataset is employed for supervised pre-training, but is discarded prior to commencing continual learning, along with the pre-training classification head. We find that the backbone of our pre-trained networks can learn representations useful for the downstream continual learning problem, thus becoming a valuable input to any existing continual learning method. Although there are complexities arising from the domain gap between real and synthetic images, we show that pre-training models in this manner improves multiple Class Incremenal Learning (CIL) methods on fine-grained image classification benchmarks. Supporting code can be found at https://github.com/cl-premonition/premonition.</li>
</ul>

<h3>Title: Challenging Forgets: Unveiling the Worst-Case Forget Sets in Machine  Unlearning</h3>
<ul>
<li><strong>Authors: </strong>Chongyu Fan, Jiancheng Liu, Alfred Hero, Sijia Liu</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2403.07362">https://arxiv.org/abs/2403.07362</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2403.07362">https://arxiv.org/pdf/2403.07362</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2403.07362]] Challenging Forgets: Unveiling the Worst-Case Forget Sets in Machine  Unlearning(https://arxiv.org/abs/2403.07362)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, generative</a></li>
<li><strong>Abstract: </strong>The trustworthy machine learning (ML) community is increasingly recognizing the crucial need for models capable of selectively 'unlearning' data points after training. This leads to the problem of machine unlearning (MU), aiming to eliminate the influence of chosen data points on model performance, while still maintaining the model's utility post-unlearning. Despite various MU methods for data influence erasure, evaluations have largely focused on random data forgetting, ignoring the vital inquiry into which subset should be chosen to truly gauge the authenticity of unlearning performance. To tackle this issue, we introduce a new evaluative angle for MU from an adversarial viewpoint. We propose identifying the data subset that presents the most significant challenge for influence erasure, i.e., pinpointing the worst-case forget set. Utilizing a bi-level optimization principle, we amplify unlearning challenges at the upper optimization level to emulate worst-case scenarios, while simultaneously engaging in standard training and unlearning at the lower level, achieving a balance between data influence erasure and model utility. Our proposal offers a worst-case evaluation of MU's resilience and effectiveness. Through extensive experiments across different datasets (including CIFAR-10, 100, CelebA, Tiny ImageNet, and ImageNet) and models (including both image classifiers and generative models), we expose critical pros and cons in existing (approximate) unlearning strategies. Our results illuminate the complex challenges of MU in practice, guiding the future development of more accurate and robust unlearning algorithms. The code is available at https://github.com/OPTML-Group/Unlearn-WorstCase.</li>
</ul>

<h3>Title: Entropy is not Enough for Test-Time Adaptation: From the Perspective of  Disentangled Factors</h3>
<ul>
<li><strong>Authors: </strong>Jonghyun Lee, Dahuin Jung, Saehyung Lee, Junsung Park, Juhyeon Shin, Uiwon Hwang, Sungroh Yoon</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2403.07366">https://arxiv.org/abs/2403.07366</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2403.07366">https://arxiv.org/pdf/2403.07366</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2403.07366]] Entropy is not Enough for Test-Time Adaptation: From the Perspective of  Disentangled Factors(https://arxiv.org/abs/2403.07366)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Test-time adaptation (TTA) fine-tunes pre-trained deep neural networks for unseen test data. The primary challenge of TTA is limited access to the entire test dataset during online updates, causing error accumulation. To mitigate it, TTA methods have utilized the model output's entropy as a confidence metric that aims to determine which samples have a lower likelihood of causing error. Through experimental studies, however, we observed the unreliability of entropy as a confidence metric for TTA under biased scenarios and theoretically revealed that it stems from the neglect of the influence of latent disentangled factors of data on predictions. Building upon these findings, we introduce a novel TTA method named Destroy Your Object (DeYO), which leverages a newly proposed confidence metric named Pseudo-Label Probability Difference (PLPD). PLPD quantifies the influence of the shape of an object on prediction by measuring the difference between predictions before and after applying an object-destructive transformation. DeYO consists of sample selection and sample weighting, which employ entropy and PLPD concurrently. For robust adaptation, DeYO prioritizes samples that dominantly incorporate shape information when making predictions. Our extensive experiments demonstrate the consistent superiority of DeYO over baseline methods across various scenarios, including biased and wild. Project page is publicly available at https://whitesnowdrop.github.io/DeYO/.</li>
</ul>

<h3>Title: Textual Knowledge Matters: Cross-Modality Co-Teaching for Generalized  Visual Class Discovery</h3>
<ul>
<li><strong>Authors: </strong>Haiyang Zheng, Nan Pu, Wenjing Li, Nicu Sebe, Zhun Zhong</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2403.07369">https://arxiv.org/abs/2403.07369</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2403.07369">https://arxiv.org/pdf/2403.07369</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2403.07369]] Textual Knowledge Matters: Cross-Modality Co-Teaching for Generalized  Visual Class Discovery(https://arxiv.org/abs/2403.07369)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>In this paper, we study the problem of Generalized Category Discovery (GCD), which aims to cluster unlabeled data from both known and unknown categories using the knowledge of labeled data from known categories. Current GCD methods rely on only visual cues, which however neglect the multi-modality perceptive nature of human cognitive processes in discovering novel visual categories. To address this, we propose a two-phase TextGCD framework to accomplish multi-modality GCD by exploiting powerful Visual-Language Models. TextGCD mainly includes a retrieval-based text generation (RTG) phase and a cross-modality co-teaching (CCT) phase. First, RTG constructs a visual lexicon using category tags from diverse datasets and attributes from Large Language Models, generating descriptive texts for images in a retrieval manner. Second, CCT leverages disparities between textual and visual modalities to foster mutual learning, thereby enhancing visual GCD. In addition, we design an adaptive class aligning strategy to ensure the alignment of category perceptions between modalities as well as a soft-voting mechanism to integrate multi-modality cues. Experiments on eight datasets show the large superiority of our approach over state-of-the-art methods. Notably, our approach outperforms the best competitor, by 7.7% and 10.8% in All accuracy on ImageNet-1k and CUB, respectively.</li>
</ul>

<h3>Title: Time-Efficient and Identity-Consistent Virtual Try-On Using A Variant of  Altered Diffusion Models</h3>
<ul>
<li><strong>Authors: </strong>Phuong Dam, Jihoon Jeong, Anh Tran, Daeyoung Kim</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2403.07371">https://arxiv.org/abs/2403.07371</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2403.07371">https://arxiv.org/pdf/2403.07371</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2403.07371]] Time-Efficient and Identity-Consistent Virtual Try-On Using A Variant of  Altered Diffusion Models(https://arxiv.org/abs/2403.07371)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>This study discusses the critical issues of Virtual Try-On in contemporary e-commerce and the prospective metaverse, emphasizing the challenges of preserving intricate texture details and distinctive features of the target person and the clothes in various scenarios, such as clothing texture and identity characteristics like tattoos or accessories. In addition to the fidelity of the synthesized images, the efficiency of the synthesis process presents a significant hurdle. Various existing approaches are explored, highlighting the limitations and unresolved aspects, e.g., identity information omission, uncontrollable artifacts, and low synthesis speed. It then proposes a novel diffusion-based solution that addresses garment texture preservation and user identity retention during virtual try-on. The proposed network comprises two primary modules - a warping module aligning clothing with individual features and a try-on module refining the attire and generating missing parts integrated with a mask-aware post-processing technique ensuring the integrity of the individual's identity. It demonstrates impressive results, surpassing the state-of-the-art in speed by nearly 20 times during inference, with superior fidelity in qualitative assessments. Quantitative evaluations confirm comparable performance with the recent SOTA method on the VITON-HD and Dresscode datasets.</li>
</ul>

<h3>Title: NavCoT: Boosting LLM-Based Vision-and-Language Navigation via Learning  Disentangled Reasoning</h3>
<ul>
<li><strong>Authors: </strong>Bingqian Lin, Yunshuang Nie, Ziming Wei, Jiaqi Chen, Shikui Ma, Jianhua Han, Hang Xu, Xiaojun Chang, Xiaodan Liang</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI, cs.CL, cs.RO</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2403.07376">https://arxiv.org/abs/2403.07376</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2403.07376">https://arxiv.org/pdf/2403.07376</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2403.07376]] NavCoT: Boosting LLM-Based Vision-and-Language Navigation via Learning  Disentangled Reasoning(https://arxiv.org/abs/2403.07376)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability, large language model</a></li>
<li><strong>Abstract: </strong>Vision-and-Language Navigation (VLN), as a crucial research problem of Embodied AI, requires an embodied agent to navigate through complex 3D environments following natural language instructions. Recent research has highlighted the promising capacity of large language models (LLMs) in VLN by improving navigational reasoning accuracy and interpretability. However, their predominant use in an offline manner usually suffers from substantial domain gap between the VLN task and the LLM training corpus. This paper introduces a novel strategy called Navigational Chain-of-Thought (NavCoT), where we fulfill parameter-efficient in-domain training to enable self-guided navigational decision, leading to a significant mitigation of the domain gap in a cost-effective manner. Specifically, at each timestep, the LLM is prompted to forecast the navigational chain-of-thought by: 1) acting as a world model to imagine the next observation according to the instruction, 2) selecting the candidate observation that best aligns with the imagination, and 3) determining the action based on the reasoning from the prior steps. Through constructing formalized labels for training, the LLM can learn to generate desired and reasonable chain-of-thought outputs for improving the action decision. Experimental results across various training settings and popular VLN benchmarks (e.g., Room-to-Room (R2R), Room-across-Room (RxR), Room-for-Room (R4R)) show the significant superiority of NavCoT over the direct action prediction variants. Through simple parameter-efficient finetuning, our NavCoT outperforms a recent GPT4-based approach with ~7% relative improvement on the R2R dataset. We believe that NavCoT will help unlock more task-adaptive and scalable LLM-based embodied agents, which are helpful for developing real-world robotics applications. Code is available at https://github.com/expectorlin/NavCoT.</li>
</ul>

<h3>Title: SVD-LLM: Truncation-aware Singular Value Decomposition for Large  Language Model Compression</h3>
<ul>
<li><strong>Authors: </strong>Xin Wang, Yu Zheng, Zhongwei Wan, Mi Zhang</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2403.07378">https://arxiv.org/abs/2403.07378</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2403.07378">https://arxiv.org/pdf/2403.07378</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2403.07378]] SVD-LLM: Truncation-aware Singular Value Decomposition for Large  Language Model Compression(https://arxiv.org/abs/2403.07378)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>The advancements in Large Language Models (LLMs) have been hindered by their substantial sizes, which necessitate LLM compression methods for practical deployment. Singular Value Decomposition (SVD) offers a promising solution for LLM compression. However, state-of-the-art SVD-based LLM compression methods have two key limitations: truncating smaller singular values may lead to higher compression loss, and the lack of update on the remaining model parameters after SVD truncation. In this work, we propose SVD-LLM, a new SVD-based LLM compression method that addresses the limitations of existing methods. SVD-LLM incorporates a truncation-aware data whitening strategy to ensure a direct mapping between singular values and compression loss. Moreover, SVD-LLM adopts a layer-wise closed-form model parameter update strategy to compensate for accuracy degradation caused by SVD truncation. We evaluate SVD-LLM on a total of 11 datasets and seven models from three different LLM families at four different scales. Our results demonstrate the superiority of SVD-LLM over state-of-the-arts, especially at high model compression ratios. The source code is available at https://github.com/AIoT-MLSys-Lab/SVD-LLM.</li>
</ul>

<h3>Title: Hallmarks of Optimization Trajectories in Neural Networks and LLMs: The  Lengths, Bends, and Dead Ends</h3>
<ul>
<li><strong>Authors: </strong>Sidak Pal Singh, Bobby He, Thomas Hofmann, Bernhard SchÃ¶lkopf</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CL, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2403.07379">https://arxiv.org/abs/2403.07379</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2403.07379">https://arxiv.org/pdf/2403.07379</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2403.07379]] Hallmarks of Optimization Trajectories in Neural Networks and LLMs: The  Lengths, Bends, and Dead Ends(https://arxiv.org/abs/2403.07379)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>We propose a fresh take on understanding the mechanisms of neural networks by analyzing the rich structure of parameters contained within their optimization trajectories. Towards this end, we introduce some natural notions of the complexity of optimization trajectories, both qualitative and quantitative, which reveal the inherent nuance and interplay involved between various optimization choices, such as momentum, weight decay, and batch size. We use them to provide key hallmarks about the nature of optimization in deep neural networks: when it goes right, and when it finds itself in a dead end. Further, thanks to our trajectory perspective, we uncover an intertwined behaviour of momentum and weight decay that promotes directional exploration, as well as a directional regularization behaviour of some others. We perform experiments over large-scale vision and language settings, including large language models (LLMs) with up to 12 billion parameters, to demonstrate the value of our approach.</li>
</ul>

<h3>Title: Gabor-guided transformer for single image deraining</h3>
<ul>
<li><strong>Authors: </strong>Sijin He, Guangfeng Lin</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2403.07380">https://arxiv.org/abs/2403.07380</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2403.07380">https://arxiv.org/pdf/2403.07380</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2403.07380]] Gabor-guided transformer for single image deraining(https://arxiv.org/abs/2403.07380)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, transformer</a></li>
<li><strong>Abstract: </strong>Image deraining have have gained a great deal of attention in order to address the challenges posed by the effects of harsh weather conditions on visual tasks. While convolutional neural networks (CNNs) are popular, their limitations in capturing global information may result in ineffective rain removal. Transformer-based methods with self-attention mechanisms have improved, but they tend to distort high-frequency details that are crucial for image fidelity. To solve this problem, we propose the Gabor-guided tranformer (Gabformer) for single image deraining. The focus on local texture features is enhanced by incorporating the information processed by the Gabor filter into the query vector, which also improves the robustness of the model to noise due to the properties of the filter. Extensive experiments on the benchmarks demonstrate that our method outperforms state-of-the-art approaches.</li>
</ul>

<h3>Title: SmallToLarge (S2L): Scalable Data Selection for Fine-tuning Large  Language Models by Summarizing Training Trajectories of Small Models</h3>
<ul>
<li><strong>Authors: </strong>Yu Yang, Siddhartha Mishra, Jeffrey N Chiang, Baharan Mirzasoleiman</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2403.07384">https://arxiv.org/abs/2403.07384</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2403.07384">https://arxiv.org/pdf/2403.07384</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2403.07384]] SmallToLarge (S2L): Scalable Data Selection for Fine-tuning Large  Language Models by Summarizing Training Trajectories of Small Models(https://arxiv.org/abs/2403.07384)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Despite the effectiveness of data selection for large language models (LLMs) during pretraining and instruction fine-tuning phases, improving data efficiency in supervised fine-tuning (SFT) for specialized domains poses significant challenges due to the complexity of fine-tuning data. To bridge this gap, we introduce an effective and scalable data selection method for SFT, SmallToLarge (S2L), which leverages training trajectories from small models to guide the data selection for larger models. We demonstrate through extensive experiments that S2L significantly improves data efficiency in SFT for mathematical problem-solving, reducing the training data to just 11% of the original MathInstruct dataset (Yue et al., 2023) to match full dataset performance while outperforming state-of-the-art data selection algorithms by an average of 4.7% across 6 in- and out-domain evaluation datasets. Remarkably, selecting only 50K data for SFT, S2L achieves a 32.7% accuracy on the most challenging MATH (Hendrycks et al., 2021) benchmark, improving Phi-2 (Li et al., 2023b) by 16.6%. In clinical text summarization on the MIMIC-III dataset (Johnson et al., 2016), S2L again outperforms training on the full dataset using only 50% of the data. Notably, S2L can perform data selection using a reference model 40x smaller than the target model, proportionally reducing the cost of data selection.</li>
</ul>

<h3>Title: Auxiliary CycleGAN-guidance for Task-Aware Domain Translation from  Duplex to Monoplex IHC Images</h3>
<ul>
<li><strong>Authors: </strong>Nicolas Brieu, Nicolas Triltsch, Philipp Wortmann, Dominik Winter, Shashank Saran, Marlon Rebelatto, GÃ¼nter Schmidt</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI, eess.IV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2403.07389">https://arxiv.org/abs/2403.07389</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2403.07389">https://arxiv.org/pdf/2403.07389</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2403.07389]] Auxiliary CycleGAN-guidance for Task-Aware Domain Translation from  Duplex to Monoplex IHC Images(https://arxiv.org/abs/2403.07389)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative, segmentation</a></li>
<li><strong>Abstract: </strong>Generative models enable the translation from a source image domain where readily trained models are available to a target domain unseen during training. While Cycle Generative Adversarial Networks (GANs) are well established, the associated cycle consistency constrain relies on that an invertible mapping exists between the two domains. This is, however, not the case for the translation between images stained with chromogenic monoplex and duplex immunohistochemistry (IHC) assays. Focusing on the translation from the latter to the first, we propose - through the introduction of a novel training design, an alternative constrain leveraging a set of immunofluorescence (IF) images as an auxiliary unpaired image domain. Quantitative and qualitative results on a downstream segmentation task show the benefit of the proposed method in comparison to baseline approaches.</li>
</ul>

<h3>Title: ViT-CoMer: Vision Transformer with Convolutional Multi-scale Feature  Interaction for Dense Predictions</h3>
<ul>
<li><strong>Authors: </strong>Chunlong Xia, Xinliang Wang, Feng Lv, Xin Hao, Yifeng Shi</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2403.07392">https://arxiv.org/abs/2403.07392</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2403.07392">https://arxiv.org/pdf/2403.07392</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2403.07392]] ViT-CoMer: Vision Transformer with Convolutional Multi-scale Feature  Interaction for Dense Predictions(https://arxiv.org/abs/2403.07392)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Although Vision Transformer (ViT) has achieved significant success in computer vision, it does not perform well in dense prediction tasks due to the lack of inner-patch information interaction and the limited diversity of feature scale. Most existing studies are devoted to designing vision-specific transformers to solve the above problems, which introduce additional pre-training costs. Therefore, we present a plain, pre-training-free, and feature-enhanced ViT backbone with Convolutional Multi-scale feature interaction, named ViT-CoMer, which facilitates bidirectional interaction between CNN and transformer. Compared to the state-of-the-art, ViT-CoMer has the following advantages: (1) We inject spatial pyramid multi-receptive field convolutional features into the ViT architecture, which effectively alleviates the problems of limited local information interaction and single-feature representation in ViT. (2) We propose a simple and efficient CNN-Transformer bidirectional fusion interaction module that performs multi-scale fusion across hierarchical features, which is beneficial for handling dense prediction tasks. (3) We evaluate the performance of ViT-CoMer across various dense prediction tasks, different frameworks, and multiple advanced pre-training. Notably, our ViT-CoMer-L achieves 64.3% AP on COCO val2017 without extra training data, and 62.1% mIoU on ADE20K val, both of which are comparable to state-of-the-art methods. We hope ViT-CoMer can serve as a new backbone for dense prediction tasks to facilitate future research. The code will be released at https://github.com/Traffic-X/ViT-CoMer.</li>
</ul>

<h3>Title: Complex Reasoning over Logical Queries on Commonsense Knowledge Graphs</h3>
<ul>
<li><strong>Authors: </strong>Tianqing Fang, Zeming Chen, Yangqiu Song, Antoine Bosselut</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2403.07398">https://arxiv.org/abs/2403.07398</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2403.07398">https://arxiv.org/pdf/2403.07398</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2403.07398]] Complex Reasoning over Logical Queries on Commonsense Knowledge Graphs(https://arxiv.org/abs/2403.07398)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative, large language model</a></li>
<li><strong>Abstract: </strong>Event commonsense reasoning requires the ability to reason about the relationship between events, as well as infer implicit context underlying that relationship. However, data scarcity makes it challenging for language models to learn to generate commonsense inferences for contexts and questions involving interactions between complex events. To address this demand, we present COM2 (COMplex COMmonsense), a new dataset created by sampling multi-hop logical queries (e.g., the joint effect or cause of both event A and B, or the effect of the effect of event C) from an existing commonsense knowledge graph (CSKG), and verbalizing them using handcrafted rules and large language models into multiple-choice and text generation questions. Our experiments show that language models trained on COM2 exhibit significant improvements in complex reasoning ability, resulting in enhanced zero-shot performance in both in-domain and out-of-domain tasks for question answering and generative commonsense reasoning, without expensive human annotations.</li>
</ul>

<h3>Title: In-context learning enables multimodal large language models to classify  cancer pathology images</h3>
<ul>
<li><strong>Authors: </strong>Dyke Ferber, Georg WÃ¶lflein, Isabella C. Wiest, Marta Ligero, Srividhya Sainath, Narmin Ghaffari Laleh, Omar S.M. El Nahhas, Gustav MÃ¼ller-Franzes, Dirk JÃ¤ger, Daniel Truhn, Jakob Nikolas Kather</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2403.07407">https://arxiv.org/abs/2403.07407</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2403.07407">https://arxiv.org/pdf/2403.07407</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2403.07407]] In-context learning enables multimodal large language models to classify  cancer pathology images(https://arxiv.org/abs/2403.07407)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer, generative, large language model</a></li>
<li><strong>Abstract: </strong>Medical image classification requires labeled, task-specific datasets which are used to train deep learning networks de novo, or to fine-tune foundation models. However, this process is computationally and technically demanding. In language processing, in-context learning provides an alternative, where models learn from within prompts, bypassing the need for parameter updates. Yet, in-context learning remains underexplored in medical image analysis. Here, we systematically evaluate the model Generative Pretrained Transformer 4 with Vision capabilities (GPT-4V) on cancer image processing with in-context learning on three cancer histopathology tasks of high importance: Classification of tissue subtypes in colorectal cancer, colon polyp subtyping and breast tumor detection in lymph node sections. Our results show that in-context learning is sufficient to match or even outperform specialized neural networks trained for particular tasks, while only requiring a minimal number of samples. In summary, this study demonstrates that large vision language models trained on non-domain specific data can be applied out-of-the box to solve medical image-processing tasks in histopathology. This democratizes access of generalist AI models to medical experts without technical background especially for areas where annotated data is scarce.</li>
</ul>

<h3>Title: NightHaze: Nighttime Image Dehazing via Self-Prior Learning</h3>
<ul>
<li><strong>Authors: </strong>Beibei Lin, Yeying Jin, Wending Yan, Wei Ye, Yuan Yuan, Robby T. Tan</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2403.07408">https://arxiv.org/abs/2403.07408</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2403.07408">https://arxiv.org/pdf/2403.07408</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2403.07408]] NightHaze: Nighttime Image Dehazing via Self-Prior Learning(https://arxiv.org/abs/2403.07408)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Masked autoencoder (MAE) shows that severe augmentation during training produces robust representations for high-level tasks. This paper brings the MAE-like framework to nighttime image enhancement, demonstrating that severe augmentation during training produces strong network priors that are resilient to real-world night haze degradations. We propose a novel nighttime image dehazing method with self-prior learning. Our main novelty lies in the design of severe augmentation, which allows our model to learn robust priors. Unlike MAE that uses masking, we leverage two key challenging factors of nighttime images as augmentation: light effects and noise. During training, we intentionally degrade clear images by blending them with light effects as well as by adding noise, and subsequently restore the clear images. This enables our model to learn clear background priors. By increasing the noise values to approach as high as the pixel intensity values of the glow and light effect blended images, our augmentation becomes severe, resulting in stronger priors. While our self-prior learning is considerably effective in suppressing glow and revealing details of background scenes, in some cases, there are still some undesired artifacts that remain, particularly in the forms of over-suppression. To address these artifacts, we propose a self-refinement module based on the semi-supervised teacher-student framework. Our NightHaze, especially our MAE-like self-prior learning, shows that models trained with severe augmentation effectively improve the visibility of input haze images, approaching the clarity of clear nighttime images. Extensive experiments demonstrate that our NightHaze achieves state-of-the-art performance, outperforming existing nighttime image dehazing methods by a substantial margin of 15.5% for MUSIQ and 23.5% for ClipIQA.</li>
</ul>

<h3>Title: Learning-Augmented Algorithms with Explicit Predictors</h3>
<ul>
<li><strong>Authors: </strong>Marek Elias, Haim Kaplan, Yishay Mansour, Shay Moran</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.DS</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2403.07413">https://arxiv.org/abs/2403.07413</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2403.07413">https://arxiv.org/pdf/2403.07413</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2403.07413]] Learning-Augmented Algorithms with Explicit Predictors(https://arxiv.org/abs/2403.07413)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Recent advances in algorithmic design show how to utilize predictions obtained by machine learning models from past and present data. These approaches have demonstrated an enhancement in performance when the predictions are accurate, while also ensuring robustness by providing worst-case guarantees when predictions fail. In this paper we focus on online problems; prior research in this context was focused on a paradigm where the predictor is pre-trained on past data and then used as a black box (to get the predictions it was trained for). In contrast, in this work, we unpack the predictor and integrate the learning problem it gives rise for within the algorithmic challenge. In particular we allow the predictor to learn as it receives larger parts of the input, with the ultimate goal of designing online learning algorithms specifically tailored for the algorithmic task at hand. Adopting this perspective, we focus on a number of fundamental problems, including caching and scheduling, which have been well-studied in the black-box setting. For each of the problems we consider, we introduce new algorithms that take advantage of explicit learning algorithms which we carefully design towards optimizing the overall performance. We demonstrate the potential of our approach by deriving performance bounds which improve over those established in previous work.</li>
</ul>

<h3>Title: Experimental Comparison of Ensemble Methods and Time-to-Event Analysis  Models Through Integrated Brier Score and Concordance Index</h3>
<ul>
<li><strong>Authors: </strong>Camila Fernandez (LPSM), Chung Shue Chen, Chen Pierre Gaillard, Alonso Silva</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2403.07460">https://arxiv.org/abs/2403.07460</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2403.07460">https://arxiv.org/pdf/2403.07460</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2403.07460]] Experimental Comparison of Ensemble Methods and Time-to-Event Analysis  Models Through Integrated Brier Score and Concordance Index(https://arxiv.org/abs/2403.07460)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Time-to-event analysis is a branch of statistics that has increased in popularity during the last decades due to its many application fields, such as predictive maintenance, customer churn prediction and population lifetime estimation. In this paper, we review and compare the performance of several prediction models for time-to-event analysis. These consist of semi-parametric and parametric statistical models, in addition to machine learning approaches. Our study is carried out on three datasets and evaluated in two different scores (the integrated Brier score and concordance index). Moreover, we show how ensemble methods, which surprisingly have not yet been much studied in time-to-event analysis, can improve the prediction accuracy and enhance the robustness of the prediction performance. We conclude the analysis with a simulation experiment in which we evaluate the factors influencing the performance ranking of the methods using both scores.</li>
</ul>

<h3>Title: Backdoor Attack with Mode Mixture Latent Modification</h3>
<ul>
<li><strong>Authors: </strong>Hongwei Zhang, Xiaoyin Xu, Dongsheng An, Xianfeng Gu, Min Zhang</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2403.07463">https://arxiv.org/abs/2403.07463</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2403.07463">https://arxiv.org/pdf/2403.07463</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2403.07463]] Backdoor Attack with Mode Mixture Latent Modification(https://arxiv.org/abs/2403.07463)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, attack</a></li>
<li><strong>Abstract: </strong>Backdoor attacks become a significant security concern for deep neural networks in recent years. An image classification model can be compromised if malicious backdoors are injected into it. This corruption will cause the model to function normally on clean images but predict a specific target label when triggers are present. Previous research can be categorized into two genres: poisoning a portion of the dataset with triggered images for users to train the model from scratch, or training a backdoored model alongside a triggered image generator. Both approaches require significant amount of attackable parameters for optimization to establish a connection between the trigger and the target label, which may raise suspicions as more people become aware of the existence of backdoor attacks. In this paper, we propose a backdoor attack paradigm that only requires minimal alterations (specifically, the output layer) to a clean model in order to inject the backdoor under the guise of fine-tuning. To achieve this, we leverage mode mixture samples, which are located between different modes in latent space, and introduce a novel method for conducting backdoor attacks. We evaluate the effectiveness of our method on four popular benchmark datasets: MNIST, CIFAR-10, GTSRB, and TinyImageNet.</li>
</ul>

<h3>Title: One for All and All for One: GNN-based Control-Flow Attestation for  Embedded Devices</h3>
<ul>
<li><strong>Authors: </strong>Marco Chilese, Richard Mitev, Meni Orenbach, Robert Thorburn, Ahmad Atamli, Ahmad-Reza Sadeghi</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2403.07465">https://arxiv.org/abs/2403.07465</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2403.07465">https://arxiv.org/pdf/2403.07465</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2403.07465]] One for All and All for One: GNN-based Control-Flow Attestation for  Embedded Devices(https://arxiv.org/abs/2403.07465)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, attack</a></li>
<li><strong>Abstract: </strong>Control-Flow Attestation (CFA) is a security service that allows an entity (verifier) to verify the integrity of code execution on a remote computer system (prover). Existing CFA schemes suffer from impractical assumptions, such as requiring access to the prover's internal state (e.g., memory or code), the complete Control-Flow Graph (CFG) of the prover's software, large sets of measurements, or tailor-made hardware. Moreover, current CFA schemes are inadequate for attesting embedded systems due to their high computational overhead and resource usage. In this paper, we overcome the limitations of existing CFA schemes for embedded devices by introducing RAGE, a novel, lightweight CFA approach with minimal requirements. RAGE can detect Code Reuse Attacks (CRA), including control- and non-control-data attacks. It efficiently extracts features from one execution trace and leverages Unsupervised Graph Neural Networks (GNNs) to identify deviations from benign executions. The core intuition behind RAGE is to exploit the correspondence between execution trace, execution graph, and execution embeddings to eliminate the unrealistic requirement of having access to a complete CFG. We evaluate RAGE on embedded benchmarks and demonstrate that (i) it detects 40 real-world attacks on embedded software; (ii) Further, we stress our scheme with synthetic return-oriented programming (ROP) and data-oriented programming (DOP) attacks on the real-world embedded software benchmark Embench, achieving 98.03% (ROP) and 91.01% (DOP) F1-Score while maintaining a low False Positive Rate of 3.19%; (iii) Additionally, we evaluate RAGE on OpenSSL, used by millions of devices and achieve 97.49% and 84.42% F1-Score for ROP and DOP attack detection, with an FPR of 5.47%.</li>
</ul>

<h3>Title: A Deep Learning Approach to Diabetes Diagnosis</h3>
<ul>
<li><strong>Authors: </strong>Zeyu Zhang, Khandaker Asif Ahmed, Md Rakibul Hasan, Tom Gedeon, Md Zakir Hossain</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2403.07483">https://arxiv.org/abs/2403.07483</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2403.07483">https://arxiv.org/pdf/2403.07483</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2403.07483]] A Deep Learning Approach to Diabetes Diagnosis(https://arxiv.org/abs/2403.07483)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Diabetes, resulting from inadequate insulin production or utilization, causes extensive harm to the body. Existing diagnostic methods are often invasive and come with drawbacks, such as cost constraints. Although there are machine learning models like Classwise k Nearest Neighbor (CkNN) and General Regression Neural Network (GRNN), they struggle with imbalanced data and result in under-performance. Leveraging advancements in sensor technology and machine learning, we propose a non-invasive diabetes diagnosis using a Back Propagation Neural Network (BPNN) with batch normalization, incorporating data re-sampling and normalization for class balancing. Our method addresses existing challenges such as limited performance associated with traditional machine learning. Experimental results on three datasets show significant improvements in overall accuracy, sensitivity, and specificity compared to traditional methods. Notably, we achieve accuracies of 89.81% in Pima diabetes dataset, 75.49% in CDC BRFSS2015 dataset, and 95.28% in Mesra Diabetes dataset. This underscores the potential of deep learning models for robust diabetes diagnosis. See project website https://steve-zeyu-zhang.github.io/DiabetesDiagnosis/</li>
</ul>

<h3>Title: XpertAI: uncovering model strategies for sub-manifolds</h3>
<ul>
<li><strong>Authors: </strong>Simon Letzgus, Klaus-Robert MÃ¼ller, GrÃ©goire Montavon</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2403.07486">https://arxiv.org/abs/2403.07486</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2403.07486">https://arxiv.org/pdf/2403.07486</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2403.07486]] XpertAI: uncovering model strategies for sub-manifolds(https://arxiv.org/abs/2403.07486)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction</a></li>
<li><strong>Abstract: </strong>In recent years, Explainable AI (XAI) methods have facilitated profound validation and knowledge extraction from ML models. While extensively studied for classification, few XAI solutions have addressed the challenges specific to regression models. In regression, explanations need to be precisely formulated to address specific user queries (e.g.\ distinguishing between `Why is the output above 0?' and `Why is the output above 50?'). They should furthermore reflect the model's behavior on the relevant data sub-manifold. In this paper, we introduce XpertAI, a framework that disentangles the prediction strategy into multiple range-specific sub-strategies and allows the formulation of precise queries about the model (the `explanandum') as a linear combination of those sub-strategies. XpertAI is formulated generally to work alongside popular XAI attribution techniques, based on occlusion, gradient integration, or reverse propagation. Qualitative and quantitative results, demonstrate the benefits of our approach.</li>
</ul>

<h3>Title: Motion Mamba: Efficient and Long Sequence Motion Generation with  Hierarchical and Bidirectional Selective SSM</h3>
<ul>
<li><strong>Authors: </strong>Zeyu Zhang, Akide Liu, Ian Reid, Richard Hartley, Bohan Zhuang, Hao Tang</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2403.07487">https://arxiv.org/abs/2403.07487</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2403.07487">https://arxiv.org/pdf/2403.07487</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2403.07487]] Motion Mamba: Efficient and Long Sequence Motion Generation with  Hierarchical and Bidirectional Selective SSM(https://arxiv.org/abs/2403.07487)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, generative</a></li>
<li><strong>Abstract: </strong>Human motion generation stands as a significant pursuit in generative computer vision, while achieving long-sequence and efficient motion generation remains challenging. Recent advancements in state space models (SSMs), notably Mamba, have showcased considerable promise in long sequence modeling with an efficient hardware-aware design, which appears to be a promising direction to build motion generation model upon it. Nevertheless, adapting SSMs to motion generation faces hurdles since the lack of a specialized design architecture to model motion sequence. To address these challenges, we propose Motion Mamba, a simple and efficient approach that presents the pioneering motion generation model utilized SSMs. Specifically, we design a Hierarchical Temporal Mamba (HTM) block to process temporal data by ensemble varying numbers of isolated SSM modules across a symmetric U-Net architecture aimed at preserving motion consistency between frames. We also design a Bidirectional Spatial Mamba (BSM) block to bidirectionally process latent poses, to enhance accurate motion generation within a temporal frame. Our proposed method achieves up to 50% FID improvement and up to 4 times faster on the HumanML3D and KIT-ML datasets compared to the previous best diffusion-based method, which demonstrates strong capabilities of high-quality long sequence motion modeling and real-time human motion generation. See project website https://steve-zeyu-zhang.github.io/MotionMamba/</li>
</ul>

<h3>Title: Block-wise LoRA: Revisiting Fine-grained LoRA for Effective  Personalization and Stylization in Text-to-Image Generation</h3>
<ul>
<li><strong>Authors: </strong>Likun Li, Haoqi Zeng, Changpeng Yang, Haozhe Jia, Di Xu</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2403.07500">https://arxiv.org/abs/2403.07500</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2403.07500">https://arxiv.org/pdf/2403.07500</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2403.07500]] Block-wise LoRA: Revisiting Fine-grained LoRA for Effective  Personalization and Stylization in Text-to-Image Generation(https://arxiv.org/abs/2403.07500)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>The objective of personalization and stylization in text-to-image is to instruct a pre-trained diffusion model to analyze new concepts introduced by users and incorporate them into expected styles. Recently, parameter-efficient fine-tuning (PEFT) approaches have been widely adopted to address this task and have greatly propelled the development of this field. Despite their popularity, existing efficient fine-tuning methods still struggle to achieve effective personalization and stylization in T2I generation. To address this issue, we propose block-wise Low-Rank Adaptation (LoRA) to perform fine-grained fine-tuning for different blocks of SD, which can generate images faithful to input prompts and target identity and also with desired style. Extensive experiments demonstrate the effectiveness of the proposed method.</li>
</ul>

<h3>Title: Detecting Security-Relevant Methods using Multi-label Machine Learning</h3>
<ul>
<li><strong>Authors: </strong>Oshando Johnson, Goran Piskachev, Ranjith Krishnamurthy, Eric Bodden</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2403.07501">https://arxiv.org/abs/2403.07501</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2403.07501">https://arxiv.org/pdf/2403.07501</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2403.07501]] Detecting Security-Relevant Methods using Multi-label Machine Learning(https://arxiv.org/abs/2403.07501)</code><input type="text"></li>
<li><strong>Keywords: </strong>security</a></li>
<li><strong>Abstract: </strong>To detect security vulnerabilities, static analysis tools need to be configured with security-relevant methods. Current approaches can automatically identify such methods using binary relevance machine learning approaches. However, they ignore dependencies among security-relevant methods, over-generalize and perform poorly in practice. Additionally, users have to nevertheless manually configure static analysis tools using the detected methods. Based on feedback from users and our observations, the excessive manual steps can often be tedious, error-prone and counter-intuitive. In this paper, we present Dev-Assist, an IntelliJ IDEA plugin that detects security-relevant methods using a multi-label machine learning approach that considers dependencies among labels. The plugin can automatically generate configurations for static analysis tools, run the static analysis, and show the results in IntelliJ IDEA. Our experiments reveal that Dev-Assist's machine learning approach has a higher F1-Measure than related approaches. Moreover, the plugin reduces and simplifies the manual effort required when configuring and using static analysis tools.</li>
</ul>

<h3>Title: MoAI: Mixture of All Intelligence for Large Language and Vision Models</h3>
<ul>
<li><strong>Authors: </strong>Byung-Kwan Lee, Beomchan Park, Chae Won Kim, Yong Man Ro</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2403.07508">https://arxiv.org/abs/2403.07508</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2403.07508">https://arxiv.org/pdf/2403.07508</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2403.07508]] MoAI: Mixture of All Intelligence for Large Language and Vision Models(https://arxiv.org/abs/2403.07508)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model, segmentation</a></li>
<li><strong>Abstract: </strong>The rise of large language models (LLMs) and instruction tuning has led to the current trend of instruction-tuned large language and vision models (LLVMs). This trend involves either meticulously curating numerous instruction tuning datasets tailored to specific objectives or enlarging LLVMs to manage vast amounts of vision language (VL) data. However, current LLVMs have disregarded the detailed and comprehensive real-world scene understanding available from specialized computer vision (CV) models in visual perception tasks such as segmentation, detection, scene graph generation (SGG), and optical character recognition (OCR). Instead, the existing LLVMs rely mainly on the large capacity and emergent capabilities of their LLM backbones. Therefore, we present a new LLVM, Mixture of All Intelligence (MoAI), which leverages auxiliary visual information obtained from the outputs of external segmentation, detection, SGG, and OCR models. MoAI operates through two newly introduced modules: MoAI-Compressor and MoAI-Mixer. After verbalizing the outputs of the external CV models, the MoAI-Compressor aligns and condenses them to efficiently use relevant auxiliary visual information for VL tasks. MoAI-Mixer then blends three types of intelligence (1) visual features, (2) auxiliary features from the external CV models, and (3) language features by utilizing the concept of Mixture of Experts. Through this integration, MoAI significantly outperforms both open-source and closed-source LLVMs in numerous zero-shot VL tasks, particularly those related to real-world scene understanding such as object existence, positions, relations, and OCR without enlarging the model size or curating extra visual instruction tuning datasets.</li>
</ul>

<h3>Title: D4D: An RGBD diffusion model to boost monocular depth estimation</h3>
<ul>
<li><strong>Authors: </strong>L. Papa, P. Russo, I. Amerini</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2403.07516">https://arxiv.org/abs/2403.07516</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2403.07516">https://arxiv.org/pdf/2403.07516</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2403.07516]] D4D: An RGBD diffusion model to boost monocular depth estimation(https://arxiv.org/abs/2403.07516)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>Ground-truth RGBD data are fundamental for a wide range of computer vision applications; however, those labeled samples are difficult to collect and time-consuming to produce. A common solution to overcome this lack of data is to employ graphic engines to produce synthetic proxies; however, those data do not often reflect real-world images, resulting in poor performance of the trained models at the inference step. In this paper we propose a novel training pipeline that incorporates Diffusion4D (D4D), a customized 4-channels diffusion model able to generate realistic RGBD samples. We show the effectiveness of the developed solution in improving the performances of deep learning models on the monocular depth estimation task, where the correspondence between RGB and depth map is crucial to achieving accurate measurements. Our supervised training pipeline, enriched by the generated samples, outperforms synthetic and original data performances achieving an RMSE reduction of (8.2%, 11.9%) and (8.1%, 6.1%) respectively on the indoor NYU Depth v2 and the outdoor KITTI dataset.</li>
</ul>

<h3>Title: Open-World Semantic Segmentation Including Class Similarity</h3>
<ul>
<li><strong>Authors: </strong>Matteo Sodano, Federico Magistri, Lucas Nunes, Jens Behley, Cyrill Stachniss</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2403.07532">https://arxiv.org/abs/2403.07532</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2403.07532">https://arxiv.org/pdf/2403.07532</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2403.07532]] Open-World Semantic Segmentation Including Class Similarity(https://arxiv.org/abs/2403.07532)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>Interpreting camera data is key for autonomously acting systems, such as autonomous vehicles. Vision systems that operate in real-world environments must be able to understand their surroundings and need the ability to deal with novel situations. This paper tackles open-world semantic segmentation, i.e., the variant of interpreting image data in which objects occur that have not been seen during training. We propose a novel approach that performs accurate closed-world semantic segmentation and, at the same time, can identify new categories without requiring any additional training data. Our approach additionally provides a similarity measure for every newly discovered class in an image to a known category, which can be useful information in downstream tasks such as planning or mapping. Through extensive experiments, we show that our model achieves state-of-the-art results on classes known from training data as well as for anomaly segmentation and can distinguish between different unknown classes.</li>
</ul>

<h3>Title: Adaptive Fusion of Single-View and Multi-View Depth for Autonomous  Driving</h3>
<ul>
<li><strong>Authors: </strong>JunDa Cheng, Wei Yin, Kaixuan Wang, Xiaozhi Chen, Shijie Wang, Xin Yang</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2403.07535">https://arxiv.org/abs/2403.07535</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2403.07535">https://arxiv.org/pdf/2403.07535</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2403.07535]] Adaptive Fusion of Single-View and Multi-View Depth for Autonomous  Driving(https://arxiv.org/abs/2403.07535)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Multi-view depth estimation has achieved impressive performance over various benchmarks. However, almost all current multi-view systems rely on given ideal camera poses, which are unavailable in many real-world scenarios, such as autonomous driving. In this work, we propose a new robustness benchmark to evaluate the depth estimation system under various noisy pose settings. Surprisingly, we find current multi-view depth estimation methods or single-view and multi-view fusion methods will fail when given noisy pose settings. To address this challenge, we propose a single-view and multi-view fused depth estimation system, which adaptively integrates high-confident multi-view and single-view results for both robust and accurate depth estimations. The adaptive fusion module performs fusion by dynamically selecting high-confidence regions between two branches based on a wrapping confidence map. Thus, the system tends to choose the more reliable branch when facing textureless scenes, inaccurate calibration, dynamic objects, and other degradation or challenging conditions. Our method outperforms state-of-the-art multi-view and fusion methods under robustness testing. Furthermore, we achieve state-of-the-art performance on challenging benchmarks (KITTI and DDAD) when given accurate pose estimations. Project website: https://github.com/Junda24/AFNet/.</li>
</ul>

<h3>Title: LaB-GATr: geometric algebra transformers for large biomedical surface  and volume meshes</h3>
<ul>
<li><strong>Authors: </strong>Julian Suk, Baris Imre, Jelmer M. Wolterink</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2403.07536">https://arxiv.org/abs/2403.07536</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2403.07536">https://arxiv.org/pdf/2403.07536</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2403.07536]] LaB-GATr: geometric algebra transformers for large biomedical surface  and volume meshes(https://arxiv.org/abs/2403.07536)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Many anatomical structures can be described by surface or volume meshes. Machine learning is a promising tool to extract information from these 3D models. However, high-fidelity meshes often contain hundreds of thousands of vertices, which creates unique challenges in building deep neural network architectures. Furthermore, patient-specific meshes may not be canonically aligned which limits the generalisation of machine learning algorithms. We propose LaB-GATr, a transfomer neural network with geometric tokenisation that can effectively learn with large-scale (bio-)medical surface and volume meshes through sequence compression and interpolation. Our method extends the recently proposed geometric algebra transformer (GATr) and thus respects all Euclidean symmetries, i.e. rotation, translation and reflection, effectively mitigating the problem of canonical alignment between patients. LaB-GATr achieves state-of-the-art results on three tasks in cardiovascular hemodynamics modelling and neurodevelopmental phenotype prediction, featuring meshes of up to 200,000 vertices. Our results demonstrate that LaB-GATr is a powerful architecture for learning with high-fidelity meshes which has the potential to enable interesting downstream applications. Our implementation is publicly available.</li>
</ul>

<h3>Title: WannaLaugh: A Configurable Ransomware Emulator -- Learning to Mimic  Malicious Storage Traces</h3>
<ul>
<li><strong>Authors: </strong>Dionysios Diamantopolous, Roman Pletka, Slavisa Sarafijanovic, A.L. Narasimha Reddy, Haris Pozidis</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2403.07540">https://arxiv.org/abs/2403.07540</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2403.07540">https://arxiv.org/pdf/2403.07540</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2403.07540]] WannaLaugh: A Configurable Ransomware Emulator -- Learning to Mimic  Malicious Storage Traces(https://arxiv.org/abs/2403.07540)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, attack</a></li>
<li><strong>Abstract: </strong>Ransomware, a fearsome and rapidly evolving cybersecurity threat, continues to inflict severe consequences on individuals and organizations worldwide. Traditional detection methods, reliant on static signatures and application behavioral patterns, are challenged by the dynamic nature of these threats. This paper introduces three primary contributions to address this challenge. First, we introduce a ransomware emulator. This tool is designed to safely mimic ransomware attacks without causing actual harm or spreading malware, making it a unique solution for studying ransomware behavior. Second, we demonstrate how we use this emulator to create storage I/O traces. These traces are then utilized to train machine-learning models. Our results show that these models are effective in detecting ransomware, highlighting the practical application of our emulator in developing responsible cybersecurity tools. Third, we show how our emulator can be used to mimic the I/O behavior of existing ransomware thereby enabling safe trace collection. Both the emulator and its application represent significant steps forward in ransomware detection in the era of machine-learning-driven cybersecurity.</li>
</ul>

<h3>Title: A Survey of Vision Transformers in Autonomous Driving: Current Trends  and Future Directions</h3>
<ul>
<li><strong>Authors: </strong>Quoc-Vinh Lai-Dang</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2403.07542">https://arxiv.org/abs/2403.07542</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2403.07542">https://arxiv.org/pdf/2403.07542</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2403.07542]] A Survey of Vision Transformers in Autonomous Driving: Current Trends  and Future Directions(https://arxiv.org/abs/2403.07542)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer, segmentation</a></li>
<li><strong>Abstract: </strong>This survey explores the adaptation of visual transformer models in Autonomous Driving, a transition inspired by their success in Natural Language Processing. Surpassing traditional Recurrent Neural Networks in tasks like sequential image processing and outperforming Convolutional Neural Networks in global context capture, as evidenced in complex scene recognition, Transformers are gaining traction in computer vision. These capabilities are crucial in Autonomous Driving for real-time, dynamic visual scene processing. Our survey provides a comprehensive overview of Vision Transformer applications in Autonomous Driving, focusing on foundational concepts such as self-attention, multi-head attention, and encoder-decoder architecture. We cover applications in object detection, segmentation, pedestrian detection, lane detection, and more, comparing their architectural merits and limitations. The survey concludes with future research directions, highlighting the growing role of Vision Transformers in Autonomous Driving.</li>
</ul>

<h3>Title: MAMMOTH: Massively Multilingual Modular Open Translation @ Helsinki</h3>
<ul>
<li><strong>Authors: </strong>Timothee Mickus, Stig-Arne GrÃ¶nroos, Joseph Attieh, Michele Boggia, Ona De Gibert, Shaoxiong Ji, Niki Andreas Lopi, Alessandro Raganato, RaÃºl VÃ¡zquez, JÃ¶rg Tiedemann</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2403.07544">https://arxiv.org/abs/2403.07544</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2403.07544">https://arxiv.org/pdf/2403.07544</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2403.07544]] MAMMOTH: Massively Multilingual Modular Open Translation @ Helsinki(https://arxiv.org/abs/2403.07544)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>NLP in the age of monolithic large language models is approaching its limits in terms of size and information that can be handled. The trend goes to modularization, a necessary step into the direction of designing smaller sub-networks and components with specialized functionality. In this paper, we present the MAMMOTH toolkit: a framework designed for training massively multilingual modular machine translation systems at scale, initially derived from OpenNMT-py and then adapted to ensure efficient training across computation clusters. We showcase its efficiency across clusters of A100 and V100 NVIDIA GPUs, and discuss our design philosophy and plans for future information. The toolkit is publicly available online.</li>
</ul>

<h3>Title: SMURF: Continuous Dynamics for Motion-Deblurring Radiance Fields</h3>
<ul>
<li><strong>Authors: </strong>Jungho Lee, Dogyoon Lee, Minhyeok Lee, Donghyung Kim, Sangyoun Lee</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2403.07547">https://arxiv.org/abs/2403.07547</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2403.07547">https://arxiv.org/pdf/2403.07547</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2403.07547]] SMURF: Continuous Dynamics for Motion-Deblurring Radiance Fields(https://arxiv.org/abs/2403.07547)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Neural radiance fields (NeRF) has attracted considerable attention for their exceptional ability in synthesizing novel views with high fidelity. However, the presence of motion blur, resulting from slight camera movements during extended shutter exposures, poses a significant challenge, potentially compromising the quality of the reconstructed 3D scenes. While recent studies have addressed this issue, they do not consider the continuous dynamics of camera movements during image acquisition, leading to inaccurate scene reconstruction. Additionally, these methods are plagued by slow training and rendering speed. To effectively handle these issues, we propose sequential motion understanding radiance fields (SMURF), a novel approach that employs neural ordinary differential equation (Neural-ODE) to model continuous camera motion and leverages the explicit volumetric representation method for faster training and robustness to motion-blurred input images. The core idea of the SMURF is continuous motion blurring kernel (CMBK), a unique module designed to model a continuous camera movements for processing blurry inputs. Our model, rigorously evaluated against benchmark datasets, demonstrates state-of-the-art performance both quantitatively and qualitatively.</li>
</ul>

<h3>Title: Truth-Aware Context Selection: Mitigating the Hallucinations of Large  Language Models Being Misled by Untruthful Contexts</h3>
<ul>
<li><strong>Authors: </strong>Tian Yu, Shaolei Zhang, Yang Feng</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2403.07556">https://arxiv.org/abs/2403.07556</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2403.07556">https://arxiv.org/pdf/2403.07556</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2403.07556]] Truth-Aware Context Selection: Mitigating the Hallucinations of Large  Language Models Being Misled by Untruthful Contexts(https://arxiv.org/abs/2403.07556)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Although large language models (LLMs) have demonstrated impressive text generation capabilities, they are easily misled by the untruthful context provided by users or knowledge argumentation tools, thereby producing hallucinations. To alleviate the LLMs from being misled by untruthful information and take advantage of knowledge argumentation, we propose Truth-Aware Context Selection (TACS), a lightweight method to shield untruthful context from the inputs. TACS begins by performing truth detection on the input context, leveraging the parameterized knowledge within the LLM. Subsequently, it constructs a corresponding attention mask based on the truthfulness of each position, selecting the truthful context and discarding the untruthful context. Additionally, we introduce a new evaluation metric, Disturbance Adaption Rate, to further study the LLMs' ability to accept truthful information and resist untruthful information. Experimental results show that TACS can effectively filter information in context and significantly improve the overall quality of LLMs' responses when presented with misleading information.</li>
</ul>

<h3>Title: SIFiD: Reassess Summary Factual Inconsistency Detection with LLM</h3>
<ul>
<li><strong>Authors: </strong>Jiuding Yang, Hui Liu, Weidong Guo, Zhuwei Rao, Yu Xu, Di Niu</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2403.07557">https://arxiv.org/abs/2403.07557</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2403.07557">https://arxiv.org/pdf/2403.07557</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2403.07557]] SIFiD: Reassess Summary Factual Inconsistency Detection with LLM(https://arxiv.org/abs/2403.07557)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Ensuring factual consistency between the summary and the original document is paramount in summarization tasks. Consequently, considerable effort has been dedicated to detecting inconsistencies. With the advent of Large Language Models (LLMs), recent studies have begun to leverage their advanced language understanding capabilities for inconsistency detection. However, early attempts have shown that LLMs underperform traditional models due to their limited ability to follow instructions and the absence of an effective detection methodology. In this study, we reassess summary inconsistency detection with LLMs, comparing the performances of GPT-3.5 and GPT-4. To advance research in LLM-based inconsistency detection, we propose SIFiD (Summary Inconsistency Detection with Filtered Document) that identify key sentences within documents by either employing natural language inference or measuring semantic similarity between summaries and documents.</li>
</ul>

<h3>Title: RSBuilding: Towards General Remote Sensing Image Building Extraction and  Change Detection with Foundation Model</h3>
<ul>
<li><strong>Authors: </strong>Mingze Wang, Keyan Chen, Lili Su, Cilin Yan, Sheng Xu, Haotian Zhang, Pengcheng Yuan, Xiaolong Jiang, Baochang Zhang</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2403.07564">https://arxiv.org/abs/2403.07564</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2403.07564">https://arxiv.org/pdf/2403.07564</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2403.07564]] RSBuilding: Towards General Remote Sensing Image Building Extraction and  Change Detection with Foundation Model(https://arxiv.org/abs/2403.07564)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, extraction, federate</a></li>
<li><strong>Abstract: </strong>The intelligent interpretation of buildings plays a significant role in urban planning and management, macroeconomic analysis, population dynamics, etc. Remote sensing image building interpretation primarily encompasses building extraction and change detection. However, current methodologies often treat these two tasks as separate entities, thereby failing to leverage shared knowledge. Moreover, the complexity and diversity of remote sensing image scenes pose additional challenges, as most algorithms are designed to model individual small datasets, thus lacking cross-scene generalization. In this paper, we propose a comprehensive remote sensing image building understanding model, termed RSBuilding, developed from the perspective of the foundation model. RSBuilding is designed to enhance cross-scene generalization and task universality. Specifically, we extract image features based on the prior knowledge of the foundation model and devise a multi-level feature sampler to augment scale information. To unify task representation and integrate image spatiotemporal clues, we introduce a cross-attention decoder with task prompts. Addressing the current shortage of datasets that incorporate annotations for both tasks, we have developed a federated training strategy to facilitate smooth model convergence even when supervision for some tasks is missing, thereby bolstering the complementarity of different tasks. Our model was trained on a dataset comprising up to 245,000 images and validated on multiple building extraction and change detection datasets. The experimental results substantiate that RSBuilding can concurrently handle two structurally distinct tasks and exhibits robust zero-shot generalization capabilities.</li>
</ul>

<h3>Title: An Active Contour Model Driven By the Hybrid Signed Pressure Function</h3>
<ul>
<li><strong>Authors: </strong>Jing Zhao</a></li>
<li><strong>Subjects: </strong>cs.CV, math.NA</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2403.07570">https://arxiv.org/abs/2403.07570</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2403.07570">https://arxiv.org/pdf/2403.07570</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2403.07570]] An Active Contour Model Driven By the Hybrid Signed Pressure Function(https://arxiv.org/abs/2403.07570)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>Due to the influence of imaging equipment and complex imaging environments, most images in daily life have features of intensity inhomogeneity and noise. Therefore, many scholars have designed many image segmentation algorithms to address these issues. Among them, the active contour model is one of the most effective image segmentation algorithms.This paper proposes an active contour model driven by the hybrid signed pressure function that combines global and local information construction. Firstly, a new global region-based signed pressure function is introduced by combining the average intensity of the inner and outer regions of the curve with the median intensity of the inner region of the evolution curve. Then, the paper uses the energy differences between the inner and outer regions of the curve in the local region to design the signed pressure function of the local term. Combine the two SPF function to obtain a new signed pressure function and get the evolution equation of the new model. Finally, experiments and numerical analysis show that the model has excellent segmentation performance for both intensity inhomogeneous images and noisy images.</li>
</ul>

<h3>Title: AACP: Aesthetics assessment of children's paintings based on  self-supervised learning</h3>
<ul>
<li><strong>Authors: </strong>Shiqi Jiang, Ning Li, Chen Shi, Liping Guo, Changbo Wang, Chenhui Li</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2403.07578">https://arxiv.org/abs/2403.07578</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2403.07578">https://arxiv.org/pdf/2403.07578</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2403.07578]] AACP: Aesthetics assessment of children's paintings based on  self-supervised learning(https://arxiv.org/abs/2403.07578)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction</a></li>
<li><strong>Abstract: </strong>The Aesthetics Assessment of Children's Paintings (AACP) is an important branch of the image aesthetics assessment (IAA), playing a significant role in children's education. This task presents unique challenges, such as limited available data and the requirement for evaluation metrics from multiple perspectives. However, previous approaches have relied on training large datasets and subsequently providing an aesthetics score to the image, which is not applicable to AACP. To solve this problem, we construct an aesthetics assessment dataset of children's paintings and a model based on self-supervised learning. 1) We build a novel dataset composed of two parts: the first part contains more than 20k unlabeled images of children's paintings; the second part contains 1.2k images of children's paintings, and each image contains eight attributes labeled by multiple design experts. 2) We design a pipeline that includes a feature extraction module, perception modules and a disentangled evaluation module. 3) We conduct both qualitative and quantitative experiments to compare our model's performance with five other methods using the AACP dataset. Our experiments reveal that our method can accurately capture aesthetic features and achieve state-of-the-art performance.</li>
</ul>

<h3>Title: LLMvsSmall Model? Large Language Model Based Text Augmentation Enhanced  Personality Detection Model</h3>
<ul>
<li><strong>Authors: </strong>Linmei Hu, Hongyu He, Duokang Wang, Ziwang Zhao, Yingxia Shao, Liqiang Nie</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2403.07581">https://arxiv.org/abs/2403.07581</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2403.07581">https://arxiv.org/pdf/2403.07581</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2403.07581]] LLMvsSmall Model? Large Language Model Based Text Augmentation Enhanced  Personality Detection Model(https://arxiv.org/abs/2403.07581)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Personality detection aims to detect one's personality traits underlying in social media posts. One challenge of this task is the scarcity of ground-truth personality traits which are collected from self-report questionnaires. Most existing methods learn post features directly by fine-tuning the pre-trained language models under the supervision of limited personality labels. This leads to inferior quality of post features and consequently affects the performance. In addition, they treat personality traits as one-hot classification labels, overlooking the semantic information within them. In this paper, we propose a large language model (LLM) based text augmentation enhanced personality detection model, which distills the LLM's knowledge to enhance the small model for personality detection, even when the LLM fails in this task. Specifically, we enable LLM to generate post analyses (augmentations) from the aspects of semantic, sentiment, and linguistic, which are critical for personality detection. By using contrastive learning to pull them together in the embedding space, the post encoder can better capture the psycho-linguistic information within the post representations, thus improving personality detection. Furthermore, we utilize the LLM to enrich the information of personality labels for enhancing the detection performance. Experimental results on the benchmark datasets demonstrate that our model outperforms the state-of-the-art methods on personality detection.</li>
</ul>

<h3>Title: Federated Learning of Socially Appropriate Agent Behaviours in Simulated  Home Environments</h3>
<ul>
<li><strong>Authors: </strong>Saksham Checker, Nikhil Churamani, Hatice Gunes</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CY, cs.RO</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2403.07586">https://arxiv.org/abs/2403.07586</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2403.07586">https://arxiv.org/pdf/2403.07586</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2403.07586]] Federated Learning of Socially Appropriate Agent Behaviours in Simulated  Home Environments(https://arxiv.org/abs/2403.07586)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, federate</a></li>
<li><strong>Abstract: </strong>As social robots become increasingly integrated into daily life, ensuring their behaviours align with social norms is crucial. For their widespread open-world application, it is important to explore Federated Learning (FL) settings where individual robots can learn about their unique environments while also learning from each others' experiences. In this paper, we present a novel FL benchmark that evaluates different strategies, using multi-label regression objectives, where each client individually learns to predict the social appropriateness of different robot actions while also sharing their learning with others. Furthermore, splitting the training data by different contexts such that each client incrementally learns across contexts, we present a novel Federated Continual Learning (FCL) benchmark that adapts FL-based methods to use state-of-the-art Continual Learning (CL) methods to continually learn socially appropriate agent behaviours under different contextual settings. Federated Averaging (FedAvg) of weights emerges as a robust FL strategy while rehearsal-based FCL enables incrementally learning the social appropriateness of robot actions, across contextual splits.</li>
</ul>

<h3>Title: Visual Privacy Auditing with Diffusion Models</h3>
<ul>
<li><strong>Authors: </strong>Kristian Schwethelm, Johannes Kaiser, Moritz Knolle, Daniel Rueckert, Georgios Kaissis, Alexander Ziller</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2403.07588">https://arxiv.org/abs/2403.07588</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2403.07588">https://arxiv.org/pdf/2403.07588</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2403.07588]] Visual Privacy Auditing with Diffusion Models(https://arxiv.org/abs/2403.07588)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, attack, diffusion</a></li>
<li><strong>Abstract: </strong>Image reconstruction attacks on machine learning models pose a significant risk to privacy by potentially leaking sensitive information. Although defending against such attacks using differential privacy (DP) has proven effective, determining appropriate DP parameters remains challenging. Current formal guarantees on data reconstruction success suffer from overly theoretical assumptions regarding adversary knowledge about the target data, particularly in the image domain. In this work, we empirically investigate this discrepancy and find that the practicality of these assumptions strongly depends on the domain shift between the data prior and the reconstruction target. We propose a reconstruction attack based on diffusion models (DMs) that assumes adversary access to real-world image priors and assess its implications on privacy leakage under DP-SGD. We show that (1) real-world data priors significantly influence reconstruction success, (2) current reconstruction bounds do not model the risk posed by data priors well, and (3) DMs can serve as effective auditing tools for visualizing privacy leakage.</li>
</ul>

<h3>Title: PeLK: Parameter-efficient Large Kernel ConvNets with Peripheral  Convolution</h3>
<ul>
<li><strong>Authors: </strong>Honghao Chen, Xiangxiang Chu, Yongjian Ren, Xin Zhao, Kaiqi Huang</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2403.07589">https://arxiv.org/abs/2403.07589</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2403.07589">https://arxiv.org/pdf/2403.07589</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2403.07589]] PeLK: Parameter-efficient Large Kernel ConvNets with Peripheral  Convolution(https://arxiv.org/abs/2403.07589)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer, segmentation</a></li>
<li><strong>Abstract: </strong>Recently, some large kernel convnets strike back with appealing performance and efficiency. However, given the square complexity of convolution, scaling up kernels can bring about an enormous amount of parameters and the proliferated parameters can induce severe optimization problem. Due to these issues, current CNNs compromise to scale up to 51x51 in the form of stripe convolution (i.e., 51x5 + 5x51) and start to saturate as the kernel size continues growing. In this paper, we delve into addressing these vital issues and explore whether we can continue scaling up kernels for more performance gains. Inspired by human vision, we propose a human-like peripheral convolution that efficiently reduces over 90% parameter count of dense grid convolution through parameter sharing, and manage to scale up kernel size to extremely large. Our peripheral convolution behaves highly similar to human, reducing the complexity of convolution from O(K^2) to O(logK) without backfiring performance. Built on this, we propose Parameter-efficient Large Kernel Network (PeLK). Our PeLK outperforms modern vision Transformers and ConvNet architectures like Swin, ConvNeXt, RepLKNet and SLaK on various vision tasks including ImageNet classification, semantic segmentation on ADE20K and object detection on MS COCO. For the first time, we successfully scale up the kernel size of CNNs to an unprecedented 101x101 and demonstrate consistent improvements.</li>
</ul>

<h3>Title: Robustifying and Boosting Training-Free Neural Architecture Search</h3>
<ul>
<li><strong>Authors: </strong>Zhenfeng He, Yao Shu, Zhongxiang Dai, Bryan Kian Hsiang Low</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2403.07591">https://arxiv.org/abs/2403.07591</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2403.07591">https://arxiv.org/pdf/2403.07591</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2403.07591]] Robustifying and Boosting Training-Free Neural Architecture Search(https://arxiv.org/abs/2403.07591)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Neural architecture search (NAS) has become a key component of AutoML and a standard tool to automate the design of deep neural networks. Recently, training-free NAS as an emerging paradigm has successfully reduced the search costs of standard training-based NAS by estimating the true architecture performance with only training-free metrics. Nevertheless, the estimation ability of these metrics typically varies across different tasks, making it challenging to achieve robust and consistently good search performance on diverse tasks with only a single training-free metric. Meanwhile, the estimation gap between training-free metrics and the true architecture performances limits training-free NAS to achieve superior performance. To address these challenges, we propose the robustifying and boosting training-free NAS (RoBoT) algorithm which (a) employs the optimized combination of existing training-free metrics explored from Bayesian optimization to develop a robust and consistently better-performing metric on diverse tasks, and (b) applies greedy search, i.e., the exploitation, on the newly developed metric to bridge the aforementioned gap and consequently to boost the search performance of standard training-free NAS further. Remarkably, the expected performance of our RoBoT can be theoretically guaranteed, which improves over the existing training-free NAS under mild conditions with additional interesting insights. Our extensive experiments on various NAS benchmark tasks yield substantial empirical evidence to support our theoretical results.</li>
</ul>

<h3>Title: Accurate Spatial Gene Expression Prediction by integrating  Multi-resolution features</h3>
<ul>
<li><strong>Authors: </strong>Youngmin Chung, Ji Hun Ha, Kyeong Chan Im, Joo Sang Lee</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2403.07592">https://arxiv.org/abs/2403.07592</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2403.07592">https://arxiv.org/pdf/2403.07592</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2403.07592]] Accurate Spatial Gene Expression Prediction by integrating  Multi-resolution features(https://arxiv.org/abs/2403.07592)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Recent advancements in Spatial Transcriptomics (ST) technology have facilitated detailed gene expression analysis within tissue contexts. However, the high costs and methodological limitations of ST necessitate a more robust predictive model. In response, this paper introduces TRIPLEX, a novel deep learning framework designed to predict spatial gene expression from Whole Slide Images (WSIs). TRIPLEX uniquely harnesses multi-resolution features, capturing cellular morphology at individual spots, the local context around these spots, and the global tissue organization. By integrating these features through an effective fusion strategy, TRIPLEX achieves accurate gene expression prediction. Our comprehensive benchmark study, conducted on three public ST datasets and supplemented with Visium data from 10X Genomics, demonstrates that TRIPLEX outperforms current state-of-the-art models in Mean Squared Error (MSE), Mean Absolute Error (MAE), and Pearson Correlation Coefficient (PCC). The model's predictions align closely with ground truth gene expression profiles and tumor annotations, underscoring TRIPLEX's potential in advancing cancer diagnosis and treatment.</li>
</ul>

<h3>Title: MinkUNeXt: Point Cloud-based Large-scale Place Recognition using 3D  Sparse Convolutions</h3>
<ul>
<li><strong>Authors: </strong>J.J. Cabrera, A. Santo, A. Gil, C. Viegas, L. PayÃ¡</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2403.07593">https://arxiv.org/abs/2403.07593</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2403.07593">https://arxiv.org/pdf/2403.07593</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2403.07593]] MinkUNeXt: Point Cloud-based Large-scale Place Recognition using 3D  Sparse Convolutions(https://arxiv.org/abs/2403.07593)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction, transformer</a></li>
<li><strong>Abstract: </strong>This paper presents MinkUNeXt, an effective and efficient architecture for place-recognition from point clouds entirely based on the new 3D MinkNeXt Block, a residual block composed of 3D sparse convolutions that follows the philosophy established by recent Transformers but purely using simple 3D convolutions. Feature extraction is performed at different scales by a U-Net encoder-decoder network and the feature aggregation of those features into a single descriptor is carried out by a Generalized Mean Pooling (GeM). The proposed architecture demonstrates that it is possible to surpass the current state-of-the-art by only relying on conventional 3D sparse convolutions without making use of more complex and sophisticated proposals such as Transformers, Attention-Layers or Deformable Convolutions. A thorough assessment of the proposal has been carried out using the Oxford RobotCar and the In-house datasets. As a result, MinkUNeXt proves to outperform other methods in the state-of-the-art.</li>
</ul>

<h3>Title: Mondrian: On-Device High-Performance Video Analytics with Compressive  Packed Inference</h3>
<ul>
<li><strong>Authors: </strong>Changmin Jeon, Seonjun Kim, Juheon Yi, Youngki Lee</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2403.07598">https://arxiv.org/abs/2403.07598</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2403.07598">https://arxiv.org/pdf/2403.07598</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2403.07598]] Mondrian: On-Device High-Performance Video Analytics with Compressive  Packed Inference(https://arxiv.org/abs/2403.07598)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction</a></li>
<li><strong>Abstract: </strong>In this paper, we present Mondrian, an edge system that enables high-performance object detection on high-resolution video streams. Many lightweight models and system optimization techniques have been proposed for resource-constrained devices, but they do not fully utilize the potential of the accelerators over dynamic, high-resolution videos. To enable such capability, we devise a novel Compressive Packed Inference to minimize per-pixel processing costs by selectively determining the necessary pixels to process and combining them to maximize processing parallelism. In particular, our system quickly extracts ROIs and dynamically shrinks them, reflecting the effect of the fast-changing characteristics of objects and scenes. It then intelligently combines such scaled ROIs into large canvases to maximize the utilization of inference accelerators such as GPU. Evaluation across various datasets, models, and devices shows Mondrian outperforms state-of-the-art baselines (e.g., input rescaling, ROI extractions, ROI extractions+batching) by 15.0-19.7% higher accuracy, leading to $\times$6.65 higher throughput than frame-wise inference for processing various 1080p video streams. We will release the code after the paper review.</li>
</ul>

<h3>Title: Unified Source-Free Domain Adaptation</h3>
<ul>
<li><strong>Authors: </strong>Song Tang, Wenxin Su, Mao Ye, Jianwei Zhang, Xiatian Zhu</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2403.07601">https://arxiv.org/abs/2403.07601</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2403.07601">https://arxiv.org/pdf/2403.07601</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2403.07601]] Unified Source-Free Domain Adaptation(https://arxiv.org/abs/2403.07601)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>In the pursuit of transferring a source model to a target domain without access to the source training data, Source-Free Domain Adaptation (SFDA) has been extensively explored across various scenarios, including closed-set, open-set, partial-set, and generalized settings. Existing methods, focusing on specific scenarios, not only address only a subset of challenges but also necessitate prior knowledge of the target domain, significantly limiting their practical utility and deployability. In light of these considerations, we introduce a more practical yet challenging problem, termed unified SFDA, which comprehensively incorporates all specific scenarios in a unified manner. To tackle this unified SFDA problem, we propose a novel approach called Latent Causal Factors Discovery (LCFD). In contrast to previous alternatives that emphasize learning the statistical description of reality, we formulate LCFD from a causality perspective. The objective is to uncover the causal relationships between latent variables and model decisions, enhancing the reliability and robustness of the learned model against domain shifts. To integrate extensive world knowledge, we leverage a pre-trained vision-language model such as CLIP. This aids in the formation and discovery of latent causal factors in the absence of supervision in the variation of distribution and semantics, coupled with a newly designed information bottleneck with theoretical guarantees. Extensive experiments demonstrate that LCFD can achieve new state-of-the-art results in distinct SFDA settings, as well as source-free out-of-distribution generalization.Our code and data are available at https://github.com/tntek/source-free-domain-adaptation.</li>
</ul>

<h3>Title: Efficient Knowledge Deletion from Trained Models through Layer-wise  Partial Machine Unlearning</h3>
<ul>
<li><strong>Authors: </strong>Vinay Chakravarthi Gogineni, Esmaeil S. Nadimi</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2403.07611">https://arxiv.org/abs/2403.07611</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2403.07611">https://arxiv.org/pdf/2403.07611</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2403.07611]] Efficient Knowledge Deletion from Trained Models through Layer-wise  Partial Machine Unlearning(https://arxiv.org/abs/2403.07611)</code><input type="text"></li>
<li><strong>Keywords: </strong>protect</a></li>
<li><strong>Abstract: </strong>Machine unlearning has garnered significant attention due to its ability to selectively erase knowledge obtained from specific training data samples in an already trained machine learning model. This capability enables data holders to adhere strictly to data protection regulations. However, existing unlearning techniques face practical constraints, often causing performance degradation, demanding brief fine-tuning post unlearning, and requiring significant storage. In response, this paper introduces a novel class of machine unlearning algorithms. First method is partial amnesiac unlearning, integration of layer-wise pruning with amnesiac unlearning. In this method, updates made to the model during training are pruned and stored, subsequently used to forget specific data from trained model. The second method assimilates layer-wise partial-updates into label-flipping and optimization-based unlearning to mitigate the adverse effects of data deletion on model efficacy. Through a detailed experimental evaluation, we showcase the effectiveness of proposed unlearning methods. Experimental results highlight that the partial amnesiac unlearning not only preserves model efficacy but also eliminates the necessity for brief post fine-tuning, unlike conventional amnesiac unlearning. Moreover, employing layer-wise partial updates in label-flipping and optimization-based unlearning techniques demonstrates superiority in preserving model efficacy compared to their naive counterparts.</li>
</ul>

<h3>Title: Smartphone region-wise image indoor localization using deep learning for  indoor tourist attraction</h3>
<ul>
<li><strong>Authors: </strong>Gabriel Toshio Hirokawa Higa, Rodrigo Stuqui Monzani, Jorge Fernando da Silva Cecatto, Maria Fernanda Balestieri Mariano de Souza, Vanessa Aparecida de Moraes Weber, Hemerson Pistori, Edson Takashi Matsubara</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2403.07621">https://arxiv.org/abs/2403.07621</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2403.07621">https://arxiv.org/pdf/2403.07621</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2403.07621]] Smartphone region-wise image indoor localization using deep learning for  indoor tourist attraction(https://arxiv.org/abs/2403.07621)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Smart indoor tourist attractions, such as smart museums and aquariums, usually require a significant investment in indoor localization devices. The smartphone Global Positional Systems use is unsuitable for scenarios where dense materials such as concrete and metal block weaken the GPS signals, which is the most common scenario in an indoor tourist attraction. Deep learning makes it possible to perform region-wise indoor localization using smartphone images. This approach does not require any investment in infrastructure, reducing the cost and time to turn museums and aquariums into smart museums or smart aquariums. This paper proposes using deep learning algorithms to classify locations using smartphone camera images for indoor tourism attractions. We evaluate our proposal in a real-world scenario in Brazil. We extensively collect images from ten different smartphones to classify biome-themed fish tanks inside the Pantanal Biopark, creating a new dataset of 3654 images. We tested seven state-of-the-art neural networks, three being transformer-based, achieving precision around 90% on average and recall and f-score around 89% on average. The results indicate good feasibility of the proposal in a most indoor tourist attractions.</li>
</ul>

<h3>Title: Hunting Attributes: Context Prototype-Aware Learning for Weakly  Supervised Semantic Segmentation</h3>
<ul>
<li><strong>Authors: </strong>Feilong Tang, Zhongxing Xu, Zhaojun Qu, Wei Feng, Xingjian Jiang, Zongyuan Ge</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2403.07630">https://arxiv.org/abs/2403.07630</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2403.07630">https://arxiv.org/pdf/2403.07630</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2403.07630]] Hunting Attributes: Context Prototype-Aware Learning for Weakly  Supervised Semantic Segmentation(https://arxiv.org/abs/2403.07630)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>Recent weakly supervised semantic segmentation (WSSS) methods strive to incorporate contextual knowledge to improve the completeness of class activation maps (CAM). In this work, we argue that the knowledge bias between instances and contexts affects the capability of the prototype to sufficiently understand instance semantics. Inspired by prototype learning theory, we propose leveraging prototype awareness to capture diverse and fine-grained feature attributes of instances. The hypothesis is that contextual prototypes might erroneously activate similar and frequently co-occurring object categories due to this knowledge bias. Therefore, we propose to enhance the prototype representation ability by mitigating the bias to better capture spatial coverage in semantic object regions. With this goal, we present a Context Prototype-Aware Learning (CPAL) strategy, which leverages semantic context to enrich instance comprehension. The core of this method is to accurately capture intra-class variations in object features through context-aware prototypes, facilitating the adaptation to the semantic attributes of various instances. We design feature distribution alignment to optimize prototype awareness, aligning instance feature distributions with dense features. In addition, a unified training framework is proposed to combine label-guided classification supervision and prototypes-guided self-supervision. Experimental results on PASCAL VOC 2012 and MS COCO 2014 show that CPAL significantly improves off-the-shelf methods and achieves state-of-the-art performance. The project is available at https://github.com/Barrett-python/CPAL.</li>
</ul>

<h3>Title: Decomposing Disease Descriptions for Enhanced Pathology Detection: A  Multi-Aspect Vision-Language Matching Framework</h3>
<ul>
<li><strong>Authors: </strong>Minh Hieu Phan, Yutong Xie, Yuankai Qi, Lingqiao Liu, Liyang Liu, Bowen Zhang, Zhibin Liao, Qi Wu, Minh-Son To, Johan W. Verjans</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2403.07636">https://arxiv.org/abs/2403.07636</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2403.07636">https://arxiv.org/pdf/2403.07636</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2403.07636]] Decomposing Disease Descriptions for Enhanced Pathology Detection: A  Multi-Aspect Vision-Language Matching Framework(https://arxiv.org/abs/2403.07636)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer, large language model</a></li>
<li><strong>Abstract: </strong>Medical vision language pre-training (VLP) has emerged as a frontier of research, enabling zero-shot pathological recognition by comparing the query image with the textual descriptions for each disease. Due to the complex semantics of biomedical texts, current methods struggle to align medical images with key pathological findings in unstructured reports. This leads to the misalignment with the target disease's textual representation. In this paper, we introduce a novel VLP framework designed to dissect disease descriptions into their fundamental aspects, leveraging prior knowledge about the visual manifestations of pathologies. This is achieved by consulting a large language model and medical experts. Integrating a Transformer module, our approach aligns an input image with the diverse elements of a disease, generating aspect-centric image representations. By consolidating the matches from each aspect, we improve the compatibility between an image and its associated disease. Additionally, capitalizing on the aspect-oriented representations, we present a dual-head Transformer tailored to process known and unknown diseases, optimizing the comprehensive detection efficacy. Conducting experiments on seven downstream datasets, ours outperforms recent methods by up to 8.07% and 11.23% in AUC scores for seen and novel categories, respectively. Our code is released at \href{https://github.com/HieuPhan33/MAVL}{https://github.com/HieuPhan33/MAVL}.</li>
</ul>

<h3>Title: Harder Tasks Need More Experts: Dynamic Routing in MoE Models</h3>
<ul>
<li><strong>Authors: </strong>Quzhe Huang, Zhenwei An, Nan Zhuang, Mingxu Tao, Chen Zhang, Yang Jin, Kun Xu, Kun Xu, Liwei Chen, Songfang Huang, Yansong Feng</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2403.07652">https://arxiv.org/abs/2403.07652</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2403.07652">https://arxiv.org/pdf/2403.07652</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2403.07652]] Harder Tasks Need More Experts: Dynamic Routing in MoE Models(https://arxiv.org/abs/2403.07652)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>In this paper, we introduce a novel dynamic expert selection framework for Mixture of Experts (MoE) models, aiming to enhance computational efficiency and model performance by adjusting the number of activated experts based on input difficulty. Unlike traditional MoE approaches that rely on fixed Top-K routing, which activates a predetermined number of experts regardless of the input's complexity, our method dynamically selects experts based on the confidence level in expert selection for each input. This allows for a more efficient utilization of computational resources, activating more experts for complex tasks requiring advanced reasoning and fewer for simpler tasks. Through extensive evaluations, our dynamic routing method demonstrates substantial improvements over conventional Top-2 routing across various benchmarks, achieving an average improvement of 0.7% with less than 90% activated parameters. Further analysis shows our model dispatches more experts to tasks requiring complex reasoning skills, like BBH, confirming its ability to dynamically allocate computational resources in alignment with the input's complexity. Our findings also highlight a variation in the number of experts needed across different layers of the transformer model, offering insights into the potential for designing heterogeneous MoE frameworks. The code and models are available at https://github.com/ZhenweiAn/Dynamic_MoE.</li>
</ul>

<h3>Title: Scalable Spatiotemporal Prediction with Bayesian Neural Fields</h3>
<ul>
<li><strong>Authors: </strong>Feras Saad, Jacob Burnim, Colin Carroll, Brian Patton, Urs KÃ¶ster, Rif A. Saurous, Matthew Hoffman</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, stat.AP, stat.ME</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2403.07657">https://arxiv.org/abs/2403.07657</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2403.07657">https://arxiv.org/pdf/2403.07657</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2403.07657]] Scalable Spatiotemporal Prediction with Bayesian Neural Fields(https://arxiv.org/abs/2403.07657)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Spatiotemporal datasets, which consist of spatially-referenced time series, are ubiquitous in many scientific and business-intelligence applications, such as air pollution monitoring, disease tracking, and cloud-demand forecasting. As modern datasets continue to increase in size and complexity, there is a growing need for new statistical methods that are flexible enough to capture complex spatiotemporal dynamics and scalable enough to handle large prediction problems. This work presents the Bayesian Neural Field (BayesNF), a domain-general statistical model for inferring rich probability distributions over a spatiotemporal domain, which can be used for data-analysis tasks including forecasting, interpolation, and variography. BayesNF integrates a novel deep neural network architecture for high-capacity function estimation with hierarchical Bayesian inference for robust uncertainty quantification. By defining the prior through a sequence of smooth differentiable transforms, posterior inference is conducted on large-scale data using variationally learned surrogates trained via stochastic gradient descent. We evaluate BayesNF against prominent statistical and machine-learning baselines, showing considerable improvements on diverse prediction problems from climate and public health datasets that contain tens to hundreds of thousands of measurements. The paper is accompanied with an open-source software package (https://github.com/google/bayesnf) that is easy-to-use and compatible with modern GPU and TPU accelerators on the JAX machine learning platform.</li>
</ul>

<h3>Title: Machine Learning for Soccer Match Result Prediction</h3>
<ul>
<li><strong>Authors: </strong>Rory Bunker, Calvin Yeung, Keisuke Fujii</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2403.07669">https://arxiv.org/abs/2403.07669</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2403.07669">https://arxiv.org/pdf/2403.07669</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2403.07669]] Machine Learning for Soccer Match Result Prediction(https://arxiv.org/abs/2403.07669)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability</a></li>
<li><strong>Abstract: </strong>Machine learning has become a common approach to predicting the outcomes of soccer matches, and the body of literature in this domain has grown substantially in the past decade and a half. This chapter discusses available datasets, the types of models and features, and ways of evaluating model performance in this application domain. The aim of this chapter is to give a broad overview of the current state and potential future developments in machine learning for soccer match results prediction, as a resource for those interested in conducting future studies in the area. Our main findings are that while gradient-boosted tree models such as CatBoost, applied to soccer-specific ratings such as pi-ratings, are currently the best-performing models on datasets containing only goals as the match features, there needs to be a more thorough comparison of the performance of deep learning models and Random Forest on a range of datasets with different types of features. Furthermore, new rating systems using both player- and team-level information and incorporating additional information from, e.g., spatiotemporal tracking and event data, could be investigated further. Finally, the interpretability of match result prediction models needs to be enhanced for them to be more useful for team management.</li>
</ul>

<h3>Title: Towards Model Extraction Attacks in GAN-Based Image Translation via  Domain Shift Mitigation</h3>
<ul>
<li><strong>Authors: </strong>Di Mi, Yanjun Zhang, Leo Yu Zhang, Shengshan Hu, Qi Zhong, Haizhuan Yuan, Shirui Pan</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2403.07673">https://arxiv.org/abs/2403.07673</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2403.07673">https://arxiv.org/pdf/2403.07673</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2403.07673]] Towards Model Extraction Attacks in GAN-Based Image Translation via  Domain Shift Mitigation(https://arxiv.org/abs/2403.07673)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, defense, attack, extraction</a></li>
<li><strong>Abstract: </strong>Model extraction attacks (MEAs) enable an attacker to replicate the functionality of a victim deep neural network (DNN) model by only querying its API service remotely, posing a severe threat to the security and integrity of pay-per-query DNN-based services. Although the majority of current research on MEAs has primarily concentrated on neural classifiers, there is a growing prevalence of image-to-image translation (I2IT) tasks in our everyday activities. However, techniques developed for MEA of DNN classifiers cannot be directly transferred to the case of I2IT, rendering the vulnerability of I2IT models to MEA attacks often underestimated. This paper unveils the threat of MEA in I2IT tasks from a new perspective. Diverging from the traditional approach of bridging the distribution gap between attacker queries and victim training samples, we opt to mitigate the effect caused by the different distributions, known as the domain shift. This is achieved by introducing a new regularization term that penalizes high-frequency noise, and seeking a flatter minimum to avoid overfitting to the shifted distribution. Extensive experiments on different image translation tasks, including image super-resolution and style transfer, are performed on different backbone victim models, and the new design consistently outperforms the baseline by a large margin across all metrics. A few real-life I2IT APIs are also verified to be extremely vulnerable to our attack, emphasizing the need for enhanced defenses and potentially revised API publishing policies.</li>
</ul>

<h3>Title: Genuine Knowledge from Practice: Diffusion Test-Time Adaptation for  Video Adverse Weather Removal</h3>
<ul>
<li><strong>Authors: </strong>Yijun Yang, Hongtao Wu, Angelica I. Aviles-Rivero, Yulun Zhang, Jing Qin, Lei Zhu</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2403.07684">https://arxiv.org/abs/2403.07684</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2403.07684">https://arxiv.org/pdf/2403.07684</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2403.07684]] Genuine Knowledge from Practice: Diffusion Test-Time Adaptation for  Video Adverse Weather Removal(https://arxiv.org/abs/2403.07684)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, transformer</a></li>
<li><strong>Abstract: </strong>Real-world vision tasks frequently suffer from the appearance of unexpected adverse weather conditions, including rain, haze, snow, and raindrops. In the last decade, convolutional neural networks and vision transformers have yielded outstanding results in single-weather video removal. However, due to the absence of appropriate adaptation, most of them fail to generalize to other weather conditions. Although ViWS-Net is proposed to remove adverse weather conditions in videos with a single set of pre-trained weights, it is seriously blinded by seen weather at train-time and degenerates when coming to unseen weather during test-time. In this work, we introduce test-time adaptation into adverse weather removal in videos, and propose the first framework that integrates test-time adaptation into the iterative diffusion reverse process. Specifically, we devise a diffusion-based network with a novel temporal noise model to efficiently explore frame-correlated information in degraded video clips at training stage. During inference stage, we introduce a proxy task named Diffusion Tubelet Self-Calibration to learn the primer distribution of test video stream and optimize the model by approximating the temporal noise model for online adaptation. Experimental results, on benchmark datasets, demonstrate that our Test-Time Adaptation method with Diffusion-based network(Diff-TTA) outperforms state-of-the-art methods in terms of restoring videos degraded by seen weather conditions. Its generalizable capability is also validated with unseen weather conditions in both synthesized and real-world videos.</li>
</ul>

<h3>Title: Masked AutoDecoder is Effective Multi-Task Vision Generalist</h3>
<ul>
<li><strong>Authors: </strong>Han Qiu, Jiaxing Huang, Peng Gao, Lewei Lu, Xiaoqin Zhang, Shijian Lu</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2403.07692">https://arxiv.org/abs/2403.07692</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2403.07692">https://arxiv.org/pdf/2403.07692</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2403.07692]] Masked AutoDecoder is Effective Multi-Task Vision Generalist(https://arxiv.org/abs/2403.07692)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Inspired by the success of general-purpose models in NLP, recent studies attempt to unify different vision tasks in the same sequence format and employ autoregressive Transformers for sequence prediction. They apply uni-directional attention to capture sequential dependencies and generate task sequences recursively. However, such autoregressive Transformers may not fit vision tasks well, as vision task sequences usually lack the sequential dependencies typically observed in natural languages. In this work, we design Masked AutoDecoder~(MAD), an effective multi-task vision generalist. MAD consists of two core designs. First, we develop a parallel decoding framework that introduces bi-directional attention to capture contextual dependencies comprehensively and decode vision task sequences in parallel. Second, we design a masked sequence modeling approach that learns rich task contexts by masking and reconstructing task sequences. In this way, MAD handles all the tasks by a single network branch and a simple cross-entropy loss with minimal task-specific designs. Extensive experiments demonstrate the great potential of MAD as a new paradigm for unifying various vision tasks. MAD achieves superior performance and inference efficiency compared to autoregressive counterparts while obtaining competitive accuracy with task-specific models. Code will be released.</li>
</ul>

<h3>Title: Large, Small or Both: A Novel Data Augmentation Framework Based on  Language Models for Debiasing Opinion Summarization</h3>
<ul>
<li><strong>Authors: </strong>Yanyue Zhang, Pengfei Li, Yilong Lai, Deyu Zhou</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2403.07693">https://arxiv.org/abs/2403.07693</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2403.07693">https://arxiv.org/pdf/2403.07693</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2403.07693]] Large, Small or Both: A Novel Data Augmentation Framework Based on  Language Models for Debiasing Opinion Summarization(https://arxiv.org/abs/2403.07693)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>As more than 70$\%$ of reviews in the existing opinion summary data set are positive, current opinion summarization approaches are reluctant to generate negative summaries given the input of negative texts. To address such sentiment bias, a direct approach without the over-reliance on a specific framework is to generate additional data based on large language models to balance the emotional distribution of the dataset. However, data augmentation based on large language models faces two disadvantages: 1) the potential issues or toxicity in the augmented data; 2) the expensive costs. Therefore, in this paper, we propose a novel data augmentation framework based on both large and small language models for debiasing opinion summarization. In specific, a small size of synthesized negative reviews is obtained by rewriting the positive text via a large language model. Then, a disentangle reconstruction model is trained based on the generated data. After training, a large amount of synthetic data can be obtained by decoding the new representation obtained from the combination of different sample representations and filtering based on confusion degree and sentiment classification. Experiments have proved that our framework can effectively alleviate emotional bias same as using only large models, but more economically.</li>
</ul>

<h3>Title: CuVLER: Enhanced Unsupervised Object Discoveries through Exhaustive  Self-Supervised Transformers</h3>
<ul>
<li><strong>Authors: </strong>Shahaf Arica, Or Rubin, Sapir Gershov, Shlomi Laufer</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2403.07700">https://arxiv.org/abs/2403.07700</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2403.07700">https://arxiv.org/pdf/2403.07700</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2403.07700]] CuVLER: Enhanced Unsupervised Object Discoveries through Exhaustive  Self-Supervised Transformers(https://arxiv.org/abs/2403.07700)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, transformer, segmentation</a></li>
<li><strong>Abstract: </strong>In this paper, we introduce VoteCut, an innovative method for unsupervised object discovery that leverages feature representations from multiple self-supervised models. VoteCut employs normalized-cut based graph partitioning, clustering and a pixel voting approach. Additionally, We present CuVLER (Cut-Vote-and-LEaRn), a zero-shot model, trained using pseudo-labels, generated by VoteCut, and a novel soft target loss to refine segmentation accuracy. Through rigorous evaluations across multiple datasets and several unsupervised setups, our methods demonstrate significant improvements in comparison to previous state-of-the-art models. Our ablation studies further highlight the contributions of each component, revealing the robustness and efficacy of our approach. Collectively, VoteCut and CuVLER pave the way for future advancements in image segmentation.</li>
</ul>

<h3>Title: Robust Synthetic-to-Real Transfer for Stereo Matching</h3>
<ul>
<li><strong>Authors: </strong>Jiawei Zhang, Jiahe Li, Lei Huang, Xiaohan Yu, Lin Gu, Jin Zheng, Xiao Bai</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2403.07705">https://arxiv.org/abs/2403.07705</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2403.07705">https://arxiv.org/pdf/2403.07705</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2403.07705]] Robust Synthetic-to-Real Transfer for Stereo Matching(https://arxiv.org/abs/2403.07705)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>With advancements in domain generalized stereo matching networks, models pre-trained on synthetic data demonstrate strong robustness to unseen domains. However, few studies have investigated the robustness after fine-tuning them in real-world scenarios, during which the domain generalization ability can be seriously degraded. In this paper, we explore fine-tuning stereo matching networks without compromising their robustness to unseen domains. Our motivation stems from comparing Ground Truth (GT) versus Pseudo Label (PL) for fine-tuning: GT degrades, but PL preserves the domain generalization ability. Empirically, we find the difference between GT and PL implies valuable information that can regularize networks during fine-tuning. We also propose a framework to utilize this difference for fine-tuning, consisting of a frozen Teacher, an exponential moving average (EMA) Teacher, and a Student network. The core idea is to utilize the EMA Teacher to measure what the Student has learned and dynamically improve GT and PL for fine-tuning. We integrate our framework with state-of-the-art networks and evaluate its effectiveness on several real-world datasets. Extensive experiments show that our method effectively preserves the domain generalization ability during fine-tuning.</li>
</ul>

<h3>Title: Fast and Simple Explainability for Point Cloud Networks</h3>
<ul>
<li><strong>Authors: </strong>Meir Yossef Levi, Guy Gilboa</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2403.07706">https://arxiv.org/abs/2403.07706</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2403.07706">https://arxiv.org/pdf/2403.07706</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2403.07706]] Fast and Simple Explainability for Point Cloud Networks(https://arxiv.org/abs/2403.07706)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, interpretability, explainability</a></li>
<li><strong>Abstract: </strong>We propose a fast and simple explainable AI (XAI) method for point cloud data. It computes pointwise importance with respect to a trained network downstream task. This allows better understanding of the network properties, which is imperative for safety-critical applications. In addition to debugging and visualization, our low computational complexity facilitates online feedback to the network at inference. This can be used to reduce uncertainty and to increase robustness. In this work, we introduce \emph{Feature Based Interpretability} (FBI), where we compute the features' norm, per point, before the bottleneck. We analyze the use of gradients and post- and pre-bottleneck strategies, showing pre-bottleneck is preferred, in terms of smoothness and ranking. We obtain at least three orders of magnitude speedup, compared to current XAI methods, thus, scalable for big point clouds or large-scale architectures. Our approach achieves SOTA results, in terms of classification explainability. We demonstrate how the proposed measure is helpful in analyzing and characterizing various aspects of 3D learning, such as rotation invariance, robustness to out-of-distribution (OOD) outliers or domain shift and dataset bias.</li>
</ul>

<h3>Title: Improving Reinforcement Learning from Human Feedback Using Contrastive  Rewards</h3>
<ul>
<li><strong>Authors: </strong>Wei Shen, Xiaoying Zhang, Yuanshun Yao, Rui Zheng, Hongyi Guo, Yang Liu</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2403.07708">https://arxiv.org/abs/2403.07708</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2403.07708">https://arxiv.org/pdf/2403.07708</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2403.07708]] Improving Reinforcement Learning from Human Feedback Using Contrastive  Rewards(https://arxiv.org/abs/2403.07708)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, large language model</a></li>
<li><strong>Abstract: </strong>Reinforcement learning from human feedback (RLHF) is the mainstream paradigm used to align large language models (LLMs) with human preferences. Yet existing RLHF heavily relies on accurate and informative reward models, which are vulnerable and sensitive to noise from various sources, e.g. human labeling errors, making the pipeline fragile. In this work, we improve the effectiveness of the reward model by introducing a penalty term on the reward, named as \textit{contrastive rewards}. %Contrastive rewards Our approach involves two steps: (1) an offline sampling step to obtain responses to prompts that serve as baseline calculation and (2) a contrastive reward calculated using the baseline responses and used in the Proximal Policy Optimization (PPO) step. We show that contrastive rewards enable the LLM to penalize reward uncertainty, improve robustness, encourage improvement over baselines, calibrate according to task difficulty, and reduce variance in PPO. We show empirically contrastive rewards can improve RLHF substantially, evaluated by both GPTs and humans, and our method consistently outperforms strong baselines.</li>
</ul>

<h3>Title: SSM Meets Video Diffusion Models: Efficient Video Generation with  Structured State Spaces</h3>
<ul>
<li><strong>Authors: </strong>Yuta Oshima, Shohei Taniguchi, Masahiro Suzuki, Yutaka Matsuo</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2403.07711">https://arxiv.org/abs/2403.07711</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2403.07711">https://arxiv.org/pdf/2403.07711</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2403.07711]] SSM Meets Video Diffusion Models: Efficient Video Generation with  Structured State Spaces(https://arxiv.org/abs/2403.07711)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>Given the remarkable achievements in image generation through diffusion models, the research community has shown increasing interest in extending these models to video generation. Recent diffusion models for video generation have predominantly utilized attention layers to extract temporal features. However, attention layers are limited by their memory consumption, which increases quadratically with the length of the sequence. This limitation presents significant challenges when attempting to generate longer video sequences using diffusion models. To overcome this challenge, we propose leveraging state-space models (SSMs). SSMs have recently gained attention as viable alternatives due to their linear memory consumption relative to sequence length. In the experiments, we first evaluate our SSM-based model with UCF101, a standard benchmark of video generation. In addition, to investigate the potential of SSMs for longer video generation, we perform an experiment using the MineRL Navigate dataset, varying the number of frames to 64 and 150. In these settings, our SSM-based model can considerably save memory consumption for longer sequences, while maintaining competitive FVD scores to the attention-based models. Our codes are available at https://github.com/shim0114/SSM-Meets-Video-Diffusion-Models.</li>
</ul>

<h3>Title: StableToolBench: Towards Stable Large-Scale Benchmarking on Tool  Learning of Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Zhicheng Guo, Sijie Cheng, Hao Wang, Shihao Liang, Yujia Qin, Peng Li, Zhiyuan Liu, Maosong Sun, Yang Liu</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2403.07714">https://arxiv.org/abs/2403.07714</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2403.07714">https://arxiv.org/pdf/2403.07714</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2403.07714]] StableToolBench: Towards Stable Large-Scale Benchmarking on Tool  Learning of Large Language Models(https://arxiv.org/abs/2403.07714)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large Language Models (LLMs) have witnessed remarkable advancements in recent years, prompting the exploration of tool learning, which integrates LLMs with external tools to address diverse real-world challenges. Assessing the capability of LLMs to utilise tools necessitates large-scale and stable benchmarks. However, previous works relied on either hand-crafted online tools with limited scale, or large-scale real online APIs suffering from instability of API status. To address this problem, we introduce StableToolBench, a benchmark evolving from ToolBench, proposing a virtual API server and stable evaluation system. The virtual API server contains a caching system and API simulators which are complementary to alleviate the change in API status. Meanwhile, the stable evaluation system designs solvable pass and win rates using GPT-4 as the automatic evaluator to eliminate the randomness during evaluation. Experimental results demonstrate the stability of StableToolBench, and further discuss the effectiveness of API simulators, the caching system, and the evaluator system.</li>
</ul>

<h3>Title: WorkArena: How Capable Are Web Agents at Solving Common Knowledge Work  Tasks?</h3>
<ul>
<li><strong>Authors: </strong>Alexandre Drouin, Maxime Gasse, Massimo Caccia, Issam H. Laradji, Manuel Del Verme, Tom Marty, LÃ©o Boisvert, Megh Thakkar, Quentin Cappart, David Vazquez, Nicolas Chapados, Alexandre Lacoste</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2403.07718">https://arxiv.org/abs/2403.07718</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2403.07718">https://arxiv.org/pdf/2403.07718</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2403.07718]] WorkArena: How Capable Are Web Agents at Solving Common Knowledge Work  Tasks?(https://arxiv.org/abs/2403.07718)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>We study the use of large language model-based agents for interacting with software via web browsers. Unlike prior work, we focus on measuring the agents' ability to perform tasks that span the typical daily work of knowledge workers utilizing enterprise software systems. To this end, we propose WorkArena, a remote-hosted benchmark of 29 tasks based on the widely-used ServiceNow platform. We also introduce BrowserGym, an environment for the design and evaluation of such agents, offering a rich set of actions as well as multimodal observations. Our empirical evaluation reveals that while current agents show promise on WorkArena, there remains a considerable gap towards achieving full task automation. Notably, our analysis uncovers a significant performance disparity between open and closed-source LLMs, highlighting a critical area for future exploration and development in the field.</li>
</ul>

<h3>Title: Multi-modal Auto-regressive Modeling via Visual Words</h3>
<ul>
<li><strong>Authors: </strong>Tianshuo Peng, Zuchao Li, Lefei Zhang, Hai Zhao, Ping Wang, Bo Du</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2403.07720">https://arxiv.org/abs/2403.07720</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2403.07720">https://arxiv.org/pdf/2403.07720</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2403.07720]] Multi-modal Auto-regressive Modeling via Visual Words(https://arxiv.org/abs/2403.07720)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large Language Models (LLMs), benefiting from the auto-regressive modelling approach performed on massive unannotated texts corpora, demonstrates powerful perceptual and reasoning capabilities. However, as for extending auto-regressive modelling to multi-modal scenarios to build Large Multi-modal Models (LMMs), there lies a great difficulty that the image information is processed in the LMM as continuous visual embeddings, which cannot obtain discrete supervised labels for classification. In this paper, we successfully perform multi-modal auto-regressive modeling with a unified objective for the first time. Specifically, we propose the concept of visual words, which maps the visual features to probability distributions over LLM's vocabulary, providing supervision information for visual modelling. We further explore the distribution of visual features in the semantic space within LMM and the possibility of using text embeddings to represent visual information. Experimental results and ablation studies on 5 VQA tasks and 4 benchmark toolkits validate the powerful performance of our proposed approach.</li>
</ul>

<h3>Title: Balancing Fairness and Accuracy in Data-Restricted Binary Classification</h3>
<ul>
<li><strong>Authors: </strong>Zachary McBride Lazri, Danial Dervovic, Antigoni Polychroniadou, Ivan Brugere, Dana Dachman-Soled, Min Wu</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CY, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2403.07724">https://arxiv.org/abs/2403.07724</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2403.07724">https://arxiv.org/pdf/2403.07724</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2403.07724]] Balancing Fairness and Accuracy in Data-Restricted Binary Classification(https://arxiv.org/abs/2403.07724)</code><input type="text"></li>
<li><strong>Keywords: </strong>fair</a></li>
<li><strong>Abstract: </strong>Applications that deal with sensitive information may have restrictions placed on the data available to a machine learning (ML) classifier. For example, in some applications, a classifier may not have direct access to sensitive attributes, affecting its ability to produce accurate and fair decisions. This paper proposes a framework that models the trade-off between accuracy and fairness under four practical scenarios that dictate the type of data available for analysis. Prior works examine this trade-off by analyzing the outputs of a scoring function that has been trained to implicitly learn the underlying distribution of the feature vector, class label, and sensitive attribute of a dataset. In contrast, our framework directly analyzes the behavior of the optimal Bayesian classifier on this underlying distribution by constructing a discrete approximation it from the dataset itself. This approach enables us to formulate multiple convex optimization problems, which allow us to answer the question: How is the accuracy of a Bayesian classifier affected in different data restricting scenarios when constrained to be fair? Analysis is performed on a set of fairness definitions that include group and individual fairness. Experiments on three datasets demonstrate the utility of the proposed framework as a tool for quantifying the trade-offs among different fairness notions and their distributional dependencies.</li>
</ul>

<h3>Title: DSEG-LIME -- Improving Image Explanation by Hierarchical Data-Driven  Segmentation</h3>
<ul>
<li><strong>Authors: </strong>Patrick Knab, Sascha Marton, Christian Bartelt</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2403.07733">https://arxiv.org/abs/2403.07733</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2403.07733">https://arxiv.org/pdf/2403.07733</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2403.07733]] DSEG-LIME -- Improving Image Explanation by Hierarchical Data-Driven  Segmentation(https://arxiv.org/abs/2403.07733)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability, segmentation</a></li>
<li><strong>Abstract: </strong>Explainable Artificial Intelligence is critical in unraveling decision-making processes in complex machine learning models. LIME (Local Interpretable Model-agnostic Explanations) is a well-known XAI framework for image analysis. It utilizes image segmentation to create features to identify relevant areas for classification. Consequently, poor segmentation can compromise the consistency of the explanation and undermine the importance of the segments, affecting the overall interpretability. Addressing these challenges, we introduce DSEG-LIME (Data-Driven Segmentation LIME), featuring: i) a data-driven segmentation for human-recognized feature generation, and ii) a hierarchical segmentation procedure through composition. We benchmark DSEG-LIME on pre-trained models with images from the ImageNet dataset - scenarios without domain-specific knowledge. The analysis includes a quantitative evaluation using established XAI metrics, complemented by a qualitative assessment through a user study. Our findings demonstrate that DSEG outperforms in most of the XAI metrics and enhances the alignment of explanations with human-recognized concepts, significantly improving interpretability. The code is available under: https://github. com/patrick-knab/DSEG-LIME</li>
</ul>

<h3>Title: Uncertainty Quantification with Deep Ensembles for 6D Object Pose  Estimation</h3>
<ul>
<li><strong>Authors: </strong>Kira Wursthorn, Markus Hillemann, Markus Ulrich</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2403.07741">https://arxiv.org/abs/2403.07741</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2403.07741">https://arxiv.org/pdf/2403.07741</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2403.07741]] Uncertainty Quantification with Deep Ensembles for 6D Object Pose  Estimation(https://arxiv.org/abs/2403.07741)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>The estimation of 6D object poses is a fundamental task in many computer vision applications. Particularly, in high risk scenarios such as human-robot interaction, industrial inspection, and automation, reliable pose estimates are crucial. In the last years, increasingly accurate and robust deep-learning-based approaches for 6D object pose estimation have been proposed. Many top-performing methods are not end-to-end trainable but consist of multiple stages. In the context of deep uncertainty quantification, deep ensembles are considered as state of the art since they have been proven to produce well-calibrated and robust uncertainty estimates. However, deep ensembles can only be applied to methods that can be trained end-to-end. In this work, we propose a method to quantify the uncertainty of multi-stage 6D object pose estimation approaches with deep ensembles. For the implementation, we choose SurfEmb as representative, since it is one of the top-performing 6D object pose estimation approaches in the BOP Challenge 2022. We apply established metrics and concepts for deep uncertainty quantification to evaluate the results. Furthermore, we propose a novel uncertainty calibration score for regression tasks to quantify the quality of the estimated uncertainty.</li>
</ul>

<h3>Title: Unleashing HyDRa: Hybrid Fusion, Depth Consistency and Radar for Unified  3D Perception</h3>
<ul>
<li><strong>Authors: </strong>Philipp Wolters, Johannes Gilg, Torben Teepe, Fabian Herzog, Anouar Laouichi, Martin Hofmann, Gerhard Rigoll</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2403.07746">https://arxiv.org/abs/2403.07746</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2403.07746">https://arxiv.org/pdf/2403.07746</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2403.07746]] Unleashing HyDRa: Hybrid Fusion, Depth Consistency and Radar for Unified  3D Perception(https://arxiv.org/abs/2403.07746)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, transformer</a></li>
<li><strong>Abstract: </strong>Low-cost, vision-centric 3D perception systems for autonomous driving have made significant progress in recent years, narrowing the gap to expensive LiDAR-based methods. The primary challenge in becoming a fully reliable alternative lies in robust depth prediction capabilities, as camera-based systems struggle with long detection ranges and adverse lighting and weather conditions. In this work, we introduce HyDRa, a novel camera-radar fusion architecture for diverse 3D perception tasks. Building upon the principles of dense BEV (Bird's Eye View)-based architectures, HyDRa introduces a hybrid fusion approach to combine the strengths of complementary camera and radar features in two distinct representation spaces. Our Height Association Transformer module leverages radar features already in the perspective view to produce more robust and accurate depth predictions. In the BEV, we refine the initial sparse representation by a Radar-weighted Depth Consistency. HyDRa achieves a new state-of-the-art for camera-radar fusion of 64.2 NDS (+1.8) and 58.4 AMOTA (+1.5) on the public nuScenes dataset. Moreover, our new semantically rich and spatially accurate BEV features can be directly converted into a powerful occupancy representation, beating all previous camera-based methods on the Occ3D benchmark by an impressive 3.7 mIoU.</li>
</ul>

<h3>Title: FineMath: A Fine-Grained Mathematical Evaluation Benchmark for Chinese  Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Yan Liu, Renren Jin, Lin Shi, Zheng Yao, Deyi Xiong</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2403.07747">https://arxiv.org/abs/2403.07747</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2403.07747">https://arxiv.org/pdf/2403.07747</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2403.07747]] FineMath: A Fine-Grained Mathematical Evaluation Benchmark for Chinese  Large Language Models(https://arxiv.org/abs/2403.07747)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>To thoroughly assess the mathematical reasoning abilities of Large Language Models (LLMs), we need to carefully curate evaluation datasets covering diverse mathematical concepts and mathematical problems at different difficulty levels. In pursuit of this objective, we propose FineMath in this paper, a fine-grained mathematical evaluation benchmark dataset for assessing Chinese LLMs. FineMath is created to cover the major key mathematical concepts taught in elementary school math, which are further divided into 17 categories of math word problems, enabling in-depth analysis of mathematical reasoning abilities of LLMs. All the 17 categories of math word problems are manually annotated with their difficulty levels according to the number of reasoning steps required to solve these problems. We conduct extensive experiments on a wide range of LLMs on FineMath and find that there is still considerable room for improvements in terms of mathematical reasoning capability of Chinese LLMs. We also carry out an in-depth analysis on the evaluation process and methods that have been overlooked previously. These two factors significantly influence the model results and our understanding of their mathematical reasoning capabilities. The dataset will be publicly available soon.</li>
</ul>

<h3>Title: Synth$^2$: Boosting Visual-Language Models with Synthetic Captions and  Image Embeddings</h3>
<ul>
<li><strong>Authors: </strong>Sahand Sharifzadeh, Christos Kaplanis, Shreya Pathak, Dharshan Kumaran, Anastasija Ilic, Jovana Mitrovic, Charles Blundell, Andrea Banino</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2403.07750">https://arxiv.org/abs/2403.07750</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2403.07750">https://arxiv.org/pdf/2403.07750</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2403.07750]] Synth$^2$: Boosting Visual-Language Models with Synthetic Captions and  Image Embeddings(https://arxiv.org/abs/2403.07750)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>The creation of high-quality human-labeled image-caption datasets presents a significant bottleneck in the development of Visual-Language Models (VLMs). We propose a novel approach that leverages the strengths of Large Language Models (LLMs) and image generation models to create synthetic image-text pairs for efficient and effective VLM training. Our method employs pretraining a text-to-image model to synthesize image embeddings starting from captions generated by an LLM. These synthetic pairs are then used to train a VLM. Extensive experiments demonstrate that the VLM trained with synthetic data exhibits comparable performance on image captioning, while requiring a fraction of the data used by models trained solely on human-annotated data. In particular, we outperform the baseline by 17% through augmentation with a synthetic dataset. Furthermore, we show that synthesizing in the image embedding space is 25% faster than in the pixel space. This research introduces a promising technique for generating large-scale, customizable image datasets, leading to enhanced VLM performance and wider applicability across various domains, all with improved data efficiency and resource utilization.</li>
</ul>

<h3>Title: Stable-Makeup: When Real-World Makeup Transfer Meets Diffusion Model</h3>
<ul>
<li><strong>Authors: </strong>Yuxuan Zhang, Lifu Wei, Qing Zhang, Yiren Song, Jiaming Liu, Huaxia Li, Xu Tang, Yao Hu, Haibo Zhao</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2403.07764">https://arxiv.org/abs/2403.07764</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2403.07764">https://arxiv.org/pdf/2403.07764</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2403.07764]] Stable-Makeup: When Real-World Makeup Transfer Meets Diffusion Model(https://arxiv.org/abs/2403.07764)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, diffusion</a></li>
<li><strong>Abstract: </strong>Current makeup transfer methods are limited to simple makeup styles, making them difficult to apply in real-world scenarios. In this paper, we introduce Stable-Makeup, a novel diffusion-based makeup transfer method capable of robustly transferring a wide range of real-world makeup, onto user-provided faces. Stable-Makeup is based on a pre-trained diffusion model and utilizes a Detail-Preserving (D-P) makeup encoder to encode makeup details. It also employs content and structural control modules to preserve the content and structural information of the source image. With the aid of our newly added makeup cross-attention layers in U-Net, we can accurately transfer the detailed makeup to the corresponding position in the source image. After content-structure decoupling training, Stable-Makeup can maintain content and the facial structure of the source image. Moreover, our method has demonstrated strong robustness and generalizability, making it applicable to varioustasks such as cross-domain makeup transfer, makeup-guided text-to-image generation and so on. Extensive experiments have demonstrated that our approach delivers state-of-the-art (SOTA) results among existing makeup transfer methods and exhibits a highly promising with broad potential applications in various related fields.</li>
</ul>

<h3>Title: SemCity: Semantic Scene Generation with Triplane Diffusion</h3>
<ul>
<li><strong>Authors: </strong>Jumin Lee, Sebin Lee, Changho Jo, Woobin Im, Juhyeong Seon, Sung-Eui Yoon</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2403.07773">https://arxiv.org/abs/2403.07773</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2403.07773">https://arxiv.org/pdf/2403.07773</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2403.07773]] SemCity: Semantic Scene Generation with Triplane Diffusion(https://arxiv.org/abs/2403.07773)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>We present "SemCity," a 3D diffusion model for semantic scene generation in real-world outdoor environments. Most 3D diffusion models focus on generating a single object, synthetic indoor scenes, or synthetic outdoor scenes, while the generation of real-world outdoor scenes is rarely addressed. In this paper, we concentrate on generating a real-outdoor scene through learning a diffusion model on a real-world outdoor dataset. In contrast to synthetic data, real-outdoor datasets often contain more empty spaces due to sensor limitations, causing challenges in learning real-outdoor distributions. To address this issue, we exploit a triplane representation as a proxy form of scene distributions to be learned by our diffusion model. Furthermore, we propose a triplane manipulation that integrates seamlessly with our triplane diffusion model. The manipulation improves our diffusion model's applicability in a variety of downstream tasks related to outdoor scene generation such as scene inpainting, scene outpainting, and semantic scene completion refinements. In experimental results, we demonstrate that our triplane diffusion model shows meaningful generation results compared with existing work in a real-outdoor dataset, SemanticKITTI. We also show our triplane manipulation facilitates seamlessly adding, removing, or modifying objects within a scene. Further, it also enables the expansion of scenes toward a city-level scale. Finally, we evaluate our method on semantic scene completion refinements where our diffusion model enhances predictions of semantic scene completion networks by learning scene distribution. Our code is available at https://github.com/zoomin-lee/SemCity.</li>
</ul>

<h3>Title: Fine-tuning Large Language Models with Sequential Instructions</h3>
<ul>
<li><strong>Authors: </strong>Hanxu Hu, Pinzhen Chen, Edoardo M. Ponti</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2403.07794">https://arxiv.org/abs/2403.07794</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2403.07794">https://arxiv.org/pdf/2403.07794</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2403.07794]] Fine-tuning Large Language Models with Sequential Instructions(https://arxiv.org/abs/2403.07794)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large language models (LLMs) struggle to follow a sequence of instructions in a single query as they may ignore or misinterpret part of it. This impairs their performance in complex problems whose solution requires multiple intermediate steps, such as multilingual (translate then answer) and multimodal (caption then answer) tasks. We empirically verify this with open-source LLMs as large as LLaMA-2 70B and Mixtral-8x7B. Targeting the scarcity of sequential instructions in present-day data, we propose sequential instruction tuning, a simple yet effective strategy to automatically augment instruction tuning data and equip LLMs with the ability to execute multiple sequential instructions. After exploring interleaving instructions in existing datasets, such as Alpaca, with a wide range of intermediate tasks, we find that sequential instruction-tuned models consistently outperform the conventional instruction-tuned baselines in downstream tasks involving reasoning, multilingual, and multimodal abilities. To shed further light on our technique, we analyse how adversarial intermediate texts, unseen tasks, prompt verbalization, number of tasks, and prompt length affect SIT. We hope that this method will open new research avenues on instruction tuning for complex tasks.</li>
</ul>

<h3>Title: Beyond Memorization: The Challenge of Random Memory Access in Language  Models</h3>
<ul>
<li><strong>Authors: </strong>Tongyao Zhu, Qian Liu, Liang Pang, Zhengbao Jiang, Min-Yen Kan, Min Lin</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2403.07805">https://arxiv.org/abs/2403.07805</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2403.07805">https://arxiv.org/pdf/2403.07805</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2403.07805]] Beyond Memorization: The Challenge of Random Memory Access in Language  Models(https://arxiv.org/abs/2403.07805)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>Recent developments in Language Models (LMs) have shown their effectiveness in NLP tasks, particularly in knowledge-intensive tasks. However, the mechanisms underlying knowledge storage and memory access within their parameters remain elusive. In this paper, we investigate whether a generative LM (e.g., GPT-2) is able to access its memory sequentially or randomly. Through carefully-designed synthetic tasks, covering the scenarios of full recitation, selective recitation and grounded question answering, we reveal that LMs manage to sequentially access their memory while encountering challenges in randomly accessing memorized content. We find that techniques including recitation and permutation improve the random memory access capability of LMs. Furthermore, by applying this intervention to realistic scenarios of open-domain question answering, we validate that enhancing random access by recitation leads to notable improvements in question answering. The code to reproduce our experiments can be found at https://github. com/sail-sg/lm-random-memory-access.</li>
</ul>

<h3>Title: pyvene: A Library for Understanding and Improving PyTorch Models via  Interventions</h3>
<ul>
<li><strong>Authors: </strong>Zhengxuan Wu, Atticus Geiger, Aryaman Arora, Jing Huang, Zheng Wang, Noah D. Goodman, Christopher D. Manning, Christopher Potts</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2403.07809">https://arxiv.org/abs/2403.07809</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2403.07809">https://arxiv.org/pdf/2403.07809</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2403.07809]] pyvene: A Library for Understanding and Improving PyTorch Models via  Interventions(https://arxiv.org/abs/2403.07809)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, interpretability</a></li>
<li><strong>Abstract: </strong>Interventions on model-internal states are fundamental operations in many areas of AI, including model editing, steering, robustness, and interpretability. To facilitate such research, we introduce $\textbf{pyvene}$, an open-source Python library that supports customizable interventions on a range of different PyTorch modules. $\textbf{pyvene}$ supports complex intervention schemes with an intuitive configuration format, and its interventions can be static or include trainable parameters. We show how $\textbf{pyvene}$ provides a unified and extensible framework for performing interventions on neural models and sharing the intervened upon models with others. We illustrate the power of the library via interpretability analyses using causal abstraction and knowledge localization. We publish our library through Python Package Index (PyPI) and provide code, documentation, and tutorials at https://github.com/stanfordnlp/pyvene.</li>
</ul>

<h3>Title: Chronos: Learning the Language of Time Series</h3>
<ul>
<li><strong>Authors: </strong>Abdul Fatir Ansari, Lorenzo Stella, Caner Turkmen, Xiyuan Zhang, Pedro Mercado, Huibin Shen, Oleksandr Shchur, Syama Sundar Rangapuram, Sebastian Pineda Arango, Shubham Kapoor, Jasper Zschiegner, Danielle C. Maddix, Michael W. Mahoney, Kari Torkkola, Andrew Gordon Wilson, Michael Bohlke-Schneider, Yuyang Wang</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2403.07815">https://arxiv.org/abs/2403.07815</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2403.07815">https://arxiv.org/pdf/2403.07815</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2403.07815]] Chronos: Learning the Language of Time Series(https://arxiv.org/abs/2403.07815)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>We introduce Chronos, a simple yet effective framework for pretrained probabilistic time series models. Chronos tokenizes time series values using scaling and quantization into a fixed vocabulary and trains existing transformer-based language model architectures on these tokenized time series via the cross-entropy loss. We pretrained Chronos models based on the T5 family (ranging from 20M to 710M parameters) on a large collection of publicly available datasets, complemented by a synthetic dataset that we generated via Gaussian processes to improve generalization. In a comprehensive benchmark consisting of 42 datasets, and comprising both classical local models and deep learning methods, we show that Chronos models: (a) significantly outperform other methods on datasets that were part of the training corpus; and (b) have comparable and occasionally superior zero-shot performance on new datasets, relative to methods that were trained specifically on them. Our results demonstrate that Chronos models can leverage time series data from diverse domains to improve zero-shot accuracy on unseen forecasting tasks, positioning pretrained models as a viable tool to greatly simplify forecasting pipelines.</li>
</ul>

<h3>Title: Branch-Train-MiX: Mixing Expert LLMs into a Mixture-of-Experts LLM</h3>
<ul>
<li><strong>Authors: </strong>Sainbayar Sukhbaatar, Olga Golovneva, Vasu Sharma, Hu Xu, Xi Victoria Lin, Baptiste RoziÃ¨re, Jacob Kahn, Daniel Li, Wen-tau Yih, Jason Weston, Xian Li</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2403.07816">https://arxiv.org/abs/2403.07816</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2403.07816">https://arxiv.org/pdf/2403.07816</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2403.07816]] Branch-Train-MiX: Mixing Expert LLMs into a Mixture-of-Experts LLM(https://arxiv.org/abs/2403.07816)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>We investigate efficient methods for training Large Language Models (LLMs) to possess capabilities in multiple specialized domains, such as coding, math reasoning and world knowledge. Our method, named Branch-Train-MiX (BTX), starts from a seed model, which is branched to train experts in embarrassingly parallel fashion with high throughput and reduced communication cost. After individual experts are asynchronously trained, BTX brings together their feedforward parameters as experts in Mixture-of-Expert (MoE) layers and averages the remaining parameters, followed by an MoE-finetuning stage to learn token-level routing. BTX generalizes two special cases, the Branch-Train-Merge method, which does not have the MoE finetuning stage to learn routing, and sparse upcycling, which omits the stage of training experts asynchronously. Compared to alternative approaches, BTX achieves the best accuracy-efficiency tradeoff.</li>
</ul>

<h3>Title: UniHand: Privacy-preserving Universal Handover for Small-Cell Networks  in 5G-enabled Mobile Communication with KCI Resilience</h3>
<ul>
<li><strong>Authors: </strong>Rabiah Alnashwan, Prosanta Gope, Benjamin Dowling</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2403.07817">https://arxiv.org/abs/2403.07817</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2403.07817">https://arxiv.org/pdf/2403.07817</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2403.07817]] UniHand: Privacy-preserving Universal Handover for Small-Cell Networks  in 5G-enabled Mobile Communication with KCI Resilience(https://arxiv.org/abs/2403.07817)</code><input type="text"></li>
<li><strong>Keywords: </strong>secure, security, privacy, attack</a></li>
<li><strong>Abstract: </strong>Introducing Small Cell Networks (SCN) has significantly improved wireless link quality, spectrum efficiency and network capacity, which has been viewed as one of the key technologies in the fifth-generation (5G) mobile network. However, this technology increases the frequency of handover (HO) procedures caused by the dense deployment of cells in the network with reduced cell coverage, bringing new security and privacy issues. The current 5G-AKA and HO protocols are vulnerable to security weaknesses, such as the lack of forward secrecy and identity confusion attacks. The high HO frequency of HOs might magnify these security and privacy concerns in the 5G mobile network. This work addresses these issues by proposing a secure privacy-preserving universal HO scheme ($\UniHand$) for SCNs in 5G mobile communication. $\UniHand$ can achieve mutual authentication, strong anonymity, perfect forward secrecy, key-escrow-free and key compromise impersonation (KCI) resilience. To the best of our knowledge, this is the \textit{first} scheme to achieve secure, privacy-preserving universal HO with \textit{KCI} resilience for roaming users in 5G environment. We demonstrate that our proposed scheme is resilient against all the essential security threats by performing a comprehensive formal security analysis and conducting relevant experiments to show the cost-effectiveness of the proposed scheme.</li>
</ul>

<h3>Title: Label Dropout: Improved Deep Learning Echocardiography Segmentation  Using Multiple Datasets With Domain Shift and Partial Labelling</h3>
<ul>
<li><strong>Authors: </strong>Iman Islam (1), Esther Puyol-AntÃ³n (1), Bram Ruijsink (1), Andrew J. Reader (1), Andrew P. King (1) ((1) King's College London)</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2403.07818">https://arxiv.org/abs/2403.07818</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2403.07818">https://arxiv.org/pdf/2403.07818</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2403.07818]] Label Dropout: Improved Deep Learning Echocardiography Segmentation  Using Multiple Datasets With Domain Shift and Partial Labelling(https://arxiv.org/abs/2403.07818)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, segmentation</a></li>
<li><strong>Abstract: </strong>Echocardiography (echo) is the first imaging modality used when assessing cardiac function. The measurement of functional biomarkers from echo relies upon the segmentation of cardiac structures and deep learning models have been proposed to automate the segmentation process. However, in order to translate these tools to widespread clinical use it is important that the segmentation models are robust to a wide variety of images (e.g. acquired from different scanners, by operators with different levels of expertise etc.). To achieve this level of robustness it is necessary that the models are trained with multiple diverse datasets. A significant challenge faced when training with multiple diverse datasets is the variation in label presence, i.e. the combined data are often partially-labelled. Adaptations of the cross entropy loss function have been proposed to deal with partially labelled data. In this paper we show that training naively with such a loss function and multiple diverse datasets can lead to a form of shortcut learning, where the model associates label presence with domain characteristics, leading to a drop in performance. To address this problem, we propose a novel label dropout scheme to break the link between domain characteristics and the presence or absence of labels. We demonstrate that label dropout improves echo segmentation Dice score by 62% and 25% on two cardiac structures when training using multiple diverse partially labelled datasets.</li>
</ul>

<h3>Title: The Variant of Designated Verifier Signature Scheme with Message  Recovery</h3>
<ul>
<li><strong>Authors: </strong>Hong-Sheng Huang, Yu-Lei Fu, Han-Yu Lin</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2403.07820">https://arxiv.org/abs/2403.07820</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2403.07820">https://arxiv.org/pdf/2403.07820</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2403.07820]] The Variant of Designated Verifier Signature Scheme with Message  Recovery(https://arxiv.org/abs/2403.07820)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy</a></li>
<li><strong>Abstract: </strong>In this work, we introduce a strong Designated Verifier Signature (DVS) scheme that incorporates a message recovery mechanism inspired by the concept of the Universal Designated Verifier Signature (UDVS) scheme. It is worth noting that Saeednia's strong designated verifier signature scheme fails to guarantee the privacy of the signature, making it unsuitable for certain applications such as medical record certificates or voting systems. To overcome this limitation, we extend Lee's strong designated verifier signature with a message recovery scheme to develop a universal designated verifier signature scheme. This universal designated verifier scheme is crafted to safeguard the privacy of signature holders, ensuring that only designated verifiers can authenticate the true signer and recover the messages.</li>
</ul>

<h3>Title: The Missing Piece in Model Editing: A Deep Dive into the Hidden Damage  Brought By Model Editing</h3>
<ul>
<li><strong>Authors: </strong>Jianchen Wang, Zhouhong Gu, Zhuozhi Xiong, Hongwei Feng, Yanghua Xiao</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2403.07825">https://arxiv.org/abs/2403.07825</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2403.07825">https://arxiv.org/pdf/2403.07825</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2403.07825]] The Missing Piece in Model Editing: A Deep Dive into the Hidden Damage  Brought By Model Editing(https://arxiv.org/abs/2403.07825)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large Language Models have revolutionized numerous tasks with their remarkable efficacy.However, the editing of these models, crucial for rectifying outdated or erroneous information, often leads to a complex issue known as the ripple effect in the hidden space. This effect, while difficult to detect, can significantly impede the efficacy of model editing tasks and deteriorate model performance.This paper addresses this scientific challenge by proposing a novel evaluation methodology, Graphical Outlier Relation based Assessment(GORA), which quantitatively evaluates the adaptations of the model and the subsequent impact of editing. Furthermore, we introduce the Selective Outlier Re-Editing Approach(SORA), a model editing method designed to mitigate this ripple effect. Our comprehensive evaluations reveal that the ripple effect in the hidden space is a significant issue in all current model editing methods. However, our proposed methods, GORA and SORA, effectively identify and alleviate this issue, respectively, contributing to the advancement of LLM editing techniques.</li>
</ul>

<h3>Title: Quantifying and Mitigating Privacy Risks for Tabular Generative Models</h3>
<ul>
<li><strong>Authors: </strong>Chaoyi Zhu, Jiayi Tang, Hans Brouwer, Juan F. PÃ©rez, Marten van Dijk, Lydia Y. Chen</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2403.07842">https://arxiv.org/abs/2403.07842</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2403.07842">https://arxiv.org/pdf/2403.07842</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2403.07842]] Quantifying and Mitigating Privacy Risks for Tabular Generative Models(https://arxiv.org/abs/2403.07842)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, protect, attack, membership infer, diffusion, generative</a></li>
<li><strong>Abstract: </strong>Synthetic data from generative models emerges as the privacy-preserving data-sharing solution. Such a synthetic data set shall resemble the original data without revealing identifiable private information. The backbone technology of tabular synthesizers is rooted in image generative models, ranging from Generative Adversarial Networks (GANs) to recent diffusion models. Recent prior work sheds light on the utility-privacy tradeoff on tabular data, revealing and quantifying privacy risks on synthetic data. We first conduct an exhaustive empirical analysis, highlighting the utility-privacy tradeoff of five state-of-the-art tabular synthesizers, against eight privacy attacks, with a special focus on membership inference attacks. Motivated by the observation of high data quality but also high privacy risk in tabular diffusion, we propose DP-TLDM, Differentially Private Tabular Latent Diffusion Model, which is composed of an autoencoder network to encode the tabular data and a latent diffusion model to synthesize the latent tables. Following the emerging f-DP framework, we apply DP-SGD to train the auto-encoder in combination with batch clipping and use the separation value as the privacy metric to better capture the privacy gain from DP algorithms. Our empirical evaluation demonstrates that DP-TLDM is capable of achieving a meaningful theoretical privacy guarantee while also significantly enhancing the utility of synthetic data. Specifically, compared to other DP-protected tabular generative models, DP-TLDM improves the synthetic quality by an average of 35% in data resemblance, 15% in the utility for downstream tasks, and 50% in data discriminability, all while preserving a comparable level of privacy risk.</li>
</ul>

<h3>Title: A Machine learning and Empirical Bayesian Approach for Predictive Buying  in B2B E-commerce</h3>
<ul>
<li><strong>Authors: </strong>Tuhin Subhra De, Pranjal Singh, Alok Patel</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2403.07843">https://arxiv.org/abs/2403.07843</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2403.07843">https://arxiv.org/pdf/2403.07843</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2403.07843]] A Machine learning and Empirical Bayesian Approach for Predictive Buying  in B2B E-commerce(https://arxiv.org/abs/2403.07843)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>In the context of developing nations like India, traditional business to business (B2B) commerce heavily relies on the establishment of robust relationships, trust, and credit arrangements between buyers and sellers. Consequently, ecommerce enterprises frequently. Established in 2016 with a vision to revolutionize trade in India through technology, Udaan is the countrys largest business to business ecommerce platform. Udaan operates across diverse product categories, including lifestyle, electronics, home and employ telecallers to cultivate buyer relationships, streamline order placement procedures, and promote special promotions. The accurate anticipation of buyer order placement behavior emerges as a pivotal factor for attaining sustainable growth, heightening competitiveness, and optimizing the efficiency of these telecallers. To address this challenge, we have employed an ensemble approach comprising XGBoost and a modified version of Poisson Gamma model to predict customer order patterns with precision. This paper provides an in-depth exploration of the strategic fusion of machine learning and an empirical Bayesian approach, bolstered by the judicious selection of pertinent features. This innovative approach has yielded a remarkable 3 times increase in customer order rates, show casing its potential for transformative impact in the ecommerce industry.</li>
</ul>

<h3>Title: Fairness Feedback Loops: Training on Synthetic Data Amplifies Bias</h3>
<ul>
<li><strong>Authors: </strong>Sierra Wyllie, Ilia Shumailov, Nicolas Papernot</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2403.07857">https://arxiv.org/abs/2403.07857</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2403.07857">https://arxiv.org/pdf/2403.07857</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2403.07857]] Fairness Feedback Loops: Training on Synthetic Data Amplifies Bias(https://arxiv.org/abs/2403.07857)</code><input type="text"></li>
<li><strong>Keywords: </strong>fair, generative</a></li>
<li><strong>Abstract: </strong>Model-induced distribution shifts (MIDS) occur as previous model outputs pollute new model training sets over generations of models. This is known as model collapse in the case of generative models, and performative prediction or unfairness feedback loops for supervised models. When a model induces a distribution shift, it also encodes its mistakes, biases, and unfairnesses into the ground truth of its data ecosystem. We introduce a framework that allows us to track multiple MIDS over many generations, finding that they can lead to loss in performance, fairness, and minoritized group representation, even in initially unbiased datasets. Despite these negative consequences, we identify how models might be used for positive, intentional, interventions in their data ecosystems, providing redress for historical discrimination through a framework called algorithmic reparation (AR). We simulate AR interventions by curating representative training batches for stochastic gradient descent to demonstrate how AR can improve upon the unfairnesses of models and data ecosystems subject to other MIDS. Our work takes an important step towards identifying, mitigating, and taking accountability for the unfair feedback loops enabled by the idea that ML systems are inherently neutral and objective.</li>
</ul>

<h3>Title: Bridging Different Language Models and Generative Vision Models for  Text-to-Image Generation</h3>
<ul>
<li><strong>Authors: </strong>Shihao Zhao, Shaozhe Hao, Bojia Zi, Huaizhe Xu, Kwan-Yee K. Wong</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2403.07860">https://arxiv.org/abs/2403.07860</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2403.07860">https://arxiv.org/pdf/2403.07860</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2403.07860]] Bridging Different Language Models and Generative Vision Models for  Text-to-Image Generation(https://arxiv.org/abs/2403.07860)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, generative</a></li>
<li><strong>Abstract: </strong>Text-to-image generation has made significant advancements with the introduction of text-to-image diffusion models. These models typically consist of a language model that interprets user prompts and a vision model that generates corresponding images. As language and vision models continue to progress in their respective domains, there is a great potential in exploring the replacement of components in text-to-image diffusion models with more advanced counterparts. A broader research objective would therefore be to investigate the integration of any two unrelated language and generative vision models for text-to-image generation. In this paper, we explore this objective and propose LaVi-Bridge, a pipeline that enables the integration of diverse pre-trained language models and generative vision models for text-to-image generation. By leveraging LoRA and adapters, LaVi-Bridge offers a flexible and plug-and-play approach without requiring modifications to the original weights of the language and vision models. Our pipeline is compatible with various language models and generative vision models, accommodating different structures. Within this framework, we demonstrate that incorporating superior modules, such as more advanced language models or generative vision models, results in notable improvements in capabilities like text alignment or image quality. Extensive evaluations have been conducted to verify the effectiveness of LaVi-Bridge. Code is available at https://github.com/ShihaoZhaoZSH/LaVi-Bridge.</li>
</ul>

<h3>Title: Exploring Safety Generalization Challenges of Large Language Models via  Code</h3>
<ul>
<li><strong>Authors: </strong>Qibing Ren, Chang Gao, Jing Shao, Junchi Yan, Xin Tan, Wai Lam, Lizhuang Ma</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.CR, cs.LG, cs.SE</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2403.07865">https://arxiv.org/abs/2403.07865</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2403.07865">https://arxiv.org/pdf/2403.07865</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2403.07865]] Exploring Safety Generalization Challenges of Large Language Models via  Code(https://arxiv.org/abs/2403.07865)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack, robust, large language model</a></li>
<li><strong>Abstract: </strong>The rapid advancement of Large Language Models (LLMs) has brought about remarkable capabilities in natural language processing but also raised concerns about their potential misuse. While strategies like supervised fine-tuning and reinforcement learning from human feedback have enhanced their safety, these methods primarily focus on natural languages, which may not generalize to other domains. This paper introduces CodeAttack, a framework that transforms natural language inputs into code inputs, presenting a novel environment for testing the safety generalization of LLMs. Our comprehensive studies on state-of-the-art LLMs including GPT-4, Claude-2, and Llama-2 series reveal a common safety vulnerability of these models against code input: CodeAttack consistently bypasses the safety guardrails of all models more than 80\% of the time. Furthermore, we find that a larger distribution gap between CodeAttack and natural language leads to weaker safety generalization, such as encoding natural language input with data structures or using less popular programming languages. These findings highlight new safety risks in the code domain and the need for more robust safety alignment algorithms to match the code capabilities of LLMs.</li>
</ul>

<h3>Title: Rethinking Generative Large Language Model Evaluation for Semantic  Comprehension</h3>
<ul>
<li><strong>Authors: </strong>Fangyun Wei, Xi Chen, Lin Luo</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2403.07872">https://arxiv.org/abs/2403.07872</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2403.07872">https://arxiv.org/pdf/2403.07872</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2403.07872]] Rethinking Generative Large Language Model Evaluation for Semantic  Comprehension(https://arxiv.org/abs/2403.07872)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative, large language model</a></li>
<li><strong>Abstract: </strong>Despite their sophisticated capabilities, large language models (LLMs) encounter a major hurdle in effective assessment. This paper first revisits the prevalent evaluation method-multiple choice question answering (MCQA), which allows for straightforward accuracy measurement. Through a comprehensive evaluation of 24 models across 11 benchmarks, we highlight several potential drawbacks of MCQA, for instance, the inconsistency between the MCQA evaluation and the generation of open-ended responses in practical scenarios. In response, we introduce an RWQ-Elo rating system, engaging 24 LLMs such as GPT-4, GPT-3.5, Google-Gemini-Pro and LLaMA-1/-2, in a two-player competitive format, with GPT-4 serving as the judge. Each LLM receives an Elo rating thereafter. This system is designed to mirror real-world usage, and for this purpose, we have compiled a new benchmark called ``Real-world questions'' (RWQ), comprising 20,772 authentic user inquiries. Additionally, we thoroughly analyze the characteristics of our system and compare it with prior leaderboards like AlpacaEval and MT-Bench. Our analysis reveals the stability of our RWQ-Elo system, the feasibility of registering new models, and its potential to reshape LLM leaderboards.</li>
</ul>

<h3>Title: Beyond Text: Frozen Large Language Models in Visual Signal Comprehension</h3>
<ul>
<li><strong>Authors: </strong>Lei Zhu, Fangyun Wei, Yanye Lu</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2403.07874">https://arxiv.org/abs/2403.07874</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2403.07874">https://arxiv.org/pdf/2403.07874</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2403.07874]] Beyond Text: Frozen Large Language Models in Visual Signal Comprehension(https://arxiv.org/abs/2403.07874)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>In this work, we investigate the potential of a large language model (LLM) to directly comprehend visual signals without the necessity of fine-tuning on multi-modal datasets. The foundational concept of our method views an image as a linguistic entity, and translates it to a set of discrete words derived from the LLM's vocabulary. To achieve this, we present the Vision-to-Language Tokenizer, abbreviated as V2T Tokenizer, which transforms an image into a ``foreign language'' with the combined aid of an encoder-decoder, the LLM vocabulary, and a CLIP model. With this innovative image encoding, the LLM gains the ability not only for visual comprehension but also for image denoising and restoration in an auto-regressive fashion-crucially, without any fine-tuning. We undertake rigorous experiments to validate our method, encompassing understanding tasks like image recognition, image captioning, and visual question answering, as well as image denoising tasks like inpainting, outpainting, deblurring, and shift restoration. Code and models are available at https://github.com/zh460045050/V2L-Tokenizer.</li>
</ul>

<button id="copy">Copy All</button>
</article>
<script src="https://cdn.staticfile.org/clipboard.js/2.0.4/clipboard.min.js"></script>
<script src="../../javascript/clipboard.js"></script>
