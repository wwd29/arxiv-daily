<link rel="stylesheet" href="../../css/markdown.css" />
<article class="markdown-body">
<h2>secure</h2>
<h3>Title: Building Resilient Web 3.0 with Quantum Information Technologies and Blockchain: An Ambilateral View. (arXiv:2303.13050v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2303.13050">http://arxiv.org/abs/2303.13050</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2303.13050] Building Resilient Web 3](http://arxiv.org/abs/2303.13050) #secure</code></li>
<li>Summary: <p>Web 3.0 pursues the establishment of decentralized ecosystems based on
blockchain technologies to drive the digital transformation of physical
commerce and governance. Through consensus algorithms and smart contracts in
blockchain, which are based on cryptography technologies, digital identity,
digital asset management, decentralized autonomous organization, and
decentralized finance are realized for secure and transparent digital economy
services in Web 3.0 for promoting the integration of digital and physical
economies. With the rapid realization of quantum devices, Web 3.0 is being
developed in parallel with the deployment of quantum cloud computing and
quantum Internet. In this regard, quantum computing first disrupts the original
cryptographic systems that protect data security while reshaping modern
cryptography with the advantages of quantum computing and communication.
Therefore, this survey provides a comprehensive overview of blockchain-based
Web 3.0 and its quantum and post-quantum enhancement from the ambilateral
perspective. On the one hand, some post-quantum migration methods, and
anti-quantum signatures offer potential ways to achieve unforgeable security
under quantum attack for the internal technologies of blockchain. On the other
hand, some quantum/post-quantum encryption and verification algorithms improve
the external performance of the blockchain, enabling a decentralized, valuable,
secure blockchain system. Finally, we discuss the future directions toward
developing a provable secure decentralized digital ecosystem.
</p></li>
</ul>

<h3>Title: BlockFW -- Towards Blockchain-based Rule-Sharing Firewall. (arXiv:2303.13073v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2303.13073">http://arxiv.org/abs/2303.13073</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2303.13073] BlockFW -- Towards Blockchain-based Rule-Sharing Firewall](http://arxiv.org/abs/2303.13073) #secure</code></li>
<li>Summary: <p>Central-managed security mechanisms are often utilized in many organizations,
but such server is also a security breaking point. This is because the server
has the authority for all nodes that share the security protection. Hence if
the attackers successfully tamper the server, the organization will be in
trouble. Also, the settings and policies saved on the server are usually not
cryptographically secured and ensured with hash. Thus, changing the settings
from alternative way is feasible, without causing the security solution to
raise any alarms. To mitigate these issues, in this work, we develop BlockFW -
a blockchain-based rule sharing firewall to create a managed security
mechanism, which provides validation and monitoring from multiple nodes. For
BlockFW, all occurred transactions are cryptographically protected to ensure
its integrity, making tampering attempts in utmost challenging for attackers.
In the evaluation, we explore the performance of BlockFW under several
adversarial conditions and demonstrate its effectiveness.
</p></li>
</ul>

<h2>security</h2>
<h3>Title: Real-World Community-in-the-Loop Smart Video Surveillance -- A Case Study at a Community College. (arXiv:2303.12934v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2303.12934">http://arxiv.org/abs/2303.12934</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2303.12934] Real-World Community-in-the-Loop Smart Video Surveillance -- A Case Study at a Community College](http://arxiv.org/abs/2303.12934) #security</code></li>
<li>Summary: <p>Smart Video surveillance systems have become important recently for ensuring
public safety and security, especially in smart cities. However, applying
real-time artificial intelligence technologies combined with low-latency
notification and alarming has made deploying these systems quite challenging.
This paper presents a case study for designing and deploying smart video
surveillance systems based on a real-world testbed at a community college. We
primarily focus on a smart camera-based system that can identify
suspicious/abnormal activities and alert the stakeholders and residents
immediately. The paper highlights and addresses different algorithmic and
system design challenges to guarantee real-time high-accuracy video analytics
processing in the testbed. It also presents an example of cloud system
infrastructure and a mobile application for real-time notification to keep
students, faculty/staff, and responsible security personnel in the loop. At the
same time, it covers the design decision to maintain communities' privacy and
ethical requirements as well as hardware configuration and setups. We evaluate
the system's performance using throughput and end-to-end latency. The
experiment results show that, on average, our system's end-to-end latency to
notify the end users in case of detecting suspicious objects is 5.3, 5.78, and
11.11 seconds when running 1, 4, and 8 cameras, respectively. On the other
hand, in case of detecting anomalous behaviors, the system could notify the end
users with 7.3, 7.63, and 20.78 seconds average latency. These results
demonstrate that the system effectively detects and notifies abnormal behaviors
and suspicious objects to the end users within a reasonable period. The system
can run eight cameras simultaneously at a 32.41 Frame Per Second (FPS) rate.
</p></li>
</ul>

<h3>Title: Cryptocurrency wallets: assessment and security. (arXiv:2303.12940v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2303.12940">http://arxiv.org/abs/2303.12940</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2303.12940] Cryptocurrency wallets: assessment and security](http://arxiv.org/abs/2303.12940) #security</code></li>
<li>Summary: <p>Digital wallet as a software program or a digital device allows users to
conduct various transactions. Hot and cold digital wallets are considered as
two types of this wallet. Digital wallets need an online connection fall into
the first group, whereas digital wallets can operate without internet
connection belong to the second group. Prior to buying a digital wallet, it is
important to define for what purpose it will be utilized. The ease with which a
mobile phone transaction may be completed in a couple of seconds and the speed
with which transactions are executed are reflection of efficiency. One of the
most important elements of digital wallets is data organization. Digital
wallets are significantly less expensive than classic methods of transaction,
which entails various charges and fees. Constantly, demand for their usage is
growing due to speed, security, and the ability to conduct transactions between
two users without the need of a third party. As the popularity of digital
currency wallets grows, the number of security concerns impacting them
increases significantly. The current status of digital wallets on the market,
as well as the options for an efficient solution for obtaining and utilizing
digital wallets. Finally, the digital wallets' security and future improvement
prospects are discussed in this chapter.
</p></li>
</ul>

<h3>Title: Feature Reduction Method Comparison Towards Explainability and Efficiency in Cybersecurity Intrusion Detection Systems. (arXiv:2303.12891v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2303.12891">http://arxiv.org/abs/2303.12891</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2303.12891] Feature Reduction Method Comparison Towards Explainability and Efficiency in Cybersecurity Intrusion Detection Systems](http://arxiv.org/abs/2303.12891) #security</code></li>
<li>Summary: <p>In the realm of cybersecurity, intrusion detection systems (IDS) detect and
prevent attacks based on collected computer and network data. In recent
research, IDS models have been constructed using machine learning (ML) and deep
learning (DL) methods such as Random Forest (RF) and deep neural networks
(DNN). Feature selection (FS) can be used to construct faster, more
interpretable, and more accurate models. We look at three different FS
techniques; RF information gain (RF-IG), correlation feature selection using
the Bat Algorithm (CFS-BA), and CFS using the Aquila Optimizer (CFS-AO). Our
results show CFS-BA to be the most efficient of the FS methods, building in 55%
of the time of the best RF-IG model while achieving 99.99% of its accuracy.
This reinforces prior contributions attesting to CFS-BA's accuracy while
building upon the relationship between subset size, CFS score, and RF-IG score
in final results.
</p></li>
</ul>

<h3>Title: A Survey on Explainable Artificial Intelligence for Network Cybersecurity. (arXiv:2303.12942v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2303.12942">http://arxiv.org/abs/2303.12942</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2303.12942] A Survey on Explainable Artificial Intelligence for Network Cybersecurity](http://arxiv.org/abs/2303.12942) #security</code></li>
<li>Summary: <p>The black-box nature of artificial intelligence (AI) models has been the
source of many concerns in their use for critical applications. Explainable
Artificial Intelligence (XAI) is a rapidly growing research field that aims to
create machine learning models that can provide clear and interpretable
explanations for their decisions and actions. In the field of network
cybersecurity, XAI has the potential to revolutionize the way we approach
network security by enabling us to better understand the behavior of cyber
threats and to design more effective defenses. In this survey, we review the
state of the art in XAI for cybersecurity in network systems and explore the
various approaches that have been proposed to address this important problem.
The review follows a systematic classification of network-driven cybersecurity
threats and issues. We discuss the challenges and limitations of current XAI
methods in the context of cybersecurity and outline promising directions for
future research.
</p></li>
</ul>

<h3>Title: Security Analysis on Social Media Networks via STRIDE Model. (arXiv:2303.13075v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2303.13075">http://arxiv.org/abs/2303.13075</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2303.13075] Security Analysis on Social Media Networks via STRIDE Model](http://arxiv.org/abs/2303.13075) #security</code></li>
<li>Summary: <p>Security associated threats are often increased for online social media
during a pandemic, such as COVID-19, along with changes in a work environment.
For example, employees in many companies and organizations have started to work
from home due to the COVID-19 pandemic. Such working style has increased many
remote activities and further relied on email for communication, thus creating
an ideal condition for email fraud schemes. Motivated by this observation, the
main purpose of this work is to evaluate the privacy policy of online social
media and identify potential security associated problems. First, we perform a
risk analysis of online social media networks such as Facebook, Twitter and
LinkedIn by using the STRIDE model. This aims to find threats and
vulnerabilities in the online social media. Then in this analysis, the phishing
attack was found to be a main threat in online social media, which is a social
engineering attack, where users are convinced through some fake messages or
emails to extract their personal credentials.
</p></li>
</ul>

<h3>Title: Failure-tolerant Distributed Learning for Anomaly Detection in Wireless Networks. (arXiv:2303.13015v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2303.13015">http://arxiv.org/abs/2303.13015</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2303.13015] Failure-tolerant Distributed Learning for Anomaly Detection in Wireless Networks](http://arxiv.org/abs/2303.13015) #security</code></li>
<li>Summary: <p>The analysis of distributed techniques is often focused upon their
efficiency, without considering their robustness (or lack thereof). Such a
consideration is particularly important when devices or central servers can
fail, which can potentially cripple distributed systems. When such failures
arise in wireless communications networks, important services that they
use/provide (like anomaly detection) can be left inoperable and can result in a
cascade of security problems. In this paper, we present a novel method to
address these risks by combining both flat- and star-topologies, combining the
performance and reliability benefits of both. We refer to this method as
"Tol-FL", due to its increased failure-tolerance as compared to the technique
of Federated Learning. Our approach both limits device failure risks while
outperforming prior methods by up to 8% in terms of anomaly detection AUROC in
a range of realistic settings that consider client as well as server failure,
all while reducing communication costs. This performance demonstrates that
Tol-FL is a highly suitable method for distributed model training for anomaly
detection, especially in the domain of wireless networks.
</p></li>
</ul>

<h2>privacy</h2>
<h3>Title: Disguise without Disruption: Utility-Preserving Face De-Identification. (arXiv:2303.13269v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2303.13269">http://arxiv.org/abs/2303.13269</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2303.13269] Disguise without Disruption: Utility-Preserving Face De-Identification](http://arxiv.org/abs/2303.13269) #privacy</code></li>
<li>Summary: <p>With the increasing ubiquity of cameras and smart sensors, humanity is
generating data at an exponential rate. Access to this trove of information,
often covering yet-underrepresented use-cases (e.g., AI in medical settings)
could fuel a new generation of deep-learning tools. However, eager data
scientists should first provide satisfying guarantees w.r.t. the privacy of
individuals present in these untapped datasets. This is especially important
for images or videos depicting faces, as their biometric information is the
target of most identification methods. While a variety of solutions have been
proposed to de-identify such images, they often corrupt other non-identifying
facial attributes that would be relevant for downstream tasks. In this paper,
we propose Disguise, a novel algorithm to seamlessly de-identify facial images
while ensuring the usability of the altered data. Unlike prior arts, we ground
our solution in both differential privacy and ensemble-learning research
domains. Our method extracts and swaps depicted identities with fake ones,
synthesized via variational mechanisms to maximize obfuscation and
non-invertibility; while leveraging the supervision from a mixture-of-experts
to disentangle and preserve other utility attributes. We extensively evaluate
our method on multiple datasets, demonstrating higher de-identification rate
and superior consistency than prior art w.r.t. various downstream tasks.
</p></li>
</ul>

<h3>Title: Practical and Ethical Challenges of Large Language Models in Education: A Systematic Literature Review. (arXiv:2303.13379v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2303.13379">http://arxiv.org/abs/2303.13379</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2303.13379] Practical and Ethical Challenges of Large Language Models in Education: A Systematic Literature Review](http://arxiv.org/abs/2303.13379) #privacy</code></li>
<li>Summary: <p>Educational technology innovations that have been developed based on large
language models (LLMs) have shown the potential to automate the laborious
process of generating and analysing textual content. While various innovations
have been developed to automate a range of educational tasks (e.g., question
generation, feedback provision, and essay grading), there are concerns
regarding the practicality and ethicality of these innovations. Such concerns
may hinder future research and the adoption of LLMs-based innovations in
authentic educational contexts. To address this, we conducted a systematic
literature review of 118 peer-reviewed papers published since 2017 to pinpoint
the current state of research on using LLMs to automate and support educational
tasks. The practical and ethical challenges of LLMs-based innovations were also
identified by assessing their technological readiness, model performance,
replicability, system transparency, privacy, equality, and beneficence. The
findings were summarised into three recommendations for future studies,
including updating existing innovations with state-of-the-art models (e.g.,
GPT-3), embracing the initiative of open-sourcing models/systems, and adopting
a human-centred approach throughout the developmental process. These
recommendations could support future research to develop practical and ethical
innovations for supporting diverse educational tasks and benefiting students,
teachers, and institutions.
</p></li>
</ul>

<h3>Title: Development and validation of a natural language processing algorithm to pseudonymize documents in the context of a clinical data warehouse. (arXiv:2303.13451v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2303.13451">http://arxiv.org/abs/2303.13451</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2303.13451] Development and validation of a natural language processing algorithm to pseudonymize documents in the context of a clinical data warehouse](http://arxiv.org/abs/2303.13451) #privacy</code></li>
<li>Summary: <p>The objective of this study is to address the critical issue of
de-identification of clinical reports in order to allow access to data for
research purposes, while ensuring patient privacy. The study highlights the
difficulties faced in sharing tools and resources in this domain and presents
the experience of the Greater Paris University Hospitals (AP-HP) in
implementing a systematic pseudonymization of text documents from its Clinical
Data Warehouse. We annotated a corpus of clinical documents according to 12
types of identifying entities, and built a hybrid system, merging the results
of a deep learning model as well as manual rules. Our results show an overall
performance of 0.99 of F1-score. We discuss implementation choices and present
experiments to better understand the effort involved in such a task, including
dataset size, document types, language models, or rule addition. We share
guidelines and code under a 3-Clause BSD license.
</p></li>
</ul>

<h3>Title: Stability is Stable: Connections between Replicability, Privacy, and Adaptive Generalization. (arXiv:2303.12921v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2303.12921">http://arxiv.org/abs/2303.12921</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2303.12921] Stability is Stable: Connections between Replicability, Privacy, and Adaptive Generalization](http://arxiv.org/abs/2303.12921) #privacy</code></li>
<li>Summary: <p>The notion of replicable algorithms was introduced in Impagliazzo et al.
[STOC '22] to describe randomized algorithms that are stable under the
resampling of their inputs. More precisely, a replicable algorithm gives the
same output with high probability when its randomness is fixed and it is run on
a new i.i.d. sample drawn from the same distribution. Using replicable
algorithms for data analysis can facilitate the verification of published
results by ensuring that the results of an analysis will be the same with high
probability, even when that analysis is performed on a new data set.
</p></li>
</ul>

<p>In this work, we establish new connections and separations between
replicability and standard notions of algorithmic stability. In particular, we
give sample-efficient algorithmic reductions between perfect generalization,
approximate differential privacy, and replicability for a broad class of
statistical problems. Conversely, we show any such equivalence must break down
computationally: there exist statistical problems that are easy under
differential privacy, but that cannot be solved replicably without breaking
public-key cryptography. Furthermore, these results are tight: our reductions
are statistically optimal, and we show that any computational separation
between DP and replicability must imply the existence of one-way functions.
</p>
<p>Our statistical reductions give a new algorithmic framework for translating
between notions of stability, which we instantiate to answer several open
questions in replicability and privacy. This includes giving sample-efficient
replicable algorithms for various PAC learning, distribution estimation, and
distribution testing problems, algorithmic amplification of $\delta$ in
approximate DP, conversions from item-level to user-level privacy, and the
existence of private agnostic-to-realizable learning reductions under
structured distributions.
</p>

<h3>Title: A Privacy-Preserving Energy Theft Detection Model for Effective Demand-Response Management in Smart Grids. (arXiv:2303.13204v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2303.13204">http://arxiv.org/abs/2303.13204</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2303.13204] A Privacy-Preserving Energy Theft Detection Model for Effective Demand-Response Management in Smart Grids](http://arxiv.org/abs/2303.13204) #privacy</code></li>
<li>Summary: <p>The detection of energy thefts is vital for the safety of the whole smart
grid system. However, the detection alone is not enough since energy thefts can
crucially affect the electricity supply leading to some blackouts. Moreover,
privacy is one of the major challenges that must be preserved when dealing with
clients' energy data. This is often overlooked in energy theft detection
research as most current detection techniques rely on raw, unencrypted data,
which may potentially expose sensitive and personal data. To solve this issue,
we present a privacy-preserving energy theft detection technique with effective
demand management that employs two layers of privacy protection. We explore a
split learning mechanism that trains a detection model in a decentralised
fashion without the need to exchange raw data. We also employ a second layer of
privacy by the use of a masking scheme to mask clients' outputs in order to
prevent inference attacks. A privacy-enhanced version of this mechanism also
employs an additional layer of privacy protection by training a randomisation
layer at the end of the client-side model. This is done to make the output as
random as possible without compromising the detection performance. For the
energy theft detection part, we design a multi-output machine learning model to
identify energy thefts, estimate their volume, and effectively predict future
demand. Finally, we use a comprehensive set of experiments to test our proposed
scheme. The experimental results show that our scheme achieves high detection
accuracy and greatly improves the privacy preservation degree.
</p></li>
</ul>

<h2>protect</h2>
<h2>defense</h2>
<h3>Title: Test-time Defense against Adversarial Attacks: Detection and Reconstruction of Adversarial Examples via Masked Autoencoder. (arXiv:2303.12848v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2303.12848">http://arxiv.org/abs/2303.12848</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2303.12848] Test-time Defense against Adversarial Attacks: Detection and Reconstruction of Adversarial Examples via Masked Autoencoder](http://arxiv.org/abs/2303.12848) #defense</code></li>
<li>Summary: <p>Existing defense methods against adversarial attacks can be categorized into
training time and test time defenses. Training time defense, i.e., adversarial
training, requires a significant amount of extra time for training and is often
not able to be generalized to unseen attacks. On the other hand, test time
defense by test time weight adaptation requires access to perform gradient
descent on (part of) the model weights, which could be infeasible for models
with frozen weights. To address these challenges, we propose DRAM, a novel
defense method to Detect and Reconstruct multiple types of Adversarial attacks
via Masked autoencoder (MAE). We demonstrate how to use MAE losses to build a
KS-test to detect adversarial attacks. Moreover, the MAE losses can be used to
repair adversarial samples from unseen attack types. In this sense, DRAM
neither requires model weight updates in test time nor augments the training
set with more adversarial samples. Evaluating DRAM on the large-scale ImageNet
data, we achieve the best detection rate of 82% on average on eight types of
adversarial attacks compared with other detection baselines. For
reconstruction, DRAM improves the robust accuracy by 6% ~ 41% for Standard
ResNet50 and 3% ~ 8% for Robust ResNet50 compared with other self-supervision
tasks, such as rotation prediction and contrastive learning.
</p></li>
</ul>

<h3>Title: Backdoor Defense via Adaptively Splitting Poisoned Dataset. (arXiv:2303.12993v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2303.12993">http://arxiv.org/abs/2303.12993</a></li>
<li>Code URL: <a href="https://github.com/kuofenggao/asd">https://github.com/kuofenggao/asd</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2303.12993] Backdoor Defense via Adaptively Splitting Poisoned Dataset](http://arxiv.org/abs/2303.12993) #defense</code></li>
<li>Summary: <p>Backdoor defenses have been studied to alleviate the threat of deep neural
networks (DNNs) being backdoor attacked and thus maliciously altered. Since
DNNs usually adopt some external training data from an untrusted third party, a
robust backdoor defense strategy during the training stage is of importance. We
argue that the core of training-time defense is to select poisoned samples and
to handle them properly. In this work, we summarize the training-time defenses
from a unified framework as splitting the poisoned dataset into two data pools.
Under our framework, we propose an adaptively splitting dataset-based defense
(ASD). Concretely, we apply loss-guided split and meta-learning-inspired split
to dynamically update two data pools. With the split clean data pool and
polluted data pool, ASD successfully defends against backdoor attacks during
training. Extensive experiments on multiple benchmark datasets and DNN models
against six state-of-the-art backdoor attacks demonstrate the superiority of
our ASD. Our code is available at https://github.com/KuofengGao/ASD.
</p></li>
</ul>

<h3>Title: Don't FREAK Out: A Frequency-Inspired Approach to Detecting Backdoor Poisoned Samples in DNNs. (arXiv:2303.13211v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2303.13211">http://arxiv.org/abs/2303.13211</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2303.13211] Don't FREAK Out: A Frequency-Inspired Approach to Detecting Backdoor Poisoned Samples in DNNs](http://arxiv.org/abs/2303.13211) #defense</code></li>
<li>Summary: <p>In this paper we investigate the frequency sensitivity of Deep Neural
Networks (DNNs) when presented with clean samples versus poisoned samples. Our
analysis shows significant disparities in frequency sensitivity between these
two types of samples. Building on these findings, we propose FREAK, a
frequency-based poisoned sample detection algorithm that is simple yet
effective. Our experimental results demonstrate the efficacy of FREAK not only
against frequency backdoor attacks but also against some spatial attacks. Our
work is just the first step in leveraging these insights. We believe that our
analysis and proposed defense mechanism will provide a foundation for future
research and development of backdoor defenses.
</p></li>
</ul>

<h3>Title: Paraphrasing evades detectors of AI-generated text, but retrieval is an effective defense. (arXiv:2303.13408v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2303.13408">http://arxiv.org/abs/2303.13408</a></li>
<li>Code URL: <a href="https://github.com/martiansideofthemoon/ai-detection-paraphrases">https://github.com/martiansideofthemoon/ai-detection-paraphrases</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2303.13408] Paraphrasing evades detectors of AI-generated text, but retrieval is an effective defense](http://arxiv.org/abs/2303.13408) #defense</code></li>
<li>Summary: <p>To detect the deployment of large language models for malicious use cases
(e.g., fake content creation or academic plagiarism), several approaches have
recently been proposed for identifying AI-generated text via watermarks or
statistical irregularities. How robust are these detection algorithms to
paraphrases of AI-generated text? To stress test these detectors, we first
train an 11B parameter paraphrase generation model (DIPPER) that can paraphrase
paragraphs, optionally leveraging surrounding text (e.g., user-written prompts)
as context. DIPPER also uses scalar knobs to control the amount of lexical
diversity and reordering in the paraphrases. Paraphrasing text generated by
three large language models (including GPT3.5-davinci-003) with DIPPER
successfully evades several detectors, including watermarking, GPTZero,
DetectGPT, and OpenAI's text classifier. For example, DIPPER drops the
detection accuracy of DetectGPT from 70.3% to 4.6% (at a constant false
positive rate of 1%), without appreciably modifying the input semantics. To
increase the robustness of AI-generated text detection to paraphrase attacks,
we introduce a simple defense that relies on retrieving semantically-similar
generations and must be maintained by a language model API provider. Given a
candidate text, our algorithm searches a database of sequences previously
generated by the API, looking for sequences that match the candidate text
within a certain threshold. We empirically verify our defense using a database
of 15M generations from a fine-tuned T5-XXL model and find that it can detect
80% to 97% of paraphrased generations across different settings, while only
classifying 1% of human-written sequences as AI-generated. We will open source
our code, model and data for future research.
</p></li>
</ul>

<h2>attack</h2>
<h3>Title: Semantic Image Attack for Visual Model Diagnosis. (arXiv:2303.13010v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2303.13010">http://arxiv.org/abs/2303.13010</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2303.13010] Semantic Image Attack for Visual Model Diagnosis](http://arxiv.org/abs/2303.13010) #attack</code></li>
<li>Summary: <p>In practice, metric analysis on a specific train and test dataset does not
guarantee reliable or fair ML models. This is partially due to the fact that
obtaining a balanced, diverse, and perfectly labeled dataset is typically
expensive, time-consuming, and error-prone. Rather than relying on a carefully
designed test set to assess ML models' failures, fairness, or robustness, this
paper proposes Semantic Image Attack (SIA), a method based on the adversarial
attack that provides semantic adversarial images to allow model diagnosis,
interpretability, and robustness. Traditional adversarial training is a popular
methodology for robustifying ML models against attacks. However, existing
adversarial methods do not combine the two aspects that enable the
interpretation and analysis of the model's flaws: semantic traceability and
perceptual quality. SIA combines the two features via iterative gradient ascent
on a predefined semantic attribute space and the image space. We illustrate the
validity of our approach in three scenarios for keypoint detection and
classification. (1) Model diagnosis: SIA generates a histogram of attributes
that highlights the semantic vulnerability of the ML model (i.e., attributes
that make the model fail). (2) Stronger attacks: SIA generates adversarial
examples with visually interpretable attributes that lead to higher attack
success rates than baseline methods. The adversarial training on SIA improves
the transferable robustness across different gradient-based attacks. (3)
Robustness to imbalanced datasets: we use SIA to augment the underrepresented
classes, which outperforms strong augmentation and re-balancing baselines.
</p></li>
</ul>

<h3>Title: Watch Out for the Confusing Faces: Detecting Face Swapping with the Probability Distribution of Face Identification Models. (arXiv:2303.13131v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2303.13131">http://arxiv.org/abs/2303.13131</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2303.13131] Watch Out for the Confusing Faces: Detecting Face Swapping with the Probability Distribution of Face Identification Models](http://arxiv.org/abs/2303.13131) #attack</code></li>
<li>Summary: <p>Recently, face swapping has been developing rapidly and achieved a surprising
reality, raising concerns about fake content. As a countermeasure, various
detection approaches have been proposed and achieved promising performance.
However, most existing detectors struggle to maintain performance on unseen
face swapping methods and low-quality images. Apart from the generalization
problem, current detection approaches have been shown vulnerable to evasion
attacks crafted by detection-aware manipulators. Lack of robustness under
adversary scenarios leaves threats for applying face swapping detection in real
world. In this paper, we propose a novel face swapping detection approach based
on face identification probability distributions, coined as IdP_FSD, to improve
the generalization and robustness. IdP_FSD is specially designed for detecting
swapped faces whose identities belong to a finite set, which is meaningful in
real-world applications. Compared with previous general detection methods, we
make use of the available real faces with concerned identities and require no
fake samples for training. IdP_FSD exploits face swapping's common nature that
the identity of swapped face combines that of two faces involved in swapping.
We reflect this nature with the confusion of a face identification model and
measure the confusion with the maximum value of the output probability
distribution. What's more, to defend our detector under adversary scenarios, an
attention-based finetuning scheme is proposed for the face identification
models used in IdP_FSD. Extensive experiments show that the proposed IdP_FSD
not only achieves high detection performance on different benchmark datasets
and image qualities but also raises the bar for manipulators to evade the
detection.
</p></li>
</ul>

<h3>Title: Managing Cyber Risk, a Science in the Making. (arXiv:2303.12939v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2303.12939">http://arxiv.org/abs/2303.12939</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2303.12939] Managing Cyber Risk, a Science in the Making](http://arxiv.org/abs/2303.12939) #attack</code></li>
<li>Summary: <p>Not a day goes by without news about a cyber attack. Fear spreads out and
lots of wrong ideas circulate. This survey aims at showing how all these
uncertainties about cyber can be transformed into manageable risk. After
reviewing the main characteristics of cyber risk, we consider the three layers
of cyber space: hardware, software and psycho-cognitive layer. We ask ourselves
how is this risk different from others, how modelling has been tackled and
needs to evolve, and what are the multi-facetted aspects of cyber risk
management. This wide exploration pictures a science in the making and points
out the questions to be solved for building a resilient society.
</p></li>
</ul>

<h3>Title: Deep Attention Recognition for Attack Identification in 5G UAV scenarios: Novel Architecture and End-to-End Evaluation. (arXiv:2303.12947v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2303.12947">http://arxiv.org/abs/2303.12947</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2303.12947] Deep Attention Recognition for Attack Identification in 5G UAV scenarios: Novel Architecture and End-to-End Evaluation](http://arxiv.org/abs/2303.12947) #attack</code></li>
<li>Summary: <p>Despite the robust security features inherent in the 5G framework, attackers
will still discover ways to disrupt 5G unmanned aerial vehicle (UAV) operations
and decrease UAV control communication performance in Air-to-Ground (A2G)
links. Operating under the assumption that the 5G UAV communications
infrastructure will never be entirely secure, we propose Deep Attention
Recognition (DAtR) as a solution to identify attacks based on a small deep
network embedded in authenticated UAVs. Our proposed solution uses two
observable parameters: the Signal-to-Interference-plus-Noise Ratio (SINR) and
the Reference Signal Received Power (RSSI) to recognize attacks under
Line-of-Sight (LoS), Non-Line-of-Sight (NLoS), and a probabilistic combination
of the two conditions. In the tested scenarios, a number of attackers are
located in random positions, while their power is varied in each simulation.
Moreover, terrestrial users are included in the network to impose additional
complexity on attack detection. To improve the systems overall performance in
the attack scenarios, we propose complementing the deep network decision with
two mechanisms based on data manipulation and majority voting techniques. We
compare several performance parameters in our proposed Deep Network. For
example, the impact of Long Short-Term-Memory (LSTM) and Attention layers in
terms of their overall accuracy, the window size effect, and test the accuracy
when only partial data is available in the training process. Finally, we
benchmark our deep network with six widely used classifiers regarding
classification accuracy. Our algorithms accuracy exceeds 4% compared with the
eXtreme Gradient Boosting (XGB) classifier in LoS condition and around 3% in
the short distance NLoS condition. Considering the proposed deep network, all
other classifiers present lower accuracy than XGB.
</p></li>
</ul>

<h3>Title: Connected Superlevel Set in (Deep) Reinforcement Learning and its Application to Minimax Theorems. (arXiv:2303.12981v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2303.12981">http://arxiv.org/abs/2303.12981</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2303.12981] Connected Superlevel Set in (Deep) Reinforcement Learning and its Application to Minimax Theorems](http://arxiv.org/abs/2303.12981) #attack</code></li>
<li>Summary: <p>The aim of this paper is to improve the understanding of the optimization
landscape for policy optimization problems in reinforcement learning.
Specifically, we show that the superlevel set of the objective function with
respect to the policy parameter is always a connected set both in the tabular
setting and under policies represented by a class of neural networks. In
addition, we show that the optimization objective as a function of the policy
parameter and reward satisfies a stronger "equiconnectedness" property. To our
best knowledge, these are novel and previously unknown discoveries.
</p></li>
</ul>

<p>We present an application of the connectedness of these superlevel sets to
the derivation of minimax theorems for robust reinforcement learning. We show
that any minimax optimization program which is convex on one side and is
equiconnected on the other side observes the minimax equality (i.e. has a Nash
equilibrium). We find that this exact structure is exhibited by an interesting
robust reinforcement learning problem under an adversarial reward attack, and
the validity of its minimax equality immediately follows. This is the first
time such a result is established in the literature.
</p>

<h3>Title: Decentralized Adversarial Training over Graphs. (arXiv:2303.13326v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2303.13326">http://arxiv.org/abs/2303.13326</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2303.13326] Decentralized Adversarial Training over Graphs](http://arxiv.org/abs/2303.13326) #attack</code></li>
<li>Summary: <p>The vulnerability of machine learning models to adversarial attacks has been
attracting considerable attention in recent years. Most existing studies focus
on the behavior of stand-alone single-agent learners. In comparison, this work
studies adversarial training over graphs, where individual agents are subjected
to perturbations of varied strength levels across space. It is expected that
interactions by linked agents, and the heterogeneity of the attack models that
are possible over the graph, can help enhance robustness in view of the
coordination power of the group. Using a min-max formulation of diffusion
learning, we develop a decentralized adversarial training framework for
multi-agent systems. We analyze the convergence properties of the proposed
scheme for both convex and non-convex environments, and illustrate the enhanced
robustness to adversarial attacks.
</p></li>
</ul>

<h2>robust</h2>
<h3>Title: NVAutoNet: Fast and Accurate 360$^{\circ}$ 3D Perception For Self Driving. (arXiv:2303.12976v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2303.12976">http://arxiv.org/abs/2303.12976</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2303.12976] NVAutoNet: Fast and Accurate 360$^{\circ}$ 3D Perception For Self Driving](http://arxiv.org/abs/2303.12976) #robust</code></li>
<li>Summary: <p>Robust real-time perception of 3D world is essential to the autonomous
vehicle. We introduce an end-to-end surround camera perception system for
self-driving. Our perception system is a novel multi-task, multi-camera network
which takes a variable set of time-synced camera images as input and produces a
rich collection of 3D signals such as sizes, orientations, locations of
obstacles, parking spaces and free-spaces, etc. Our perception network is
modular and end-to-end: 1) the outputs can be consumed directly by downstream
modules without any post-processing such as clustering and fusion -- improving
speed of model deployment and in-car testing 2) the whole network training is
done in one single stage -- improving speed of model improvement and
iterations. The network is well designed to have high accuracy while running at
53 fps on NVIDIA Orin SoC (system-on-a-chip). The network is robust to sensor
mounting variations (within some tolerances) and can be quickly customized for
different vehicle types via efficient model fine-tuning thanks of its
capability of taking calibration parameters as additional inputs during
training and testing. Most importantly, our network has been successfully
deployed and being tested on real roads.
</p></li>
</ul>

<h3>Title: Benchmarking the Reliability of Post-training Quantization: a Particular Focus on Worst-case Performance. (arXiv:2303.13003v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2303.13003">http://arxiv.org/abs/2303.13003</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2303.13003] Benchmarking the Reliability of Post-training Quantization: a Particular Focus on Worst-case Performance](http://arxiv.org/abs/2303.13003) #robust</code></li>
<li>Summary: <p>Post-training quantization (PTQ) is a popular method for compressing deep
neural networks (DNNs) without modifying their original architecture or
training procedures. Despite its effectiveness and convenience, the reliability
of PTQ methods in the presence of some extrem cases such as distribution shift
and data noise remains largely unexplored. This paper first investigates this
problem on various commonly-used PTQ methods. We aim to answer several research
questions related to the influence of calibration set distribution variations,
calibration paradigm selection, and data augmentation or sampling strategies on
PTQ reliability. A systematic evaluation process is conducted across a wide
range of tasks and commonly-used PTQ paradigms. The results show that most
existing PTQ methods are not reliable enough in term of the worst-case group
performance, highlighting the need for more robust methods. Our findings
provide insights for developing PTQ methods that can effectively handle
distribution shift scenarios and enable the deployment of quantized DNNs in
real-world applications.
</p></li>
</ul>

<h3>Title: Top-Down Visual Attention from Analysis by Synthesis. (arXiv:2303.13043v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2303.13043">http://arxiv.org/abs/2303.13043</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2303.13043] Top-Down Visual Attention from Analysis by Synthesis](http://arxiv.org/abs/2303.13043) #robust</code></li>
<li>Summary: <p>Current attention algorithms (e.g., self-attention) are stimulus-driven and
highlight all the salient objects in an image. However, intelligent agents like
humans often guide their attention based on the high-level task at hand,
focusing only on task-related objects. This ability of task-guided top-down
attention provides task-adaptive representation and helps the model generalize
to various tasks. In this paper, we consider top-down attention from a classic
Analysis-by-Synthesis (AbS) perspective of vision. Prior work indicates a
functional equivalence between visual attention and sparse reconstruction; we
show that an AbS visual system that optimizes a similar sparse reconstruction
objective modulated by a goal-directed top-down signal naturally simulates
top-down attention. We further propose Analysis-by-Synthesis Vision Transformer
(AbSViT), which is a top-down modulated ViT model that variationally
approximates AbS, and achieves controllable top-down attention. For real-world
applications, AbSViT consistently improves over baselines on Vision-Language
tasks such as VQA and zero-shot retrieval where language guides the top-down
attention. AbSViT can also serve as a general backbone, improving performance
on classification, semantic segmentation, and model robustness.
</p></li>
</ul>

<h3>Title: PanoHead: Geometry-Aware 3D Full-Head Synthesis in 360$^{\circ}$. (arXiv:2303.13071v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2303.13071">http://arxiv.org/abs/2303.13071</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2303.13071] PanoHead: Geometry-Aware 3D Full-Head Synthesis in 360$^{\circ}$](http://arxiv.org/abs/2303.13071) #robust</code></li>
<li>Summary: <p>Synthesis and reconstruction of 3D human head has gained increasing interests
in computer vision and computer graphics recently. Existing state-of-the-art 3D
generative adversarial networks (GANs) for 3D human head synthesis are either
limited to near-frontal views or hard to preserve 3D consistency in large view
angles. We propose PanoHead, the first 3D-aware generative model that enables
high-quality view-consistent image synthesis of full heads in $360^\circ$ with
diverse appearance and detailed geometry using only in-the-wild unstructured
images for training. At its core, we lift up the representation power of recent
3D GANs and bridge the data alignment gap when training from in-the-wild images
with widely distributed views. Specifically, we propose a novel two-stage
self-adaptive image alignment for robust 3D GAN training. We further introduce
a tri-grid neural volume representation that effectively addresses front-face
and back-head feature entanglement rooted in the widely-adopted tri-plane
formulation. Our method instills prior knowledge of 2D image segmentation in
adversarial learning of 3D neural scene structures, enabling compositable head
synthesis in diverse backgrounds. Benefiting from these designs, our method
significantly outperforms previous 3D GANs, generating high-quality 3D heads
with accurate geometry and diverse appearances, even with long wavy and afro
hairstyles, renderable from arbitrary poses. Furthermore, we show that our
system can reconstruct full 3D heads from single input images for personalized
realistic 3D avatars.
</p></li>
</ul>

<h3>Title: Robust Generalization against Photon-Limited Corruptions via Worst-Case Sharpness Minimization. (arXiv:2303.13087v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2303.13087">http://arxiv.org/abs/2303.13087</a></li>
<li>Code URL: <a href="https://github.com/zhuohuangai/sharpdro">https://github.com/zhuohuangai/sharpdro</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2303.13087] Robust Generalization against Photon-Limited Corruptions via Worst-Case Sharpness Minimization](http://arxiv.org/abs/2303.13087) #robust</code></li>
<li>Summary: <p>Robust generalization aims to tackle the most challenging data distributions
which are rare in the training set and contain severe noises, i.e.,
photon-limited corruptions. Common solutions such as distributionally robust
optimization (DRO) focus on the worst-case empirical risk to ensure low
training error on the uncommon noisy distributions. However, due to the
over-parameterized model being optimized on scarce worst-case data, DRO fails
to produce a smooth loss landscape, thus struggling on generalizing well to the
test set. Therefore, instead of focusing on the worst-case risk minimization,
we propose SharpDRO by penalizing the sharpness of the worst-case distribution,
which measures the loss changes around the neighbor of learning parameters.
Through worst-case sharpness minimization, the proposed method successfully
produces a flat loss curve on the corrupted distributions, thus achieving
robust generalization. Moreover, by considering whether the distribution
annotation is available, we apply SharpDRO to two problem settings and design a
worst-case selection process for robust generalization. Theoretically, we show
that SharpDRO has a great convergence guarantee. Experimentally, we simulate
photon-limited corruptions using CIFAR10/100 and ImageNet30 datasets and show
that SharpDRO exhibits a strong generalization ability against severe
corruptions and exceeds well-known baseline methods with large performance
gains.
</p></li>
</ul>

<h3>Title: CP$^3$: Channel Pruning Plug-in for Point-based Networks. (arXiv:2303.13097v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2303.13097">http://arxiv.org/abs/2303.13097</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2303.13097] CP$^3$: Channel Pruning Plug-in for Point-based Networks](http://arxiv.org/abs/2303.13097) #robust</code></li>
<li>Summary: <p>Channel pruning can effectively reduce both computational cost and memory
footprint of the original network while keeping a comparable accuracy
performance. Though great success has been achieved in channel pruning for 2D
image-based convolutional networks (CNNs), existing works seldom extend the
channel pruning methods to 3D point-based neural networks (PNNs). Directly
implementing the 2D CNN channel pruning methods to PNNs undermine the
performance of PNNs because of the different representations of 2D images and
3D point clouds as well as the network architecture disparity. In this paper,
we proposed CP$^3$, which is a Channel Pruning Plug-in for Point-based network.
CP$^3$ is elaborately designed to leverage the characteristics of point clouds
and PNNs in order to enable 2D channel pruning methods for PNNs. Specifically,
it presents a coordinate-enhanced channel importance metric to reflect the
correlation between dimensional information and individual channel features,
and it recycles the discarded points in PNN's sampling process and reconsiders
their potentially-exclusive information to enhance the robustness of channel
pruning. Experiments on various PNN architectures show that CP$^3$ constantly
improves state-of-the-art 2D CNN pruning approaches on different point cloud
tasks. For instance, our compressed PointNeXt-S on ScanObjectNN achieves an
accuracy of 88.52% with a pruning rate of 57.8%, outperforming the baseline
pruning methods with an accuracy gain of 1.94%.
</p></li>
</ul>

<h3>Title: Laplacian Segmentation Networks: Improved Epistemic Uncertainty from Spatial Aleatoric Uncertainty. (arXiv:2303.13123v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2303.13123">http://arxiv.org/abs/2303.13123</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2303.13123] Laplacian Segmentation Networks: Improved Epistemic Uncertainty from Spatial Aleatoric Uncertainty](http://arxiv.org/abs/2303.13123) #robust</code></li>
<li>Summary: <p>Out of distribution (OOD) medical images are frequently encountered, e.g.
because of site- or scanner differences, or image corruption. OOD images come
with a risk of incorrect image segmentation, potentially negatively affecting
downstream diagnoses or treatment. To ensure robustness to such incorrect
segmentations, we propose Laplacian Segmentation Networks (LSN) that jointly
model epistemic (model) and aleatoric (data) uncertainty in image segmentation.
We capture data uncertainty with a spatially correlated logit distribution. For
model uncertainty, we propose the first Laplace approximation of the weight
posterior that scales to large neural networks with skip connections that have
high-dimensional outputs. Empirically, we demonstrate that modelling spatial
pixel correlation allows the Laplacian Segmentation Network to successfully
assign high epistemic uncertainty to out-of-distribution objects appearing
within images.
</p></li>
</ul>

<h3>Title: Calibrated Out-of-Distribution Detection with a Generic Representation. (arXiv:2303.13148v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2303.13148">http://arxiv.org/abs/2303.13148</a></li>
<li>Code URL: <a href="https://github.com/vojirt/grood">https://github.com/vojirt/grood</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2303.13148] Calibrated Out-of-Distribution Detection with a Generic Representation](http://arxiv.org/abs/2303.13148) #robust</code></li>
<li>Summary: <p>Out-of-distribution detection is a common issue in deploying vision models in
practice and solving it is an essential building block in safety critical
applications. Existing OOD detection solutions focus on improving the OOD
robustness of a classification model trained exclusively on in-distribution
(ID) data. In this work, we take a different approach and propose to leverage
generic pre-trained representations. We first investigate the behaviour of
simple classifiers built on top of such representations and show striking
performance gains compared to the ID trained representations. We propose a
novel OOD method, called GROOD, that achieves excellent performance, predicated
by the use of a good generic representation. Only a trivial training process is
required for adapting GROOD to a particular problem. The method is simple,
general, efficient, calibrated and with only a few hyper-parameters. The method
achieves state-of-the-art performance on a number of OOD benchmarks, reaching
near perfect performance on several of them. The source code is available at
https://github.com/vojirt/GROOD.
</p></li>
</ul>

<h3>Title: VADER: Video Alignment Differencing and Retrieval. (arXiv:2303.13193v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2303.13193">http://arxiv.org/abs/2303.13193</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2303.13193] VADER: Video Alignment Differencing and Retrieval](http://arxiv.org/abs/2303.13193) #robust</code></li>
<li>Summary: <p>We propose VADER, a spatio-temporal matching, alignment, and change
summarization method to help fight misinformation spread via manipulated
videos. VADER matches and coarsely aligns partial video fragments to candidate
videos using a robust visual descriptor and scalable search over adaptively
chunked video content. A transformer-based alignment module then refines the
temporal localization of the query fragment within the matched video. A
space-time comparator module identifies regions of manipulation between aligned
content, invariant to any changes due to any residual temporal misalignments or
artifacts arising from non-editorial changes of the content. Robustly matching
video to a trusted source enables conclusions to be drawn on video provenance,
enabling informed trust decisions on content encountered.
</p></li>
</ul>

<h3>Title: Transforming Radiance Field with Lipschitz Network for Photorealistic 3D Scene Stylization. (arXiv:2303.13232v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2303.13232">http://arxiv.org/abs/2303.13232</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2303.13232] Transforming Radiance Field with Lipschitz Network for Photorealistic 3D Scene Stylization](http://arxiv.org/abs/2303.13232) #robust</code></li>
<li>Summary: <p>Recent advances in 3D scene representation and novel view synthesis have
witnessed the rise of Neural Radiance Fields (NeRFs). Nevertheless, it is not
trivial to exploit NeRF for the photorealistic 3D scene stylization task, which
aims to generate visually consistent and photorealistic stylized scenes from
novel views. Simply coupling NeRF with photorealistic style transfer (PST) will
result in cross-view inconsistency and degradation of stylized view syntheses.
Through a thorough analysis, we demonstrate that this non-trivial task can be
simplified in a new light: When transforming the appearance representation of a
pre-trained NeRF with Lipschitz mapping, the consistency and photorealism
across source views will be seamlessly encoded into the syntheses. That
motivates us to build a concise and flexible learning framework namely LipRF,
which upgrades arbitrary 2D PST methods with Lipschitz mapping tailored for the
3D scene. Technically, LipRF first pre-trains a radiance field to reconstruct
the 3D scene, and then emulates the style on each view by 2D PST as the prior
to learn a Lipschitz network to stylize the pre-trained appearance. In view of
that Lipschitz condition highly impacts the expressivity of the neural network,
we devise an adaptive regularization to balance the reconstruction and
stylization. A gradual gradient aggregation strategy is further introduced to
optimize LipRF in a cost-efficient manner. We conduct extensive experiments to
show the high quality and robust performance of LipRF on both photorealistic 3D
stylization and object appearance editing.
</p></li>
</ul>

<h3>Title: Optimization and Optimizers for Adversarial Robustness. (arXiv:2303.13401v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2303.13401">http://arxiv.org/abs/2303.13401</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2303.13401] Optimization and Optimizers for Adversarial Robustness](http://arxiv.org/abs/2303.13401) #robust</code></li>
<li>Summary: <p>Empirical robustness evaluation (RE) of deep learning models against
adversarial perturbations entails solving nontrivial constrained optimization
problems. Existing numerical algorithms that are commonly used to solve them in
practice predominantly rely on projected gradient, and mostly handle
perturbations modeled by the $\ell_1$, $\ell_2$ and $\ell_\infty$ distances. In
this paper, we introduce a novel algorithmic framework that blends a
general-purpose constrained-optimization solver PyGRANSO with Constraint
Folding (PWCF), which can add more reliability and generality to the
state-of-the-art RE packages, e.g., AutoAttack. Regarding reliability, PWCF
provides solutions with stationarity measures and feasibility tests to assess
the solution quality. For generality, PWCF can handle perturbation models that
are typically inaccessible to the existing projected gradient methods; the main
requirement is the distance metric to be almost everywhere differentiable.
Taking advantage of PWCF and other existing numerical algorithms, we further
explore the distinct patterns in the solutions found for solving these
optimization problems using various combinations of losses, perturbation
models, and optimization algorithms. We then discuss the implications of these
patterns on the current robustness evaluation and adversarial training.
</p></li>
</ul>

<h3>Title: Egocentric Audio-Visual Object Localization. (arXiv:2303.13471v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2303.13471">http://arxiv.org/abs/2303.13471</a></li>
<li>Code URL: <a href="https://github.com/wikichao/ego-av-loc">https://github.com/wikichao/ego-av-loc</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2303.13471] Egocentric Audio-Visual Object Localization](http://arxiv.org/abs/2303.13471) #robust</code></li>
<li>Summary: <p>Humans naturally perceive surrounding scenes by unifying sound and sight in a
first-person view. Likewise, machines are advanced to approach human
intelligence by learning with multisensory inputs from an egocentric
perspective. In this paper, we explore the challenging egocentric audio-visual
object localization task and observe that 1) egomotion commonly exists in
first-person recordings, even within a short duration; 2) The out-of-view sound
components can be created while wearers shift their attention. To address the
first problem, we propose a geometry-aware temporal aggregation module to
handle the egomotion explicitly. The effect of egomotion is mitigated by
estimating the temporal geometry transformation and exploiting it to update
visual representations. Moreover, we propose a cascaded feature enhancement
module to tackle the second issue. It improves cross-modal localization
robustness by disentangling visually-indicated audio representation. During
training, we take advantage of the naturally available audio-visual temporal
synchronization as the ``free'' self-supervision to avoid costly labeling. We
also annotate and create the Epic Sounding Object dataset for evaluation
purposes. Extensive experiments show that our method achieves state-of-the-art
localization performance in egocentric videos and can be generalized to diverse
audio-visual scenes.
</p></li>
</ul>

<h3>Title: Position-Guided Point Cloud Panoptic Segmentation Transformer. (arXiv:2303.13509v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2303.13509">http://arxiv.org/abs/2303.13509</a></li>
<li>Code URL: <a href="https://github.com/smartbot-pjlab/p3former">https://github.com/smartbot-pjlab/p3former</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2303.13509] Position-Guided Point Cloud Panoptic Segmentation Transformer](http://arxiv.org/abs/2303.13509) #robust</code></li>
<li>Summary: <p>DEtection TRansformer (DETR) started a trend that uses a group of learnable
queries for unified visual perception. This work begins by applying this
appealing paradigm to LiDAR-based point cloud segmentation and obtains a simple
yet effective baseline. Although the naive adaptation obtains fair results, the
instance segmentation performance is noticeably inferior to previous works. By
diving into the details, we observe that instances in the sparse point clouds
are relatively small to the whole scene and often have similar geometry but
lack distinctive appearance for segmentation, which are rare in the image
domain. Considering instances in 3D are more featured by their positional
information, we emphasize their roles during the modeling and design a robust
Mixed-parameterized Positional Embedding (MPE) to guide the segmentation
process. It is embedded into backbone features and later guides the mask
prediction and query update processes iteratively, leading to Position-Aware
Segmentation (PA-Seg) and Masked Focal Attention (MFA). All these designs impel
the queries to attend to specific regions and identify various instances. The
method, named Position-guided Point cloud Panoptic segmentation transFormer
(P3Former), outperforms previous state-of-the-art methods by 3.4% and 1.2% PQ
on SemanticKITTI and nuScenes benchmark, respectively. The source code and
models are available at https://github.com/SmartBot-PJLab/P3Former .
</p></li>
</ul>

<h3>Title: Towards Understanding the Generalization of Medical Text-to-SQL Models and Datasets. (arXiv:2303.12898v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2303.12898">http://arxiv.org/abs/2303.12898</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2303.12898] Towards Understanding the Generalization of Medical Text-to-SQL Models and Datasets](http://arxiv.org/abs/2303.12898) #robust</code></li>
<li>Summary: <p>Electronic medical records (EMRs) are stored in relational databases. It can
be challenging to access the required information if the user is unfamiliar
with the database schema or general database fundamentals. Hence, researchers
have explored text-to-SQL generation methods that provide healthcare
professionals direct access to EMR data without needing a database expert.
However, currently available datasets have been essentially "solved" with
state-of-the-art models achieving accuracy greater than or near 90%. In this
paper, we show that there is still a long way to go before solving text-to-SQL
generation in the medical domain. To show this, we create new splits of the
existing medical text-to-SQL dataset MIMICSQL that better measure the
generalizability of the resulting models. We evaluate state-of-the-art language
models on our new split showing substantial drops in performance with accuracy
dropping from up to 92% to 28%, thus showing substantial room for improvement.
Moreover, we introduce a novel data augmentation approach to improve the
generalizability of the language models. Overall, this paper is the first step
towards developing more robust text-to-SQL models in the medical
domain.\footnote{The dataset and code will be released upon acceptance.
</p></li>
</ul>

<h3>Title: Analyzing the Generalizability of Deep Contextualized Language Representations For Text Classification. (arXiv:2303.12936v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2303.12936">http://arxiv.org/abs/2303.12936</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2303.12936] Analyzing the Generalizability of Deep Contextualized Language Representations For Text Classification](http://arxiv.org/abs/2303.12936) #robust</code></li>
<li>Summary: <p>This study evaluates the robustness of two state-of-the-art deep contextual
language representations, ELMo and DistilBERT, on supervised learning of binary
protest news classification and sentiment analysis of product reviews. A
"cross-context" setting is enabled using test sets that are distinct from the
training data. Specifically, in the news classification task, the models are
developed on local news from India and tested on the local news from China. In
the sentiment analysis task, the models are trained on movie reviews and tested
on customer reviews. This comparison is aimed at exploring the limits of the
representative power of today's Natural Language Processing systems on the path
to the systems that are generalizable to real-life scenarios. The models are
fine-tuned and fed into a Feed-Forward Neural Network and a Bidirectional Long
Short Term Memory network. Multinomial Naive Bayes and Linear Support Vector
Machine are used as traditional baselines. The results show that, in binary
text classification, DistilBERT is significantly better than ELMo on
generalizing to the cross-context setting. ELMo is observed to be significantly
more robust to the cross-context test data than both baselines. On the other
hand, the baselines performed comparably well to ELMo when the training and
test data are subsets of the same corpus (no cross-context). DistilBERT is also
found to be 30% smaller and 83% faster than ELMo. The results suggest that
DistilBERT can transfer generic semantic knowledge to other domains better than
ELMo. DistilBERT is also favorable in incorporating into real-life systems for
it requires a smaller computational training budget. When generalization is not
the utmost preference and test domain is similar to the training domain, the
traditional ML algorithms can still be considered as more economic alternatives
to deep language representations.
</p></li>
</ul>

<h3>Title: Adversarial Robustness of Learning-based Static Malware Classifiers. (arXiv:2303.13372v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2303.13372">http://arxiv.org/abs/2303.13372</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2303.13372] Adversarial Robustness of Learning-based Static Malware Classifiers](http://arxiv.org/abs/2303.13372) #robust</code></li>
<li>Summary: <p>Malware detection has long been a stage for an ongoing arms race between
malware authors and anti-virus systems. Solutions that utilize machine learning
(ML) gain traction as the scale of this arms race increases. This trend,
however, makes performing attacks directly on ML an attractive prospect for
adversaries. We study this arms race from both perspectives in the context of
MalConv, a popular convolutional neural network-based malware classifier that
operates on raw bytes of files. First, we show that MalConv is vulnerable to
adversarial patch attacks: appending a byte-level patch to malware files
bypasses detection 94.3% of the time. Moreover, we develop a universal
adversarial patch (UAP) attack where a single patch can drop the detection rate
in constant time of any malware file that contains it by 80%. These patches are
effective even being relatively small with respect to the original file size --
between 2%-8%. As a countermeasure, we then perform window ablation that allows
us to apply de-randomized smoothing, a modern certified defense to patch
attacks in vision tasks, to raw files. The resulting `smoothed-MalConv' can
detect over 80% of malware that contains the universal patch and provides
certified robustness up to 66%, outlining a promising step towards robust
malware detection. To our knowledge, we are the first to apply universal
adversarial patch attack and certified defense using ablations on byte level in
the malware field.
</p></li>
</ul>

<h3>Title: Robust Consensus in Ranking Data Analysis: Definitions, Properties and Computational Issues. (arXiv:2303.12878v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2303.12878">http://arxiv.org/abs/2303.12878</a></li>
<li>Code URL: <a href="https://github.com/robustconsensusranking/robustconsensusranking">https://github.com/robustconsensusranking/robustconsensusranking</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2303.12878] Robust Consensus in Ranking Data Analysis: Definitions, Properties and Computational Issues](http://arxiv.org/abs/2303.12878) #robust</code></li>
<li>Summary: <p>As the issue of robustness in AI systems becomes vital, statistical learning
techniques that are reliable even in presence of partly contaminated data have
to be developed. Preference data, in the form of (complete) rankings in the
simplest situations, are no exception and the demand for appropriate concepts
and tools is all the more pressing given that technologies fed by or producing
this type of data (e.g. search engines, recommending systems) are now massively
deployed. However, the lack of vector space structure for the set of rankings
(i.e. the symmetric group $\mathfrak{S}_n$) and the complex nature of
statistics considered in ranking data analysis make the formulation of
robustness objectives in this domain challenging. In this paper, we introduce
notions of robustness, together with dedicated statistical methods, for
Consensus Ranking the flagship problem in ranking data analysis, aiming at
summarizing a probability distribution on $\mathfrak{S}_n$ by a median ranking.
Precisely, we propose specific extensions of the popular concept of breakdown
point, tailored to consensus ranking, and address the related computational
issues. Beyond the theoretical contributions, the relevance of the approach
proposed is supported by an experimental study.
</p></li>
</ul>

<h3>Title: Revisiting the Fragility of Influence Functions. (arXiv:2303.12922v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2303.12922">http://arxiv.org/abs/2303.12922</a></li>
<li>Code URL: <a href="https://github.com/jrepifano/xai_is_fragile">https://github.com/jrepifano/xai_is_fragile</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2303.12922] Revisiting the Fragility of Influence Functions](http://arxiv.org/abs/2303.12922) #robust</code></li>
<li>Summary: <p>In the last few years, many works have tried to explain the predictions of
deep learning models. Few methods, however, have been proposed to verify the
accuracy or faithfulness of these explanations. Recently, influence functions,
which is a method that approximates the effect that leave-one-out training has
on the loss function, has been shown to be fragile. The proposed reason for
their fragility remains unclear. Although previous work suggests the use of
regularization to increase robustness, this does not hold in all cases. In this
work, we seek to investigate the experiments performed in the prior work in an
effort to understand the underlying mechanisms of influence function fragility.
First, we verify influence functions using procedures from the literature under
conditions where the convexity assumptions of influence functions are met.
Then, we relax these assumptions and study the effects of non-convexity by
using deeper models and more complex datasets. Here, we analyze the key metrics
and procedures that are used to validate influence functions. Our results
indicate that the validation procedures may cause the observed fragility.
</p></li>
</ul>

<h3>Title: A Closer Look at Model Adaptation using Feature Distortion and Simplicity Bias. (arXiv:2303.13500v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2303.13500">http://arxiv.org/abs/2303.13500</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2303.13500] A Closer Look at Model Adaptation using Feature Distortion and Simplicity Bias](http://arxiv.org/abs/2303.13500) #robust</code></li>
<li>Summary: <p>Advances in the expressivity of pretrained models have increased interest in
the design of adaptation protocols which enable safe and effective transfer
learning. Going beyond conventional linear probing (LP) and fine tuning (FT)
strategies, protocols that can effectively control feature distortion, i.e.,
the failure to update features orthogonal to the in-distribution, have been
found to achieve improved out-of-distribution generalization (OOD). In order to
limit this distortion, the LP+FT protocol, which first learns a linear probe
and then uses this initialization for subsequent FT, was proposed. However, in
this paper, we find when adaptation protocols (LP, FT, LP+FT) are also
evaluated on a variety of safety objectives (e.g., calibration, robustness,
etc.), a complementary perspective to feature distortion is helpful to explain
protocol behavior. To this end, we study the susceptibility of protocols to
simplicity bias (SB), i.e. the well-known propensity of deep neural networks to
rely upon simple features, as SB has recently been shown to underlie several
problems in robust generalization. Using a synthetic dataset, we demonstrate
the susceptibility of existing protocols to SB. Given the strong effectiveness
of LP+FT, we then propose modified linear probes that help mitigate SB, and
lead to better initializations for subsequent FT. We verify the effectiveness
of the proposed LP+FT variants for decreasing SB in a controlled setting, and
their ability to improve OOD generalization and safety on three adaptation
datasets.
</p></li>
</ul>

<h2>biometric</h2>
<h3>Title: Considerations on the Evaluation of Biometric Quality Assessment Algorithms. (arXiv:2303.13294v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2303.13294">http://arxiv.org/abs/2303.13294</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2303.13294] Considerations on the Evaluation of Biometric Quality Assessment Algorithms](http://arxiv.org/abs/2303.13294) #biometric</code></li>
<li>Summary: <p>Quality assessment algorithms can be used to estimate the utility of a
biometric sample for the purpose of biometric recognition. "Error versus
Discard Characteristic" (EDC) plots, and "partial Area Under Curve" (pAUC)
values of curves therein, are generally used by researchers to evaluate the
predictive performance of such quality assessment algorithms. An EDC curve
depends on an error type such as the "False Non Match Rate" (FNMR), a quality
assessment algorithm, a biometric recognition system, a set of comparisons each
corresponding to a biometric sample pair, and a comparison score threshold
corresponding to a starting error. To compute an EDC curve, comparisons are
progressively discarded based on the associated samples' lowest quality scores,
and the error is computed for the remaining comparisons. Additionally, a
discard fraction limit or range must be selected to compute pAUC values, which
can then be used to quantitatively rank quality assessment algorithms.
</p></li>
</ul>

<p>This paper discusses and analyses various details for this kind of quality
assessment algorithm evaluation, including general EDC properties,
interpretability improvements for pAUC values based on a hard lower error limit
and a soft upper error limit, the use of relative instead of discrete rankings,
stepwise vs. linear curve interpolation, and normalisation of quality scores to
a [0, 100] integer range. We also analyse the stability of quantitative quality
assessment algorithm rankings based on pAUC values across varying pAUC discard
fraction limits and starting errors, concluding that higher pAUC discard
fraction limits should be preferred. The analyses are conducted both with
synthetic data and with real data for a face image quality assessment scenario,
with a focus on general modality-independent conclusions for EDC evaluations.
</p>

<h2>steal</h2>
<h2>extraction</h2>
<h3>Title: Modeling Entities as Semantic Points for Visual Information Extraction in the Wild. (arXiv:2303.13095v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2303.13095">http://arxiv.org/abs/2303.13095</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2303.13095] Modeling Entities as Semantic Points for Visual Information Extraction in the Wild](http://arxiv.org/abs/2303.13095) #extraction</code></li>
<li>Summary: <p>Recently, Visual Information Extraction (VIE) has been becoming increasingly
important in both the academia and industry, due to the wide range of
real-world applications. Previously, numerous works have been proposed to
tackle this problem. However, the benchmarks used to assess these methods are
relatively plain, i.e., scenarios with real-world complexity are not fully
represented in these benchmarks. As the first contribution of this work, we
curate and release a new dataset for VIE, in which the document images are much
more challenging in that they are taken from real applications, and
difficulties such as blur, partial occlusion, and printing shift are quite
common. All these factors may lead to failures in information extraction.
Therefore, as the second contribution, we explore an alternative approach to
precisely and robustly extract key information from document images under such
tough conditions. Specifically, in contrast to previous methods, which usually
either incorporate visual information into a multi-modal architecture or train
text spotting and information extraction in an end-to-end fashion, we
explicitly model entities as semantic points, i.e., center points of entities
are enriched with semantic information describing the attributes and
relationships of different entities, which could largely benefit entity
labeling and linking. Extensive experiments on standard benchmarks in this
field as well as the proposed dataset demonstrate that the proposed method can
achieve significantly enhanced performance on entity labeling and linking,
compared with previous state-of-the-art models. Dataset is available at
https://www.modelscope.cn/datasets/damo/SIBR/summary.
</p></li>
</ul>

<h3>Title: Complementary Pseudo Multimodal Feature for Point Cloud Anomaly Detection. (arXiv:2303.13194v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2303.13194">http://arxiv.org/abs/2303.13194</a></li>
<li>Code URL: <a href="https://github.com/caoyunkang/CPMF">https://github.com/caoyunkang/CPMF</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2303.13194] Complementary Pseudo Multimodal Feature for Point Cloud Anomaly Detection](http://arxiv.org/abs/2303.13194) #extraction</code></li>
<li>Summary: <p>Point cloud (PCD) anomaly detection steadily emerges as a promising research
area. This study aims to improve PCD anomaly detection performance by combining
handcrafted PCD descriptions with powerful pre-trained 2D neural networks. To
this end, this study proposes Complementary Pseudo Multimodal Feature (CPMF)
that incorporates local geometrical information in 3D modality using
handcrafted PCD descriptors and global semantic information in the generated
pseudo 2D modality using pre-trained 2D neural networks. For global semantics
extraction, CPMF projects the origin PCD into a pseudo 2D modality containing
multi-view images. These images are delivered to pre-trained 2D neural networks
for informative 2D modality feature extraction. The 3D and 2D modality features
are aggregated to obtain the CPMF for PCD anomaly detection. Extensive
experiments demonstrate the complementary capacity between 2D and 3D modality
features and the effectiveness of CPMF, with 95.15% image-level AU-ROC and
92.93% pixel-level PRO on the MVTec3D benchmark. Code is available on
https://github.com/caoyunkang/CPMF.
</p></li>
</ul>

<h3>Title: Leveraging Foundation Models for Clinical Text Analysis. (arXiv:2303.13314v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2303.13314">http://arxiv.org/abs/2303.13314</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2303.13314] Leveraging Foundation Models for Clinical Text Analysis](http://arxiv.org/abs/2303.13314) #extraction</code></li>
<li>Summary: <p>Infectious diseases are a significant public health concern globally, and
extracting relevant information from scientific literature can facilitate the
development of effective prevention and treatment strategies. However, the
large amount of clinical data available presents a challenge for information
extraction. To address this challenge, this study proposes a natural language
processing (NLP) framework that uses a pre-trained transformer model fine-tuned
on task-specific data to extract key information related to infectious diseases
from free-text clinical data. The proposed framework includes three components:
a data layer for preparing datasets from clinical texts, a foundation model
layer for entity extraction, and an assessment layer for performance analysis.
The results of the evaluation indicate that the proposed method outperforms
standard methods, and leveraging prior knowledge through the pre-trained
transformer model makes it useful for investigating other infectious diseases
in the future.
</p></li>
</ul>

<h3>Title: W2KPE: Keyphrase Extraction with Word-Word Relation. (arXiv:2303.13463v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2303.13463">http://arxiv.org/abs/2303.13463</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2303.13463] W2KPE: Keyphrase Extraction with Word-Word Relation](http://arxiv.org/abs/2303.13463) #extraction</code></li>
<li>Summary: <p>This paper describes our submission to ICASSP 2023 MUG Challenge Track 4,
Keyphrase Extraction, which aims to extract keyphrases most relevant to the
conference theme from conference materials. We model the challenge as a
single-class Named Entity Recognition task and developed techniques for better
performance on the challenge: For the data preprocessing, we encode the split
keyphrases after word segmentation. In addition, we increase the amount of
input information that the model can accept at one time by fusing multiple
preprocessed sentences into one segment. We replace the loss function with the
multi-class focal loss to address the sparseness of keyphrases. Besides, we
score each appearance of keyphrases and add an extra output layer to fit the
score to rank keyphrases. Exhaustive evaluations are performed to find the best
combination of the word segmentation tool, the pre-trained embedding model, and
the corresponding hyperparameters. With these proposals, we scored 45.04 on the
final test set.
</p></li>
</ul>

<h3>Title: A Comparison of Graph Neural Networks for Malware Classification. (arXiv:2303.12812v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2303.12812">http://arxiv.org/abs/2303.12812</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2303.12812] A Comparison of Graph Neural Networks for Malware Classification](http://arxiv.org/abs/2303.12812) #extraction</code></li>
<li>Summary: <p>Managing the threat posed by malware requires accurate detection and
classification techniques. Traditional detection strategies, such as signature
scanning, rely on manual analysis of malware to extract relevant features,
which is labor intensive and requires expert knowledge. Function call graphs
consist of a set of program functions and their inter-procedural calls,
providing a rich source of information that can be leveraged to classify
malware without the labor intensive feature extraction step of traditional
techniques. In this research, we treat malware classification as a graph
classification problem. Based on Local Degree Profile features, we train a wide
range of Graph Neural Network (GNN) architectures to generate embeddings which
we then classify. We find that our best GNN models outperform previous
comparable research involving the well-known MalNet-Tiny Android malware
dataset. In addition, our GNN models do not suffer from the overfitting issues
that commonly afflict non-GNN techniques, although GNN models require longer
training times.
</p></li>
</ul>

<h2>membership infer</h2>
<h2>federate</h2>
<h3>Title: Use of Federated Learning and Blockchain towards Securing Financial Services. (arXiv:2303.12944v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2303.12944">http://arxiv.org/abs/2303.12944</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2303.12944] Use of Federated Learning and Blockchain towards Securing Financial Services](http://arxiv.org/abs/2303.12944) #federate</code></li>
<li>Summary: <p>In recent days, the proliferation of several existing and new cyber-attacks
pose an axiomatic threat to the stability of financial services. It is hard to
predict the nature of attacks that can trigger a serious financial crisis. The
unprecedented digital transformation to financial services has been accelerated
during the COVID-19 pandemic and it is still ongoing. Attackers are taking
advantage of this transformation and pose a new global threat to financial
stability and integrity. Many large organizations are switching from
centralized finance (CeFi) to decentralized finance (DeFi) because
decentralized finance has many advantages. Blockchain can bring big and
far-reaching effects on the trustworthiness, safety, accessibility,
cost-effectiveness, and openness of the financial sector. The present paper
gives an in-depth look at how blockchain and federated learning (FL) are used
in financial services. It starts with an overview of recent developments in
both use cases. This paper explores and discusses existing financial service
vulnerabilities, potential threats, and consequent risks. So, we explain the
problems that can be fixed in financial services and how blockchain and FL
could help solve them. These problems include data protection, storage
optimization, and making more money in financial services. We looked at many
blockchain-enabled FL methods and came up with some possible solutions that
could be used in financial services to solve several challenges like
cost-effectiveness, automation, and security control. Finally, we point out
some future directions at the end of this study.
</p></li>
</ul>

<h3>Title: Automated Federated Learning in Mobile Edge Networks -- Fast Adaptation and Convergence. (arXiv:2303.12999v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2303.12999">http://arxiv.org/abs/2303.12999</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2303.12999] Automated Federated Learning in Mobile Edge Networks -- Fast Adaptation and Convergence](http://arxiv.org/abs/2303.12999) #federate</code></li>
<li>Summary: <p>Federated Learning (FL) can be used in mobile edge networks to train machine
learning models in a distributed manner. Recently, FL has been interpreted
within a Model-Agnostic Meta-Learning (MAML) framework, which brings FL
significant advantages in fast adaptation and convergence over heterogeneous
datasets. However, existing research simply combines MAML and FL without
explicitly addressing how much benefit MAML brings to FL and how to maximize
such benefit over mobile edge networks. In this paper, we quantify the benefit
from two aspects: optimizing FL hyperparameters (i.e., sampled data size and
the number of communication rounds) and resource allocation (i.e., transmit
power) in mobile edge networks. Specifically, we formulate the MAML-based FL
design as an overall learning time minimization problem, under the constraints
of model accuracy and energy consumption. Facilitated by the convergence
analysis of MAML-based FL, we decompose the formulated problem and then solve
it using analytical solutions and the coordinate descent method. With the
obtained FL hyperparameters and resource allocation, we design a MAML-based FL
algorithm, called Automated Federated Learning (AutoFL), that is able to
conduct fast adaptation and convergence. Extensive experimental results verify
that AutoFL outperforms other benchmark algorithms regarding the learning time
and convergence performance.
</p></li>
</ul>

<h3>Title: FedGH: Heterogeneous Federated Learning with Generalized Global Header. (arXiv:2303.13137v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2303.13137">http://arxiv.org/abs/2303.13137</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2303.13137] FedGH: Heterogeneous Federated Learning with Generalized Global Header](http://arxiv.org/abs/2303.13137) #federate</code></li>
<li>Summary: <p>Federated learning (FL) is an emerging machine learning paradigm that allows
multiple parties to train a shared model collaboratively in a
privacy-preserving manner. Existing horizontal FL methods generally assume that
the FL server and clients hold the same model structure. However, due to system
heterogeneity and the need for personalization, enabling clients to hold models
with diverse structures has become an important direction. Existing
model-heterogeneous FL approaches often require publicly available datasets and
incur high communication and/or computational costs, which limit their
performances. To address these limitations, we propose the Federated Global
prediction Header (FedGH) approach. It is a communication and
computation-efficient model-heterogeneous FL framework which trains a shared
generalized global prediction header with representations extracted by
heterogeneous extractors for clients' models at the FL server. The trained
generalized global prediction header learns from different clients. The
acquired global knowledge is then transferred to clients to substitute each
client's local prediction header. We derive the non-convex convergence rate of
FedGH. Extensive experiments on two real-world datasets demonstrate that FedGH
achieves significantly more advantageous performance in both model-homogeneous
and -heterogeneous FL scenarios compared to seven state-of-the-art personalized
FL models, beating the best-performing baseline by up to 8.87% (for
model-homogeneous FL) and 1.83% (for model-heterogeneous FL) in terms of
average test accuracy, while saving up to 85.53% of communication overhead.
</p></li>
</ul>

<h3>Title: FS-Real: Towards Real-World Cross-Device Federated Learning. (arXiv:2303.13363v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2303.13363">http://arxiv.org/abs/2303.13363</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2303.13363] FS-Real: Towards Real-World Cross-Device Federated Learning](http://arxiv.org/abs/2303.13363) #federate</code></li>
<li>Summary: <p>Federated Learning (FL) aims to train high-quality models in collaboration
with distributed clients while not uploading their local data, which attracts
increasing attention in both academia and industry. However, there is still a
considerable gap between the flourishing FL research and real-world scenarios,
mainly caused by the characteristics of heterogeneous devices and its scales.
Most existing works conduct evaluations with homogeneous devices, which are
mismatched with the diversity and variability of heterogeneous devices in
real-world scenarios. Moreover, it is challenging to conduct research and
development at scale with heterogeneous devices due to limited resources and
complex software stacks. These two key factors are important yet underexplored
in FL research as they directly impact the FL training dynamics and final
performance, making the effectiveness and usability of FL algorithms unclear.
To bridge the gap, in this paper, we propose an efficient and scalable
prototyping system for real-world cross-device FL, FS-Real. It supports
heterogeneous device runtime, contains parallelism and robustness enhanced FL
server, and provides implementations and extensibility for advanced FL utility
features such as personalization, communication compression and asynchronous
aggregation. To demonstrate the usability and efficiency of FS-Real, we conduct
extensive experiments with various device distributions, quantify and analyze
the effect of the heterogeneous device and various scales, and further provide
insights and open discussions about real-world FL scenarios. Our system is
released to help to pave the way for further real-world FL research and broad
applications involving diverse devices and scales.
</p></li>
</ul>

<h2>fair</h2>
<h3>Title: Box-Level Active Detection. (arXiv:2303.13089v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2303.13089">http://arxiv.org/abs/2303.13089</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2303.13089] Box-Level Active Detection](http://arxiv.org/abs/2303.13089) #fair</code></li>
<li>Summary: <p>Active learning selects informative samples for annotation within budget,
which has proven efficient recently on object detection. However, the widely
used active detection benchmarks conduct image-level evaluation, which is
unrealistic in human workload estimation and biased towards crowded images.
Furthermore, existing methods still perform image-level annotation, but equally
scoring all targets within the same image incurs waste of budget and redundant
labels. Having revealed above problems and limitations, we introduce a
box-level active detection framework that controls a box-based budget per
cycle, prioritizes informative targets and avoids redundancy for fair
comparison and efficient application.
</p></li>
</ul>

<p>Under the proposed box-level setting, we devise a novel pipeline, namely
Complementary Pseudo Active Strategy (ComPAS). It exploits both human
annotations and the model intelligence in a complementary fashion: an efficient
input-end committee queries labels for informative objects only; meantime
well-learned targets are identified by the model and compensated with
pseudo-labels. ComPAS consistently outperforms 10 competitors under 4 settings
in a unified codebase. With supervision from labeled data only, it achieves
100% supervised performance of VOC0712 with merely 19% box annotations. On the
COCO dataset, it yields up to 4.3% mAP improvement over the second-best method.
ComPAS also supports training with the unlabeled pool, where it surpasses 90%
COCO supervised performance with 85% label reduction. Our source code is
publicly available at https://github.com/lyumengyao/blad.
</p>

<h3>Title: A Large-scale Study of Spatiotemporal Representation Learning with a New Benchmark on Action Recognition. (arXiv:2303.13505v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2303.13505">http://arxiv.org/abs/2303.13505</a></li>
<li>Code URL: <a href="https://github.com/andongdeng/bear">https://github.com/andongdeng/bear</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2303.13505] A Large-scale Study of Spatiotemporal Representation Learning with a New Benchmark on Action Recognition](http://arxiv.org/abs/2303.13505) #fair</code></li>
<li>Summary: <p>The goal of building a benchmark (suite of datasets) is to provide a unified
protocol for fair evaluation and thus facilitate the evolution of a specific
area. Nonetheless, we point out that existing protocols of action recognition
could yield partial evaluations due to several limitations. To comprehensively
probe the effectiveness of spatiotemporal representation learning, we introduce
BEAR, a new BEnchmark on video Action Recognition. BEAR is a collection of 18
video datasets grouped into 5 categories (anomaly, gesture, daily, sports, and
instructional), which covers a diverse set of real-world applications. With
BEAR, we thoroughly evaluate 6 common spatiotemporal models pre-trained by both
supervised and self-supervised learning. We also report transfer performance
via standard finetuning, few-shot finetuning, and unsupervised domain
adaptation. Our observation suggests that current state-of-the-art cannot
solidly guarantee high performance on datasets close to real-world
applications, and we hope BEAR can serve as a fair and challenging evaluation
benchmark to gain insights on building next-generation spatiotemporal learners.
Our dataset, code, and models are released at:
https://github.com/AndongDeng/BEAR
</p></li>
</ul>

<h3>Title: Fairness-guided Few-shot Prompting for Large Language Models. (arXiv:2303.13217v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2303.13217">http://arxiv.org/abs/2303.13217</a></li>
<li>Code URL: <a href="https://github.com/mahuanaaa/in_context_bloom">https://github.com/mahuanaaa/in_context_bloom</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2303.13217] Fairness-guided Few-shot Prompting for Large Language Models](http://arxiv.org/abs/2303.13217) #fair</code></li>
<li>Summary: <p>Large language models have demonstrated surprising ability to perform
in-context learning, i.e., these models can be directly applied to solve
numerous downstream tasks by conditioning on a prompt constructed by a few
input-output examples. However, prior research has shown that in-context
learning can suffer from high instability due to variations in training
examples, example order, and prompt formats. Therefore, the construction of an
appropriate prompt is essential for improving the performance of in-context
learning. In this paper, we revisit this problem from the view of predictive
bias. Specifically, we introduce a metric to evaluate the predictive bias of a
fixed prompt against labels or a given attributes. Then we empirically show
that prompts with higher bias always lead to unsatisfactory predictive quality.
Based on this observation, we propose a novel search strategy based on the
greedy search to identify the near-optimal prompt for improving the performance
of in-context learning. We perform comprehensive experiments with
state-of-the-art mainstream models such as GPT-3 on various downstream tasks.
Our results indicate that our method can enhance the model's in-context
learning performance in an effective and interpretable manner.
</p></li>
</ul>

<h2>interpretability</h2>
<h3>Title: Masked Image Training for Generalizable Deep Image Denoising. (arXiv:2303.13132v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2303.13132">http://arxiv.org/abs/2303.13132</a></li>
<li>Code URL: <a href="https://github.com/haoyuc/maskeddenoising">https://github.com/haoyuc/maskeddenoising</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2303.13132] Masked Image Training for Generalizable Deep Image Denoising](http://arxiv.org/abs/2303.13132) #interpretability</code></li>
<li>Summary: <p>When capturing and storing images, devices inevitably introduce noise.
Reducing this noise is a critical task called image denoising. Deep learning
has become the de facto method for image denoising, especially with the
emergence of Transformer-based models that have achieved notable
state-of-the-art results on various image tasks. However, deep learning-based
methods often suffer from a lack of generalization ability. For example, deep
models trained on Gaussian noise may perform poorly when tested on other noise
distributions. To address this issue, we present a novel approach to enhance
the generalization performance of denoising networks, known as masked training.
Our method involves masking random pixels of the input image and reconstructing
the missing information during training. We also mask out the features in the
self-attention layers to avoid the impact of training-testing inconsistency.
Our approach exhibits better generalization ability than other deep learning
models and is directly applicable to real-world scenarios. Additionally, our
interpretability analysis demonstrates the superiority of our method.
</p></li>
</ul>

<h3>Title: Take 5: Interpretable Image Classification with a Handful of Features. (arXiv:2303.13166v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2303.13166">http://arxiv.org/abs/2303.13166</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2303.13166] Take 5: Interpretable Image Classification with a Handful of Features](http://arxiv.org/abs/2303.13166) #interpretability</code></li>
<li>Summary: <p>Deep Neural Networks use thousands of mostly incomprehensible features to
identify a single class, a decision no human can follow. We propose an
interpretable sparse and low dimensional final decision layer in a deep neural
network with measurable aspects of interpretability and demonstrate it on
fine-grained image classification. We argue that a human can only understand
the decision of a machine learning model, if the features are interpretable and
only very few of them are used for a single decision. For that matter, the
final layer has to be sparse and, to make interpreting the features feasible,
low dimensional. We call a model with a Sparse Low-Dimensional Decision
SLDD-Model. We show that a SLDD-Model is easier to interpret locally and
globally than a dense high-dimensional decision layer while being able to
maintain competitive accuracy. Additionally, we propose a loss function that
improves a model's feature diversity and accuracy. Our more interpretable
SLDD-Model only uses 5 out of just 50 features per class, while maintaining 97%
to 100% of the accuracy on four common benchmark datasets compared to the
baseline model with 2048 features.
</p></li>
</ul>

<h3>Title: Leveraging Multi-time Hamilton-Jacobi PDEs for Certain Scientific Machine Learning Problems. (arXiv:2303.12928v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2303.12928">http://arxiv.org/abs/2303.12928</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2303.12928] Leveraging Multi-time Hamilton-Jacobi PDEs for Certain Scientific Machine Learning Problems](http://arxiv.org/abs/2303.12928) #interpretability</code></li>
<li>Summary: <p>Hamilton-Jacobi partial differential equations (HJ PDEs) have deep
connections with a wide range of fields, including optimal control,
differential games, and imaging sciences. By considering the time variable to
be a higher dimensional quantity, HJ PDEs can be extended to the multi-time
case. In this paper, we establish a novel theoretical connection between
specific optimization problems arising in machine learning and the multi-time
Hopf formula, which corresponds to a representation of the solution to certain
multi-time HJ PDEs. Through this connection, we increase the interpretability
of the training process of certain machine learning applications by showing
that when we solve these learning problems, we also solve a multi-time HJ PDE
and, by extension, its corresponding optimal control problem. As a first
exploration of this connection, we develop the relation between the regularized
linear regression problem and the Linear Quadratic Regulator (LQR). We then
leverage our theoretical connection to adapt standard LQR solvers (namely,
those based on the Riccati ordinary differential equations) to design new
training approaches for machine learning. Finally, we provide some numerical
examples that demonstrate the versatility and possible computational advantages
of our Riccati-based approach in the context of continual learning,
post-training calibration, transfer learning, and sparse dynamics
identification.
</p></li>
</ul>

<h2>explainability</h2>
<h3>Title: Xplainer: From X-Ray Observations to Explainable Zero-Shot Diagnosis. (arXiv:2303.13391v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2303.13391">http://arxiv.org/abs/2303.13391</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2303.13391] Xplainer: From X-Ray Observations to Explainable Zero-Shot Diagnosis](http://arxiv.org/abs/2303.13391) #explainability</code></li>
<li>Summary: <p>Automated diagnosis prediction from medical images is a valuable resource to
support clinical decision-making. However, such systems usually need to be
trained on large amounts of annotated data, which often is scarce in the
medical domain. Zero-shot methods address this challenge by allowing a flexible
adaption to new settings with different clinical findings without relying on
labeled data. Further, to integrate automated diagnosis in the clinical
workflow, methods should be transparent and explainable, increasing medical
professionals' trust and facilitating correctness verification. In this work,
we introduce Xplainer, a novel framework for explainable zero-shot diagnosis in
the clinical setting. Xplainer adapts the classification-by-description
approach of contrastive vision-language models to the multi-label medical
diagnosis task. Specifically, instead of directly predicting a diagnosis, we
prompt the model to classify the existence of descriptive observations, which a
radiologist would look for on an X-Ray scan, and use the descriptor
probabilities to estimate the likelihood of a diagnosis. Our model is
explainable by design, as the final diagnosis prediction is directly based on
the prediction of the underlying descriptors. We evaluate Xplainer on two chest
X-ray datasets, CheXpert and ChestX-ray14, and demonstrate its effectiveness in
improving the performance and explainability of zero-shot diagnosis. Our
results suggest that Xplainer provides a more detailed understanding of the
decision-making process and can be a valuable tool for clinical diagnosis.
</p></li>
</ul>

<h3>Title: Fault Prognosis of Turbofan Engines: Eventual Failure Prediction and Remaining Useful Life Estimation. (arXiv:2303.12982v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2303.12982">http://arxiv.org/abs/2303.12982</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2303.12982] Fault Prognosis of Turbofan Engines: Eventual Failure Prediction and Remaining Useful Life Estimation](http://arxiv.org/abs/2303.12982) #explainability</code></li>
<li>Summary: <p>In the era of industrial big data, prognostics and health management is
essential to improve the prediction of future failures to minimize inventory,
maintenance, and human costs. Used for the 2021 PHM Data Challenge, the new
Commercial Modular Aero-Propulsion System Simulation dataset from NASA is an
open-source benchmark containing simulated turbofan engine units flown under
realistic flight conditions. Deep learning approaches implemented previously
for this application attempt to predict the remaining useful life of the engine
units, but have not utilized labeled failure mode information, impeding
practical usage and explainability. To address these limitations, a new
prognostics approach is formulated with a customized loss function to
simultaneously predict the current health state, the eventual failing
component(s), and the remaining useful life. The proposed method incorporates
principal component analysis to orthogonalize statistical time-domain features,
which are inputs into supervised regressors such as random forests, extreme
random forests, XGBoost, and artificial neural networks. The highest performing
algorithm, ANN-Flux, achieves AUROC and AUPR scores exceeding 0.95 for each
classification. In addition, ANN-Flux reduces the remaining useful life RMSE by
38% for the same test split of the dataset compared to past work, with
significantly less computational cost.
</p></li>
</ul>

<h2>watermark</h2>
<h2>diffusion</h2>
<h3>Title: Controllable Inversion of Black-Box Face-Recognition Models via Diffusion. (arXiv:2303.13006v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2303.13006">http://arxiv.org/abs/2303.13006</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2303.13006] Controllable Inversion of Black-Box Face-Recognition Models via Diffusion](http://arxiv.org/abs/2303.13006) #diffusion</code></li>
<li>Summary: <p>Face recognition models embed a face image into a low-dimensional identity
vector containing abstract encodings of identity-specific facial features that
allow individuals to be distinguished from one another. We tackle the
challenging task of inverting the latent space of pre-trained face recognition
models without full model access (i.e. black-box setting). A variety of methods
have been proposed in literature for this task, but they have serious
shortcomings such as a lack of realistic outputs, long inference times, and
strong requirements for the data set and accessibility of the face recognition
model. Through an analysis of the black-box inversion problem, we show that the
conditional diffusion model loss naturally emerges and that we can effectively
sample from the inverse distribution even without an identity-specific loss.
Our method, named identity denoising diffusion probabilistic model (ID3PM),
leverages the stochastic nature of the denoising diffusion process to produce
high-quality, identity-preserving face images with various backgrounds,
lighting, poses, and expressions. We demonstrate state-of-the-art performance
in terms of identity preservation and diversity both qualitatively and
quantitatively. Our method is the first black-box face recognition model
inversion method that offers intuitive control over the generation process and
does not suffer from any of the common shortcomings from competing methods.
</p></li>
</ul>

<h3>Title: DiffPattern: Layout Pattern Generation via Discrete Diffusion. (arXiv:2303.13060v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2303.13060">http://arxiv.org/abs/2303.13060</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2303.13060] DiffPattern: Layout Pattern Generation via Discrete Diffusion](http://arxiv.org/abs/2303.13060) #diffusion</code></li>
<li>Summary: <p>Deep generative models dominate the existing literature in layout pattern
generation. However, leaving the guarantee of legality to an inexplicable
neural network could be problematic in several applications. In this paper, we
propose \tool{DiffPattern} to generate reliable layout patterns.
\tool{DiffPattern} introduces a novel diverse topology generation method via a
discrete diffusion model with compute-efficiently lossless layout pattern
representation. Then a white-box pattern assessment is utilized to generate
legal patterns given desired design rules. Our experiments on several benchmark
settings show that \tool{DiffPattern} significantly outperforms existing
baselines and is capable of synthesizing reliable layout patterns.
</p></li>
</ul>

<h3>Title: MagicFusion: Boosting Text-to-Image Generation Performance by Fusing Diffusion Models. (arXiv:2303.13126v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2303.13126">http://arxiv.org/abs/2303.13126</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2303.13126] MagicFusion: Boosting Text-to-Image Generation Performance by Fusing Diffusion Models](http://arxiv.org/abs/2303.13126) #diffusion</code></li>
<li>Summary: <p>The advent of open-source AI communities has produced a cornucopia of
powerful text-guided diffusion models that are trained on various datasets.
While few explorations have been conducted on ensembling such models to combine
their strengths. In this work, we propose a simple yet effective method called
Saliency-aware Noise Blending (SNB) that can empower the fused text-guided
diffusion models to achieve more controllable generation. Specifically, we
experimentally find that the responses of classifier-free guidance are highly
related to the saliency of generated images. Thus we propose to trust different
models in their areas of expertise by blending the predicted noises of two
diffusion models in a saliency-aware manner. SNB is training-free and can be
completed within a DDIM sampling process. Additionally, it can automatically
align the semantics of two noise spaces without requiring additional
annotations such as masks. Extensive experiments show the impressive
effectiveness of SNB in various applications. Project page is available at
https://magicfusion.github.io/.
</p></li>
</ul>

<h3>Title: DDT: A Diffusion-Driven Transformer-based Framework for Human Mesh Recovery from a Video. (arXiv:2303.13397v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2303.13397">http://arxiv.org/abs/2303.13397</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2303.13397] DDT: A Diffusion-Driven Transformer-based Framework for Human Mesh Recovery from a Video](http://arxiv.org/abs/2303.13397) #diffusion</code></li>
<li>Summary: <p>Human mesh recovery (HMR) provides rich human body information for various
real-world applications such as gaming, human-computer interaction, and virtual
reality. Compared to single image-based methods, video-based methods can
utilize temporal information to further improve performance by incorporating
human body motion priors. However, many-to-many approaches such as VIBE suffer
from motion smoothness and temporal inconsistency. While many-to-one approaches
such as TCMR and MPS-Net rely on the future frames, which is non-causal and
time inefficient during inference. To address these challenges, a novel
Diffusion-Driven Transformer-based framework (DDT) for video-based HMR is
presented. DDT is designed to decode specific motion patterns from the input
sequence, enhancing motion smoothness and temporal consistency. As a
many-to-many approach, the decoder of our DDT outputs the human mesh of all the
frames, making DDT more viable for real-world applications where time
efficiency is crucial and a causal model is desired. Extensive experiments are
conducted on the widely used datasets (Human3.6M, MPI-INF-3DHP, and 3DPW),
which demonstrated the effectiveness and efficiency of our DDT.
</p></li>
</ul>

<h3>Title: Medical diffusion on a budget: textual inversion for medical image generation. (arXiv:2303.13430v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2303.13430">http://arxiv.org/abs/2303.13430</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2303.13430] Medical diffusion on a budget: textual inversion for medical image generation](http://arxiv.org/abs/2303.13430) #diffusion</code></li>
<li>Summary: <p>Diffusion-based models for text-to-image generation have gained immense
popularity due to recent advancements in efficiency, accessibility, and
quality. Although it is becoming increasingly feasible to perform inference
with these systems using consumer-grade GPUs, training them from scratch still
requires access to large datasets and significant computational resources. In
the case of medical image generation, the availability of large, publicly
accessible datasets that include text reports is limited due to legal and
ethical concerns. While training a diffusion model on a private dataset may
address this issue, it is not always feasible for institutions lacking the
necessary computational resources. This work demonstrates that pre-trained
Stable Diffusion models, originally trained on natural images, can be adapted
to various medical imaging modalities by training text embeddings with textual
inversion. In this study, we conducted experiments using medical datasets
comprising only 100 samples from three medical modalities. Embeddings were
trained in a matter of hours, while still retaining diagnostic relevance in
image generation. Experiments were designed to achieve several objectives.
Firstly, we fine-tuned the training and inference processes of textual
inversion, revealing that larger embeddings and more examples are required.
Secondly, we validated our approach by demonstrating a 2\% increase in the
diagnostic accuracy (AUC) for detecting prostate cancer on MRI, which is a
challenging multi-modal imaging modality, from 0.78 to 0.80. Thirdly, we
performed simulations by interpolating between healthy and diseased states,
combining multiple pathologies, and inpainting to show embedding flexibility
and control of disease appearance. Finally, the embeddings trained in this
study are small (less than 1 MB), which facilitates easy sharing of medical
data with reduced privacy concerns.
</p></li>
</ul>

<h3>Title: Text2Video-Zero: Text-to-Image Diffusion Models are Zero-Shot Video Generators. (arXiv:2303.13439v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2303.13439">http://arxiv.org/abs/2303.13439</a></li>
<li>Code URL: <a href="https://github.com/picsart-ai-research/text2video-zero">https://github.com/picsart-ai-research/text2video-zero</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2303.13439] Text2Video-Zero: Text-to-Image Diffusion Models are Zero-Shot Video Generators](http://arxiv.org/abs/2303.13439) #diffusion</code></li>
<li>Summary: <p>Recent text-to-video generation approaches rely on computationally heavy
training and require large-scale video datasets. In this paper, we introduce a
new task of zero-shot text-to-video generation and propose a low-cost approach
(without any training or optimization) by leveraging the power of existing
text-to-image synthesis methods (e.g., Stable Diffusion), making them suitable
for the video domain.
</p></li>
</ul>

<p>Our key modifications include (i) enriching the latent codes of the generated
frames with motion dynamics to keep the global scene and the background time
consistent; and (ii) reprogramming frame-level self-attention using a new
cross-frame attention of each frame on the first frame, to preserve the
context, appearance, and identity of the foreground object.
</p>
<p>Experiments show that this leads to low overhead, yet high-quality and
remarkably consistent video generation. Moreover, our approach is not limited
to text-to-video synthesis but is also applicable to other tasks such as
conditional and content-specialized video generation, and Video
Instruct-Pix2Pix, i.e., instruction-guided video editing.
</p>
<p>As experiments show, our method performs comparably or sometimes better than
recent approaches, despite not being trained on additional video data. Our code
will be open sourced at: https://github.com/Picsart-AI-Research/Text2Video-Zero .
</p>

<h3>Title: ReVersion: Diffusion-Based Relation Inversion from Images. (arXiv:2303.13495v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2303.13495">http://arxiv.org/abs/2303.13495</a></li>
<li>Code URL: <a href="https://github.com/ziqihuangg/reversion">https://github.com/ziqihuangg/reversion</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2303.13495] ReVersion: Diffusion-Based Relation Inversion from Images](http://arxiv.org/abs/2303.13495) #diffusion</code></li>
<li>Summary: <p>Diffusion models gain increasing popularity for their generative
capabilities. Recently, there have been surging needs to generate customized
images by inverting diffusion models from exemplar images. However, existing
inversion methods mainly focus on capturing object appearances. How to invert
object relations, another important pillar in the visual world, remains
unexplored. In this work, we propose ReVersion for the Relation Inversion task,
which aims to learn a specific relation (represented as "relation prompt") from
exemplar images. Specifically, we learn a relation prompt from a frozen
pre-trained text-to-image diffusion model. The learned relation prompt can then
be applied to generate relation-specific images with new objects, backgrounds,
and styles. Our key insight is the "preposition prior" - real-world relation
prompts can be sparsely activated upon a set of basis prepositional words.
Specifically, we propose a novel relation-steering contrastive learning scheme
to impose two critical properties of the relation prompt: 1) The relation
prompt should capture the interaction between objects, enforced by the
preposition prior. 2) The relation prompt should be disentangled away from
object appearances. We further devise relation-focal importance sampling to
emphasize high-level interactions over low-level appearances (e.g., texture,
color). To comprehensively evaluate this new task, we contribute ReVersion
Benchmark, which provides various exemplar images with diverse relations.
Extensive experiments validate the superiority of our approach over existing
methods across a wide range of visual relations.
</p></li>
</ul>

<h3>Title: Ablating Concepts in Text-to-Image Diffusion Models. (arXiv:2303.13516v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2303.13516">http://arxiv.org/abs/2303.13516</a></li>
<li>Code URL: <a href="https://github.com/nupurkmr9/concept-ablation">https://github.com/nupurkmr9/concept-ablation</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2303.13516] Ablating Concepts in Text-to-Image Diffusion Models](http://arxiv.org/abs/2303.13516) #diffusion</code></li>
<li>Summary: <p>Large-scale text-to-image diffusion models can generate high-fidelity images
with powerful compositional ability. However, these models are typically
trained on an enormous amount of Internet data, often containing copyrighted
material, licensed images, and personal photos. Furthermore, they have been
found to replicate the style of various living artists or memorize exact
training samples. How can we remove such copyrighted concepts or images without
retraining the model from scratch? To achieve this goal, we propose an
efficient method of ablating concepts in the pretrained model, i.e., preventing
the generation of a target concept. Our algorithm learns to match the image
distribution for a target style, instance, or text prompt we wish to ablate to
the distribution corresponding to an anchor concept. This prevents the model
from generating target concepts given its text condition. Extensive experiments
show that our method can successfully prevent the generation of the ablated
concept while preserving closely related concepts in the model.
</p></li>
</ul>

<h3>Title: Variantional autoencoder with decremental information bottleneck for disentanglement. (arXiv:2303.12959v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2303.12959">http://arxiv.org/abs/2303.12959</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2303.12959] Variantional autoencoder with decremental information bottleneck for disentanglement](http://arxiv.org/abs/2303.12959) #diffusion</code></li>
<li>Summary: <p>One major challenge of disentanglement learning with variational autoencoders
is the trade-off between disentanglement and reconstruction fidelity. Previous
incremental methods with only on latent space cannot optimize these two targets
simultaneously, so they expand the Information Bottleneck while training to
{optimize from disentanglement to reconstruction. However, a large bottleneck
will lose the constraint of disentanglement, causing the information diffusion
problem. To tackle this issue, we present a novel decremental variational
autoencoder with disentanglement-invariant transformations to optimize multiple
objectives in different layers, termed DeVAE, for balancing disentanglement and
reconstruction fidelity by decreasing the information bottleneck of diverse
latent spaces gradually. Benefiting from the multiple latent spaces, DeVAE
allows simultaneous optimization of multiple objectives to optimize
reconstruction while keeping the constraint of disentanglement, avoiding
information diffusion. DeVAE is also compatible with large models with
high-dimension latent space. Experimental results on dSprites and Shapes3D that
DeVAE achieves \fix{R2q6}{a good balance between disentanglement and
reconstruction.DeVAE shows high tolerant of hyperparameters and on
high-dimensional latent spaces.
</p></li>
</ul>

<button id="copy">Copy All</button>
</article>
<script src="../../javascript/clipboard.min.js"></script>
<script src="../../javascript/clipboard.js"></script>
