<link rel="stylesheet" href="../../css/markdown.css" />
<article class="markdown-body">
<h2>secure</h2>
<h3>Title: Differentially Private Decentralized Deep Learning with Consensus Algorithms. (arXiv:2306.13892v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.13892">http://arxiv.org/abs/2306.13892</a></li>
<li>Code URL: <a href="https://github.com/jbayrooti/dp-dec-learning">https://github.com/jbayrooti/dp-dec-learning</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2306.13892] Differentially Private Decentralized Deep Learning with Consensus Algorithms](http://arxiv.org/abs/2306.13892) #secure</code></li>
<li>Summary: <p>Cooperative decentralized deep learning relies on direct information exchange
between communicating agents, each with access to a local dataset which should
be kept private. The goal is for all agents to achieve consensus on model
parameters after training. However, sharing parameters with untrustworthy
neighboring agents could leak exploitable information about local datasets. To
combat this, we introduce differentially private decentralized learning that
secures each agent's local dataset during and after cooperative training. In
our approach, we generalize Differentially Private Stochastic Gradient Descent
(DP-SGD) -- a popular differentially private training method for centralized
deep learning -- to practical subgradient- and ADMM-based decentralized
learning methods. Our algorithms' differential privacy guarantee holds for
arbitrary deep learning objective functions, and we analyze the convergence
properties for strongly convex objective functions. We compare our algorithms
against centrally trained models on standard classification tasks and evaluate
the relationships between performance, privacy budget, graph connectivity, and
degree of training data overlap among agents. We find that differentially
private gradient tracking is resistant to performance degradation under sparse
graphs and non-uniform data distributions. Furthermore, we show that it is
possible to learn a model achieving high accuracies, within 3% of DP-SGD on
MNIST under (1, 10^-5)-differential privacy and within 6% of DP-SGD on
CIFAR-100 under (10, 10^-5)-differential privacy, without ever sharing raw data
with other agents. Open source code can be found at:
https://github.com/jbayrooti/dp-dec-learning.
</p></li>
</ul>

<h2>security</h2>
<h3>Title: LLM-assisted Generation of Hardware Assertions. (arXiv:2306.14027v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.14027">http://arxiv.org/abs/2306.14027</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.14027] LLM-assisted Generation of Hardware Assertions](http://arxiv.org/abs/2306.14027) #security</code></li>
<li>Summary: <p>The security of computer systems typically relies on a hardware root of
trust. As vulnerabilities in hardware can have severe implications on a system,
there is a need for techniques to support security verification activities.
Assertion-based verification is a popular verification technique that involves
capturing design intent in a set of assertions that can be used in formal
verification or testing-based checking. However, writing security-centric
assertions is a challenging task. In this work, we investigate the use of
emerging large language models (LLMs) for code generation in hardware assertion
generation for security, where primarily natural language prompts, such as
those one would see as code comments in assertion files, are used to produce
SystemVerilog assertions. We focus our attention on a popular LLM and
characterize its ability to write assertions out of the box, given varying
levels of detail in the prompt. We design an evaluation framework that
generates a variety of prompts, and we create a benchmark suite comprising
real-world hardware designs and corresponding golden reference assertions that
we want to generate with the LLM.
</p></li>
</ul>

<h2>privacy</h2>
<h3>Title: MeciFace: Mechanomyography and Inertial Fusion based Glasses for Edge Real-Time Recognition of Facial and Eating Activities. (arXiv:2306.13674v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.13674">http://arxiv.org/abs/2306.13674</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.13674] MeciFace: Mechanomyography and Inertial Fusion based Glasses for Edge Real-Time Recognition of Facial and Eating Activities](http://arxiv.org/abs/2306.13674) #privacy</code></li>
<li>Summary: <p>We present MeciFace, a low-power (0.55 Watts), privacy-conscious, real-time
on-the-edge (RTE) wearable solution with a tiny memory footprint (11-19 KB),
designed to monitor facial expressions and eating activities. We employ
lightweight convolutional neural networks as the backbone models for both
facial and eating scenarios. The system yielded an F1-score of 86% for the RTE
evaluation in the facial expression case. In addition, we obtained an F1-score
of 90% for eating/drinking monitoring for the RTE of an unseen user.
</p></li>
</ul>

<h3>Title: Mobile-Cloud Inference for Collaborative Intelligence. (arXiv:2306.13982v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.13982">http://arxiv.org/abs/2306.13982</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.13982] Mobile-Cloud Inference for Collaborative Intelligence](http://arxiv.org/abs/2306.13982) #privacy</code></li>
<li>Summary: <p>As AI applications for mobile devices become more prevalent, there is an
increasing need for faster execution and lower energy consumption for deep
learning model inference. Historically, the models run on mobile devices have
been smaller and simpler in comparison to large state-of-the-art research
models, which can only run on the cloud. However, cloud-only inference has
drawbacks such as increased network bandwidth consumption and higher latency.
In addition, cloud-only inference requires the input data (images, audio) to be
fully transferred to the cloud, creating concerns about potential privacy
breaches.
</p></li>
</ul>

<p>There is an alternative approach: shared mobile-cloud inference. Partial
inference is performed on the mobile in order to reduce the dimensionality of
the input data and arrive at a compact feature tensor, which is a latent space
representation of the input signal. The feature tensor is then transmitted to
the server for further inference. This strategy can reduce inference latency,
energy consumption, and network bandwidth usage, as well as provide privacy
protection, because the original signal never leaves the mobile. Further
performance gain can be achieved by compressing the feature tensor before its
transmission.
</p>

<h3>Title: Adaptive Privacy Composition for Accuracy-first Mechanisms. (arXiv:2306.13824v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.13824">http://arxiv.org/abs/2306.13824</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.13824] Adaptive Privacy Composition for Accuracy-first Mechanisms](http://arxiv.org/abs/2306.13824) #privacy</code></li>
<li>Summary: <p>In many practical applications of differential privacy, practitioners seek to
provide the best privacy guarantees subject to a target level of accuracy. A
recent line of work by \cite{LigettNeRoWaWu17, WhitehouseWuRaRo22} has
developed such accuracy-first mechanisms by leveraging the idea of \emph{noise
reduction} that adds correlated noise to the sufficient statistic in a private
computation and produces a sequence of increasingly accurate answers. A major
advantage of noise reduction mechanisms is that the analysts only pay the
privacy cost of the least noisy or most accurate answer released. Despite this
appealing property in isolation, there has not been a systematic study on how
to use them in conjunction with other differentially private mechanisms. A
fundamental challenge is that the privacy guarantee for noise reduction
mechanisms is (necessarily) formulated as \emph{ex-post privacy} that bounds
the privacy loss as a function of the released outcome. Furthermore, there has
yet to be any study on how ex-post private mechanisms compose, which allows us
to track the accumulated privacy over several mechanisms. We develop privacy
filters \citep{RogersRoUlVa16, FeldmanZr21, WhitehouseRaRoWu22} that allow an
analyst to adaptively switch between differentially private and ex-post private
mechanisms subject to an overall privacy guarantee.
</p></li>
</ul>

<h3>Title: Locally Differentially Private Distributed Online Learning with Guaranteed Optimality. (arXiv:2306.14094v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.14094">http://arxiv.org/abs/2306.14094</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.14094] Locally Differentially Private Distributed Online Learning with Guaranteed Optimality](http://arxiv.org/abs/2306.14094) #privacy</code></li>
<li>Summary: <p>Distributed online learning is gaining increased traction due to its unique
ability to process large-scale datasets and streaming data. To address the
growing public awareness and concern on privacy protection, plenty of private
distributed online learning algorithms have been proposed, mostly based on
differential privacy which has emerged as the <code>gold standard" for privacy
protection. However, these algorithms often face the dilemma of trading
learning accuracy for privacy. By exploiting the unique characteristics of
online learning, this paper proposes an approach that tackles the dilemma and
ensures both differential privacy and learning accuracy in distributed online
learning. More specifically, while ensuring a diminishing expected
instantaneous regret, the approach can simultaneously ensure a finite
cumulative privacy budget, even on the infinite time horizon. To cater for the
fully distributed setting, we adopt the local differential-privacy framework
which avoids the reliance on a trusted data curator, and hence, provides
stronger protection than the classic</code>centralized" (global) differential
privacy. To the best of our knowledge, this is the first algorithm that
successfully ensures both rigorous local differential privacy and learning
accuracy. The effectiveness of the proposed algorithm is evaluated using
machine learning tasks, including logistic regression on the <code>Mushrooms" and</code>Covtype" datasets and CNN based image classification on the <code>MNIST" and</code>CIFAR-10" datasets.
</p></li>
</ul>

<h2>protect</h2>
<h2>defense</h2>
<h2>attack</h2>
<h3>Title: Deconstructing Classifiers: Towards A Data Reconstruction Attack Against Text Classification Models. (arXiv:2306.13789v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.13789">http://arxiv.org/abs/2306.13789</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.13789] Deconstructing Classifiers: Towards A Data Reconstruction Attack Against Text Classification Models](http://arxiv.org/abs/2306.13789) #attack</code></li>
<li>Summary: <p>Natural language processing (NLP) models have become increasingly popular in
real-world applications, such as text classification. However, they are
vulnerable to privacy attacks, including data reconstruction attacks that aim
to extract the data used to train the model. Most previous studies on data
reconstruction attacks have focused on LLM, while classification models were
assumed to be more secure. In this work, we propose a new targeted data
reconstruction attack called the Mix And Match attack, which takes advantage of
the fact that most classification models are based on LLM. The Mix And Match
attack uses the base model of the target model to generate candidate tokens and
then prunes them using the classification head. We extensively demonstrate the
effectiveness of the attack using both random and organic canaries. This work
highlights the importance of considering the privacy risks associated with data
reconstruction attacks in classification models and offers insights into
possible leakages.
</p></li>
</ul>

<h3>Title: Similarity Preserving Adversarial Graph Contrastive Learning. (arXiv:2306.13854v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.13854">http://arxiv.org/abs/2306.13854</a></li>
<li>Code URL: <a href="https://github.com/yeonjun-in/torch-sp-agcl">https://github.com/yeonjun-in/torch-sp-agcl</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2306.13854] Similarity Preserving Adversarial Graph Contrastive Learning](http://arxiv.org/abs/2306.13854) #attack</code></li>
<li>Summary: <p>Recent works demonstrate that GNN models are vulnerable to adversarial
attacks, which refer to imperceptible perturbation on the graph structure and
node features. Among various GNN models, graph contrastive learning (GCL) based
methods specifically suffer from adversarial attacks due to their inherent
design that highly depends on the self-supervision signals derived from the
original graph, which however already contains noise when the graph is
attacked. To achieve adversarial robustness against such attacks, existing
methods adopt adversarial training (AT) to the GCL framework, which considers
the attacked graph as an augmentation under the GCL framework. However, we find
that existing adversarially trained GCL methods achieve robustness at the
expense of not being able to preserve the node feature similarity. In this
paper, we propose a similarity-preserving adversarial graph contrastive
learning (SP-AGCL) framework that contrasts the clean graph with two auxiliary
views of different properties (i.e., the node similarity-preserving view and
the adversarial view). Extensive experiments demonstrate that SP-AGCL achieves
a competitive performance on several downstream tasks, and shows its
effectiveness in various scenarios, e.g., a network with adversarial attacks,
noisy labels, and heterophilous neighbors. Our code is available at
https://github.com/yeonjun-in/torch-SP-AGCL.
</p></li>
</ul>

<h3>Title: Boosting Model Inversion Attacks with Adversarial Examples. (arXiv:2306.13965v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.13965">http://arxiv.org/abs/2306.13965</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.13965] Boosting Model Inversion Attacks with Adversarial Examples](http://arxiv.org/abs/2306.13965) #attack</code></li>
<li>Summary: <p>Model inversion attacks involve reconstructing the training data of a target
model, which raises serious privacy concerns for machine learning models.
However, these attacks, especially learning-based methods, are likely to suffer
from low attack accuracy, i.e., low classification accuracy of these
reconstructed data by machine learning classifiers. Recent studies showed an
alternative strategy of model inversion attacks, GAN-based optimization, can
improve the attack accuracy effectively. However, these series of GAN-based
attacks reconstruct only class-representative training data for a class,
whereas learning-based attacks can reconstruct diverse data for different
training data in each class. Hence, in this paper, we propose a new training
paradigm for a learning-based model inversion attack that can achieve higher
attack accuracy in a black-box setting. First, we regularize the training
process of the attack model with an added semantic loss function and, second,
we inject adversarial examples into the training data to increase the diversity
of the class-related parts (i.e., the essential features for classification
tasks) in training data. This scheme guides the attack model to pay more
attention to the class-related parts of the original data during the data
reconstruction process. The experimental results show that our method greatly
boosts the performance of existing learning-based model inversion attacks. Even
when no extra queries to the target model are allowed, the approach can still
improve the attack accuracy of reconstructed data. This new attack shows that
the severity of the threat from learning-based model inversion adversaries is
underestimated and more robust defenses are required.
</p></li>
</ul>

<h3>Title: HODOR: Shrinking Attack Surface on Node.js via System Call Limitation. (arXiv:2306.13984v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.13984">http://arxiv.org/abs/2306.13984</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.13984] HODOR: Shrinking Attack Surface on Node](http://arxiv.org/abs/2306.13984) #attack</code></li>
<li>Summary: <p>Node.js provides Node.js applications with system interaction capabilities
using system calls. However, such convenience comes with a price, i.e., the
attack surface of JavaScript arbitrary code execution (ACE) vulnerabilities is
expanded to the system call level. There lies a noticeable gap between existing
protection techniques in the JavaScript code level (either by code debloating
or read-write-execute permission restriction) and a targeted defense for
emerging critical system call level exploitation. To fill the gap, we design
and implement HODOR, a lightweight runtime protection system based on enforcing
precise system call restrictions when running a Node.js application. HODOR
achieved this by addressing several nontrivialial technical challenges. First,
HODOR requires to construct high-quality call graphs for both the Node.js
application (in JavaScript) and its underlying Node.js framework (in JavaScript
and C/C++). Specifically, HODOR incorporates several important optimizations in
both the JavaScript and C/C++ level to improve the state-of-the-art tools for
building more precise call graphs. Then, HODOR creates the main-thread
whitelist and the thread-pool whitelist respectively containing the identified
necessary system calls based on the call graphs mappings. Finally, with the
whitelists, HODOR implements lightweight system call restriction using the
Linux kernel feature Secure Computing Mode (seccomp) to shrink the attack
surface. We utilize HODOR to protect 83 real-world Node.js applications
compromised by arbitrary code/command execution attacks. HODOR could reduce the
attack surface to 16.75% on average with negligible runtime overhead (i.e.,
<3%).
</p></li>
</ul>

<h3>Title: Machine Learning needs its own Randomness Standard: Randomised Smoothing and PRNG-based attacks. (arXiv:2306.14043v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.14043">http://arxiv.org/abs/2306.14043</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.14043] Machine Learning needs its own Randomness Standard: Randomised Smoothing and PRNG-based attacks](http://arxiv.org/abs/2306.14043) #attack</code></li>
<li>Summary: <p>Randomness supports many critical functions in the field of machine learning
(ML) including optimisation, data selection, privacy, and security. ML systems
outsource the task of generating or harvesting randomness to the compiler, the
cloud service provider or elsewhere in the toolchain. Yet there is a long
history of attackers exploiting poor randomness, or even creating it -- as when
the NSA put backdoors in random number generators to break cryptography. In
this paper we consider whether attackers can compromise an ML system using only
the randomness on which they commonly rely. We focus our effort on Randomised
Smoothing, a popular approach to train certifiably robust models, and to
certify specific input datapoints of an arbitrary model. We choose Randomised
Smoothing since it is used for both security and safety -- to counteract
adversarial examples and quantify uncertainty respectively. Under the hood, it
relies on sampling Gaussian noise to explore the volume around a data point to
certify that a model is not vulnerable to adversarial examples. We demonstrate
an entirely novel attack against it, where an attacker backdoors the supplied
randomness to falsely certify either an overestimate or an underestimate of
robustness. We demonstrate that such attacks are possible, that they require
very small changes to randomness to succeed, and that they can be hard to
detect. As an example, we hide an attack in the random number generator and
show that the randomness tests suggested by NIST fail to detect it. We advocate
updating the NIST guidelines on random number testing to make them more
appropriate for safety-critical and security-critical machine-learning
applications.
</p></li>
</ul>

<h2>robust</h2>
<h3>Title: Stable Yaw Estimation of Boats from the Viewpoint of UAVs and USVs. (arXiv:2306.14056v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.14056">http://arxiv.org/abs/2306.14056</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.14056] Stable Yaw Estimation of Boats from the Viewpoint of UAVs and USVs](http://arxiv.org/abs/2306.14056) #robust</code></li>
<li>Summary: <p>Yaw estimation of boats from the viewpoint of unmanned aerial vehicles (UAVs)
and unmanned surface vehicles (USVs) or boats is a crucial task in various
applications such as 3D scene rendering, trajectory prediction, and navigation.
However, the lack of literature on yaw estimation of objects from the viewpoint
of UAVs has motivated us to address this domain. In this paper, we propose a
method based on HyperPosePDF for predicting the orientation of boats in the 6D
space. For that, we use existing datasets, such as PASCAL3D+ and our own
datasets, SeaDronesSee-3D and BOArienT, which we annotated manually. We extend
HyperPosePDF to work in video-based scenarios, such that it yields robust
orientation predictions across time. Naively applying HyperPosePDF on video
data yields single-point predictions, resulting in far-off predictions and
often incorrect symmetric orientations due to unseen or visually different
data. To alleviate this issue, we propose aggregating the probability
distributions of pose predictions, resulting in significantly improved
performance, as shown in our experimental evaluation. Our proposed method could
significantly benefit downstream tasks in marine robotics.
</p></li>
</ul>

<h3>Title: SuperBench: A Super-Resolution Benchmark Dataset for Scientific Machine Learning. (arXiv:2306.14070v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.14070">http://arxiv.org/abs/2306.14070</a></li>
<li>Code URL: <a href="https://github.com/erichson/superbench">https://github.com/erichson/superbench</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2306.14070] SuperBench: A Super-Resolution Benchmark Dataset for Scientific Machine Learning](http://arxiv.org/abs/2306.14070) #robust</code></li>
<li>Summary: <p>Super-Resolution (SR) techniques aim to enhance data resolution, enabling the
retrieval of finer details, and improving the overall quality and fidelity of
the data representation. There is growing interest in applying SR methods to
complex spatiotemporal systems within the Scientific Machine Learning (SciML)
community, with the hope of accelerating numerical simulations and/or improving
forecasts in weather, climate, and related areas. However, the lack of
standardized benchmark datasets for comparing and validating SR methods hinders
progress and adoption in SciML. To address this, we introduce SuperBench, the
first benchmark dataset featuring high-resolution datasets (up to
$2048\times2048$ dimensions), including data from fluid flows, cosmology, and
weather. Here, we focus on validating spatial SR performance from data-centric
and physics-preserved perspectives, as well as assessing robustness to data
degradation tasks. While deep learning-based SR methods (developed in the
computer vision community) excel on certain tasks, despite relatively limited
prior physics information, we identify limitations of these methods in
accurately capturing intricate fine-scale features and preserving fundamental
physical properties and constraints in scientific data. These shortcomings
highlight the importance and subtlety of incorporating domain knowledge into ML
models. We anticipate that SuperBench will significantly advance SR methods for
scientific tasks.
</p></li>
</ul>

<h3>Title: SpikeCodec: An End-to-end Learned Compression Framework for Spiking Camera. (arXiv:2306.14108v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.14108">http://arxiv.org/abs/2306.14108</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.14108] SpikeCodec: An End-to-end Learned Compression Framework for Spiking Camera](http://arxiv.org/abs/2306.14108) #robust</code></li>
<li>Summary: <p>Recently, the bio-inspired spike camera with continuous motion recording
capability has attracted tremendous attention due to its ultra high temporal
resolution imaging characteristic. Such imaging feature results in huge data
storage and transmission burden compared to that of traditional camera, raising
severe challenge and imminent necessity in compression for spike camera
captured content. Existing lossy data compression methods could not be applied
for compressing spike streams efficiently due to integrate-and-fire
characteristic and binarized data structure. Considering the imaging principle
and information fidelity of spike cameras, we introduce an effective and robust
representation of spike streams. Based on this representation, we propose a
novel learned spike compression framework using scene recovery, variational
auto-encoder plus spike simulator. To our knowledge, it is the first
data-trained model for efficient and robust spike stream compression. Extensive
experimental results show that our method outperforms the conventional and
learning-based codecs, contributing a strong baseline for learned spike data
compression.
</p></li>
</ul>

<h3>Title: Math Word Problem Solving by Generating Linguistic Variants of Problem Statements. (arXiv:2306.13899v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.13899">http://arxiv.org/abs/2306.13899</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.13899] Math Word Problem Solving by Generating Linguistic Variants of Problem Statements](http://arxiv.org/abs/2306.13899) #robust</code></li>
<li>Summary: <p>The art of mathematical reasoning stands as a fundamental pillar of
intellectual progress and is a central catalyst in cultivating human ingenuity.
Researchers have recently published a plethora of works centered around the
task of solving Math Word Problems (MWP) $-$ a crucial stride towards general
AI. These existing models are susceptible to dependency on shallow heuristics
and spurious correlations to derive the solution expressions. In order to
ameliorate this issue, in this paper, we propose a framework for MWP solvers
based on the generation of linguistic variants of the problem text. The
approach involves solving each of the variant problems and electing the
predicted expression with the majority of the votes. We use DeBERTa
(Decoding-enhanced BERT with disentangled attention) as the encoder to leverage
its rich textual representations and enhanced mask decoder to construct the
solution expressions. Furthermore, we introduce a challenging dataset,
$\mathrm{P\small{ARA}\normalsize{MAWPS}}$, consisting of paraphrased,
adversarial, and inverse variants of selectively sampled MWPs from the
benchmark $\mathrm{M\small{AWPS}}$ dataset. We extensively experiment on this
dataset along with other benchmark datasets using some baseline MWP solver
models. We show that training on linguistic variants of problem statements and
voting on candidate predictions improve the mathematical reasoning and
robustness of the model. We make our code and data publicly available.
</p></li>
</ul>

<h3>Title: Towards Robust Aspect-based Sentiment Analysis through Non-counterfactual Augmentations. (arXiv:2306.13971v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.13971">http://arxiv.org/abs/2306.13971</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.13971] Towards Robust Aspect-based Sentiment Analysis through Non-counterfactual Augmentations](http://arxiv.org/abs/2306.13971) #robust</code></li>
<li>Summary: <p>While state-of-the-art NLP models have demonstrated excellent performance for
aspect based sentiment analysis (ABSA), substantial evidence has been presented
on their lack of robustness. This is especially manifested as significant
degradation in performance when faced with out-of-distribution data. Recent
solutions that rely on counterfactually augmented datasets show promising
results, but they are inherently limited because of the lack of access to
explicit causal structure. In this paper, we present an alternative approach
that relies on non-counterfactual data augmentation. Our proposal instead
relies on using noisy, cost-efficient data augmentations that preserve
semantics associated with the target aspect. Our approach then relies on
modelling invariances between different versions of the data to improve
robustness. A comprehensive suite of experiments shows that our proposal
significantly improves upon strong pre-trained baselines on both standard and
robustness-specific datasets. Our approach further establishes a new
state-of-the-art on the ABSA robustness benchmark and transfers well across
domains.
</p></li>
</ul>

<h3>Title: A First Order Meta Stackelberg Method for Robust Federated Learning. (arXiv:2306.13800v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.13800">http://arxiv.org/abs/2306.13800</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.13800] A First Order Meta Stackelberg Method for Robust Federated Learning](http://arxiv.org/abs/2306.13800) #robust</code></li>
<li>Summary: <p>Previous research has shown that federated learning (FL) systems are exposed
to an array of security risks. Despite the proposal of several defensive
strategies, they tend to be non-adaptive and specific to certain types of
attacks, rendering them ineffective against unpredictable or adaptive threats.
This work models adversarial federated learning as a Bayesian Stackelberg
Markov game (BSMG) to capture the defender's incomplete information of various
attack types. We propose meta-Stackelberg learning (meta-SL), a provably
efficient meta-learning algorithm, to solve the equilibrium strategy in BSMG,
leading to an adaptable FL defense. We demonstrate that meta-SL converges to
the first-order $\varepsilon$-equilibrium point in $O(\varepsilon^{-2})$
gradient iterations, with $O(\varepsilon^{-4})$ samples needed per iteration,
matching the state of the art. Empirical evidence indicates that our
meta-Stackelberg framework performs exceptionally well against potent model
poisoning and backdoor attacks of an uncertain nature.
</p></li>
</ul>

<h3>Title: MIRACLE: Multi-task Learning based Interpretable Regulation of Autoimmune Diseases through Common Latent Epigenetics. (arXiv:2306.13866v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.13866">http://arxiv.org/abs/2306.13866</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.13866] MIRACLE: Multi-task Learning based Interpretable Regulation of Autoimmune Diseases through Common Latent Epigenetics](http://arxiv.org/abs/2306.13866) #robust</code></li>
<li>Summary: <p>DNA methylation is a crucial regulator of gene transcription and has been
linked to various diseases, including autoimmune diseases and cancers. However,
diagnostics based on DNA methylation face challenges due to large feature sets
and small sample sizes, resulting in overfitting and suboptimal performance. To
address these issues, we propose MIRACLE, a novel interpretable neural network
that leverages autoencoder-based multi-task learning to integrate multiple
datasets and jointly identify common patterns in DNA methylation.
</p></li>
</ul>

<p>MIRACLE's architecture reflects the relationships between methylation sites,
genes, and pathways, ensuring biological interpretability and meaningfulness.
The network comprises an encoder and a decoder, with a bottleneck layer
representing pathway information as the basic unit of heredity. Customized
defined MaskedLinear Layer is constrained by site-gene-pathway graph adjacency
matrix information, which provides explainability and expresses the
site-gene-pathway hierarchical structure explicitly. And from the embedding,
there are different multi-task classifiers to predict diseases.
</p>
<p>Tested on six datasets, including rheumatoid arthritis, systemic lupus
erythematosus, multiple sclerosis, inflammatory bowel disease, psoriasis, and
type 1 diabetes, MIRACLE demonstrates robust performance in identifying common
functions of DNA methylation across different phenotypes, with higher accuracy
in prediction dieseases than baseline methods. By incorporating biological
prior knowledge, MIRACLE offers a meaningful and interpretable framework for
DNA methylation data analysis in the context of autoimmune diseases.
</p>

<h3>Title: Individualized Dosing Dynamics via Neural Eigen Decomposition. (arXiv:2306.14020v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.14020">http://arxiv.org/abs/2306.14020</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.14020] Individualized Dosing Dynamics via Neural Eigen Decomposition](http://arxiv.org/abs/2306.14020) #robust</code></li>
<li>Summary: <p>Dosing models often use differential equations to model biological dynamics.
Neural differential equations in particular can learn to predict the derivative
of a process, which permits predictions at irregular points of time. However,
this temporal flexibility often comes with a high sensitivity to noise, whereas
medical problems often present high noise and limited data. Moreover, medical
dosing models must generalize reliably over individual patients and changing
treatment policies. To address these challenges, we introduce the Neural Eigen
Stochastic Differential Equation algorithm (NESDE). NESDE provides
individualized modeling (using a hypernetwork over patient-level parameters);
generalization to new treatment policies (using decoupled control); tunable
expressiveness according to the noise level (using piecewise linearity); and
fast, continuous, closed-form prediction (using spectral representation). We
demonstrate the robustness of NESDE in both synthetic and real medical
problems, and use the learned dynamics to publish simulated medical gym
environments.
</p></li>
</ul>

<h3>Title: Modeling Graphs Beyond Hyperbolic: Graph Neural Networks in Symmetric Positive Definite Matrices. (arXiv:2306.14064v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.14064">http://arxiv.org/abs/2306.14064</a></li>
<li>Code URL: <a href="https://github.com/andyweizhao/spd4gnns">https://github.com/andyweizhao/spd4gnns</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2306.14064] Modeling Graphs Beyond Hyperbolic: Graph Neural Networks in Symmetric Positive Definite Matrices](http://arxiv.org/abs/2306.14064) #robust</code></li>
<li>Summary: <p>Recent research has shown that alignment between the structure of graph data
and the geometry of an embedding space is crucial for learning high-quality
representations of the data. The uniform geometry of Euclidean and hyperbolic
spaces allows for representing graphs with uniform geometric and topological
features, such as grids and hierarchies, with minimal distortion. However,
real-world graph data is characterized by multiple types of geometric and
topological features, necessitating more sophisticated geometric embedding
spaces. In this work, we utilize the Riemannian symmetric space of symmetric
positive definite matrices (SPD) to construct graph neural networks that can
robustly handle complex graphs. To do this, we develop an innovative library
that leverages the SPD gyrocalculus tools \cite{lopez2021gyroSPD} to implement
the building blocks of five popular graph neural networks in SPD. Experimental
results demonstrate that our graph neural networks in SPD substantially
outperform their counterparts in Euclidean and hyperbolic spaces, as well as
the Cartesian product thereof, on complex graphs for node and graph
classification tasks. We release the library and datasets at
\url{https://github.com/andyweizhao/SPD4GNNs}.
</p></li>
</ul>

<h3>Title: Is RLHF More Difficult than Standard RL?. (arXiv:2306.14111v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.14111">http://arxiv.org/abs/2306.14111</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.14111] Is RLHF More Difficult than Standard RL?](http://arxiv.org/abs/2306.14111) #robust</code></li>
<li>Summary: <p>Reinforcement learning from Human Feedback (RLHF) learns from preference
signals, while standard Reinforcement Learning (RL) directly learns from reward
signals. Preferences arguably contain less information than rewards, which
makes preference-based RL seemingly more difficult. This paper theoretically
proves that, for a wide range of preference models, we can solve
preference-based RL directly using existing algorithms and techniques for
reward-based RL, with small or no extra costs. Specifically, (1) for
preferences that are drawn from reward-based probabilistic models, we reduce
the problem to robust reward-based RL that can tolerate small errors in
rewards; (2) for general arbitrary preferences where the objective is to find
the von Neumann winner, we reduce the problem to multiagent reward-based RL
which finds Nash equilibria for factored Markov games under a restricted set of
policies. The latter case can be further reduce to adversarial MDP when
preferences only depend on the final state. We instantiate all reward-based RL
subroutines by concrete provable algorithms, and apply our theory to a large
class of models including tabular MDPs and MDPs with generic function
approximation. We further provide guarantees when K-wise comparisons are
available.
</p></li>
</ul>

<h2>biometric</h2>
<h3>Title: Person Recognition using Facial Micro-Expressions with Deep Learning. (arXiv:2306.13907v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.13907">http://arxiv.org/abs/2306.13907</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.13907] Person Recognition using Facial Micro-Expressions with Deep Learning](http://arxiv.org/abs/2306.13907) #biometric</code></li>
<li>Summary: <p>This study investigates the efficacy of facial micro-expressions as a soft
biometric for enhancing person recognition, aiming to broaden the understanding
of the subject and its potential applications. We propose a deep learning
approach designed to capture spatial semantics and motion at a fine temporal
resolution. Experiments on three widely-used micro-expression databases
demonstrate a notable increase in identification accuracy compared to existing
benchmarks, highlighting the potential of integrating facial micro-expressions
for improved person recognition across various fields.
</p></li>
</ul>

<h2>steal</h2>
<h2>extraction</h2>
<h3>Title: Resume Information Extraction via Post-OCR Text Processing. (arXiv:2306.13775v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.13775">http://arxiv.org/abs/2306.13775</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.13775] Resume Information Extraction via Post-OCR Text Processing](http://arxiv.org/abs/2306.13775) #extraction</code></li>
<li>Summary: <p>Information extraction (IE), one of the main tasks of natural language
processing (NLP), has recently increased importance in the use of resumes. In
studies on the text to extract information from the CV, sentence classification
was generally made using NLP models. In this study, it is aimed to extract
information by classifying all of the text groups after pre-processing such as
Optical Character Recognition (OCT) and object recognition with the YOLOv8
model of the resumes. The text dataset consists of 286 resumes collected for 5
different (education, experience, talent, personal and language) job
descriptions in the IT industry. The dataset created for object recognition
consists of 1198 resumes, which were collected from the open-source internet
and labeled as sets of text. BERT, BERT-t, DistilBERT, RoBERTa and XLNet were
used as models. F1 score variances were used to compare the model results. In
addition, the YOLOv8 model has also been reported comparatively in itself. As a
result of the comparison, DistilBERT was showed better results despite having a
lower number of parameters than other models.
</p></li>
</ul>

<h3>Title: A Novel Dual-pooling Attention Module for UAV Vehicle Re-identification. (arXiv:2306.14104v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.14104">http://arxiv.org/abs/2306.14104</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.14104] A Novel Dual-pooling Attention Module for UAV Vehicle Re-identification](http://arxiv.org/abs/2306.14104) #extraction</code></li>
<li>Summary: <p>Vehicle re-identification (Re-ID) involves identifying the same vehicle
captured by other cameras, given a vehicle image. It plays a crucial role in
the development of safe cities and smart cities. With the rapid growth and
implementation of unmanned aerial vehicles (UAVs) technology, vehicle Re-ID in
UAV aerial photography scenes has garnered significant attention from
researchers. However, due to the high altitude of UAVs, the shooting angle of
vehicle images sometimes approximates vertical, resulting in fewer local
features for Re-ID. Therefore, this paper proposes a novel dual-pooling
attention (DpA) module, which achieves the extraction and enhancement of
locally important information about vehicles from both channel and spatial
dimensions by constructing two branches of channel-pooling attention (CpA) and
spatial-pooling attention (SpA), and employing multiple pooling operations to
enhance the attention to fine-grained information of vehicles. Specifically,
the CpA module operates between the channels of the feature map and splices
features by combining four pooling operations so that vehicle regions
containing discriminative information are given greater attention. The SpA
module uses the same pooling operations strategy to identify discriminative
representations and merge vehicle features in image regions in a weighted
manner. The feature information of both dimensions is finally fused and trained
jointly using label smoothing cross-entropy loss and hard mining triplet loss,
thus solving the problem of missing detail information due to the high height
of UAV shots. The proposed method's effectiveness is demonstrated through
extensive experiments on the UAV-based vehicle datasets VeRi-UAV and VRU.
</p></li>
</ul>

<h3>Title: Weighted Automata Extraction and Explanation of Recurrent Neural Networks for Natural Language Tasks. (arXiv:2306.14040v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.14040">http://arxiv.org/abs/2306.14040</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.14040] Weighted Automata Extraction and Explanation of Recurrent Neural Networks for Natural Language Tasks](http://arxiv.org/abs/2306.14040) #extraction</code></li>
<li>Summary: <p>Recurrent Neural Networks (RNNs) have achieved tremendous success in
processing sequential data, yet understanding and analyzing their behaviours
remains a significant challenge. To this end, many efforts have been made to
extract finite automata from RNNs, which are more amenable for analysis and
explanation. However, existing approaches like exact learning and compositional
approaches for model extraction have limitations in either scalability or
precision. In this paper, we propose a novel framework of Weighted Finite
Automata (WFA) extraction and explanation to tackle the limitations for natural
language tasks. First, to address the transition sparsity and context loss
problems we identified in WFA extraction for natural language tasks, we propose
an empirical method to complement missing rules in the transition diagram, and
adjust transition matrices to enhance the context-awareness of the WFA. We also
propose two data augmentation tactics to track more dynamic behaviours of RNN,
which further allows us to improve the extraction precision. Based on the
extracted model, we propose an explanation method for RNNs including a word
embedding method -- Transition Matrix Embeddings (TME) and TME-based task
oriented explanation for the target RNN. Our evaluation demonstrates the
advantage of our method in extraction precision than existing approaches, and
the effectiveness of TME-based explanation method in applications to
pretraining and adversarial example generation.
</p></li>
</ul>

<h2>membership infer</h2>
<h2>federate</h2>
<h3>Title: Exploring Data Redundancy in Real-world Image Classification through Data Selection. (arXiv:2306.14113v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.14113">http://arxiv.org/abs/2306.14113</a></li>
<li>Code URL: <a href="https://github.com/zhenyutang2023/data_selection">https://github.com/zhenyutang2023/data_selection</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2306.14113] Exploring Data Redundancy in Real-world Image Classification through Data Selection](http://arxiv.org/abs/2306.14113) #federate</code></li>
<li>Summary: <p>Deep learning models often require large amounts of data for training,
leading to increased costs. It is particularly challenging in medical imaging,
i.e., gathering distributed data for centralized training, and meanwhile,
obtaining quality labels remains a tedious job. Many methods have been proposed
to address this issue in various training paradigms, e.g., continual learning,
active learning, and federated learning, which indeed demonstrate certain forms
of the data valuation process. However, existing methods are either overly
intuitive or limited to common clean/toy datasets in the experiments. In this
work, we present two data valuation metrics based on Synaptic Intelligence and
gradient norms, respectively, to study the redundancy in real-world image data.
Novel online and offline data selection algorithms are then proposed via
clustering and grouping based on the examined data values. Our online approach
effectively evaluates data utilizing layerwise model parameter updates and
gradients in each epoch and can accelerate model training with fewer epochs and
a subset (e.g., 19%-59%) of data while maintaining equivalent levels of
accuracy in a variety of datasets. It also extends to the offline coreset
construction, producing subsets of only 18%-30% of the original. The codes for
the proposed adaptive data selection and coreset computation are available
(https://github.com/ZhenyuTANG2023/data_selection).
</p></li>
</ul>

<h3>Title: Private Aggregation in Wireless Federated Learning with Heterogeneous Clusters. (arXiv:2306.14088v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.14088">http://arxiv.org/abs/2306.14088</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.14088] Private Aggregation in Wireless Federated Learning with Heterogeneous Clusters](http://arxiv.org/abs/2306.14088) #federate</code></li>
<li>Summary: <p>Federated learning collaboratively trains a neural network on privately owned
data held by several participating clients. The gradient descent algorithm, a
well-known and popular iterative optimization procedure, is run to train the
neural network. Every client uses its local data to compute partial gradients
and sends it to the federator which aggregates the results. Privacy of the
clients' data is a major concern. In fact, observing the partial gradients can
be enough to reveal the clients' data. Private aggregation schemes have been
investigated to tackle the privacy problem in federated learning where all the
users are connected to each other and to the federator. In this paper, we
consider a wireless system architecture where clients are only connected to the
federator via base stations. We derive fundamental limits on the communication
cost when information-theoretic privacy is required, and introduce and analyze
a private aggregation scheme tailored for this setting.
</p></li>
</ul>

<h3>Title: Federated Learning Approach for Distributed Ransomware Analysis. (arXiv:2306.14090v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.14090">http://arxiv.org/abs/2306.14090</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.14090] Federated Learning Approach for Distributed Ransomware Analysis](http://arxiv.org/abs/2306.14090) #federate</code></li>
<li>Summary: <p>Researchers have proposed a wide range of ransomware detection and analysis
schemes. However, most of these efforts have focused on older families
targeting Windows 7/8 systems. Hence there is a critical need to develop
efficient solutions to tackle the latest threats, many of which may have
relatively fewer samples to analyze. This paper presents a machine learning
(ML) framework for early ransomware detection and attribution. The solution
pursues a data-centric approach which uses a minimalist ransomware dataset and
implements static analysis using portable executable (PE) files. Results for
several ML classifiers confirm strong performance in terms of accuracy and
zero-day threat detection.
</p></li>
</ul>

<h2>fair</h2>
<h3>Title: Is Pre-training Truly Better Than Meta-Learning?. (arXiv:2306.13841v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.13841">http://arxiv.org/abs/2306.13841</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.13841] Is Pre-training Truly Better Than Meta-Learning?](http://arxiv.org/abs/2306.13841) #fair</code></li>
<li>Summary: <p>In the context of few-shot learning, it is currently believed that a fixed
pre-trained (PT) model, along with fine-tuning the final layer during
evaluation, outperforms standard meta-learning algorithms. We re-evaluate these
claims under an in-depth empirical examination of an extensive set of formally
diverse datasets and compare PT to Model Agnostic Meta-Learning (MAML). Unlike
previous work, we emphasize a fair comparison by using: the same architecture,
the same optimizer, and all models trained to convergence. Crucially, we use a
more rigorous statistical tool -- the effect size (Cohen's d) -- to determine
the practical significance of the difference between a model trained with PT
vs. a MAML. We then use a previously proposed metric -- the diversity
coefficient -- to compute the average formal diversity of a dataset. Using this
analysis, we demonstrate the following: 1. when the formal diversity of a data
set is low, PT beats MAML on average and 2. when the formal diversity is high,
MAML beats PT on average. The caveat is that the magnitude of the average
difference between a PT vs. MAML using the effect size is low (according to
classical statistical thresholds) -- less than 0.2. Nevertheless, this
observation is contrary to the currently held belief that a pre-trained model
is always better than a meta-learning model. Our extensive experiments consider
21 few-shot learning benchmarks, including the large-scale few-shot learning
dataset Meta-Data set. We also show no significant difference between a MAML
model vs. a PT model with GPT-2 on Openwebtext. We, therefore, conclude that a
pre-trained model does not always beat a meta-learned model and that the formal
diversity of a dataset is a driving factor.
</p></li>
</ul>

<h3>Title: Multi-Target Multiplicity: Flexibility and Fairness in Target Specification under Resource Constraints. (arXiv:2306.13738v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.13738">http://arxiv.org/abs/2306.13738</a></li>
<li>Code URL: <a href="https://github.com/jwatsondaniels/multitarget-multiplicity">https://github.com/jwatsondaniels/multitarget-multiplicity</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2306.13738] Multi-Target Multiplicity: Flexibility and Fairness in Target Specification under Resource Constraints](http://arxiv.org/abs/2306.13738) #fair</code></li>
<li>Summary: <p>Prediction models have been widely adopted as the basis for decision-making
in domains as diverse as employment, education, lending, and health. Yet, few
real world problems readily present themselves as precisely formulated
prediction tasks. In particular, there are often many reasonable target
variable options. Prior work has argued that this is an important and sometimes
underappreciated choice, and has also shown that target choice can have a
significant impact on the fairness of the resulting model. However, the
existing literature does not offer a formal framework for characterizing the
extent to which target choice matters in a particular task. Our work fills this
gap by drawing connections between the problem of target choice and recent work
on predictive multiplicity. Specifically, we introduce a conceptual and
computational framework for assessing how the choice of target affects
individuals' outcomes and selection rate disparities across groups. We call
this multi-target multiplicity. Along the way, we refine the study of
single-target multiplicity by introducing notions of multiplicity that respect
resource constraints -- a feature of many real-world tasks that is not captured
by existing notions of predictive multiplicity. We apply our methods on a
healthcare dataset, and show that the level of multiplicity that stems from
target variable choice can be greater than that stemming from nearly-optimal
models of a single target.
</p></li>
</ul>

<h2>interpretability</h2>
<h3>Title: Beyond Scale: the Diversity Coefficient as a Data Quality Metric Demonstrates LLMs are Pre-trained on Formally Diverse Data. (arXiv:2306.13840v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.13840">http://arxiv.org/abs/2306.13840</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.13840] Beyond Scale: the Diversity Coefficient as a Data Quality Metric Demonstrates LLMs are Pre-trained on Formally Diverse Data](http://arxiv.org/abs/2306.13840) #interpretability</code></li>
<li>Summary: <p>Current trends to pre-train capable Large Language Models (LLMs) mostly focus
on scaling of model and dataset size. However, the quality of pre-training data
is an important factor for training powerful LLMs, yet it is a nebulous concept
that has not been fully characterized. Therefore, we use the recently proposed
Task2Vec diversity coefficient to ground and understand formal aspects of data
quality, to go beyond scale alone. Specifically, we measure the diversity
coefficient of publicly available pre-training datasets to demonstrate that
their formal diversity is high when compared to theoretical lower and upper
bounds. In addition, to build confidence in the diversity coefficient, we
conduct interpretability experiments and find that the coefficient aligns with
intuitive properties of diversity, e.g., it increases as the number of latent
concepts increases. We conclude the diversity coefficient is reliable, show
it's high for publicly available LLM datasets, and conjecture it can be used to
build useful diverse datasets for LLMs.
</p></li>
</ul>

<h3>Title: IERL: Interpretable Ensemble Representation Learning -- Combining CrowdSourced Knowledge and Distributed Semantic Representations. (arXiv:2306.13865v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.13865">http://arxiv.org/abs/2306.13865</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.13865] IERL: Interpretable Ensemble Representation Learning -- Combining CrowdSourced Knowledge and Distributed Semantic Representations](http://arxiv.org/abs/2306.13865) #interpretability</code></li>
<li>Summary: <p>Large Language Models (LLMs) encode meanings of words in the form of
distributed semantics. Distributed semantics capture common statistical
patterns among language tokens (words, phrases, and sentences) from large
amounts of data. LLMs perform exceedingly well across General Language
Understanding Evaluation (GLUE) tasks designed to test a model's understanding
of the meanings of the input tokens. However, recent studies have shown that
LLMs tend to generate unintended, inconsistent, or wrong texts as outputs when
processing inputs that were seen rarely during training, or inputs that are
associated with diverse contexts (e.g., well-known hallucination phenomenon in
language generation tasks). Crowdsourced and expert-curated knowledge graphs
such as ConceptNet are designed to capture the meaning of words from a compact
set of well-defined contexts. Thus LLMs may benefit from leveraging such
knowledge contexts to reduce inconsistencies in outputs. We propose a novel
ensemble learning method, Interpretable Ensemble Representation Learning
(IERL), that systematically combines LLM and crowdsourced knowledge
representations of input tokens. IERL has the distinct advantage of being
interpretable by design (when was the LLM context used vs. when was the
knowledge context used?) over state-of-the-art (SOTA) methods, allowing
scrutiny of the inputs in conjunction with the parameters of the model,
facilitating the analysis of models' inconsistent or irrelevant outputs.
Although IERL is agnostic to the choice of LLM and crowdsourced knowledge, we
demonstrate our approach using BERT and ConceptNet. We report improved or
competitive results with IERL across GLUE tasks over current SOTA methods and
significantly enhanced model interpretability.
</p></li>
</ul>

<h2>explainability</h2>
<h2>watermark</h2>
<h2>diffusion</h2>
<h3>Title: Decoupled Diffusion Models with Explicit Transition Probability. (arXiv:2306.13720v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.13720">http://arxiv.org/abs/2306.13720</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.13720] Decoupled Diffusion Models with Explicit Transition Probability](http://arxiv.org/abs/2306.13720) #diffusion</code></li>
<li>Summary: <p>Recent diffusion probabilistic models (DPMs) have shown remarkable abilities
of generated content, however, they often suffer from complex forward
processes, resulting in inefficient solutions for the reversed process and
prolonged sampling times. In this paper, we aim to address the aforementioned
challenges by focusing on the diffusion process itself that we propose to
decouple the intricate diffusion process into two comparatively simpler process
to improve the generative efficacy and speed. In particular, we present a novel
diffusion paradigm named DDM (\textbf{D}ecoupled \textbf{D}iffusion
\textbf{M}odels) based on the It\^{o} diffusion process, in which the image
distribution is approximated by an explicit transition probability while the
noise path is controlled by the standard Wiener process. We find that
decoupling the diffusion process reduces the learning difficulty and the
explicit transition probability improves the generative speed significantly. We
prove a new training objective for DPM, which enables the model to learn to
predict the noise and image components separately. Moreover, given the novel
forward diffusion equation, we derive the reverse denoising formula of DDM that
naturally supports fewer steps of generation without ordinary differential
equation (ODE) based accelerators. Our experiments demonstrate that DDM
outperforms previous DPMs by a large margin in fewer function evaluations
setting and gets comparable performances in long function evaluations setting.
We also show that our framework can be applied to image-conditioned generation
and high-resolution image synthesis, and that it can generate high-quality
images with only 10 function evaluations.
</p></li>
</ul>

<h3>Title: Zero-shot spatial layout conditioning for text-to-image diffusion models. (arXiv:2306.13754v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.13754">http://arxiv.org/abs/2306.13754</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.13754] Zero-shot spatial layout conditioning for text-to-image diffusion models](http://arxiv.org/abs/2306.13754) #diffusion</code></li>
<li>Summary: <p>Large-scale text-to-image diffusion models have significantly improved the
state of the art in generative image modelling and allow for an intuitive and
powerful user interface to drive the image generation process. Expressing
spatial constraints, e.g. to position specific objects in particular locations,
is cumbersome using text; and current text-based image generation models are
not able to accurately follow such instructions. In this paper we consider
image generation from text associated with segments on the image canvas, which
combines an intuitive natural language interface with precise spatial control
over the generated content. We propose ZestGuide, a zero-shot segmentation
guidance approach that can be plugged into pre-trained text-to-image diffusion
models, and does not require any additional training. It leverages implicit
segmentation maps that can be extracted from cross-attention layers, and uses
them to align the generation with input masks. Our experimental results combine
high image quality with accurate alignment of generated content with input
segmentations, and improve over prior work both quantitatively and
qualitatively, including methods that require training on images with
corresponding segmentations. Compared to Paint with Words, the previous
state-of-the art in image generation with zero-shot segmentation conditioning,
we improve by 5 to 10 mIoU points on the COCO dataset with similar FID scores.
</p></li>
</ul>

<h3>Title: DiffDTM: A conditional structure-free framework for bioactive molecules generation targeted for dual proteins. (arXiv:2306.13957v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.13957">http://arxiv.org/abs/2306.13957</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.13957] DiffDTM: A conditional structure-free framework for bioactive molecules generation targeted for dual proteins](http://arxiv.org/abs/2306.13957) #diffusion</code></li>
<li>Summary: <p>Advances in deep generative models shed light on de novo molecule generation
with desired properties. However, molecule generation targeted for dual protein
targets still faces formidable challenges including protein 3D structure data
requisition for model training, auto-regressive sampling, and model
generalization for unseen targets. Here, we proposed DiffDTM, a novel
conditional structure-free deep generative model based on a diffusion model for
dual targets based molecule generation to address the above issues.
Specifically, DiffDTM receives protein sequences and molecular graphs as inputs
instead of protein and molecular conformations and incorporates an information
fusion module to achieve conditional generation in a one-shot manner. We have
conducted comprehensive multi-view experiments to demonstrate that DiffDTM can
generate drug-like, synthesis-accessible, novel, and high-binding affinity
molecules targeting specific dual proteins, outperforming the state-of-the-art
(SOTA) models in terms of multiple evaluation metrics. Furthermore, we utilized
DiffDTM to generate molecules towards dopamine receptor D2 and
5-hydroxytryptamine receptor 1A as new antipsychotics. The experimental results
indicate that DiffDTM can be easily plugged into unseen dual targets to
generate bioactive molecules, addressing the issues of requiring insufficient
active molecule data for training as well as the need to retrain when
encountering new targets.
</p></li>
</ul>

<h3>Title: SEEDS: Emulation of Weather Forecast Ensembles with Diffusion Models. (arXiv:2306.14066v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.14066">http://arxiv.org/abs/2306.14066</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.14066] SEEDS: Emulation of Weather Forecast Ensembles with Diffusion Models](http://arxiv.org/abs/2306.14066) #diffusion</code></li>
<li>Summary: <p>Probabilistic forecasting is crucial to decision-making under uncertainty
about future weather. The dominant approach is to use an ensemble of forecasts
to represent and quantify uncertainty in operational numerical weather
prediction. However, generating ensembles is computationally costly. In this
paper, we propose to generate ensemble forecasts at scale by leveraging recent
advances in generative artificial intelligence. Our approach learns a
data-driven probabilistic diffusion model from the 5-member ensemble GEFS
reforecast dataset. The model can then be sampled efficiently to produce
realistic weather forecasts, conditioned on a few members of the operational
GEFS forecasting system. The generated ensembles have similar predictive skill
as the full GEFS 31-member ensemble, evaluated against ERA5 reanalysis, and
emulate well the statistics of large physics-based ensembles. We also apply the
same methodology to developing a diffusion model for generative
post-processing: the model directly learns to correct biases present in the
emulated forecasting system by leveraging reanalysis data as labels during
training. Ensembles from this generative post-processing model show greater
reliability and accuracy, particularly in extreme event classification. In
general, they are more reliable and forecast the probability of extreme weather
more accurately than the GEFS operational ensemble. Our models achieve these
results at less than 1/10th of the computational cost incurred by the
operational GEFS system.
</p></li>
</ul>

<h3>Title: Fighting Uncertainty with Gradients: Offline Reinforcement Learning via Diffusion Score Matching. (arXiv:2306.14079v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.14079">http://arxiv.org/abs/2306.14079</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.14079] Fighting Uncertainty with Gradients: Offline Reinforcement Learning via Diffusion Score Matching](http://arxiv.org/abs/2306.14079) #diffusion</code></li>
<li>Summary: <p>Offline optimization paradigms such as offline Reinforcement Learning (RL) or
Imitation Learning (IL) allow policy search algorithms to make use of offline
data, but require careful incorporation of uncertainty in order to circumvent
the challenges of distribution shift. Gradient-based policy search methods are
a promising direction due to their effectiveness in high dimensions; however,
we require a more careful consideration of how these methods interplay with
uncertainty estimation. We claim that in order for an uncertainty metric to be
amenable for gradient-based optimization, it must be (i) stably convergent to
data when uncertainty is minimized with gradients, and (ii) not prone to
underestimation of true uncertainty. We investigate smoothed distance to data
as a metric, and show that it not only stably converges to data, but also
allows us to analyze model bias with Lipschitz constants. Moreover, we
establish an equivalence between smoothed distance to data and data likelihood,
which allows us to use score-matching techniques to learn gradients of distance
to data. Importantly, we show that offline model-based policy search problems
that maximize data likelihood do not require values of likelihood; but rather
only the gradient of the log likelihood (the score function). Using this
insight, we propose Score-Guided Planning (SGP), a planning algorithm for
offline RL that utilizes score-matching to enable first-order planning in
high-dimensional problems, where zeroth-order methods were unable to scale, and
ensembles were unable to overcome local minima. Website:
https://sites.google.com/view/score-guided-planning/home
</p></li>
</ul>

<h2>noise learning</h2>
<h2>data-free</h2>
<h3>Title: QNNRepair: Quantized Neural Network Repair. (arXiv:2306.13793v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.13793">http://arxiv.org/abs/2306.13793</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.13793] QNNRepair: Quantized Neural Network Repair](http://arxiv.org/abs/2306.13793) #data-free</code></li>
<li>Summary: <p>We present QNNRepair, the first method in the literature for repairing
quantized neural networks (QNNs). QNNRepair aims to improve the accuracy of a
neural network model after quantization. It accepts the full-precision and
weight-quantized neural networks and a repair dataset of passing and failing
tests. At first, QNNRepair applies a software fault localization method to
identify the neurons that cause performance degradation during neural network
quantization. Then, it formulates the repair problem into a linear programming
problem of solving neuron weights parameters, which corrects the QNN's
performance on failing tests while not compromising its performance on passing
tests. We evaluate QNNRepair with widely used neural network architectures such
as MobileNetV2, ResNet, and VGGNet on popular datasets, including
high-resolution images. We also compare QNNRepair with the state-of-the-art
data-free quantization method SQuant. According to the experiment results, we
conclude that QNNRepair is effective in improving the quantized model's
performance in most cases. Its repaired models have 24% higher accuracy than
SQuant's in the independent validation set, especially for the ImageNet
dataset.
</p></li>
</ul>

<h2>transformer</h2>
<h3>Title: Swin-Free: Achieving Better Cross-Window Attention and Efficiency with Size-varying Window. (arXiv:2306.13776v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.13776">http://arxiv.org/abs/2306.13776</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.13776] Swin-Free: Achieving Better Cross-Window Attention and Efficiency with Size-varying Window](http://arxiv.org/abs/2306.13776) #transformer</code></li>
<li>Summary: <p>Transformer models have shown great potential in computer vision, following
their success in language tasks. Swin Transformer is one of them that
outperforms convolution-based architectures in terms of accuracy, while
improving efficiency when compared to Vision Transformer (ViT) and its
variants, which have quadratic complexity with respect to the input size. Swin
Transformer features shifting windows that allows cross-window connection while
limiting self-attention computation to non-overlapping local windows. However,
shifting windows introduces memory copy operations, which account for a
significant portion of its runtime. To mitigate this issue, we propose
Swin-Free in which we apply size-varying windows across stages, instead of
shifting windows, to achieve cross-connection among local windows. With this
simple design change, Swin-Free runs faster than the Swin Transformer at
inference with better accuracy. Furthermore, we also propose a few of Swin-Free
variants that are faster than their Swin Transformer counterparts.
</p></li>
</ul>

<h3>Title: The Second-place Solution for CVPR VISION 23 Challenge Track 1 -- Data Effificient Defect Detection. (arXiv:2306.14116v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.14116">http://arxiv.org/abs/2306.14116</a></li>
<li>Code URL: <a href="https://github.com/love6tao/aoi-overfitting-team">https://github.com/love6tao/aoi-overfitting-team</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2306.14116] The Second-place Solution for CVPR VISION 23 Challenge Track 1 -- Data Effificient Defect Detection](http://arxiv.org/abs/2306.14116) #transformer</code></li>
<li>Summary: <p>The Vision Challenge Track 1 for Data-Effificient Defect Detection requires
competitors to instance segment 14 industrial inspection datasets in a
data-defificient setting. This report introduces the technical details of the
team Aoi-overfifitting-Team for this challenge. Our method focuses on the key
problem of segmentation quality of defect masks in scenarios with limited
training samples. Based on the Hybrid Task Cascade (HTC) instance segmentation
algorithm, we connect the transformer backbone (Swin-B) through composite
connections inspired by CBNetv2 to enhance the baseline results. Additionally,
we propose two model ensemble methods to further enhance the segmentation
effect: one incorporates semantic segmentation into instance segmentation,
while the other employs multi-instance segmentation fusion algorithms. Finally,
using multi-scale training and test-time augmentation (TTA), we achieve an
average mAP@0.50:0.95 of more than 48.49% and an average mAR@0.50:0.95 of
66.71% on the test set of the Data Effificient Defect Detection Challenge. The
code is available at https://github.com/love6tao/Aoi-overfitting-team
</p></li>
</ul>

<h3>Title: Cross-Language Speech Emotion Recognition Using Multimodal Dual Attention Transformers. (arXiv:2306.13804v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.13804">http://arxiv.org/abs/2306.13804</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.13804] Cross-Language Speech Emotion Recognition Using Multimodal Dual Attention Transformers](http://arxiv.org/abs/2306.13804) #transformer</code></li>
<li>Summary: <p>Despite the recent progress in speech emotion recognition (SER),
state-of-the-art systems are unable to achieve improved performance in
cross-language settings. In this paper, we propose a Multimodal Dual Attention
Transformer (MDAT) model to improve cross-language SER. Our model utilises
pre-trained models for multimodal feature extraction and is equipped with a
dual attention mechanism including graph attention and co-attention to capture
complex dependencies across different modalities and achieve improved
cross-language SER results using minimal target language data. In addition, our
model also exploits a transformer encoder layer for high-level feature
representation to improve emotion classification accuracy. In this way, MDAT
performs refinement of feature representation at various stages and provides
emotional salient features to the classification layer. This novel approach
also ensures the preservation of modality-specific emotional information while
enhancing cross-modality and cross-language interactions. We assess our model's
performance on four publicly available SER datasets and establish its superior
effectiveness compared to recent approaches and baseline models.
</p></li>
</ul>

<h3>Title: L3Cube-MahaSent-MD: A Multi-domain Marathi Sentiment Analysis Dataset and Transformer Models. (arXiv:2306.13888v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.13888">http://arxiv.org/abs/2306.13888</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.13888] L3Cube-MahaSent-MD: A Multi-domain Marathi Sentiment Analysis Dataset and Transformer Models](http://arxiv.org/abs/2306.13888) #transformer</code></li>
<li>Summary: <p>The exploration of sentiment analysis in low-resource languages, such as
Marathi, has been limited due to the availability of suitable datasets. In this
work, we present L3Cube-MahaSent-MD, a multi-domain Marathi sentiment analysis
dataset, with four different domains - movie reviews, general tweets, TV show
subtitles, and political tweets. The dataset consists of around 60,000 manually
tagged samples covering 3 distinct sentiments - positive, negative, and
neutral. We create a sub-dataset for each domain comprising 15k samples. The
MahaSent-MD is the first comprehensive multi-domain sentiment analysis dataset
within the Indic sentiment landscape. We fine-tune different monolingual and
multilingual BERT models on these datasets and report the best accuracy with
the MahaBERT model. We also present an extensive in-domain and cross-domain
analysis thus highlighting the need for low-resource multi-domain datasets. The
data and models are available at https://github.com/l3cube-pune/MarathiNLP .
</p></li>
</ul>

<h3>Title: Can GPT-4 Support Analysis of Textual Data in Tasks Requiring Highly Specialized Domain Expertise?. (arXiv:2306.13906v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.13906">http://arxiv.org/abs/2306.13906</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.13906] Can GPT-4 Support Analysis of Textual Data in Tasks Requiring Highly Specialized Domain Expertise?](http://arxiv.org/abs/2306.13906) #transformer</code></li>
<li>Summary: <p>We evaluated the capability of generative pre-trained transformers~(GPT-4) in
analysis of textual data in tasks that require highly specialized domain
expertise. Specifically, we focused on the task of analyzing court opinions to
interpret legal concepts. We found that GPT-4, prompted with annotation
guidelines, performs on par with well-trained law student annotators. We
observed that, with a relatively minor decrease in performance, GPT-4 can
perform batch predictions leading to significant cost reductions. However,
employing chain-of-thought prompting did not lead to noticeably improved
performance on this task. Further, we demonstrated how to analyze GPT-4's
predictions to identify and mitigate deficiencies in annotation guidelines, and
subsequently improve the performance of the model. Finally, we observed that
the model is quite brittle, as small formatting related changes in the prompt
had a high impact on the predictions. These findings can be leveraged by
researchers and practitioners who engage in semantic/pragmatic annotations of
texts in the context of the tasks requiring highly specialized domain
expertise.
</p></li>
</ul>

<h3>Title: Comparison of Pre-trained Language Models for Turkish Address Parsing. (arXiv:2306.13947v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.13947">http://arxiv.org/abs/2306.13947</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.13947] Comparison of Pre-trained Language Models for Turkish Address Parsing](http://arxiv.org/abs/2306.13947) #transformer</code></li>
<li>Summary: <p>Transformer based pre-trained models such as BERT and its variants, which are
trained on large corpora, have demonstrated tremendous success for natural
language processing (NLP) tasks. Most of academic works are based on the
English language; however, the number of multilingual and language specific
studies increase steadily. Furthermore, several studies claimed that language
specific models outperform multilingual models in various tasks. Therefore, the
community tends to train or fine-tune the models for the language of their case
study, specifically. In this paper, we focus on Turkish maps data and
thoroughly evaluate both multilingual and Turkish based BERT, DistilBERT,
ELECTRA and RoBERTa. Besides, we also propose a MultiLayer Perceptron (MLP) for
fine-tuning BERT in addition to the standard approach of one-layer fine-tuning.
For the dataset, a mid-sized Address Parsing corpus taken with a relatively
high quality is constructed. Conducted experiments on this dataset indicate
that Turkish language specific models with MLP fine-tuning yields slightly
better results when compared to the multilingual fine-tuned models. Moreover,
visualization of address tokens' representations further indicates the
effectiveness of BERT variants for classifying a variety of addresses.
</p></li>
</ul>

<h3>Title: Characterizing the Emotion Carriers of COVID-19 Misinformation and Their Impact on Vaccination Outcomes in India and the United States. (arXiv:2306.13954v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.13954">http://arxiv.org/abs/2306.13954</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.13954] Characterizing the Emotion Carriers of COVID-19 Misinformation and Their Impact on Vaccination Outcomes in India and the United States](http://arxiv.org/abs/2306.13954) #transformer</code></li>
<li>Summary: <p>The COVID-19 Infodemic had an unprecedented impact on health behaviors and
outcomes at a global scale. While many studies have focused on a qualitative
and quantitative understanding of misinformation, including sentiment analysis,
there is a gap in understanding the emotion-carriers of misinformation and
their differences across geographies. In this study, we characterized emotion
carriers and their impact on vaccination rates in India and the United States.
A manually labelled dataset was created from 2.3 million tweets and collated
with three publicly available datasets (CoAID, AntiVax, CMU) to train deep
learning models for misinformation classification. Misinformation labelled
tweets were further analyzed for behavioral aspects by leveraging Plutchik
Transformers to determine the emotion for each tweet. Time series analysis was
conducted to study the impact of misinformation on spatial and temporal
characteristics. Further, categorical classification was performed using
transformer models to assign categories for the misinformation tweets.
Word2Vec+BiLSTM was the best model for misinformation classification, with an
F1-score of 0.92. The US had the highest proportion of misinformation tweets
(58.02%), followed by the UK (10.38%) and India (7.33%). Disgust, anticipation,
and anger were associated with an increased prevalence of misinformation
tweets. Disgust was the predominant emotion associated with misinformation
tweets in the US, while anticipation was the predominant emotion in India. For
India, the misinformation rate exhibited a lead relationship with vaccination,
while in the US it lagged behind vaccination. Our study deciphered that
emotions acted as differential carriers of misinformation across geography and
time. These carriers can be monitored to develop strategic interventions for
countering misinformation, leading to improved public health.
</p></li>
</ul>

<h3>Title: Emotion Flip Reasoning in Multiparty Conversations. (arXiv:2306.13959v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.13959">http://arxiv.org/abs/2306.13959</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.13959] Emotion Flip Reasoning in Multiparty Conversations](http://arxiv.org/abs/2306.13959) #transformer</code></li>
<li>Summary: <p>In a conversational dialogue, speakers may have different emotional states
and their dynamics play an important role in understanding dialogue's emotional
discourse. However, simply detecting emotions is not sufficient to entirely
comprehend the speaker-specific changes in emotion that occur during a
conversation. To understand the emotional dynamics of speakers in an efficient
manner, it is imperative to identify the rationale or instigator behind any
changes or flips in emotion expressed by the speaker. In this paper, we explore
the task called Instigator based Emotion Flip Reasoning (EFR), which aims to
identify the instigator behind a speaker's emotion flip within a conversation.
For example, an emotion flip from joy to anger could be caused by an instigator
like threat. To facilitate this task, we present MELD-I, a dataset that
includes ground-truth EFR instigator labels, which are in line with emotional
psychology. To evaluate the dataset, we propose a novel neural architecture
called TGIF, which leverages Transformer encoders and stacked GRUs to capture
the dialogue context, speaker dynamics, and emotion sequence in a conversation.
Our evaluation demonstrates state-of-the-art performance (+4-12% increase in
F1-score) against five baselines used for the task. Further, we establish the
generalizability of TGIF on an unseen dataset in a zero-shot setting.
Additionally, we provide a detailed analysis of the competing models,
highlighting the advantages and limitations of our neural architecture.
</p></li>
</ul>

<h3>Title: Fusing Multimodal Signals on Hyper-complex Space for Extreme Abstractive Text Summarization (TL;DR) of Scientific Contents. (arXiv:2306.13968v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.13968">http://arxiv.org/abs/2306.13968</a></li>
<li>Code URL: <a href="https://github.com/lcs2-iiitd/mtldrgen">https://github.com/lcs2-iiitd/mtldrgen</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2306.13968] Fusing Multimodal Signals on Hyper-complex Space for Extreme Abstractive Text Summarization (TL;DR) of Scientific Contents](http://arxiv.org/abs/2306.13968) #transformer</code></li>
<li>Summary: <p>The realm of scientific text summarization has experienced remarkable
progress due to the availability of annotated brief summaries and ample data.
However, the utilization of multiple input modalities, such as videos and
audio, has yet to be thoroughly explored. At present, scientific
multimodal-input-based text summarization systems tend to employ longer target
summaries like abstracts, leading to an underwhelming performance in the task
of text summarization.
</p></li>
</ul>

<p>In this paper, we deal with a novel task of extreme abstractive text
summarization (aka TL;DR generation) by leveraging multiple input modalities.
To this end, we introduce mTLDR, a first-of-its-kind dataset for the
aforementioned task, comprising videos, audio, and text, along with both
author-composed summaries and expert-annotated summaries. The mTLDR dataset
accompanies a total of 4,182 instances collected from various academic
conference proceedings, such as ICLR, ACL, and CVPR. Subsequently, we present
mTLDRgen, an encoder-decoder-based model that employs a novel dual-fused
hyper-complex Transformer combined with a Wasserstein Riemannian Encoder
Transformer, to dexterously capture the intricacies between different
modalities in a hyper-complex latent geometric space. The hyper-complex
Transformer captures the intrinsic properties between the modalities, while the
Wasserstein Riemannian Encoder Transformer captures the latent structure of the
modalities in the latent space geometry, thereby enabling the model to produce
diverse sentences. mTLDRgen outperforms 20 baselines on mTLDR as well as
another non-scientific dataset (How2) across three Rouge-based evaluation
measures. Furthermore, based on the qualitative metrics, BERTScore and FEQA,
and human evaluations, we demonstrate that the summaries generated by mTLDRgen
are fluent and congruent to the original source material.
</p>

<h3>Title: My Boli: Code-mixed Marathi-English Corpora, Pretrained Language Models and Evaluation Benchmarks. (arXiv:2306.14030v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.14030">http://arxiv.org/abs/2306.14030</a></li>
<li>Code URL: <a href="https://github.com/l3cube-pune/MarathiNLP">https://github.com/l3cube-pune/MarathiNLP</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2306.14030] My Boli: Code-mixed Marathi-English Corpora, Pretrained Language Models and Evaluation Benchmarks](http://arxiv.org/abs/2306.14030) #transformer</code></li>
<li>Summary: <p>The research on code-mixed data is limited due to the unavailability of
dedicated code-mixed datasets and pre-trained language models. In this work, we
focus on the low-resource Indian language Marathi which lacks any prior work in
code-mixing. We present L3Cube-MeCorpus, a large code-mixed Marathi-English
(Mr-En) corpus with 5 million tweets for pretraining. We also release
L3Cube-MeBERT and MeRoBERTa, code-mixed BERT-based transformer models
pre-trained on MeCorpus. Furthermore, for benchmarking, we present three
supervised datasets MeHate, MeSent, and MeLID for downstream tasks like
code-mixed Mr-En hate speech detection, sentiment analysis, and language
identification respectively. These evaluation datasets individually consist of
manually annotated \url{~}12,000 Marathi-English code-mixed tweets. Ablations
show that the models trained on this novel corpus significantly outperform the
existing state-of-the-art BERT models. This is the first work that presents
artifacts for code-mixed Marathi research. All datasets and models are publicly
released at https://github.com/l3cube-pune/MarathiNLP .
</p></li>
</ul>

<h3>Title: Upscaling Global Hourly GPP with Temporal Fusion Transformer (TFT). (arXiv:2306.13815v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.13815">http://arxiv.org/abs/2306.13815</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.13815] Upscaling Global Hourly GPP with Temporal Fusion Transformer (TFT)](http://arxiv.org/abs/2306.13815) #transformer</code></li>
<li>Summary: <p>Reliable estimates of Gross Primary Productivity (GPP), crucial for
evaluating climate change initiatives, are currently only available from
sparsely distributed eddy covariance tower sites. This limitation hampers
access to reliable GPP quantification at regional to global scales. Prior
machine learning studies on upscaling \textit{in situ} GPP to global
wall-to-wall maps at sub-daily time steps faced limitations such as lack of
input features at higher temporal resolutions and significant missing values.
This research explored a novel upscaling solution using Temporal Fusion
Transformer (TFT) without relying on past GPP time series. Model development
was supplemented by Random Forest Regressor (RFR) and XGBoost, followed by the
hybrid model of TFT and tree algorithms. The best preforming model yielded to
model performance of 0.704 NSE and 3.54 RMSE. Another contribution of the study
was the breakdown analysis of encoder feature importance based on time and flux
tower sites. Such analysis enhanced the interpretability of the multi-head
attention layer as well as the visual understanding of temporal dynamics of
influential features.
</p></li>
</ul>

<h3>Title: Action Q-Transformer: Visual Explanation in Deep Reinforcement Learning with Encoder-Decoder Model using Action Query. (arXiv:2306.13879v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.13879">http://arxiv.org/abs/2306.13879</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.13879] Action Q-Transformer: Visual Explanation in Deep Reinforcement Learning with Encoder-Decoder Model using Action Query](http://arxiv.org/abs/2306.13879) #transformer</code></li>
<li>Summary: <p>The excellent performance of Transformer in supervised learning has led to
growing interest in its potential application to deep reinforcement learning
(DRL) to achieve high performance on a wide variety of problems. However, the
decision making of a DRL agent is a black box, which greatly hinders the
application of the agent to real-world problems. To address this problem, we
propose the Action Q-Transformer (AQT), which introduces a transformer
encoder-decoder structure to Q-learning based DRL methods. In AQT, the encoder
calculates the state value function and the decoder calculates the advantage
function to promote the acquisition of different attentions indicating the
agent's decision-making. The decoder in AQT utilizes action queries, which
represent the information of each action, as queries. This enables us to obtain
the attentions for the state value and for each action. By acquiring and
visualizing these attentions that detail the agent's decision-making, we
achieve a DRL model with high interpretability. In this paper, we show that
visualization of attention in Atari 2600 games enables detailed analysis of
agents' decision-making in various game tasks. Further, experimental results
demonstrate that our method can achieve higher performance than the baseline in
some games.
</p></li>
</ul>

<h3>Title: Large Sequence Models for Sequential Decision-Making: A Survey. (arXiv:2306.13945v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.13945">http://arxiv.org/abs/2306.13945</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.13945] Large Sequence Models for Sequential Decision-Making: A Survey](http://arxiv.org/abs/2306.13945) #transformer</code></li>
<li>Summary: <p>Transformer architectures have facilitated the development of large-scale and
general-purpose sequence models for prediction tasks in natural language
processing and computer vision, e.g., GPT-3 and Swin Transformer. Although
originally designed for prediction problems, it is natural to inquire about
their suitability for sequential decision-making and reinforcement learning
problems, which are typically beset by long-standing issues involving sample
efficiency, credit assignment, and partial observability. In recent years,
sequence models, especially the Transformer, have attracted increasing interest
in the RL communities, spawning numerous approaches with notable effectiveness
and generalizability. This survey presents a comprehensive overview of recent
works aimed at solving sequential decision-making tasks with sequence models
such as the Transformer, by discussing the connection between sequential
decision-making and sequence modeling, and categorizing them based on the way
they utilize the Transformer. Moreover, this paper puts forth various potential
avenues for future research intending to improve the effectiveness of large
sequence models for sequential decision-making, encompassing theoretical
foundations, network architectures, algorithms, and efficient training systems.
As this article has been accepted by the Frontiers of Computer Science, here is
an early version, and the most up-to-date version can be found at
https://journal.hep.com.cn/fcs/EN/10.1007/s11704-023-2689-5
</p></li>
</ul>

<h3>Title: Waypoint Transformer: Reinforcement Learning via Supervised Learning with Intermediate Targets. (arXiv:2306.14069v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.14069">http://arxiv.org/abs/2306.14069</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.14069] Waypoint Transformer: Reinforcement Learning via Supervised Learning with Intermediate Targets](http://arxiv.org/abs/2306.14069) #transformer</code></li>
<li>Summary: <p>Despite the recent advancements in offline reinforcement learning via
supervised learning (RvS) and the success of the decision transformer (DT)
architecture in various domains, DTs have fallen short in several challenging
benchmarks. The root cause of this underperformance lies in their inability to
seamlessly connect segments of suboptimal trajectories. To overcome this
limitation, we present a novel approach to enhance RvS methods by integrating
intermediate targets. We introduce the Waypoint Transformer (WT), using an
architecture that builds upon the DT framework and conditioned on
automatically-generated waypoints. The results show a significant increase in
the final return compared to existing RvS methods, with performance on par or
greater than existing state-of-the-art temporal difference learning-based
methods. Additionally, the performance and stability improvements are largest
in the most challenging environments and data configurations, including AntMaze
Large Play/Diverse and Kitchen Mixed/Partial.
</p></li>
</ul>

<h2>generative</h2>
<h3>Title: Score-based Generative Models for Photoacoustic Image Reconstruction with Rotation Consistency Constraints. (arXiv:2306.13843v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.13843">http://arxiv.org/abs/2306.13843</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.13843] Score-based Generative Models for Photoacoustic Image Reconstruction with Rotation Consistency Constraints](http://arxiv.org/abs/2306.13843) #generative</code></li>
<li>Summary: <p>Photoacoustic tomography (PAT) is a newly emerged imaging modality which
enables both high optical contrast and acoustic depth of penetration.
Reconstructing images of photoacoustic tomography from limited amount of senser
data is among one of the major challenges in photoacoustic imaging. Previous
works based on deep learning were trained in supervised fashion, which directly
map the input partially known sensor data to the ground truth reconstructed
from full field of view. Recently, score-based generative models played an
increasingly significant role in generative modeling. Leveraging this
probabilistic model, we proposed Rotation Consistency Constrained Score-based
Generative Model (RCC-SGM), which recovers the PAT images by iterative sampling
between Langevin dynamics and a constraint term utilizing the rotation
consistency between the images and the measurements. Our proposed method can
generalize to different measurement processes (32.29 PSNR with 16 measurements
under random sampling, whereas 28.50 for supervised counterpart), while
supervised methods need to train on specific inverse mappings.
</p></li>
</ul>

<h3>Title: Spatio-temporal Storytelling? Leveraging Generative Models for Semantic Trajectory Analysis. (arXiv:2306.13905v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.13905">http://arxiv.org/abs/2306.13905</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.13905] Spatio-temporal Storytelling? Leveraging Generative Models for Semantic Trajectory Analysis](http://arxiv.org/abs/2306.13905) #generative</code></li>
<li>Summary: <p>In this paper, we lay out a vision for analysing semantic trajectory traces
and generating synthetic semantic trajectory data (SSTs) using generative
language model. Leveraging the advancements in deep learning, as evident by
progress in the field of natural language processing (NLP), computer vision,
etc. we intend to create intelligent models that can study the semantic
trajectories in various contexts, predicting future trends, increasing machine
understanding of the movement of animals, humans, goods, etc. enhancing
human-computer interactions, and contributing to an array of applications
ranging from urban-planning to personalized recommendation engines and business
strategy.
</p></li>
</ul>

<h3>Title: H$_2$O: Heavy-Hitter Oracle for Efficient Generative Inference of Large Language Models. (arXiv:2306.14048v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.14048">http://arxiv.org/abs/2306.14048</a></li>
<li>Code URL: <a href="https://github.com/fminference/h2o">https://github.com/fminference/h2o</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2306.14048] H$_2$O: Heavy-Hitter Oracle for Efficient Generative Inference of Large Language Models](http://arxiv.org/abs/2306.14048) #generative</code></li>
<li>Summary: <p>Large Language Models (LLMs), despite their recent impressive
accomplishments, are notably cost-prohibitive to deploy, particularly for
applications involving long-content generation, such as dialogue systems and
story writing. Often, a large amount of transient state information, referred
to as the KV cache, is stored in GPU memory in addition to model parameters,
scaling linearly with the sequence length and batch size. In this paper, we
introduce a novel approach for implementing the KV cache which significantly
reduces its memory footprint. Our approach is based on the noteworthy
observation that a small portion of tokens contributes most of the value when
computing attention scores. We call these tokens Heavy Hitters (H$_2$). Through
a comprehensive investigation, we find that (i) the emergence of H$_2$ is
natural and strongly correlates with the frequent co-occurrence of tokens in
the text, and (ii) removing them results in significant performance
degradation. Based on these insights, we propose Heavy Hitter Oracle (H$_2$O),
a KV cache eviction policy that dynamically retains a balance of recent and
H$_2$ tokens. We formulate the KV cache eviction as a dynamic submodular
problem and prove (under mild assumptions) a theoretical guarantee for our
novel eviction algorithm which could help guide future work. We validate the
accuracy of our algorithm with OPT, LLaMA, and GPT-NeoX across a wide range of
tasks. Our implementation of H$_2$O with 20% heavy hitters improves the
throughput over three leading inference systems DeepSpeed Zero-Inference,
Hugging Face Accelerate, and FlexGen by up to 29$\times$, 29$\times$, and
3$\times$ on OPT-6.7B and OPT-30B. With the same batch size, H2O can reduce the
latency by up to 1.9$\times$. The code is available at
https://github.com/FMInference/H2O.
</p></li>
</ul>

<h2>large language model</h2>
<h3>Title: DesCo: Learning Object Recognition with Rich Language Descriptions. (arXiv:2306.14060v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.14060">http://arxiv.org/abs/2306.14060</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.14060] DesCo: Learning Object Recognition with Rich Language Descriptions](http://arxiv.org/abs/2306.14060) #large language model</code></li>
<li>Summary: <p>Recent development in vision-language approaches has instigated a paradigm
shift in learning visual recognition models from language supervision. These
approaches align objects with language queries (e.g. "a photo of a cat") and
improve the models' adaptability to identify novel objects and domains.
Recently, several studies have attempted to query these models with complex
language expressions that include specifications of fine-grained semantic
details, such as attributes, shapes, textures, and relations. However, simply
incorporating language descriptions as queries does not guarantee accurate
interpretation by the models. In fact, our experiments show that GLIP, the
state-of-the-art vision-language model for object detection, often disregards
contextual information in the language descriptions and instead relies heavily
on detecting objects solely by their names. To tackle the challenges, we
propose a new description-conditioned (DesCo) paradigm of learning object
recognition models with rich language descriptions consisting of two major
innovations: 1) we employ a large language model as a commonsense knowledge
engine to generate rich language descriptions of objects based on object names
and the raw image-text caption; 2) we design context-sensitive queries to
improve the model's ability in deciphering intricate nuances embedded within
descriptions and enforce the model to focus on context rather than object names
alone. On two novel object detection benchmarks, LVIS and OminiLabel, under the
zero-shot detection setting, our approach achieves 34.8 APr minival (+9.1) and
29.3 AP (+3.6), respectively, surpassing the prior state-of-the-art models,
GLIP and FIBER, by a large margin.
</p></li>
</ul>

<h3>Title: Large Language Models as Sous Chefs: Revising Recipes with GPT-3. (arXiv:2306.13986v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.13986">http://arxiv.org/abs/2306.13986</a></li>
<li>Code URL: <a href="https://github.com/ahwang16/mturk-templates">https://github.com/ahwang16/mturk-templates</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2306.13986] Large Language Models as Sous Chefs: Revising Recipes with GPT-3](http://arxiv.org/abs/2306.13986) #large language model</code></li>
<li>Summary: <p>With their remarkably improved text generation and prompting capabilities,
large language models can adapt existing written information into forms that
are easier to use and understand. In our work, we focus on recipes as an
example of complex, diverse, and widely used instructions. We develop a prompt
grounded in the original recipe and ingredients list that breaks recipes down
into simpler steps. We apply this prompt to recipes from various world
cuisines, and experiment with several large language models (LLMs), finding
best results with GPT-3.5. We also contribute an Amazon Mechanical Turk task
that is carefully designed to reduce fatigue while collecting human judgment of
the quality of recipe revisions. We find that annotators usually prefer the
revision over the original, demonstrating a promising application of LLMs in
serving as digital sous chefs for recipes and beyond. We release our prompt,
code, and MTurk template for public use.
</p></li>
</ul>

<h3>Title: Chinese Fine-Grained Financial Sentiment Analysis with Large Language Models. (arXiv:2306.14096v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.14096">http://arxiv.org/abs/2306.14096</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.14096] Chinese Fine-Grained Financial Sentiment Analysis with Large Language Models](http://arxiv.org/abs/2306.14096) #large language model</code></li>
<li>Summary: <p>Entity-level fine-grained sentiment analysis in the financial domain is a
crucial subtask of sentiment analysis and currently faces numerous challenges.
The primary challenge stems from the lack of high-quality and large-scale
annotated corpora specifically designed for financial text sentiment analysis,
which in turn limits the availability of data necessary for developing
effective text processing techniques. Recent advancements in large language
models (LLMs) have yielded remarkable performance in natural language
processing tasks, primarily centered around language pattern matching. In this
paper, we propose a novel and extensive Chinese fine-grained financial
sentiment analysis dataset, FinChina SA, for enterprise early warning. We
thoroughly evaluate and experiment with well-known existing open-source LLMs
using our dataset. We firmly believe that our dataset will serve as a valuable
resource to advance the exploration of real-world financial sentiment analysis
tasks, which should be the focus of future research. Our dataset and all code
to replicate the experimental results will be released.
</p></li>
</ul>

<h3>Title: Language models are weak learners. (arXiv:2306.14101v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.14101">http://arxiv.org/abs/2306.14101</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.14101] Language models are weak learners](http://arxiv.org/abs/2306.14101) #large language model</code></li>
<li>Summary: <p>A central notion in practical and theoretical machine learning is that of a
$\textit{weak learner}$, classifiers that achieve better-than-random
performance (on any given distribution over data), even by a small margin. Such
weak learners form the practical basis for canonical machine learning methods
such as boosting. In this work, we illustrate that prompt-based large language
models can operate effectively as said weak learners. Specifically, we
illustrate the use of a large language model (LLM) as a weak learner in a
boosting algorithm applied to tabular data. We show that by providing (properly
sampled according to the distribution of interest) text descriptions of tabular
data samples, LLMs can produce a summary of the samples that serves as a
template for classification and achieves the aim of acting as a weak learner on
this task. We incorporate these models into a boosting approach, which in some
settings can leverage the knowledge within the LLM to outperform traditional
tree-based boosting. The model outperforms both few-shot learning and
occasionally even more involved fine-tuning procedures, particularly for tasks
involving small numbers of data points. The results illustrate the potential
for prompt-based LLMs to function not just as few-shot learners themselves, but
as components of larger machine learning pipelines.
</p></li>
</ul>

<h2>segmentation</h2>
<h3>Title: Improving Panoptic Segmentation for Nighttime or Low-Illumination Urban Driving Scenes. (arXiv:2306.13725v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.13725">http://arxiv.org/abs/2306.13725</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.13725] Improving Panoptic Segmentation for Nighttime or Low-Illumination Urban Driving Scenes](http://arxiv.org/abs/2306.13725) #segmentation</code></li>
<li>Summary: <p>Autonomous vehicles and driving systems use scene parsing as an essential
tool to understand the surrounding environment. Panoptic segmentation is a
state-of-the-art technique which proves to be pivotal in this use case. Deep
learning-based architectures have been utilized for effective and efficient
Panoptic Segmentation in recent times. However, when it comes to adverse
conditions like dark scenes with poor illumination or nighttime images,
existing methods perform poorly in comparison to daytime images. One of the
main factors for poor results is the lack of sufficient and accurately
annotated nighttime images for urban driving scenes. In this work, we propose
two new methods, first to improve the performance, and second to improve the
robustness of panoptic segmentation in nighttime or poor illumination urban
driving scenes using a domain translation approach. The proposed approach makes
use of CycleGAN (Zhu et al., 2017) to translate daytime images with existing
panoptic annotations into nighttime images, which are then utilized to retrain
a Panoptic segmentation model to improve performance and robustness under poor
illumination and nighttime conditions. In our experiments, Approach-1
demonstrates a significant improvement in the Panoptic segmentation performance
on the converted Cityscapes dataset with more than +10% PQ, +12% RQ, +2% SQ,
+14% mIoU and +10% AP50 absolute gain. Approach-2 demonstrates improved
robustness to varied nighttime driving environments. Both the approaches are
supported via comprehensive quantitative and qualitative analysis.
</p></li>
</ul>

<h3>Title: How to Efficiently Adapt Large Segmentation Model(SAM) to Medical Images. (arXiv:2306.13731v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.13731">http://arxiv.org/abs/2306.13731</a></li>
<li>Code URL: <a href="https://github.com/xhu248/autosam">https://github.com/xhu248/autosam</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2306.13731] How to Efficiently Adapt Large Segmentation Model(SAM) to Medical Images](http://arxiv.org/abs/2306.13731) #segmentation</code></li>
<li>Summary: <p>The emerging scale segmentation model, Segment Anything (SAM), exhibits
impressive capabilities in zero-shot segmentation for natural images. However,
when applied to medical images, SAM suffers from noticeable performance drop.
To make SAM a real ``foundation model" for the computer vision community, it is
critical to find an efficient way to customize SAM for medical image dataset.
In this work, we propose to freeze SAM encoder and finetune a lightweight
task-specific prediction head, as most of weights in SAM are contributed by the
encoder. In addition, SAM is a promptable model, while prompt is not
necessarily available in all application cases, and precise prompts for
multiple class segmentation are also time-consuming. Therefore, we explore
three types of prompt-free prediction heads in this work, include ViT, CNN, and
linear layers. For ViT head, we remove the prompt tokens in the mask decoder of
SAM, which is named AutoSAM. AutoSAM can also generate masks for different
classes with one single inference after modification. To evaluate the
label-efficiency of our finetuning method, we compare the results of these
three prediction heads on a public medical image segmentation dataset with
limited labeled data. Experiments demonstrate that finetuning SAM significantly
improves its performance on medical image dataset, even with just one labeled
volume. Moreover, AutoSAM and CNN prediction head also has better segmentation
accuracy than training from scratch and self-supervised learning approaches
when there is a shortage of annotations.
</p></li>
</ul>

<h3>Title: Efficient Annotation of Medieval Charters. (arXiv:2306.14071v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.14071">http://arxiv.org/abs/2306.14071</a></li>
<li>Code URL: <a href="https://github.com/anguelos/resolution_regressor">https://github.com/anguelos/resolution_regressor</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2306.14071] Efficient Annotation of Medieval Charters](http://arxiv.org/abs/2306.14071) #segmentation</code></li>
<li>Summary: <p>Diplomatics, the analysis of medieval charters, is a major field of research
in which paleography is applied. Annotating data, if performed by laymen, needs
validation and correction by experts. In this paper, we propose an effective
and efficient annotation approach for charter segmentation, essentially
reducing it to object detection. This approach allows for a much more efficient
use of the paleographer's time and produces results that can compete and even
outperform pixel-level segmentation in some use cases. Further experiments shed
light on how to design a class ontology in order to make the best use of
annotators' time and effort. Exploiting the presence of calibration cards in
the image, we further annotate the data with the physical length in pixels and
train regression neural networks to predict it from image patches.
</p></li>
</ul>

<h3>Title: When SAM Meets Sonar Images. (arXiv:2306.14109v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.14109">http://arxiv.org/abs/2306.14109</a></li>
<li>Code URL: <a href="https://github.com/wangsssky/sonarsam">https://github.com/wangsssky/sonarsam</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2306.14109] When SAM Meets Sonar Images](http://arxiv.org/abs/2306.14109) #segmentation</code></li>
<li>Summary: <p>Segment Anything Model (SAM) has revolutionized the way of segmentation.
However, SAM's performance may decline when applied to tasks involving domains
that differ from natural images. Nonetheless, by employing fine-tuning
techniques, SAM exhibits promising capabilities in specific domains, such as
medicine and planetary science. Notably, there is a lack of research on the
application of SAM to sonar imaging. In this paper, we aim to address this gap
by conducting a comprehensive investigation of SAM's performance on sonar
images. Specifically, we evaluate SAM using various settings on sonar images.
Additionally, we fine-tune SAM using effective methods both with prompts and
for semantic segmentation, thereby expanding its applicability to tasks
requiring automated segmentation. Experimental results demonstrate a
significant improvement in the performance of the fine-tuned SAM.
</p></li>
</ul>

<h3>Title: UAlberta at SemEval-2023 Task 1: Context Augmentation and Translation for Multilingual Visual Word Sense Disambiguation. (arXiv:2306.14067v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.14067">http://arxiv.org/abs/2306.14067</a></li>
<li>Code URL: <a href="https://github.com/ualberta-nlp/v-wsd">https://github.com/ualberta-nlp/v-wsd</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2306.14067] UAlberta at SemEval-2023 Task 1: Context Augmentation and Translation for Multilingual Visual Word Sense Disambiguation](http://arxiv.org/abs/2306.14067) #segmentation</code></li>
<li>Summary: <p>We describe the systems of the University of Alberta team for the
SemEval-2023 Visual Word Sense Disambiguation (V-WSD) Task. We present a novel
algorithm that leverages glosses retrieved from BabelNet, in combination with
text and image encoders. Furthermore, we compare language-specific encoders
against the application of English encoders to translated texts. As the
contexts given in the task datasets are extremely short, we also experiment
with augmenting these contexts with descriptions generated by a language model.
This yields substantial improvements in accuracy. We describe and evaluate
additional V-WSD methods which use image generation and text-conditioned image
segmentation. Overall, the results of our official submission rank us 18 out of
56 teams. Some of our unofficial results are even better than the official
ones. Our code is publicly available at https://github.com/UAlberta-NLP/v-wsd.
</p></li>
</ul>

<h3>Title: Aircraft Environmental Impact Segmentation via Metric Learning. (arXiv:2306.13830v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.13830">http://arxiv.org/abs/2306.13830</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.13830] Aircraft Environmental Impact Segmentation via Metric Learning](http://arxiv.org/abs/2306.13830) #segmentation</code></li>
<li>Summary: <p>Metric learning is the process of learning a tailored distance metric for a
particular task. This advanced subfield of machine learning is useful to any
machine learning or data mining task that relies on the computation of
distances or similarities over objects. In recently years, machine learning
techniques have been extensively used in aviation and aerospace engineering to
make predictions, extract patterns, discover knowledge, etc. Nevertheless,
metric learning, an element that can advance the performance of complex machine
learning tasks, has so far been hardly utilized in relevant literature. In this
study, we apply classic metric learning formulations with novel components on
aviation environmental impact modeling. Through a weakly-supervised metric
learning task, we achieve significant improvement in the newly emerged problem
of aircraft characterization and segmentation for environmental impacts. The
result will enable the more efficient and accurate modeling of aircraft
environmental impacts, a focal topic in sustainable aviation. This work is also
a demonstration that shows the potential and value of metric learning in a wide
variety of similar studies in the transportation domain.
</p></li>
</ul>

<button id="copy">Copy All</button>
</article>
<script src="https://cdn.staticfile.org/clipboard.js/2.0.4/clipboard.min.js"></script>
<script src="../../javascript/clipboard.js"></script>
