<link rel="stylesheet" href="../../css/markdown.css" />
<article class="markdown-body">
<h2>secure</h2>
<h3>Title: FedNC: A Secure and Efficient Federated Learning Method Inspired by Network Coding. (arXiv:2305.03292v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2305.03292">http://arxiv.org/abs/2305.03292</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2305.03292] FedNC: A Secure and Efficient Federated Learning Method Inspired by Network Coding](http://arxiv.org/abs/2305.03292) #secure</code></li>
<li>Summary: <p>Federated Learning (FL) is a promising distributed learning mechanism which
still faces two major challenges, namely privacy breaches and system
efficiency. In this work, we reconceptualize the FL system from the perspective
of network information theory, and formulate an original FL communication
framework, FedNC, which is inspired by Network Coding (NC). The main idea of
FedNC is mixing the information of the local models by making random linear
combinations of the original packets, before uploading for further aggregation.
Due to the benefits of the coding scheme, both theoretical and experimental
analysis indicate that FedNC improves the performance of traditional FL in
several important ways, including security, throughput, and robustness. To the
best of our knowledge, this is the first framework where NC is introduced in
FL. As FL continues to evolve within practical network frameworks, more
applications and variants can be further designed based on FedNC.
</p></li>
</ul>

<h3>Title: Detecting GNSS misbehavior leveraging secure heterogeneous time sources. (arXiv:2305.03385v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2305.03385">http://arxiv.org/abs/2305.03385</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2305.03385] Detecting GNSS misbehavior leveraging secure heterogeneous time sources](http://arxiv.org/abs/2305.03385) #secure</code></li>
<li>Summary: <p>Civilian Global Navigation Satellite Systems (GNSS) vulnerabilities are a
threat to a wide gamut of critical systems. GNSS receivers, as part of the
encompassing platform, can leverage external information to detect GNSS
attacks. Specifically, cross-checking the time produced by the GNSS receiver
against multiple trusted time sources can provide robust and assured PNT. In
this work, we explore the combination of secure remote, network-based time
providers and local precision oscillators. This multi-layered defense mechanism
detects GNSS attacks that induce even small time offsets, including attacks
mounted in cold start. Our system does not require any modification to the
current structure of the GNSS receiver, it is agnostic to the satellite
constellation and the attacker type. This makes time-based data validation of
GNSS information compatible with existing receivers and readily deployable.
</p></li>
</ul>

<h2>security</h2>
<h3>Title: BadSAM: Exploring Security Vulnerabilities of SAM via Backdoor Attacks. (arXiv:2305.03289v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2305.03289">http://arxiv.org/abs/2305.03289</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2305.03289] BadSAM: Exploring Security Vulnerabilities of SAM via Backdoor Attacks](http://arxiv.org/abs/2305.03289) #security</code></li>
<li>Summary: <p>Recently, the Segment Anything Model (SAM) has gained significant attention
as an image segmentation foundation model due to its strong performance on
various downstream tasks. However, it has been found that SAM does not always
perform satisfactorily when faced with challenging downstream tasks. This has
led downstream users to demand a customized SAM model that can be adapted to
these downstream tasks. In this paper, we present BadSAM, the first backdoor
attack on the image segmentation foundation model. Our preliminary experiments
on the CAMO dataset demonstrate the effectiveness of BadSAM.
</p></li>
</ul>

<h3>Title: A Serious Game for Simulating Cyberattacks to Teach Cybersecurity. (arXiv:2305.03062v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2305.03062">http://arxiv.org/abs/2305.03062</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2305.03062] A Serious Game for Simulating Cyberattacks to Teach Cybersecurity](http://arxiv.org/abs/2305.03062) #security</code></li>
<li>Summary: <p>With the rising number of cyberattacks, such as ransomware attacks and cyber
espionage, educating non-cybersecurity professionals to recognize threats has
become more important than ever before. However, traditional training methods,
such as phishing awareness campaigns, training videos and assessments have
proven to be less effective over time. Therefore, it is time to rethink the
approach on how to train cyber awareness. In this paper we suggest an
alternative approach -- a serious game -- to educate awareness for common
cyberattacks. While many serious games for cybersecurity education exist, all
follow a very similar approach: showing people the effects of a cyber attack on
their own system or company network. For example, one of the main tasks in
these games is to sort out phishing mails. We developed and evaluated a new
type of cybersecurity game: an attack simulator, which shows the entire setting
from a different perspective. Instead of sorting out phishing mails the players
should write phishing mails to trick potential victims and use other forms of
cyberattacks. Our game explains the intention of each attack and shows the
consequences of a successful attack. This way, we hope, players will get a
better understanding on how to detect cyberattacks.
</p></li>
</ul>

<h3>Title: POET: A Self-learning Framework for PROFINET Industrial Operations Behaviour. (arXiv:2305.03175v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2305.03175">http://arxiv.org/abs/2305.03175</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2305.03175] POET: A Self-learning Framework for PROFINET Industrial Operations Behaviour](http://arxiv.org/abs/2305.03175) #security</code></li>
<li>Summary: <p>Since 2010, multiple cyber incidents on industrial infrastructure, such as
Stuxnet and CrashOverride, have exposed the vulnerability of Industrial Control
Systems (ICS) to cyber threats. The industrial systems are commissioned for
longer duration amounting to decades, often resulting in non-compliance to
technological advancements in industrial cybersecurity mechanisms. The
unavailability of network infrastructure information makes designing the
security policies or configuring the cybersecurity countermeasures such as
Network Intrusion Detection Systems (NIDS) challenging. An empirical solution
is to self-learn the network infrastructure information of an industrial system
from its monitored network traffic to make the network transparent for
downstream analyses tasks such as anomaly detection. In this work, a
Python-based industrial communication paradigm-aware framework, named PROFINET
Operations Enumeration and Tracking (POET), that enumerates different
industrial operations executed in a deterministic order of a PROFINET-based
industrial system is reported. The operation-driving industrial network
protocol frames are dissected for enumeration of the operations. For the
requirements of capturing the transitions between industrial operations
triggered by the communication events, the Finite State Machines (FSM) are
modelled to enumerate the PROFINET operations of the device, connection and
system. POET extracts the network information from network traffic to
instantiate appropriate FSM models (Device, Connection or System) and track the
industrial operations. It successfully detects and reports the anomalies
triggered by a network attack in a miniaturized PROFINET-based industrial
system, executed through valid network protocol exchanges and resulting in
invalid PROFINET operation transition for the device.
</p></li>
</ul>

<h3>Title: Hardware Honeypot: Setting Sequential Reverse Engineering on a Wrong Track. (arXiv:2305.03707v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2305.03707">http://arxiv.org/abs/2305.03707</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2305.03707] Hardware Honeypot: Setting Sequential Reverse Engineering on a Wrong Track](http://arxiv.org/abs/2305.03707) #security</code></li>
<li>Summary: <p>Reverse engineering of finite state machines is a serious threat when
protecting designs against reverse engineering attacks. While most recent
protection techniques rely on the security of a secret key, this work presents
a new approach: hardware state machine honeypots. These honeypots lead the
reverse engineering tools to a wrong, but for the tools highly attractive state
machine, while the original state machine is made less attractive. The results
show that state-of-the-art reverse engineering methods favor the highly
attractive honeypot as state machine candidate or do no longer detect the
correct, original state machine.
</p></li>
</ul>

<h2>privacy</h2>
<h3>Title: Reconstructing Training Data from Multiclass Neural Networks. (arXiv:2305.03350v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2305.03350">http://arxiv.org/abs/2305.03350</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2305.03350] Reconstructing Training Data from Multiclass Neural Networks](http://arxiv.org/abs/2305.03350) #privacy</code></li>
<li>Summary: <p>Reconstructing samples from the training set of trained neural networks is a
major privacy concern. Haim et al. (2022) recently showed that it is possible
to reconstruct training samples from neural network binary classifiers, based
on theoretical results about the implicit bias of gradient methods. In this
work, we present several improvements and new insights over this previous work.
As our main improvement, we show that training-data reconstruction is possible
in the multi-class setting and that the reconstruction quality is even higher
than in the case of binary classification. Moreover, we show that using
weight-decay during training increases the vulnerability to sample
reconstruction. Finally, while in the previous work the training set was of
size at most $1000$ from $10$ classes, we show preliminary evidence of the
ability to reconstruct from a model trained on $5000$ samples from $100$
classes.
</p></li>
</ul>

<h3>Title: Training Natural Language Processing Models on Encrypted Text for Enhanced Privacy. (arXiv:2305.03497v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2305.03497">http://arxiv.org/abs/2305.03497</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2305.03497] Training Natural Language Processing Models on Encrypted Text for Enhanced Privacy](http://arxiv.org/abs/2305.03497) #privacy</code></li>
<li>Summary: <p>With the increasing use of cloud-based services for training and deploying
machine learning models, data privacy has become a major concern. This is
particularly important for natural language processing (NLP) models, which
often process sensitive information such as personal communications and
confidential documents. In this study, we propose a method for training NLP
models on encrypted text data to mitigate data privacy concerns while
maintaining similar performance to models trained on non-encrypted data. We
demonstrate our method using two different architectures, namely
Doc2Vec+XGBoost and Doc2Vec+LSTM, and evaluate the models on the 20 Newsgroups
dataset. Our results indicate that both encrypted and non-encrypted models
achieve comparable performance, suggesting that our encryption method is
effective in preserving data privacy without sacrificing model accuracy. In
order to replicate our experiments, we have provided a Colab notebook at the
following address: https://t.ly/lR-TP
</p></li>
</ul>

<h3>Title: Digital and Cloud Forensic Challenges. (arXiv:2305.03059v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2305.03059">http://arxiv.org/abs/2305.03059</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2305.03059] Digital and Cloud Forensic Challenges](http://arxiv.org/abs/2305.03059) #privacy</code></li>
<li>Summary: <p>Digital forensics and cloud forensics are increasingly important fields that
face a range of challenges. This study aims to assess the general challenges
faced in these fields. A literature review was conducted to identify the major
challenges in digital and cloud forensics, including data acquisition, data
analysis, data preservation, privacy concerns, and legal issues. The challenges
were analyzed in detail, considering the reasons why they are challenges, the
impact they have on digital and cloud forensics, and any potential solutions.
The study concludes that the challenges faced in digital and cloud forensics
are significant and varied, and that addressing these challenges is critical
for the effective and efficient use of digital and cloud forensics in
investigations. This study provides a valuable overview of the current state of
digital and cloud forensic challenges and can help guide future research in
this important field.
</p></li>
</ul>

<h3>Title: Over-the-Air Federated Averaging with Limited Power and Privacy Budgets. (arXiv:2305.03547v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2305.03547">http://arxiv.org/abs/2305.03547</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2305.03547] Over-the-Air Federated Averaging with Limited Power and Privacy Budgets](http://arxiv.org/abs/2305.03547) #privacy</code></li>
<li>Summary: <p>To jointly overcome the communication bottleneck and privacy leakage of
wireless federated learning (FL), this paper studies a differentially private
over-the-air federated averaging (DP-OTA-FedAvg) system with a limited sum
power budget. With DP-OTA-FedAvg, the gradients are aligned by an alignment
coefficient and aggregated over the air, and channel noise is employed to
protect privacy. We aim to improve the learning performance by jointly
designing the device scheduling, alignment coefficient, and the number of
aggregation rounds of federated averaging (FedAvg) subject to sum power and
privacy constraints. We first present the privacy analysis based on
differential privacy (DP) to quantify the impact of the alignment coefficient
on privacy preservation in each communication round. Furthermore, to study how
the device scheduling, alignment coefficient, and the number of the global
aggregation affect the learning process, we conduct the convergence analysis of
DP-OTA-FedAvg in the cases of convex and non-convex loss functions. Based on
these analytical results, we formulate an optimization problem to minimize the
optimality gap of the DP-OTA-FedAvg subject to limited sum power and privacy
budgets. The problem is solved by decoupling it into two sub-problems. Given
the number of communication rounds, we conclude the relationship between the
number of scheduled devices and the alignment coefficient, which offers a set
of potential optimal solution pairs of device scheduling and the alignment
coefficient. Thanks to the reduced search space, the optimal solution can be
efficiently obtained. The effectiveness of the proposed policy is validated
through simulations.
</p></li>
</ul>

<h3>Title: Data Encoding For Healthcare Data Democratisation and Information Leakage Prevention. (arXiv:2305.03710v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2305.03710">http://arxiv.org/abs/2305.03710</a></li>
<li>Code URL: <a href="https://github.com/AnshThakur/Quantum-Encoding">https://github.com/AnshThakur/Quantum-Encoding</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2305.03710] Data Encoding For Healthcare Data Democratisation and Information Leakage Prevention](http://arxiv.org/abs/2305.03710) #privacy</code></li>
<li>Summary: <p>The lack of data democratization and information leakage from trained models
hinder the development and acceptance of robust deep learning-based healthcare
solutions. This paper argues that irreversible data encoding can provide an
effective solution to achieve data democratization without violating the
privacy constraints imposed on healthcare data and clinical models. An ideal
encoding framework transforms the data into a new space where it is
imperceptible to a manual or computational inspection. However, encoded data
should preserve the semantics of the original data such that deep learning
models can be trained effectively. This paper hypothesizes the characteristics
of the desired encoding framework and then exploits random projections and
random quantum encoding to realize this framework for dense and longitudinal or
time-series data. Experimental evaluation highlights that models trained on
encoded time-series data effectively uphold the information bottleneck
principle and hence, exhibit lesser information leakage from trained models.
</p></li>
</ul>

<h3>Title: A Comprehensive Study on Dataset Distillation: Performance, Privacy, Robustness and Fairness. (arXiv:2305.03355v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2305.03355">http://arxiv.org/abs/2305.03355</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2305.03355] A Comprehensive Study on Dataset Distillation: Performance, Privacy, Robustness and Fairness](http://arxiv.org/abs/2305.03355) #privacy</code></li>
<li>Summary: <p>The aim of dataset distillation is to encode the rich features of an original
dataset into a tiny dataset. It is a promising approach to accelerate neural
network training and related studies. Different approaches have been proposed
to improve the informativeness and generalization performance of distilled
images. However, no work has comprehensively analyzed this technique from a
security perspective and there is a lack of systematic understanding of
potential risks. In this work, we conduct extensive experiments to evaluate
current state-of-the-art dataset distillation methods. We successfully use
membership inference attacks to show that privacy risks still remain. Our work
also demonstrates that dataset distillation can cause varying degrees of impact
on model robustness and amplify model unfairness across classes when making
predictions. This work offers a large-scale benchmarking framework for dataset
distillation evaluation.
</p></li>
</ul>

<h3>Title: Is dataset condensation a silver bullet for healthcare data sharing?. (arXiv:2305.03711v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2305.03711">http://arxiv.org/abs/2305.03711</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2305.03711] Is dataset condensation a silver bullet for healthcare data sharing?](http://arxiv.org/abs/2305.03711) #privacy</code></li>
<li>Summary: <p>Safeguarding personal information is paramount for healthcare data sharing, a
challenging issue without any silver bullet thus far. We study the prospect of
a recent deep-learning advent, dataset condensation (DC), in sharing healthcare
data for AI research, and the results are promising. The condensed data
abstracts original records and irreversibly conceals individual-level knowledge
to achieve a bona fide de-identification, which permits free sharing. Moreover,
the original deep-learning utilities are well preserved in the condensed data
with compressed volume and accelerated model convergences. In PhysioNet-2012, a
condensed dataset of 20 samples can orient deep models attaining 80.3% test AUC
of mortality prediction (versus 85.8% of 5120 original records), an inspiring
discovery generalised to MIMIC-III and Coswara datasets. We also interpret the
inhere privacy protections of DC through theoretical analysis and empirical
evidence. Dataset condensation opens a new gate to sharing healthcare data for
AI research with multiple desirable traits.
</p></li>
</ul>

<h2>protect</h2>
<h3>Title: Leaf Cultivar Identification via Prototype-enhanced Learning. (arXiv:2305.03351v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2305.03351">http://arxiv.org/abs/2305.03351</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2305.03351] Leaf Cultivar Identification via Prototype-enhanced Learning](http://arxiv.org/abs/2305.03351) #protect</code></li>
<li>Summary: <p>Plant leaf identification is crucial for biodiversity protection and
conservation and has gradually attracted the attention of academia in recent
years. Due to the high similarity among different varieties, leaf cultivar
recognition is also considered to be an ultra-fine-grained visual
classification (UFGVC) task, which is facing a huge challenge. In practice, an
instance may be related to multiple varieties to varying degrees, especially in
the UFGVC datasets. However, deep learning methods trained on one-hot labels
fail to reflect patterns shared across categories and thus perform poorly on
this task. To address this issue, we generate soft targets integrated with
inter-class similarity information. Specifically, we continuously update the
prototypical features for each category and then capture the similarity scores
between instances and prototypes accordingly. Original one-hot labels and the
similarity scores are incorporated to yield enhanced labels. Prototype-enhanced
soft labels not only contain original one-hot label information, but also
introduce rich inter-category semantic association information, thus providing
more effective supervision for deep model training. Extensive experimental
results on public datasets show that our method can significantly improve the
performance on the UFGVC task of leaf cultivar identification.
</p></li>
</ul>

<h3>Title: Sensitive Data Detection with High-Throughput Machine Learning Models in Electrical Health Records. (arXiv:2305.03169v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2305.03169">http://arxiv.org/abs/2305.03169</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2305.03169] Sensitive Data Detection with High-Throughput Machine Learning Models in Electrical Health Records](http://arxiv.org/abs/2305.03169) #protect</code></li>
<li>Summary: <p>In the era of big data, there is an increasing need for healthcare providers,
communities, and researchers to share data and collaborate to improve health
outcomes, generate valuable insights, and advance research. The Health
Insurance Portability and Accountability Act of 1996 (HIPAA) is a federal law
designed to protect sensitive health information by defining regulations for
protected health information (PHI). However, it does not provide efficient
tools for detecting or removing PHI before data sharing. One of the challenges
in this area of research is the heterogeneous nature of PHI fields in data
across different parties. This variability makes rule-based sensitive variable
identification systems that work on one database fail on another. To address
this issue, our paper explores the use of machine learning algorithms to
identify sensitive variables in structured data, thus facilitating the
de-identification process. We made a key observation that the distributions of
metadata of PHI fields and non-PHI fields are very different. Based on this
novel finding, we engineered over 30 features from the metadata of the original
features and used machine learning to build classification models to
automatically identify PHI fields in structured Electronic Health Record (EHR)
data. We trained the model on a variety of large EHR databases from different
data sources and found that our algorithm achieves 99% accuracy when detecting
PHI-related fields for unseen datasets. The implications of our study are
significant and can benefit industries that handle sensitive data.
</p></li>
</ul>

<h3>Title: All models are local: time to replace external validation with recurrent local validation. (arXiv:2305.03219v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2305.03219">http://arxiv.org/abs/2305.03219</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2305.03219] All models are local: time to replace external validation with recurrent local validation](http://arxiv.org/abs/2305.03219) #protect</code></li>
<li>Summary: <p>External validation is often recommended to ensure the generalizability of ML
models. However, it neither guarantees generalizability nor equates to a
model's clinical usefulness (the ultimate goal of any clinical decision-support
tool). External validation is misaligned with current healthcare ML needs.
First, patient data changes across time, geography, and facilities. These
changes create significant volatility in the performance of a single fixed
model (especially for deep learning models, which dominate clinical ML).
Second, newer ML techniques, current market forces, and updated regulatory
frameworks are enabling frequent updating and monitoring of individual deployed
model instances. We submit that external validation is insufficient to
establish ML models' safety or utility. Proposals to fix the external
validation paradigm do not go far enough. Continued reliance on it as the
ultimate test is likely to lead us astray. We propose the MLOps-inspired
paradigm of recurring local validation as an alternative that ensures the
validity of models while protecting against performance-disruptive data
variability. This paradigm relies on site-specific reliability tests before
every deployment, followed by regular and recurrent checks throughout the life
cycle of the deployed algorithm. Initial and recurrent reliability tests
protect against performance-disruptive distribution shifts, and concept drifts
that jeopardize patient safety.
</p></li>
</ul>

<h2>defense</h2>
<h2>attack</h2>
<h3>Title: New Adversarial Image Detection Based on Sentiment Analysis. (arXiv:2305.03173v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2305.03173">http://arxiv.org/abs/2305.03173</a></li>
<li>Code URL: <a href="https://github.com/wangfrombupt/adversarial_detector">https://github.com/wangfrombupt/adversarial_detector</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2305.03173] New Adversarial Image Detection Based on Sentiment Analysis](http://arxiv.org/abs/2305.03173) #attack</code></li>
<li>Summary: <p>Deep Neural Networks (DNNs) are vulnerable to adversarial examples, while
adversarial attack models, e.g., DeepFool, are on the rise and outrunning
adversarial example detection techniques. This paper presents a new adversarial
example detector that outperforms state-of-the-art detectors in identifying the
latest adversarial attacks on image datasets. Specifically, we propose to use
sentiment analysis for adversarial example detection, qualified by the
progressively manifesting impact of an adversarial perturbation on the
hidden-layer feature maps of a DNN under attack. Accordingly, we design a
modularized embedding layer with the minimum learnable parameters to embed the
hidden-layer feature maps into word vectors and assemble sentences ready for
sentiment analysis. Extensive experiments demonstrate that the new detector
consistently surpasses the state-of-the-art detection algorithms in detecting
the latest attacks launched against ResNet and Inception neutral networks on
the CIFAR-10, CIFAR-100 and SVHN datasets. The detector only has about 2
million parameters, and takes shorter than 4.6 milliseconds to detect an
adversarial example generated by the latest attack models using a Tesla K80 GPU
card.
</p></li>
</ul>

<h3>Title: Robust Face Morphing Attack Detection Using Fusion of Multiple Features and Classification Techniques. (arXiv:2305.03264v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2305.03264">http://arxiv.org/abs/2305.03264</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2305.03264] Robust Face Morphing Attack Detection Using Fusion of Multiple Features and Classification Techniques](http://arxiv.org/abs/2305.03264) #attack</code></li>
<li>Summary: <p>Face Recognition System (FRS) are shown to be vulnerable to morphed images of
newborns. Detecting morphing attacks stemming from face images of newborn is
important to avoid unwanted consequences, both for security and society. In
this paper, we present a new reference-based/Differential Morphing Attack
Detection (MAD) method to detect newborn morphing images using Wavelet
Scattering Network (WSN). We propose a two-layer WSN with 250 $\times$ 250
pixels and six rotations of wavelets per layer, resulting in 577 paths. The
proposed approach is validated on a dataset of 852 bona fide images and 2460
morphing images constructed using face images of 42 unique newborns. The
obtained results indicate a gain of over 10\% in detection accuracy over other
existing D-MAD techniques.
</p></li>
</ul>

<h3>Title: White-Box Multi-Objective Adversarial Attack on Dialogue Generation. (arXiv:2305.03655v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2305.03655">http://arxiv.org/abs/2305.03655</a></li>
<li>Code URL: <a href="https://github.com/yul091/dgslow">https://github.com/yul091/dgslow</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2305.03655] White-Box Multi-Objective Adversarial Attack on Dialogue Generation](http://arxiv.org/abs/2305.03655) #attack</code></li>
<li>Summary: <p>Pre-trained transformers are popular in state-of-the-art dialogue generation
(DG) systems. Such language models are, however, vulnerable to various
adversarial samples as studied in traditional tasks such as text
classification, which inspires our curiosity about their robustness in DG
systems. One main challenge of attacking DG models is that perturbations on the
current sentence can hardly degrade the response accuracy because the unchanged
chat histories are also considered for decision-making. Instead of merely
pursuing pitfalls of performance metrics such as BLEU, ROUGE, we observe that
crafting adversarial samples to force longer generation outputs benefits attack
effectiveness -- the generated responses are typically irrelevant, lengthy, and
repetitive. To this end, we propose a white-box multi-objective attack method
called DGSlow. Specifically, DGSlow balances two objectives -- generation
accuracy and length, via a gradient-based multi-objective optimizer and applies
an adaptive searching mechanism to iteratively craft adversarial samples with
only a few modifications. Comprehensive experiments on four benchmark datasets
demonstrate that DGSlow could significantly degrade state-of-the-art DG models
with a higher success rate than traditional accuracy-based methods. Besides,
our crafted sentences also exhibit strong transferability in attacking other
models.
</p></li>
</ul>

<h3>Title: RARES: Runtime Attack Resilient Embedded System Design Using Verified Proof-of-Execution. (arXiv:2305.03266v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2305.03266">http://arxiv.org/abs/2305.03266</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2305.03266] RARES: Runtime Attack Resilient Embedded System Design Using Verified Proof-of-Execution](http://arxiv.org/abs/2305.03266) #attack</code></li>
<li>Summary: <p>Modern society is getting accustomed to the Internet of Things (IoT) and
Cyber-Physical Systems (CPS) for a variety of applications that involves
security-critical user data and information transfers. In the lower end of the
spectrum, these devices are resource-constrained with no attack protection.
They become a soft target for malicious code modification attacks that steals
and misuses device data in malicious activities. The resilient system requires
continuous detection, prevention, and/or recovery and correct code execution
(including in degraded mode). By end large, existing security primitives (e.g.,
secure-boot, Remote Attestation RA, Control Flow Attestation (CFA) and Data
Flow Attestation (DFA)) focuses on detection and prevention, leaving the proof
of code execution and recovery unanswered. To this end, the proposed work
presents lightweight RARES -- Runtime Attack Resilient Embedded System design
using verified Proof-of-Execution. It presents first custom hardware control
register (Ctrl_register) based runtime memory modification attacks
classification and detection technique. It further demonstrates the Proof Of
Concept (POC) implementation of use-case-specific attacks prevention and
onboard recovery techniques. The prototype implementation on Artix 7 Field
Programmable Gate Array (FPGA) and state-of-the-art comparison demonstrates
very low (2.3%) resource overhead and efficacy of the proposed solution.
</p></li>
</ul>

<h2>robust</h2>
<h3>Title: Generating Virtual On-body Accelerometer Data from Virtual Textual Descriptions for Human Activity Recognition. (arXiv:2305.03187v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2305.03187">http://arxiv.org/abs/2305.03187</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2305.03187] Generating Virtual On-body Accelerometer Data from Virtual Textual Descriptions for Human Activity Recognition](http://arxiv.org/abs/2305.03187) #robust</code></li>
<li>Summary: <p>The development of robust, generalized models in human activity recognition
(HAR) has been hindered by the scarcity of large-scale, labeled data sets.
Recent work has shown that virtual IMU data extracted from videos using
computer vision techniques can lead to substantial performance improvements
when training HAR models combined with small portions of real IMU data.
Inspired by recent advances in motion synthesis from textual descriptions and
connecting Large Language Models (LLMs) to various AI models, we introduce an
automated pipeline that first uses ChatGPT to generate diverse textual
descriptions of activities. These textual descriptions are then used to
generate 3D human motion sequences via a motion synthesis model, T2M-GPT, and
later converted to streams of virtual IMU data. We benchmarked our approach on
three HAR datasets (RealWorld, PAMAP2, and USC-HAD) and demonstrate that the
use of virtual IMU training data generated using our new approach leads to
significantly improved HAR model performance compared to only using real IMU
data. Our approach contributes to the growing field of cross-modality transfer
methods and illustrate how HAR models can be improved through the generation of
virtual training data that do not require any manual effort.
</p></li>
</ul>

<h3>Title: FlowText: Synthesizing Realistic Scene Text Video with Optical Flow Estimation. (arXiv:2305.03327v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2305.03327">http://arxiv.org/abs/2305.03327</a></li>
<li>Code URL: <a href="https://github.com/callsys/flowtext">https://github.com/callsys/flowtext</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2305.03327] FlowText: Synthesizing Realistic Scene Text Video with Optical Flow Estimation](http://arxiv.org/abs/2305.03327) #robust</code></li>
<li>Summary: <p>Current video text spotting methods can achieve preferable performance,
powered with sufficient labeled training data. However, labeling data manually
is time-consuming and labor-intensive. To overcome this, using low-cost
synthetic data is a promising alternative. This paper introduces a novel video
text synthesis technique called FlowText, which utilizes optical flow
estimation to synthesize a large amount of text video data at a low cost for
training robust video text spotters. Unlike existing methods that focus on
image-level synthesis, FlowText concentrates on synthesizing temporal
information of text instances across consecutive frames using optical flow.
This temporal information is crucial for accurately tracking and spotting text
in video sequences, including text movement, distortion, appearance,
disappearance, shelter, and blur. Experiments show that combining general
detectors like TransDETR with the proposed FlowText produces remarkable results
on various datasets, such as ICDAR2015video and ICDAR2013video. Code is
available at https://github.com/callsys/FlowText.
</p></li>
</ul>

<h3>Title: Towards Effective Collaborative Learning in Long-Tailed Recognition. (arXiv:2305.03378v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2305.03378">http://arxiv.org/abs/2305.03378</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2305.03378] Towards Effective Collaborative Learning in Long-Tailed Recognition](http://arxiv.org/abs/2305.03378) #robust</code></li>
<li>Summary: <p>Real-world data usually suffers from severe class imbalance and long-tailed
distributions, where minority classes are significantly underrepresented
compared to the majority ones. Recent research prefers to utilize multi-expert
architectures to mitigate the model uncertainty on the minority, where
collaborative learning is employed to aggregate the knowledge of experts, i.e.,
online distillation. In this paper, we observe that the knowledge transfer
between experts is imbalanced in terms of class distribution, which results in
limited performance improvement of the minority classes. To address it, we
propose a re-weighted distillation loss by comparing two classifiers'
predictions, which are supervised by online distillation and label annotations,
respectively. We also emphasize that feature-level distillation will
significantly improve model performance and increase feature robustness.
Finally, we propose an Effective Collaborative Learning (ECL) framework that
integrates a contrastive proxy task branch to further improve feature quality.
Quantitative and qualitative experiments on four standard datasets demonstrate
that ECL achieves state-of-the-art performance and the detailed ablation
studies manifest the effectiveness of each component in ECL.
</p></li>
</ul>

<h3>Title: HD2Reg: Hierarchical Descriptors and Detectors for Point Cloud Registration. (arXiv:2305.03487v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2305.03487">http://arxiv.org/abs/2305.03487</a></li>
<li>Code URL: <a href="https://github.com/hui-design/hd2reg">https://github.com/hui-design/hd2reg</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2305.03487] HD2Reg: Hierarchical Descriptors and Detectors for Point Cloud Registration](http://arxiv.org/abs/2305.03487) #robust</code></li>
<li>Summary: <p>Feature Descriptors and Detectors are two main components of feature-based
point cloud registration. However, little attention has been drawn to the
explicit representation of local and global semantics in the learning of
descriptors and detectors. In this paper, we present a framework that
explicitly extracts dual-level descriptors and detectors and performs
coarse-to-fine matching with them. First, to explicitly learn local and global
semantics, we propose a hierarchical contrastive learning strategy, training
the robust matching ability of high-level descriptors, and refining the local
feature space using low-level descriptors. Furthermore, we propose to learn
dual-level saliency maps that extract two groups of keypoints in two different
senses. To overcome the weak supervision of binary matchability labels, we
propose a ranking strategy to label the significance ranking of keypoints, and
thus provide more fine-grained supervision signals. Finally, we propose a
global-to-local matching scheme to obtain robust and accurate correspondences
by leveraging the complementary dual-level features.Quantitative experiments on
3DMatch and KITTI odometry datasets show that our method achieves robust and
accurate point cloud registration and outperforms recent keypoint-based
methods.
</p></li>
</ul>

<h3>Title: DualCross: Cross-Modality Cross-Domain Adaptation for Monocular BEV Perception. (arXiv:2305.03724v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2305.03724">http://arxiv.org/abs/2305.03724</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2305.03724] DualCross: Cross-Modality Cross-Domain Adaptation for Monocular BEV Perception](http://arxiv.org/abs/2305.03724) #robust</code></li>
<li>Summary: <p>Closing the domain gap between training and deployment and incorporating
multiple sensor modalities are two challenging yet critical topics for
self-driving. Existing work only focuses on single one of the above topics,
overlooking the simultaneous domain and modality shift which pervasively exists
in real-world scenarios. A model trained with multi-sensor data collected in
Europe may need to run in Asia with a subset of input sensors available. In
this work, we propose DualCross, a cross-modality cross-domain adaptation
framework to facilitate the learning of a more robust monocular bird's-eye-view
(BEV) perception model, which transfers the point cloud knowledge from a LiDAR
sensor in one domain during the training phase to the camera-only testing
scenario in a different domain. This work results in the first open analysis of
cross-domain cross-sensor perception and adaptation for monocular 3D tasks in
the wild. We benchmark our approach on large-scale datasets under a wide range
of domain shifts and show state-of-the-art results against various baselines.
</p></li>
</ul>

<h3>Title: Investigating Lexical Sharing in Multilingual Machine Translation for Indian Languages. (arXiv:2305.03207v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2305.03207">http://arxiv.org/abs/2305.03207</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2305.03207] Investigating Lexical Sharing in Multilingual Machine Translation for Indian Languages](http://arxiv.org/abs/2305.03207) #robust</code></li>
<li>Summary: <p>Multilingual language models have shown impressive cross-lingual transfer
ability across a diverse set of languages and tasks. To improve the
cross-lingual ability of these models, some strategies include transliteration
and finer-grained segmentation into characters as opposed to subwords. In this
work, we investigate lexical sharing in multilingual machine translation (MT)
from Hindi, Gujarati, Nepali into English. We explore the trade-offs that exist
in translation performance between data sampling and vocabulary size, and we
explore whether transliteration is useful in encouraging cross-script
generalisation. We also verify how the different settings generalise to unseen
languages (Marathi and Bengali). We find that transliteration does not give
pronounced improvements and our analysis suggests that our multilingual MT
models trained on original scripts seem to already be robust to cross-script
differences even for relatively low-resource languages
</p></li>
</ul>

<h3>Title: Out-of-Domain Intent Detection Considering Multi-turn Dialogue Contexts. (arXiv:2305.03237v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2305.03237">http://arxiv.org/abs/2305.03237</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2305.03237] Out-of-Domain Intent Detection Considering Multi-turn Dialogue Contexts](http://arxiv.org/abs/2305.03237) #robust</code></li>
<li>Summary: <p>Out-of-Domain (OOD) intent detection is vital for practical dialogue systems,
and it usually requires considering multi-turn dialogue contexts. However, most
previous OOD intent detection approaches are limited to single dialogue turns.
In this paper, we introduce a context-aware OOD intent detection (Caro)
framework to model multi-turn contexts in OOD intent detection tasks.
Specifically, we follow the information bottleneck principle to extract robust
representations from multi-turn dialogue contexts. Two different views are
constructed for each input sample and the superfluous information not related
to intent detection is removed using a multi-view information bottleneck loss.
Moreover, we also explore utilizing unlabeled data in Caro. A two-stage
training process is introduced to mine OOD samples from these unlabeled data,
and these OOD samples are used to train the resulting model with a
bootstrapping approach. Comprehensive experiments demonstrate that Caro
establishes state-of-the-art performances on multi-turn OOD detection tasks by
improving the F1-OOD score of over $29\%$ compared to the previous best method.
</p></li>
</ul>

<h3>Title: Using ChatGPT for Entity Matching. (arXiv:2305.03423v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2305.03423">http://arxiv.org/abs/2305.03423</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2305.03423] Using ChatGPT for Entity Matching](http://arxiv.org/abs/2305.03423) #robust</code></li>
<li>Summary: <p>Entity Matching is the task of deciding if two entity descriptions refer to
the same real-world entity. State-of-the-art entity matching methods often rely
on fine-tuning Transformer models such as BERT or RoBERTa. Two major drawbacks
of using these models for entity matching are that (i) the models require
significant amounts of fine-tuning data for reaching a good performance and
(ii) the fine-tuned models are not robust concerning out-of-distribution
entities. In this paper, we investigate using ChatGPT for entity matching as a
more robust, training data-efficient alternative to traditional Transformer
models. We perform experiments along three dimensions: (i) general prompt
design, (ii) in-context learning, and (iii) provision of higher-level matching
knowledge. We show that ChatGPT is competitive with a fine-tuned RoBERTa model,
reaching an average zero-shot performance of 83% F1 on a challenging matching
task on which RoBERTa requires 2000 training examples for reaching a similar
performance. Adding in-context demonstrations to the prompts further improves
the F1 by up to 5% even using only a small set of 20 handpicked examples.
Finally, we show that guiding the zero-shot model by stating higher-level
matching rules leads to similar gains as providing in-context examples.
</p></li>
</ul>

<h3>Title: Verifiable Learning for Robust Tree Ensembles. (arXiv:2305.03626v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2305.03626">http://arxiv.org/abs/2305.03626</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2305.03626] Verifiable Learning for Robust Tree Ensembles](http://arxiv.org/abs/2305.03626) #robust</code></li>
<li>Summary: <p>Verifying the robustness of machine learning models against evasion attacks
at test time is an important research problem. Unfortunately, prior work
established that this problem is NP-hard for decision tree ensembles, hence
bound to be intractable for specific inputs. In this paper, we identify a
restricted class of decision tree ensembles, called large-spread ensembles,
which admit a security verification algorithm running in polynomial time. We
then propose a new approach called verifiable learning, which advocates the
training of such restricted model classes which are amenable for efficient
verification. We show the benefits of this idea by designing a new training
algorithm that automatically learns a large-spread decision tree ensemble from
labelled data, thus enabling its security verification in polynomial time.
Experimental results on publicly available datasets confirm that large-spread
ensembles trained using our algorithm can be verified in a matter of seconds,
using standard commercial hardware. Moreover, large-spread ensembles are more
robust than traditional ensembles against evasion attacks, while incurring in
just a relatively small loss of accuracy in the non-adversarial setting.
</p></li>
</ul>

<h3>Title: Carbon Price Forecasting with Quantile Regression and Feature Selection. (arXiv:2305.03224v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2305.03224">http://arxiv.org/abs/2305.03224</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2305.03224] Carbon Price Forecasting with Quantile Regression and Feature Selection](http://arxiv.org/abs/2305.03224) #robust</code></li>
<li>Summary: <p>Carbon futures has recently emerged as a novel financial asset in the trading
markets such as the European Union and China. Monitoring the trend of the
carbon price has become critical for both national policy-making as well as
industrial manufacturing planning. However, various geopolitical, social, and
economic factors can impose substantial influence on the carbon price. Due to
its volatility and non-linearity, predicting accurate carbon prices is
generally a difficult task. In this study, we propose to improve carbon price
forecasting with several novel practices. First, we collect various influencing
factors, including commodity prices, export volumes such as oil and natural
gas, and prosperity indices. Then we select the most significant factors and
disclose their optimal grouping for explainability. Finally, we use the Sparse
Quantile Group Lasso and Adaptive Sparse Quantile Group Lasso for robust price
predictions. We demonstrate through extensive experimental studies that our
proposed methods outperform existing ones. Also, our quantile predictions
provide a complete profile of future prices at different levels, which better
describes the distributions of the carbon market.
</p></li>
</ul>

<h3>Title: Optimizing Hyperparameters with Conformal Quantile Regression. (arXiv:2305.03623v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2305.03623">http://arxiv.org/abs/2305.03623</a></li>
<li>Code URL: <a href="https://github.com/geoalgo/syne-tune">https://github.com/geoalgo/syne-tune</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2305.03623] Optimizing Hyperparameters with Conformal Quantile Regression](http://arxiv.org/abs/2305.03623) #robust</code></li>
<li>Summary: <p>Many state-of-the-art hyperparameter optimization (HPO) algorithms rely on
model-based optimizers that learn surrogate models of the target function to
guide the search. Gaussian processes are the de facto surrogate model due to
their ability to capture uncertainty but they make strong assumptions about the
observation noise, which might not be warranted in practice. In this work, we
propose to leverage conformalized quantile regression which makes minimal
assumptions about the observation noise and, as a result, models the target
function in a more realistic and robust fashion which translates to quicker HPO
convergence on empirical benchmarks. To apply our method in a multi-fidelity
setting, we propose a simple, yet effective, technique that aggregates observed
results across different resource levels and outperforms conventional methods
across many empirical tasks.
</p></li>
</ul>

<h3>Title: On the Effectiveness of Equivariant Regularization for Robust Online Continual Learning. (arXiv:2305.03648v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2305.03648">http://arxiv.org/abs/2305.03648</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2305.03648] On the Effectiveness of Equivariant Regularization for Robust Online Continual Learning](http://arxiv.org/abs/2305.03648) #robust</code></li>
<li>Summary: <p>Humans can learn incrementally, whereas neural networks forget previously
acquired information catastrophically. Continual Learning (CL) approaches seek
to bridge this gap by facilitating the transfer of knowledge to both previous
tasks (backward transfer) and future ones (forward transfer) during training.
</p></li>
</ul>

<p>Recent research has shown that self-supervision can produce versatile models
that can generalize well to diverse downstream tasks. However, contrastive
self-supervised learning (CSSL), a popular self-supervision technique, has
limited effectiveness in online CL (OCL). OCL only permits one iteration of the
input dataset, and CSSL's low sample efficiency hinders its use on the input
data-stream.
</p>
<p>In this work, we propose Continual Learning via Equivariant Regularization
(CLER), an OCL approach that leverages equivariant tasks for self-supervision,
avoiding CSSL's limitations. Our method represents the first attempt at
combining equivariant knowledge with CL and can be easily integrated with
existing OCL methods. Extensive ablations shed light on how equivariant pretext
tasks affect the network's information flow and its impact on CL dynamics.
</p>

<h2>biometric</h2>
<h2>steal</h2>
<h2>extraction</h2>
<h3>Title: High-Level Context Representation for Emotion Recognition in Images. (arXiv:2305.03500v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2305.03500">http://arxiv.org/abs/2305.03500</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2305.03500] High-Level Context Representation for Emotion Recognition in Images](http://arxiv.org/abs/2305.03500) #extraction</code></li>
<li>Summary: <p>Emotion recognition is the task of classifying perceived emotions in people.
Previous works have utilized various nonverbal cues to extract features from
images and correlate them to emotions. Of these cues, situational context is
particularly crucial in emotion perception since it can directly influence the
emotion of a person. In this paper, we propose an approach for high-level
context representation extraction from images. The model relies on a single cue
and a single encoding stream to correlate this representation with emotions.
Our model competes with the state-of-the-art, achieving an mAP of 0.3002 on the
EMOTIC dataset while also being capable of execution on consumer-grade hardware
at approximately 90 frames per second. Overall, our approach is more efficient
than previous models and can be easily deployed to address real-world problems
related to emotion recognition.
</p></li>
</ul>

<h3>Title: Enhancing Pashto Text Classification using Language Processing Techniques for Single And Multi-Label Analysis. (arXiv:2305.03201v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2305.03201">http://arxiv.org/abs/2305.03201</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2305.03201] Enhancing Pashto Text Classification using Language Processing Techniques for Single And Multi-Label Analysis](http://arxiv.org/abs/2305.03201) #extraction</code></li>
<li>Summary: <p>Text classification has become a crucial task in various fields, leading to a
significant amount of research on developing automated text classification
systems for national and international languages. However, there is a growing
need for automated text classification systems that can handle local languages.
This study aims to establish an automated classification system for Pashto
text. To achieve this goal, we constructed a dataset of Pashto documents and
applied various models, including statistical and neural machine learning
models such as DistilBERT-base-multilingual-cased, Multilayer Perceptron,
Support Vector Machine, K Nearest Neighbor, decision tree, Gaussian na\"ive
Bayes, multinomial na\"ive Bayes, random forest, and logistic regression, to
identify the most effective approach. We also evaluated two different feature
extraction methods, bag of words and Term Frequency Inverse Document Frequency.
The study achieved an average testing accuracy rate of 94% using the MLP
classification algorithm and TFIDF feature extraction method in single-label
multiclass classification. Similarly, MLP+TFIDF yielded the best results, with
an F1-measure of 0.81. Furthermore, the use of pre-trained language
representation models, such as DistilBERT, showed promising results for Pashto
text classification; however, the study highlights the importance of developing
a specific tokenizer for a particular language to achieve reasonable results.
</p></li>
</ul>

<h3>Title: Open Information Extraction via Chunks. (arXiv:2305.03299v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2305.03299">http://arxiv.org/abs/2305.03299</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2305.03299] Open Information Extraction via Chunks](http://arxiv.org/abs/2305.03299) #extraction</code></li>
<li>Summary: <p>Open Information Extraction (OIE) aims to extract relational tuples from
open-domain sentences. Existing OIE systems split a sentence into tokens and
recognize token spans as tuple relations and arguments. We instead propose
Sentence as Chunk sequence (SaC) and recognize chunk spans as tuple relations
and arguments. We argue that SaC has better quantitative and qualitative
properties for OIE than sentence as token sequence, and evaluate four choices
of chunks (i.e., CoNLL chunks, simple phrases, NP chunks, and spans from
SpanOIE) against gold OIE tuples. Accordingly, we propose a simple BERT-based
model for sentence chunking, and propose Chunk-OIE for tuple extraction on top
of SaC. Chunk-OIE achieves state-of-the-art results on multiple OIE datasets,
showing that SaC benefits OIE task.
</p></li>
</ul>

<h3>Title: Think Rationally about What You See: Continuous Rationale Extraction for Relation Extraction. (arXiv:2305.03503v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2305.03503">http://arxiv.org/abs/2305.03503</a></li>
<li>Code URL: <a href="https://github.com/thu-bpm/re2">https://github.com/thu-bpm/re2</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2305.03503] Think Rationally about What You See: Continuous Rationale Extraction for Relation Extraction](http://arxiv.org/abs/2305.03503) #extraction</code></li>
<li>Summary: <p>Relation extraction (RE) aims to extract potential relations according to the
context of two entities, thus, deriving rational contexts from sentences plays
an important role. Previous works either focus on how to leverage the entity
information (e.g., entity types, entity verbalization) to inference relations,
but ignore context-focused content, or use counterfactual thinking to remove
the model's bias of potential relations in entities, but the relation reasoning
process will still be hindered by irrelevant content. Therefore, how to
preserve relevant content and remove noisy segments from sentences is a crucial
task. In addition, retained content needs to be fluent enough to maintain
semantic coherence and interpretability. In this work, we propose a novel
rationale extraction framework named RE2, which leverages two continuity and
sparsity factors to obtain relevant and coherent rationales from sentences. To
solve the problem that the gold rationales are not labeled, RE2 applies an
optimizable binary mask to each token in the sentence, and adjust the
rationales that need to be selected according to the relation label.
Experiments on four datasets show that RE2 surpasses baselines.
</p></li>
</ul>

<h3>Title: Shared Latent Space by Both Languages in Non-Autoregressive Neural Machine Translation. (arXiv:2305.03511v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2305.03511">http://arxiv.org/abs/2305.03511</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2305.03511] Shared Latent Space by Both Languages in Non-Autoregressive Neural Machine Translation](http://arxiv.org/abs/2305.03511) #extraction</code></li>
<li>Summary: <p>Latent variable modeling in non-autoregressive neural machine translation
(NAT) is a promising approach to mitigate the multimodality problem. In the
previous works, they added an auxiliary model to estimate the posterior
distribution of the latent variable conditioned on the source and target
sentences. However, it causes several disadvantages, such as redundant
information extraction in the latent variable, increasing parameters, and a
tendency to ignore a part of the information from the inputs. In this paper, we
propose a new latent variable modeling that is based on a dual reconstruction
perspective and an advanced hierarchical latent modeling approach. Our proposed
method, {\em LadderNMT}, shares a latent space across both languages so that it
hypothetically alleviates or solves the above disadvantages. Experimental
results quantitatively and qualitatively demonstrate that our proposed latent
variable modeling learns an advantageous latent space and significantly
improves translation quality in WMT translation tasks.
</p></li>
</ul>

<h3>Title: ChatGraph: Interpretable Text Classification by Converting ChatGPT Knowledge to Graphs. (arXiv:2305.03513v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2305.03513">http://arxiv.org/abs/2305.03513</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2305.03513] ChatGraph: Interpretable Text Classification by Converting ChatGPT Knowledge to Graphs](http://arxiv.org/abs/2305.03513) #extraction</code></li>
<li>Summary: <p>ChatGPT, as a recently launched large language model (LLM), has shown
superior performance in various natural language processing (NLP) tasks.
However, two major limitations hinder its potential applications: (1) the
inflexibility of finetuning on downstream tasks and (2) the lack of
interpretability in the decision-making process. To tackle these limitations,
we propose a novel framework that leverages the power of ChatGPT for specific
tasks, such as text classification, while improving its interpretability. The
proposed framework conducts a knowledge graph extraction task to extract
refined and structural knowledge from the raw data using ChatGPT. The rich
knowledge is then converted into a graph, which is further used to train an
interpretable linear classifier to make predictions. To evaluate the
effectiveness of our proposed method, we conduct experiments on four datasets.
The result shows that our method can significantly improve the performance
compared to directly utilizing ChatGPT for text classification tasks. And our
method provides a more transparent decision-making process compared with
previous text classification methods.
</p></li>
</ul>

<h3>Title: Jointly Extracting Interventions, Outcomes, and Findings from RCT Reports with LLMs. (arXiv:2305.03642v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2305.03642">http://arxiv.org/abs/2305.03642</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2305.03642] Jointly Extracting Interventions, Outcomes, and Findings from RCT Reports with LLMs](http://arxiv.org/abs/2305.03642) #extraction</code></li>
<li>Summary: <p>Results from Randomized Controlled Trials (RCTs) establish the comparative
effectiveness of interventions, and are in turn critical inputs for
evidence-based care. However, results from RCTs are presented in (often
unstructured) natural language articles describing the design, execution, and
outcomes of trials; clinicians must manually extract findings pertaining to
interventions and outcomes of interest from such articles. This onerous manual
process has motivated work on (semi-)automating extraction of structured
evidence from trial reports. In this work we propose and evaluate a
text-to-text model built on instruction-tuned Large Language Models (LLMs) to
jointly extract Interventions, Outcomes, and Comparators (ICO elements) from
clinical abstracts, and infer the associated results reported. Manual (expert)
and automated evaluations indicate that framing evidence extraction as a
conditional generation task and fine-tuning LLMs for this purpose realizes
considerable ($\sim$20 point absolute F1 score) gains over the previous SOTA.
We perform ablations and error analyses to assess aspects that contribute to
model performance, and to highlight potential directions for further
improvements. We apply our model to a collection of published RCTs through
mid-2022, and release a searchable database of structured findings (anonymously
for now): bit.ly/joint-relations-extraction-mlhc
</p></li>
</ul>

<h3>Title: DAMO-NLP at SemEval-2023 Task 2: A Unified Retrieval-augmented System for Multilingual Named Entity Recognition. (arXiv:2305.03688v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2305.03688">http://arxiv.org/abs/2305.03688</a></li>
<li>Code URL: <a href="https://github.com/modelscope/adaseq">https://github.com/modelscope/adaseq</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2305.03688] DAMO-NLP at SemEval-2023 Task 2: A Unified Retrieval-augmented System for Multilingual Named Entity Recognition](http://arxiv.org/abs/2305.03688) #extraction</code></li>
<li>Summary: <p>The MultiCoNER \RNum{2} shared task aims to tackle multilingual named entity
recognition (NER) in fine-grained and noisy scenarios, and it inherits the
semantic ambiguity and low-context setting of the MultiCoNER \RNum{1} task. To
cope with these problems, the previous top systems in the MultiCoNER \RNum{1}
either incorporate the knowledge bases or gazetteers. However, they still
suffer from insufficient knowledge, limited context length, single retrieval
strategy. In this paper, our team \textbf{DAMO-NLP} proposes a unified
retrieval-augmented system (U-RaNER) for fine-grained multilingual NER. We
perform error analysis on the previous top systems and reveal that their
performance bottleneck lies in insufficient knowledge. Also, we discover that
the limited context length causes the retrieval knowledge to be invisible to
the model. To enhance the retrieval context, we incorporate the entity-centric
Wikidata knowledge base, while utilizing the infusion approach to broaden the
contextual scope of the model. Also, we explore various search strategies and
refine the quality of retrieval knowledge. Our system\footnote{We will release
the dataset, code, and scripts of our system at {\small
\url{https://github.com/modelscope/AdaSeq/tree/master/examples/U-RaNER}}.} wins
9 out of 13 tracks in the MultiCoNER \RNum{2} shared task. Additionally, we
compared our system with ChatGPT, one of the large language models which have
unlocked strong capabilities on many tasks. The results show that there is
still much room for improvement for ChatGPT on the extraction task.
</p></li>
</ul>

<h3>Title: Adaptive Graph Convolutional Subspace Clustering. (arXiv:2305.03414v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2305.03414">http://arxiv.org/abs/2305.03414</a></li>
<li>Code URL: <a href="https://github.com/weilyshmtu/agcsc">https://github.com/weilyshmtu/agcsc</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2305.03414] Adaptive Graph Convolutional Subspace Clustering](http://arxiv.org/abs/2305.03414) #extraction</code></li>
<li>Summary: <p>Spectral-type subspace clustering algorithms have shown excellent performance
in many subspace clustering applications. The existing spectral-type subspace
clustering algorithms either focus on designing constraints for the
reconstruction coefficient matrix or feature extraction methods for finding
latent features of original data samples. In this paper, inspired by graph
convolutional networks, we use the graph convolution technique to develop a
feature extraction method and a coefficient matrix constraint simultaneously.
And the graph-convolutional operator is updated iteratively and adaptively in
our proposed algorithm. Hence, we call the proposed method adaptive graph
convolutional subspace clustering (AGCSC). We claim that by using AGCSC, the
aggregated feature representation of original data samples is suitable for
subspace clustering, and the coefficient matrix could reveal the subspace
structure of the original data set more faithfully. Finally, plenty of subspace
clustering experiments prove our conclusions and show that AGCSC outperforms
some related methods as well as some deep models.
</p></li>
</ul>

<h2>membership infer</h2>
<h2>federate</h2>
<h3>Title: Now It Sounds Like You: Learning Personalized Vocabulary On Device. (arXiv:2305.03584v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2305.03584">http://arxiv.org/abs/2305.03584</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2305.03584] Now It Sounds Like You: Learning Personalized Vocabulary On Device](http://arxiv.org/abs/2305.03584) #federate</code></li>
<li>Summary: <p>In recent years, Federated Learning (FL) has shown significant advancements
in its ability to perform various natural language processing (NLP) tasks. This
work focuses on applying personalized FL for on-device language modeling. Due
to limitations of memory and latency, these models cannot support the
complexity of sub-word tokenization or beam search decoding, resulting in the
decision to deploy a closed-vocabulary language model. However,
closed-vocabulary models are unable to handle out-of-vocabulary (OOV) words
belonging to specific users. To address this issue, We propose a novel
technique called "OOV expansion" that improves OOV coverage and increases model
accuracy while minimizing the impact on memory and latency. This method
introduces a personalized "OOV adapter" that effectively transfers knowledge
from a central model and learns word embedding for personalized vocabulary. OOV
expansion significantly outperforms standard FL personalization methods on a
set of common FL benchmarks.
</p></li>
</ul>

<h3>Title: Federated Ensemble-Directed Offline Reinforcement Learning. (arXiv:2305.03097v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2305.03097">http://arxiv.org/abs/2305.03097</a></li>
<li>Code URL: <a href="https://github.com/desikrengarajan/fedora">https://github.com/desikrengarajan/fedora</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2305.03097] Federated Ensemble-Directed Offline Reinforcement Learning](http://arxiv.org/abs/2305.03097) #federate</code></li>
<li>Summary: <p>We consider the problem of federated offline reinforcement learning (RL), a
scenario under which distributed learning agents must collaboratively learn a
high-quality control policy only using small pre-collected datasets generated
according to different unknown behavior policies. Naively combining a standard
offline RL approach with a standard federated learning approach to solve this
problem can lead to poorly performing policies. In response, we develop the
Federated Ensemble-Directed Offline Reinforcement Learning Algorithm (FEDORA),
which distills the collective wisdom of the clients using an ensemble learning
approach. We develop the FEDORA codebase to utilize distributed compute
resources on a federated learning platform. We show that FEDORA significantly
outperforms other approaches, including offline RL over the combined data pool,
in various complex continuous control environments and real world datasets.
Finally, we demonstrate the performance of FEDORA in the real-world on a mobile
robot.
</p></li>
</ul>

<h2>fair</h2>
<h3>Title: LLM2Loss: Leveraging Language Models for Explainable Model Diagnostics. (arXiv:2305.03212v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2305.03212">http://arxiv.org/abs/2305.03212</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2305.03212] LLM2Loss: Leveraging Language Models for Explainable Model Diagnostics](http://arxiv.org/abs/2305.03212) #fair</code></li>
<li>Summary: <p>Trained on a vast amount of data, Large Language models (LLMs) have achieved
unprecedented success and generalization in modeling fairly complex textual
inputs in the abstract space, making them powerful tools for zero-shot
learning. Such capability is extended to other modalities such as the visual
domain using cross-modal foundation models such as CLIP, and as a result,
semantically meaningful representation are extractable from visual inputs.
</p></li>
</ul>

<p>In this work, we leverage this capability and propose an approach that can
provide semantic insights into a model's patterns of failures and biases. Given
a black box model, its training data, and task definition, we first calculate
its task-related loss for each data point. We then extract a semantically
meaningful representation for each training data point (such as CLIP embeddings
from its visual encoder) and train a lightweight diagnosis model which maps
this semantically meaningful representation of a data point to its task loss.
We show that an ensemble of such lightweight models can be used to generate
insights on the performance of the black-box model, in terms of identifying its
patterns of failures and biases.
</p>

<h3>Title: Mining bias-target Alignment from Voronoi Cells. (arXiv:2305.03691v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2305.03691">http://arxiv.org/abs/2305.03691</a></li>
<li>Code URL: <a href="https://github.com/renahon/mining_bias_target_alignment_from_voronoi_cells">https://github.com/renahon/mining_bias_target_alignment_from_voronoi_cells</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2305.03691] Mining bias-target Alignment from Voronoi Cells](http://arxiv.org/abs/2305.03691) #fair</code></li>
<li>Summary: <p>Despite significant research efforts, deep neural networks are still
vulnerable to biases: this raises concerns about their fairness and limits
their generalization. In this paper, we propose a bias-agnostic approach to
mitigate the impact of bias in deep neural networks. Unlike traditional
debiasing approaches, we rely on a metric to quantify ``bias
alignment/misalignment'' on target classes, and use this information to
discourage the propagation of bias-target alignment information through the
network. We conduct experiments on several commonly used datasets for debiasing
and compare our method to supervised and bias-specific approaches. Our results
indicate that the proposed method achieves comparable performance to
state-of-the-art supervised approaches, although it is bias-agnostic, even in
presence of multiple biases in the same sample.
</p></li>
</ul>

<h2>interpretability</h2>
<h3>Title: A technical note on bilinear layers for interpretability. (arXiv:2305.03452v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2305.03452">http://arxiv.org/abs/2305.03452</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2305.03452] A technical note on bilinear layers for interpretability](http://arxiv.org/abs/2305.03452) #interpretability</code></li>
<li>Summary: <p>The ability of neural networks to represent more features than neurons makes
interpreting them challenging. This phenomenon, known as superposition, has
spurred efforts to find architectures that are more interpretable than standard
multilayer perceptrons (MLPs) with elementwise activation functions. In this
note, I examine bilinear layers, which are a type of MLP layer that are
mathematically much easier to analyze while simultaneously performing better
than standard MLPs. Although they are nonlinear functions of their input, I
demonstrate that bilinear layers can be expressed using only linear operations
and third order tensors. We can integrate this expression for bilinear layers
into a mathematical framework for transformer circuits, which was previously
limited to attention-only transformers. These results suggest that bilinear
layers are easier to analyze mathematically than current architectures and thus
may lend themselves to deeper safety insights by allowing us to talk more
formally about circuits in neural networks. Additionally, bilinear layers may
offer an alternative path for mechanistic interpretability through
understanding the mechanisms of feature construction instead of enumerating a
(potentially exponentially) large number of features in large models.
</p></li>
</ul>

<h3>Title: Learning Decision Trees with Gradient Descent. (arXiv:2305.03515v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2305.03515">http://arxiv.org/abs/2305.03515</a></li>
<li>Code URL: <a href="https://github.com/s-marton/gradientbaseddecisiontrees">https://github.com/s-marton/gradientbaseddecisiontrees</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2305.03515] Learning Decision Trees with Gradient Descent](http://arxiv.org/abs/2305.03515) #interpretability</code></li>
<li>Summary: <p>Decision Trees (DTs) are commonly used for many machine learning tasks due to
their high degree of interpretability. However, learning a DT from data is a
difficult optimization problem, as it is non-convex and non-differentiable.
Therefore, common approaches learn DTs using a greedy growth algorithm that
minimizes the impurity locally at each internal node. Unfortunately, this
greedy procedure can lead to suboptimal trees. In this paper, we present a
novel approach for learning hard, axis-aligned DTs with gradient descent. The
proposed method uses backpropagation with a straight-through operator on a
dense DT representation to jointly optimize all tree parameters. Our approach
outperforms existing methods on binary classification benchmarks and achieves
competitive results for multi-class tasks.
</p></li>
</ul>

<h2>explainability</h2>
<h3>Title: Neuro-symbolic model for cantilever beams damage detection. (arXiv:2305.03063v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2305.03063">http://arxiv.org/abs/2305.03063</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2305.03063] Neuro-symbolic model for cantilever beams damage detection](http://arxiv.org/abs/2305.03063) #explainability</code></li>
<li>Summary: <p>In the last decade, damage detection approaches swiftly changed from advanced
signal processing methods to machine learning and especially deep learning
models, to accurately and non-intrusively estimate the state of the beam
structures. But as the deep learning models reached their peak performances,
also their limitations in applicability and vulnerabilities were observed. One
of the most important reason for the lack of trustworthiness in operational
conditions is the absence of intrinsic explainability of the deep learning
system, due to the encoding of the knowledge in tensor values and without the
inclusion of logical constraints. In this paper, we propose a neuro-symbolic
model for the detection of damages in cantilever beams based on a novel
cognitive architecture in which we join the processing power of convolutional
networks with the interactive control offered by queries realized through the
inclusion of real logic directly into the model. The hybrid discriminative
model is introduced under the name Logic Convolutional Neural Regressor and it
is tested on a dataset of values of the relative natural frequency shifts of
cantilever beams derived from an original mathematical relation. While the
obtained results preserve all the predictive capabilities of deep learning
models, the usage of three distances as predicates for satisfiability, makes
the system more trustworthy and scalable for practical applications. Extensive
numerical and laboratory experiments were performed, and they all demonstrated
the superiority of the hybrid approach, which can open a new path for solving
the damage detection problem.
</p></li>
</ul>

<h3>Title: Distributing Synergy Functions: Unifying Game-Theoretic Interaction Methods for Machine-Learning Explainability. (arXiv:2305.03100v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2305.03100">http://arxiv.org/abs/2305.03100</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2305.03100] Distributing Synergy Functions: Unifying Game-Theoretic Interaction Methods for Machine-Learning Explainability](http://arxiv.org/abs/2305.03100) #explainability</code></li>
<li>Summary: <p>Deep learning has revolutionized many areas of machine learning, from
computer vision to natural language processing, but these high-performance
models are generally "black box." Explaining such models would improve
transparency and trust in AI-powered decision making and is necessary for
understanding other practical needs such as robustness and fairness. A popular
means of enhancing model transparency is to quantify how individual inputs
contribute to model outputs (called attributions) and the magnitude of
interactions between groups of inputs. A growing number of these methods import
concepts and results from game theory to produce attributions and interactions.
This work presents a unifying framework for game-theory-inspired attribution
and $k^\text{th}$-order interaction methods. We show that, given modest
assumptions, a unique full account of interactions between features, called
synergies, is possible in the continuous input setting. We identify how various
methods are characterized by their policy of distributing synergies. We also
demonstrate that gradient-based methods are characterized by their actions on
monomials, a type of synergy function, and introduce unique gradient-based
methods. We show that the combination of various criteria uniquely defines the
attribution/interaction methods. Thus, the community needs to identify goals
and contexts when developing and employing attribution and interaction methods.
</p></li>
</ul>

<h2>watermark</h2>
<h2>diffusion</h2>
<h3>Title: DisenBooth: Disentangled Parameter-Efficient Tuning for Subject-Driven Text-to-Image Generation. (arXiv:2305.03374v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2305.03374">http://arxiv.org/abs/2305.03374</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2305.03374] DisenBooth: Disentangled Parameter-Efficient Tuning for Subject-Driven Text-to-Image Generation](http://arxiv.org/abs/2305.03374) #diffusion</code></li>
<li>Summary: <p>Given a small set of images of a specific subject, subject-driven
text-to-image generation aims to generate customized images of the subject
according to new text descriptions, which has attracted increasing attention in
the community recently. Current subject-driven text-to-image generation methods
are mainly based on finetuning a pretrained large-scale text-to-image
generation model. However, these finetuning methods map the images of the
subject into an embedding highly entangled with subject-identity-unrelated
information, which may result in the inconsistency between the generated images
and the text descriptions and the changes in the subject identity. To tackle
the problem, we propose DisenBooth, a disentangled parameter-efficient tuning
framework for subject-driven text-to-image generation. DisenBooth enables
generating new images that simultaneously preserve the subject identity and
conform to the text descriptions, by disentangling the embedding into an
identity-related and an identity-unrelated part. Specifically, DisenBooth is
based on the pretrained diffusion models and conducts finetuning in the
diffusion denoising process, where a shared identity embedding and an
image-specific identity-unrelated embedding are utilized jointly for denoising
each image. To make the two embeddings disentangled, two auxiliary objectives
are proposed. Additionally, to improve the finetuning efficiency, a
parameter-efficient finetuning strategy is adopted. Extensive experiments show
that our DisenBooth can faithfully learn well-disentangled identity-related and
identity-unrelated embeddings. With the shared identity embedding, DisenBooth
demonstrates superior subject-driven text-to-image generation ability.
Additionally, DisenBooth provides a more flexible and controllable framework
with different combinations of the disentangled embeddings.
</p></li>
</ul>

<h3>Title: Guided Image Synthesis via Initial Image Editing in Diffusion Model. (arXiv:2305.03382v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2305.03382">http://arxiv.org/abs/2305.03382</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2305.03382] Guided Image Synthesis via Initial Image Editing in Diffusion Model](http://arxiv.org/abs/2305.03382) #diffusion</code></li>
<li>Summary: <p>Diffusion models have the ability to generate high quality images by
denoising pure Gaussian noise images. While previous research has primarily
focused on improving the control of image generation through adjusting the
denoising process, we propose a novel direction of manipulating the initial
noise to control the generated image. Through experiments on stable diffusion,
we show that blocks of pixels in the initial latent images have a preference
for generating specific content, and that modifying these blocks can
significantly influence the generated image. In particular, we show that
modifying a part of the initial image affects the corresponding region of the
generated image while leaving other regions unaffected, which is useful for
repainting tasks. Furthermore, we find that the generation preferences of pixel
blocks are primarily determined by their values, rather than their position. By
moving pixel blocks with a tendency to generate user-desired content to
user-specified regions, our approach achieves state-of-the-art performance in
layout-to-image generation. Our results highlight the flexibility and power of
initial image manipulation in controlling the generated image.
</p></li>
</ul>

<h3>Title: Conditional Diffusion Feature Refinement for Continuous Sign Language Recognition. (arXiv:2305.03614v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2305.03614">http://arxiv.org/abs/2305.03614</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2305.03614] Conditional Diffusion Feature Refinement for Continuous Sign Language Recognition](http://arxiv.org/abs/2305.03614) #diffusion</code></li>
<li>Summary: <p>In this work, we are dedicated to leveraging the denoising diffusion models'
success and formulating feature refinement as the autoencoder-formed diffusion
process. The state-of-the-art CSLR framework consists of a spatial module, a
visual module, a sequence module, and a sequence learning function. However,
this framework has faced sequence module overfitting caused by the objective
function and small-scale available benchmarks, resulting in insufficient model
training. To overcome the overfitting problem, some CSLR studies enforce the
sequence module to learn more visual temporal information or be guided by more
informative supervision to refine its representations. In this work, we propose
a novel autoencoder-formed conditional diffusion feature refinement~(ACDR) to
refine the sequence representations to equip desired properties by learning the
encoding-decoding optimization process in an end-to-end way. Specifically, for
the ACDR, a noising Encoder is proposed to progressively add noise equipped
with semantic conditions to the sequence representations. And a denoising
Decoder is proposed to progressively denoise the noisy sequence representations
with semantic conditions. Therefore, the sequence representations can be imbued
with the semantics of provided semantic conditions. Further, a semantic
constraint is employed to prevent the denoised sequence representations from
semantic corruption. Extensive experiments are conducted to validate the
effectiveness of our ACDR, benefiting state-of-the-art methods and achieving a
notable gain on three benchmarks.
</p></li>
</ul>

<h3>Title: Diffusion Explainer: Visual Explanation for Text-to-image Stable Diffusion. (arXiv:2305.03509v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2305.03509">http://arxiv.org/abs/2305.03509</a></li>
<li>Code URL: <a href="https://github.com/poloclub/diffusion-explainer">https://github.com/poloclub/diffusion-explainer</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2305.03509] Diffusion Explainer: Visual Explanation for Text-to-image Stable Diffusion](http://arxiv.org/abs/2305.03509) #diffusion</code></li>
<li>Summary: <p>Diffusion-based generative models' impressive ability to create convincing
images has captured global attention. However, their complex internal
structures and operations often make them difficult for non-experts to
understand. We present Diffusion Explainer, the first interactive visualization
tool that explains how Stable Diffusion transforms text prompts into images.
Diffusion Explainer tightly integrates a visual overview of Stable Diffusion's
complex components with detailed explanations of their underlying operations,
enabling users to fluidly transition between multiple levels of abstraction
through animations and interactive elements. By comparing the evolutions of
image representations guided by two related text prompts over refinement
timesteps, users can discover the impact of prompts on image generation.
Diffusion Explainer runs locally in users' web browsers without the need for
installation or specialized hardware, broadening the public's education access
to modern AI techniques. Our open-sourced tool is available at:
https://poloclub.github.io/diffusion-explainer/.
</p></li>
</ul>

<h2>noise learning</h2>
<h2>data-free</h2>
<h2>transformer</h2>
<h3>Title: Mitigating Undisciplined Over-Smoothing in Transformer for Weakly Supervised Semantic Segmentation. (arXiv:2305.03112v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2305.03112">http://arxiv.org/abs/2305.03112</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2305.03112] Mitigating Undisciplined Over-Smoothing in Transformer for Weakly Supervised Semantic Segmentation](http://arxiv.org/abs/2305.03112) #transformer</code></li>
<li>Summary: <p>A surge of interest has emerged in weakly supervised semantic segmentation
due to its remarkable efficiency in recent years. Existing approaches based on
transformers mainly focus on exploring the affinity matrix to boost CAMs with
global relationships. While in this work, we first perform a scrupulous
examination towards the impact of successive affinity matrices and discover
that they possess an inclination toward sparsification as the network
approaches convergence, hence disclosing a manifestation of over-smoothing.
Besides, it has been observed that enhanced attention maps tend to evince a
substantial amount of extraneous background noise in deeper layers. Drawing
upon this, we posit a daring conjecture that the undisciplined over-smoothing
phenomenon introduces a noteworthy quantity of semantically irrelevant
background noise, causing performance degradation. To alleviate this issue, we
propose a novel perspective that highlights the objects of interest by
investigating the regions of the trait, thereby fostering an extensive
comprehension of the successive affinity matrix. Consequently, we suggest an
adaptive re-activation mechanism (AReAM) that alleviates the issue of
incomplete attention within the object and the unbounded background noise.
AReAM accomplishes this by supervising high-level attention with shallow
affinity matrices, yielding promising results. Exhaustive experiments conducted
on the commonly used dataset manifest that segmentation results can be greatly
improved through our proposed AReAM, which imposes restrictions on each
affinity matrix in deep layers to make it attentive to semantic regions.
</p></li>
</ul>

<h3>Title: Semantic Segmentation using Vision Transformers: A survey. (arXiv:2305.03273v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2305.03273">http://arxiv.org/abs/2305.03273</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2305.03273] Semantic Segmentation using Vision Transformers: A survey](http://arxiv.org/abs/2305.03273) #transformer</code></li>
<li>Summary: <p>Semantic segmentation has a broad range of applications in a variety of
domains including land coverage analysis, autonomous driving, and medical image
analysis. Convolutional neural networks (CNN) and Vision Transformers (ViTs)
provide the architecture models for semantic segmentation. Even though ViTs
have proven success in image classification, they cannot be directly applied to
dense prediction tasks such as image segmentation and object detection since
ViT is not a general purpose backbone due to its patch partitioning scheme. In
this survey, we discuss some of the different ViT architectures that can be
used for semantic segmentation and how their evolution managed the above-stated
challenge. The rise of ViT and its performance with a high success rate
motivated the community to slowly replace the traditional convolutional neural
networks in various computer vision tasks. This survey aims to review and
compare the performances of ViT architectures designed for semantic
segmentation using benchmarking datasets. This will be worthwhile for the
community to yield knowledge regarding the implementations carried out in
semantic segmentation and to discover more efficient methodologies using ViTs.
</p></li>
</ul>

<h3>Title: FM-ViT: Flexible Modal Vision Transformers for Face Anti-Spoofing. (arXiv:2305.03277v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2305.03277">http://arxiv.org/abs/2305.03277</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2305.03277] FM-ViT: Flexible Modal Vision Transformers for Face Anti-Spoofing](http://arxiv.org/abs/2305.03277) #transformer</code></li>
<li>Summary: <p>The availability of handy multi-modal (i.e., RGB-D) sensors has brought about
a surge of face anti-spoofing research. However, the current multi-modal face
presentation attack detection (PAD) has two defects: (1) The framework based on
multi-modal fusion requires providing modalities consistent with the training
input, which seriously limits the deployment scenario. (2) The performance of
ConvNet-based model on high fidelity datasets is increasingly limited. In this
work, we present a pure transformer-based framework, dubbed the Flexible Modal
Vision Transformer (FM-ViT), for face anti-spoofing to flexibly target any
single-modal (i.e., RGB) attack scenarios with the help of available
multi-modal data. Specifically, FM-ViT retains a specific branch for each
modality to capture different modal information and introduces the Cross-Modal
Transformer Block (CMTB), which consists of two cascaded attentions named
Multi-headed Mutual-Attention (MMA) and Fusion-Attention (MFA) to guide each
modal branch to mine potential features from informative patch tokens, and to
learn modality-agnostic liveness features by enriching the modal information of
own CLS token, respectively. Experiments demonstrate that the single model
trained based on FM-ViT can not only flexibly evaluate different modal samples,
but also outperforms existing single-modal frameworks by a large margin, and
approaches the multi-modal frameworks introduced with smaller FLOPs and model
parameters.
</p></li>
</ul>

<h3>Title: LOGO-Former: Local-Global Spatio-Temporal Transformer for Dynamic Facial Expression Recognition. (arXiv:2305.03343v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2305.03343">http://arxiv.org/abs/2305.03343</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2305.03343] LOGO-Former: Local-Global Spatio-Temporal Transformer for Dynamic Facial Expression Recognition](http://arxiv.org/abs/2305.03343) #transformer</code></li>
<li>Summary: <p>Previous methods for dynamic facial expression recognition (DFER) in the wild
are mainly based on Convolutional Neural Networks (CNNs), whose local
operations ignore the long-range dependencies in videos. Transformer-based
methods for DFER can achieve better performances but result in higher FLOPs and
computational costs. To solve these problems, the local-global spatio-temporal
Transformer (LOGO-Former) is proposed to capture discriminative features within
each frame and model contextual relationships among frames while balancing the
complexity. Based on the priors that facial muscles move locally and facial
expressions gradually change, we first restrict both the space attention and
the time attention to a local window to capture local interactions among
feature tokens. Furthermore, we perform the global attention by querying a
token with features from each local window iteratively to obtain long-range
information of the whole video sequence. In addition, we propose the compact
loss regularization term to further encourage the learned features have the
minimum intra-class distance and the maximum inter-class distance. Experiments
on two in-the-wild dynamic facial expression datasets (i.e., DFEW and FERV39K)
indicate that our method provides an effective way to make use of the spatial
and temporal dependencies for DFER.
</p></li>
</ul>

<h3>Title: Optimized Table Tokenization for Table Structure Recognition. (arXiv:2305.03393v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2305.03393">http://arxiv.org/abs/2305.03393</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2305.03393] Optimized Table Tokenization for Table Structure Recognition](http://arxiv.org/abs/2305.03393) #transformer</code></li>
<li>Summary: <p>Extracting tables from documents is a crucial task in any document conversion
pipeline. Recently, transformer-based models have demonstrated that
table-structure can be recognized with impressive accuracy using
Image-to-Markup-Sequence (Im2Seq) approaches. Taking only the image of a table,
such models predict a sequence of tokens (e.g. in HTML, LaTeX) which represent
the structure of the table. Since the token representation of the table
structure has a significant impact on the accuracy and run-time performance of
any Im2Seq model, we investigate in this paper how table-structure
representation can be optimised. We propose a new, optimised table-structure
language (OTSL) with a minimized vocabulary and specific rules. The benefits of
OTSL are that it reduces the number of tokens to 5 (HTML needs 28+) and
shortens the sequence length to half of HTML on average. Consequently, model
accuracy improves significantly, inference time is halved compared to
HTML-based models, and the predicted table structures are always syntactically
correct. This in turn eliminates most post-processing needs.
</p></li>
</ul>

<h3>Title: HSCNet++: Hierarchical Scene Coordinate Classification and Regression for Visual Localization with Transformer. (arXiv:2305.03595v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2305.03595">http://arxiv.org/abs/2305.03595</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2305.03595] HSCNet++: Hierarchical Scene Coordinate Classification and Regression for Visual Localization with Transformer](http://arxiv.org/abs/2305.03595) #transformer</code></li>
<li>Summary: <p>Visual localization is critical to many applications in computer vision and
robotics. To address single-image RGB localization, state-of-the-art
feature-based methods match local descriptors between a query image and a
pre-built 3D model. Recently, deep neural networks have been exploited to
regress the mapping between raw pixels and 3D coordinates in the scene, and
thus the matching is implicitly performed by the forward pass through the
network. However, in a large and ambiguous environment, learning such a
regression task directly can be difficult for a single network. In this work,
we present a new hierarchical scene coordinate network to predict pixel scene
coordinates in a coarse-to-fine manner from a single RGB image. The proposed
method, which is an extension of HSCNet, allows us to train compact models
which scale robustly to large environments. It sets a new state-of-the-art for
single-image localization on the 7-Scenes, 12 Scenes, Cambridge Landmarks
datasets, and the combined indoor scenes.
</p></li>
</ul>

<h3>Title: COLA: How to adapt vision-language models to Compose Objects Localized with Attributes?. (arXiv:2305.03689v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2305.03689">http://arxiv.org/abs/2305.03689</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2305.03689] COLA: How to adapt vision-language models to Compose Objects Localized with Attributes?](http://arxiv.org/abs/2305.03689) #transformer</code></li>
<li>Summary: <p>Compositional reasoning is a hallmark of human visual intelligence; yet
despite the size of large vision-language models, they struggle to represent
simple compositions by combining objects with their attributes. To measure this
lack of compositional capability, we design Cola, a text-to-image retrieval
benchmark to Compose Objects Localized with Attributes. Using Cola as a
testbed, we explore modeling designs to adapt pre-trained vision-language
models to reason compositionally about multiple attributes attached to multiple
objects. We explore 6 finetuning strategies on 2 seminal vision-language
models, using 3 finetuning datasets and 2 test benchmarks (Cola and CREPE).
Surprisingly, our optimal finetuning strategy improves a 151M parameter CLIP,
which disjointly encodes image and language during pretraining, to perform as
well as a 241M parameter FLAVA, which uses a multi-modal transformer encoder
during pretraining to attend over both vision and language modalities. This
optimal finetuning strategy is a lightweight multi-modal adapter that jointly
attends over both image and language features generated by the pretrained
model. We show this works better than common strategies such as
prompt/fine-tuning, or tuning a comparable number of unimodal layers.
</p></li>
</ul>

<h3>Title: Otter: A Multi-Modal Model with In-Context Instruction Tuning. (arXiv:2305.03726v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2305.03726">http://arxiv.org/abs/2305.03726</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2305.03726] Otter: A Multi-Modal Model with In-Context Instruction Tuning](http://arxiv.org/abs/2305.03726) #transformer</code></li>
<li>Summary: <p>Large language models (LLMs) have demonstrated significant universal
capabilities as few/zero-shot learners in various tasks due to their
pre-training on vast amounts of text data, as exemplified by GPT-3, which
boosted to InstrctGPT and ChatGPT, effectively following natural language
instructions to accomplish real-world tasks. In this paper, we propose to
introduce instruction tuning into multi-modal models, motivated by the Flamingo
model's upstream interleaved format pretraining dataset. We adopt a similar
approach to construct our MultI-Modal In-Context Instruction Tuning (MIMIC-IT)
dataset. We then introduce Otter, a multi-modal model based on OpenFlamingo
(open-sourced version of DeepMind's Flamingo), trained on MIMIC-IT and
showcasing improved instruction-following ability and in-context learning. We
also optimize OpenFlamingo's implementation for researchers, democratizing the
required training resources from 1$\times$ A100 GPU to 4$\times$ RTX-3090 GPUs,
and integrate both OpenFlamingo and Otter into Huggingface Transformers for
more researchers to incorporate the models into their customized training and
inference pipelines.
</p></li>
</ul>

<h3>Title: Curating corpora with classifiers: A case study of clean energy sentiment online. (arXiv:2305.03092v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2305.03092">http://arxiv.org/abs/2305.03092</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2305.03092] Curating corpora with classifiers: A case study of clean energy sentiment online](http://arxiv.org/abs/2305.03092) #transformer</code></li>
<li>Summary: <p>Well curated, large-scale corpora of social media posts containing broad
public opinion offer an alternative data source to complement traditional
surveys. While surveys are effective at collecting representative samples and
are capable of achieving high accuracy, they can be both expensive to run and
lag public opinion by days or weeks. Both of these drawbacks could be overcome
with a real-time, high volume data stream and fast analysis pipeline. A central
challenge in orchestrating such a data pipeline is devising an effective method
for rapidly selecting the best corpus of relevant documents for analysis.
Querying with keywords alone often includes irrelevant documents that are not
easily disambiguated with bag-of-words natural language processing methods.
Here, we explore methods of corpus curation to filter irrelevant tweets using
pre-trained transformer-based models, fine-tuned for our binary classification
task on hand-labeled tweets. We are able to achieve F1 scores of up to 0.95.
The low cost and high performance of fine-tuning such a model suggests that our
approach could be of broad benefit as a pre-processing step for social media
datasets with uncertain corpus boundaries.
</p></li>
</ul>

<h3>Title: Chain-of-Skills: A Configurable Model for Open-domain Question Answering. (arXiv:2305.03130v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2305.03130">http://arxiv.org/abs/2305.03130</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2305.03130] Chain-of-Skills: A Configurable Model for Open-domain Question Answering](http://arxiv.org/abs/2305.03130) #transformer</code></li>
<li>Summary: <p>The retrieval model is an indispensable component for real-world
knowledge-intensive tasks, e.g., open-domain question answering (ODQA). As
separate retrieval skills are annotated for different datasets, recent work
focuses on customized methods, limiting the model transferability and
scalability. In this work, we propose a modular retriever where individual
modules correspond to key skills that can be reused across datasets. Our
approach supports flexible skill configurations based on the target domain to
boost performance. To mitigate task interference, we design a novel
modularization parameterization inspired by sparse Transformer. We demonstrate
that our model can benefit from self-supervised pretraining on Wikipedia and
fine-tuning using multiple ODQA datasets, both in a multi-task fashion. Our
approach outperforms recent self-supervised retrievers in zero-shot evaluations
and achieves state-of-the-art fine-tuned retrieval performance on NQ, HotpotQA
and OTT-QA.
</p></li>
</ul>

<h3>Title: The Role of Global and Local Context in Named Entity Recognition. (arXiv:2305.03132v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2305.03132">http://arxiv.org/abs/2305.03132</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2305.03132] The Role of Global and Local Context in Named Entity Recognition](http://arxiv.org/abs/2305.03132) #transformer</code></li>
<li>Summary: <p>Pre-trained transformer-based models have recently shown great performance
when applied to Named Entity Recognition (NER). As the complexity of their
self-attention mechanism prevents them from processing long documents at once,
these models are usually applied in a sequential fashion. Such an approach
unfortunately only incorporates local context and prevents leveraging global
document context in long documents such as novels, which might hinder
performance. In this article, we explore the impact of global document context,
and its relationships with local context. We find that correctly retrieving
global document context has a greater impact on performance than only
leveraging local context, prompting for further research on how to better
retrieve that context.
</p></li>
</ul>

<h3>Title: Gpt-4: A Review on Advancements and Opportunities in Natural Language Processing. (arXiv:2305.03195v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2305.03195">http://arxiv.org/abs/2305.03195</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2305.03195] Gpt-4: A Review on Advancements and Opportunities in Natural Language Processing](http://arxiv.org/abs/2305.03195) #transformer</code></li>
<li>Summary: <p>Generative Pre-trained Transformer 4 (GPT-4) is the fourth-generation
language model in the GPT series, developed by OpenAI, which promises
significant advancements in the field of natural language processing (NLP). In
this research article, we have discussed the features of GPT-4, its potential
applications, and the challenges that it might face. We have also compared
GPT-4 with its predecessor, GPT-3. GPT-4 has a larger model size (more than one
trillion), better multilingual capabilities, improved contextual understanding,
and reasoning capabilities than GPT-3. Some of the potential applications of
GPT-4 include chatbots, personal assistants, language translation, text
summarization, and question-answering. However, GPT-4 poses several challenges
and limitations such as computational requirements, data requirements, and
ethical concerns.
</p></li>
</ul>

<h3>Title: Neuromodulation Gated Transformer. (arXiv:2305.03232v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2305.03232">http://arxiv.org/abs/2305.03232</a></li>
<li>Code URL: <a href="https://github.com/kobeknowles/neuromodulation-gated-transformer">https://github.com/kobeknowles/neuromodulation-gated-transformer</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2305.03232] Neuromodulation Gated Transformer](http://arxiv.org/abs/2305.03232) #transformer</code></li>
<li>Summary: <p>We introduce a novel architecture, the Neuromodulation Gated Transformer
(NGT), which is a simple implementation of neuromodulation in transformers via
a multiplicative effect. We compare it to baselines and show that it results in
the best average performance on the SuperGLUE benchmark validation sets.
</p></li>
</ul>

<h3>Title: Online Gesture Recognition using Transformer and Natural Language Processing. (arXiv:2305.03407v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2305.03407">http://arxiv.org/abs/2305.03407</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2305.03407] Online Gesture Recognition using Transformer and Natural Language Processing](http://arxiv.org/abs/2305.03407) #transformer</code></li>
<li>Summary: <p>The Transformer architecture is shown to provide a powerful machine
transduction framework for online handwritten gestures corresponding to glyph
strokes of natural language sentences. The attention mechanism is successfully
used to create latent representations of an end-to-end encoder-decoder model,
solving multi-level segmentation while also learning some language features and
syntax rules. The additional use of a large decoding space with some learned
Byte-Pair-Encoding (BPE) is shown to provide robustness to ablated inputs and
syntax rules. The encoder stack was directly fed with spatio-temporal data
tokens potentially forming an infinitely large input vocabulary, an approach
that finds applications beyond that of this work. Encoder transfer learning
capabilities is also demonstrated on several languages resulting in faster
optimisation and shared parameters. A new supervised dataset of online
handwriting gestures suitable for generic handwriting recognition tasks was
used to successfully train a small transformer model to an average normalised
Levenshtein accuracy of 96% on English or German sentences and 94% in French.
</p></li>
</ul>

<h3>Title: Cancer Hallmark Classification Using Bidirectional Encoder Representations From Transformers. (arXiv:2305.03501v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2305.03501">http://arxiv.org/abs/2305.03501</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2305.03501] Cancer Hallmark Classification Using Bidirectional Encoder Representations From Transformers](http://arxiv.org/abs/2305.03501) #transformer</code></li>
<li>Summary: <p>This paper presents a novel approach to accurately classify the hallmarks of
cancer, which is a crucial task in cancer research. Our proposed method
utilizes the Bidirectional Encoder Representations from Transformers (BERT)
architecture, which has shown exceptional performance in various downstream
applications. By applying transfer learning, we fine-tuned the pre-trained BERT
model on a small corpus of biomedical text documents related to cancer. The
outcomes of our experimental investigations demonstrate that our approach
attains a noteworthy accuracy of 94.45%, surpassing almost all prior findings
with a substantial increase of at least 8.04% as reported in the literature.
These findings highlight the effectiveness of our proposed model in accurately
classifying and comprehending text documents for cancer research, thus
contributing significantly to the field. As cancer remains one of the top ten
leading causes of death globally, our approach holds great promise in advancing
cancer research and improving patient outcomes.
</p></li>
</ul>

<h3>Title: Predicting COVID-19 and pneumonia complications from admission texts. (arXiv:2305.03661v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2305.03661">http://arxiv.org/abs/2305.03661</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2305.03661] Predicting COVID-19 and pneumonia complications from admission texts](http://arxiv.org/abs/2305.03661) #transformer</code></li>
<li>Summary: <p>In this paper we present a novel approach to risk assessment for patients
hospitalized with pneumonia or COVID-19 based on their admission reports. We
applied a Longformer neural network to admission reports and other textual data
available shortly after admission to compute risk scores for the patients. We
used patient data of multiple European hospitals to demonstrate that our
approach outperforms the Transformer baselines. Our experiments show that the
proposed model generalises across institutions and diagnoses. Also, our method
has several other advantages described in the paper.
</p></li>
</ul>

<h3>Title: G-MATT: Single-step Retrosynthesis Prediction using Molecular Grammar Tree Transformer. (arXiv:2305.03153v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2305.03153">http://arxiv.org/abs/2305.03153</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2305.03153] G-MATT: Single-step Retrosynthesis Prediction using Molecular Grammar Tree Transformer](http://arxiv.org/abs/2305.03153) #transformer</code></li>
<li>Summary: <p>In recent years, several reaction templates-based and template-free
approaches have been reported for single-step retrosynthesis prediction. Even
though many of these approaches perform well from traditional data-driven
metrics standpoint, there is a disconnect between model architectures used and
underlying chemistry principles governing retrosynthesis. Here, we propose a
novel chemistry-aware retrosynthesis prediction framework that combines
powerful data-driven models with chemistry knowledge. We report a
tree-to-sequence transformer architecture based on hierarchical SMILES grammar
trees as input containing underlying chemistry information that is otherwise
ignored by models based on purely SMILES-based representations. The proposed
framework, grammar-based molecular attention tree transformer (G-MATT),
achieves significant performance improvements compared to baseline
retrosynthesis models. G-MATT achieves a top-1 accuracy of 51% (top-10 accuracy
of 79.1%), invalid rate of 1.5%, and bioactive similarity rate of 74.8%.
Further analyses based on attention maps demonstrate G-MATT's ability to
preserve chemistry knowledge without having to use extremely complex model
architectures.
</p></li>
</ul>

<h2>generative</h2>
<h3>Title: VideoOFA: Two-Stage Pre-Training for Video-to-Text Generation. (arXiv:2305.03204v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2305.03204">http://arxiv.org/abs/2305.03204</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2305.03204] VideoOFA: Two-Stage Pre-Training for Video-to-Text Generation](http://arxiv.org/abs/2305.03204) #generative</code></li>
<li>Summary: <p>We propose a new two-stage pre-training framework for video-to-text
generation tasks such as video captioning and video question answering: A
generative encoder-decoder model is first jointly pre-trained on massive
image-text data to learn fundamental vision-language concepts, and then adapted
to video data in an intermediate video-text pre-training stage to learn
video-specific skills such as spatio-temporal reasoning. As a result, our
VideoOFA model achieves new state-of-the-art performance on four Video
Captioning benchmarks, beating prior art by an average of 9.7 points in CIDEr
score. It also outperforms existing models on two open-ended Video Question
Answering datasets, showcasing its generalization capability as a universal
video-to-text model.
</p></li>
</ul>

<h3>Title: Data Curation for Image Captioning with Text-to-Image Generative Models. (arXiv:2305.03610v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2305.03610">http://arxiv.org/abs/2305.03610</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2305.03610] Data Curation for Image Captioning with Text-to-Image Generative Models](http://arxiv.org/abs/2305.03610) #generative</code></li>
<li>Summary: <p>Recent advances in image captioning are mainly driven by large-scale
vision-language pretraining, relying heavily on computational resources and
increasingly large multimodal datasets. Instead of scaling up pretraining data,
we ask whether it is possible to improve performance by improving the quality
of the samples in existing datasets. We pursue this question through two
approaches to data curation: one that assumes that some examples should be
avoided due to mismatches between the image and caption, and one that assumes
that the mismatch can be addressed by replacing the image, for which we use the
state-of-the-art Stable Diffusion model. These approaches are evaluated using
the BLIP model on MS COCO and Flickr30K in both finetuning and few-shot
learning settings. Our simple yet effective approaches consistently outperform
baselines, indicating that better image captioning models can be trained by
curating existing resources. Finally, we conduct a human study to understand
the errors made by the Stable Diffusion model and highlight directions for
future work in text-to-image generation.
</p></li>
</ul>

<h3>Title: A Suite of Generative Tasks for Multi-Level Multimodal Webpage Understanding. (arXiv:2305.03668v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2305.03668">http://arxiv.org/abs/2305.03668</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2305.03668] A Suite of Generative Tasks for Multi-Level Multimodal Webpage Understanding](http://arxiv.org/abs/2305.03668) #generative</code></li>
<li>Summary: <p>Webpages have been a rich, scalable resource for vision-language and language
only tasks. Yet only pieces of webpages are kept: image-caption pairs, long
text articles, or raw HTML, never all in one place. Webpage tasks have
resultingly received little attention and structured image-text data left
underused. To study multimodal webpage understanding, we introduce the
Wikipedia Webpage suite (WikiWeb2M) of 2M pages. We verify its utility on three
generative tasks: page description generation, section summarization, and
contextual image captioning. We design a novel attention mechanism Prefix
Global, which selects the most relevant image and text content as global tokens
to attend to the rest of the webpage for context. By using page structure to
separate such tokens, it performs better than full attention with lower
computational complexity. Experiments show that the new annotations from
WikiWeb2M improve task performance compared to data from prior work. We also
include ablations on sequence length, input features, and model size.
</p></li>
</ul>

<h3>Title: Retrieval Augmented Chest X-Ray Report Generation using OpenAI GPT models. (arXiv:2305.03660v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2305.03660">http://arxiv.org/abs/2305.03660</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2305.03660] Retrieval Augmented Chest X-Ray Report Generation using OpenAI GPT models](http://arxiv.org/abs/2305.03660) #generative</code></li>
<li>Summary: <p>We propose Retrieval Augmented Generation (RAG) as an approach for automated
radiology report writing that leverages multimodally aligned embeddings from a
contrastively pretrained vision language model for retrieval of relevant
candidate radiology text for an input radiology image and a general domain
generative model like OpenAI text-davinci-003, gpt-3.5-turbo and gpt-4 for
report generation using the relevant radiology text retrieved. This approach
keeps hallucinated generations under check and provides capabilities to
generate report content in the format we desire leveraging the instruction
following capabilities of these generative models. Our approach achieves better
clinical metrics with a BERTScore of 0.2865 ({\Delta}+ 25.88%) and Semb score
of 0.4026 ({\Delta}+ 6.31%). Our approach can be broadly relevant for different
clinical settings as it allows to augment the automated radiology report
generation process with content relevant for that setting while also having the
ability to inject user intents and requirements in the prompts as part of the
report generation process to modulate the content and format of the generated
reports as applicable for that clinical setting.
</p></li>
</ul>

<h3>Title: A Generative Modeling Framework for Inferring Families of Biomechanical Constitutive Laws in Data-Sparse Regimes. (arXiv:2305.03184v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2305.03184">http://arxiv.org/abs/2305.03184</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2305.03184] A Generative Modeling Framework for Inferring Families of Biomechanical Constitutive Laws in Data-Sparse Regimes](http://arxiv.org/abs/2305.03184) #generative</code></li>
<li>Summary: <p>Quantifying biomechanical properties of the human vasculature could deepen
our understanding of cardiovascular diseases. Standard nonlinear regression in
constitutive modeling requires considerable high-quality data and an explicit
form of the constitutive model as prior knowledge. By contrast, we propose a
novel approach that combines generative deep learning with Bayesian inference
to efficiently infer families of constitutive relationships in data-sparse
regimes. Inspired by the concept of functional priors, we develop a generative
adversarial network (GAN) that incorporates a neural operator as the generator
and a fully-connected neural network as the discriminator. The generator takes
a vector of noise conditioned on measurement data as input and yields the
predicted constitutive relationship, which is scrutinized by the discriminator
in the following step. We demonstrate that this framework can accurately
estimate means and standard deviations of the constitutive relationships of the
murine aorta using data collected either from model-generated synthetic data or
ex vivo experiments for mice with genetic deficiencies. In addition, the
framework learns priors of constitutive models without explicitly knowing their
functional form, providing a new model-agnostic approach to learning hidden
constitutive behaviors from data.
</p></li>
</ul>

<h2>large language model</h2>
<h3>Title: LMEye: An Interactive Perception Network for Large Language Models. (arXiv:2305.03701v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2305.03701">http://arxiv.org/abs/2305.03701</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2305.03701] LMEye: An Interactive Perception Network for Large Language Models](http://arxiv.org/abs/2305.03701) #large language model</code></li>
<li>Summary: <p>Training a Large Visual Language Model (LVLM) from scratch, like GPT-4, is
resource-intensive. Our paper proposes an alternative method called LMEye, a
play-plug-in Interactive Perception Network for Large Language Models (LLMs),
aiming to improve the accuracy of image understanding for the LVLM. Previous
methods that infuse visual information into LLMs utilize a static visual
mapping network, but lack dynamic interaction between the LLMs and visual
information. LMEye addresses this issue by allowing the LLM to incorporate the
visual information that aligned with human instruction. Specifically, the LMEye
network consists of a static visual mapping network to provide the basic
perception of an image to LLMs. Then, it also contains additional linear layers
responsible for acquiring requests from LLMs, decomposing image features, and
transmitting the interleaved information to LLMs, respectively. In this way,
LLMs act to be in charge of understanding human instructions, sending it to the
interactive perception network, and generating the response based on the
interleaved multimodal information. We evaluate LMEye through extensive
experiments on multimodal question answering and reasoning tasks, demonstrating
that it significantly improves the zero-shot performance of LLMs on multimodal
tasks compared to previous methods.
</p></li>
</ul>

<h3>Title: VicunaNER: Zero/Few-shot Named Entity Recognition using Vicuna. (arXiv:2305.03253v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2305.03253">http://arxiv.org/abs/2305.03253</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2305.03253] VicunaNER: Zero/Few-shot Named Entity Recognition using Vicuna](http://arxiv.org/abs/2305.03253) #large language model</code></li>
<li>Summary: <p>Large Language Models (LLMs, e.g., ChatGPT) have shown impressive zero- and
few-shot capabilities in Named Entity Recognition (NER). However, these models
can only be accessed via online APIs, which may cause data leak and
non-reproducible problems. In this paper, we propose VicunaNER, a zero/few-shot
NER framework based on the newly released open-source LLM -- Vicuna. VicunaNER
is a two-phase framework, where each phase leverages multi-turn dialogues with
Vicuna to recognize entities from texts. We name the second phase as
Re-Recognition, which recognizes those entities not recognized in the first
phase (a.k.a. Recognition). Moreover, we set entity correctness check dialogues
in each phase to filter out wrong entities. We evaluate VicunaNER's zero-shot
capacity on 10 datasets crossing 5 domains and few-shot capacity on Few-NERD.
Experimental results demonstrate that VicunaNER achieves superior performance
in both shot settings. Additionally, we conduct comprehensive investigations on
Vicuna from multiple perspectives.
</p></li>
</ul>

<h3>Title: Verify-and-Edit: A Knowledge-Enhanced Chain-of-Thought Framework. (arXiv:2305.03268v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2305.03268">http://arxiv.org/abs/2305.03268</a></li>
<li>Code URL: <a href="https://github.com/ruochenzhao/verify-and-edit">https://github.com/ruochenzhao/verify-and-edit</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2305.03268] Verify-and-Edit: A Knowledge-Enhanced Chain-of-Thought Framework](http://arxiv.org/abs/2305.03268) #large language model</code></li>
<li>Summary: <p>As large language models (LLMs) have become the norm in NLP, demonstrating
good performance in generation and reasoning tasks, one of its most fatal
disadvantages is the lack of factual correctness. Generating unfactual texts
not only leads to lower performances but also degrades the trust and validity
of their applications. Chain-of-Thought (CoT) prompting improves trust and
model performance on complex reasoning tasks by generating interpretable
reasoning chains, but still suffers from factuality concerns in
knowledge-intensive tasks. In this paper, we propose the Verify-and-Edit
framework for CoT prompting, which seeks to increase prediction factuality by
post-editing reasoning chains according to external knowledge. Building on top
of GPT-3, our framework lead to accuracy improvements in multiple open-domain
question-answering tasks.
</p></li>
</ul>

<h3>Title: MindGames: Targeting Theory of Mind in Large Language Models with Dynamic Epistemic Modal Logic. (arXiv:2305.03353v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2305.03353">http://arxiv.org/abs/2305.03353</a></li>
<li>Code URL: <a href="https://github.com/antoinelrnld/modlog">https://github.com/antoinelrnld/modlog</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2305.03353] MindGames: Targeting Theory of Mind in Large Language Models with Dynamic Epistemic Modal Logic](http://arxiv.org/abs/2305.03353) #large language model</code></li>
<li>Summary: <p>Theory of Mind (ToM) is a critical component of intelligence, yet accurately
measuring it continues to be a subject of debate. Prior research has attempted
to apply human ToM assessments to natural language processing models using
either human-created standardized tests or rule-based templates. However, these
methods primarily focus on simplistic reasoning and require further validation.
In this study, we utilize dynamic epistemic logic, which has established
overlaps with ToM, to generate more intricate problems. We also introduce novel
verbalization techniques to express these problems using natural language. Our
findings indicate that certain language model scaling (from 70M to 6B and 350M
to 174B) does not consistently yield results better than random chance. While
GPT-4 demonstrates improved epistemic reasoning capabilities, there is still
room for enhancement. Our code and datasets are publicly available
https://github.com/antoinelrnld/modlog
https://huggingface.co/datasets/sileod/mindgames
</p></li>
</ul>

<h3>Title: Simulating H.P. Lovecraft horror literature with the ChatGPT large language model. (arXiv:2305.03429v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2305.03429">http://arxiv.org/abs/2305.03429</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2305.03429] Simulating H](http://arxiv.org/abs/2305.03429) #large language model</code></li>
<li>Summary: <p>In this paper, we present a novel approach to simulating H.P. Lovecraft's
horror literature using the ChatGPT large language model, specifically the
GPT-4 architecture. Our study aims to generate text that emulates Lovecraft's
unique writing style and themes, while also examining the effectiveness of
prompt engineering techniques in guiding the model's output. To achieve this,
we curated a prompt containing several specialized literature references and
employed advanced prompt engineering methods. We conducted an empirical
evaluation of the generated text by administering a survey to a sample of
undergraduate students. Utilizing statistical hypothesis testing, we assessed
the students ability to distinguish between genuine Lovecraft works and those
generated by our model. Our findings demonstrate that the participants were
unable to reliably differentiate between the two, indicating the effectiveness
of the GPT-4 model and our prompt engineering techniques in emulating
Lovecraft's literary style. In addition to presenting the GPT model's
capabilities, this paper provides a comprehensive description of its underlying
architecture and offers a comparative analysis with related work that simulates
other notable authors and philosophers, such as Dennett. By exploring the
potential of large language models in the context of literary emulation, our
study contributes to the body of research on the applications and limitations
of these models in various creative domains.
</p></li>
</ul>

<h3>Title: T-SciQ: Teaching Multimodal Chain-of-Thought Reasoning via Large Language Model Signals for Science Question Answering. (arXiv:2305.03453v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2305.03453">http://arxiv.org/abs/2305.03453</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2305.03453] T-SciQ: Teaching Multimodal Chain-of-Thought Reasoning via Large Language Model Signals for Science Question Answering](http://arxiv.org/abs/2305.03453) #large language model</code></li>
<li>Summary: <p>Large Language Models (LLMs) have recently demonstrated exceptional
performance in various Natural Language Processing (NLP) tasks. They have also
shown the ability to perform chain-of-thought (CoT) reasoning to solve complex
problems. Recent studies have explored CoT reasoning in complex multimodal
scenarios, such as the science question answering task, by fine-tuning
multimodal models with high-quality human-annotated CoT rationales. However,
collecting high-quality COT rationales is usually time-consuming and costly.
Besides, the annotated rationales are hardly accurate due to the redundant
information involved or the essential information missed. To address these
issues, we propose a novel method termed \emph{T-SciQ} that aims at teaching
science question answering with LLM signals. The T-SciQ approach generates
high-quality CoT rationales as teaching signals and is advanced to train much
smaller models to perform CoT reasoning in complex modalities. Additionally, we
introduce a novel data mixing strategy to produce more effective teaching data
samples for simple and complex science question answer problems. Extensive
experimental results show that our T-SciQ method achieves a new
state-of-the-art performance on the ScienceQA benchmark, with an accuracy of
96.18%. Moreover, our approach outperforms the most powerful fine-tuned
baseline by 4.5%.
</p></li>
</ul>

<h3>Title: Automatic Prompt Optimization with "Gradient Descent" and Beam Search. (arXiv:2305.03495v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2305.03495">http://arxiv.org/abs/2305.03495</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2305.03495] Automatic Prompt Optimization with "Gradient Descent" and Beam Search](http://arxiv.org/abs/2305.03495) #large language model</code></li>
<li>Summary: <p>Large Language Models (LLMs) have shown impressive performance as general
purpose agents, but their abilities remain highly dependent on prompts which
are hand written with onerous trial-and-error effort. We propose a simple and
nonparametric solution to this problem, Automatic Prompt Optimization (APO),
which is inspired by numerical gradient descent to automatically improve
prompts, assuming access to training data and an LLM API. The algorithm uses
minibatches of data to form natural language <code>gradients'' that criticize the
current prompt. The gradients are then</code>propagated'' into the prompt by
editing the prompt in the opposite semantic direction of the gradient. These
gradient descent steps are guided by a beam search and bandit selection
procedure which significantly improves algorithmic efficiency. Preliminary
results across three benchmark NLP tasks and the novel problem of LLM jailbreak
detection suggest that Automatic Prompt Optimization can outperform prior
prompt editing techniques and improve an initial prompt's performance by up to
31\%, by using data to rewrite vague task descriptions into more precise
annotation instructions.
</p></li>
</ul>

<h3>Title: Can Large Language Models Transform Computational Social Science?. (arXiv:2305.03514v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2305.03514">http://arxiv.org/abs/2305.03514</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2305.03514] Can Large Language Models Transform Computational Social Science?](http://arxiv.org/abs/2305.03514) #large language model</code></li>
<li>Summary: <p>Large Language Models (LLMs) like ChatGPT are capable of successfully
performing many language processing tasks zero-shot (without the need for
training data). If this capacity also applies to the coding of social phenomena
like persuasiveness and political ideology, then LLMs could effectively
transform Computational Social Science (CSS). This work provides a road map for
using LLMs as CSS tools. Towards this end, we contribute a set of prompting
best practices and an extensive evaluation pipeline to measure the zero-shot
performance of 13 language models on 24 representative CSS benchmarks. On
taxonomic labeling tasks (classification), LLMs fail to outperform the best
fine-tuned models but still achieve fair levels of agreement with humans. On
free-form coding tasks (generation), LLMs produce explanations that often
exceed the quality of crowdworkers' gold references. We conclude that today's
LLMs can radically augment the CSS research pipeline in two ways: (1) serving
as zero-shot data annotators on human annotation teams, and (2) bootstrapping
challenging creative generation tasks (e.g., explaining the hidden meaning
behind text). In summary, LLMs can significantly reduce costs and increase
efficiency of social science analysis in partnership with humans.
</p></li>
</ul>

<h3>Title: Black-box Prompt Tuning with Subspace Learning. (arXiv:2305.03518v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2305.03518">http://arxiv.org/abs/2305.03518</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2305.03518] Black-box Prompt Tuning with Subspace Learning](http://arxiv.org/abs/2305.03518) #large language model</code></li>
<li>Summary: <p>Black-box prompt tuning uses derivative-free optimization algorithms to learn
prompts in low-dimensional subspaces instead of back-propagating through the
network of Large Language Models (LLMs). Recent studies have found that
black-box prompt tuning lacks versatility across tasks and LLMs, which we
believe is related to the inappropriate choice of subspaces. In this paper, we
propose Black-box prompt tuning with Subspace Learning (BSL) to improve the
versatility of black-box prompt tuning. Based on the assumption that nearly
optimal prompts for similar tasks exist in a common subspace, we propose
identifying such subspaces by meta-learning on a set of similar source tasks.
Therefore, for a target task that shares similarities with source tasks, we
guarantee that optimizing in the subspace can find a prompt that performs well
on the target task. Experiments confirm that our BSL framework consistently
achieves competitive performance regardless of downstream tasks and LLMs.
</p></li>
</ul>

<h3>Title: In-context Learning as Maintaining Coherency: A Study of On-the-fly Machine Translation Using Large Language Models. (arXiv:2305.03573v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2305.03573">http://arxiv.org/abs/2305.03573</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2305.03573] In-context Learning as Maintaining Coherency: A Study of On-the-fly Machine Translation Using Large Language Models](http://arxiv.org/abs/2305.03573) #large language model</code></li>
<li>Summary: <p>The phenomena of in-context learning has typically been thought of as
"learning from examples". In this work which focuses on Machine Translation, we
present a perspective of in-context learning as the desired generation task
maintaining coherency with its context, i.e., the prompt examples. We first
investigate randomly sampled prompts across 4 domains, and find that
translation performance improves when shown in-domain prompts. Next, we
investigate coherency for the in-domain setting, which uses prompt examples
from a moving window. We study this with respect to other factors that have
previously been identified in the literature such as length, surface similarity
and sentence embedding similarity. Our results across 3 models (GPTNeo2.7B,
Bloom3B, XGLM2.9B), and three translation directions
(\texttt{en}$\rightarrow${\texttt{pt, de, fr}}) suggest that the long-term
coherency of the prompts and the test sentence is a good indicator of
downstream translation performance. In doing so, we demonstrate the efficacy of
In-context Machine Translation for on-the-fly adaptation.
</p></li>
</ul>

<h3>Title: Large Language Models in Ambulatory Devices for Home Health Diagnostics: A case study of Sickle Cell Anemia Management. (arXiv:2305.03715v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2305.03715">http://arxiv.org/abs/2305.03715</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2305.03715] Large Language Models in Ambulatory Devices for Home Health Diagnostics: A case study of Sickle Cell Anemia Management](http://arxiv.org/abs/2305.03715) #large language model</code></li>
<li>Summary: <p>This study investigates the potential of an ambulatory device that
incorporates Large Language Models (LLMs) in cadence with other specialized ML
models to assess anemia severity in sickle cell patients in real time. The
device would rely on sensor data that measures angiogenic material levels to
assess anemia severity, providing real-time information to patients and
clinicians to reduce the frequency of vaso-occlusive crises because of the
early detection of anemia severity, allowing for timely interventions and
potentially reducing the likelihood of serious complications. The main
challenges in developing such a device are the creation of a reliable
non-invasive tool for angiogenic level assessment, a biophysics model and the
practical consideration of an LLM communicating with emergency personnel on
behalf of an incapacitated patient. A possible system is proposed, and the
limitations of this approach are discussed.
</p></li>
</ul>

<h2>segmentation</h2>
<h3>Title: HAISTA-NET: Human Assisted Instance Segmentation Through Attention. (arXiv:2305.03105v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2305.03105">http://arxiv.org/abs/2305.03105</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2305.03105] HAISTA-NET: Human Assisted Instance Segmentation Through Attention](http://arxiv.org/abs/2305.03105) #segmentation</code></li>
<li>Summary: <p>Instance segmentation is a form of image detection which has a range of
applications, such as object refinement, medical image analysis, and
image/video editing, all of which demand a high degree of accuracy. However,
this precision is often beyond the reach of what even state-of-the-art, fully
automated instance segmentation algorithms can deliver. The performance gap
becomes particularly prohibitive for small and complex objects. Practitioners
typically resort to fully manual annotation, which can be a laborious process.
In order to overcome this problem, we propose a novel approach to enable more
precise predictions and generate higher-quality segmentation masks for
high-curvature, complex and small-scale objects. Our human-assisted
segmentation model, HAISTA-NET, augments the existing Strong Mask R-CNN network
to incorporate human-specified partial boundaries. We also present a dataset of
hand-drawn partial object boundaries, which we refer to as human attention
maps. In addition, the Partial Sketch Object Boundaries (PSOB) dataset contains
hand-drawn partial object boundaries which represent curvatures of an object's
ground truth mask with several pixels. Through extensive evaluation using the
PSOB dataset, we show that HAISTA-NET outperforms state-of-the art methods such
as Mask R-CNN, Strong Mask R-CNN, and Mask2Former, achieving respective
increases of +36.7, +29.6, and +26.5 points in AP-Mask metrics for these three
models. We hope that our novel approach will set a baseline for future
human-aided deep learning models by combining fully automated and interactive
instance segmentation architectures.
</p></li>
</ul>

<h3>Title: Smaller3d: Smaller Models for 3D Semantic Segmentation Using Minkowski Engine and Knowledge Distillation Methods. (arXiv:2305.03188v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2305.03188">http://arxiv.org/abs/2305.03188</a></li>
<li>Code URL: <a href="https://github.com/madanela/smaller3d">https://github.com/madanela/smaller3d</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2305.03188] Smaller3d: Smaller Models for 3D Semantic Segmentation Using Minkowski Engine and Knowledge Distillation Methods](http://arxiv.org/abs/2305.03188) #segmentation</code></li>
<li>Summary: <p>There are various optimization techniques in the realm of 3D, including point
cloud-based approaches that use mesh, texture, and voxels which optimize how
you store, and how do calculate in 3D. These techniques employ methods such as
feed-forward networks, 3D convolutions, graph neural networks, transformers,
and sparse tensors. However, the field of 3D is one of the most computationally
expensive fields, and these methods have yet to achieve their full potential
due to their large capacity, complexity, and computation limits. This paper
proposes the application of knowledge distillation techniques, especially for
sparse tensors in 3D deep learning, to reduce model sizes while maintaining
performance. We analyze and purpose different loss functions, including
standard methods and combinations of various losses, to simulate the
performance of state-of-the-art models of different Sparse Convolutional NNs.
Our experiments are done on the standard ScanNet V2 dataset, and we achieved
around 2.6\% mIoU difference with a 4 times smaller model and around 8\% with a
16 times smaller model on the latest state-of-the-art spacio-temporal convents
based models.
</p></li>
</ul>

<h3>Title: Clothes Grasping and Unfolding Based on RGB-D Semantic Segmentation. (arXiv:2305.03259v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2305.03259">http://arxiv.org/abs/2305.03259</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2305.03259] Clothes Grasping and Unfolding Based on RGB-D Semantic Segmentation](http://arxiv.org/abs/2305.03259) #segmentation</code></li>
<li>Summary: <p>Clothes grasping and unfolding is a core step in robotic-assisted dressing.
Most existing works leverage depth images of clothes to train a deep
learning-based model to recognize suitable grasping points. These methods often
utilize physics engines to synthesize depth images to reduce the cost of real
labeled data collection. However, the natural domain gap between synthetic and
real images often leads to poor performance of these methods on real data.
Furthermore, these approaches often struggle in scenarios where grasping points
are occluded by the clothing item itself. To address the above challenges, we
propose a novel Bi-directional Fractal Cross Fusion Network (BiFCNet) for
semantic segmentation, enabling recognition of graspable regions in order to
provide more possibilities for grasping. Instead of using depth images only, we
also utilize RGB images with rich color features as input to our network in
which the Fractal Cross Fusion (FCF) module fuses RGB and depth data by
considering global complex features based on fractal geometry. To reduce the
cost of real data collection, we further propose a data augmentation method
based on an adversarial strategy, in which the color and geometric
transformations simultaneously process RGB and depth data while maintaining the
label correspondence. Finally, we present a pipeline for clothes grasping and
unfolding from the perspective of semantic segmentation, through the addition
of a strategy for grasp point selection from segmentation regions based on
clothing flatness measures, while taking into account the grasping direction.
We evaluate our BiFCNet on the public dataset NYUDv2 and obtained comparable
performance to current state-of-the-art models. We also deploy our model on a
Baxter robot, running extensive grasping and unfolding experiments as part of
our ablation studies, achieving an 84% success rate.
</p></li>
</ul>

<h3>Title: Asynchronous Events-based Panoptic Segmentation using Graph Mixer Neural Network. (arXiv:2305.03640v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2305.03640">http://arxiv.org/abs/2305.03640</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2305.03640] Asynchronous Events-based Panoptic Segmentation using Graph Mixer Neural Network](http://arxiv.org/abs/2305.03640) #segmentation</code></li>
<li>Summary: <p>In the context of robotic grasping, object segmentation encounters several
difficulties when faced with dynamic conditions such as real-time operation,
occlusion, low lighting, motion blur, and object size variability. In response
to these challenges, we propose the Graph Mixer Neural Network that includes a
novel collaborative contextual mixing layer, applied to 3D event graphs formed
on asynchronous events. The proposed layer is designed to spread spatiotemporal
correlation within an event graph at four nearest neighbor levels parallelly.
We evaluate the effectiveness of our proposed method on the Event-based
Segmentation (ESD) Dataset, which includes five unique image degradation
challenges, including occlusion, blur, brightness, trajectory, scale variance,
and segmentation of known and unknown objects. The results show that our
proposed approach outperforms state-of-the-art methods in terms of mean
intersection over the union and pixel accuracy. Code available at:
https://github.com/sanket0707/GNN-Mixer.git
</p></li>
</ul>

<button id="copy">Copy All</button>
</article>
<script src="https://cdn.staticfile.org/clipboard.js/2.0.4/clipboard.min.js"></script>
<script src="../../javascript/clipboard.js"></script>
