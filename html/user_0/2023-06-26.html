<link rel="stylesheet" href="../../css/markdown.css" />
<article class="markdown-body">
<h2>secure</h2>
<h3>Title: Cryptanalysis on Secure ECC based Mutual Authentication Protocol for Cloud-Assisted TMIS. (arXiv:2306.13100v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.13100">http://arxiv.org/abs/2306.13100</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.13100] Cryptanalysis on Secure ECC based Mutual Authentication Protocol for Cloud-Assisted TMIS](http://arxiv.org/abs/2306.13100) #secure</code></li>
<li>Summary: <p>The creation of TMIS (Telecare Medical Information System) makes it simpler
for patients to receive healthcare services and opens up options for seeking
medical attention and storing medical records with access control. With
Wireless Medical Sensor Network and cloud-based architecture, TMIS gives the
chance to patients to collect their physical health information from medical
sensors and also upload this information to the cloud through their mobile
devices. The communication is held through internet connectivity, therefore
security and privacy are the main motive aspects of a secure cloud-assisted
TMIS. However, because very sensitive data is transmitted between patients and
doctors through the cloud server, thus security protection is important for
this system. Recently, Kumar et al designed a mutual authentication protocol
for cloud-assisted TMIS based on ECC [2]. In this paper, we revisited this
scheme and traced out that their scheme has some significant pitfalls like
health report revelation attack, and report confidentiality. In this study, we
will provide the cryptanalysis of the scheme developed by Kumar et al.
</p></li>
</ul>

<h3>Title: The Landscape of Computing Symmetric $n$-Variable Functions with $2n$ Cards. (arXiv:2306.13551v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.13551">http://arxiv.org/abs/2306.13551</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.13551] The Landscape of Computing Symmetric $n$-Variable Functions with $2n$ Cards](http://arxiv.org/abs/2306.13551) #secure</code></li>
<li>Summary: <p>Secure multi-party computation using a physical deck of cards, often called
card-based cryptography, has been extensively studied during the past decade.
Many card-based protocols to securely compute various Boolean functions have
been developed. As each input bit is typically encoded by two cards, computing
an $n$-variable Boolean function requires at least $2n$ cards. We are
interested in optimal protocols that use exactly $2n$ cards. In particular, we
focus on symmetric functions, where the output only depends on the number of 1s
in the inputs. In this paper, we formulate the problem of developing $2n$-card
protocols to compute $n$-variable symmetric Boolean functions by classifying
all such functions into several NPN-equivalence classes. We then summarize
existing protocols that can compute some representative functions from these
classes, and also solve some of the open problems by developing protocols to
compute particular functions in the cases $n=4$, $5$, $6$, and $7$.
</p></li>
</ul>

<h2>security</h2>
<h3>Title: Fuzzification-based Feature Selection for Enhanced Website Content Encryption. (arXiv:2306.13548v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.13548">http://arxiv.org/abs/2306.13548</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.13548] Fuzzification-based Feature Selection for Enhanced Website Content Encryption](http://arxiv.org/abs/2306.13548) #security</code></li>
<li>Summary: <p>We propose a novel approach that utilizes fuzzification theory to perform
feature selection on website content for encryption purposes. Our objective is
to identify and select the most relevant features from the website by
harnessing the principles of fuzzy logic. Fuzzification allows us to transform
the crisp website content into fuzzy representations, enabling a more nuanced
analysis of their characteristics. By considering the degree of membership of
each feature in different fuzzy categories, we can evaluate their importance
and relevance for encryption. This approach enables us to prioritize and focus
on the features that exhibit higher membership degrees, indicating their
significance in the encryption process. By employing fuzzification-based
feature selection, we aim to enhance the effectiveness and efficiency of
website content encryption, ultimately improving the overall internet security.
</p></li>
</ul>

<h2>privacy</h2>
<h3>Title: Differentially Private Synthetic Data Using KD-Trees. (arXiv:2306.13211v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.13211">http://arxiv.org/abs/2306.13211</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.13211] Differentially Private Synthetic Data Using KD-Trees](http://arxiv.org/abs/2306.13211) #privacy</code></li>
<li>Summary: <p>Creation of a synthetic dataset that faithfully represents the data
distribution and simultaneously preserves privacy is a major research
challenge. Many space partitioning based approaches have emerged in recent
years for answering statistical queries in a differentially private manner.
However, for synthetic data generation problem, recent research has been mainly
focused on deep generative models. In contrast, we exploit space partitioning
techniques together with noise perturbation and thus achieve intuitive and
transparent algorithms. We propose both data independent and data dependent
algorithms for $\epsilon$-differentially private synthetic data generation
whose kernel density resembles that of the real dataset. Additionally, we
provide theoretical results on the utility-privacy trade-offs and show how our
data dependent approach overcomes the curse of dimensionality and leads to a
scalable algorithm. We show empirical utility improvements over the prior work,
and discuss performance of our algorithm on a downstream classification task on
a real dataset.
</p></li>
</ul>

<h3>Title: Prior-itizing Privacy: A Bayesian Approach to Setting the Privacy Budget in Differential Privacy. (arXiv:2306.13214v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.13214">http://arxiv.org/abs/2306.13214</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.13214] Prior-itizing Privacy: A Bayesian Approach to Setting the Privacy Budget in Differential Privacy](http://arxiv.org/abs/2306.13214) #privacy</code></li>
<li>Summary: <p>When releasing outputs from confidential data, agencies need to balance the
analytical usefulness of the released data with the obligation to protect data
subjects' confidentiality. For releases satisfying differential privacy, this
balance is reflected by the parameter epsilon, known as the privacy budget. In
practice, it can be difficult for agencies to select and interpret epsilon. We
use Bayesian posterior probabilities of disclosure to provide a framework for
setting epsilon. The agency decides how much posterior risk it is willing to
accept in a data release at various levels of prior risk. Using a mathematical
relationship among these probabilities and epsilon, the agency selects the
maximum epsilon that ensures the posterior-to-prior ratios are acceptable for
all values of prior disclosure risk. The framework applies to any
differentially private mechanism.
</p></li>
</ul>

<h3>Title: Diverse Community Data for Benchmarking Data Privacy Algorithms. (arXiv:2306.13216v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.13216">http://arxiv.org/abs/2306.13216</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.13216] Diverse Community Data for Benchmarking Data Privacy Algorithms](http://arxiv.org/abs/2306.13216) #privacy</code></li>
<li>Summary: <p>The Diverse Communities Data Excerpts are the core of a National Institute of
Standards and Technology (NIST) program to strengthen understanding of tabular
data deidentification technologies such as synthetic data. Synthetic data is an
ambitious attempt to democratize the benefits of big data; it uses generative
models to recreate sensitive personal data with new records for public release.
However, it is vulnerable to the same bias and privacy issues that impact other
machine learning applications, and can even amplify those issues. When
deidentified data distributions introduce bias or artifacts, or leak sensitive
information, they propagate these problems to downstream applications.
Furthermore, real-world survey conditions such as diverse subpopulations,
heterogeneous non-ordinal data spaces, and complex dependencies between
features pose specific challenges for synthetic data algorithms. These
observations motivate the need for real, diverse, and complex benchmark data to
support a robust understanding of algorithm behavior. This paper introduces
four contributions: new theoretical work on the relationship between diverse
populations and challenges for equitable deidentification; public benchmark
data focused on diverse populations and challenging features curated from the
American Community Survey; an open source suite of evaluation metrology for
deidentified datasets; and an archive of evaluation results on a broad
collection of deidentification techniques. The initial set of evaluation
results demonstrate the suitability of these tools for investigations in this
field.
</p></li>
</ul>

<h3>Title: Variational Counterfactual Prediction under Runtime Domain Corruption. (arXiv:2306.13271v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.13271">http://arxiv.org/abs/2306.13271</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.13271] Variational Counterfactual Prediction under Runtime Domain Corruption](http://arxiv.org/abs/2306.13271) #privacy</code></li>
<li>Summary: <p>To date, various neural methods have been proposed for causal effect
estimation based on observational data, where a default assumption is the same
distribution and availability of variables at both training and inference
(i.e., runtime) stages. However, distribution shift (i.e., domain shift) could
happen during runtime, and bigger challenges arise from the impaired
accessibility of variables. This is commonly caused by increasing privacy and
ethical concerns, which can make arbitrary variables unavailable in the entire
runtime data and imputation impractical. We term the co-occurrence of domain
shift and inaccessible variables runtime domain corruption, which seriously
impairs the generalizability of a trained counterfactual predictor. To counter
runtime domain corruption, we subsume counterfactual prediction under the
notion of domain adaptation. Specifically, we upper-bound the error w.r.t. the
target domain (i.e., runtime covariates) by the sum of source domain error and
inter-domain distribution distance. In addition, we build an adversarially
unified variational causal effect model, named VEGAN, with a novel two-stage
adversarial domain adaptation scheme to reduce the latent distribution
disparity between treated and control groups first, and between training and
runtime variables afterwards. We demonstrate that VEGAN outperforms other
state-of-the-art baselines on individual-level treatment effect estimation in
the presence of runtime domain corruption on benchmark datasets.
</p></li>
</ul>

<h2>protect</h2>
<h3>Title: Full Transparency in DBI frameworks. (arXiv:2306.13529v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.13529">http://arxiv.org/abs/2306.13529</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.13529] Full Transparency in DBI frameworks](http://arxiv.org/abs/2306.13529) #protect</code></li>
<li>Summary: <p>Following the increasing trends of malicious applications or cyber threats in
general, program analysis has become a ubiquitous technique in extracting
relevant features. The current state-of-the-art solutions seem to fall behind
new techniques. For instance, dynamic binary instrumentation (DBI) provides
some promising results, but falls short when it comes to ease of use and
overcoming analysis evasion. In this regard, we propose a two-fold
contribution. First, we introduce COBAI (Complex Orchestrator for Binary
Analysis and Instrumentation), a DBI framework designed for malware analysis,
prioritizing ease-of-use and analysis transparency, without imposing a
significant overhead. Second, we introduce an aggregated test suite intended to
stand as a benchmark in determining the quality of an analysis solution
regarding the protection against evasion mechanisms. The efficiency of our
solution is validated by a careful evaluation taking into consideration other
DBI frameworks, analysis environments, and the proposed benchmark.
</p></li>
</ul>

<h3>Title: Creating Valid Adversarial Examples of Malware. (arXiv:2306.13587v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.13587">http://arxiv.org/abs/2306.13587</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.13587] Creating Valid Adversarial Examples of Malware](http://arxiv.org/abs/2306.13587) #protect</code></li>
<li>Summary: <p>Machine learning is becoming increasingly popular as a go-to approach for
many tasks due to its world-class results. As a result, antivirus developers
are incorporating machine learning models into their products. While these
models improve malware detection capabilities, they also carry the disadvantage
of being susceptible to adversarial attacks. Although this vulnerability has
been demonstrated for many models in white-box settings, a black-box attack is
more applicable in practice for the domain of malware detection. We present a
generator of adversarial malware examples using reinforcement learning
algorithms. The reinforcement learning agents utilize a set of
functionality-preserving modifications, thus creating valid adversarial
examples. Using the proximal policy optimization (PPO) algorithm, we achieved
an evasion rate of 53.84% against the gradient-boosted decision tree (GBDT)
model. The PPO agent previously trained against the GBDT classifier scored an
evasion rate of 11.41% against the neural network-based classifier MalConv and
an average evasion rate of 2.31% against top antivirus programs. Furthermore,
we discovered that random application of our functionality-preserving portable
executable modifications successfully evades leading antivirus engines, with an
average evasion rate of 11.65%. These findings indicate that machine
learning-based models used in malware detection systems are vulnerable to
adversarial attacks and that better safeguards need to be taken to protect
these systems.
</p></li>
</ul>

<h2>defense</h2>
<h2>attack</h2>
<h3>Title: Evaluating the Robustness of Text-to-image Diffusion Models against Real-world Attacks. (arXiv:2306.13103v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.13103">http://arxiv.org/abs/2306.13103</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.13103] Evaluating the Robustness of Text-to-image Diffusion Models against Real-world Attacks](http://arxiv.org/abs/2306.13103) #attack</code></li>
<li>Summary: <p>Text-to-image (T2I) diffusion models (DMs) have shown promise in generating
high-quality images from textual descriptions. The real-world applications of
these models require particular attention to their safety and fidelity, but
this has not been sufficiently explored. One fundamental question is whether
existing T2I DMs are robust against variations over input texts. To answer it,
this work provides the first robustness evaluation of T2I DMs against
real-world attacks. Unlike prior studies that focus on malicious attacks
involving apocryphal alterations to the input texts, we consider an attack
space spanned by realistic errors (e.g., typo, glyph, phonetic) that humans can
make, to ensure semantic consistency. Given the inherent randomness of the
generation process, we develop novel distribution-based attack objectives to
mislead T2I DMs. We perform attacks in a black-box manner without any knowledge
of the model. Extensive experiments demonstrate the effectiveness of our method
for attacking popular T2I DMs and simultaneously reveal their non-trivial
robustness issues. Moreover, we provide an in-depth analysis of our method to
show that it is not designed to attack the text encoder in T2I DMs solely.
</p></li>
</ul>

<h3>Title: Document Image Cleaning using Budget-Aware Black-Box Approximation. (arXiv:2306.13236v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.13236">http://arxiv.org/abs/2306.13236</a></li>
<li>Code URL: <a href="https://github.com/tataganesh/query-efficient-approx-to-improve-ocr">https://github.com/tataganesh/query-efficient-approx-to-improve-ocr</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2306.13236] Document Image Cleaning using Budget-Aware Black-Box Approximation](http://arxiv.org/abs/2306.13236) #attack</code></li>
<li>Summary: <p>Recent work has shown that by approximating the behaviour of a
non-differentiable black-box function using a neural network, the black-box can
be integrated into a differentiable training pipeline for end-to-end training.
This methodology is termed "differentiable bypass,'' and a successful
application of this method involves training a document preprocessor to improve
the performance of a black-box OCR engine. However, a good approximation of an
OCR engine requires querying it for all samples throughout the training
process, which can be computationally and financially expensive. Several
zeroth-order optimization (ZO) algorithms have been proposed in black-box
attack literature to find adversarial examples for a black-box model by
computing its gradient in a query-efficient manner. However, the query
complexity and convergence rate of such algorithms makes them infeasible for
our problem. In this work, we propose two sample selection algorithms to train
an OCR preprocessor with less than 10% of the original system's OCR engine
queries, resulting in more than 60% reduction of the total training time
without significant loss of accuracy. We also show an improvement of 4% in the
word-level accuracy of a commercial OCR engine with only 2.5% of the total
queries and a 32x reduction in monetary cost. Further, we propose a simple
ranking technique to prune 30% of the document images from the training dataset
without affecting the system's performance.
</p></li>
</ul>

<h3>Title: Preventing EFail Attacks with Client-Side WebAssembly: The Case of Swiss Post's IncaMail. (arXiv:2306.13388v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.13388">http://arxiv.org/abs/2306.13388</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.13388] Preventing EFail Attacks with Client-Side WebAssembly: The Case of Swiss Post's IncaMail](http://arxiv.org/abs/2306.13388) #attack</code></li>
<li>Summary: <p>Traditional email encryption schemes are vulnerable to EFail attacks, which
exploit the lack of message authentication by manipulating ciphertexts and
exfiltrating plaintext via HTML backchannels. Swiss Post's IncaMail, a secure
email service for transmitting legally binding, encrypted, and verifiable
emails, counters EFail attacks using an authenticated-encryption with
associated data (AEAD) encryption scheme to ensure message privacy and
authentication between servers. IncaMail relies on a trusted infrastructure
backend and encrypts messages per user policy. This paper presents a revised
IncaMail architecture that offloads the majority of cryptographic operations to
clients, offering benefits such as reduced computational load and energy
footprint, relaxed trust assumptions, and per-message encryption key policies.
Our proof-of-concept prototype and benchmarks demonstrate the robustness of the
proposed scheme, with client-side WebAssembly-based cryptographic operations
yielding significant performance improvements (up to ~14x) over conventional
JavaScript implementations.
</p></li>
</ul>

<h2>robust</h2>
<h3>Title: Targeted Background Removal Creates Interpretable Feature Visualizations. (arXiv:2306.13178v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.13178">http://arxiv.org/abs/2306.13178</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.13178] Targeted Background Removal Creates Interpretable Feature Visualizations](http://arxiv.org/abs/2306.13178) #robust</code></li>
<li>Summary: <p>Feature visualization is used to visualize learned features for black box
machine learning models. Our approach explores an altered training process to
improve interpretability of the visualizations. We argue that by using
background removal techniques as a form of robust training, a network is forced
to learn more human recognizable features, namely, by focusing on the main
object of interest without any distractions from the background. Four different
training methods were used to verify this hypothesis. The first used unmodified
pictures. The second used a black background. The third utilized Gaussian noise
as the background. The fourth approach employed a mix of background removed
images and unmodified images. The feature visualization results show that the
background removed images reveal a significant improvement over the baseline
model. These new results displayed easily recognizable features from their
respective classes, unlike the model trained on unmodified data.
</p></li>
</ul>

<h3>Title: Continuous Online Extrinsic Calibration of Fisheye Camera and LiDAR. (arXiv:2306.13240v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.13240">http://arxiv.org/abs/2306.13240</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.13240] Continuous Online Extrinsic Calibration of Fisheye Camera and LiDAR](http://arxiv.org/abs/2306.13240) #robust</code></li>
<li>Summary: <p>Automated driving systems use multi-modal sensor suites to ensure the
reliable, redundant and robust perception of the operating domain, for example
camera and LiDAR. An accurate extrinsic calibration is required to fuse the
camera and LiDAR data into a common spatial reference frame required by
high-level perception functions. Over the life of the vehicle the value of the
extrinsic calibration can change due physical disturbances, introducing an
error into the high-level perception functions. Therefore there is a need for
continuous online extrinsic calibration algorithms which can automatically
update the value of the camera-LiDAR calibration during the life of the vehicle
using only sensor data.
</p></li>
</ul>

<p>We propose using mutual information between the camera image's depth
estimate, provided by commonly available monocular depth estimation networks,
and the LiDAR pointcloud's geometric distance as a optimization metric for
extrinsic calibration. Our method requires no calibration target, no ground
truth training data and no expensive offline optimization. We demonstrate our
algorithm's accuracy, precision, speed and self-diagnosis capability on the
KITTI-360 data set.
</p>

<h3>Title: Robustness of Segment Anything Model (SAM) for Autonomous Driving in Adverse Weather Conditions. (arXiv:2306.13290v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.13290">http://arxiv.org/abs/2306.13290</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.13290] Robustness of Segment Anything Model (SAM) for Autonomous Driving in Adverse Weather Conditions](http://arxiv.org/abs/2306.13290) #robust</code></li>
<li>Summary: <p>Segment Anything Model (SAM) has gained considerable interest in recent times
for its remarkable performance and has emerged as a foundational model in
computer vision. It has been integrated in diverse downstream tasks, showcasing
its strong zero-shot transfer capabilities. Given its impressive performance,
there is a strong desire to apply SAM in autonomous driving to improve the
performance of vision tasks, particularly in challenging scenarios such as
driving under adverse weather conditions. However, its robustness under adverse
weather conditions remains uncertain. In this work, we investigate the
application of SAM in autonomous driving and specifically explore its
robustness under adverse weather conditions. Overall, this work aims to enhance
understanding of SAM's robustness in challenging scenarios before integrating
it into autonomous driving vision tasks, providing valuable insights for future
applications.
</p></li>
</ul>

<h3>Title: Deep Omni-supervised Learning for Rib Fracture Detection from Chest Radiology Images. (arXiv:2306.13301v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.13301">http://arxiv.org/abs/2306.13301</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.13301] Deep Omni-supervised Learning for Rib Fracture Detection from Chest Radiology Images](http://arxiv.org/abs/2306.13301) #robust</code></li>
<li>Summary: <p>Deep learning (DL)-based rib fracture detection has shown promise of playing
an important role in preventing mortality and improving patient outcome.
Normally, developing DL-based object detection models requires huge amount of
bounding box annotation. However, annotating medical data is time-consuming and
expertise-demanding, making obtaining a large amount of fine-grained
annotations extremely infeasible. This poses pressing need of developing
label-efficient detection models to alleviate radiologists' labeling burden. To
tackle this challenge, the literature of object detection has witnessed an
increase of weakly-supervised and semi-supervised approaches, yet still lacks a
unified framework that leverages various forms of fully-labeled,
weakly-labeled, and unlabeled data. In this paper, we present a novel
omni-supervised object detection network, ORF-Netv2, to leverage as much
available supervision as possible. Specifically, a multi-branch omni-supervised
detection head is introduced with each branch trained with a specific type of
supervision. A co-training-based dynamic label assignment strategy is then
proposed to enable flexibly and robustly learning from the weakly-labeled and
unlabeled data. Extensively evaluation was conducted for the proposed framework
with three rib fracture datasets on both chest CT and X-ray. By leveraging all
forms of supervision, ORF-Netv2 achieves mAPs of 34.7, 44.7, and 19.4 on the
three datasets, respectively, surpassing the baseline detector which uses only
box annotations by mAP gains of 3.8, 4.8, and 5.0, respectively. Furthermore,
ORF-Netv2 consistently outperforms other competitive label-efficient methods
over various scenarios, showing a promising framework for label-efficient
fracture detection.
</p></li>
</ul>

<h3>Title: Differentiable Display Photometric Stereo. (arXiv:2306.13325v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.13325">http://arxiv.org/abs/2306.13325</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.13325] Differentiable Display Photometric Stereo](http://arxiv.org/abs/2306.13325) #robust</code></li>
<li>Summary: <p>Photometric stereo leverages variations in illumination conditions to
reconstruct per-pixel surface normals. The concept of display photometric
stereo, which employs a conventional monitor as an illumination source, has the
potential to overcome limitations often encountered in bulky and
difficult-to-use conventional setups. In this paper, we introduce
Differentiable Display Photometric Stereo (DDPS), a method designed to achieve
high-fidelity normal reconstruction using an off-the-shelf monitor and camera.
DDPS addresses a critical yet often neglected challenge in photometric stereo:
the optimization of display patterns for enhanced normal reconstruction. We
present a differentiable framework that couples basis-illumination image
formation with a photometric-stereo reconstruction method. This facilitates the
learning of display patterns that leads to high-quality normal reconstruction
through automatic differentiation. Addressing the synthetic-real domain gap
inherent in end-to-end optimization, we propose the use of a real-world
photometric-stereo training dataset composed of 3D-printed objects. Moreover,
to reduce the ill-posed nature of photometric stereo, we exploit the linearly
polarized light emitted from the monitor to optically separate diffuse and
specular reflections in the captured images. We demonstrate that DDPS allows
for learning display patterns optimized for a target configuration and is
robust to initialization. We assess DDPS on 3D-printed objects with
ground-truth normals and diverse real-world objects, validating that DDPS
enables effective photometric-stereo reconstruction.
</p></li>
</ul>

<h3>Title: Bridging the Performance Gap between DETR and R-CNN for Graphical Object Detection in Document Images. (arXiv:2306.13526v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.13526">http://arxiv.org/abs/2306.13526</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.13526] Bridging the Performance Gap between DETR and R-CNN for Graphical Object Detection in Document Images](http://arxiv.org/abs/2306.13526) #robust</code></li>
<li>Summary: <p>This paper takes an important step in bridging the performance gap between
DETR and R-CNN for graphical object detection. Existing graphical object
detection approaches have enjoyed recent enhancements in CNN-based object
detection methods, achieving remarkable progress. Recently, Transformer-based
detectors have considerably boosted the generic object detection performance,
eliminating the need for hand-crafted features or post-processing steps such as
Non-Maximum Suppression (NMS) using object queries. However, the effectiveness
of such enhanced transformer-based detection algorithms has yet to be verified
for the problem of graphical object detection. Essentially, inspired by the
latest advancements in the DETR, we employ the existing detection transformer
with few modifications for graphical object detection. We modify object queries
in different ways, using points, anchor boxes and adding positive and negative
noise to the anchors to boost performance. These modifications allow for better
handling of objects with varying sizes and aspect ratios, more robustness to
small variations in object positions and sizes, and improved image
discrimination between objects and non-objects. We evaluate our approach on the
four graphical datasets: PubTables, TableBank, NTable and PubLaynet. Upon
integrating query modifications in the DETR, we outperform prior works and
achieve new state-of-the-art results with the mAP of 96.9\%, 95.7\% and 99.3\%
on TableBank, PubLaynet, PubTables, respectively. The results from extensive
ablations show that transformer-based methods are more effective for document
analysis analogous to other applications. We hope this study draws more
attention to the research of using detection transformers in document image
analysis.
</p></li>
</ul>

<h3>Title: A First Order Meta Stackelberg Method for Robust Federated Learning (Technical Report). (arXiv:2306.13273v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.13273">http://arxiv.org/abs/2306.13273</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.13273] A First Order Meta Stackelberg Method for Robust Federated Learning (Technical Report)](http://arxiv.org/abs/2306.13273) #robust</code></li>
<li>Summary: <p>Recent research efforts indicate that federated learning (FL) systems are
vulnerable to a variety of security breaches. While numerous defense strategies
have been suggested, they are mainly designed to counter specific attack
patterns and lack adaptability, rendering them less effective when facing
uncertain or adaptive threats. This work models adversarial FL as a Bayesian
Stackelberg Markov game (BSMG) between the defender and the attacker to address
the lack of adaptability to uncertain adaptive attacks. We further devise an
effective meta-learning technique to solve for the Stackelberg equilibrium,
leading to a resilient and adaptable defense. The experiment results suggest
that our meta-Stackelberg learning approach excels in combating intense model
poisoning and backdoor attacks of indeterminate types.
</p></li>
</ul>

<h3>Title: Pruning for Better Domain Generalizability. (arXiv:2306.13237v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.13237">http://arxiv.org/abs/2306.13237</a></li>
<li>Code URL: <a href="https://github.com/alexsunnik/pruning-for-better-domain-generalizability">https://github.com/alexsunnik/pruning-for-better-domain-generalizability</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2306.13237] Pruning for Better Domain Generalizability](http://arxiv.org/abs/2306.13237) #robust</code></li>
<li>Summary: <p>In this paper, we investigate whether we could use pruning as a reliable
method to boost the generalization ability of the model. We found that existing
pruning method like L2 can already offer small improvement on the target domain
performance. We further propose a novel pruning scoring method, called DSS,
designed not to maintain source accuracy as typical pruning work, but to
directly enhance the robustness of the model. We conduct empirical experiments
to validate our method and demonstrate that it can be even combined with
state-of-the-art generalization work like MIRO(Cha et al., 2022) to further
boost the performance. On MNIST to MNIST-M, we could improve the baseline
performance by over 5 points by introducing 60% channel sparsity into the
model. On DomainBed benchmark and state-of-the-art MIRO, we can further boost
its performance by 1 point only by introducing 10% sparsity into the model.
Code can be found at:
https://github.com/AlexSunNik/Pruning-for-Better-Domain-Generalizability
</p></li>
</ul>

<h3>Title: TrustGuard: GNN-based Robust and Explainable Trust Evaluation with Dynamicity Support. (arXiv:2306.13339v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.13339">http://arxiv.org/abs/2306.13339</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.13339] TrustGuard: GNN-based Robust and Explainable Trust Evaluation with Dynamicity Support](http://arxiv.org/abs/2306.13339) #robust</code></li>
<li>Summary: <p>Trust evaluation assesses trust relationships between entities and
facilitates decision-making. Machine Learning (ML) shows great potential for
trust evaluation owing to its learning capabilities. In recent years, Graph
Neural Networks (GNNs), as a new ML paradigm, have demonstrated superiority in
dealing with graph data. This has motivated researchers to explore their use in
trust evaluation, as trust relationships among entities can be modeled as a
graph. However, current trust evaluation methods that employ GNNs fail to fully
satisfy the dynamicity nature of trust, overlook the adverse effects of attacks
on trust evaluation, and cannot provide convincing explanations on evaluation
results. To address these problems, in this paper, we propose TrustGuard, a
GNN-based accurate trust evaluation model that supports trust dynamicity, is
robust against typical attacks, and provides explanations through
visualization. Specifically, TrustGuard is designed with a layered architecture
that contains a snapshot input layer, a spatial aggregation layer, a temporal
aggregation layer, and a prediction layer. Among them, the spatial aggregation
layer can be plugged into a defense mechanism for a robust aggregation of local
trust relationships, and the temporal aggregation layer applies an attention
mechanism for effective learning of temporal patterns. Extensive experiments on
two real-world datasets show that TrustGuard outperforms state-of-the-art
GNN-based trust evaluation models with respect to trust prediction across
single-timeslot and multi-timeslot, even in the presence of attacks. In
particular, TrustGuard can explain its evaluation results by visualizing both
spatial and temporal views.
</p></li>
</ul>

<h3>Title: Binary domain generalization for sparsifying binary neural networks. (arXiv:2306.13515v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.13515">http://arxiv.org/abs/2306.13515</a></li>
<li>Code URL: <a href="https://github.com/robustml-eurecom/sbnn">https://github.com/robustml-eurecom/sbnn</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2306.13515] Binary domain generalization for sparsifying binary neural networks](http://arxiv.org/abs/2306.13515) #robust</code></li>
<li>Summary: <p>Binary neural networks (BNNs) are an attractive solution for developing and
deploying deep neural network (DNN)-based applications in resource constrained
devices. Despite their success, BNNs still suffer from a fixed and limited
compression factor that may be explained by the fact that existing pruning
methods for full-precision DNNs cannot be directly applied to BNNs. In fact,
weight pruning of BNNs leads to performance degradation, which suggests that
the standard binarization domain of BNNs is not well adapted for the task. This
work proposes a novel more general binary domain that extends the standard
binary one that is more robust to pruning techniques, thus guaranteeing
improved compression and avoiding severe performance losses. We demonstrate a
closed-form solution for quantizing the weights of a full-precision network
into the proposed binary domain. Finally, we show the flexibility of our
method, which can be combined with other pruning strategies. Experiments over
CIFAR-10 and CIFAR-100 demonstrate that the novel approach is able to generate
efficient sparse networks with reduced memory usage and run-time latency, while
maintaining performance.
</p></li>
</ul>

<h3>Title: Adversarial Robustness Certification for Bayesian Neural Networks. (arXiv:2306.13614v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.13614">http://arxiv.org/abs/2306.13614</a></li>
<li>Code URL: <a href="https://github.com/matthewwicker/adversarialrobustnesscertificationforbnns">https://github.com/matthewwicker/adversarialrobustnesscertificationforbnns</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2306.13614] Adversarial Robustness Certification for Bayesian Neural Networks](http://arxiv.org/abs/2306.13614) #robust</code></li>
<li>Summary: <p>We study the problem of certifying the robustness of Bayesian neural networks
(BNNs) to adversarial input perturbations. Given a compact set of input points
$T \subseteq \mathbb{R}^m$ and a set of output points $S \subseteq
\mathbb{R}^n$, we define two notions of robustness for BNNs in an adversarial
setting: probabilistic robustness and decision robustness. Probabilistic
robustness is the probability that for all points in $T$ the output of a BNN
sampled from the posterior is in $S$. On the other hand, decision robustness
considers the optimal decision of a BNN and checks if for all points in $T$ the
optimal decision of the BNN for a given loss function lies within the output
set $S$. Although exact computation of these robustness properties is
challenging due to the probabilistic and non-convex nature of BNNs, we present
a unified computational framework for efficiently and formally bounding them.
Our approach is based on weight interval sampling, integration, and bound
propagation techniques, and can be applied to BNNs with a large number of
parameters, and independently of the (approximate) inference method employed to
train the BNN. We evaluate the effectiveness of our methods on various
regression and classification tasks, including an industrial regression
benchmark, MNIST, traffic sign recognition, and airborne collision avoidance,
and demonstrate that our approach enables certification of robustness and
uncertainty of BNN predictions.
</p></li>
</ul>

<h2>biometric</h2>
<h2>steal</h2>
<h2>extraction</h2>
<h3>Title: Key Frame Extraction with Attention Based Deep Neural Networks. (arXiv:2306.13176v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.13176">http://arxiv.org/abs/2306.13176</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.13176] Key Frame Extraction with Attention Based Deep Neural Networks](http://arxiv.org/abs/2306.13176) #extraction</code></li>
<li>Summary: <p>Automatic keyframe detection from videos is an exercise in selecting scenes
that can best summarize the content for long videos. Providing a summary of the
video is an important task to facilitate quick browsing and content
summarization. The resulting photos are used for automated works (e.g.
summarizing security footage, detecting different scenes used in music clips)
in different industries. In addition, processing high-volume videos in advanced
machine learning methods also creates resource costs. Keyframes obtained; It
can be used as an input feature to the methods and models to be used. In this
study; We propose a deep learning-based approach for keyframe detection using a
deep auto-encoder model with an attention layer. The proposed method first
extracts the features from the video frames using the encoder part of the
autoencoder and applies segmentation using the k-means clustering algorithm to
group these features and similar frames together. Then, keyframes are selected
from each cluster by selecting the frames closest to the center of the
clusters. The method was evaluated on the TVSUM video dataset and achieved a
classification accuracy of 0.77, indicating a higher success rate than many
existing methods. The proposed method offers a promising solution for key frame
extraction in video analysis and can be applied to various applications such as
video summarization and video retrieval.
</p></li>
</ul>

<h3>Title: Mutually Guided Few-shot Learning for Relational Triple Extraction. (arXiv:2306.13310v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.13310">http://arxiv.org/abs/2306.13310</a></li>
<li>Code URL: <a href="https://github.com/ycm094/mg-fte-main">https://github.com/ycm094/mg-fte-main</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2306.13310] Mutually Guided Few-shot Learning for Relational Triple Extraction](http://arxiv.org/abs/2306.13310) #extraction</code></li>
<li>Summary: <p>Knowledge graphs (KGs), containing many entity-relation-entity triples,
provide rich information for downstream applications. Although extracting
triples from unstructured texts has been widely explored, most of them require
a large number of labeled instances. The performance will drop dramatically
when only few labeled data are available. To tackle this problem, we propose
the Mutually Guided Few-shot learning framework for Relational Triple
Extraction (MG-FTE). Specifically, our method consists of an entity-guided
relation proto-decoder to classify the relations firstly and a relation-guided
entity proto-decoder to extract entities based on the classified relations. To
draw the connection between entity and relation, we design a proto-level fusion
module to boost the performance of both entity extraction and relation
classification. Moreover, a new cross-domain few-shot triple extraction task is
introduced. Extensive experiments show that our method outperforms many
state-of-the-art methods by 12.6 F1 score on FewRel 1.0 (single-domain) and
20.5 F1 score on FewRel 2.0 (cross-domain).
</p></li>
</ul>

<h3>Title: Stress Testing BERT Anaphora Resolution Models for Reaction Extraction in Chemical Patents. (arXiv:2306.13379v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.13379">http://arxiv.org/abs/2306.13379</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.13379] Stress Testing BERT Anaphora Resolution Models for Reaction Extraction in Chemical Patents](http://arxiv.org/abs/2306.13379) #extraction</code></li>
<li>Summary: <p>The high volume of published chemical patents and the importance of a timely
acquisition of their information gives rise to automating information
extraction from chemical patents. Anaphora resolution is an important component
of comprehensive information extraction, and is critical for extracting
reactions. In chemical patents, there are five anaphoric relations of interest:
co-reference, transformed, reaction associated, work up, and contained. Our
goal is to investigate how the performance of anaphora resolution models for
reaction texts in chemical patents differs in a noise-free and noisy
environment and to what extent we can improve the robustness against noise of
the model.
</p></li>
</ul>

<h2>membership infer</h2>
<h2>federate</h2>
<h3>Title: Synthetic data shuffling accelerates the convergence of federated learning under data heterogeneity. (arXiv:2306.13263v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.13263">http://arxiv.org/abs/2306.13263</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.13263] Synthetic data shuffling accelerates the convergence of federated learning under data heterogeneity](http://arxiv.org/abs/2306.13263) #federate</code></li>
<li>Summary: <p>In federated learning, data heterogeneity is a critical challenge. A
straightforward solution is to shuffle the clients' data to homogenize the
distribution. However, this may violate data access rights, and how and when
shuffling can accelerate the convergence of a federated optimization algorithm
is not theoretically well understood. In this paper, we establish a precise and
quantifiable correspondence between data heterogeneity and parameters in the
convergence rate when a fraction of data is shuffled across clients. We prove
that shuffling can quadratically reduce the gradient dissimilarity with respect
to the shuffling percentage, accelerating convergence. Inspired by the theory,
we propose a practical approach that addresses the data access rights issue by
shuffling locally generated synthetic data. The experimental results show that
shuffling synthetic data improves the performance of multiple existing
federated learning algorithms by a large margin.
</p></li>
</ul>

<h3>Title: FedSelect: Customized Selection of Parameters for Fine-Tuning during Personalized Federated Learning. (arXiv:2306.13264v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.13264">http://arxiv.org/abs/2306.13264</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.13264] FedSelect: Customized Selection of Parameters for Fine-Tuning during Personalized Federated Learning](http://arxiv.org/abs/2306.13264) #federate</code></li>
<li>Summary: <p>Recent advancements in federated learning (FL) seek to increase client-level
performance by fine-tuning client parameters on local data or personalizing
architectures for the local task. Existing methods for such personalization
either prune a global model or fine-tune a global model on a local client
distribution. However, these existing methods either personalize at the expense
of retaining important global knowledge, or predetermine network layers for
fine-tuning, resulting in suboptimal storage of global knowledge within client
models. Enlightened by the lottery ticket hypothesis, we first introduce a
hypothesis for finding optimal client subnetworks to locally fine-tune while
leaving the rest of the parameters frozen. We then propose a novel FL
framework, FedSelect, using this procedure that directly personalizes both
client subnetwork structure and parameters, via the simultaneous discovery of
optimal parameters for personalization and the rest of parameters for global
aggregation during training. We show that this method achieves promising
results on CIFAR-10.
</p></li>
</ul>

<h2>fair</h2>
<h3>Title: Trading-off price for data quality to achieve fair online allocation. (arXiv:2306.13440v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.13440">http://arxiv.org/abs/2306.13440</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.13440] Trading-off price for data quality to achieve fair online allocation](http://arxiv.org/abs/2306.13440) #fair</code></li>
<li>Summary: <p>We consider the problem of online allocation subject to a long-term fairness
penalty. Contrary to existing works, however, we do not assume that the
decision-maker observes the protected attributes -- which is often unrealistic
in practice. Instead they can purchase data that help estimate them from
sources of different quality; and hence reduce the fairness penalty at some
cost. We model this problem as a multi-armed bandit problem where each arm
corresponds to the choice of a data source, coupled with the online allocation
problem. We propose an algorithm that jointly solves both problems and show
that it has a regret bounded by $\mathcal{O}(\sqrt{T})$. A key difficulty is
that the rewards received by selecting a source are correlated by the fairness
penalty, which leads to a need for randomization (despite a stochastic
setting). Our algorithm takes into account contextual information available
before the source selection, and can adapt to many different fairness notions.
We also show that in some instances, the estimates used can be learned on the
fly.
</p></li>
</ul>

<h2>interpretability</h2>
<h2>explainability</h2>
<h2>watermark</h2>
<h3>Title: ovla: Neural Network Ownership Verification using Latent Watermarks. (arXiv:2306.13215v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.13215">http://arxiv.org/abs/2306.13215</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.13215] ovla: Neural Network Ownership Verification using Latent Watermarks](http://arxiv.org/abs/2306.13215) #watermark</code></li>
<li>Summary: <p>Ownership verification for neural networks is important for protecting these
models from illegal copying, free-riding, re-distribution and other
intellectual property misuse. We present a novel methodology for neural network
ownership verification based on the notion of latent watermarks. Existing
ownership verification methods either modify or introduce constraints to the
neural network parameters, which are accessible to an attacker in a white-box
attack and can be harmful to the network's normal operation, or train the
network to respond to specific watermarks in the inputs similar to data
poisoning-based backdoor attacks, which are susceptible to backdoor removal
techniques. In this paper, we address these problems by decoupling a network's
normal operation from its responses to watermarked inputs during ownership
verification. The key idea is to train the network such that the watermarks
remain dormant unless the owner's secret key is applied to activate it. The
secret key is realized as a specific perturbation only known to the owner to
the network's parameters. We show that our approach offers strong defense
against backdoor detection, backdoor removal and surrogate model attacks.In
addition, our method provides protection against ambiguity attacks where the
attacker either tries to guess the secret weight key or uses fine-tuning to
embed their own watermarks with a different key into a pre-trained neural
network. Experimental results demonstrate the advantages and effectiveness of
our proposed approach.
</p></li>
</ul>

<h2>diffusion</h2>
<h3>Title: Directional diffusion models for graph representation learning. (arXiv:2306.13210v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.13210">http://arxiv.org/abs/2306.13210</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.13210] Directional diffusion models for graph representation learning](http://arxiv.org/abs/2306.13210) #diffusion</code></li>
<li>Summary: <p>In recent years, diffusion models have achieved remarkable success in various
domains of artificial intelligence, such as image synthesis, super-resolution,
and 3D molecule generation. However, the application of diffusion models in
graph learning has received relatively little attention. In this paper, we
address this gap by investigating the use of diffusion models for unsupervised
graph representation learning. We begin by identifying the anisotropic
structures of graphs and a crucial limitation of the vanilla forward diffusion
process in learning anisotropic structures. This process relies on continuously
adding an isotropic Gaussian noise to the data, which may convert the
anisotropic signals to noise too quickly. This rapid conversion hampers the
training of denoising neural networks and impedes the acquisition of
semantically meaningful representations in the reverse process. To address this
challenge, we propose a new class of models called {\it directional diffusion
models}. These models incorporate data-dependent, anisotropic, and directional
noises in the forward diffusion process. To assess the efficacy of our proposed
models, we conduct extensive experiments on 12 publicly available datasets,
focusing on two distinct graph representation learning tasks. The experimental
results demonstrate the superiority of our models over state-of-the-art
baselines, indicating their effectiveness in capturing meaningful graph
representations. Our studies not only provide valuable insights into the
forward process of diffusion models but also highlight the wide-ranging
potential of these models for various graph-related tasks.
</p></li>
</ul>

<h3>Title: DreamEditor: Text-Driven 3D Scene Editing with Neural Fields. (arXiv:2306.13455v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.13455">http://arxiv.org/abs/2306.13455</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.13455] DreamEditor: Text-Driven 3D Scene Editing with Neural Fields](http://arxiv.org/abs/2306.13455) #diffusion</code></li>
<li>Summary: <p>Neural fields have achieved impressive advancements in view synthesis and
scene reconstruction. However, editing these neural fields remains challenging
due to the implicit encoding of geometry and texture information. In this
paper, we propose DreamEditor, a novel framework that enables users to perform
controlled editing of neural fields using text prompts. By representing scenes
as mesh-based neural fields, DreamEditor allows localized editing within
specific regions. DreamEditor utilizes the text encoder of a pretrained
text-to-Image diffusion model to automatically identify the regions to be
edited based on the semantics of the text prompts. Subsequently, DreamEditor
optimizes the editing region and aligns its geometry and texture with the text
prompts through score distillation sampling [29]. Extensive experiments have
demonstrated that DreamEditor can accurately edit neural fields of real-world
scenes according to the given text prompts while ensuring consistency in
irrelevant areas. DreamEditor generates highly realistic textures and geometry,
significantly surpassing previous works in both quantitative and qualitative
evaluations.
</p></li>
</ul>

<h2>noise learning</h2>
<h2>data-free</h2>
<h2>transformer</h2>
<h3>Title: Efficient Online Processing with Deep Neural Networks. (arXiv:2306.13474v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.13474">http://arxiv.org/abs/2306.13474</a></li>
<li>Code URL: <a href="https://github.com/LukasHedegaard/continual-inference">https://github.com/LukasHedegaard/continual-inference</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2306.13474] Efficient Online Processing with Deep Neural Networks](http://arxiv.org/abs/2306.13474) #transformer</code></li>
<li>Summary: <p>The capabilities and adoption of deep neural networks (DNNs) grow at an
exhilarating pace: Vision models accurately classify human actions in videos
and identify cancerous tissue in medical scans as precisely than human experts;
large language models answer wide-ranging questions, generate code, and write
prose, becoming the topic of everyday dinner-table conversations. Even though
their uses are exhilarating, the continually increasing model sizes and
computational complexities have a dark side. The economic cost and negative
environmental externalities of training and serving models is in evident
disharmony with financial viability and climate action goals.
</p></li>
</ul>

<p>Instead of pursuing yet another increase in predictive performance, this
dissertation is dedicated to the improvement of neural network efficiency.
Specifically, a core contribution addresses the efficiency aspects during
online inference. Here, the concept of Continual Inference Networks (CINs) is
proposed and explored across four publications. CINs extend prior
state-of-the-art methods developed for offline processing of spatio-temporal
data and reuse their pre-trained weights, improving their online processing
efficiency by an order of magnitude. These advances are attained through a
bottom-up computational reorganization and judicious architectural
modifications. The benefit to online inference is demonstrated by reformulating
several widely used network architectures into CINs, including 3D CNNs,
ST-GCNs, and Transformer Encoders. An orthogonal contribution tackles the
concurrent adaptation and computational acceleration of a large source model
into multiple lightweight derived models. Drawing on fusible adapter networks
and structured pruning, Structured Pruning Adapters achieve superior predictive
accuracy under aggressive pruning using significantly fewer learned weights
compared to fine-tuning with pruning.
</p>

<h3>Title: ProRes: Exploring Degradation-aware Visual Prompt for Universal Image Restoration. (arXiv:2306.13653v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.13653">http://arxiv.org/abs/2306.13653</a></li>
<li>Code URL: <a href="https://github.com/leonmakise/prores">https://github.com/leonmakise/prores</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2306.13653] ProRes: Exploring Degradation-aware Visual Prompt for Universal Image Restoration](http://arxiv.org/abs/2306.13653) #transformer</code></li>
<li>Summary: <p>Image restoration aims to reconstruct degraded images, e.g., denoising or
deblurring. Existing works focus on designing task-specific methods and there
are inadequate attempts at universal methods. However, simply unifying multiple
tasks into one universal architecture suffers from uncontrollable and undesired
predictions. To address those issues, we explore prompt learning in universal
architectures for image restoration tasks. In this paper, we present
Degradation-aware Visual Prompts, which encode various types of image
degradation, e.g., noise and blur, into unified visual prompts. These
degradation-aware prompts provide control over image processing and allow
weighted combinations for customized image restoration. We then leverage
degradation-aware visual prompts to establish a controllable and universal
model for image restoration, called ProRes, which is applicable to an extensive
range of image restoration tasks. ProRes leverages the vanilla Vision
Transformer (ViT) without any task-specific designs. Furthermore, the
pre-trained ProRes can easily adapt to new tasks through efficient prompt
tuning with only a few images. Without bells and whistles, ProRes achieves
competitive performance compared to task-specific methods and experiments can
demonstrate its ability for controllable restoration and adaptation for new
tasks. The code and models will be released in
\url{https://github.com/leonmakise/ProRes}.
</p></li>
</ul>

<h3>Title: Abstractive Text Summarization for Resumes With Cutting Edge NLP Transformers and LSTM. (arXiv:2306.13315v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.13315">http://arxiv.org/abs/2306.13315</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.13315] Abstractive Text Summarization for Resumes With Cutting Edge NLP Transformers and LSTM](http://arxiv.org/abs/2306.13315) #transformer</code></li>
<li>Summary: <p>Text summarization is a fundamental task in natural language processing that
aims to condense large amounts of textual information into concise and coherent
summaries. With the exponential growth of content and the need to extract key
information efficiently, text summarization has gained significant attention in
recent years. In this study, LSTM and pre-trained T5, Pegasus, BART and
BART-Large model performances were evaluated on the open source dataset (Xsum,
CNN/Daily Mail, Amazon Fine Food Review and News Summary) and the prepared
resume dataset. This resume dataset consists of many information such as
language, education, experience, personal information, skills, and this data
includes 75 resumes. The primary objective of this research was to classify
resume text. Various techniques such as LSTM, pre-trained models, and
fine-tuned models were assessed using a dataset of resumes. The BART-Large
model fine-tuned with the resume dataset gave the best performance.
</p></li>
</ul>

<h3>Title: Long-range Language Modeling with Self-retrieval. (arXiv:2306.13421v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.13421">http://arxiv.org/abs/2306.13421</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.13421] Long-range Language Modeling with Self-retrieval](http://arxiv.org/abs/2306.13421) #transformer</code></li>
<li>Summary: <p>Retrieval-augmented language models (LMs) have received much attention
recently. However, typically the retriever is not trained jointly as a native
component of the LM, but added to an already-pretrained LM, which limits the
ability of the LM and the retriever to adapt to one another. In this work, we
propose the Retrieval-Pretrained Transformer (RPT), an architecture and
training procedure for jointly training a retrieval-augmented LM from scratch
for the task of modeling long texts. Given a recently generated text chunk in a
long document, the LM computes query representations, which are then used to
retrieve earlier chunks in the document, located potentially tens of thousands
of tokens before. Information from retrieved chunks is fused into the LM
representations to predict the next target chunk. We train the retriever
component with a semantic objective, where the goal is to retrieve chunks that
increase the probability of the next chunk, according to a reference LM. We
evaluate RPT on four long-range language modeling tasks, spanning books, code,
and mathematical writing, and demonstrate that RPT improves retrieval quality
and subsequently perplexity across the board compared to strong baselines.
</p></li>
</ul>

<h3>Title: Incorporating Graph Information in Transformer-based AMR Parsing. (arXiv:2306.13467v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.13467">http://arxiv.org/abs/2306.13467</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.13467] Incorporating Graph Information in Transformer-based AMR Parsing](http://arxiv.org/abs/2306.13467) #transformer</code></li>
<li>Summary: <p>Abstract Meaning Representation (AMR) is a Semantic Parsing formalism that
aims at providing a semantic graph abstraction representing a given text.
Current approaches are based on autoregressive language models such as BART or
T5, fine-tuned through Teacher Forcing to obtain a linearized version of the
AMR graph from a sentence. In this paper, we present LeakDistill, a model and
method that explores a modification to the Transformer architecture, using
structural adapters to explicitly incorporate graph information into the
learned representations and improve AMR parsing performance. Our experiments
show how, by employing word-to-node alignment to embed graph structural
information into the encoder at training time, we can obtain state-of-the-art
AMR parsing through self-knowledge distillation, even without the use of
additional data. We release the code at
\url{<a href="http://www.github.com/sapienzanlp/LeakDistill">this http URL</a>}.
</p></li>
</ul>

<h3>Title: Knowledge-Infused Self Attention Transformers. (arXiv:2306.13501v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.13501">http://arxiv.org/abs/2306.13501</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.13501] Knowledge-Infused Self Attention Transformers](http://arxiv.org/abs/2306.13501) #transformer</code></li>
<li>Summary: <p>Transformer-based language models have achieved impressive success in various
natural language processing tasks due to their ability to capture complex
dependencies and contextual information using self-attention mechanisms.
However, they are not without limitations. These limitations include
hallucinations, where they produce incorrect outputs with high confidence, and
alignment issues, where they generate unhelpful and unsafe outputs for human
users. These limitations stem from the absence of implicit and missing context
in the data alone. To address this, researchers have explored augmenting these
models with external knowledge from knowledge graphs to provide the necessary
additional context. However, the ad-hoc nature of existing methods makes it
difficult to properly analyze the effects of knowledge infusion on the many
moving parts or components of a transformer. This paper introduces a systematic
method for infusing knowledge into different components of a transformer-based
model. A modular framework is proposed to identify specific components within
the transformer architecture, such as the self-attention mechanism, encoder
layers, or the input embedding layer, where knowledge infusion can be applied.
Additionally, extensive experiments are conducted on the General Language
Understanding Evaluation (GLUE) benchmark tasks, and the findings are reported.
This systematic approach aims to facilitate more principled approaches to
incorporating knowledge into language model architectures.
</p></li>
</ul>

<h3>Title: Margin Maximization in Attention Mechanism. (arXiv:2306.13596v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.13596">http://arxiv.org/abs/2306.13596</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.13596] Margin Maximization in Attention Mechanism](http://arxiv.org/abs/2306.13596) #transformer</code></li>
<li>Summary: <p>Attention mechanism is a central component of the transformer architecture
which led to the phenomenal success of large language models. However, the
theoretical principles underlying the attention mechanism are poorly
understood, especially its nonconvex optimization dynamics. In this work, we
explore the seminal softmax-attention model $f(\boldsymbol{X})=\langle
\boldsymbol{Xv}, \texttt{softmax}(\boldsymbol{XWp})\rangle$, where,
$\boldsymbol{X}$ is the token sequence and
$(\boldsymbol{v},\boldsymbol{W},\boldsymbol{p})$ are tunable parameters. We
prove that running gradient descent on $\boldsymbol{p}$, or equivalently
$\boldsymbol{W}$, converges in direction to a max-margin solution that
separates $\textit{locally-optimal}$ tokens from non-optimal ones. This clearly
formalizes attention as a token separation mechanism. Remarkably, our results
are applicable to general data and precisely characterize $\textit{optimality}$
of tokens in terms of the value embeddings $\boldsymbol{Xv}$ and problem
geometry. We also provide a broader regularization path analysis that
establishes the margin maximizing nature of attention even for nonlinear
prediction heads. When optimizing $\boldsymbol{v}$ and $\boldsymbol{p}$
simultaneously with logistic loss, we identify conditions under which the
regularization paths directionally converge to their respective hard-margin SVM
solutions where $\boldsymbol{v}$ separates the input features based on their
labels. Interestingly, the SVM formulation of $\boldsymbol{p}$ is influenced by
the support vector geometry of $\boldsymbol{v}$. Finally, we verify our
theoretical findings via numerical experiments and provide insights.
</p></li>
</ul>

<h3>Title: Scaling MLPs: A Tale of Inductive Bias. (arXiv:2306.13575v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.13575">http://arxiv.org/abs/2306.13575</a></li>
<li>Code URL: <a href="https://github.com/gregorbachmann/scaling_mlps">https://github.com/gregorbachmann/scaling_mlps</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2306.13575] Scaling MLPs: A Tale of Inductive Bias](http://arxiv.org/abs/2306.13575) #transformer</code></li>
<li>Summary: <p>In this work we revisit the most fundamental building block in deep learning,
the multi-layer perceptron (MLP), and study the limits of its performance on
vision tasks. Empirical insights into MLPs are important for multiple reasons.
(1) Given the recent narrative "less inductive bias is better", popularized due
to transformers eclipsing convolutional models, it is natural to explore the
limits of this hypothesis. To that end, MLPs offer an ideal test bed, being
completely free of any inductive bias. (2) MLPs have almost exclusively been
the main protagonist in the deep learning theory literature due to their
mathematical simplicity, serving as a proxy to explain empirical phenomena
observed for more complex architectures. Surprisingly, experimental datapoints
for MLPs are very difficult to find in the literature, especially when coupled
with large pre-training protocols. This discrepancy between practice and theory
is worrying: Do MLPs reflect the empirical advances exhibited by practical
models? Or do theorists need to rethink the role of MLPs as a proxy? We provide
insights into both these aspects. We show that the performance of MLPs
drastically improves with scale (93% on CIFAR10, 79% on CIFAR100, 69% on
TinyImageNet), highlighting that lack of inductive bias can indeed be
compensated. We observe that MLPs mimic the behaviour of their modern
counterparts faithfully, with some components in the learning setting however
surprisingly exhibiting stronger or unexpected behaviours. Due to their
inherent computational efficiency, large pre-training experiments become more
accessible for academic researchers. All of our experiments were run on a
single GPU.
</p></li>
</ul>

<h2>generative</h2>
<h3>Title: PP-GAN : Style Transfer from Korean Portraits to ID Photos Using Landmark Extractor with GAN. (arXiv:2306.13418v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.13418">http://arxiv.org/abs/2306.13418</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.13418] PP-GAN : Style Transfer from Korean Portraits to ID Photos Using Landmark Extractor with GAN](http://arxiv.org/abs/2306.13418) #generative</code></li>
<li>Summary: <p>The objective of a style transfer is to maintain the content of an image
while transferring the style of another image. However, conventional research
on style transfer has a significant limitation in preserving facial landmarks,
such as the eyes, nose, and mouth, which are crucial for maintaining the
identity of the image. In Korean portraits, the majority of individuals wear
"Gat", a type of headdress exclusively worn by men. Owing to its distinct
characteristics from the hair in ID photos, transferring the "Gat" is
challenging. To address this issue, this study proposes a deep learning network
that can perform style transfer, including the "Gat", while preserving the
identity of the face. Unlike existing style transfer approaches, the proposed
method aims to preserve texture, costume, and the "Gat" on the style image. The
Generative Adversarial Network forms the backbone of the proposed network. The
color, texture, and intensity were extracted differently based on the
characteristics of each block and layer of the pre-trained VGG-16, and only the
necessary elements during training were preserved using a facial landmark mask.
The head area was presented using the eyebrow area to transfer the "Gat".
Furthermore, the identity of the face was retained, and style correlation was
considered based on the Gram matrix. The proposed approach demonstrated
superior transfer and preservation performance compared to previous studies.
</p></li>
</ul>

<h3>Title: Penalty Gradient Normalization for Generative Adversarial Networks. (arXiv:2306.13576v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.13576">http://arxiv.org/abs/2306.13576</a></li>
<li>Code URL: <a href="https://github.com/sumorday/edgan-pytorch">https://github.com/sumorday/edgan-pytorch</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2306.13576] Penalty Gradient Normalization for Generative Adversarial Networks](http://arxiv.org/abs/2306.13576) #generative</code></li>
<li>Summary: <p>In this paper, we propose a novel normalization method called penalty
gradient normalization (PGN) to tackle the training instability of Generative
Adversarial Networks (GANs) caused by the sharp gradient space. Unlike existing
work such as gradient penalty and spectral normalization, the proposed PGN only
imposes a penalty gradient norm constraint on the discriminator function, which
increases the capacity of the discriminator. Moreover, the proposed penalty
gradient normalization can be applied to different GAN architectures with
little modification. Extensive experiments on three datasets show that GANs
trained with penalty gradient normalization outperform existing methods in
terms of both Frechet Inception and Distance and Inception Score.
</p></li>
</ul>

<h3>Title: Machine Learning methods for simulating particle response in the Zero Degree Calorimeter at the ALICE experiment, CERN. (arXiv:2306.13606v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.13606">http://arxiv.org/abs/2306.13606</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.13606] Machine Learning methods for simulating particle response in the Zero Degree Calorimeter at the ALICE experiment, CERN](http://arxiv.org/abs/2306.13606) #generative</code></li>
<li>Summary: <p>Currently, over half of the computing power at CERN GRID is used to run High
Energy Physics simulations. The recent updates at the Large Hadron Collider
(LHC) create the need for developing more efficient simulation methods. In
particular, there exists a demand for a fast simulation of the neutron Zero
Degree Calorimeter, where existing Monte Carlo-based methods impose a
significant computational burden. We propose an alternative approach to the
problem that leverages machine learning. Our solution utilises neural network
classifiers and generative models to directly simulate the response of the
calorimeter. In particular, we examine the performance of variational
autoencoders and generative adversarial networks, expanding the GAN
architecture by an additional regularisation network and a simple, yet
effective postprocessing step. Our approach increases the simulation speed by 2
orders of magnitude while maintaining the high fidelity of the simulation.
</p></li>
</ul>

<h3>Title: GKD: Generalized Knowledge Distillation for Auto-regressive Sequence Models. (arXiv:2306.13649v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.13649">http://arxiv.org/abs/2306.13649</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.13649] GKD: Generalized Knowledge Distillation for Auto-regressive Sequence Models](http://arxiv.org/abs/2306.13649) #generative</code></li>
<li>Summary: <p>Knowledge distillation is commonly used for compressing neural networks to
reduce their inference cost and memory footprint. However, current distillation
methods for auto-regressive models, such as generative language models (LMs),
suffer from two key issues: (1) distribution mismatch between output sequences
during training and the sequences generated by the student during its
deployment, and (2) model under-specification, where the student model may not
be expressive enough to fit the teacher's distribution. To address these
issues, we propose Generalized Knowledge Distillation (GKD). GKD mitigates
distribution mismatch by sampling output sequences from the student during
training. Furthermore, GKD handles model under-specification by optimizing
alternative divergences, such as reverse KL, that focus on generating samples
from the student that are likely under the teacher's distribution. We
demonstrate that GKD outperforms commonly-used approaches for distilling LLMs
on summarization, machine translation, and arithmetic reasoning tasks.
</p></li>
</ul>

<h3>Title: On the Convergence Rate of Gaussianization with Random Rotations. (arXiv:2306.13520v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.13520">http://arxiv.org/abs/2306.13520</a></li>
<li>Code URL: <a href="https://github.com/vislearn/gaussianization-bound">https://github.com/vislearn/gaussianization-bound</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2306.13520] On the Convergence Rate of Gaussianization with Random Rotations](http://arxiv.org/abs/2306.13520) #generative</code></li>
<li>Summary: <p>Gaussianization is a simple generative model that can be trained without
backpropagation. It has shown compelling performance on low dimensional data.
As the dimension increases, however, it has been observed that the convergence
speed slows down. We show analytically that the number of required layers
scales linearly with the dimension for Gaussian input. We argue that this is
because the model is unable to capture dependencies between dimensions.
Empirically, we find the same linear increase in cost for arbitrary input
$p(x)$, but observe favorable scaling for some distributions. We explore
potential speed-ups and formulate challenges for further research.
</p></li>
</ul>

<h3>Title: Manifold Contrastive Learning with Variational Lie Group Operators. (arXiv:2306.13544v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.13544">http://arxiv.org/abs/2306.13544</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.13544] Manifold Contrastive Learning with Variational Lie Group Operators](http://arxiv.org/abs/2306.13544) #generative</code></li>
<li>Summary: <p>Self-supervised learning of deep neural networks has become a prevalent
paradigm for learning representations that transfer to a variety of downstream
tasks. Similar to proposed models of the ventral stream of biological vision,
it is observed that these networks lead to a separation of category manifolds
in the representations of the penultimate layer. Although this observation
matches the manifold hypothesis of representation learning, current
self-supervised approaches are limited in their ability to explicitly model
this manifold. Indeed, current approaches often only apply augmentations from a
pre-specified set of "positive pairs" during learning. In this work, we propose
a contrastive learning approach that directly models the latent manifold using
Lie group operators parameterized by coefficients with a sparsity-promoting
prior. A variational distribution over these coefficients provides a generative
model of the manifold, with samples which provide feature augmentations
applicable both during contrastive training and downstream tasks. Additionally,
learned coefficient distributions provide a quantification of which
transformations are most likely at each point on the manifold while preserving
identity. We demonstrate benefits in self-supervised benchmarks for image
datasets, as well as a downstream semi-supervised task. In the former case, we
demonstrate that the proposed methods can effectively apply manifold feature
augmentations and improve learning both with and without a projection head. In
the latter case, we demonstrate that feature augmentations sampled from learned
Lie group operators can improve classification performance when using few
labels.
</p></li>
</ul>

<h2>large language model</h2>
<h3>Title: MME: A Comprehensive Evaluation Benchmark for Multimodal Large Language Models. (arXiv:2306.13394v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.13394">http://arxiv.org/abs/2306.13394</a></li>
<li>Code URL: <a href="https://github.com/bradyfu/awesome-multimodal-large-language-models">https://github.com/bradyfu/awesome-multimodal-large-language-models</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2306.13394] MME: A Comprehensive Evaluation Benchmark for Multimodal Large Language Models](http://arxiv.org/abs/2306.13394) #large language model</code></li>
<li>Summary: <p>Multimodal Large Language Model (MLLM) relies on the powerful LLM to perform
multimodal tasks, showing amazing emergent abilities in recent studies, such as
writing poems based on an image. However, it is difficult for these case
studies to fully reflect the performance of MLLM, lacking a comprehensive
evaluation. In this paper, we fill in this blank, presenting the first MLLM
Evaluation benchmark MME. It measures both perception and cognition abilities
on a total of 14 subtasks. In order to avoid data leakage that may arise from
direct use of public datasets for evaluation, the annotations of
instruction-answer pairs are all manually designed. The concise instruction
design allows us to fairly compare MLLMs, instead of struggling in prompt
engineering. Besides, with such an instruction, we can also easily carry out
quantitative statistics. A total of 10 advanced MLLMs are comprehensively
evaluated on our MME, which not only suggests that existing MLLMs still have a
large room for improvement, but also reveals the potential directions for the
subsequent model optimization.
</p></li>
</ul>

<h3>Title: A Survey on Multimodal Large Language Models. (arXiv:2306.13549v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.13549">http://arxiv.org/abs/2306.13549</a></li>
<li>Code URL: <a href="https://github.com/bradyfu/awesome-multimodal-large-language-models">https://github.com/bradyfu/awesome-multimodal-large-language-models</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2306.13549] A Survey on Multimodal Large Language Models](http://arxiv.org/abs/2306.13549) #large language model</code></li>
<li>Summary: <p>Multimodal Large Language Model (MLLM) recently has been a new rising
research hotspot, which uses powerful Large Language Models (LLMs) as a brain
to perform multimodal tasks. The surprising emergent capabilities of MLLM, such
as writing stories based on images and OCR-free math reasoning, are rare in
traditional methods, suggesting a potential path to artificial general
intelligence. In this paper, we aim to trace and summarize the recent progress
of MLLM. First of all, we present the formulation of MLLM and delineate its
related concepts. Then, we discuss the key techniques and applications,
including Multimodal Instruction Tuning (M-IT), Multimodal In-Context Learning
(M-ICL), Multimodal Chain of Thought (M-CoT), and LLM-Aided Visual Reasoning
(LAVR). Finally, we discuss existing challenges and point out promising
research directions. In light of the fact that the era of MLLM has only just
begun, we will keep updating this survey and hope it can inspire more research.
An associated GitHub link collecting the latest papers is available at
https://github.com/BradyFU/Awesome-Multimodal-Large-Language-Models.
</p></li>
</ul>

<h3>Title: Visual Adversarial Examples Jailbreak Large Language Models. (arXiv:2306.13213v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.13213">http://arxiv.org/abs/2306.13213</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.13213] Visual Adversarial Examples Jailbreak Large Language Models](http://arxiv.org/abs/2306.13213) #large language model</code></li>
<li>Summary: <p>Recently, there has been a surge of interest in introducing vision into Large
Language Models (LLMs). The proliferation of large Visual Language Models
(VLMs), such as Flamingo, BLIP-2, and GPT-4, signifies an exciting convergence
of advancements in both visual and language foundation models. Yet, the risks
associated with this integrative approach are largely unexamined. In this
paper, we shed light on the security and safety implications of this trend.
First, we underscore that the continuous and high-dimensional nature of the
additional visual input space intrinsically makes it a fertile ground for
adversarial attacks. This unavoidably expands the attack surfaces of LLMs.
Second, we highlight that the broad functionality of LLMs also presents visual
attackers with a wider array of achievable adversarial objectives, extending
the implications of security failures beyond mere misclassification. To
elucidate these risks, we study adversarial examples in the visual input space
of a VLM. Specifically, against MiniGPT-4, which incorporates safety mechanisms
that can refuse harmful instructions, we present visual adversarial examples
that can circumvent the safety mechanisms and provoke harmful behaviors of the
model. Remarkably, we discover that adversarial examples, even if optimized on
a narrow, manually curated derogatory corpus against specific social groups,
can universally jailbreak the model's safety mechanisms. A single such
adversarial example can generally undermine MiniGPT-4's safety, enabling it to
heed a wide range of harmful instructions and produce harmful content far
beyond simply imitating the derogatory corpus used in optimization. Unveiling
these risks, we accentuate the urgent need for comprehensive risk assessments,
robust defense strategies, and the implementation of responsible practices for
the secure and safe utilization of VLMs.
</p></li>
</ul>

<h3>Title: DiversiGATE: A Comprehensive Framework for Reliable Large Language Models. (arXiv:2306.13230v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.13230">http://arxiv.org/abs/2306.13230</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.13230] DiversiGATE: A Comprehensive Framework for Reliable Large Language Models](http://arxiv.org/abs/2306.13230) #large language model</code></li>
<li>Summary: <p>In this paper, we introduce DiversiGATE, a unified framework that
consolidates diverse methodologies for LLM verification. The proposed framework
comprises two main components: Diversification and Aggregation which provide a
holistic perspective on existing verification approaches, such as
Self-Consistency, Math Prompter and WebGPT. Furthermore, we propose a novel
`SelfLearner' model that conforms to the DiversiGATE framework which can learn
from its own outputs and refine its performance over time, leading to improved
accuracy. To evaluate the effectiveness of SelfLearner, we conducted a rigorous
series of experiments, including tests on synthetic data as well as on popular
arithmetic reasoning benchmarks such as GSM8K. Our results demonstrate that our
approach outperforms traditional LLMs, achieving a considerable 54.8% -> 61.8%
improvement on the GSM8K benchmark.
</p></li>
</ul>

<h3>Title: ToolQA: A Dataset for LLM Question Answering with External Tools. (arXiv:2306.13304v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.13304">http://arxiv.org/abs/2306.13304</a></li>
<li>Code URL: <a href="https://github.com/night-chen/toolqa">https://github.com/night-chen/toolqa</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2306.13304] ToolQA: A Dataset for LLM Question Answering with External Tools](http://arxiv.org/abs/2306.13304) #large language model</code></li>
<li>Summary: <p>Large Language Models (LLMs) have demonstrated impressive performance in
various NLP tasks, but they still suffer from challenges such as hallucination
and weak numerical reasoning. To overcome these challenges, external tools can
be used to enhance LLMs' question-answering abilities. However, current
evaluation methods do not distinguish between questions that can be answered
using LLMs' internal knowledge and those that require external information
through tool use. To address this issue, we introduce a new dataset called
ToolQA, which is designed to faithfully evaluate LLMs' ability to use external
tools for question answering. Our development of ToolQA involved a scalable,
automated process for dataset curation, along with 13 specialized tools
designed for interaction with external knowledge in order to answer questions.
Importantly, we strive to minimize the overlap between our benchmark data and
LLMs' pre-training data, enabling a more precise evaluation of LLMs' tool-use
reasoning abilities. We conducted an in-depth diagnosis of existing tool-use
LLMs to highlight their strengths, weaknesses, and potential improvements. Our
findings set a new benchmark for evaluating LLMs and suggest new directions for
future advancements. Our data and code are freely available to the broader
scientific community on GitHub.
</p></li>
</ul>

<h3>Title: Bring Your Own Data! Self-Supervised Evaluation for Large Language Models. (arXiv:2306.13651v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.13651">http://arxiv.org/abs/2306.13651</a></li>
<li>Code URL: <a href="https://github.com/neelsjain/byod">https://github.com/neelsjain/byod</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2306.13651] Bring Your Own Data! Self-Supervised Evaluation for Large Language Models](http://arxiv.org/abs/2306.13651) #large language model</code></li>
<li>Summary: <p>With the rise of Large Language Models (LLMs) and their ubiquitous deployment
in diverse domains, measuring language model behavior on realistic data is
imperative. For example, a company deploying a client-facing chatbot must
ensure that the model will not respond to client requests with profanity.
Current evaluations approach this problem using small, domain-specific datasets
with human-curated labels. These evaluation sets are often sampled from a
narrow and simplified distribution, and data sources can unknowingly be leaked
into the training set which can lead to misleading evaluations. To bypass these
drawbacks, we propose a framework for self-supervised evaluation of LLMs by
analyzing their sensitivity or invariance to transformations on the input text.
Self-supervised evaluation can directly monitor LLM behavior on datasets
collected in the wild or streamed during live model deployment. We demonstrate
self-supervised evaluation strategies for measuring closed-book knowledge,
toxicity, and long-range context dependence, in addition to sensitivity to
grammatical structure and tokenization errors. When comparisons to similar
human-labeled benchmarks are available, we find strong correlations between
self-supervised and human-supervised evaluations. The self-supervised paradigm
complements current evaluation strategies that rely on labeled data.
</p></li>
</ul>

<h2>segmentation</h2>
<h3>Title: A Sparse Graph Formulation for Efficient Spectral Image Segmentation. (arXiv:2306.13166v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.13166">http://arxiv.org/abs/2306.13166</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.13166] A Sparse Graph Formulation for Efficient Spectral Image Segmentation](http://arxiv.org/abs/2306.13166) #segmentation</code></li>
<li>Summary: <p>Spectral Clustering is one of the most traditional methods to solve
segmentation problems. Based on Normalized Cuts, it aims at partitioning an
image using an objective function defined by a graph. Despite their
mathematical attractiveness, spectral approaches are traditionally neglected by
the scientific community due to their practical issues and underperformance. In
this paper, we adopt a sparse graph formulation based on the inclusion of extra
nodes to a simple grid graph. While the grid encodes the pixel spatial
disposition, the extra nodes account for the pixel color data. Applying the
original Normalized Cuts algorithm to this graph leads to a simple and scalable
method for spectral image segmentation, with an interpretable solution. Our
experiments also demonstrate that our proposed methodology over performs
traditional spectral algorithms for segmentation.
</p></li>
</ul>

<h3>Title: Neural Network Pruning for Real-time Polyp Segmentation. (arXiv:2306.13203v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.13203">http://arxiv.org/abs/2306.13203</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.13203] Neural Network Pruning for Real-time Polyp Segmentation](http://arxiv.org/abs/2306.13203) #segmentation</code></li>
<li>Summary: <p>Computer-assisted treatment has emerged as a viable application of medical
imaging, owing to the efficacy of deep learning models. Real-time inference
speed remains a key requirement for such applications to help medical
personnel. Even though there generally exists a trade-off between performance
and model size, impressive efforts have been made to retain near-original
performance by compromising model size. Neural network pruning has emerged as
an exciting area that aims to eliminate redundant parameters to make the
inference faster. In this study, we show an application of neural network
pruning in polyp segmentation. We compute the importance score of convolutional
filters and remove the filters having the least scores, which to some value of
pruning does not degrade the performance. For computing the importance score,
we use the Taylor First Order (TaylorFO) approximation of the change in network
output for the removal of certain filters. Specifically, we employ a
gradient-normalized backpropagation for the computation of the importance
score. Through experiments in the polyp datasets, we validate that our approach
can significantly reduce the parameter count and FLOPs retaining similar
performance.
</p></li>
</ul>

<h3>Title: Patch-Level Contrasting without Patch Correspondence for Accurate and Dense Contrastive Representation Learning. (arXiv:2306.13337v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.13337">http://arxiv.org/abs/2306.13337</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.13337] Patch-Level Contrasting without Patch Correspondence for Accurate and Dense Contrastive Representation Learning](http://arxiv.org/abs/2306.13337) #segmentation</code></li>
<li>Summary: <p>We propose ADCLR: A ccurate and D ense Contrastive Representation Learning, a
novel self-supervised learning framework for learning accurate and dense vision
representation. To extract spatial-sensitive information, ADCLR introduces
query patches for contrasting in addition with global contrasting. Compared
with previous dense contrasting methods, ADCLR mainly enjoys three merits: i)
achieving both global-discriminative and spatial-sensitive representation, ii)
model-efficient (no extra parameters in addition to the global contrasting
baseline), and iii) correspondence-free and thus simpler to implement. Our
approach achieves new state-of-the-art performance for contrastive methods. On
classification tasks, for ViT-S, ADCLR achieves 77.5% top-1 accuracy on
ImageNet with linear probing, outperforming our baseline (DINO) without our
devised techniques as plug-in, by 0.5%. For ViT-B, ADCLR achieves 79.8%, 84.0%
accuracy on ImageNet by linear probing and finetune, outperforming iBOT by
0.3%, 0.2% accuracy. For dense tasks, on MS-COCO, ADCLR achieves significant
improvements of 44.3% AP on object detection, 39.7% AP on instance
segmentation, outperforming previous SOTA method SelfPatch by 2.2% and 1.2%,
respectively. On ADE20K, ADCLR outperforms SelfPatch by 1.0% mIoU, 1.2% mAcc on
the segme
</p></li>
</ul>

<h3>Title: 3DSAM-adapter: Holistic Adaptation of SAM from 2D to 3D for Promptable Medical Image Segmentation. (arXiv:2306.13465v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.13465">http://arxiv.org/abs/2306.13465</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.13465] 3DSAM-adapter: Holistic Adaptation of SAM from 2D to 3D for Promptable Medical Image Segmentation](http://arxiv.org/abs/2306.13465) #segmentation</code></li>
<li>Summary: <p>Despite that the segment anything model (SAM) achieved impressive results on
general-purpose semantic segmentation with strong generalization ability on
daily images, its demonstrated performance on medical image segmentation is
less precise and not stable, especially when dealing with tumor segmentation
tasks that involve objects of small sizes, irregular shapes, and low contrast.
Notably, the original SAM architecture is designed for 2D natural images,
therefore would not be able to extract the 3D spatial information from
volumetric medical data effectively. In this paper, we propose a novel
adaptation method for transferring SAM from 2D to 3D for promptable medical
image segmentation. Through a holistically designed scheme for architecture
modification, we transfer the SAM to support volumetric inputs while retaining
the majority of its pre-trained parameters for reuse. The fine-tuning process
is conducted in a parameter-efficient manner, wherein most of the pre-trained
parameters remain frozen, and only a few lightweight spatial adapters are
introduced and tuned. Regardless of the domain gap between natural and medical
data and the disparity in the spatial arrangement between 2D and 3D, the
transformer trained on natural images can effectively capture the spatial
patterns present in volumetric medical images with only lightweight
adaptations. We conduct experiments on four open-source tumor segmentation
datasets, and with a single click prompt, our model can outperform domain
state-of-the-art medical image segmentation models on 3 out of 4 tasks,
specifically by 8.25%, 29.87%, and 10.11% for kidney tumor, pancreas tumor,
colon cancer segmentation, and achieve similar performance for liver tumor
segmentation. We also compare our adaptation method with existing popular
adapters, and observed significant performance improvement on most datasets.
</p></li>
</ul>

<h3>Title: Segmentation and Tracking of Vegetable Plants by Exploiting Vegetable Shape Feature for Precision Spray of Agricultural Robots. (arXiv:2306.13518v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.13518">http://arxiv.org/abs/2306.13518</a></li>
<li>Code URL: <a href="https://github.com/nanh5837/lettucemots">https://github.com/nanh5837/lettucemots</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2306.13518] Segmentation and Tracking of Vegetable Plants by Exploiting Vegetable Shape Feature for Precision Spray of Agricultural Robots](http://arxiv.org/abs/2306.13518) #segmentation</code></li>
<li>Summary: <p>With the increasing deployment of agricultural robots, the traditional manual
spray of liquid fertilizer and pesticide is gradually being replaced by
agricultural robots. For robotic precision spray application in vegetable
farms, accurate plant phenotyping through instance segmentation and robust
plant tracking are of great importance and a prerequisite for the following
spray action. Regarding the robust tracking of vegetable plants, to solve the
challenging problem of associating vegetables with similar color and texture in
consecutive images, in this paper, a novel method of Multiple Object Tracking
and Segmentation (MOTS) is proposed for instance segmentation and tracking of
multiple vegetable plants. In our approach, contour and blob features are
extracted to describe unique feature of each individual vegetable, and
associate the same vegetables in different images. By assigning a unique ID for
each vegetable, it ensures the robot to spray each vegetable exactly once,
while traversing along the farm rows. Comprehensive experiments including
ablation studies are conducted, which prove its superior performance over two
State-Of-The-Art (SOTA) MOTS methods. Compared to the conventional MOTS
methods, the proposed method is able to re-identify objects which have gone out
of the camera field of view and re-appear again using the proposed data
association strategy, which is important to ensure each vegetable be sprayed
only once when the robot travels back and forth. Although the method is tested
on lettuce farm, it can be applied to other similar vegetables such as broccoli
and canola. Both code and the dataset of this paper is publicly released for
the benefit of the community: https://github.com/NanH5837/LettuceMOTS.
</p></li>
</ul>

<h3>Title: OpenMask3D: Open-Vocabulary 3D Instance Segmentation. (arXiv:2306.13631v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.13631">http://arxiv.org/abs/2306.13631</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.13631] OpenMask3D: Open-Vocabulary 3D Instance Segmentation](http://arxiv.org/abs/2306.13631) #segmentation</code></li>
<li>Summary: <p>We introduce the task of open-vocabulary 3D instance segmentation.
Traditional approaches for 3D instance segmentation largely rely on existing 3D
annotated datasets, which are restricted to a closed-set of object categories.
This is an important limitation for real-life applications where one might need
to perform tasks guided by novel, open-vocabulary queries related to objects
from a wide variety. Recently, open-vocabulary 3D scene understanding methods
have emerged to address this problem by learning queryable features per each
point in the scene. While such a representation can be directly employed to
perform semantic segmentation, existing methods have limitations in their
ability to identify object instances. In this work, we address this limitation,
and propose OpenMask3D, which is a zero-shot approach for open-vocabulary 3D
instance segmentation. Guided by predicted class-agnostic 3D instance masks,
our model aggregates per-mask features via multi-view fusion of CLIP-based
image embeddings. We conduct experiments and ablation studies on the ScanNet200
dataset to evaluate the performance of OpenMask3D, and provide insights about
the open-vocabulary 3D instance segmentation task. We show that our approach
outperforms other open-vocabulary counterparts, particularly on the long-tail
distribution. Furthermore, OpenMask3D goes beyond the limitations of
close-vocabulary approaches, and enables the segmentation of object instances
based on free-form queries describing object properties such as semantics,
geometry, affordances, and material properties.
</p></li>
</ul>

<button id="copy">Copy All</button>
</article>
<script src="https://cdn.staticfile.org/clipboard.js/2.0.4/clipboard.min.js"></script>
<script src="../../javascript/clipboard.js"></script>
