<link rel="stylesheet" href="../../css/markdown.css" />
<article class="markdown-body">
<h1>2025-08-22</h1>
<h3>Title: Efficient Switchable Safety Control in LLMs via Magic-Token-Guided Co-Training</h3>
<ul>
<li><strong>Authors: </strong>Jianfeng Si, Lin Sun, Zhewen Tan, Xiangzheng Zhang</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.14904">https://arxiv.org/abs/2508.14904</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.14904">https://arxiv.org/pdf/2508.14904</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.14904]] Efficient Switchable Safety Control in LLMs via Magic-Token-Guided Co-Training(https://arxiv.org/abs/2508.14904)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, steal, large language model</a></li>
<li><strong>Abstract: </strong>Current methods for content safety in Large Language Models (LLMs), such as Supervised Fine-Tuning (SFT) and Reinforcement Learning from Human Feedback (RLHF), often rely on multi-stage training pipelines and lack fine-grained, post-deployment controllability. To address these limitations, we propose a unified co-training framework that efficiently integrates multiple safety behaviors: positive (lawful/prosocial), negative (unfiltered/risk-prone) and rejective (refusal-oriented/conservative) within a single SFT stage. Notably, each behavior is dynamically activated via a simple system-level instruction, or magic token, enabling stealthy and efficient behavioral switching at inference time. This flexibility supports diverse deployment scenarios, such as positive for safe user interaction, negative for internal red-teaming, and rejective for context-aware refusals triggered by upstream moderation signals. This co-training strategy induces a distinct Safety Alignment Margin in the output space, characterized by well-separated response distributions corresponding to each safety mode. The existence of this margin provides empirical evidence for the model's safety robustness and enables unprecedented fine-grained control. Experiments show that our method matches the safety alignment quality of SFT+DPO, with our 8B model notably surpassing DeepSeek-R1 (671B) in safety performance, while significantly reducing both training complexity and deployment costs. This work presents a scalable, efficient, and highly controllable solution for LLM content safety.</li>
</ul>

<h3>Title: Bridging the Culture Gap: A Framework for LLM-Driven Socio-Cultural Localization of Math Word Problems in Low-Resource Languages</h3>
<ul>
<li><strong>Authors: </strong>Israel Abebe Azime, Tadesse Destaw Belay, Dietrich Klakow, Philipp Slusallek, Anshuman Chhabra</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.14913">https://arxiv.org/abs/2508.14913</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.14913">https://arxiv.org/pdf/2508.14913</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.14913]] Bridging the Culture Gap: A Framework for LLM-Driven Socio-Cultural Localization of Math Word Problems in Low-Resource Languages(https://arxiv.org/abs/2508.14913)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, large language model</a></li>
<li><strong>Abstract: </strong>Large language models (LLMs) have demonstrated significant capabilities in solving mathematical problems expressed in natural language. However, multilingual and culturally-grounded mathematical reasoning in low-resource languages lags behind English due to the scarcity of socio-cultural task datasets that reflect accurate native entities such as person names, organization names, and currencies. Existing multilingual benchmarks are predominantly produced via translation and typically retain English-centric entities, owing to the high cost associated with human annotater-based localization. Moreover, automated localization tools are limited, and hence, truly localized datasets remain scarce. To bridge this gap, we introduce a framework for LLM-driven cultural localization of math word problems that automatically constructs datasets with native names, organizations, and currencies from existing sources. We find that translated benchmarks can obscure true multilingual math ability under appropriate socio-cultural contexts. Through extensive experiments, we also show that our framework can help mitigate English-centric entity bias and improves robustness when native entities are introduced across various languages.</li>
</ul>

<h3>Title: MCPTox: A Benchmark for Tool Poisoning Attack on Real-World MCP Servers</h3>
<ul>
<li><strong>Authors: </strong>Zhiqiang Wang, Yichao Gao, Yanting Wang, Suyuan Liu, Haifeng Sun, Haoran Cheng, Guanquan Shi, Haohua Du, Xiangyang Li</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.14925">https://arxiv.org/abs/2508.14925</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.14925">https://arxiv.org/pdf/2508.14925</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.14925]] MCPTox: A Benchmark for Tool Poisoning Attack on Real-World MCP Servers(https://arxiv.org/abs/2508.14925)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack, robust</a></li>
<li><strong>Abstract: </strong>By providing a standardized interface for LLM agents to interact with external tools, the Model Context Protocol (MCP) is quickly becoming a cornerstone of the modern autonomous agent ecosystem. However, it creates novel attack surfaces due to untrusted external tools. While prior work has focused on attacks injected through external tool outputs, we investigate a more fundamental vulnerability: Tool Poisoning, where malicious instructions are embedded within a tool's metadata without execution. To date, this threat has been primarily demonstrated through isolated cases, lacking a systematic, large-scale evaluation. We introduce MCPTox, the first benchmark to systematically evaluate agent robustness against Tool Poisoning in realistic MCP settings. MCPTox is constructed upon 45 live, real-world MCP servers and 353 authentic tools. To achieve this, we design three distinct attack templates to generate a comprehensive suite of 1312 malicious test cases by few-shot learning, covering 10 categories of potential risks. Our evaluation on 20 prominent LLM agents setting reveals a widespread vulnerability to Tool Poisoning, with o1-mini, achieving an attack success rate of 72.8\%. We find that more capable models are often more susceptible, as the attack exploits their superior instruction-following abilities. Finally, the failure case analysis reveals that agents rarely refuse these attacks, with the highest refused rate (Claude-3.7-Sonnet) less than 3\%, demonstrating that existing safety alignment is ineffective against malicious actions that use legitimate tools for unauthorized operation. Our findings create a crucial empirical baseline for understanding and mitigating this widespread threat, and we release MCPTox for the development of verifiably safer AI agents. Our dataset is available at an anonymized repository: \textit{this https URL}.</li>
</ul>

<h3>Title: Learning to Drive Ethically: Embedding Moral Reasoning into Autonomous Driving</h3>
<ul>
<li><strong>Authors: </strong>Dianzhao Li, Ostap Okhrin</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.RO</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.14926">https://arxiv.org/abs/2508.14926</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.14926">https://arxiv.org/pdf/2508.14926</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.14926]] Learning to Drive Ethically: Embedding Moral Reasoning into Autonomous Driving(https://arxiv.org/abs/2508.14926)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Autonomous vehicles hold great promise for reducing traffic fatalities and improving transportation efficiency, yet their widespread adoption hinges on embedding robust ethical reasoning into routine and emergency maneuvers. Here, we present a hierarchical Safe Reinforcement Learning (Safe RL) framework that explicitly integrates moral considerations with standard driving objectives. At the decision level, a Safe RL agent is trained using a composite ethical risk cost, combining collision probability and harm severity, to generate high-level motion targets. A dynamic Prioritized Experience Replay mechanism amplifies learning from rare but critical, high-risk events. At the execution level, polynomial path planning coupled with Proportional-Integral-Derivative (PID) and Stanley controllers translates these targets into smooth, feasible trajectories, ensuring both accuracy and comfort. We train and validate our approach on rich, real-world traffic datasets encompassing diverse vehicles, cyclists, and pedestrians, and demonstrate that it outperforms baseline methods in reducing ethical risk and maintaining driving performance. To our knowledge, this is the first study of ethical decision-making for autonomous vehicles via Safe RL in real-world scenarios. Our results highlight the potential of combining formal control theory and data-driven learning to advance ethically accountable autonomy in complex, human-mixed traffic environments.</li>
</ul>

<h3>Title: Cohort-Aware Agents for Individualized Lung Cancer Risk Prediction Using a Retrieval-Augmented Model Selection Framework</h3>
<ul>
<li><strong>Authors: </strong>Chongyu Qu, Allen J. Luna, Thomas Z. Li, Junchao Zhu, Junlin Guo, Juming Xiong, Kim L. Sandler, Bennett A. Landman, Yuankai Huo</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.14940">https://arxiv.org/abs/2508.14940</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.14940">https://arxiv.org/pdf/2508.14940</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.14940]] Cohort-Aware Agents for Individualized Lung Cancer Risk Prediction Using a Retrieval-Augmented Model Selection Framework(https://arxiv.org/abs/2508.14940)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Accurate lung cancer risk prediction remains challenging due to substantial variability across patient populations and clinical settings -- no single model performs best for all cohorts. To address this, we propose a personalized lung cancer risk prediction agent that dynamically selects the most appropriate model for each patient by combining cohort-specific knowledge with modern retrieval and reasoning techniques. Given a patient's CT scan and structured metadata -- including demographic, clinical, and nodule-level features -- the agent first performs cohort retrieval using FAISS-based similarity search across nine diverse real-world cohorts to identify the most relevant patient population from a multi-institutional database. Second, a Large Language Model (LLM) is prompted with the retrieved cohort and its associated performance metrics to recommend the optimal prediction algorithm from a pool of eight representative models, including classical linear risk models (e.g., Mayo, Brock), temporally-aware models (e.g., TDVIT, DLSTM), and multi-modal computer vision-based approaches (e.g., Liao, Sybil, DLS, DLI). This two-stage agent pipeline -- retrieval via FAISS and reasoning via LLM -- enables dynamic, cohort-aware risk prediction personalized to each patient's profile. Building on this architecture, the agent supports flexible and cohort-driven model selection across diverse clinical populations, offering a practical path toward individualized risk assessment in real-world lung cancer screening.</li>
</ul>

<h3>Title: Structure-Aware Temporal Modeling for Chronic Disease Progression Prediction</h3>
<ul>
<li><strong>Authors: </strong>Jiacheng Hu, Bo Zhang, Ting Xu, Haifeng Yang, Min Gao</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.14942">https://arxiv.org/abs/2508.14942</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.14942">https://arxiv.org/pdf/2508.14942</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.14942]] Structure-Aware Temporal Modeling for Chronic Disease Progression Prediction(https://arxiv.org/abs/2508.14942)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>This study addresses the challenges of symptom evolution complexity and insufficient temporal dependency modeling in Parkinson's disease progression prediction. It proposes a unified prediction framework that integrates structural perception and temporal modeling. The method leverages graph neural networks to model the structural relationships among multimodal clinical symptoms and introduces graph-based representations to capture semantic dependencies between symptoms. It also incorporates a Transformer architecture to model dynamic temporal features during disease progression. To fuse structural and temporal information, a structure-aware gating mechanism is designed to dynamically adjust the fusion weights between structural encodings and temporal features, enhancing the model's ability to identify key progression stages. To improve classification accuracy and stability, the framework includes a multi-component modeling pipeline, consisting of a graph construction module, a temporal encoding module, and a prediction output layer. The model is evaluated on real-world longitudinal Parkinson's disease data. The experiments involve comparisons with mainstream models, sensitivity analysis of hyperparameters, and graph connection density control. Results show that the proposed method outperforms existing approaches in AUC, RMSE, and IPW-F1 metrics. It effectively distinguishes progression stages and improves the model's ability to capture personalized symptom trajectories. The overall framework demonstrates strong generalization and structural scalability, providing reliable support for intelligent modeling of chronic progressive diseases such as Parkinson's disease.</li>
</ul>

<h3>Title: Linear Preference Optimization: Decoupled Gradient Control via Absolute Regularization</h3>
<ul>
<li><strong>Authors: </strong>Rui Wang, Qianguo Sun, Chao Song, Junlong Wu, Tianrong Chen, Zhiyun Zeng, Yu Li</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.14947">https://arxiv.org/abs/2508.14947</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.14947">https://arxiv.org/pdf/2508.14947</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.14947]] Linear Preference Optimization: Decoupled Gradient Control via Absolute Regularization(https://arxiv.org/abs/2508.14947)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>DPO (Direct Preference Optimization) has become a widely used offline preference optimization algorithm due to its simplicity and training stability. However, DPO is prone to overfitting and collapse. To address these challenges, we propose Linear Preference Optimization (LPO), a novel alignment framework featuring three key innovations. First, we introduce gradient decoupling by replacing the log-sigmoid function with an absolute difference loss, thereby isolating the optimization dynamics. Second, we improve stability through an offset constraint combined with a positive regularization term to preserve the chosen response quality. Third, we implement controllable rejection suppression using gradient separation with straightforward estimation and a tunable coefficient that linearly regulates the descent of the rejection probability. Through extensive experiments, we demonstrate that LPO consistently improves performance on various tasks, including general text tasks, math tasks, and text-to-speech (TTS) tasks. These results establish LPO as a robust and tunable paradigm for preference alignment, and we release the source code, models, and training data publicly.</li>
</ul>

<h3>Title: Large Foundation Model for Ads Recommendation</h3>
<ul>
<li><strong>Authors: </strong>Shangyu Zhang, Shijie Quan, Zhongren Wang, Junwei Pan, Tianqu Zhuang, Bo Fu, Yilong Sun, Jieying Lin, Jushuo Chen, Xiaotian Li, Zhixiang Feng, Xian Hu, Huiting Deng, Hua Lu, Jinpeng Wang, Boqi Dai, Xiaoyu Chen, Bin Hu, Lili Huang, Yanwen Wu, Yeshou Cai, Qi Zhou, Huang Tang, Chunfeng Yang, Chengguo Yin, Tingyu Jiang, Lifeng Wang, Shudong Huang, Dapeng Liu, Lei Xiao, Haijie Gu, Shu-Tao Xia, Jie Jiang</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.14948">https://arxiv.org/abs/2508.14948</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.14948">https://arxiv.org/pdf/2508.14948</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.14948]] Large Foundation Model for Ads Recommendation(https://arxiv.org/abs/2508.14948)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction</a></li>
<li><strong>Abstract: </strong>Online advertising relies on accurate recommendation models, with recent advances using pre-trained large-scale foundation models (LFMs) to capture users' general interests across multiple scenarios and tasks. However, existing methods have critical limitations: they extract and transfer only user representations (URs), ignoring valuable item representations (IRs) and user-item cross representations (CRs); and they simply use a UR as a feature in downstream applications, which fails to bridge upstream-downstream gaps and overlooks more transfer granularities. In this paper, we propose LFM4Ads, an All-Representation Multi-Granularity transfer framework for ads recommendation. It first comprehensively transfers URs, IRs, and CRs, i.e., all available representations in the pre-trained foundation model. To effectively utilize the CRs, it identifies the optimal extraction layer and aggregates them into transferable coarse-grained forms. Furthermore, we enhance the transferability via multi-granularity mechanisms: non-linear adapters for feature-level transfer, an Isomorphic Interaction Module for module-level transfer, and Standalone Retrieval for model-level transfer. LFM4Ads has been successfully deployed in Tencent's industrial-scale advertising platform, processing tens of billions of daily samples while maintaining terabyte-scale model parameters with billions of sparse embedding keys across approximately two thousand features. Since its production deployment in Q4 2024, LFM4Ads has achieved 10+ successful production launches across various advertising scenarios, including primary ones like Weixin Moments and Channels. These launches achieve an overall GMV lift of 2.45% across the entire platform, translating to estimated annual revenue increases in the hundreds of millions of dollars.</li>
</ul>

<h3>Title: Improving LLMs for Machine Translation Using Synthetic Preference Data</h3>
<ul>
<li><strong>Authors: </strong>Dario Vajda, Domen Vreš, Marko Robnik-Šikonja</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.14951">https://arxiv.org/abs/2508.14951</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.14951">https://arxiv.org/pdf/2508.14951</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.14951]] Improving LLMs for Machine Translation Using Synthetic Preference Data(https://arxiv.org/abs/2508.14951)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large language models have emerged as effective machine translation systems. In this paper, we explore how a general instruction-tuned large language model can be improved for machine translation using relatively few easily produced data resources. Using Slovene as a use case, we improve the GaMS-9B-Instruct model using Direct Preference Optimization (DPO) training on a programmatically curated and enhanced subset of a public dataset. As DPO requires pairs of quality-ranked instances, we generated its training dataset by translating English Wikipedia articles using two LLMs, GaMS-9B-Instruct and EuroLLM-9B-Instruct. We ranked the resulting translations based on heuristics coupled with automatic evaluation metrics such as COMET. The evaluation shows that our fine-tuned model outperforms both models involved in the dataset generation. In comparison to the baseline models, the fine-tuned model achieved a COMET score gain of around 0.04 and 0.02, respectively, on translating Wikipedia articles. It also more consistently avoids language and formatting errors.</li>
</ul>

<h3>Title: Fast Graph Neural Network for Image Classification</h3>
<ul>
<li><strong>Authors: </strong>Mustafa Mohammadi Gharasuie, Luis Rueda</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.14958">https://arxiv.org/abs/2508.14958</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.14958">https://arxiv.org/pdf/2508.14958</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.14958]] Fast Graph Neural Network for Image Classification(https://arxiv.org/abs/2508.14958)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>The rapid progress in image classification has been largely driven by the adoption of Graph Convolutional Networks (GCNs), which offer a robust framework for handling complex data structures. This study introduces a novel approach that integrates GCNs with Voronoi diagrams to enhance image classification by leveraging their ability to effectively model relational data. Unlike conventional convolutional neural networks (CNNs), our method represents images as graphs, where pixels or regions function as vertices. These graphs are then refined using corresponding Delaunay triangulations, optimizing their representation. The proposed model achieves significant improvements in both preprocessing efficiency and classification accuracy across various benchmark datasets, surpassing state-of-the-art approaches, particularly in challenging scenarios involving intricate scenes and fine-grained categories. Experimental results, validated through cross-validation, underscore the effectiveness of combining GCNs with Voronoi diagrams for advancing image classification. This research not only presents a novel perspective on image classification but also expands the potential applications of graph-based learning paradigms in computer vision and unstructured data analysis.</li>
</ul>

<h3>Title: You Only Pose Once: A Minimalist's Detection Transformer for Monocular RGB Category-level 9D Multi-Object Pose Estimation</h3>
<ul>
<li><strong>Authors: </strong>Hakjin Lee, Junghoon Seo, Jaehoon Sim</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.RO</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.14965">https://arxiv.org/abs/2508.14965</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.14965">https://arxiv.org/pdf/2508.14965</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.14965]] You Only Pose Once: A Minimalist's Detection Transformer for Monocular RGB Category-level 9D Multi-Object Pose Estimation(https://arxiv.org/abs/2508.14965)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Accurately recovering the full 9-DoF pose of unseen instances within specific categories from a single RGB image remains a core challenge for robotics and automation. Most existing solutions still rely on pseudo-depth, CAD models, or multi-stage cascades that separate 2D detection from pose estimation. Motivated by the need for a simpler, RGB-only alternative that learns directly at the category level, we revisit a longstanding question: Can object detection and 9-DoF pose estimation be unified with high performance, without any additional data? We show that they can with our method, YOPO, a single-stage, query-based framework that treats category-level 9-DoF estimation as a natural extension of 2D detection. YOPO augments a transformer detector with a lightweight pose head, a bounding-box-conditioned translation module, and a 6D-aware Hungarian matching cost. The model is trained end-to-end only with RGB images and category-level pose labels. Despite its minimalist design, YOPO sets a new state of the art on three benchmarks. On the REAL275 dataset, it achieves 79.6% $\rm{IoU}_{50}$ and 54.1% under the $10^\circ$$10{\rm{cm}}$ metric, surpassing prior RGB-only methods and closing much of the gap to RGB-D systems. The code, models, and additional qualitative results can be found on our project.</li>
</ul>

<h3>Title: Aura-CAPTCHA: A Reinforcement Learning and GAN-Enhanced Multi-Modal CAPTCHA System</h3>
<ul>
<li><strong>Authors: </strong>Joydeep Chandra, Prabal Manhas, Ramanjot Kaur, Rashi Sahay</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.14976">https://arxiv.org/abs/2508.14976</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.14976">https://arxiv.org/pdf/2508.14976</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.14976]] Aura-CAPTCHA: A Reinforcement Learning and GAN-Enhanced Multi-Modal CAPTCHA System(https://arxiv.org/abs/2508.14976)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, generative, large language model</a></li>
<li><strong>Abstract: </strong>Aura-CAPTCHA was developed as a multi-modal CAPTCHA system to address vulnerabilities in traditional methods that are increasingly bypassed by AI technologies, such as Optical Character Recognition (OCR) and adversarial image processing. The design integrated Generative Adversarial Networks (GANs) for generating dynamic image challenges, Reinforcement Learning (RL) for adaptive difficulty tuning, and Large Language Models (LLMs) for creating text and audio prompts. Visual challenges included 3x3 grid selections with at least three correct images, while audio challenges combined randomized numbers and words into a single task. RL adjusted difficulty based on incorrect attempts, response time, and suspicious user behavior. Evaluations on real-world traffic demonstrated a 92% human success rate and a 10% bot bypass rate, significantly outperforming existing CAPTCHA systems. The system provided a robust and scalable approach for securing online applications while remaining accessible to users, addressing gaps highlighted in previous research.</li>
</ul>

<h3>Title: Paired-Sampling Contrastive Framework for Joint Physical-Digital Face Attack Detection</h3>
<ul>
<li><strong>Authors: </strong>Andrei Balykin, Anvar Ganiev, Denis Kondranin, Kirill Polevoda, Nikolai Liudkevich, Artem Petrov</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.14980">https://arxiv.org/abs/2508.14980</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.14980">https://arxiv.org/pdf/2508.14980</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.14980]] Paired-Sampling Contrastive Framework for Joint Physical-Digital Face Attack Detection(https://arxiv.org/abs/2508.14980)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack</a></li>
<li><strong>Abstract: </strong>Modern face recognition systems remain vulnerable to spoofing attempts, including both physical presentation attacks and digital forgeries. Traditionally, these two attack vectors have been handled by separate models, each targeting its own artifacts and modalities. However, maintaining distinct detectors increases system complexity and inference latency and leaves systems exposed to combined attack vectors. We propose the Paired-Sampling Contrastive Framework, a unified training approach that leverages automatically matched pairs of genuine and attack selfies to learn modality-agnostic liveness cues. Evaluated on the 6th Face Anti-Spoofing Challenge Unified Physical-Digital Attack Detection benchmark, our method achieves an average classification error rate (ACER) of 2.10 percent, outperforming prior solutions. The framework is lightweight (4.46 GFLOPs) and trains in under one hour, making it practical for real-world deployment. Code and pretrained models are available at this https URL.</li>
</ul>

<h3>Title: Multilingual Datasets for Custom Input Extraction and Explanation Requests Parsing in Conversational XAI Systems</h3>
<ul>
<li><strong>Authors: </strong>Qianli Wang, Tatiana Anikina, Nils Feldhus, Simon Ostermann, Fedor Splitt, Jiaao Li, Yoana Tsoneva, Sebastian Möller, Vera Schmitt</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.14982">https://arxiv.org/abs/2508.14982</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.14982">https://arxiv.org/pdf/2508.14982</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.14982]] Multilingual Datasets for Custom Input Extraction and Explanation Requests Parsing in Conversational XAI Systems(https://arxiv.org/abs/2508.14982)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction, explainability, large language model</a></li>
<li><strong>Abstract: </strong>Conversational explainable artificial intelligence (ConvXAI) systems based on large language models (LLMs) have garnered considerable attention for their ability to enhance user comprehension through dialogue-based explanations. Current ConvXAI systems often are based on intent recognition to accurately identify the user's desired intention and map it to an explainability method. While such methods offer great precision and reliability in discerning users' underlying intentions for English, a significant challenge in the scarcity of training data persists, which impedes multilingual generalization. Besides, the support for free-form custom inputs, which are user-defined data distinct from pre-configured dataset instances, remains largely limited. To bridge these gaps, we first introduce MultiCoXQL, a multilingual extension of the CoXQL dataset spanning five typologically diverse languages, including one low-resource language. Subsequently, we propose a new parsing approach aimed at enhancing multilingual parsing performance, and evaluate three LLMs on MultiCoXQL using various parsing strategies. Furthermore, we present Compass, a new multilingual dataset designed for custom input extraction in ConvXAI systems, encompassing 11 intents across the same five languages as MultiCoXQL. We conduct monolingual, cross-lingual, and multilingual evaluations on Compass, employing three LLMs of varying sizes alongside BERT-type models.</li>
</ul>

<h3>Title: Generative Neural Operators of Log-Complexity Can Simultaneously Solve Infinitely Many Convex Programs</h3>
<ul>
<li><strong>Authors: </strong>Anastasis Kratsios, Ariel Neufeld, Philipp Schmocker</a></li>
<li><strong>Subjects: </strong>cs.LG, math.NA, math.OC, q-fin.CP</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.14995">https://arxiv.org/abs/2508.14995</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.14995">https://arxiv.org/pdf/2508.14995</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.14995]] Generative Neural Operators of Log-Complexity Can Simultaneously Solve Infinitely Many Convex Programs(https://arxiv.org/abs/2508.14995)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>Neural operators (NOs) are a class of deep learning models designed to simultaneously solve infinitely many related problems by casting them into an infinite-dimensional space, whereon these NOs operate. A significant gap remains between theory and practice: worst-case parameter bounds from universal approximation theorems suggest that NOs may require an unrealistically large number of parameters to solve most operator learning problems, which stands in direct opposition to a slew of experimental evidence. This paper closes that gap for a specific class of {NOs}, generative {equilibrium operators} (GEOs), using (realistic) finite-dimensional deep equilibrium layers, when solving families of convex optimization problems over a separable Hilbert space $X$. Here, the inputs are smooth, convex loss functions on $X$, and outputs are the associated (approximate) solutions to the optimization problem defined by each input loss. We show that when the input losses lie in suitable infinite-dimensional compact sets, our GEO can uniformly approximate the corresponding solutions to arbitrary precision, with rank, depth, and width growing only logarithmically in the reciprocal of the approximation error. We then validate both our theoretical results and the trainability of GEOs on three applications: (1) nonlinear PDEs, (2) stochastic optimal control problems, and (3) hedging problems in mathematical finance under liquidity constraints.</li>
</ul>

<h3>Title: Fragment-Wise Interpretability in Graph Neural Networks via Molecule Decomposition and Contribution Analysis</h3>
<ul>
<li><strong>Authors: </strong>Sebastian Musiał, Bartosz Zieliński, Tomasz Danel</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.15015">https://arxiv.org/abs/2508.15015</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.15015">https://arxiv.org/pdf/2508.15015</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.15015]] Fragment-Wise Interpretability in Graph Neural Networks via Molecule Decomposition and Contribution Analysis(https://arxiv.org/abs/2508.15015)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability, explainability</a></li>
<li><strong>Abstract: </strong>Graph neural networks have demonstrated remarkable success in predicting molecular properties by leveraging the rich structural information encoded in molecular graphs. However, their black-box nature reduces interpretability, which limits trust in their predictions for important applications such as drug discovery and materials design. Furthermore, existing explanation techniques often fail to reliably quantify the contribution of individual atoms or substructures due to the entangled message-passing dynamics. We introduce SEAL (Substructure Explanation via Attribution Learning), a new interpretable graph neural network that attributes model predictions to meaningful molecular subgraphs. SEAL decomposes input graphs into chemically relevant fragments and estimates their causal influence on the output. The strong alignment between fragment contributions and model predictions is achieved by explicitly reducing inter-fragment message passing in our proposed model architecture. Extensive evaluations on synthetic benchmarks and real-world molecular datasets demonstrate that SEAL outperforms other explainability methods in both quantitative attribution metrics and human-aligned interpretability. A user study further confirms that SEAL provides more intuitive and trustworthy explanations to domain experts. By bridging the gap between predictive performance and interpretability, SEAL offers a promising direction for more transparent and actionable molecular modeling.</li>
</ul>

<h3>Title: TAIGen: Training-Free Adversarial Image Generation via Diffusion Models</h3>
<ul>
<li><strong>Authors: </strong>Susim Roy, Anubhooti Jain, Mayank Vatsa, Richa Singh</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.15020">https://arxiv.org/abs/2508.15020</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.15020">https://arxiv.org/pdf/2508.15020</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.15020]] TAIGen: Training-Free Adversarial Image Generation via Diffusion Models(https://arxiv.org/abs/2508.15020)</code><input type="text"></li>
<li><strong>Keywords: </strong>defense, attack, robust, diffusion, generative</a></li>
<li><strong>Abstract: </strong>Adversarial attacks from generative models often produce low-quality images and require substantial computational resources. Diffusion models, though capable of high-quality generation, typically need hundreds of sampling steps for adversarial generation. This paper introduces TAIGen, a training-free black-box method for efficient adversarial image generation. TAIGen produces adversarial examples using only 3-20 sampling steps from unconditional diffusion models. Our key finding is that perturbations injected during the mixing step interval achieve comparable attack effectiveness without processing all timesteps. We develop a selective RGB channel strategy that applies attention maps to the red channel while using GradCAM-guided perturbations on green and blue channels. This design preserves image structure while maximizing misclassification in target models. TAIGen maintains visual quality with PSNR above 30 dB across all tested datasets. On ImageNet with VGGNet as source, TAIGen achieves 70.6% success against ResNet, 80.8% against MNASNet, and 97.8% against ShuffleNet. The method generates adversarial examples 10x faster than existing diffusion-based attacks. Our method achieves the lowest robust accuracy, indicating it is the most impactful attack as the defense mechanism is least successful in purifying the images generated by TAIGen.</li>
</ul>

<h3>Title: Nonlinear Federated System Identification</h3>
<ul>
<li><strong>Authors: </strong>Omkar Tupe, Max Hartman, Lav R. Varshney, Saurav Prakash</a></li>
<li><strong>Subjects: </strong>cs.LG, eess.SY</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.15025">https://arxiv.org/abs/2508.15025</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.15025">https://arxiv.org/pdf/2508.15025</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.15025]] Nonlinear Federated System Identification(https://arxiv.org/abs/2508.15025)</code><input type="text"></li>
<li><strong>Keywords: </strong>federate</a></li>
<li><strong>Abstract: </strong>We consider federated learning of linearly-parameterized nonlinear systems. We establish theoretical guarantees on the effectiveness of federated nonlinear system identification compared to centralized approaches, demonstrating that the convergence rate improves as the number of clients increases. Although the convergence rates in the linear and nonlinear cases differ only by a constant, this constant depends on the feature map $\phi$, which can be carefully chosen in the nonlinear setting to increase excitation and improve performance. We experimentally validate our theory in physical settings where client devices are driven by i.i.d. control inputs and control policies exhibiting i.i.d. random perturbations, ensuring non-active exploration. Experiments use trajectories from nonlinear dynamical systems characterized by real-analytic feature functions, including polynomial and trigonometric components, representative of physical systems including pendulum and quadrotor dynamics. We analyze the convergence behavior of the proposed method under varying noise levels and data distributions. Results show that federated learning consistently improves convergence of any individual client as the number of participating clients increases.</li>
</ul>

<h3>Title: Reversible Unfolding Network for Concealed Visual Perception with Generative Refinement</h3>
<ul>
<li><strong>Authors: </strong>Chunming He, Fengyang Xiao, Rihan Zhang, Chengyu Fang, Deng-Ping Fan, Sina Farsiu</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.15027">https://arxiv.org/abs/2508.15027</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.15027">https://arxiv.org/pdf/2508.15027</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.15027]] Reversible Unfolding Network for Concealed Visual Perception with Generative Refinement(https://arxiv.org/abs/2508.15027)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, extraction, diffusion, generative, segmentation</a></li>
<li><strong>Abstract: </strong>Existing methods for concealed visual perception (CVP) often leverage reversible strategies to decrease uncertainty, yet these are typically confined to the mask domain, leaving the potential of the RGB domain underexplored. To address this, we propose a reversible unfolding network with generative refinement, termed RUN++. Specifically, RUN++ first formulates the CVP task as a mathematical optimization problem and unfolds the iterative solution into a multi-stage deep network. This approach provides a principled way to apply reversible modeling across both mask and RGB domains while leveraging a diffusion model to resolve the resulting uncertainty. Each stage of the network integrates three purpose-driven modules: a Concealed Object Region Extraction (CORE) module applies reversible modeling to the mask domain to identify core object regions; a Context-Aware Region Enhancement (CARE) module extends this principle to the RGB domain to foster better foreground-background separation; and a Finetuning Iteration via Noise-based Enhancement (FINE) module provides a final refinement. The FINE module introduces a targeted Bernoulli diffusion model that refines only the uncertain regions of the segmentation mask, harnessing the generative power of diffusion for fine-detail restoration without the prohibitive computational cost of a full-image process. This unique synergy, where the unfolding network provides a strong uncertainty prior for the diffusion model, allows RUN++ to efficiently direct its focus toward ambiguous areas, significantly mitigating false positives and negatives. Furthermore, we introduce a new paradigm for building robust CVP systems that remain effective under real-world degradations and extend this concept into a broader bi-level optimization framework.</li>
</ul>

<h3>Title: A Systematic Survey of Model Extraction Attacks and Defenses: State-of-the-Art and Perspectives</h3>
<ul>
<li><strong>Authors: </strong>Kaixiang Zhao, Lincan Li, Kaize Ding, Neil Zhenqiang Gong, Yue Zhao, Yushun Dong</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.15031">https://arxiv.org/abs/2508.15031</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.15031">https://arxiv.org/pdf/2508.15031</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.15031]] A Systematic Survey of Model Extraction Attacks and Defenses: State-of-the-Art and Perspectives(https://arxiv.org/abs/2508.15031)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, privacy, defense, attack, extraction</a></li>
<li><strong>Abstract: </strong>Machine learning (ML) models have significantly grown in complexity and utility, driving advances across multiple domains. However, substantial computational resources and specialized expertise have historically restricted their wide adoption. Machine-Learning-as-a-Service (MLaaS) platforms have addressed these barriers by providing scalable, convenient, and affordable access to sophisticated ML models through user-friendly APIs. While this accessibility promotes widespread use of advanced ML capabilities, it also introduces vulnerabilities exploited through Model Extraction Attacks (MEAs). Recent studies have demonstrated that adversaries can systematically replicate a target model's functionality by interacting with publicly exposed interfaces, posing threats to intellectual property, privacy, and system security. In this paper, we offer a comprehensive survey of MEAs and corresponding defense strategies. We propose a novel taxonomy that classifies MEAs according to attack mechanisms, defense approaches, and computing environments. Our analysis covers various attack techniques, evaluates their effectiveness, and highlights challenges faced by existing defenses, particularly the critical trade-off between preserving model utility and ensuring security. We further assess MEAs within different computing paradigms and discuss their technical, ethical, legal, and societal implications, along with promising directions for future research. This systematic survey aims to serve as a valuable reference for researchers, practitioners, and policymakers engaged in AI security and privacy. Additionally, we maintain an online repository continuously updated with related literature at this https URL.</li>
</ul>

<h3>Title: MoEcho: Exploiting Side-Channel Attacks to Compromise User Privacy in Mixture-of-Experts LLMs</h3>
<ul>
<li><strong>Authors: </strong>Ruyi Ding, Tianhong Xu, Xinyi Shen, Aidong Adam Ding, Yunsi Fei</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.15036">https://arxiv.org/abs/2508.15036</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.15036">https://arxiv.org/pdf/2508.15036</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.15036]] MoEcho: Exploiting Side-Channel Attacks to Compromise User Privacy in Mixture-of-Experts LLMs(https://arxiv.org/abs/2508.15036)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, privacy, attack, transformer, large language model</a></li>
<li><strong>Abstract: </strong>The transformer architecture has become a cornerstone of modern AI, fueling remarkable progress across applications in natural language processing, computer vision, and multimodal learning. As these models continue to scale explosively for performance, implementation efficiency remains a critical challenge. Mixture of Experts (MoE) architectures, selectively activating specialized subnetworks (experts), offer a unique balance between model accuracy and computational cost. However, the adaptive routing in MoE architectures, where input tokens are dynamically directed to specialized experts based on their semantic meaning inadvertently opens up a new attack surface for privacy breaches. These input-dependent activation patterns leave distinctive temporal and spatial traces in hardware execution, which adversaries could exploit to deduce sensitive user data. In this work, we propose MoEcho, discovering a side channel analysis based attack surface that compromises user privacy on MoE based systems. Specifically, in MoEcho, we introduce four novel architectural side channels on different computing platforms, including Cache Occupancy Channels and Pageout+Reload on CPUs, and Performance Counter and TLB Evict+Reload on GPUs, respectively. Exploiting these vulnerabilities, we propose four attacks that effectively breach user privacy in large language models (LLMs) and vision language models (VLMs) based on MoE architectures: Prompt Inference Attack, Response Reconstruction Attack, Visual Inference Attack, and Visual Reconstruction Attack. MoEcho is the first runtime architecture level security analysis of the popular MoE structure common in modern transformers, highlighting a serious security and privacy threat and calling for effective and timely safeguards when harnessing MoE based models for developing efficient large scale AI services.</li>
</ul>

<h3>Title: Reward-Shifted Speculative Sampling Is An Efficient Test-Time Weak-to-Strong Aligner</h3>
<ul>
<li><strong>Authors: </strong>Bolian Li, Yanran Wu, Xinyu Luo, Ruqi Zhang</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.15044">https://arxiv.org/abs/2508.15044</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.15044">https://arxiv.org/pdf/2508.15044</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.15044]] Reward-Shifted Speculative Sampling Is An Efficient Test-Time Weak-to-Strong Aligner(https://arxiv.org/abs/2508.15044)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Aligning large language models (LLMs) with human preferences has become a critical step in their development. Recent research has increasingly focused on test-time alignment, where additional compute is allocated during inference to enhance LLM safety and reasoning capabilities. However, these test-time alignment techniques often incur substantial inference costs, limiting their practical application. We are inspired by the speculative sampling acceleration, which leverages a small draft model to efficiently predict future tokens, to address the efficiency bottleneck of test-time alignment. We introduce the reward-Shifted Speculative Sampling (SSS) algorithm, in which the draft model is aligned with human preferences, while the target model remains unchanged. We theoretically demonstrate that the distributional shift between the aligned draft model and the unaligned target model can be exploited to recover the RLHF optimal solution without actually obtaining it, by modifying the acceptance criterion and bonus token distribution. Our algorithm achieves superior gold reward scores at a significantly reduced inference cost in test-time weak-to-strong alignment experiments, thereby validating both its effectiveness and efficiency.</li>
</ul>

<h3>Title: Robust Estimation Under Heterogeneous Corruption Rates</h3>
<ul>
<li><strong>Authors: </strong>Syomantak Chaudhuri, Jerry Li, Thomas A. Courtade</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.IT, math.ST, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.15051">https://arxiv.org/abs/2508.15051</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.15051">https://arxiv.org/pdf/2508.15051</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.15051]] Robust Estimation Under Heterogeneous Corruption Rates(https://arxiv.org/abs/2508.15051)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, federate</a></li>
<li><strong>Abstract: </strong>We study the problem of robust estimation under heterogeneous corruption rates, where each sample may be independently corrupted with a known but non-identical probability. This setting arises naturally in distributed and federated learning, crowdsourcing, and sensor networks, yet existing robust estimators typically assume uniform or worst-case corruption, ignoring structural heterogeneity. For mean estimation for multivariate bounded distributions and univariate gaussian distributions, we give tight minimax rates for all heterogeneous corruption patterns. For multivariate gaussian mean estimation and linear regression, we establish the minimax rate for squared error up to a factor of $\sqrt{d}$, where $d$ is the dimension. Roughly, our findings suggest that samples beyond a certain corruption threshold may be discarded by the optimal estimators -- this threshold is determined by the empirical distribution of the corruption rates given.</li>
</ul>

<h3>Title: GasTwinFormer: A Hybrid Vision Transformer for Livestock Methane Emission Segmentation and Dietary Classification in Optical Gas Imaging</h3>
<ul>
<li><strong>Authors: </strong>Toqi Tahamid Sarker, Mohamed Embaby, Taminul Islam, Amer AbuGhazaleh, Khaled R Ahmed</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.15057">https://arxiv.org/abs/2508.15057</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.15057">https://arxiv.org/pdf/2508.15057</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.15057]] GasTwinFormer: A Hybrid Vision Transformer for Livestock Methane Emission Segmentation and Dietary Classification in Optical Gas Imaging(https://arxiv.org/abs/2508.15057)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer, segmentation</a></li>
<li><strong>Abstract: </strong>Livestock methane emissions represent 32% of human-caused methane production, making automated monitoring critical for climate mitigation strategies. We introduce GasTwinFormer, a hybrid vision transformer for real-time methane emission segmentation and dietary classification in optical gas imaging through a novel Mix Twin encoder alternating between spatially-reduced global attention and locally-grouped attention mechanisms. Our architecture incorporates a lightweight LR-ASPP decoder for multi-scale feature aggregation and enables simultaneous methane segmentation and dietary classification in a unified framework. We contribute the first comprehensive beef cattle methane emission dataset using OGI, containing 11,694 annotated frames across three dietary treatments. GasTwinFormer achieves 74.47% mIoU and 83.63% mF1 for segmentation while maintaining exceptional efficiency with only 3.348M parameters, 3.428G FLOPs, and 114.9 FPS inference speed. Additionally, our method achieves perfect dietary classification accuracy (100%), demonstrating the effectiveness of leveraging diet-emission correlations. Extensive ablation studies validate each architectural component, establishing GasTwinFormer as a practical solution for real-time livestock emission monitoring. Please see our project page at this http URL.</li>
</ul>

<h3>Title: Enhancing Optimizer Stability: Momentum Adaptation of The NGN Step-size</h3>
<ul>
<li><strong>Authors: </strong>Rustem Islamov, Niccolo Ajroldi, Antonio Orvieto, Aurelien Lucchi</a></li>
<li><strong>Subjects: </strong>cs.LG, math.OC, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.15071">https://arxiv.org/abs/2508.15071</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.15071">https://arxiv.org/pdf/2508.15071</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.15071]] Enhancing Optimizer Stability: Momentum Adaptation of The NGN Step-size(https://arxiv.org/abs/2508.15071)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Modern optimization algorithms that incorporate momentum and adaptive step-size offer improved performance in numerous challenging deep learning tasks. However, their effectiveness is often highly sensitive to the choice of hyperparameters, especially the step-size. Tuning these parameters is often difficult, resource-intensive, and time-consuming. Therefore, recent efforts have been directed toward enhancing the stability of optimizers across a wide range of hyperparameter choices [Schaipp et al., 2024]. In this paper, we introduce an algorithm that matches the performance of state-of-the-art optimizers while improving stability to the choice of the step-size hyperparameter through a novel adaptation of the NGN step-size method [Orvieto and Xiao, 2024]. Specifically, we propose a momentum-based version (NGN-M) that attains the standard convergence rate of $\mathcal{O}(1/\sqrt{K})$ under less restrictive assumptions, without the need for interpolation condition or assumptions of bounded stochastic gradients or iterates, in contrast to previous approaches. Additionally, we empirically demonstrate that the combination of the NGN step-size with momentum results in enhanced robustness to the choice of the step-size hyperparameter while delivering performance that is comparable to or surpasses other state-of-the-art optimizers.</li>
</ul>

<h3>Title: LongRecall: A Structured Approach for Robust Recall Evaluation in Long-Form Text</h3>
<ul>
<li><strong>Authors: </strong>MohamamdJavad Ardestani, Ehsan Kamalloo, Davood Rafiei</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.IR, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.15085">https://arxiv.org/abs/2508.15085</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.15085">https://arxiv.org/pdf/2508.15085</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.15085]] LongRecall: A Structured Approach for Robust Recall Evaluation in Long-Form Text(https://arxiv.org/abs/2508.15085)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>LongRecall. The completeness of machine-generated text, ensuring that it captures all relevant information, is crucial in domains such as medicine and law and in tasks like list-based question answering (QA), where omissions can have serious consequences. However, existing recall metrics often depend on lexical overlap, leading to errors with unsubstantiated entities and paraphrased answers, while LLM-as-a-Judge methods with long holistic prompts capture broader semantics but remain prone to misalignment and hallucinations without structured verification. We introduce LongRecall, a general three-stage recall evaluation framework that decomposes answers into self-contained facts, successively narrows plausible candidate matches through lexical and semantic filtering, and verifies their alignment through structured entailment checks. This design reduces false positives and false negatives while accommodating diverse phrasings and contextual variations, serving as a foundational building block for systematic recall assessment. We evaluate LongRecall on three challenging long-form QA benchmarks using both human annotations and LLM-based judges, demonstrating substantial improvements in recall accuracy over strong lexical and LLM-as-a-Judge baselines.</li>
</ul>

<h3>Title: Tighter Privacy Analysis for Truncated Poisson Sampling</h3>
<ul>
<li><strong>Authors: </strong>Arun Ganesh</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.15089">https://arxiv.org/abs/2508.15089</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.15089">https://arxiv.org/pdf/2508.15089</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.15089]] Tighter Privacy Analysis for Truncated Poisson Sampling(https://arxiv.org/abs/2508.15089)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy</a></li>
<li><strong>Abstract: </strong>We give a new privacy amplification analysis for truncated Poisson sampling, a Poisson sampling variant that truncates a batch if it exceeds a given maximum batch size.</li>
</ul>

<h3>Title: CurveFlow: Curvature-Guided Flow Matching for Image Generation</h3>
<ul>
<li><strong>Authors: </strong>Yan Luo, Drake Du, Hao Huang, Yi Fang, Mengyu Wang</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.15093">https://arxiv.org/abs/2508.15093</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.15093">https://arxiv.org/pdf/2508.15093</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.15093]] CurveFlow: Curvature-Guided Flow Matching for Image Generation(https://arxiv.org/abs/2508.15093)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, diffusion</a></li>
<li><strong>Abstract: </strong>Existing rectified flow models are based on linear trajectories between data and noise distributions. This linearity enforces zero curvature, which can inadvertently force the image generation process through low-probability regions of the data manifold. A key question remains underexplored: how does the curvature of these trajectories correlate with the semantic alignment between generated images and their corresponding captions, i.e., instructional compliance? To address this, we introduce CurveFlow, a novel flow matching framework designed to learn smooth, non-linear trajectories by directly incorporating curvature guidance into the flow path. Our method features a robust curvature regularization technique that penalizes abrupt changes in the trajectory's intrinsic this http URL experiments on MS COCO 2014 and 2017 demonstrate that CurveFlow achieves state-of-the-art performance in text-to-image generation, significantly outperforming both standard rectified flow variants and other non-linear baselines like Rectified Diffusion. The improvements are especially evident in semantic consistency metrics such as BLEU, METEOR, ROUGE, and CLAIR. This confirms that our curvature-aware modeling substantially enhances the model's ability to faithfully follow complex instructions while simultaneously maintaining high image quality. The code is made publicly available at this https URL.</li>
</ul>

<h3>Title: Evaluating Sparse Autoencoders for Monosemantic Representation</h3>
<ul>
<li><strong>Authors: </strong>Moghis Fereidouni, Muhammad Umair Haider, Peizhong Ju, A.B. Siddique</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.15094">https://arxiv.org/abs/2508.15094</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.15094">https://arxiv.org/pdf/2508.15094</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.15094]] Evaluating Sparse Autoencoders for Monosemantic Representation(https://arxiv.org/abs/2508.15094)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>A key barrier to interpreting large language models is polysemanticity, where neurons activate for multiple unrelated concepts. Sparse autoencoders (SAEs) have been proposed to mitigate this issue by transforming dense activations into sparse, more interpretable features. While prior work suggests that SAEs promote monosemanticity, there has been no quantitative comparison with their base models. This paper provides the first systematic evaluation of SAEs against base models concerning monosemanticity. We introduce a fine-grained concept separability score based on the Jensen-Shannon distance, which captures how distinctly a neuron's activation distributions vary across concepts. Using Gemma-2-2B and multiple SAE variants across five benchmarks, we show that SAEs reduce polysemanticity and achieve higher concept separability. However, greater sparsity of SAEs does not always yield better separability and often impairs downstream performance. To assess practical utility, we evaluate concept-level interventions using two strategies: full neuron masking and partial suppression. We find that, compared to base models, SAEs enable more precise concept-level control when using partial suppression. Building on this, we propose Attenuation via Posterior Probabilities (APP), a new intervention method that uses concept-conditioned activation distributions for targeted suppression. APP outperforms existing approaches in targeted concept removal.</li>
</ul>

<h3>Title: Nemotron-CC-Math: A 133 Billion-Token-Scale High Quality Math Pretraining Dataset</h3>
<ul>
<li><strong>Authors: </strong>Rabeeh Karimi Mahabadi, Sanjeev Satheesh, Shrimai Prabhumoye, Mostofa Patwary, Mohammad Shoeybi, Bryan Catanzaro</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.15096">https://arxiv.org/abs/2508.15096</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.15096">https://arxiv.org/pdf/2508.15096</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.15096]] Nemotron-CC-Math: A 133 Billion-Token-Scale High Quality Math Pretraining Dataset(https://arxiv.org/abs/2508.15096)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, extraction, large language model</a></li>
<li><strong>Abstract: </strong>Pretraining large language models (LLMs) on high-quality, structured data such as mathematics and code substantially enhances reasoning capabilities. However, existing math-focused datasets built from Common Crawl suffer from degraded quality due to brittle extraction heuristics, lossy HTML-to-text conversion, and the failure to reliably preserve mathematical structure. In this work, we introduce Nemotron-CC-Math, a large-scale, high-quality mathematical corpus constructed from Common Crawl using a novel, domain-agnostic pipeline specifically designed for robust scientific text extraction. Unlike previous efforts, our pipeline recovers math across various formats (e.g., MathJax, KaTeX, MathML) by leveraging layout-aware rendering with lynx and a targeted LLM-based cleaning stage. This approach preserves the structural integrity of equations and code blocks while removing boilerplate, standardizing notation into LaTeX representation, and correcting inconsistencies. We collected a large, high-quality math corpus, namely Nemotron-CC-Math-3+ (133B tokens) and Nemotron-CC-Math-4+ (52B tokens). Notably, Nemotron-CC-Math-4+ not only surpasses all prior open math datasets-including MegaMath, FineMath, and OpenWebMath-but also contains 5.5 times more tokens than FineMath-4+, which was previously the highest-quality math pretraining dataset. When used to pretrain a Nemotron-T 8B model, our corpus yields +4.8 to +12.6 gains on MATH and +4.6 to +14.3 gains on MBPP+ over strong baselines, while also improving general-domain performance on MMLU and MMLU-Stem. We present the first pipeline to reliably extract scientific content--including math--from noisy web-scale data, yielding measurable gains in math, code, and general reasoning, and setting a new state of the art among open math pretraining corpora. To support open-source efforts, we release our code and datasets.</li>
</ul>

<h3>Title: Adaptive Anomaly Detection in Evolving Network Environments</h3>
<ul>
<li><strong>Authors: </strong>Ehssan Mousavipour, Andrey Dimanchev, Majid Ghaderi</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.15100">https://arxiv.org/abs/2508.15100</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.15100">https://arxiv.org/pdf/2508.15100</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.15100]] Adaptive Anomaly Detection in Evolving Network Environments(https://arxiv.org/abs/2508.15100)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Distribution shift, a change in the statistical properties of data over time, poses a critical challenge for deep learning anomaly detection systems. Existing anomaly detection systems often struggle to adapt to these shifts. Specifically, systems based on supervised learning require costly manual labeling, while those based on unsupervised learning rely on clean data, which is difficult to obtain, for shift adaptation. Both of these requirements are challenging to meet in practice.  In this paper, we introduce NetSight, a framework for supervised anomaly detection in network data that continually detects and adapts to distribution shifts in an online manner. NetSight eliminates manual intervention through a novel pseudo-labeling technique and uses a knowledge distillation-based adaptation strategy to prevent catastrophic forgetting. Evaluated on three long-term network datasets, NetSight demonstrates superior adaptation performance compared to state-of-the-art methods that rely on manual labeling, achieving F1-score improvements of up to 11.72%. This proves its robustness and effectiveness in dynamic networks that experience distribution shifts over time.</li>
</ul>

<h3>Title: Side Effects of Erasing Concepts from Diffusion Models</h3>
<ul>
<li><strong>Authors: </strong>Shaswati Saha, Sourajit Saha, Manas Gaur, Tejas Gokhale</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.15124">https://arxiv.org/abs/2508.15124</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.15124">https://arxiv.org/pdf/2508.15124</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.15124]] Side Effects of Erasing Concepts from Diffusion Models(https://arxiv.org/abs/2508.15124)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, robust, diffusion, generative</a></li>
<li><strong>Abstract: </strong>Concerns about text-to-image (T2I) generative models infringing on privacy, copyright, and safety have led to the development of Concept Erasure Techniques (CETs). The goal of an effective CET is to prohibit the generation of undesired ``target'' concepts specified by the user, while preserving the ability to synthesize high-quality images of the remaining concepts. In this work, we demonstrate that CETs can be easily circumvented and present several side effects of concept erasure. For a comprehensive measurement of the robustness of CETs, we present Side Effect Evaluation (\see), an evaluation benchmark that consists of hierarchical and compositional prompts that describe objects and their attributes. This dataset and our automated evaluation pipeline quantify side effects of CETs across three aspects: impact on neighboring concepts, evasion of targets, and attribute leakage. Our experiments reveal that CETs can be circumvented by using superclass-subclass hierarchy and semantically similar prompts, such as compositional variants of the target. We show that CETs suffer from attribute leakage and counterintuitive phenomena of attention concentration or dispersal. We release our dataset, code, and evaluation tools to aid future work on robust concept erasure.</li>
</ul>

<h3>Title: Towards Source-Free Machine Unlearning</h3>
<ul>
<li><strong>Authors: </strong>Sk Miraj Ahmed, Umit Yigit Basaran, Dripta S. Raychaudhuri, Arindam Dutta, Rohit Kundu, Fahim Faisal Niloy, Basak Guler, Amit K. Roy-Chowdhury</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.15127">https://arxiv.org/abs/2508.15127</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.15127">https://arxiv.org/pdf/2508.15127</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.15127]] Towards Source-Free Machine Unlearning(https://arxiv.org/abs/2508.15127)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, robust</a></li>
<li><strong>Abstract: </strong>As machine learning becomes more pervasive and data privacy regulations evolve, the ability to remove private or copyrighted information from trained models is becoming an increasingly critical requirement. Existing unlearning methods often rely on the assumption of having access to the entire training dataset during the forgetting process. However, this assumption may not hold true in practical scenarios where the original training data may not be accessible, i.e., the source-free setting. To address this challenge, we focus on the source-free unlearning scenario, where an unlearning algorithm must be capable of removing specific data from a trained model without requiring access to the original training dataset. Building on recent work, we present a method that can estimate the Hessian of the unknown remaining training data, a crucial component required for efficient unlearning. Leveraging this estimation technique, our method enables efficient zero-shot unlearning while providing robust theoretical guarantees on the unlearning performance, while maintaining performance on the remaining data. Extensive experiments over a wide range of datasets verify the efficacy of our method.</li>
</ul>

<h3>Title: Identifying and Answering Questions with False Assumptions: An Interpretable Approach</h3>
<ul>
<li><strong>Authors: </strong>Zijie Wang, Eduardo Blanco</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.15139">https://arxiv.org/abs/2508.15139</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.15139">https://arxiv.org/pdf/2508.15139</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.15139]] Identifying and Answering Questions with False Assumptions: An Interpretable Approach(https://arxiv.org/abs/2508.15139)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>People often ask questions with false assumptions, a type of question that does not have regular answers. Answering such questions require first identifying the false assumptions. Large Language Models (LLMs) often generate misleading answers because of hallucinations. In this paper, we focus on identifying and answering questions with false assumptions in several domains. We first investigate to reduce the problem to fact verification. Then, we present an approach leveraging external evidence to mitigate hallucinations. Experiments with five LLMs demonstrate that (1) incorporating retrieved evidence is beneficial and (2) generating and validating atomic assumptions yields more improvements and provides an interpretable answer by specifying the false assumptions.</li>
</ul>

<h3>Title: A Robust BERT-Based Deep Learning Model for Automated Cancer Type Extraction from Unstructured Pathology Reports</h3>
<ul>
<li><strong>Authors: </strong>Minh Tran, Jeffery C. Chan, Min Li Huang, Maya Kansara, John P. Grady, Christine E. Napier, Subotheni Thavaneswaran, Mandy L. Ballinger, David M. Thomas, Frank P. Lin</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.15149">https://arxiv.org/abs/2508.15149</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.15149">https://arxiv.org/pdf/2508.15149</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.15149]] A Robust BERT-Based Deep Learning Model for Automated Cancer Type Extraction from Unstructured Pathology Reports(https://arxiv.org/abs/2508.15149)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, extraction, large language model</a></li>
<li><strong>Abstract: </strong>The accurate extraction of clinical information from electronic medical records is particularly critical to clinical research but require much trained expertise and manual labor. In this study we developed a robust system for automated extraction of the specific cancer types for the purpose of supporting precision oncology research. from pathology reports using a fine-tuned RoBERTa model. This model significantly outperformed the baseline model and a Large Language Model, Mistral 7B, achieving F1_Bertscore 0.98 and overall exact match of 80.61%. This fine-tuning approach demonstrates the potential for scalability that can integrate seamlessly into the molecular tumour board process. Fine-tuning domain-specific models for precision tasks in oncology, may pave the way for more efficient and accurate clinical information extraction.</li>
</ul>

<h3>Title: ContextualLVLM-Agent: A Holistic Framework for Multi-Turn Visually-Grounded Dialogue and Complex Instruction Following</h3>
<ul>
<li><strong>Authors: </strong>Seungmin Han, Haeun Kwon, Ji-jun Park, Taeyang Yoon</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.15164">https://arxiv.org/abs/2508.15164</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.15164">https://arxiv.org/pdf/2508.15164</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.15164]] ContextualLVLM-Agent: A Holistic Framework for Multi-Turn Visually-Grounded Dialogue and Complex Instruction Following(https://arxiv.org/abs/2508.15164)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, large language model</a></li>
<li><strong>Abstract: </strong>Despite significant advancements in Large Language Models (LLMs) and Large Vision-Language Models (LVLMs), current models still face substantial challenges in handling complex, multi-turn, and visually-grounded tasks that demand deep reasoning, sustained contextual understanding, entity tracking, and multi-step instruction following. Existing benchmarks often fall short in capturing the dynamism and intricacies of real-world multi-modal interactions, leading to issues such as context loss and visual hallucinations. To address these limitations, we introduce MMDR-Bench (Multi-Modal Dialogue Reasoning Benchmark), a novel dataset comprising 300 meticulously designed complex multi-turn dialogue scenarios, each averaging 5-7 turns and evaluated across six core dimensions including visual entity tracking and reasoning depth. Furthermore, we propose CoLVLM Agent (Contextual LVLM Agent), a holistic framework that enhances existing LVLMs with advanced reasoning and instruction following capabilities through an iterative "memory-perception-planning-execution" cycle, requiring no extensive re-training of the underlying models. Our extensive experiments on MMDR-Bench demonstrate that CoLVLM Agent consistently achieves superior performance, attaining an average human evaluation score of 4.03, notably surpassing state-of-the-art commercial models like GPT-4o (3.92) and Gemini 1.5 Pro (3.85). The framework exhibits significant advantages in reasoning depth, instruction adherence, and error suppression, and maintains robust performance over extended dialogue turns, validating the effectiveness of its modular design and iterative approach for complex multi-modal interactions.</li>
</ul>

<h3>Title: XDR-LVLM: An Explainable Vision-Language Large Model for Diabetic Retinopathy Diagnosis</h3>
<ul>
<li><strong>Authors: </strong>Masato Ito, Kaito Tanaka, Keisuke Matsuda, Aya Nakayama</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.15168">https://arxiv.org/abs/2508.15168</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.15168">https://arxiv.org/pdf/2508.15168</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.15168]] XDR-LVLM: An Explainable Vision-Language Large Model for Diabetic Retinopathy Diagnosis(https://arxiv.org/abs/2508.15168)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, interpretability</a></li>
<li><strong>Abstract: </strong>Diabetic Retinopathy (DR) is a major cause of global blindness, necessitating early and accurate diagnosis. While deep learning models have shown promise in DR detection, their black-box nature often hinders clinical adoption due to a lack of transparency and interpretability. To address this, we propose XDR-LVLM (eXplainable Diabetic Retinopathy Diagnosis with LVLM), a novel framework that leverages Vision-Language Large Models (LVLMs) for high-precision DR diagnosis coupled with natural language-based explanations. XDR-LVLM integrates a specialized Medical Vision Encoder, an LVLM Core, and employs Multi-task Prompt Engineering and Multi-stage Fine-tuning to deeply understand pathological features within fundus images and generate comprehensive diagnostic reports. These reports explicitly include DR severity grading, identification of key pathological concepts (e.g., hemorrhages, exudates, microaneurysms), and detailed explanations linking observed features to the diagnosis. Extensive experiments on the Diabetic Retinopathy (DDR) dataset demonstrate that XDR-LVLM achieves state-of-the-art performance, with a Balanced Accuracy of 84.55% and an F1 Score of 79.92% for disease diagnosis, and superior results for concept detection (77.95% BACC, 66.88% F1). Furthermore, human evaluations confirm the high fluency, accuracy, and clinical utility of the generated explanations, showcasing XDR-LVLM's ability to bridge the gap between automated diagnosis and clinical needs by providing robust and interpretable insights.</li>
</ul>

<h3>Title: MeSS: City Mesh-Guided Outdoor Scene Generation with Cross-View Consistent Diffusion</h3>
<ul>
<li><strong>Authors: </strong>Xuyang Chen, Zhijun Zhai, Kaixuan Zhou, Zengmao Wang, Jianan He, Dong Wang, Yanfeng Zhang, mingwei Sun, Rüdiger Westermann, Konrad Schindler, Liqiu Meng</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.15169">https://arxiv.org/abs/2508.15169</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.15169">https://arxiv.org/pdf/2508.15169</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.15169]] MeSS: City Mesh-Guided Outdoor Scene Generation with Cross-View Consistent Diffusion(https://arxiv.org/abs/2508.15169)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>Mesh models have become increasingly accessible for numerous cities; however, the lack of realistic textures restricts their application in virtual urban navigation and autonomous driving. To address this, this paper proposes MeSS (Meshbased Scene Synthesis) for generating high-quality, styleconsistent outdoor scenes with city mesh models serving as the geometric prior. While image and video diffusion models can leverage spatial layouts (such as depth maps or HD maps) as control conditions to generate street-level perspective views, they are not directly applicable to 3D scene generation. Video diffusion models excel at synthesizing consistent view sequences that depict scenes but often struggle to adhere to predefined camera paths or align accurately with rendered control videos. In contrast, image diffusion models, though unable to guarantee cross-view visual consistency, can produce more geometry-aligned results when combined with ControlNet. Building on this insight, our approach enhances image diffusion models by improving cross-view consistency. The pipeline comprises three key stages: first, we generate geometrically consistent sparse views using Cascaded Outpainting ControlNets; second, we propagate denser intermediate views via a component dubbed AGInpaint; and third, we globally eliminate visual inconsistencies (e.g., varying exposure) using the GCAlign module. Concurrently with generation, a 3D Gaussian Splatting (3DGS) scene is reconstructed by initializing Gaussian balls on the mesh surface. Our method outperforms existing approaches in both geometric alignment and generation quality. Once synthesized, the scene can be rendered in diverse styles through relighting and style transfer techniques.</li>
</ul>

<h3>Title: Conditional Cube Attack on Round-Reduced ASCON</h3>
<ul>
<li><strong>Authors: </strong>Zheng Li, Xiaoyang Dong, Xiaoyun Wang</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.15172">https://arxiv.org/abs/2508.15172</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.15172">https://arxiv.org/pdf/2508.15172</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.15172]] Conditional Cube Attack on Round-Reduced ASCON(https://arxiv.org/abs/2508.15172)</code><input type="text"></li>
<li><strong>Keywords: </strong>secure, attack</a></li>
<li><strong>Abstract: </strong>This paper evaluates the secure level of authenticated encryption \textsc{Ascon} against cube-like method. \textsc{Ascon} submitted by Dobraunig \emph{et~al.} is one of 16 survivors of the 3rd round CAESAR competition. The cube-like method is first used by Dinur \emph{et~al.} to analyze Keccak keyed modes. At CT-RSA 2015, Dobraunig \emph{et~al.} applied this method to 5/6-round reduced \textsc{Ascon}, whose structure is similar to Keccak keyed modes. However, for \textsc{Ascon} the non-linear layer is more complex and state is much smaller, which make it hard for the attackers to select enough cube variables that do not multiply with each other after the first round. This seems to be the reason why the best previous key-recovery attack is on 6-round \textsc{Ascon}, while for Keccak keyed modes (Keccak-MAC and Keyak) the attacked round is no less than 7-round. In this paper, we generalize the conditional cube attack proposed by Huang \emph{et~al.}, and find new cubes depending on some key bit conditions for 5/6-round reduced \textsc{Ascon}, and translate the previous theoretic 6-round attack with $2^{66}$ time complexity to a practical one with $2^{40}$ time complexity. Moreover, we propose the first 7-round key-recovery attack on \textsc{Ascon}. By introducing \emph{the cube-like key-subset technique}, we divide the full key space into many subsets according to different key conditions. For each key subset, we launch the cube tester to determine if the key falls into it. Finally, we recover the full key space by testing all the key subsets. The total time complexity is about $2^{103.9}$. In addition, for a weak-key subset, whose size is $2^{117}$, the attack is more efficient and costs only $2^{77}$ time complexity. Those attacks do not threaten the full round (12 rounds) \textsc{Ascon}.</li>
</ul>

<h3>Title: SafeLLM: Unlearning Harmful Outputs from Large Language Models against Jailbreak Attacks</h3>
<ul>
<li><strong>Authors: </strong>Xiangman Li, Xiaodong Wu, Qi Li, Jianbing Ni, Rongxing Lu</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.15182">https://arxiv.org/abs/2508.15182</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.15182">https://arxiv.org/pdf/2508.15182</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.15182]] SafeLLM: Unlearning Harmful Outputs from Large Language Models against Jailbreak Attacks(https://arxiv.org/abs/2508.15182)</code><input type="text"></li>
<li><strong>Keywords: </strong>defense, attack, robust, large language model</a></li>
<li><strong>Abstract: </strong>Jailbreak attacks pose a serious threat to the safety of Large Language Models (LLMs) by crafting adversarial prompts that bypass alignment mechanisms, causing the models to produce harmful, restricted, or biased content. In this paper, we propose SafeLLM, a novel unlearning-based defense framework that unlearn the harmful knowledge from LLMs while preserving linguistic fluency and general capabilities. SafeLLM employs a three-stage pipeline: (1) dynamic unsafe output detection using a hybrid approach that integrates external classifiers with model-internal evaluations; (2) token-level harmful content tracing through feedforward network (FFN) activations to localize harmful knowledge; and (3) constrained optimization to suppress unsafe behavior without degrading overall model quality. SafeLLM achieves targeted and irreversible forgetting by identifying and neutralizing FFN substructures responsible for harmful generation pathways. Extensive experiments on prominent LLMs (Vicuna, LLaMA, and GPT-J) across multiple jailbreak benchmarks show that SafeLLM substantially reduces attack success rates while maintaining high general-purpose performance. Compared to standard defense methods such as supervised fine-tuning and direct preference optimization, SafeLLM offers stronger safety guarantees, more precise control over harmful behavior, and greater robustness to unseen attacks. Moreover, SafeLLM maintains the general performance after the harmful knowledge unlearned. These results highlight unlearning as a promising direction for scalable and effective LLM safety.</li>
</ul>

<h3>Title: Private Hyperparameter Tuning with Ex-Post Guarantee</h3>
<ul>
<li><strong>Authors: </strong>Badih Ghazi, Pritish Kamath, Alexander Knop, Ravi Kumar, Pasin Manurangsi, Chiyuan Zhang</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.DS</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.15183">https://arxiv.org/abs/2508.15183</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.15183">https://arxiv.org/pdf/2508.15183</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.15183]] Private Hyperparameter Tuning with Ex-Post Guarantee(https://arxiv.org/abs/2508.15183)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy</a></li>
<li><strong>Abstract: </strong>The conventional approach in differential privacy (DP) literature formulates the privacy-utility trade-off with a "privacy-first" perspective: for a predetermined level of privacy, a certain utility is achievable. However, practitioners often operate under a "utility-first" paradigm, prioritizing a desired level of utility and then determining the corresponding privacy cost. Wu et al. [2019] initiated a formal study of this "utility-first" perspective by introducing ex-post DP. They demonstrated that by adding correlated Laplace noise and progressively reducing it on demand, a sequence of increasingly accurate estimates of a private parameter can be generated, with the privacy cost attributed only to the least noisy iterate released. This led to a Laplace mechanism variant that achieves a specified utility with minimal privacy loss. However, their work, and similar findings by Whitehouse et al. [2022], are primarily limited to simple mechanisms based on Laplace or Gaussian noise. In this paper, we significantly generalize these results. In particular, we extend the work of Wu et al. [2019] and Liu and Talwar [2019] to support any sequence of private estimators, incurring at most a doubling of the original privacy budget. Furthermore, we demonstrate that hyperparameter tuning for these estimators, including the selection of an optimal privacy budget, can be performed without additional privacy cost. Finally, we extend our results to ex-post Renyi DP, further broadening the applicability of utility-first privacy mechanisms.</li>
</ul>

<h3>Title: SurgWound-Bench: A Benchmark for Surgical Wound Diagnosis</h3>
<ul>
<li><strong>Authors: </strong>Jiahao Xu (Ohio State University, USA), Changchang Yin (Ohio State University Wexner Medical Center, USA), Odysseas Chatzipanagiotou (Ohio State University Wexner Medical Center, USA), Diamantis Tsilimigras (Ohio State University Wexner Medical Center, USA), Kevin Clear (Ohio State University Wexner Medical Center, USA), Bingsheng Yao (Northeastern University, USA), Dakuo Wang (Northeastern University, USA), Timothy Pawlik (Ohio State University Wexner Medical Center, USA), Ping Zhang (Ohio State University, USA)</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.15189">https://arxiv.org/abs/2508.15189</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.15189">https://arxiv.org/pdf/2508.15189</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.15189]] SurgWound-Bench: A Benchmark for Surgical Wound Diagnosis(https://arxiv.org/abs/2508.15189)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy</a></li>
<li><strong>Abstract: </strong>Surgical site infection (SSI) is one of the most common and costly healthcare-associated infections and and surgical wound care remains a significant clinical challenge in preventing SSIs and improving patient outcomes. While recent studies have explored the use of deep learning for preliminary surgical wound screening, progress has been hindered by concerns over data privacy and the high costs associated with expert annotation. Currently, no publicly available dataset or benchmark encompasses various types of surgical wounds, resulting in the absence of an open-source Surgical-Wound screening tool. To address this gap: (1) we present SurgWound, the first open-source dataset featuring a diverse array of surgical wound types. It contains 697 surgical wound images annotated by 3 professional surgeons with eight fine-grained clinical attributes. (2) Based on SurgWound, we introduce the first benchmark for surgical wound diagnosis, which includes visual question answering (VQA) and report generation tasks to comprehensively evaluate model performance. (3) Furthermore, we propose a three-stage learning framework, WoundQwen, for surgical wound diagnosis. In the first stage, we employ five independent MLLMs to accurately predict specific surgical wound characteristics. In the second stage, these predictions serve as additional knowledge inputs to two MLLMs responsible for diagnosing outcomes, which assess infection risk and guide subsequent interventions. In the third stage, we train a MLLM that integrates the diagnostic results from the previous two stages to produce a comprehensive report. This three-stage framework can analyze detailed surgical wound characteristics and provide subsequent instructions to patients based on surgical images, paving the way for personalized wound care, timely intervention, and improved patient outcomes.</li>
</ul>

<h3>Title: SemToken: Semantic-Aware Tokenization for Efficient Long-Context Language Modeling</h3>
<ul>
<li><strong>Authors: </strong>Dong Liu, Yanxuan Yu</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.15190">https://arxiv.org/abs/2508.15190</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.15190">https://arxiv.org/pdf/2508.15190</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.15190]] SemToken: Semantic-Aware Tokenization for Efficient Long-Context Language Modeling(https://arxiv.org/abs/2508.15190)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Tokenization plays a critical role in language modeling, yet existing approaches such as Byte-Pair Encoding (BPE) or WordPiece operate purely on frequency statistics, ignoring the underlying semantic structure of text. This leads to over-tokenization of semantically redundant spans and underutilization of contextual coherence, particularly in long-context scenarios. In this work, we propose \textbf{SemToken}, a semantic-aware tokenization framework that jointly reduces token redundancy and improves computation efficiency. SemToken first extracts contextual semantic embeddings via lightweight encoders and performs local semantic clustering to merge semantically equivalent tokens. Then, it allocates heterogeneous token granularity based on semantic density, allowing finer-grained tokenization in content-rich regions and coarser compression in repetitive or low-entropy spans. SemToken can be seamlessly integrated with modern language models and attention acceleration methods. Experiments on long-context language modeling benchmarks such as WikiText-103 and LongBench show that SemToken achieves up to $2.4\times$ reduction in token count and $1.9\times$ speedup, with negligible or no degradation in perplexity and downstream accuracy. Our findings suggest that semantic structure offers a promising new axis for optimizing tokenization and computation in large language models.</li>
</ul>

<h3>Title: Revisiting Pre-processing Group Fairness: A Modular Benchmarking Framework</h3>
<ul>
<li><strong>Authors: </strong>Brodie Oldfield, Ziqi Xu, Sevvandi Kandanaarachchi</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.15193">https://arxiv.org/abs/2508.15193</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.15193">https://arxiv.org/pdf/2508.15193</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.15193]] Revisiting Pre-processing Group Fairness: A Modular Benchmarking Framework(https://arxiv.org/abs/2508.15193)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, fair</a></li>
<li><strong>Abstract: </strong>As machine learning systems become increasingly integrated into high-stakes decision-making processes, ensuring fairness in algorithmic outcomes has become a critical concern. Methods to mitigate bias typically fall into three categories: pre-processing, in-processing, and post-processing. While significant attention has been devoted to the latter two, pre-processing methods, which operate at the data level and offer advantages such as model-agnosticism and improved privacy compliance, have received comparatively less focus and lack standardised evaluation tools. In this work, we introduce FairPrep, an extensible and modular benchmarking framework designed to evaluate fairness-aware pre-processing techniques on tabular datasets. Built on the AIF360 platform, FairPrep allows seamless integration of datasets, fairness interventions, and predictive models. It features a batch-processing interface that enables efficient experimentation and automatic reporting of fairness and utility metrics. By offering standardised pipelines and supporting reproducible evaluations, FairPrep fills a critical gap in the fairness benchmarking landscape and provides a practical foundation for advancing data-level fairness research.</li>
</ul>

<h3>Title: Frequency-adaptive tensor neural networks for high-dimensional multi-scale problems</h3>
<ul>
<li><strong>Authors: </strong>Jizu Huang, Rukang You, Tao Zhou</a></li>
<li><strong>Subjects: </strong>cs.LG, math-ph</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.15198">https://arxiv.org/abs/2508.15198</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.15198">https://arxiv.org/pdf/2508.15198</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.15198]] Frequency-adaptive tensor neural networks for high-dimensional multi-scale problems(https://arxiv.org/abs/2508.15198)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Tensor neural networks (TNNs) have demonstrated their superiority in solving high-dimensional problems. However, similar to conventional neural networks, TNNs are also influenced by the Frequency Principle, which limits their ability to accurately capture high-frequency features of the solution. In this work, we analyze the training dynamics of TNNs by Fourier analysis and enhance their expressivity for high-dimensional multi-scale problems by incorporating random Fourier features. Leveraging the inherent tensor structure of TNNs, we further propose a novel approach to extract frequency features of high-dimensional functions by performing the Discrete Fourier Transform to one-dimensional component functions. This strategy effectively mitigates the curse of dimensionality. Building on this idea, we propose a frequency-adaptive TNNs algorithm, which significantly improves the ability of TNNs in solving complex multi-scale problems. Extensive numerical experiments are performed to validate the effectiveness and robustness of the proposed frequency-adaptive TNNs algorithm.</li>
</ul>

<h3>Title: Fin-PRM: A Domain-Specialized Process Reward Model for Financial Reasoning in Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Yuanchen Zhou, Shuo Jiang, Jie Zhu, Junhui Li, Lifan Guo, Feng Chen, Chi Zhang</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.15202">https://arxiv.org/abs/2508.15202</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.15202">https://arxiv.org/pdf/2508.15202</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.15202]] Fin-PRM: A Domain-Specialized Process Reward Model for Financial Reasoning in Large Language Models(https://arxiv.org/abs/2508.15202)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Process Reward Models (PRMs) have emerged as a promising framework for supervising intermediate reasoning in large language models (LLMs), yet existing PRMs are primarily trained on general or Science, Technology, Engineering, and Mathematics (STEM) domains and fall short in domain-specific contexts such as finance, where reasoning is more structured, symbolic, and sensitive to factual and regulatory correctness. We introduce \textbf{Fin-PRM}, a domain-specialized, trajectory-aware PRM tailored to evaluate intermediate reasoning steps in financial tasks. Fin-PRM integrates step-level and trajectory-level reward supervision, enabling fine-grained evaluation of reasoning traces aligned with financial logic. We apply Fin-PRM in both offline and online reward learning settings, supporting three key applications: (i) selecting high-quality reasoning trajectories for distillation-based supervised fine-tuning, (ii) providing dense process-level rewards for reinforcement learning, and (iii) guiding reward-informed Best-of-N inference at test time. Experimental results on financial reasoning benchmarks, including CFLUE and FinQA, demonstrate that Fin-PRM consistently outperforms general-purpose PRMs and strong domain baselines in trajectory selection quality. Downstream models trained with Fin-PRM yield substantial improvements with baselines, with gains of 12.9\% in supervised learning, 5.2\% in reinforcement learning, and 5.1\% in test-time performance. These findings highlight the value of domain-specialized reward modeling for aligning LLMs with expert-level financial reasoning. Our project resources will be available at this https URL.</li>
</ul>

<h3>Title: DyMorph-B2I: Dynamic and Morphology-Guided Binary-to-Instance Segmentation for Renal Pathology</h3>
<ul>
<li><strong>Authors: </strong>Leiyue Zhao, Yuechen Yang, Yanfan Zhu, Haichun Yang, Yuankai Huo, Paul D. Simonson, Kenji Ikemura, Mert R. Sabuncu, Yihe Yang, Ruining Deng</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.15208">https://arxiv.org/abs/2508.15208</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.15208">https://arxiv.org/pdf/2508.15208</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.15208]] DyMorph-B2I: Dynamic and Morphology-Guided Binary-to-Instance Segmentation for Renal Pathology(https://arxiv.org/abs/2508.15208)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, segmentation</a></li>
<li><strong>Abstract: </strong>Accurate morphological quantification of renal pathology functional units relies on instance-level segmentation, yet most existing datasets and automated methods provide only binary (semantic) masks, limiting the precision of downstream analyses. Although classical post-processing techniques such as watershed, morphological operations, and skeletonization, are often used to separate semantic masks into instances, their individual effectiveness is constrained by the diverse morphologies and complex connectivity found in renal tissue. In this study, we present DyMorph-B2I, a dynamic, morphology-guided binary-to-instance segmentation pipeline tailored for renal pathology. Our approach integrates watershed, skeletonization, and morphological operations within a unified framework, complemented by adaptive geometric refinement and customizable hyperparameter tuning for each class of functional unit. Through systematic parameter optimization, DyMorph-B2I robustly separates adherent and heterogeneous structures present in binary masks. Experimental results demonstrate that our method outperforms individual classical approaches and naïve combinations, enabling superior instance separation and facilitating more accurate morphometric analysis in renal pathology workflows. The pipeline is publicly available at: this https URL.</li>
</ul>

<h3>Title: SparK: Query-Aware Unstructured Sparsity with Recoverable KV Cache Channel Pruning</h3>
<ul>
<li><strong>Authors: </strong>Huanxuan Liao, Yixing Xu, Shizhu He, Guanchen Li, Xuanwu Yin, Dong Li, Emad Barsoum, Jun Zhao, Kang Liu</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.15212">https://arxiv.org/abs/2508.15212</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.15212">https://arxiv.org/pdf/2508.15212</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.15212]] SparK: Query-Aware Unstructured Sparsity with Recoverable KV Cache Channel Pruning(https://arxiv.org/abs/2508.15212)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, large language model</a></li>
<li><strong>Abstract: </strong>Long-context inference in large language models (LLMs) is increasingly constrained by the KV cache bottleneck: memory usage grows linearly with sequence length, while attention computation scales quadratically. Existing approaches address this issue by compressing the KV cache along the temporal axis through strategies such as token eviction or merging to reduce memory and computational overhead. However, these methods often neglect fine-grained importance variations across feature dimensions (i.e., the channel axis), thereby limiting their ability to effectively balance efficiency and model accuracy. In reality, we observe that channel saliency varies dramatically across both queries and positions: certain feature channels carry near-zero information for a given query, while others spike in relevance. To address this oversight, we propose SPARK, a training-free plug-and-play method that applies unstructured sparsity by pruning KV at the channel level, while dynamically restoring the pruned entries during attention score computation. Notably, our approach is orthogonal to existing KV compression and quantization techniques, making it compatible for integration with them to achieve further acceleration. By reducing channel-level redundancy, SPARK enables processing of longer sequences within the same memory budget. For sequences of equal length, SPARK not only preserves or improves model accuracy but also reduces KV cache storage by over 30% compared to eviction-based methods. Furthermore, even with an aggressive pruning ratio of 80%, SPARK maintains performance with less degradation than 5% compared to the baseline eviction method, demonstrating its robustness and effectiveness. Our code will be available at this https URL.</li>
</ul>

<h3>Title: Select to Know: An Internal-External Knowledge Self-Selection Framework for Domain-Specific Question Answering</h3>
<ul>
<li><strong>Authors: </strong>Bolei He, Xinran He, Run Shao, Shanfu Shu, Xianwei Xue, Mingquan Cheng, Haifeng Li, Zhenhua Ling</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.15213">https://arxiv.org/abs/2508.15213</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.15213">https://arxiv.org/pdf/2508.15213</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.15213]] Select to Know: An Internal-External Knowledge Self-Selection Framework for Domain-Specific Question Answering(https://arxiv.org/abs/2508.15213)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large Language Models (LLMs) perform well in general QA but often struggle in domain-specific scenarios. Retrieval-Augmented Generation (RAG) introduces external knowledge but suffers from hallucinations and latency due to noisy retrievals. Continued pretraining internalizes domain knowledge but is costly and lacks cross-domain flexibility. We attribute this challenge to the long-tail distribution of domain knowledge, which leaves partial yet useful internal knowledge underutilized. We further argue that knowledge acquisition should be progressive, mirroring human learning: first understanding concepts, then applying them to complex reasoning. To address this, we propose Selct2Know (S2K), a cost-effective framework that internalizes domain knowledge through an internal-external knowledge self-selection strategy and selective supervised fine-tuning. We also introduce a structured reasoning data generation pipeline and integrate GRPO to enhance reasoning ability. Experiments on medical, legal, and financial QA benchmarks show that S2K consistently outperforms existing methods and matches domain-pretrained LLMs with significantly lower cost.</li>
</ul>

<h3>Title: Self-Guided Function Calling in Large Language Models via Stepwise Experience Recall</h3>
<ul>
<li><strong>Authors: </strong>Sijia Cui, Aiyao He, Shuai Xu, Hongming Zhang, Yanna Wang, Qingyang Zhang, Yajing Wang, Bo Xu</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.15214">https://arxiv.org/abs/2508.15214</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.15214">https://arxiv.org/pdf/2508.15214</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.15214]] Self-Guided Function Calling in Large Language Models via Stepwise Experience Recall(https://arxiv.org/abs/2508.15214)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Function calling enables large language models (LLMs) to interact with external systems by leveraging tools and APIs. When faced with multi-step tool usage, LLMs still struggle with tool selection, parameter generation, and tool-chain planning. Existing methods typically rely on manually designing task-specific demonstrations, or retrieving from a curated library. These approaches demand substantial expert effort and prompt engineering becomes increasingly complex and inefficient as tool diversity and task difficulty scale. To address these challenges, we propose a self-guided method, Stepwise Experience Recall (SEER), which performs fine-grained, stepwise retrieval from a continually updated experience pool. Instead of relying on static or manually curated library, SEER incrementally augments the experience pool with past successful trajectories, enabling continuous expansion of the pool and improved model performance over time. Evaluated on the ToolQA benchmark, SEER achieves an average improvement of 6.1\% on easy and 4.7\% on hard questions. We further test SEER on $\tau$-bench, which includes two real-world domains. Powered by Qwen2.5-7B and Qwen2.5-72B models, SEER demonstrates substantial accuracy gains of 7.44\% and 23.38\%, respectively.</li>
</ul>

<h3>Title: SleepDIFFormer: Sleep Stage Classification via Multivariate Differential Transformer</h3>
<ul>
<li><strong>Authors: </strong>Benjamin Wei Hao Chin, Yuin Torng Yew, Haocheng Wu, Lanxin Liang, Chow Khuen Chan, Norita Mohd Zain, Siti Balqis Samdin, Sim Kuan Goh</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.15215">https://arxiv.org/abs/2508.15215</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.15215">https://arxiv.org/pdf/2508.15215</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.15215]] SleepDIFFormer: Sleep Stage Classification via Multivariate Differential Transformer(https://arxiv.org/abs/2508.15215)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Classification of sleep stages is essential for assessing sleep quality and diagnosing sleep disorders such as insomnia. However, manual inspection of EEG characteristics for each stage is time-consuming and prone to human error. Although machine learning and deep learning methods have been actively developed, they continue to face challenges from the non-stationarity and variability of electroencephalography (EEG) and electrooculography (EOG) signals, often leading to poor generalization on unseen datasets. This research proposed a Sleep Stage Classification method by developing Multivariate Differential Transformer (SleepDIFFormer) for joint EEG and EOG representation learning. Specifically, SleepDIFFormer was developed to process EEG and EOG signals using our Multivariate Differential Transformer Architecture (MDTA) for time series, trained with cross-domain alignment. Our method mitigated spatial and temporal attention noise while learning a domain-invariant joint EEG-EOG representation through feature distribution alignment, thereby enabling generalization to unseen target datasets. Empirically, we evaluated our method on five different sleep staging datasets and compared it with existing approaches, achieving state-of-the-art performance. We also conducted thorough ablation analyses of SleepDIFFormer and interpreted the differential attention weights, highlighting their relevance to characteristic sleep EEG patterns. These findings have implications for advancing automated sleep stage classification and its application to sleep quality assessment. Our source code is publicly available at this https URL</li>
</ul>

<h3>Title: Are Checklists Really Useful for Automatic Evaluation of Generative Tasks?</h3>
<ul>
<li><strong>Authors: </strong>Momoka Furuhashi, Kouta Nakayama, Takashi Kodama, Saku Sugawara</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.15218">https://arxiv.org/abs/2508.15218</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.15218">https://arxiv.org/pdf/2508.15218</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.15218]] Are Checklists Really Useful for Automatic Evaluation of Generative Tasks?(https://arxiv.org/abs/2508.15218)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative, large language model</a></li>
<li><strong>Abstract: </strong>Automatic evaluation of generative tasks using large language models faces challenges due to ambiguous criteria. Although automatic checklist generation is a potentially promising approach, its usefulness remains underexplored. We investigate whether checklists should be used for all questions or selectively, generate them using six methods, evaluate their effectiveness across eight model sizes, and identify checklist items that correlate with human evaluations. Through experiments on pairwise comparison and direct scoring tasks, we find that selective checklist use tends to improve evaluation performance in pairwise settings, while its benefits are less consistent in direct scoring. Our analysis also shows that even checklist items with low correlation to human scores often reflect human-written criteria, indicating potential inconsistencies in human evaluation. These findings highlight the need to more clearly define objective evaluation criteria to guide both human and automatic evaluations. \footnote{Our code is available at~this https URL</li>
</ul>

<h3>Title: Locally Pareto-Optimal Interpretations for Black-Box Machine Learning Models</h3>
<ul>
<li><strong>Authors: </strong>Aniruddha Joshi, Supratik Chakraborty, S Akshay, Shetal Shah, Hazem Torfah, Sanjit Seshia</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.LO</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.15220">https://arxiv.org/abs/2508.15220</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.15220">https://arxiv.org/pdf/2508.15220</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.15220]] Locally Pareto-Optimal Interpretations for Black-Box Machine Learning Models(https://arxiv.org/abs/2508.15220)</code><input type="text"></li>
<li><strong>Keywords: </strong>explainability</a></li>
<li><strong>Abstract: </strong>Creating meaningful interpretations for black-box machine learning models involves balancing two often conflicting objectives: accuracy and explainability. Exploring the trade-off between these objectives is essential for developing trustworthy interpretations. While many techniques for multi-objective interpretation synthesis have been developed, they typically lack formal guarantees on the Pareto-optimality of the results. Methods that do provide such guarantees, on the other hand, often face severe scalability limitations when exploring the Pareto-optimal space. To address this, we develop a framework based on local optimality guarantees that enables more scalable synthesis of interpretations. Specifically, we consider the problem of synthesizing a set of Pareto-optimal interpretations with local optimality guarantees, within the immediate neighborhood of each solution. Our approach begins with a multi-objective learning or search technique, such as Multi-Objective Monte Carlo Tree Search, to generate a best-effort set of Pareto-optimal candidates with respect to accuracy and explainability. We then verify local optimality for each candidate as a Boolean satisfiability problem, which we solve using a SAT solver. We demonstrate the efficacy of our approach on a set of benchmarks, comparing it against previous methods for exploring the Pareto-optimal front of interpretations. In particular, we show that our approach yields interpretations that closely match those synthesized by methods offering global guarantees.</li>
</ul>

<h3>Title: Learning ECG Representations via Poly-Window Contrastive Learning</h3>
<ul>
<li><strong>Authors: </strong>Yi Yuan, Joseph Van Duyn, Runze Yan, Zhuoyi Huang, Sulaiman Vesal, Sergey Plis, Xiao Hu, Gloria Hyunjung Kwak, Ran Xiao, Alex Fedorov</a></li>
<li><strong>Subjects: </strong>cs.LG, eess.SP</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.15225">https://arxiv.org/abs/2508.15225</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.15225">https://arxiv.org/pdf/2508.15225</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.15225]] Learning ECG Representations via Poly-Window Contrastive Learning(https://arxiv.org/abs/2508.15225)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Electrocardiogram (ECG) analysis is foundational for cardiovascular disease diagnosis, yet the performance of deep learning models is often constrained by limited access to annotated data. Self-supervised contrastive learning has emerged as a powerful approach for learning robust ECG representations from unlabeled signals. However, most existing methods generate only pairwise augmented views and fail to leverage the rich temporal structure of ECG recordings. In this work, we present a poly-window contrastive learning framework. We extract multiple temporal windows from each ECG instance to construct positive pairs and maximize their agreement via statistics. Inspired by the principle of slow feature analysis, our approach explicitly encourages the model to learn temporally invariant and physiologically meaningful features that persist across time. We validate our approach through extensive experiments and ablation studies on the PTB-XL dataset. Our results demonstrate that poly-window contrastive learning consistently outperforms conventional two-view methods in multi-label superclass classification, achieving higher AUROC (0.891 vs. 0.888) and F1 scores (0.680 vs. 0.679) while requiring up to four times fewer pre-training epochs (32 vs. 128) and 14.8% in total wall clock pre-training time reduction. Despite processing multiple windows per sample, we achieve a significant reduction in the number of training epochs and total computation time, making our method practical for training foundational models. Through extensive ablations, we identify optimal design choices and demonstrate robustness across various hyperparameters. These findings establish poly-window contrastive learning as a highly efficient and scalable paradigm for automated ECG analysis and provide a promising general framework for self-supervised representation learning in biomedical time-series data.</li>
</ul>

<h3>Title: Collaborative Multi-Modal Coding for High-Quality 3D Generation</h3>
<ul>
<li><strong>Authors: </strong>Ziang Cao, Zhaoxi Chen, Liang Pan, Ziwei Liu</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.15228">https://arxiv.org/abs/2508.15228</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.15228">https://arxiv.org/pdf/2508.15228</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.15228]] Collaborative Multi-Modal Coding for High-Quality 3D Generation(https://arxiv.org/abs/2508.15228)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, diffusion, generative</a></li>
<li><strong>Abstract: </strong>3D content inherently encompasses multi-modal characteristics and can be projected into different modalities (e.g., RGB images, RGBD, and point clouds). Each modality exhibits distinct advantages in 3D asset modeling: RGB images contain vivid 3D textures, whereas point clouds define fine-grained 3D geometries. However, most existing 3D-native generative architectures either operate predominantly within single-modality paradigms-thus overlooking the complementary benefits of multi-modality data-or restrict themselves to 3D structures, thereby limiting the scope of available training datasets. To holistically harness multi-modalities for 3D modeling, we present TriMM, the first feed-forward 3D-native generative model that learns from basic multi-modalities (e.g., RGB, RGBD, and point cloud). Specifically, 1) TriMM first introduces collaborative multi-modal coding, which integrates modality-specific features while preserving their unique representational strengths. 2) Furthermore, auxiliary 2D and 3D supervision are introduced to raise the robustness and performance of multi-modal coding. 3) Based on the embedded multi-modal code, TriMM employs a triplane latent diffusion model to generate 3D assets of superior quality, enhancing both the texture and the geometric detail. Extensive experiments on multiple well-known datasets demonstrate that TriMM, by effectively leveraging multi-modality, achieves competitive performance with models trained on large-scale datasets, despite utilizing a small amount of training data. Furthermore, we conduct additional experiments on recent RGB-D datasets, verifying the feasibility of incorporating other multi-modal datasets into 3D generation.</li>
</ul>

<h3>Title: AeroDuo: Aerial Duo for UAV-based Vision and Language Navigation</h3>
<ul>
<li><strong>Authors: </strong>Ruipu Wu, Yige Zhang, Jinyu Chen, Linjiang Huang, Shifeng Zhang, Xu Zhou, Liang Wang, Si Liu</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.15232">https://arxiv.org/abs/2508.15232</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.15232">https://arxiv.org/pdf/2508.15232</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.15232]] AeroDuo: Aerial Duo for UAV-based Vision and Language Navigation(https://arxiv.org/abs/2508.15232)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Aerial Vision-and-Language Navigation (VLN) is an emerging task that enables Unmanned Aerial Vehicles (UAVs) to navigate outdoor environments using natural language instructions and visual cues. However, due to the extended trajectories and complex maneuverability of UAVs, achieving reliable UAV-VLN performance is challenging and often requires human intervention or overly detailed instructions. To harness the advantages of UAVs' high mobility, which could provide multi-grained perspectives, while maintaining a manageable motion space for learning, we introduce a novel task called Dual-Altitude UAV Collaborative VLN (DuAl-VLN). In this task, two UAVs operate at distinct altitudes: a high-altitude UAV responsible for broad environmental reasoning, and a low-altitude UAV tasked with precise navigation. To support the training and evaluation of the DuAl-VLN, we construct the HaL-13k, a dataset comprising 13,838 collaborative high-low UAV demonstration trajectories, each paired with target-oriented language instructions. This dataset includes both unseen maps and an unseen object validation set to systematically evaluate the model's generalization capabilities across novel environments and unfamiliar targets. To consolidate their complementary strengths, we propose a dual-UAV collaborative VLN framework, AeroDuo, where the high-altitude UAV integrates a multimodal large language model (Pilot-LLM) for target reasoning, while the low-altitude UAV employs a lightweight multi-stage policy for navigation and target grounding. The two UAVs work collaboratively and only exchange minimal coordinate information to ensure efficiency.</li>
</ul>

<h3>Title: Pretrained Diffusion Models Are Inherently Skipped-Step Samplers</h3>
<ul>
<li><strong>Authors: </strong>Wenju Xu</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.15233">https://arxiv.org/abs/2508.15233</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.15233">https://arxiv.org/pdf/2508.15233</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.15233]] Pretrained Diffusion Models Are Inherently Skipped-Step Samplers(https://arxiv.org/abs/2508.15233)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>Diffusion models have been achieving state-of-the-art results across various generation tasks. However, a notable drawback is their sequential generation process, requiring long-sequence step-by-step generation. Existing methods, such as DDIM, attempt to reduce sampling steps by constructing a class of non-Markovian diffusion processes that maintain the same training objective. However, there remains a gap in understanding whether the original diffusion process can achieve the same efficiency without resorting to non-Markovian processes. In this paper, we provide a confirmative answer and introduce skipped-step sampling, a mechanism that bypasses multiple intermediate denoising steps in the iterative generation process, in contrast with the traditional step-by-step refinement of standard diffusion inference. Crucially, we demonstrate that this skipped-step sampling mechanism is derived from the same training objective as the standard diffusion model, indicating that accelerated sampling via skipped-step sampling via a Markovian way is an intrinsic property of pretrained diffusion models. Additionally, we propose an enhanced generation method by integrating our accelerated sampling technique with DDIM. Extensive experiments on popular pretrained diffusion models, including the OpenAI ADM, Stable Diffusion, and Open Sora models, show that our method achieves high-quality generation with significantly reduced sampling steps.</li>
</ul>

<h3>Title: WangchanThaiInstruct: An instruction-following Dataset for Culture-Aware, Multitask, and Multi-domain Evaluation in Thai</h3>
<ul>
<li><strong>Authors: </strong>Peerat Limkonchotiwat, Pume Tuchinda, Lalita Lowphansirikul, Surapon Nonesung, Panuthep Tasawong, Alham Fikri Aji, Can Udomcharoenchaikit, Sarana Nutanong</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.15239">https://arxiv.org/abs/2508.15239</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.15239">https://arxiv.org/pdf/2508.15239</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.15239]] WangchanThaiInstruct: An instruction-following Dataset for Culture-Aware, Multitask, and Multi-domain Evaluation in Thai(https://arxiv.org/abs/2508.15239)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large language models excel at instruction-following in English, but their performance in low-resource languages like Thai remains underexplored. Existing benchmarks often rely on translations, missing cultural and domain-specific nuances needed for real-world use. We present WangchanThaiInstruct, a human-authored Thai dataset for evaluation and instruction tuning, covering four professional domains and seven task types. Created through a multi-stage quality control process with annotators, domain experts, and AI researchers, WangchanThaiInstruct supports two studies: (1) a zero-shot evaluation showing performance gaps on culturally and professionally specific tasks, and (2) an instruction tuning study with ablations isolating the effect of native supervision. Models fine-tuned on WangchanThaiInstruct outperform those using translated data in both in-domain and out-of-domain benchmarks. These findings underscore the need for culturally and professionally grounded instruction data to improve LLM alignment in low-resource, linguistically diverse settings.</li>
</ul>

<h3>Title: Comp-X: On Defining an Interactive Learned Image Compression Paradigm With Expert-driven LLM Agent</h3>
<ul>
<li><strong>Authors: </strong>Yixin Gao, Xin Li, Xiaohan Pan, Runsen Feng, Bingchen Li, Yunpeng Qi, Yiting Lu, Zhengxue Cheng, Zhibo Chen, Jörn Ostermann</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.15243">https://arxiv.org/abs/2508.15243</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.15243">https://arxiv.org/pdf/2508.15243</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.15243]] Comp-X: On Defining an Interactive Learned Image Compression Paradigm With Expert-driven LLM Agent(https://arxiv.org/abs/2508.15243)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>We present Comp-X, the first intelligently interactive image compression paradigm empowered by the impressive reasoning capability of large language model (LLM) agent. Notably, commonly used image codecs usually suffer from limited coding modes and rely on manual mode selection by engineers, making them unfriendly for unprofessional users. To overcome this, we advance the evolution of image coding paradigm by introducing three key innovations: (i) multi-functional coding framework, which unifies different coding modes of various objective/requirements, including human-machine perception, variable coding, and spatial bit allocation, into one framework. (ii) interactive coding agent, where we propose an augmented in-context learning method with coding expert feedback to teach the LLM agent how to understand the coding request, mode selection, and the use of the coding tools. (iii) IIC-bench, the first dedicated benchmark comprising diverse user requests and the corresponding annotations from coding experts, which is systematically designed for intelligently interactive image compression evaluation. Extensive experimental results demonstrate that our proposed Comp-X can understand the coding requests efficiently and achieve impressive textual interaction capability. Meanwhile, it can maintain comparable compression performance even with a single coding framework, providing a promising avenue for artificial general intelligence (AGI) in image compression.</li>
</ul>

<h3>Title: EMNLP: Educator-role Moral and Normative Large Language Models Profiling</h3>
<ul>
<li><strong>Authors: </strong>Yilin Jiang, Mingzi Zhang, Sheng Jin, Zengyi Yu, Xiangjie Kong, Binghao Tu</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.15250">https://arxiv.org/abs/2508.15250</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.15250">https://arxiv.org/pdf/2508.15250</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.15250]] EMNLP: Educator-role Moral and Normative Large Language Models Profiling(https://arxiv.org/abs/2508.15250)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Simulating Professions (SP) enables Large Language Models (LLMs) to emulate professional roles. However, comprehensive psychological and ethical evaluation in these contexts remains lacking. This paper introduces EMNLP, an Educator-role Moral and Normative LLMs Profiling framework for personality profiling, moral development stage measurement, and ethical risk under soft prompt injection. EMNLP extends existing scales and constructs 88 teacher-specific moral dilemmas, enabling profession-oriented comparison with human teachers. A targeted soft prompt injection set evaluates compliance and vulnerability in teacher SP. Experiments on 12 LLMs show teacher-role LLMs exhibit more idealized and polarized personalities than human teachers, excel in abstract moral reasoning, but struggle with emotionally complex situations. Models with stronger reasoning are more vulnerable to harmful prompt injection, revealing a paradox between capability and safety. The model temperature and other hyperparameters have limited influence except in some risk behaviors. This paper presents the first benchmark to assess ethical and psychological alignment of teacher-role LLMs for educational AI. Resources are available at this https URL.</li>
</ul>

<h3>Title: Retrieval-Augmented Review Generation for Poisoning Recommender Systems</h3>
<ul>
<li><strong>Authors: </strong>Shiyi Yang, Xinshu Li, Guanglin Zhou, Chen Wang, Xiwei Xu, Liming Zhu, Lina Yao</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.CL, cs.IR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.15252">https://arxiv.org/abs/2508.15252</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.15252">https://arxiv.org/pdf/2508.15252</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.15252]] Retrieval-Augmented Review Generation for Poisoning Recommender Systems(https://arxiv.org/abs/2508.15252)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, privacy, attack, robust</a></li>
<li><strong>Abstract: </strong>Recent studies have shown that recommender systems (RSs) are highly vulnerable to data poisoning attacks, where malicious actors inject fake user profiles, including a group of well-designed fake ratings, to manipulate recommendations. Due to security and privacy constraints in practice, attackers typically possess limited knowledge of the victim system and thus need to craft profiles that have transferability across black-box RSs. To maximize the attack impact, the profiles often remains imperceptible. However, generating such high-quality profiles with the restricted resources is challenging. Some works suggest incorporating fake textual reviews to strengthen the profiles; yet, the poor quality of the reviews largely undermines the attack effectiveness and imperceptibility under the practical setting. To tackle the above challenges, in this paper, we propose to enhance the quality of the review text by harnessing in-context learning (ICL) capabilities of multimodal foundation models. To this end, we introduce a demonstration retrieval algorithm and a text style transfer strategy to augment the navie ICL. Specifically, we propose a novel practical attack framework named RAGAN to generate high-quality fake user profiles, which can gain insights into the robustness of RSs. The profiles are generated by a jailbreaker and collaboratively optimized on an instructional agent and a guardian to improve the attack transferability and imperceptibility. Comprehensive experiments on various real-world datasets demonstrate that RAGAN achieves the state-of-the-art poisoning attack performance.</li>
</ul>

<h3>Title: Conflict-Aware Soft Prompting for Retrieval-Augmented Generation</h3>
<ul>
<li><strong>Authors: </strong>Eunseong Choi, June Park, Hyeri Lee, Jongwuk Lee</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.15253">https://arxiv.org/abs/2508.15253</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.15253">https://arxiv.org/pdf/2508.15253</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.15253]] Conflict-Aware Soft Prompting for Retrieval-Augmented Generation(https://arxiv.org/abs/2508.15253)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Retrieval-augmented generation (RAG) enhances the capabilities of large language models (LLMs) by incorporating external knowledge into their input prompts. However, when the retrieved context contradicts the LLM's parametric knowledge, it often fails to resolve the conflict between incorrect external context and correct parametric knowledge, known as context-memory conflict. To tackle this problem, we introduce Conflict-Aware REtrieval-Augmented Generation (CARE), consisting of a context assessor and a base LLM. The context assessor encodes compact memory token embeddings from raw context tokens. Through grounded/adversarial soft prompting, the context assessor is trained to discern unreliable context and capture a guidance signal that directs reasoning toward the more reliable knowledge source. Extensive experiments show that CARE effectively mitigates context-memory conflicts, leading to an average performance gain of 5.0\% on QA and fact-checking benchmarks, establishing a promising direction for trustworthy and adaptive RAG systems.</li>
</ul>

<h3>Title: Normal and Abnormal Pathology Knowledge-Augmented Vision-Language Model for Anomaly Detection in Pathology Images</h3>
<ul>
<li><strong>Authors: </strong>Jinsol Song, Jiamu Wang, Anh Tien Nguyen, Keunho Byeon, Sangjeong Ahn, Sung Hak Lee, Jin Tae Kwak</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.15256">https://arxiv.org/abs/2508.15256</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.15256">https://arxiv.org/pdf/2508.15256</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.15256]] Normal and Abnormal Pathology Knowledge-Augmented Vision-Language Model for Anomaly Detection in Pathology Images(https://arxiv.org/abs/2508.15256)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, interpretability</a></li>
<li><strong>Abstract: </strong>Anomaly detection in computational pathology aims to identify rare and scarce anomalies where disease-related data are often limited or missing. Existing anomaly detection methods, primarily designed for industrial settings, face limitations in pathology due to computational constraints, diverse tissue structures, and lack of interpretability. To address these challenges, we propose Ano-NAViLa, a Normal and Abnormal pathology knowledge-augmented Vision-Language model for Anomaly detection in pathology images. Ano-NAViLa is built on a pre-trained vision-language model with a lightweight trainable MLP. By incorporating both normal and abnormal pathology knowledge, Ano-NAViLa enhances accuracy and robustness to variability in pathology images and provides interpretability through image-text associations. Evaluated on two lymph node datasets from different organs, Ano-NAViLa achieves the state-of-the-art performance in anomaly detection and localization, outperforming competing models.</li>
</ul>

<h3>Title: Deep Think with Confidence</h3>
<ul>
<li><strong>Authors: </strong>Yichao Fu, Xuewei Wang, Yuandong Tian, Jiawei Zhao</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.15260">https://arxiv.org/abs/2508.15260</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.15260">https://arxiv.org/pdf/2508.15260</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.15260]] Deep Think with Confidence(https://arxiv.org/abs/2508.15260)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large Language Models (LLMs) have shown great potential in reasoning tasks through test-time scaling methods like self-consistency with majority voting. However, this approach often leads to diminishing returns in accuracy and high computational overhead. To address these challenges, we introduce Deep Think with Confidence (DeepConf), a simple yet powerful method that enhances both reasoning efficiency and performance at test time. DeepConf leverages model-internal confidence signals to dynamically filter out low-quality reasoning traces during or after generation. It requires no additional model training or hyperparameter tuning and can be seamlessly integrated into existing serving frameworks. We evaluate DeepConf across a variety of reasoning tasks and the latest open-source models, including Qwen 3 and GPT-OSS series. Notably, on challenging benchmarks such as AIME 2025, DeepConf@512 achieves up to 99.9% accuracy and reduces generated tokens by up to 84.7% compared to full parallel thinking.</li>
</ul>

<h3>Title: RATopo: Improving Lane Topology Reasoning via Redundancy Assignment</h3>
<ul>
<li><strong>Authors: </strong>Han Li, Shaofei Huang, Longfei Xu, Yulu Gao, Beipeng Mu, Si Liu</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.15272">https://arxiv.org/abs/2508.15272</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.15272">https://arxiv.org/pdf/2508.15272</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.15272]] RATopo: Improving Lane Topology Reasoning via Redundancy Assignment(https://arxiv.org/abs/2508.15272)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Lane topology reasoning plays a critical role in autonomous driving by modeling the connections among lanes and the topological relationships between lanes and traffic elements. Most existing methods adopt a first-detect-then-reason paradigm, where topological relationships are supervised based on the one-to-one assignment results obtained during the detection stage. This supervision strategy results in suboptimal topology reasoning performance due to the limited range of valid supervision. In this paper, we propose RATopo, a Redundancy Assignment strategy for lane Topology reasoning that enables quantity-rich and geometry-diverse topology supervision. Specifically, we restructure the Transformer decoder by swapping the cross-attention and self-attention layers. This allows redundant lane predictions to be retained before suppression, enabling effective one-to-many assignment. We also instantiate multiple parallel cross-attention blocks with independent parameters, which further enhances the diversity of detected lanes. Extensive experiments on OpenLane-V2 demonstrate that our RATopo strategy is model-agnostic and can be seamlessly integrated into existing topology reasoning frameworks, consistently improving both lane-lane and lane-traffic topology performance.</li>
</ul>

<h3>Title: TComQA: Extracting Temporal Commonsense from Text</h3>
<ul>
<li><strong>Authors: </strong>Lekshmi R Nair, Arun Sankar, Koninika Pal</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.IR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.15274">https://arxiv.org/abs/2508.15274</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.15274">https://arxiv.org/pdf/2508.15274</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.15274]] TComQA: Extracting Temporal Commonsense from Text(https://arxiv.org/abs/2508.15274)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, extraction, large language model</a></li>
<li><strong>Abstract: </strong>Understanding events necessitates grasping their temporal context, which is often not explicitly stated in natural language. For example, it is not a trivial task for a machine to infer that a museum tour may last for a few hours, but can not take months. Recent studies indicate that even advanced large language models (LLMs) struggle in generating text that require reasoning with temporal commonsense due to its infrequent explicit mention in text. Therefore, automatically mining temporal commonsense for events enables the creation of robust language models. In this work, we investigate the capacity of LLMs to extract temporal commonsense from text and evaluate multiple experimental setups to assess their effectiveness. Here, we propose a temporal commonsense extraction pipeline that leverages LLMs to automatically mine temporal commonsense and use it to construct TComQA, a dataset derived from SAMSum and RealNews corpora. TComQA has been validated through crowdsourcing and achieves over 80\% precision in extracting temporal commonsense. The model trained with TComQA also outperforms an LLM fine-tuned on existing dataset of temporal question answering task.</li>
</ul>

<h3>Title: Evaluating Knowledge Graph Complexity via Semantic, Spectral, and Structural Metrics for Link Prediction</h3>
<ul>
<li><strong>Authors: </strong>Haji Gul, Abul Ghani Naim, Ajaz Ahmad Bhat</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.15291">https://arxiv.org/abs/2508.15291</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.15291">https://arxiv.org/pdf/2508.15291</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.15291]] Evaluating Knowledge Graph Complexity via Semantic, Spectral, and Structural Metrics for Link Prediction(https://arxiv.org/abs/2508.15291)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, transformer</a></li>
<li><strong>Abstract: </strong>Understanding dataset complexity is fundamental to evaluating and comparing link prediction models on knowledge graphs (KGs). While the Cumulative Spectral Gradient (CSG) metric, derived from probabilistic divergence between classes within a spectral clustering framework, has been proposed as a classifier agnostic complexity metric purportedly scaling with class cardinality and correlating with downstream performance, it has not been evaluated in KG settings so far. In this work, we critically examine CSG in the context of multi relational link prediction, incorporating semantic representations via transformer derived embeddings. Contrary to prior claims, we find that CSG is highly sensitive to parametrisation and does not robustly scale with the number of classes. Moreover, it exhibits weak or inconsistent correlation with standard performance metrics such as Mean Reciprocal Rank (MRR) and Hit@1. To deepen the analysis, we introduce and benchmark a set of structural and semantic KG complexity metrics. Our findings reveal that global and local relational ambiguity captured via Relation Entropy, node level Maximum Relation Diversity, and Relation Type Cardinality exhibit strong inverse correlations with MRR and Hit@1, suggesting these as more faithful indicators of task difficulty. Conversely, graph connectivity measures such as Average Degree, Degree Entropy, PageRank, and Eigenvector Centrality correlate positively with Hit@10. Our results demonstrate that CSGs purported stability and generalization predictive power fail to hold in link prediction settings and underscore the need for more stable, interpretable, and task-aligned measures of dataset complexity in knowledge driven learning.</li>
</ul>

<h3>Title: Connected and Exposed: Cybersecurity Risks, Regulatory Gaps, and Public Perception in Internet-Connected Vehicles</h3>
<ul>
<li><strong>Authors: </strong>Henrietta Hegyi, Laszlo Erdodi</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.15306">https://arxiv.org/abs/2508.15306</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.15306">https://arxiv.org/pdf/2508.15306</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.15306]] Connected and Exposed: Cybersecurity Risks, Regulatory Gaps, and Public Perception in Internet-Connected Vehicles(https://arxiv.org/abs/2508.15306)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, privacy, protect</a></li>
<li><strong>Abstract: </strong>The rapid advancement of Internet-connected vehicle technologies has introduced a new era of smart mobility, while simultaneously raising significant cybersecurity and privacy concerns. This paper explores the evolving threat landscape associated with connected vehicles, focusing on risks such as unauthorized remote access and the potential leakage of personal data. To assess the current state of protection, we conducted a comprehensive analysis of 16 international standards and regulations, evaluating them from multiple perspectives including regulatory strength, technical specificity, treatment of supply chain risks, and approaches to personal data handling. In parallel, we carried out a user-focused survey designed to map consumer attitudes toward smart cars. The survey investigated which types of vehicles users trust and prefer, the reasons behind rejecting certain car types, their awareness of data-related risks, and whether they feel adequately informed about how their vehicles handle data. By combining regulatory analysis with user perception insights, this study aims to contribute to a more holistic understanding of the challenges and expectations surrounding connected vehicle ecosystems.</li>
</ul>

<h3>Title: IPIGuard: A Novel Tool Dependency Graph-Based Defense Against Indirect Prompt Injection in LLM Agents</h3>
<ul>
<li><strong>Authors: </strong>Hengyu An, Jinghuai Zhang, Tianyu Du, Chunyi Zhou, Qingming Li, Tao Lin, Shouling Ji</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.AI, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.15310">https://arxiv.org/abs/2508.15310</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.15310">https://arxiv.org/pdf/2508.15310</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.15310]] IPIGuard: A Novel Tool Dependency Graph-Based Defense Against Indirect Prompt Injection in LLM Agents(https://arxiv.org/abs/2508.15310)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, defense, attack, robust, large language model</a></li>
<li><strong>Abstract: </strong>Large language model (LLM) agents are widely deployed in real-world applications, where they leverage tools to retrieve and manipulate external data for complex tasks. However, when interacting with untrusted data sources (e.g., fetching information from public websites), tool responses may contain injected instructions that covertly influence agent behaviors and lead to malicious outcomes, a threat referred to as Indirect Prompt Injection (IPI). Existing defenses typically rely on advanced prompting strategies or auxiliary detection models. While these methods have demonstrated some effectiveness, they fundamentally rely on assumptions about the model's inherent security, which lacks structural constraints on agent behaviors. As a result, agents still retain unrestricted access to tool invocations, leaving them vulnerable to stronger attack vectors that can bypass the security guardrails of the model. To prevent malicious tool invocations at the source, we propose a novel defensive task execution paradigm, called IPIGuard, which models the agents' task execution process as a traversal over a planned Tool Dependency Graph (TDG). By explicitly decoupling action planning from interaction with external data, IPIGuard significantly reduces unintended tool invocations triggered by injected instructions, thereby enhancing robustness against IPI attacks. Experiments on the AgentDojo benchmark show that IPIGuard achieves a superior balance between effectiveness and robustness, paving the way for the development of safer agentic systems in dynamic environments.</li>
</ul>

<h3>Title: First RAG, Second SEG: A Training-Free Paradigm for Camouflaged Object Detection</h3>
<ul>
<li><strong>Authors: </strong>Wutao Liu, YiDan Wang, Pan Gao</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.15313">https://arxiv.org/abs/2508.15313</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.15313">https://arxiv.org/pdf/2508.15313</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.15313]] First RAG, Second SEG: A Training-Free Paradigm for Camouflaged Object Detection(https://arxiv.org/abs/2508.15313)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>Camouflaged object detection (COD) poses a significant challenge in computer vision due to the high similarity between objects and their backgrounds. Existing approaches often rely on heavy training and large computational resources. While foundation models such as the Segment Anything Model (SAM) offer strong generalization, they still struggle to handle COD tasks without fine-tuning and require high-quality prompts to yield good performance. However, generating such prompts manually is costly and inefficient. To address these challenges, we propose \textbf{First RAG, Second SEG (RAG-SEG)}, a training-free paradigm that decouples COD into two stages: Retrieval-Augmented Generation (RAG) for generating coarse masks as prompts, followed by SAM-based segmentation (SEG) for refinement. RAG-SEG constructs a compact retrieval database via unsupervised clustering, enabling fast and effective feature retrieval. During inference, the retrieved features produce pseudo-labels that guide precise mask generation using SAM2. Our method eliminates the need for conventional training while maintaining competitive performance. Extensive experiments on benchmark COD datasets demonstrate that RAG-SEG performs on par with or surpasses state-of-the-art methods. Notably, all experiments are conducted on a \textbf{personal laptop}, highlighting the computational efficiency and practicality of our approach. We present further analysis in the Appendix, covering limitations, salient object detection extension, and possible improvements.</li>
</ul>

<h3>Title: VideoEraser: Concept Erasure in Text-to-Video Diffusion Models</h3>
<ul>
<li><strong>Authors: </strong>Naen Xu, Jinghuai Zhang, Changjiang Li, Zhi Chen, Chunyi Zhou, Qingming Li, Tianyu Du, Shouling Ji</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI, cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.15314">https://arxiv.org/abs/2508.15314</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.15314">https://arxiv.org/pdf/2508.15314</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.15314]] VideoEraser: Concept Erasure in Text-to-Video Diffusion Models(https://arxiv.org/abs/2508.15314)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, robust, diffusion</a></li>
<li><strong>Abstract: </strong>The rapid growth of text-to-video (T2V) diffusion models has raised concerns about privacy, copyright, and safety due to their potential misuse in generating harmful or misleading content. These models are often trained on numerous datasets, including unauthorized personal identities, artistic creations, and harmful materials, which can lead to uncontrolled production and distribution of such content. To address this, we propose VideoEraser, a training-free framework that prevents T2V diffusion models from generating videos with undesirable concepts, even when explicitly prompted with those concepts. Designed as a plug-and-play module, VideoEraser can seamlessly integrate with representative T2V diffusion models via a two-stage process: Selective Prompt Embedding Adjustment (SPEA) and Adversarial-Resilient Noise Guidance (ARNG). We conduct extensive evaluations across four tasks, including object erasure, artistic style erasure, celebrity erasure, and explicit content erasure. Experimental results show that VideoEraser consistently outperforms prior methods regarding efficacy, integrity, fidelity, robustness, and generalizability. Notably, VideoEraser achieves state-of-the-art performance in suppressing undesirable content during T2V generation, reducing it by 46% on average across four tasks compared to baselines.</li>
</ul>

<h3>Title: RCDINO: Enhancing Radar-Camera 3D Object Detection with DINOv2 Semantic Features</h3>
<ul>
<li><strong>Authors: </strong>Olga Matykina, Dmitry Yudin</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.15353">https://arxiv.org/abs/2508.15353</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.15353">https://arxiv.org/pdf/2508.15353</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.15353]] RCDINO: Enhancing Radar-Camera 3D Object Detection with DINOv2 Semantic Features(https://arxiv.org/abs/2508.15353)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Three-dimensional object detection is essential for autonomous driving and robotics, relying on effective fusion of multimodal data from cameras and radar. This work proposes RCDINO, a multimodal transformer-based model that enhances visual backbone features by fusing them with semantically rich representations from the pretrained DINOv2 foundation model. This approach enriches visual representations and improves the model's detection performance while preserving compatibility with the baseline architecture. Experiments on the nuScenes dataset demonstrate that RCDINO achieves state-of-the-art performance among radar-camera models, with 56.4 NDS and 48.1 mAP. Our implementation is available at this https URL.</li>
</ul>

<h3>Title: KG-EDAS: A Meta-Metric Framework for Evaluating Knowledge Graph Completion Models</h3>
<ul>
<li><strong>Authors: </strong>Haji Gul, Abul Ghani Naim, Ajaz Ahmad Bhat</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.PF</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.15357">https://arxiv.org/abs/2508.15357</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.15357">https://arxiv.org/pdf/2508.15357</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.15357]] KG-EDAS: A Meta-Metric Framework for Evaluating Knowledge Graph Completion Models(https://arxiv.org/abs/2508.15357)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, fair</a></li>
<li><strong>Abstract: </strong>Knowledge Graphs (KGs) enable applications in various domains such as semantic search, recommendation systems, and natural language processing. KGs are often incomplete, missing entities and relations, an issue addressed by Knowledge Graph Completion (KGC) methods that predict missing elements. Different evaluation metrics, such as Mean Reciprocal Rank (MRR), Mean Rank (MR), and Hit@k, are commonly used to assess the performance of such KGC models. A major challenge in evaluating KGC models, however, lies in comparing their performance across multiple datasets and metrics. A model may outperform others on one dataset but underperform on another, making it difficult to determine overall superiority. Moreover, even within a single dataset, different metrics such as MRR and Hit@1 can yield conflicting rankings, where one model excels in MRR while another performs better in Hit@1, further complicating model selection for downstream tasks. These inconsistencies hinder holistic comparisons and highlight the need for a unified meta-metric that integrates performance across all metrics and datasets to enable a more reliable and interpretable evaluation framework. To address this need, we propose KG Evaluation based on Distance from Average Solution (EDAS), a robust and interpretable meta-metric that synthesizes model performance across multiple datasets and diverse evaluation criteria into a single normalized score ($M_i \in [0,1]$). Unlike traditional metrics that focus on isolated aspects of performance, EDAS offers a global perspective that supports more informed model selection and promotes fairness in cross-dataset evaluation. Experimental results on benchmark datasets such as FB15k-237 and WN18RR demonstrate that EDAS effectively integrates multi-metric, multi-dataset performance into a unified ranking, offering a consistent, robust, and generalizable framework for evaluating KGC models.</li>
</ul>

<h3>Title: An Empirical Study on How Video-LLMs Answer Video Questions</h3>
<ul>
<li><strong>Authors: </strong>Chenhui Gou, Ziyu Ma, Zicheng Duan, Haoyu He, Feng Chen, Akide Liu, Bohan Zhuang, Jianfei Cai, Hamid Rezatofighi</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.15360">https://arxiv.org/abs/2508.15360</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.15360">https://arxiv.org/pdf/2508.15360</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.15360]] An Empirical Study on How Video-LLMs Answer Video Questions(https://arxiv.org/abs/2508.15360)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction, interpretability, large language model</a></li>
<li><strong>Abstract: </strong>Taking advantage of large-scale data and pretrained language models, Video Large Language Models (Video-LLMs) have shown strong capabilities in answering video questions. However, most existing efforts focus on improving performance, with limited attention to understanding their internal mechanisms. This paper aims to bridge this gap through a systematic empirical study. To interpret existing VideoLLMs, we adopt attention knockouts as our primary analytical tool and design three variants: Video Temporal Knockout, Video Spatial Knockout, and Language-to-Video Knockout. Then, we apply these three knockouts on different numbers of layers (window of layers). By carefully controlling the window of layers and types of knockouts, we provide two settings: a global setting and a fine-grained setting. Our study reveals three key findings: (1) Global setting indicates Video information extraction primarily occurs in early layers, forming a clear two-stage process -- lower layers focus on perceptual encoding, while higher layers handle abstract reasoning; (2) In the fine-grained setting, certain intermediate layers exert an outsized impact on video question answering, acting as critical outliers, whereas most other layers contribute minimally; (3) In both settings, we observe that spatial-temporal modeling relies more on language-guided retrieval than on intra- and inter-frame self-attention among video tokens, despite the latter's high computational cost. Finally, we demonstrate that these insights can be leveraged to reduce attention computation in Video-LLMs. To our knowledge, this is the first work to systematically uncover how Video-LLMs internally process and understand video content, offering interpretability and efficiency perspectives for future research.</li>
</ul>

<h3>Title: A Survey on Large Language Model Benchmarks</h3>
<ul>
<li><strong>Authors: </strong>Shiwen Ni, Guhong Chen, Shuaimin Li, Xuanang Chen, Siyi Li, Bingli Wang, Qiyao Wang, Xingjian Wang, Yifan Zhang, Liyang Fan, Chengming Li, Ruifeng Xu, Le Sun, Min Yang</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.15361">https://arxiv.org/abs/2508.15361</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.15361">https://arxiv.org/pdf/2508.15361</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.15361]] A Survey on Large Language Model Benchmarks(https://arxiv.org/abs/2508.15361)</code><input type="text"></li>
<li><strong>Keywords: </strong>fair, large language model</a></li>
<li><strong>Abstract: </strong>In recent years, with the rapid development of the depth and breadth of large language models' capabilities, various corresponding evaluation benchmarks have been emerging in increasing numbers. As a quantitative assessment tool for model performance, benchmarks are not only a core means to measure model capabilities but also a key element in guiding the direction of model development and promoting technological innovation. We systematically review the current status and development of large language model benchmarks for the first time, categorizing 283 representative benchmarks into three categories: general capabilities, domain-specific, and target-specific. General capability benchmarks cover aspects such as core linguistics, knowledge, and reasoning; domain-specific benchmarks focus on fields like natural sciences, humanities and social sciences, and engineering technology; target-specific benchmarks pay attention to risks, reliability, agents, etc. We point out that current benchmarks have problems such as inflated scores caused by data contamination, unfair evaluation due to cultural and linguistic biases, and lack of evaluation on process credibility and dynamic environments, and provide a referable design paradigm for future benchmark innovation.</li>
</ul>

<h3>Title: ExBigBang: A Dynamic Approach for Explainable Persona Classification through Contextualized Hybrid Transformer Analysis</h3>
<ul>
<li><strong>Authors: </strong>Saleh Afzoon, Amin Beheshti, Nabi Rezvani, Farshad Khunjush, Usman Naseem, John McMahon, Zahra Fathollahi, Mahdieh Labani, Wathiq Mansoor, Xuyun Zhang</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.15364">https://arxiv.org/abs/2508.15364</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.15364">https://arxiv.org/pdf/2508.15364</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.15364]] ExBigBang: A Dynamic Approach for Explainable Persona Classification through Contextualized Hybrid Transformer Analysis(https://arxiv.org/abs/2508.15364)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, explainability, transformer</a></li>
<li><strong>Abstract: </strong>In user-centric design, persona development plays a vital role in understanding user behaviour, capturing needs, segmenting audiences, and guiding design decisions. However, the growing complexity of user interactions calls for a more contextualized approach to ensure designs align with real user needs. While earlier studies have advanced persona classification by modelling user behaviour, capturing contextual information, especially by integrating textual and tabular data, remains a key challenge. These models also often lack explainability, leaving their predictions difficult to interpret or justify. To address these limitations, we present ExBigBang (Explainable BigBang), a hybrid text-tabular approach that uses transformer-based architectures to model rich contextual features for persona classification. ExBigBang incorporates metadata, domain knowledge, and user profiling to embed deeper context into predictions. Through a cyclical process of user profiling and classification, our approach dynamically updates to reflect evolving user behaviours. Experiments on a benchmark persona classification dataset demonstrate the robustness of our model. An ablation study confirms the benefits of combining text and tabular data, while Explainable AI techniques shed light on the rationale behind the model's predictions.</li>
</ul>

<h3>Title: Unveiling Trust in Multimodal Large Language Models: Evaluation, Analysis, and Mitigation</h3>
<ul>
<li><strong>Authors: </strong>Yichi Zhang, Yao Huang, Yifan Wang, Yitong Sun, Chang Liu, Zhe Zhao, Zhengwei Fang, Huanran Chen, Xiao Yang, Xingxing Wei, Hang Su, Yinpeng Dong, Jun Zhu</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.15370">https://arxiv.org/abs/2508.15370</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.15370">https://arxiv.org/pdf/2508.15370</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.15370]] Unveiling Trust in Multimodal Large Language Models: Evaluation, Analysis, and Mitigation(https://arxiv.org/abs/2508.15370)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, robust, fair, large language model</a></li>
<li><strong>Abstract: </strong>The trustworthiness of Multimodal Large Language Models (MLLMs) remains an intense concern despite the significant progress in their capabilities. Existing evaluation and mitigation approaches often focus on narrow aspects and overlook risks introduced by the multimodality. To tackle these challenges, we propose MultiTrust-X, a comprehensive benchmark for evaluating, analyzing, and mitigating the trustworthiness issues of MLLMs. We define a three-dimensional framework, encompassing five trustworthiness aspects which include truthfulness, robustness, safety, fairness, and privacy; two novel risk types covering multimodal risks and cross-modal impacts; and various mitigation strategies from the perspectives of data, model architecture, training, and inference algorithms. Based on the taxonomy, MultiTrust-X includes 32 tasks and 28 curated datasets, enabling holistic evaluations over 30 open-source and proprietary MLLMs and in-depth analysis with 8 representative mitigation methods. Our extensive experiments reveal significant vulnerabilities in current models, including a gap between trustworthiness and general capabilities, as well as the amplification of potential risks in base LLMs by both multimodal training and inference. Moreover, our controlled analysis uncovers key limitations in existing mitigation strategies that, while some methods yield improvements in specific aspects, few effectively address overall trustworthiness, and many introduce unexpected trade-offs that compromise model utility. These findings also provide practical insights for future improvements, such as the benefits of reasoning to better balance safety and performance. Based on these insights, we introduce a Reasoning-Enhanced Safety Alignment (RESA) approach that equips the model with chain-of-thought reasoning ability to discover the underlying risks, achieving state-of-the-art results.</li>
</ul>

<h3>Title: Confidence-Modulated Speculative Decoding for Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Jaydip Sen, Subhasis Dasgupta, Hetvi Waghela</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.15371">https://arxiv.org/abs/2508.15371</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.15371">https://arxiv.org/pdf/2508.15371</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.15371]] Confidence-Modulated Speculative Decoding for Large Language Models(https://arxiv.org/abs/2508.15371)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, large language model</a></li>
<li><strong>Abstract: </strong>Speculative decoding has emerged as an effective approach for accelerating autoregressive inference by parallelizing token generation through a draft-then-verify paradigm. However, existing methods rely on static drafting lengths and rigid verification criteria, limiting their adaptability across varying model uncertainties and input complexities. This paper proposes an information-theoretic framework for speculative decoding based on confidence-modulated drafting. By leveraging entropy and margin-based uncertainty measures over the drafter's output distribution, the proposed method dynamically adjusts the number of speculatively generated tokens at each iteration. This adaptive mechanism reduces rollback frequency, improves resource utilization, and maintains output fidelity. Additionally, the verification process is modulated using the same confidence signals, enabling more flexible acceptance of drafted tokens without sacrificing generation quality. Experiments on machine translation and summarization tasks demonstrate significant speedups over standard speculative decoding while preserving or improving BLEU and ROUGE scores. The proposed approach offers a principled, plug-in method for efficient and robust decoding in large language models under varying conditions of uncertainty.</li>
</ul>

<h3>Title: Fairness for the People, by the People: Minority Collective Action</h3>
<ul>
<li><strong>Authors: </strong>Omri Ben-Dov, Samira Samadi, Amartya Sanyal, Alexandru Ţifrea</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CY</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.15374">https://arxiv.org/abs/2508.15374</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.15374">https://arxiv.org/pdf/2508.15374</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.15374]] Fairness for the People, by the People: Minority Collective Action(https://arxiv.org/abs/2508.15374)</code><input type="text"></li>
<li><strong>Keywords: </strong>fair</a></li>
<li><strong>Abstract: </strong>Machine learning models often preserve biases present in training data, leading to unfair treatment of certain minority groups. Despite an array of existing firm-side bias mitigation techniques, they typically incur utility costs and require organizational buy-in. Recognizing that many models rely on user-contributed data, end-users can induce fairness through the framework of Algorithmic Collective Action, where a coordinated minority group strategically relabels its own data to enhance fairness, without altering the firm's training process. We propose three practical, model-agnostic methods to approximate ideal relabeling and validate them on real-world datasets. Our findings show that a subgroup of the minority can substantially reduce unfairness with a small impact on the overall prediction error.</li>
</ul>

<h3>Title: DriveSplat: Decoupled Driving Scene Reconstruction with Geometry-enhanced Partitioned Neural Gaussians</h3>
<ul>
<li><strong>Authors: </strong>Cong Wang, Xianda Guo, Wenbo Xu, Wei Tian, Ruiqi Song, Chenming Zhang, Lingxi Li, Long Chen</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.15376">https://arxiv.org/abs/2508.15376</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.15376">https://arxiv.org/pdf/2508.15376</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.15376]] DriveSplat: Decoupled Driving Scene Reconstruction with Geometry-enhanced Partitioned Neural Gaussians(https://arxiv.org/abs/2508.15376)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>In the realm of driving scenarios, the presence of rapidly moving vehicles, pedestrians in motion, and large-scale static backgrounds poses significant challenges for 3D scene reconstruction. Recent methods based on 3D Gaussian Splatting address the motion blur problem by decoupling dynamic and static components within the scene. However, these decoupling strategies overlook background optimization with adequate geometry relationships and rely solely on fitting each training view by adding Gaussians. Therefore, these models exhibit limited robustness in rendering novel views and lack an accurate geometric representation. To address the above issues, we introduce DriveSplat, a high-quality reconstruction method for driving scenarios based on neural Gaussian representations with dynamic-static decoupling. To better accommodate the predominantly linear motion patterns of driving viewpoints, a region-wise voxel initialization scheme is employed, which partitions the scene into near, middle, and far regions to enhance close-range detail representation. Deformable neural Gaussians are introduced to model non-rigid dynamic actors, whose parameters are temporally adjusted by a learnable deformation network. The entire framework is further supervised by depth and normal priors from pre-trained models, improving the accuracy of geometric structures. Our method has been rigorously evaluated on the Waymo and KITTI datasets, demonstrating state-of-the-art performance in novel-view synthesis for driving scenarios.</li>
</ul>

<h3>Title: EvoFormer: Learning Dynamic Graph-Level Representations with Structural and Temporal Bias Correction</h3>
<ul>
<li><strong>Authors: </strong>Haodi Zhong, Liuxin Zou, Di Wang, Bo Wang, Zhenxing Niu, Quan Wang</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.15378">https://arxiv.org/abs/2508.15378</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.15378">https://arxiv.org/pdf/2508.15378</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.15378]] EvoFormer: Learning Dynamic Graph-Level Representations with Structural and Temporal Bias Correction(https://arxiv.org/abs/2508.15378)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer, segmentation</a></li>
<li><strong>Abstract: </strong>Dynamic graph-level embedding aims to capture structural evolution in networks, which is essential for modeling real-world scenarios. However, existing methods face two critical yet under-explored issues: Structural Visit Bias, where random walk sampling disproportionately emphasizes high-degree nodes, leading to redundant and noisy structural representations; and Abrupt Evolution Blindness, the failure to effectively detect sudden structural changes due to rigid or overly simplistic temporal modeling strategies, resulting in inconsistent temporal embeddings. To overcome these challenges, we propose EvoFormer, an evolution-aware Transformer framework tailored for dynamic graph-level representation learning. To mitigate Structural Visit Bias, EvoFormer introduces a Structure-Aware Transformer Module that incorporates positional encoding based on node structural roles, allowing the model to globally differentiate and accurately represent node structures. To overcome Abrupt Evolution Blindness, EvoFormer employs an Evolution-Sensitive Temporal Module, which explicitly models temporal evolution through a sequential three-step strategy: (I) Random Walk Timestamp Classification, generating initial timestamp-aware graph-level embeddings; (II) Graph-Level Temporal Segmentation, partitioning the graph stream into segments reflecting structurally coherent periods; and (III) Segment-Aware Temporal Self-Attention combined with an Edge Evolution Prediction task, enabling the model to precisely capture segment boundaries and perceive structural evolution trends, effectively adapting to rapid temporal shifts. Extensive evaluations on five benchmark datasets confirm that EvoFormer achieves state-of-the-art performance in graph similarity ranking, temporal anomaly detection, and temporal segmentation tasks, validating its effectiveness in correcting structural and temporal biases.</li>
</ul>

<h3>Title: A Practical Guideline and Taxonomy to LLVM's Control Flow Integrity</h3>
<ul>
<li><strong>Authors: </strong>Sabine Houy, Bruno Kreyssig, Timothee Riom, Alexandre Bartel, Patrick McDaniel</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.SE</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.15386">https://arxiv.org/abs/2508.15386</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.15386">https://arxiv.org/pdf/2508.15386</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.15386]] A Practical Guideline and Taxonomy to LLVM's Control Flow Integrity(https://arxiv.org/abs/2508.15386)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, attack</a></li>
<li><strong>Abstract: </strong>Memory corruption vulnerabilities remain one of the most severe threats to software security. They often allow attackers to achieve arbitrary code execution by redirecting a vulnerable program's control flow. While Control Flow Integrity (CFI) has gained traction to mitigate this exploitation path, developers are not provided with any direction on how to apply CFI to real-world software. In this work, we establish a taxonomy mapping LLVM's forward-edge CFI variants to memory corruption vulnerability classes, offering actionable guidance for developers seeking to deploy CFI incrementally in existing codebases. Based on the Top 10 Known Exploited Vulnerabilities (KEV) list, we identify four high-impact vulnerability categories and select one representative CVE for each. We evaluate LLVM's CFI against each CVE and explain why CFI blocks exploitation in two cases while failing in the other two, illustrating its potential and current limitations. Our findings support informed deployment decisions and provide a foundation for improving the practical use of CFI in production systems.</li>
</ul>

<h3>Title: Exploiting Vocabulary Frequency Imbalance in Language Model Pre-training</h3>
<ul>
<li><strong>Authors: </strong>Woojin Chung, Jeonghoon Kim</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.15390">https://arxiv.org/abs/2508.15390</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.15390">https://arxiv.org/pdf/2508.15390</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.15390]] Exploiting Vocabulary Frequency Imbalance in Language Model Pre-training(https://arxiv.org/abs/2508.15390)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large language models are trained with tokenizers, and the resulting token distribution is highly imbalanced: a few words dominate the stream while most occur rarely. Recent practice favors ever-larger vocabularies, but the source of the benefit is unclear. We conduct a controlled study that scales the language model's vocabulary from 24K to 196K while holding data, compute, and optimization fixed. We first quantify the complexity of tokenized text, formalized via Kolmogorov complexity, and show that larger vocabularies reduce this complexity. Above 24K, every common word is already a single token, so further growth mainly deepens the relative token-frequency imbalance. A word-level loss decomposition shows that larger vocabularies reduce cross-entropy almost exclusively by lowering uncertainty on the 2,500 most frequent words, even though loss on the rare tail rises. Constraining input and output embedding norms to attenuate the effect of token-frequency imbalance reverses the gain, directly showing that the model exploits rather than suffers from imbalance. Because the same frequent words cover roughly 77% of tokens in downstream benchmarks, this training advantage transfers intact. We also show that enlarging model parameters with a fixed vocabulary yields the same frequent-word benefit. Our results reframe "bigger vocabularies help" as "lowering the complexity of tokenized text helps," providing a simple, principled lever for tokenizer-model co-design and clarifying the loss dynamics that govern language-model scaling in pre-training.</li>
</ul>

<h3>Title: CITE: A Comprehensive Benchmark for Heterogeneous Text-Attributed Graphs on Catalytic Materials</h3>
<ul>
<li><strong>Authors: </strong>Chenghao Zhang, Qingqing Long, Ludi Wang, Wenjuan Cui, Jianjun Yu, Yi Du</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.15392">https://arxiv.org/abs/2508.15392</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.15392">https://arxiv.org/pdf/2508.15392</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.15392]] CITE: A Comprehensive Benchmark for Heterogeneous Text-Attributed Graphs on Catalytic Materials(https://arxiv.org/abs/2508.15392)</code><input type="text"></li>
<li><strong>Keywords: </strong>fair, large language model</a></li>
<li><strong>Abstract: </strong>Text-attributed graphs(TAGs) are pervasive in real-world systems,where each node carries its own textual features. In many cases these graphs are inherently heterogeneous, containing multiple node types and diverse edge types. Despite the ubiquity of such heterogeneous TAGs, there remains a lack of large-scale benchmark datasets. This shortage has become a critical bottleneck, hindering the development and fair comparison of representation learning methods on heterogeneous text-attributed graphs. In this paper, we introduce CITE - Catalytic Information Textual Entities Graph, the first and largest heterogeneous text-attributed citation graph benchmark for catalytic materials. CITE comprises over 438K nodes and 1.2M edges, spanning four relation types. In addition, we establish standardized evaluation procedures and conduct extensive benchmarking on the node classification task, as well as ablation experiments on the heterogeneous and textual properties of CITE. We compare four classes of learning paradigms, including homogeneous graph models, heterogeneous graph models, LLM(Large Language Model)-centric models, and LLM+Graph models. In a nutshell, we provide (i) an overview of the CITE dataset, (ii) standardized evaluation protocols, and (iii) baseline and ablation experiments across diverse modeling paradigms.</li>
</ul>

<h3>Title: Federated Learning based on Self-Evolving Gaussian Clustering</h3>
<ul>
<li><strong>Authors: </strong>Miha Ožbot, Igor Škrjanc</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.15393">https://arxiv.org/abs/2508.15393</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.15393">https://arxiv.org/pdf/2508.15393</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.15393]] Federated Learning based on Self-Evolving Gaussian Clustering(https://arxiv.org/abs/2508.15393)</code><input type="text"></li>
<li><strong>Keywords: </strong>federate</a></li>
<li><strong>Abstract: </strong>In this study, we present an Evolving Fuzzy System within the context of Federated Learning, which adapts dynamically with the addition of new clusters and therefore does not require the number of clusters to be selected apriori. Unlike traditional methods, Federated Learning allows models to be trained locally on clients' devices, sharing only the model parameters with a central server instead of the data. Our method, implemented using PyTorch, was tested on clustering and classification tasks. The results show that our approach outperforms established classification methods on several well-known UCI datasets. While computationally intensive due to overlap condition calculations, the proposed method demonstrates significant advantages in decentralized data processing.</li>
</ul>

<h3>Title: Attribution, Citation, and Quotation: A Survey of Evidence-based Text Generation with Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Tobias Schreieder, Tim Schopf, Michael Färber</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.15396">https://arxiv.org/abs/2508.15396</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.15396">https://arxiv.org/pdf/2508.15396</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.15396]] Attribution, Citation, and Quotation: A Survey of Evidence-based Text Generation with Large Language Models(https://arxiv.org/abs/2508.15396)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>The increasing adoption of large language models (LLMs) has been accompanied by growing concerns regarding their reliability and trustworthiness. As a result, a growing body of research focuses on evidence-based text generation with LLMs, aiming to link model outputs to supporting evidence to ensure traceability and verifiability. However, the field is fragmented due to inconsistent terminology, isolated evaluation practices, and a lack of unified benchmarks. To bridge this gap, we systematically analyze 134 papers, introduce a unified taxonomy of evidence-based text generation with LLMs, and investigate 300 evaluation metrics across seven key dimensions. Thereby, we focus on approaches that use citations, attribution, or quotations for evidence-based text generation. Building on this, we examine the distinctive characteristics and representative methods in the field. Finally, we highlight open challenges and outline promising directions for future work.</li>
</ul>

<h3>Title: When Audio and Text Disagree: Revealing Text Bias in Large Audio-Language Models</h3>
<ul>
<li><strong>Authors: </strong>Cheng Wang, Gelei Deng, Xianglin Yang, Han Qiu, Tianwei Zhang</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.15407">https://arxiv.org/abs/2508.15407</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.15407">https://arxiv.org/pdf/2508.15407</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.15407]] When Audio and Text Disagree: Revealing Text Bias in Large Audio-Language Models(https://arxiv.org/abs/2508.15407)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Large Audio-Language Models (LALMs) are enhanced with audio perception capabilities, enabling them to effectively process and understand multimodal inputs that combine audio and text. However, their performance in handling conflicting information between audio and text modalities remains largely unexamined. This paper introduces MCR-BENCH, the first comprehensive benchmark specifically designed to evaluate how LALMs prioritize information when presented with inconsistent audio-text pairs. Through extensive evaluation across diverse audio understanding tasks, we reveal a concerning phenomenon: when inconsistencies exist between modalities, LALMs display a significant bias toward textual input, frequently disregarding audio evidence. This tendency leads to substantial performance degradation in audio-centric tasks and raises important reliability concerns for real-world applications. We further investigate the influencing factors of text bias, and explore mitigation strategies through supervised finetuning, and analyze model confidence patterns that reveal persistent overconfidence even with contradictory inputs. These findings underscore the need for improved modality balance during training and more sophisticated fusion mechanisms to enhance the robustness when handling conflicting multi-modal inputs. The project is available at this https URL.</li>
</ul>

<h3>Title: Bridging Generalization and Personalization in Wearable Human Activity Recognition via On-Device Few-Shot Learning</h3>
<ul>
<li><strong>Authors: </strong>Pixi Kang, Julian Moosmann, Mengxi Liu, Bo Zhou, Michele Magno, Paul Lukowicz, Sizhen Bian</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.15413">https://arxiv.org/abs/2508.15413</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.15413">https://arxiv.org/pdf/2508.15413</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.15413]] Bridging Generalization and Personalization in Wearable Human Activity Recognition via On-Device Few-Shot Learning(https://arxiv.org/abs/2508.15413)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Human Activity Recognition (HAR) using wearable devices has advanced significantly in recent years, yet its generalization remains limited when models are deployed to new users. This degradation in performance is primarily due to user-induced concept drift (UICD), highlighting the importance of efficient personalization. In this paper, we present a hybrid framework that first generalizes across users and then rapidly adapts to individual users using few-shot learning directly on-device. By updating only the classifier layer with user-specific data, our method achieves robust personalization with minimal computational and memory overhead. We implement this framework on the energy-efficient RISC-V-based GAP9 microcontroller and validate it across three diverse HAR scenarios: RecGym, QVAR-Gesture, and Ultrasound-Gesture. Post-deployment adaptation yields consistent accuracy improvements of 3.73\%, 17.38\%, and 3.70\% respectively. These results confirm that fast, lightweight, and effective personalization is feasible on embedded platforms, paving the way for scalable and user-aware HAR systems in the wild \footnote{this https URL}.</li>
</ul>

<h3>Title: A Study of Privacy-preserving Language Modeling Approaches</h3>
<ul>
<li><strong>Authors: </strong>Pritilata Saha, Abhirup Sinha</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.15421">https://arxiv.org/abs/2508.15421</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.15421">https://arxiv.org/pdf/2508.15421</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.15421]] A Study of Privacy-preserving Language Modeling Approaches(https://arxiv.org/abs/2508.15421)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, protect, attack</a></li>
<li><strong>Abstract: </strong>Recent developments in language modeling have increased their use in various applications and domains. Language models, often trained on sensitive data, can memorize and disclose this information during privacy attacks, raising concerns about protecting individuals' privacy rights. Preserving privacy in language models has become a crucial area of research, as privacy is one of the fundamental human rights. Despite its significance, understanding of how much privacy risk these language models possess and how it can be mitigated is still limited. This research addresses this by providing a comprehensive study of the privacy-preserving language modeling approaches. This study gives an in-depth overview of these approaches, highlights their strengths, and investigates their limitations. The outcomes of this study contribute to the ongoing research on privacy-preserving language modeling, providing valuable insights and outlining future research directions.</li>
</ul>

<h3>Title: A Curated Dataset and Deep Learning Approach for Minor Dent Detection in Vehicles</h3>
<ul>
<li><strong>Authors: </strong>Danish Zia Baig, Mohsin Kamal</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.15431">https://arxiv.org/abs/2508.15431</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.15431">https://arxiv.org/pdf/2508.15431</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.15431]] A Curated Dataset and Deep Learning Approach for Minor Dent Detection in Vehicles(https://arxiv.org/abs/2508.15431)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Conventional car damage inspection techniques are labor-intensive, manual, and frequently overlook tiny surface imperfections like microscopic dents. Machine learning provides an innovative solution to the increasing demand for quicker and more precise inspection methods. The paper uses the YOLOv8 object recognition framework to provide a deep learning-based solution for automatically detecting microscopic surface flaws, notably tiny dents, on car exteriors. Traditional automotive damage inspection procedures are manual, time-consuming, and frequently unreliable at detecting tiny flaws. To solve this, a bespoke dataset containing annotated photos of car surfaces under various lighting circumstances, angles, and textures was created. To improve robustness, the YOLOv8m model and its customized variants, YOLOv8m-t4 and YOLOv8m-t42, were trained employing real-time data augmentation approaches. Experimental results show that the technique has excellent detection accuracy and low inference latency, making it suited for real-time applications such as automated insurance evaluations and automobile inspections. Evaluation parameters such as mean Average Precision (mAP), precision, recall, and F1-score verified the model's efficacy. With a precision of 0.86, recall of 0.84, and F1-score of 0.85, the YOLOv8m-t42 model outperformed the YOLOv8m-t4 model (precision: 0.81, recall: 0.79, F1-score: 0.80) in identifying microscopic surface defects. With a little reduced mAP@0.5:0.95 of 0.20, the mAP@0.5 for YOLOv8m-t42 stabilized at 0.60. Furthermore, YOLOv8m-t42's PR curve area was 0.88, suggesting more consistent performance than YOLOv8m-t4 (0.82). YOLOv8m-t42 has greater accuracy and is more appropriate for practical dent detection applications, even though its convergence is slower.</li>
</ul>

<h3>Title: Aligning Moments in Time using Video Queries</h3>
<ul>
<li><strong>Authors: </strong>Yogesh Kumar, Uday Agarwal, Manish Gupta, Anand Mishra</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.15439">https://arxiv.org/abs/2508.15439</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.15439">https://arxiv.org/pdf/2508.15439</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.15439]] Aligning Moments in Time using Video Queries(https://arxiv.org/abs/2508.15439)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Video-to-video moment retrieval (Vid2VidMR) is the task of localizing unseen events or moments in a target video using a query video. This task poses several challenges, such as the need for semantic frame-level alignment and modeling complex dependencies between query and target videos. To tackle this challenging problem, we introduce MATR (Moment Alignment TRansformer), a transformer-based model designed to capture semantic context as well as the temporal details necessary for precise moment localization. MATR conditions target video representations on query video features using dual-stage sequence alignment that encodes the required correlations and dependencies. These representations are then used to guide foreground/background classification and boundary prediction heads, enabling the model to accurately identify moments in the target video that semantically match with the query video. Additionally, to provide a strong task-specific initialization for MATR, we propose a self-supervised pre-training technique that involves training the model to localize random clips within videos. Extensive experiments demonstrate that MATR achieves notable performance improvements of 13.1% in R@1 and 8.1% in mIoU on an absolute scale compared to state-of-the-art methods on the popular ActivityNet-VRL dataset. Additionally, on our newly proposed dataset, SportsMoments, MATR shows a 14.7% gain in R@1 and a 14.4% gain in mIoU on an absolute scale over strong baselines.</li>
</ul>

<h3>Title: Reliable Unlearning Harmful Information in LLMs with Metamorphosis Representation Projection</h3>
<ul>
<li><strong>Authors: </strong>Chengcan Wu, Zeming Wei, Huanran Chen, Yinpeng Dong, Meng Sun</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.15449">https://arxiv.org/abs/2508.15449</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.15449">https://arxiv.org/pdf/2508.15449</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.15449]] Reliable Unlearning Harmful Information in LLMs with Metamorphosis Representation Projection(https://arxiv.org/abs/2508.15449)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack, large language model</a></li>
<li><strong>Abstract: </strong>While Large Language Models (LLMs) have demonstrated impressive performance in various domains and tasks, concerns about their safety are becoming increasingly severe. In particular, since models may store unsafe knowledge internally, machine unlearning has emerged as a representative paradigm to ensure model safety. Existing approaches employ various training techniques, such as gradient ascent and negative preference optimization, in attempts to eliminate the influence of undesired data on target models. However, these methods merely suppress the activation of undesired data through parametric training without completely eradicating its informational traces within the model. This fundamental limitation makes it difficult to achieve effective continuous unlearning, rendering these methods vulnerable to relearning attacks. To overcome these challenges, we propose a Metamorphosis Representation Projection (MRP) approach that pioneers the application of irreversible projection properties to machine unlearning. By implementing projective transformations in the hidden state space of specific network layers, our method effectively eliminates harmful information while preserving useful knowledge. Experimental results demonstrate that our approach enables effective continuous unlearning and successfully defends against relearning attacks, achieving state-of-the-art performance in unlearning effectiveness while preserving natural performance. Our code is available in this https URL.</li>
</ul>

<h3>Title: Mini-Batch Robustness Verification of Deep Neural Networks</h3>
<ul>
<li><strong>Authors: </strong>Saar Tzour-Shaday, Dana Drachsler Cohen</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.LO, cs.PL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.15454">https://arxiv.org/abs/2508.15454</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.15454">https://arxiv.org/pdf/2508.15454</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.15454]] Mini-Batch Robustness Verification of Deep Neural Networks(https://arxiv.org/abs/2508.15454)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack, robust</a></li>
<li><strong>Abstract: </strong>Neural network image classifiers are ubiquitous in many safety-critical applications. However, they are susceptible to adversarial attacks. To understand their robustness to attacks, many local robustness verifiers have been proposed to analyze $\epsilon$-balls of inputs. Yet, existing verifiers introduce a long analysis time or lose too much precision, making them less effective for a large set of inputs. In this work, we propose a new approach to local robustness: group local robustness verification. The key idea is to leverage the similarity of the network computations of certain $\epsilon$-balls to reduce the overall analysis time. We propose BaVerLy, a sound and complete verifier that boosts the local robustness verification of a set of $\epsilon$-balls by dynamically constructing and verifying mini-batches. BaVerLy adaptively identifies successful mini-batch sizes, accordingly constructs mini-batches of $\epsilon$-balls that have similar network computations, and verifies them jointly. If a mini-batch is verified, all $\epsilon$-balls are proven robust. Otherwise, one $\epsilon$-ball is suspected as not being robust, guiding the refinement. In the latter case, BaVerLy leverages the analysis results to expedite the analysis of that $\epsilon$-ball as well as the other $\epsilon$-balls in the batch. We evaluate BaVerLy on fully connected and convolutional networks for MNIST and CIFAR-10. Results show that BaVerLy scales the common one by one verification by 2.3x on average and up to 4.1x, in which case it reduces the total analysis time from 24 hours to 6 hours.</li>
</ul>

<h3>Title: PyTOD: Programmable Task-Oriented Dialogue with Execution Feedback</h3>
<ul>
<li><strong>Authors: </strong>Alexandru Coca, Bo-Hsiang Tseng, Pete Boothroyd, Jianpeng Cheng, Mark Gaynor, Zhenxing Zhang, Joe Stacey, Tristan Guigue, Héctor Martinez Alonso, Diarmuid Ó Séaghdha, Anders Johannsen</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.15456">https://arxiv.org/abs/2508.15456</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.15456">https://arxiv.org/pdf/2508.15456</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.15456]] PyTOD: Programmable Task-Oriented Dialogue with Execution Feedback(https://arxiv.org/abs/2508.15456)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Programmable task-oriented dialogue (TOD) agents enable language models to follow structured dialogue policies, but their effectiveness hinges on accurate state tracking. We present PyTOD, an agent that generates executable code to track dialogue state and uses policy and execution feedback for efficient error correction. To this end, PyTOD employs a simple constrained decoding approach, using a language model instead of grammar rules to follow API schemata. This leads to state-of-the-art state tracking performance on the challenging SGD benchmark. Our experiments show that PyTOD surpasses strong baselines in both accuracy and robust user goal estimation as the dialogue progresses, demonstrating the effectiveness of execution-aware state tracking.</li>
</ul>

<h3>Title: SLM4Offer: Personalized Marketing Offer Generation Using Contrastive Learning Based Fine-Tuning</h3>
<ul>
<li><strong>Authors: </strong>Vedasamhitha Challapalli, Konduru Venkat Sai, Piyush Pratap Singh, Rupesh Prasad, Arvind Maurya, Atul Singh</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.15471">https://arxiv.org/abs/2508.15471</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.15471">https://arxiv.org/pdf/2508.15471</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.15471]] SLM4Offer: Personalized Marketing Offer Generation Using Contrastive Learning Based Fine-Tuning(https://arxiv.org/abs/2508.15471)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer, generative</a></li>
<li><strong>Abstract: </strong>Personalized marketing has emerged as a pivotal strategy for enhancing customer engagement and driving business growth. Academic and industry efforts have predominantly focused on recommendation systems and personalized advertisements. Nonetheless, this facet of personalization holds significant potential for increasing conversion rates and improving customer satisfaction. Prior studies suggest that well-executed personalization strategies can boost revenue by up to 40 percent, underscoring the strategic importance of developing intelligent, data-driven approaches for offer generation. This work introduces SLM4Offer, a generative AI model for personalized offer generation, developed by fine-tuning a pre-trained encoder-decoder language model, specifically Google's Text-to-Text Transfer Transformer (T5-Small 60M) using a contrastive learning approach. SLM4Offer employs InfoNCE (Information Noise-Contrastive Estimation) loss to align customer personas with relevant offers in a shared embedding space. A key innovation in SLM4Offer lies in the adaptive learning behaviour introduced by contrastive loss, which reshapes the latent space during training and enhances the model's generalizability. The model is fine-tuned and evaluated on a synthetic dataset designed to simulate customer behaviour and offer acceptance patterns. Experimental results demonstrate a 17 percent improvement in offer acceptance rate over a supervised fine-tuning baseline, highlighting the effectiveness of contrastive objectives in advancing personalized marketing.</li>
</ul>

<h3>Title: Subjective Behaviors and Preferences in LLM: Language of Browsing</h3>
<ul>
<li><strong>Authors: </strong>Sai Sundaresan, Harshita Chopra, Atanu R. Sinha, Koustava Goswami, Nagasai Saketh Naidu, Raghav Karan, N Anushka</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.15474">https://arxiv.org/abs/2508.15474</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.15474">https://arxiv.org/pdf/2508.15474</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.15474]] Subjective Behaviors and Preferences in LLM: Language of Browsing(https://arxiv.org/abs/2508.15474)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>A Large Language Model (LLM) offers versatility across domains and tasks, purportedly benefiting users with a wide variety of behaviors and preferences. We question this perception about an LLM when users have inherently subjective behaviors and preferences, as seen in their ubiquitous and idiosyncratic browsing of websites or apps. The sequential behavior logs of pages, thus generated, form something akin to each user's self-constructed "language", albeit without the structure and grammar imbued in natural languages. We ask: (i) Can a small LM represent the "language of browsing" better than a large LM? (ii) Can an LM with a single set of parameters (or, single LM) adequately capture myriad users' heterogeneous, subjective behaviors and preferences? (iii) Can a single LM with high average performance, yield low variance in performance to make alignment good at user level? We introduce clusterwise LM training, HeTLM (Heterogeneity aware Training of Language Model), appropriate for subjective behaviors. We find that (i) a small LM trained using a page-level tokenizer outperforms large pretrained or finetuned LMs; (ii) HeTLM with heterogeneous cluster specific set of parameters outperforms a single LM of the same family, controlling for the number of parameters; and (iii) a higher mean and a lower variance in generation ensues, implying improved alignment.</li>
</ul>

<h3>Title: LGMSNet: Thinning a medical image segmentation model via dual-level multiscale fusion</h3>
<ul>
<li><strong>Authors: </strong>Chengqi Dong, Fenghe Tang, Rongge Mao, Xinpei Gao, S.Kevin Zhou</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.15476">https://arxiv.org/abs/2508.15476</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.15476">https://arxiv.org/pdf/2508.15476</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.15476]] LGMSNet: Thinning a medical image segmentation model via dual-level multiscale fusion(https://arxiv.org/abs/2508.15476)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction, transformer, segmentation</a></li>
<li><strong>Abstract: </strong>Medical image segmentation plays a pivotal role in disease diagnosis and treatment planning, particularly in resource-constrained clinical settings where lightweight and generalizable models are urgently needed. However, existing lightweight models often compromise performance for efficiency and rarely adopt computationally expensive attention mechanisms, severely restricting their global contextual perception capabilities. Additionally, current architectures neglect the channel redundancy issue under the same convolutional kernels in medical imaging, which hinders effective feature extraction. To address these challenges, we propose LGMSNet, a novel lightweight framework based on local and global dual multiscale that achieves state-of-the-art performance with minimal computational overhead. LGMSNet employs heterogeneous intra-layer kernels to extract local high-frequency information while mitigating channel redundancy. In addition, the model integrates sparse transformer-convolutional hybrid branches to capture low-frequency global information. Extensive experiments across six public datasets demonstrate LGMSNet's superiority over existing state-of-the-art methods. In particular, LGMSNet maintains exceptional performance in zero-shot generalization tests on four unseen datasets, underscoring its potential for real-world deployment in resource-limited medical scenarios. The whole project code is in this https URL.</li>
</ul>

<h3>Title: SLM-Bench: A Comprehensive Benchmark of Small Language Models on Environmental Impacts -- Extended Version</h3>
<ul>
<li><strong>Authors: </strong>Nghiem Thanh Pham, Tung Kieu, Duc-Manh Nguyen, Son Ha Xuan, Nghia Duong-Trung, Danh Le-Phuoc</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.CY, cs.PF</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.15478">https://arxiv.org/abs/2508.15478</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.15478">https://arxiv.org/pdf/2508.15478</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.15478]] SLM-Bench: A Comprehensive Benchmark of Small Language Models on Environmental Impacts -- Extended Version(https://arxiv.org/abs/2508.15478)</code><input type="text"></li>
<li><strong>Keywords: </strong>fair</a></li>
<li><strong>Abstract: </strong>Small Language Models (SLMs) offer computational efficiency and accessibility, yet a systematic evaluation of their performance and environmental impact remains lacking. We introduce SLM-Bench, the first benchmark specifically designed to assess SLMs across multiple dimensions, including accuracy, computational efficiency, and sustainability metrics. SLM-Bench evaluates 15 SLMs on 9 NLP tasks using 23 datasets spanning 14 domains. The evaluation is conducted on 4 hardware configurations, providing a rigorous comparison of their effectiveness. Unlike prior benchmarks, SLM-Bench quantifies 11 metrics across correctness, computation, and consumption, enabling a holistic assessment of efficiency trade-offs. Our evaluation considers controlled hardware conditions, ensuring fair comparisons across models. We develop an open-source benchmarking pipeline with standardized evaluation protocols to facilitate reproducibility and further research. Our findings highlight the diverse trade-offs among SLMs, where some models excel in accuracy while others achieve superior energy efficiency. SLM-Bench sets a new standard for SLM evaluation, bridging the gap between resource efficiency and real-world applicability.</li>
</ul>

<h3>Title: HebID: Detecting Social Identities in Hebrew-language Political Text</h3>
<ul>
<li><strong>Authors: </strong>Guy Mor-Lan, Naama Rivlin-Angert, Yael R. Kaplan, Tamir Sheafer, Shaul R. Shenhav</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.15483">https://arxiv.org/abs/2508.15483</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.15483">https://arxiv.org/pdf/2508.15483</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.15483]] HebID: Detecting Social Identities in Hebrew-language Political Text(https://arxiv.org/abs/2508.15483)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>Political language is deeply intertwined with social identities. While social identities are often shaped by specific cultural contexts and expressed through particular uses of language, existing datasets for group and identity detection are predominantly English-centric, single-label and focus on coarse identity categories. We introduce HebID, the first multilabel Hebrew corpus for social identity detection: 5,536 sentences from Israeli politicians' Facebook posts (Dec 2018-Apr 2021), manually annotated for twelve nuanced social identities (e.g. Rightist, Ultra-Orthodox, Socially-oriented) grounded by survey data. We benchmark multilabel and single-label encoders alongside 2B-9B-parameter generative LLMs, finding that Hebrew-tuned LLMs provide the best results (macro-$F_1$ = 0.74). We apply our classifier to politicians' Facebook posts and parliamentary speeches, evaluating differences in popularity, temporal trends, clustering patterns, and gender-related variations in identity expression. We utilize identity choices from a national public survey, enabling a comparison between identities portrayed in elite discourse and the public's identity priorities. HebID provides a comprehensive foundation for studying social identities in Hebrew and can serve as a model for similar research in other non-English political contexts.</li>
</ul>

<h3>Title: Dream 7B: Diffusion Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Jiacheng Ye, Zhihui Xie, Lin Zheng, Jiahui Gao, Zirui Wu, Xin Jiang, Zhenguo Li, Lingpeng Kong</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.15487">https://arxiv.org/abs/2508.15487</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.15487">https://arxiv.org/pdf/2508.15487</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.15487]] Dream 7B: Diffusion Large Language Models(https://arxiv.org/abs/2508.15487)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, large language model</a></li>
<li><strong>Abstract: </strong>We introduce Dream 7B, the most powerful open diffusion large language model to date. Unlike autoregressive (AR) models that generate tokens sequentially, Dream 7B employs discrete diffusion modeling to refine sequences in parallel through iterative denoising. Our model consistently outperforms existing diffusion language models on general, mathematical, and coding tasks. Dream 7B demonstrates superior planning abilities and inference flexibility, including arbitrary-order generation, infilling capabilities, and tunable quality-speed trade-offs. These results are achieved through simple yet effective training techniques, including AR-based LLM initialization and context-adaptive token-level noise rescheduling. We release both Dream-Base and Dream-Instruct to facilitate further research in diffusion-based language modeling.</li>
</ul>

<h3>Title: Let's Grow an Unbiased Community: Guiding the Fairness of Graphs via New Links</h3>
<ul>
<li><strong>Authors: </strong>Jiahua Lu, Huaxiao Liu, Shuotong Bai, Junjie Xu, Renqiang Luo, Enyan Dai</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.15499">https://arxiv.org/abs/2508.15499</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.15499">https://arxiv.org/pdf/2508.15499</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.15499]] Let's Grow an Unbiased Community: Guiding the Fairness of Graphs via New Links(https://arxiv.org/abs/2508.15499)</code><input type="text"></li>
<li><strong>Keywords: </strong>fair</a></li>
<li><strong>Abstract: </strong>Graph Neural Networks (GNNs) have achieved remarkable success across diverse applications. However, due to the biases in the graph structures, graph neural networks face significant challenges in fairness. Although the original user graph structure is generally biased, it is promising to guide these existing structures toward unbiased ones by introducing new links. The fairness guidance via new links could foster unbiased communities, thereby enhancing fairness in downstream applications. To address this issue, we propose a novel framework named FairGuide. Specifically, to ensure fairness in downstream tasks trained on fairness-guided graphs, we introduce a differentiable community detection task as a pseudo downstream task. Our theoretical analysis further demonstrates that optimizing fairness within this pseudo task effectively enhances structural fairness, promoting fairness generalization across diverse downstream applications. Moreover, FairGuide employs an effective strategy which leverages meta-gradients derived from the fairness-guidance objective to identify new links that significantly enhance structural fairness. Extensive experimental results demonstrate the effectiveness and generalizability of our proposed method across a variety of graph-based fairness tasks.</li>
</ul>

<h3>Title: Task-Generalized Adaptive Cross-Domain Learning for Multimodal Image Fusion</h3>
<ul>
<li><strong>Authors: </strong>Mengyu Wang, Zhenyu Liu, Kun Li, Yu Wang, Yuwei Wang, Yanyan Wei, Fei Wang</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.15505">https://arxiv.org/abs/2508.15505</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.15505">https://arxiv.org/pdf/2508.15505</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.15505]] Task-Generalized Adaptive Cross-Domain Learning for Multimodal Image Fusion(https://arxiv.org/abs/2508.15505)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, extraction</a></li>
<li><strong>Abstract: </strong>Multimodal Image Fusion (MMIF) aims to integrate complementary information from different imaging modalities to overcome the limitations of individual sensors. It enhances image quality and facilitates downstream applications such as remote sensing, medical diagnostics, and robotics. Despite significant advancements, current MMIF methods still face challenges such as modality misalignment, high-frequency detail destruction, and task-specific limitations. To address these challenges, we propose AdaSFFuse, a novel framework for task-generalized MMIF through adaptive cross-domain co-fusion learning. AdaSFFuse introduces two key innovations: the Adaptive Approximate Wavelet Transform (AdaWAT) for frequency decoupling, and the Spatial-Frequency Mamba Blocks for efficient multimodal fusion. AdaWAT adaptively separates the high- and low-frequency components of multimodal images from different scenes, enabling fine-grained extraction and alignment of distinct frequency characteristics for each modality. The Spatial-Frequency Mamba Blocks facilitate cross-domain fusion in both spatial and frequency domains, enhancing this process. These blocks dynamically adjust through learnable mappings to ensure robust fusion across diverse modalities. By combining these components, AdaSFFuse improves the alignment and integration of multimodal features, reduces frequency loss, and preserves critical details. Extensive experiments on four MMIF tasks -- Infrared-Visible Image Fusion (IVF), Multi-Focus Image Fusion (MFF), Multi-Exposure Image Fusion (MEF), and Medical Image Fusion (MIF) -- demonstrate AdaSFFuse's superior fusion performance, ensuring both low computational cost and a compact network, offering a strong balance between performance and efficiency. The code will be publicly available at this https URL.</li>
</ul>

<h3>Title: Stabilization of Perturbed Loss Function: Differential Privacy without Gradient Noise</h3>
<ul>
<li><strong>Authors: </strong>Salman Habib, Remi Chou, Taejoon Kim</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.IT</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.15523">https://arxiv.org/abs/2508.15523</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.15523">https://arxiv.org/pdf/2508.15523</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.15523]] Stabilization of Perturbed Loss Function: Differential Privacy without Gradient Noise(https://arxiv.org/abs/2508.15523)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, robust</a></li>
<li><strong>Abstract: </strong>We propose SPOF (Stabilization of Perturbed Loss Function), a differentially private training mechanism intended for multi-user local differential privacy (LDP). SPOF perturbs a stabilized Taylor expanded polynomial approximation of a model's training loss function, where each user's data is privatized by calibrated noise added to the coefficients of the polynomial. Unlike gradient-based mechanisms such as differentially private stochastic gradient descent (DP-SGD), SPOF does not require injecting noise into the gradients of the loss function, which improves both computational efficiency and stability. This formulation naturally supports simultaneous privacy guarantees across all users. Moreover, SPOF exhibits robustness to environmental noise during training, maintaining stable performance even when user inputs are corrupted. We compare SPOF with a multi-user extension of DP-SGD, evaluating both methods in a wireless body area network (WBAN) scenario involving heterogeneous user data and stochastic channel noise from body sensors. Our results show that SPOF achieves, on average, up to 3.5% higher reconstruction accuracy and reduces mean training time by up to 57.2% compared to DP-SGD, demonstrating superior privacy-utility trade-offs in multi-user environments.</li>
</ul>

<h3>Title: The Enemy from Within: A Study of Political Delegitimization Discourse in Israeli Political Speech</h3>
<ul>
<li><strong>Authors: </strong>Naama Rivlin-Angert, Guy Mor-Lan</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.15524">https://arxiv.org/abs/2508.15524</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.15524">https://arxiv.org/pdf/2508.15524</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.15524]] The Enemy from Within: A Study of Political Delegitimization Discourse in Israeli Political Speech(https://arxiv.org/abs/2508.15524)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack</a></li>
<li><strong>Abstract: </strong>We present the first large-scale computational study of political delegitimization discourse (PDD), defined as symbolic attacks on the normative validity of political entities. We curate and manually annotate a novel Hebrew-language corpus of 10,410 sentences drawn from Knesset speeches (1993-2023), Facebook posts (2018-2021), and leading news outlets, of which 1,812 instances (17.4\%) exhibit PDD and 642 carry additional annotations for intensity, incivility, target type, and affective framing. We introduce a two-stage classification pipeline combining finetuned encoder models and decoder LLMs. Our best model (DictaLM 2.0) attains an F$_1$ of 0.74 for binary PDD detection and a macro-F$_1$ of 0.67 for classification of delegitimization characteristics. Applying this classifier to longitudinal and cross-platform data, we see a marked rise in PDD over three decades, higher prevalence on social media versus parliamentary debate, greater use by male than female politicians, and stronger tendencies among right-leaning actors - with pronounced spikes during election campaigns and major political events. Our findings demonstrate the feasibility and value of automated PDD analysis for understanding democratic discourse.</li>
</ul>

<h3>Title: SafetyFlow: An Agent-Flow System for Automated LLM Safety Benchmarking</h3>
<ul>
<li><strong>Authors: </strong>Xiangyang Zhu, Yuan Tian, Chunyi Li, Kaiwei Zhang, Wei Sun, Guangtao Zhai</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.15526">https://arxiv.org/abs/2508.15526</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.15526">https://arxiv.org/pdf/2508.15526</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.15526]] SafetyFlow: An Agent-Flow System for Automated LLM Safety Benchmarking(https://arxiv.org/abs/2508.15526)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>The rapid proliferation of large language models (LLMs) has intensified the requirement for reliable safety evaluation to uncover model vulnerabilities. To this end, numerous LLM safety evaluation benchmarks are proposed. However, existing benchmarks generally rely on labor-intensive manual curation, which causes excessive time and resource consumption. They also exhibit significant redundancy and limited difficulty. To alleviate these problems, we introduce SafetyFlow, the first agent-flow system designed to automate the construction of LLM safety benchmarks. SafetyFlow can automatically build a comprehensive safety benchmark in only four days without any human intervention by orchestrating seven specialized agents, significantly reducing time and resource cost. Equipped with versatile tools, the agents of SafetyFlow ensure process and cost controllability while integrating human expertise into the automatic pipeline. The final constructed dataset, SafetyFlowBench, contains 23,446 queries with low redundancy and strong discriminative power. Our contribution includes the first fully automated benchmarking pipeline and a comprehensive safety benchmark. We evaluate the safety of 49 advanced LLMs on our dataset and conduct extensive experiments to validate our efficacy and efficiency.</li>
</ul>

<h3>Title: ExtraGS: Geometric-Aware Trajectory Extrapolation with Uncertainty-Guided Generative Priors</h3>
<ul>
<li><strong>Authors: </strong>Kaiyuan Tan, Yingying Shen, Haohui Zhu, Zhiwei Zhan, Shan Zhao, Mingfei Tu, Hongcheng Luo, Haiyang Sun, Bing Wang, Guang Chen, Hangjun Ye</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.15529">https://arxiv.org/abs/2508.15529</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.15529">https://arxiv.org/pdf/2508.15529</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.15529]] ExtraGS: Geometric-Aware Trajectory Extrapolation with Uncertainty-Guided Generative Priors(https://arxiv.org/abs/2508.15529)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>Synthesizing extrapolated views from recorded driving logs is critical for simulating driving scenes for autonomous driving vehicles, yet it remains a challenging task. Recent methods leverage generative priors as pseudo ground truth, but often lead to poor geometric consistency and over-smoothed renderings. To address these limitations, we propose ExtraGS, a holistic framework for trajectory extrapolation that integrates both geometric and generative priors. At the core of ExtraGS is a novel Road Surface Gaussian(RSG) representation based on a hybrid Gaussian-Signed Distance Function (SDF) design, and Far Field Gaussians (FFG) that use learnable scaling factors to efficiently handle distant objects. Furthermore, we develop a self-supervised uncertainty estimation framework based on spherical harmonics that enables selective integration of generative priors only where extrapolation artifacts occur. Extensive experiments on multiple datasets, diverse multi-camera setups, and various generative priors demonstrate that ExtraGS significantly enhances the realism and geometric consistency of extrapolated views, while preserving high fidelity along the original trajectory.</li>
</ul>

<h3>Title: D3FNet: A Differential Attention Fusion Network for Fine-Grained Road Structure Extraction in Remote Perception Systems</h3>
<ul>
<li><strong>Authors: </strong>Chang Liu, Yang Xu, Tamas Sziranyi</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.15537">https://arxiv.org/abs/2508.15537</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.15537">https://arxiv.org/pdf/2508.15537</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.15537]] D3FNet: A Differential Attention Fusion Network for Fine-Grained Road Structure Extraction in Remote Perception Systems(https://arxiv.org/abs/2508.15537)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, extraction, segmentation</a></li>
<li><strong>Abstract: </strong>Extracting narrow roads from high-resolution remote sensing imagery remains a significant challenge due to their limited width, fragmented topology, and frequent occlusions. To address these issues, we propose D3FNet, a Dilated Dual-Stream Differential Attention Fusion Network designed for fine-grained road structure segmentation in remote perception systems. Built upon the encoder-decoder backbone of D-LinkNet, D3FNet introduces three key innovations:(1) a Differential Attention Dilation Extraction (DADE) module that enhances subtle road features while suppressing background noise at the bottleneck; (2) a Dual-stream Decoding Fusion Mechanism (DDFM) that integrates original and attention-modulated features to balance spatial precision with semantic context; and (3) a multi-scale dilation strategy (rates 1, 3, 5, 9) that mitigates gridding artifacts and improves continuity in narrow road prediction. Unlike conventional models that overfit to generic road widths, D3FNet specifically targets fine-grained, occluded, and low-contrast road segments. Extensive experiments on the DeepGlobe and CHN6-CUG benchmarks show that D3FNet achieves superior IoU and recall on challenging road regions, outperforming state-of-the-art baselines. Ablation studies further verify the complementary synergy of attention-guided encoding and dual-path decoding. These results confirm D3FNet as a robust solution for fine-grained narrow road extraction in complex remote and cooperative perception scenarios.</li>
</ul>

<h3>Title: BadFU: Backdoor Federated Learning through Adversarial Machine Unlearning</h3>
<ul>
<li><strong>Authors: </strong>Bingguang Lu, Hongsheng Hu, Yuantian Miao, Shaleeza Sohail, Chaoxiang He, Shuo Wang, Xiao Chen</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.15541">https://arxiv.org/abs/2508.15541</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.15541">https://arxiv.org/pdf/2508.15541</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.15541]] BadFU: Backdoor Federated Learning through Adversarial Machine Unlearning(https://arxiv.org/abs/2508.15541)</code><input type="text"></li>
<li><strong>Keywords: </strong>secure, security, privacy, attack, robust, federate</a></li>
<li><strong>Abstract: </strong>Federated learning (FL) has been widely adopted as a decentralized training paradigm that enables multiple clients to collaboratively learn a shared model without exposing their local data. As concerns over data privacy and regulatory compliance grow, machine unlearning, which aims to remove the influence of specific data from trained models, has become increasingly important in the federated setting to meet legal, ethical, or user-driven demands. However, integrating unlearning into FL introduces new challenges and raises largely unexplored security risks. In particular, adversaries may exploit the unlearning process to compromise the integrity of the global model. In this paper, we present the first backdoor attack in the context of federated unlearning, demonstrating that an adversary can inject backdoors into the global model through seemingly legitimate unlearning requests. Specifically, we propose BadFU, an attack strategy where a malicious client uses both backdoor and camouflage samples to train the global model normally during the federated training process. Once the client requests unlearning of the camouflage samples, the global model transitions into a backdoored state. Extensive experiments under various FL frameworks and unlearning strategies validate the effectiveness of BadFU, revealing a critical vulnerability in current federated unlearning practices and underscoring the urgent need for more secure and robust federated unlearning mechanisms.</li>
</ul>

<h3>Title: AI-Powered Machine Learning Approaches for Fault Diagnosis in Industrial Pumps</h3>
<ul>
<li><strong>Authors: </strong>Khaled M. A. Alghtus, Ayad Gannan, Khalid M. Alhajri, Ali L. A. Al Jubouri, Hassan A. I. Al-Janahi</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.15550">https://arxiv.org/abs/2508.15550</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.15550">https://arxiv.org/pdf/2508.15550</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.15550]] AI-Powered Machine Learning Approaches for Fault Diagnosis in Industrial Pumps(https://arxiv.org/abs/2508.15550)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>This study presents a practical approach for early fault detection in industrial pump systems using real-world sensor data from a large-scale vertical centrifugal pump operating in a demanding marine environment. Five key operational parameters were monitored: vibration, temperature, flow rate, pressure, and electrical current. A dual-threshold labeling method was applied, combining fixed engineering limits with adaptive thresholds calculated as the 95th percentile of historical sensor values. To address the rarity of documented failures, synthetic fault signals were injected into the data using domain-specific rules, simulating critical alerts within plausible operating ranges. Three machine learning classifiers - Random Forest, Extreme Gradient Boosting (XGBoost), and Support Vector Machine (SVM) - were trained to distinguish between normal operation, early warnings, and critical alerts. Results showed that Random Forest and XGBoost models achieved high accuracy across all classes, including minority cases representing rare or emerging faults, while the SVM model exhibited lower sensitivity to anomalies. Visual analyses, including grouped confusion matrices and time-series plots, indicated that the proposed hybrid method provides robust detection capabilities. The framework is scalable, interpretable, and suitable for real-time industrial deployment, supporting proactive maintenance decisions before failures occur. Furthermore, it can be adapted to other machinery with similar sensor architectures, highlighting its potential as a scalable solution for predictive maintenance in complex systems.</li>
</ul>

<h3>Title: Backpropagation-Free Test-Time Adaptation via Probabilistic Gaussian Alignment</h3>
<ul>
<li><strong>Authors: </strong>Youjia Zhang, Youngeun Kim, Young-Geun Choi, Hongyeob Kim, Huiling Liu, Sungeun Hong</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.15568">https://arxiv.org/abs/2508.15568</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.15568">https://arxiv.org/pdf/2508.15568</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.15568]] Backpropagation-Free Test-Time Adaptation via Probabilistic Gaussian Alignment(https://arxiv.org/abs/2508.15568)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Test-time adaptation (TTA) enhances the zero-shot robustness under distribution shifts by leveraging unlabeled test data during inference. Despite notable advances, several challenges still limit its broader applicability. First, most methods rely on backpropagation or iterative optimization, which limits scalability and hinders real-time deployment. Second, they lack explicit modeling of class-conditional feature distributions. This modeling is crucial for producing reliable decision boundaries and calibrated predictions, but it remains underexplored due to the lack of both source data and supervision at test time. In this paper, we propose ADAPT, an Advanced Distribution-Aware and backPropagation-free Test-time adaptation method. We reframe TTA as a Gaussian probabilistic inference task by modeling class-conditional likelihoods using gradually updated class means and a shared covariance matrix. This enables closed-form, training-free inference. To correct potential likelihood bias, we introduce lightweight regularization guided by CLIP priors and a historical knowledge bank. ADAPT requires no source data, no gradient updates, and no full access to target data, supporting both online and transductive settings. Extensive experiments across diverse benchmarks demonstrate that our method achieves state-of-the-art performance under a wide range of distribution shifts with superior scalability and robustness.</li>
</ul>

<h3>Title: Conformalized Exceptional Model Mining: Telling Where Your Model Performs (Not) Well</h3>
<ul>
<li><strong>Authors: </strong>Xin Du, Sikun Yang, Wouter Duivesteijn, Mykola Pechenizkiy</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.15569">https://arxiv.org/abs/2508.15569</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.15569">https://arxiv.org/pdf/2508.15569</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.15569]] Conformalized Exceptional Model Mining: Telling Where Your Model Performs (Not) Well(https://arxiv.org/abs/2508.15569)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability</a></li>
<li><strong>Abstract: </strong>Understanding the nuanced performance of machine learning models is essential for responsible deployment, especially in high-stakes domains like healthcare and finance. This paper introduces a novel framework, Conformalized Exceptional Model Mining, which combines the rigor of Conformal Prediction with the explanatory power of Exceptional Model Mining (EMM). The proposed framework identifies cohesive subgroups within data where model performance deviates exceptionally, highlighting regions of both high confidence and high uncertainty. We develop a new model class, mSMoPE (multiplex Soft Model Performance Evaluation), which quantifies uncertainty through conformal prediction's rigorous coverage guarantees. By defining a new quality measure, Relative Average Uncertainty Loss (RAUL), our framework isolates subgroups with exceptional performance patterns in multi-class classification and regression tasks. Experimental results across diverse datasets demonstrate the framework's effectiveness in uncovering interpretable subgroups that provide critical insights into model behavior. This work lays the groundwork for enhancing model interpretability and reliability, advancing the state-of-the-art in explainable AI and uncertainty quantification.</li>
</ul>

<h3>Title: Towards Scalable and Interpretable Mobile App Risk Analysis via Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Yu Yang, Zhenyuan Li, Xiandong Ran, Jiahao Liu, Jiahui Wang, Bo Yu, Shouling Ji</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.15606">https://arxiv.org/abs/2508.15606</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.15606">https://arxiv.org/pdf/2508.15606</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.15606]] Towards Scalable and Interpretable Mobile App Risk Analysis via Large Language Models(https://arxiv.org/abs/2508.15606)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, large language model</a></li>
<li><strong>Abstract: </strong>Mobile application marketplaces are responsible for vetting apps to identify and mitigate security risks. Current vetting processes are labor-intensive, relying on manual analysis by security professionals aided by semi-automated tools. To address this inefficiency, we propose Mars, a system that leverages Large Language Models (LLMs) for automated risk identification and profiling. Mars is designed to concurrently analyze multiple applications across diverse risk categories with minimal human intervention. To enhance analytical precision and operational efficiency, Mars leverages a pre-constructed risk identification tree to extract relevant indicators from high-dimensional application features. This initial step filters the data, reducing the input volume for the LLM and mitigating the potential for model hallucination induced by irrelevant features. The extracted indicators are then subjected to LLM analysis for final risk determination. Furthermore, Mars automatically generates a comprehensive evidence chain for each assessment, documenting the analytical process to provide transparent justification. These chains are designed to facilitate subsequent manual review and to inform enforcement decisions, such as application delisting. The performance of Mars was evaluated on a real-world dataset from a partner Android marketplace. The results demonstrate that Mars attained an F1-score of 0.838 in risk identification and an F1-score of 0.934 in evidence retrieval. To assess its practical applicability, a user study involving 20 expert analysts was conducted, which indicated that Mars yielded a substantial efficiency gain, ranging from 60% to 90%, over conventional manual analysis.</li>
</ul>

<h3>Title: Fast globally optimal Truncated Least Squares point cloud registration with fixed rotation axis</h3>
<ul>
<li><strong>Authors: </strong>Ivo Ivanov, Carsten Markgraf</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.15613">https://arxiv.org/abs/2508.15613</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.15613">https://arxiv.org/pdf/2508.15613</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.15613]] Fast globally optimal Truncated Least Squares point cloud registration with fixed rotation axis(https://arxiv.org/abs/2508.15613)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Recent results showed that point cloud registration with given correspondences can be made robust to outlier rates of up to 95\% using the truncated least squares (TLS) formulation. However, solving this combinatorial optimization problem to global optimality is challenging. Provably globally optimal approaches using semidefinite programming (SDP) relaxations take hundreds of seconds for 100 points. In this paper, we propose a novel linear time convex relaxation as well as a contractor method to speed up Branch and Bound (BnB). Our solver can register two 3D point clouds with 100 points to provable global optimality in less than half a second when the axis of rotation is provided. Although it currently cannot solve the full 6DoF problem, it is two orders of magnitude faster than the state-of-the-art SDP solver STRIDE when solving the rotation-only TLS problem. In addition to providing a formal proof for global optimality, we present empirical evidence of global optimality using adversarial instances with local minimas close to the global minimum.</li>
</ul>

<h3>Title: Trained Miniatures: Low cost, High Efficacy SLMs for Sales & Marketing</h3>
<ul>
<li><strong>Authors: </strong>Ishaan Bhola, Mukunda NS, Sravanth Kurmala, Harsh Nandwani, Arihant Jain</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.15617">https://arxiv.org/abs/2508.15617</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.15617">https://arxiv.org/pdf/2508.15617</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.15617]] Trained Miniatures: Low cost, High Efficacy SLMs for Sales & Marketing(https://arxiv.org/abs/2508.15617)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large language models (LLMs) excel in text generation; however, these creative elements require heavy computation and are accompanied by a steep cost. Especially for targeted applications such as sales and marketing outreach, these costs are far from feasible. This paper introduces the concept of "Trained Miniatures" - Small Language Models(SLMs) fine-tuned for specific, high-value applications, generating similar domain-specific responses for a fraction of the cost.</li>
</ul>

<h3>Title: When and What: Diffusion-Grounded VideoLLM with Entity Aware Segmentation for Long Video Understanding</h3>
<ul>
<li><strong>Authors: </strong>Pengcheng Fang, Yuxia Chen, Rui Guo</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.15641">https://arxiv.org/abs/2508.15641</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.15641">https://arxiv.org/pdf/2508.15641</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.15641]] When and What: Diffusion-Grounded VideoLLM with Entity Aware Segmentation for Long Video Understanding(https://arxiv.org/abs/2508.15641)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, diffusion, segmentation</a></li>
<li><strong>Abstract: </strong>Understanding videos requires more than answering open ended questions, it demands the ability to pinpoint when events occur and how entities interact across time. While recent Video LLMs have achieved remarkable progress in holistic reasoning, they remain coarse in temporal perception: timestamps are encoded only implicitly, frame level features are weak in capturing continuity, and language vision alignment often drifts from the entities of interest. In this paper, we present Grounded VideoDiT, a Video LLM designed to overcome these limitations by introducing three key innovations. First, a Diffusion Temporal Latent (DTL) encoder enhances boundary sensitivity and maintains temporal consistency. Second, object grounded representations explicitly bind query entities to localized visual evidence, strengthening alignment. Third, a mixed token scheme with discrete temporal tokens provides explicit timestamp modeling, enabling fine grained temporal reasoning. Together, these designs equip Grounded VideoDiT with robust grounding capabilities, as validated by state of the art results on Charades STA, NExT GQA, and multiple VideoQA benchmarks.</li>
</ul>

<h3>Title: Correct-By-Construction: Certified Individual Fairness through Neural Network Training</h3>
<ul>
<li><strong>Authors: </strong>Ruihan Zhang, Jun Sun</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.15642">https://arxiv.org/abs/2508.15642</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.15642">https://arxiv.org/pdf/2508.15642</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.15642]] Correct-By-Construction: Certified Individual Fairness through Neural Network Training(https://arxiv.org/abs/2508.15642)</code><input type="text"></li>
<li><strong>Keywords: </strong>protect, fair</a></li>
<li><strong>Abstract: </strong>Fairness in machine learning is more important than ever as ethical concerns continue to grow. Individual fairness demands that individuals differing only in sensitive attributes receive the same outcomes. However, commonly used machine learning algorithms often fail to achieve such fairness. To improve individual fairness, various training methods have been developed, such as incorporating fairness constraints as optimisation objectives. While these methods have demonstrated empirical effectiveness, they lack formal guarantees of fairness. Existing approaches that aim to provide fairness guarantees primarily rely on verification techniques, which can sometimes fail to produce definitive results. Moreover, verification alone does not actively enhance individual fairness during training. To address this limitation, we propose a novel framework that formally guarantees individual fairness throughout training. Our approach consists of two parts, i.e., (1) provably fair initialisation that ensures the model starts in a fair state, and (2) a fairness-preserving training algorithm that maintains fairness as the model learns. A key element of our method is the use of randomised response mechanisms, which protect sensitive attributes while maintaining fairness guarantees. We formally prove that this mechanism sustains individual fairness throughout the training process. Experimental evaluations confirm that our approach is effective, i.e., producing models that are empirically fair and accurate. Furthermore, our approach is much more efficient than the alternative approach based on certified training (which requires neural network verification during training).</li>
</ul>

<h3>Title: Weakly-Supervised Learning for Tree Instances Segmentation in Airborne Lidar Point Clouds</h3>
<ul>
<li><strong>Authors: </strong>Swann Emilien Céleste Destouches, Jesse Lahaye, Laurent Valentin Jospin, Jan Skaloud</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.15646">https://arxiv.org/abs/2508.15646</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.15646">https://arxiv.org/pdf/2508.15646</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.15646]] Weakly-Supervised Learning for Tree Instances Segmentation in Airborne Lidar Point Clouds(https://arxiv.org/abs/2508.15646)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>Tree instance segmentation of airborne laser scanning (ALS) data is of utmost importance for forest monitoring, but remains challenging due to variations in the data caused by factors such as sensor resolution, vegetation state at acquisition time, terrain characteristics, etc. Moreover, obtaining a sufficient amount of precisely labeled data to train fully supervised instance segmentation methods is expensive. To address these challenges, we propose a weakly supervised approach where labels of an initial segmentation result obtained either by a non-finetuned model or a closed form algorithm are provided as a quality rating by a human operator. The labels produced during the quality assessment are then used to train a rating model, whose task is to classify a segmentation output into the same classes as specified by the human operator. Finally, the segmentation model is finetuned using feedback from the rating model. This in turn improves the original segmentation model by 34\% in terms of correctly identified tree instances while considerably reducing the number of non-tree instances predicted. Challenges still remain in data over sparsely forested regions characterized by small trees (less than two meters in height) or within complex surroundings containing shrubs, boulders, etc. which can be confused as trees where the performance of the proposed method is reduced.</li>
</ul>

<h3>Title: SDGO: Self-Discrimination-Guided Optimization for Consistent Safety in Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Peng Ding, Wen Sun, Dailin Li, Wei Zou, Jiaming Wang, Jiajun Chen, Shujian Huang</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.15648">https://arxiv.org/abs/2508.15648</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.15648">https://arxiv.org/pdf/2508.15648</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.15648]] SDGO: Self-Discrimination-Guided Optimization for Consistent Safety in Large Language Models(https://arxiv.org/abs/2508.15648)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack, robust, large language model</a></li>
<li><strong>Abstract: </strong>Large Language Models (LLMs) excel at various natural language processing tasks but remain vulnerable to jailbreaking attacks that induce harmful content generation. In this paper, we reveal a critical safety inconsistency: LLMs can more effectively identify harmful requests as discriminators than defend against them as generators. This insight inspires us to explore aligning the model's inherent discrimination and generation capabilities. To this end, we propose SDGO (Self-Discrimination-Guided Optimization), a reinforcement learning framework that leverages the model's own discrimination capabilities as a reward signal to enhance generation safety through iterative self-improvement. Our method does not require any additional annotated data or external models during the training phase. Extensive experiments demonstrate that SDGO significantly improves model safety compared to both prompt-based and training-based baselines while maintaining helpfulness on general benchmarks. By aligning LLMs' discrimination and generation capabilities, SDGO brings robust performance against out-of-distribution (OOD) jailbreaking attacks. This alignment achieves tighter coupling between these two capabilities, enabling the model's generation capability to be further enhanced with only a small amount of discriminative samples. Our code and datasets are available at this https URL.</li>
</ul>

<h3>Title: Towards a 3D Transfer-based Black-box Attack via Critical Feature Guidance</h3>
<ul>
<li><strong>Authors: </strong>Shuchao Pang, Zhenghan Chen, Shen Zhang, Liming Lu, Siyuan Liang, Anan Du, Yongbin Zhou</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.15650">https://arxiv.org/abs/2508.15650</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.15650">https://arxiv.org/pdf/2508.15650</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.15650]] Towards a 3D Transfer-based Black-box Attack via Critical Feature Guidance(https://arxiv.org/abs/2508.15650)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, attack</a></li>
<li><strong>Abstract: </strong>Deep neural networks for 3D point clouds have been demonstrated to be vulnerable to adversarial examples. Previous 3D adversarial attack methods often exploit certain information about the target models, such as model parameters or outputs, to generate adversarial point clouds. However, in realistic scenarios, it is challenging to obtain any information about the target models under conditions of absolute security. Therefore, we focus on transfer-based attacks, where generating adversarial point clouds does not require any information about the target models. Based on our observation that the critical features used for point cloud classification are consistent across different DNN architectures, we propose CFG, a novel transfer-based black-box attack method that improves the transferability of adversarial point clouds via the proposed Critical Feature Guidance. Specifically, our method regularizes the search of adversarial point clouds by computing the importance of the extracted features, prioritizing the corruption of critical features that are likely to be adopted by diverse architectures. Further, we explicitly constrain the maximum deviation extent of the generated adversarial point clouds in the loss function to ensure their imperceptibility. Extensive experiments conducted on the ModelNet40 and ScanObjectNN benchmark datasets demonstrate that the proposed CFG outperforms the state-of-the-art attack methods by a large margin.</li>
</ul>

<h3>Title: Benchmarking Computer Science Survey Generation</h3>
<ul>
<li><strong>Authors: </strong>Weihang Su, Anzhe Xie, Qingyao Ai, Jianming Long, Jiaxin Mao, Ziyi Ye, Yiqun Liu</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.IR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.15658">https://arxiv.org/abs/2508.15658</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.15658">https://arxiv.org/pdf/2508.15658</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.15658]] Benchmarking Computer Science Survey Generation(https://arxiv.org/abs/2508.15658)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Scientific survey articles play a vital role in summarizing research progress, yet their manual creation is becoming increasingly infeasible due to the rapid growth of academic literature. While large language models (LLMs) offer promising capabilities for automating this process, progress in this area is hindered by the absence of standardized benchmarks and evaluation protocols. To address this gap, we introduce SurGE (Survey Generation Evaluation), a new benchmark for evaluating scientific survey generation in the computer science domain. SurGE consists of (1) a collection of test instances, each including a topic description, an expert-written survey, and its full set of cited references, and (2) a large-scale academic corpus of over one million papers that serves as the retrieval pool. In addition, we propose an automated evaluation framework that measures generated surveys across four dimensions: information coverage, referencing accuracy, structural organization, and content quality. Our evaluation of diverse LLM-based approaches shows that survey generation remains highly challenging, even for advanced self-reflection frameworks. These findings highlight the complexity of the task and the necessity for continued research. We have open-sourced all the code, data, and models at: this https URL</li>
</ul>

<h3>Title: Amortized In-Context Mixed Effect Transformer Models: A Zero-Shot Approach for Pharmacokinetics</h3>
<ul>
<li><strong>Authors: </strong>César Ali Ojeda Marin, Wilhelm Huisinga, Purity Kavwele, Niklas Hartung</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.15659">https://arxiv.org/abs/2508.15659</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.15659">https://arxiv.org/pdf/2508.15659</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.15659]] Amortized In-Context Mixed Effect Transformer Models: A Zero-Shot Approach for Pharmacokinetics(https://arxiv.org/abs/2508.15659)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Accurate dose-response forecasting under sparse sampling is central to precision pharmacotherapy. We present the Amortized In-Context Mixed-Effect Transformer (AICMET) model, a transformer-based latent-variable framework that unifies mechanistic compartmental priors with amortized in-context Bayesian inference. AICMET is pre-trained on hundreds of thousands of synthetic pharmacokinetic trajectories with Ornstein-Uhlenbeck priors over the parameters of compartment models, endowing the model with strong inductive biases and enabling zero-shot adaptation to new compounds. At inference time, the decoder conditions on the collective context of previously profiled trial participants, generating calibrated posterior predictions for newly enrolled patients after a few early drug concentration measurements. This capability collapses traditional model-development cycles from weeks to hours while preserving some degree of expert modelling. Experiments across public datasets show that AICMET attains state-of-the-art predictive accuracy and faithfully quantifies inter-patient variability -- outperforming both nonlinear mixed-effects baselines and recent neural ODE variants. Our results highlight the feasibility of transformer-based, population-aware neural architectures as offering a new alternative for bespoke pharmacokinetic modeling pipelines, charting a path toward truly population-aware personalized dosing regimens.</li>
</ul>

<h3>Title: CM2LoD3: Reconstructing LoD3 Building Models Using Semantic Conflict Maps</h3>
<ul>
<li><strong>Authors: </strong>Franz Hanke, Antonia Bieringer, Olaf Wysocki, Boris Jutzi</a></li>
<li><strong>Subjects: </strong>cs.CV, eess.IV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.15672">https://arxiv.org/abs/2508.15672</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.15672">https://arxiv.org/pdf/2508.15672</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.15672]] CM2LoD3: Reconstructing LoD3 Building Models Using Semantic Conflict Maps(https://arxiv.org/abs/2508.15672)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>Detailed 3D building models are crucial for urban planning, digital twins, and disaster management applications. While Level of Detail 1 (LoD)1 and LoD2 building models are widely available, they lack detailed facade elements essential for advanced urban analysis. In contrast, LoD3 models address this limitation by incorporating facade elements such as windows, doors, and underpasses. However, their generation has traditionally required manual modeling, making large-scale adoption challenging. In this contribution, CM2LoD3, we present a novel method for reconstructing LoD3 building models leveraging Conflict Maps (CMs) obtained from ray-to-model-prior analysis. Unlike previous works, we concentrate on semantically segmenting real-world CMs with synthetically generated CMs from our developed Semantic Conflict Map Generator (SCMG). We also observe that additional segmentation of textured models can be fused with CMs using confidence scores to further increase segmentation performance and thus increase 3D reconstruction accuracy. Experimental results demonstrate the effectiveness of our CM2LoD3 method in segmenting and reconstructing building openings, with the 61% performance with uncertainty-aware fusion of segmented building textures. This research contributes to the advancement of automated LoD3 model reconstruction, paving the way for scalable and efficient 3D city modeling. Our project is available: this https URL</li>
</ul>

<h3>Title: Tensorized Multi-Task Learning for Personalized Modeling of Heterogeneous Individuals with High-Dimensional Data</h3>
<ul>
<li><strong>Authors: </strong>Elif Konyar, Mostafa Reisi Gahrooei, Kamran Paynabar</a></li>
<li><strong>Subjects: </strong>cs.LG, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.15676">https://arxiv.org/abs/2508.15676</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.15676">https://arxiv.org/pdf/2508.15676</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.15676]] Tensorized Multi-Task Learning for Personalized Modeling of Heterogeneous Individuals with High-Dimensional Data(https://arxiv.org/abs/2508.15676)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability</a></li>
<li><strong>Abstract: </strong>Effective modeling of heterogeneous subpopulations presents a significant challenge due to variations in individual characteristics and behaviors. This paper proposes a novel approach to address this issue through multi-task learning (MTL) and low-rank tensor decomposition techniques. Our MTL approach aims to enhance personalized modeling by leveraging shared structures among similar tasks while accounting for distinct subpopulation-specific variations. We introduce a framework where low-rank decomposition decomposes the collection of task model parameters into a low-rank structure that captures commonalities and variations across tasks and subpopulations. This approach allows for efficient learning of personalized models by sharing knowledge between similar tasks while preserving the unique characteristics of each subpopulation. Experimental results in simulation and case study datasets demonstrate the superior performance of the proposed method compared to several benchmarks, particularly in scenarios with high variability among subpopulations. The proposed framework not only improves prediction accuracy but also enhances interpretability by revealing underlying patterns that contribute to the personalization of models.</li>
</ul>

<h3>Title: LLM-empowered Dynamic Prompt Routing for Vision-Language Models Tuning under Long-Tailed Distributions</h3>
<ul>
<li><strong>Authors: </strong>Yongju Jia, Jiarui Ma, Xiangxian Li, Baiqiao Zhang, Xianhui Cao, Juan Liu, Yulong Bian</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.15688">https://arxiv.org/abs/2508.15688</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.15688">https://arxiv.org/pdf/2508.15688</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.15688]] LLM-empowered Dynamic Prompt Routing for Vision-Language Models Tuning under Long-Tailed Distributions(https://arxiv.org/abs/2508.15688)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Pre-trained vision-language models (VLMs), such as CLIP, have demonstrated impressive capability in visual tasks, but their fine-tuning often suffers from bias in class-imbalanced scene. Recent works have introduced large language models (LLMs) to enhance VLM fine-tuning with supplementing semantic information. However, they often overlook inherent class imbalance in VLMs' pre-training, which may lead to bias accumulation in downstream tasks. To address this problem, this paper proposes a Multi-dimensional Dynamic Prompt Routing (MDPR) framework. MDPR constructs a comprehensive knowledge base for classes, spanning five visual-semantic dimensions. During fine-tuning, the dynamic routing mechanism aligns global visual classes, retrieves optimal prompts, and balances fine-grained semantics, yielding stable predictions through logits fusion. Extensive experiments on long-tailed benchmarks, including CIFAR-LT, ImageNet-LT, and Places-LT, demonstrate that MDPR achieves comparable results with current SOTA methods. Ablation studies further confirm the effectiveness of our semantic library for tail classes, and show that our dynamic routing incurs minimal computational overhead, making MDPR a flexible and efficient enhancement for VLM fine-tuning under data imbalance.</li>
</ul>

<h3>Title: Conditionally adaptive augmented Lagrangian method for physics-informed learning of forward and inverse problems using artificial neural networks</h3>
<ul>
<li><strong>Authors: </strong>Qifeng Hu, Shamsulhaq Basir, Inanc Senocak</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.15695">https://arxiv.org/abs/2508.15695</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.15695">https://arxiv.org/pdf/2508.15695</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.15695]] Conditionally adaptive augmented Lagrangian method for physics-informed learning of forward and inverse problems using artificial neural networks(https://arxiv.org/abs/2508.15695)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>We present several advances to the physics and equality constrained artificial neural networks (PECANN) framework that substantially improve its capability to learn solutions of canonical partial differential equations (PDEs). First, we generalize the augmented Lagrangian method (ALM) to support multiple independent penalty parameters, enabling simultaneous enforcement of heterogeneous constraints. Second, we reformulate pointwise constraint enforcement and Lagrange multipliers as expectations over constraint terms, reducing memory overhead and permitting efficient mini-batch training. Third, to address PDEs with oscillatory, multi-scale features, we incorporate Fourier feature mappings and show that a single mapping suffices where multiple mappings or more costly architectures were required in related methods. Fourth, we introduce a time-windowing strategy for long-time evolution in which the terminal state of each window is enforced as an initial-condition constraint for the next, ensuring continuity without discrete time models. Crucially, we propose a conditionally adaptive penalty update (CAPU) strategy for ALM, which preserves the principle that larger constraint violations incur stronger penalties. CAPU accelerates the growth of Lagrange multipliers for selectively challenging constraints, enhancing constraint enforcement during training. We demonstrate the effectiveness of PECANN-CAPU on problems including the transonic rarefaction problem, reversible advection of a passive by a vortex, high-wavenumber Helmholtz and Poisson equations, and inverse identification of spatially varying heat sources. Comparisons with established methods and recent Kolmogorov-Arnold network approaches show that PECANN-CAPU achieves competitive accuracy across all cases. Collectively, these advances improve PECANN's robustness, efficiency, and applicability to demanding problems in scientific computing.</li>
</ul>

<h3>Title: Investigation of D-Wave quantum annealing for training Restricted Boltzmann Machines and mitigating catastrophic forgetting</h3>
<ul>
<li><strong>Authors: </strong>Abdelmoula El-Yazizi, Yaroslav Koshka</a></li>
<li><strong>Subjects: </strong>cs.LG, quant-ph, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.15697">https://arxiv.org/abs/2508.15697</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.15697">https://arxiv.org/pdf/2508.15697</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.15697]] Investigation of D-Wave quantum annealing for training Restricted Boltzmann Machines and mitigating catastrophic forgetting(https://arxiv.org/abs/2508.15697)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>Modest statistical differences between the sampling performances of the D-Wave quantum annealer (QA) and the classical Markov Chain Monte Carlo (MCMC), when applied to Restricted Boltzmann Machines (RBMs), are explored to explain, and possibly address, the absence of significant and consistent improvements in RBM trainability when the D-Wave sampling was used in previous investigations. A novel hybrid sampling approach, combining the classical and the QA contributions, is investigated as a promising way to benefit from the modest differences between the two sampling methods. No improvements in the RBM training are achieved in this work, thereby suggesting that the differences between the QA-based and MCMC sampling, mainly found in the medium-to-low probability regions of the distribution, which are less important for the quality of the sample, are insufficient to benefit the training. Difficulties in achieving sufficiently high quality of embedding RBMs into the lattice of the newer generation of D-Wave hardware could be further complicating the task. On the other hand, the ability to generate samples of sufficient variety from lower-probability parts of the distribution has a potential to benefit other machine learning applications, such as the mitigation of catastrophic forgetting (CF) during incremental learning. The feasibility of using QA-generated patterns of desirable classes for CF mitigation by the generative replay is demonstrated in this work for the first time. While the efficiency of the CF mitigation using the D-Wave QA was comparable to that of the classical mitigation, both the speed of generating a large number of distinct desirable patterns and the potential for further improvement make this approach promising for a variety of challenging machine learning applications.</li>
</ul>

<h3>Title: Communication Efficient LLM Pre-training with SparseLoCo</h3>
<ul>
<li><strong>Authors: </strong>Amir Sarfi, Benjamin Thérien, Joel Lidin, Eugene Belilovsky</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.15706">https://arxiv.org/abs/2508.15706</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.15706">https://arxiv.org/pdf/2508.15706</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.15706]] Communication Efficient LLM Pre-training with SparseLoCo(https://arxiv.org/abs/2508.15706)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Communication-efficient distributed training algorithms have received considerable interest recently due to their benefits for training Large Language Models (LLMs) in bandwidth-constrained settings, such as across data centers and over the internet. Despite reducing communication frequency, these methods still typically require communicating a full copy of the model's gradients-resulting in a communication bottleneck even for cross-datacenter links. Furthermore, they can slightly degrade performance compared to a naive AdamW DDP baseline. While quantization and error feedback are often applied to reduce the pseudo-gradient's size, in the context of LLM pre-training, existing approaches have been unable to additionally leverage sparsification and have obtained limited quantization. In this work, we introduce SparseLoCo, a communication-efficient training algorithm for LLMs that effectively leverages Top-k sparsification and quantization to reach extreme compression ratios of up to 1-3% sparsity and 2-bit quantization while outperforming full-precision DiLoCo. Our key observations are that outer momentum can be locally approximated by an error feedback combined with aggressive sparsity and that sparse aggregation can actually improve model performance. We empirically demonstrate in a range of communication-constrained LLM training settings that SparseLoCo provides significant benefits in both performance and communication cost.</li>
</ul>

<h3>Title: Stemming -- The Evolution and Current State with a Focus on Bangla</h3>
<ul>
<li><strong>Authors: </strong>Abhijit Paul, Mashiat Amin Farin, Sharif Md. Abdullah, Ahmedul Kabir, Zarif Masud, Shebuti Rayana</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.IR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.15711">https://arxiv.org/abs/2508.15711</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.15711">https://arxiv.org/pdf/2508.15711</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.15711]] Stemming -- The Evolution and Current State with a Focus on Bangla(https://arxiv.org/abs/2508.15711)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Bangla, the seventh most widely spoken language worldwide with 300 million native speakers, faces digital under-representation due to limited resources and lack of annotated datasets. Stemming, a critical preprocessing step in language analysis, is essential for low-resource, highly-inflectional languages like Bangla, because it can reduce the complexity of algorithms and models by significantly reducing the number of words the algorithm needs to consider. This paper conducts a comprehensive survey of stemming approaches, emphasizing the importance of handling morphological variants effectively. While exploring the landscape of Bangla stemming, it becomes evident that there is a significant gap in the existing literature. The paper highlights the discontinuity from previous research and the scarcity of accessible implementations for replication. Furthermore, it critiques the evaluation methodologies, stressing the need for more relevant metrics. In the context of Bangla's rich morphology and diverse dialects, the paper acknowledges the challenges it poses. To address these challenges, the paper suggests directions for Bangla stemmer development. It concludes by advocating for robust Bangla stemmers and continued research in the field to enhance language analysis and processing.</li>
</ul>

<h3>Title: StreamMem: Query-Agnostic KV Cache Memory for Streaming Video Understanding</h3>
<ul>
<li><strong>Authors: </strong>Yanlai Yang, Zhuokai Zhao, Satya Narayan Shukla, Aashu Singh, Shlok Kumar Mishra, Lizhu Zhang, Mengye Ren</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.15717">https://arxiv.org/abs/2508.15717</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.15717">https://arxiv.org/pdf/2508.15717</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.15717]] StreamMem: Query-Agnostic KV Cache Memory for Streaming Video Understanding(https://arxiv.org/abs/2508.15717)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Multimodal large language models (MLLMs) have made significant progress in visual-language reasoning, but their ability to efficiently handle long videos remains limited. Despite recent advances in long-context MLLMs, storing and attending to the key-value (KV) cache for long visual contexts incurs substantial memory and computational overhead. Existing visual compression methods require either encoding the entire visual context before compression or having access to the questions in advance, which is impractical for long video understanding and multi-turn conversational settings. In this work, we propose StreamMem, a query-agnostic KV cache memory mechanism for streaming video understanding. Specifically, StreamMem encodes new video frames in a streaming manner, compressing the KV cache using attention scores between visual tokens and generic query tokens, while maintaining a fixed-size KV memory to enable efficient question answering (QA) in memory-constrained, long-video scenarios. Evaluation on three long video understanding and two streaming video question answering benchmarks shows that StreamMem achieves state-of-the-art performance in query-agnostic KV cache compression and is competitive with query-aware compression approaches.</li>
</ul>

<h3>Title: Tutorial on the Probabilistic Unification of Estimation Theory, Machine Learning, and Generative AI</h3>
<ul>
<li><strong>Authors: </strong>Mohammed Elmusrati</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.15719">https://arxiv.org/abs/2508.15719</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.15719">https://arxiv.org/pdf/2508.15719</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.15719]] Tutorial on the Probabilistic Unification of Estimation Theory, Machine Learning, and Generative AI(https://arxiv.org/abs/2508.15719)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability, generative, large language model</a></li>
<li><strong>Abstract: </strong>Extracting meaning from uncertain, noisy data is a fundamental problem across time series analysis, pattern recognition, and language modeling. This survey presents a unified mathematical framework that connects classical estimation theory, statistical inference, and modern machine learning, including deep learning and large language models. By analyzing how techniques such as maximum likelihood estimation, Bayesian inference, and attention mechanisms address uncertainty, the paper illustrates that many AI methods are rooted in shared probabilistic principles. Through illustrative scenarios including system identification, image classification, and language generation, we show how increasingly complex models build upon these foundations to tackle practical challenges like overfitting, data sparsity, and interpretability. In other words, the work demonstrates that maximum likelihood, MAP estimation, Bayesian classification, and deep learning all represent different facets of a shared goal: inferring hidden causes from noisy and/or biased observations. It serves as both a theoretical synthesis and a practical guide for students and researchers navigating the evolving landscape of machine learning.</li>
</ul>

<h3>Title: WorldWeaver: Generating Long-Horizon Video Worlds via Rich Perception</h3>
<ul>
<li><strong>Authors: </strong>Zhiheng Liu, Xueqing Deng, Shoufa Chen, Angtian Wang, Qiushan Guo, Mingfei Han, Zeyue Xue, Mengzhao Chen, Ping Luo, Linjie Yang</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.15720">https://arxiv.org/abs/2508.15720</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.15720">https://arxiv.org/pdf/2508.15720</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.15720]] WorldWeaver: Generating Long-Horizon Video Worlds via Rich Perception(https://arxiv.org/abs/2508.15720)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, diffusion, generative</a></li>
<li><strong>Abstract: </strong>Generative video modeling has made significant strides, yet ensuring structural and temporal consistency over long sequences remains a challenge. Current methods predominantly rely on RGB signals, leading to accumulated errors in object structure and motion over extended durations. To address these issues, we introduce WorldWeaver, a robust framework for long video generation that jointly models RGB frames and perceptual conditions within a unified long-horizon modeling scheme. Our training framework offers three key advantages. First, by jointly predicting perceptual conditions and color information from a unified representation, it significantly enhances temporal consistency and motion dynamics. Second, by leveraging depth cues, which we observe to be more resistant to drift than RGB, we construct a memory bank that preserves clearer contextual information, improving quality in long-horizon video generation. Third, we employ segmented noise scheduling for training prediction groups, which further mitigates drift and reduces computational cost. Extensive experiments on both diffusion- and rectified flow-based models demonstrate the effectiveness of WorldWeaver in reducing temporal drift and improving the fidelity of generated videos.</li>
</ul>

<h3>Title: EcomMMMU: Strategic Utilization of Visuals for Robust Multimodal E-Commerce Models</h3>
<ul>
<li><strong>Authors: </strong>Xinyi Ling, Hanwen Du, Zhihui Zhu, Xia Ning</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.15721">https://arxiv.org/abs/2508.15721</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.15721">https://arxiv.org/pdf/2508.15721</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.15721]] EcomMMMU: Strategic Utilization of Visuals for Robust Multimodal E-Commerce Models(https://arxiv.org/abs/2508.15721)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, large language model</a></li>
<li><strong>Abstract: </strong>E-commerce platforms are rich in multimodal data, featuring a variety of images that depict product details. However, this raises an important question: do these images always enhance product understanding, or can they sometimes introduce redundancy or degrade performance? Existing datasets are limited in both scale and design, making it difficult to systematically examine this question. To this end, we introduce EcomMMMU, an e-commerce multimodal multitask understanding dataset with 406,190 samples and 8,989,510 images. EcomMMMU is comprised of multi-image visual-language data designed with 8 essential tasks and a specialized VSS subset to benchmark the capability of multimodal large language models (MLLMs) to effectively utilize visual content. Analysis on EcomMMMU reveals that product images do not consistently improve performance and can, in some cases, degrade it. This indicates that MLLMs may struggle to effectively leverage rich visual content for e-commerce tasks. Building on these insights, we propose SUMEI, a data-driven method that strategically utilizes multiple images via predicting visual utilities before using them for downstream tasks. Comprehensive experiments demonstrate the effectiveness and robustness of SUMEI. The data and code are available through this https URL.</li>
</ul>

<h3>Title: Probability Density from Latent Diffusion Models for Out-of-Distribution Detection</h3>
<ul>
<li><strong>Authors: </strong>Joonas Järve, Karl Kaspar Haavel, Meelis Kull</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.15737">https://arxiv.org/abs/2508.15737</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.15737">https://arxiv.org/pdf/2508.15737</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.15737]] Probability Density from Latent Diffusion Models for Out-of-Distribution Detection(https://arxiv.org/abs/2508.15737)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, generative</a></li>
<li><strong>Abstract: </strong>Despite rapid advances in AI, safety remains the main bottleneck to deploying machine-learning systems. A critical safety component is out-of-distribution detection: given an input, decide whether it comes from the same distribution as the training data. In generative models, the most natural OOD score is the data likelihood. Actually, under the assumption of uniformly distributed OOD data, the likelihood is even the optimal OOD detector, as we show in this work. However, earlier work reported that likelihood often fails in practice, raising doubts about its usefulness. We explore whether, in practice, the representation space also suffers from the inability to learn good density estimation for OOD detection, or if it is merely a problem of the pixel space typically used in generative models. To test this, we trained a Variational Diffusion Model not on images, but on the representation space of a pre-trained ResNet-18 to assess the performance of our likelihood-based detector in comparison to state-of-the-art methods from the OpenOOD suite.</li>
</ul>

<h3>Title: End-to-End Agentic RAG System Training for Traceable Diagnostic Reasoning</h3>
<ul>
<li><strong>Authors: </strong>Qiaoyu Zheng, Yuze Sun, Chaoyi Wu, Weike Zhao, Pengcheng Qiu, Yongguo Yu, Kun Sun, Yanfeng Wang, Ya Zhang, Weidi Xie</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.15746">https://arxiv.org/abs/2508.15746</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.15746">https://arxiv.org/pdf/2508.15746</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.15746]] End-to-End Agentic RAG System Training for Traceable Diagnostic Reasoning(https://arxiv.org/abs/2508.15746)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability, large language model</a></li>
<li><strong>Abstract: </strong>Accurate diagnosis with medical large language models is hindered by knowledge gaps and hallucinations. Retrieval and tool-augmented methods help, but their impact is limited by weak use of external knowledge and poor feedback-reasoning traceability. To address these challenges, We introduce Deep-DxSearch, an agentic RAG system trained end-to-end with reinforcement learning (RL) that enables steer tracebale retrieval-augmented reasoning for medical diagnosis. In Deep-DxSearch, we first construct a large-scale medical retrieval corpus comprising patient records and reliable medical knowledge sources to support retrieval-aware reasoning across diagnostic scenarios. More crutially, we frame the LLM as the core agent and the retrieval corpus as its environment, using tailored rewards on format, retrieval, reasoning structure, and diagnostic accuracy, thereby evolving the agentic RAG policy from large-scale data through RL. Experiments demonstrate that our end-to-end agentic RL training framework consistently outperforms prompt-engineering and training-free RAG approaches across multiple data centers. After training, Deep-DxSearch achieves substantial gains in diagnostic accuracy, surpassing strong diagnostic baselines such as GPT-4o, DeepSeek-R1, and other medical-specific frameworks for both common and rare disease diagnosis under in-distribution and out-of-distribution settings. Moreover, ablation studies on reward design and retrieval corpus components confirm their critical roles, underscoring the uniqueness and effectiveness of our approach compared with traditional implementations. Finally, case studies and interpretability analyses highlight improvements in Deep-DxSearch's diagnostic policy, providing deeper insight into its performance gains and supporting clinicians in delivering more reliable and precise preliminary diagnoses. See this https URL.</li>
</ul>

<h3>Title: Fine-grained Multi-class Nuclei Segmentation with Molecular-empowered All-in-SAM Model</h3>
<ul>
<li><strong>Authors: </strong>Xueyuan Li, Can Cui, Ruining Deng, Yucheng Tang, Quan Liu, Tianyuan Yao, Shunxing Bao, Naweed Chowdhury, Haichun Yang, Yuankai Huo</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.15751">https://arxiv.org/abs/2508.15751</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.15751">https://arxiv.org/pdf/2508.15751</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.15751]] Fine-grained Multi-class Nuclei Segmentation with Molecular-empowered All-in-SAM Model(https://arxiv.org/abs/2508.15751)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>Purpose: Recent developments in computational pathology have been driven by advances in Vision Foundation Models, particularly the Segment Anything Model (SAM). This model facilitates nuclei segmentation through two primary methods: prompt-based zero-shot segmentation and the use of cell-specific SAM models for direct segmentation. These approaches enable effective segmentation across a range of nuclei and cells. However, general vision foundation models often face challenges with fine-grained semantic segmentation, such as identifying specific nuclei subtypes or particular cells. Approach: In this paper, we propose the molecular-empowered All-in-SAM Model to advance computational pathology by leveraging the capabilities of vision foundation models. This model incorporates a full-stack approach, focusing on: (1) annotation-engaging lay annotators through molecular-empowered learning to reduce the need for detailed pixel-level annotations, (2) learning-adapting the SAM model to emphasize specific semantics, which utilizes its strong generalizability with SAM adapter, and (3) refinement-enhancing segmentation accuracy by integrating Molecular-Oriented Corrective Learning (MOCL). Results: Experimental results from both in-house and public datasets show that the All-in-SAM model significantly improves cell classification performance, even when faced with varying annotation quality. Conclusions: Our approach not only reduces the workload for annotators but also extends the accessibility of precise biomedical image analysis to resource-limited settings, thereby advancing medical diagnostics and automating pathology image analysis.</li>
</ul>

<h3>Title: Dissecting Tool-Integrated Reasoning: An Empirical Study and Analysis</h3>
<ul>
<li><strong>Authors: </strong>Yufeng Zhao, Junnan Liu, Hongwei Liu, Dongsheng Zhu, Yuan Shen, Songyang Zhang, Kai Chen</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.15754">https://arxiv.org/abs/2508.15754</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.15754">https://arxiv.org/pdf/2508.15754</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.15754]] Dissecting Tool-Integrated Reasoning: An Empirical Study and Analysis(https://arxiv.org/abs/2508.15754)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large Language Models (LLMs) have made significant strides in reasoning tasks through methods like chain-of-thought (CoT) reasoning. However, they often fall short in tasks requiring precise computations. Tool-Integrated Reasoning (TIR) has emerged as a solution by incorporating external tools into the reasoning process. Nevertheless, the generalization of TIR in improving the reasoning ability of LLM is still unclear. Additionally, whether TIR has improved the model's reasoning behavior and helped the model think remains to be studied. We introduce ReasonZoo, a comprehensive benchmark encompassing nine diverse reasoning categories, to evaluate the effectiveness of TIR across various domains. Additionally, we propose two novel metrics, Performance-Aware Cost (PAC) and Area Under the Performance-Cost Curve (AUC-PCC), to assess reasoning efficiency. Our empirical evaluation demonstrates that TIR-enabled models consistently outperform their non-TIR counterparts in both mathematical and non-mathematical tasks. Furthermore, TIR enhances reasoning efficiency, as evidenced by improved PAC and AUC-PCC, indicating reduced overthinking and more streamlined reasoning. These findings underscore the domain-general benefits of TIR and its potential to advance LLM capabilities in complex reasoning tasks.</li>
</ul>

<h3>Title: Distributed Detection of Adversarial Attacks in Multi-Agent Reinforcement Learning with Continuous Action Space</h3>
<ul>
<li><strong>Authors: </strong>Kiarash Kazari, Ezzeldin Shereen, György Dán</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.MA</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.15764">https://arxiv.org/abs/2508.15764</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.15764">https://arxiv.org/pdf/2508.15764</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.15764]] Distributed Detection of Adversarial Attacks in Multi-Agent Reinforcement Learning with Continuous Action Space(https://arxiv.org/abs/2508.15764)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack</a></li>
<li><strong>Abstract: </strong>We address the problem of detecting adversarial attacks against cooperative multi-agent reinforcement learning with continuous action space. We propose a decentralized detector that relies solely on the local observations of the agents and makes use of a statistical characterization of the normal behavior of observable agents. The proposed detector utilizes deep neural networks to approximate the normal behavior of agents as parametric multivariate Gaussian distributions. Based on the predicted density functions, we define a normality score and provide a characterization of its mean and variance. This characterization allows us to employ a two-sided CUSUM procedure for detecting deviations of the normality score from its mean, serving as a detector of anomalous behavior in real-time. We evaluate our scheme on various multi-agent PettingZoo benchmarks against different state-of-the-art attack methods, and our results demonstrate the effectiveness of our method in detecting impactful adversarial attacks. Particularly, it outperforms the discrete counterpart by achieving AUC-ROC scores of over 0.95 against the most impactful attacks in all evaluated environments.</li>
</ul>

<h3>Title: Discovering Hidden Algebraic Structures via Transformers with Rank-Aware Beam GRPO</h3>
<ul>
<li><strong>Authors: </strong>Jaeha Lee, Gio Huh, Ning Su, Tony Yue YU</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.15766">https://arxiv.org/abs/2508.15766</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.15766">https://arxiv.org/pdf/2508.15766</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.15766]] Discovering Hidden Algebraic Structures via Transformers with Rank-Aware Beam GRPO(https://arxiv.org/abs/2508.15766)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Recent efforts have extended the capabilities of transformers in logical reasoning and symbolic computations. In this work, we investigate their capacity for non-linear latent pattern discovery in the context of functional decomposition, focusing on the challenging algebraic task of multivariate polynomial decomposition. This problem, with widespread applications in science and engineering, is proved to be NP-hard, and demands both precision and insight. Our contributions are threefold: First, we develop a synthetic data generation pipeline providing fine-grained control over problem complexity. Second, we train transformer models via supervised learning and evaluate them across four key dimensions involving scaling behavior and generalizability. Third, we propose Beam Grouped Relative Policy Optimization (BGRPO), a rank-aware reinforcement learning method suitable for hard algebraic problems. Finetuning with BGRPO improves accuracy while reducing beam width by up to half, resulting in approximately 75% lower inference compute. Additionally, our model demonstrates competitive performance in polynomial simplification, outperforming Mathematica in various cases.</li>
</ul>

<h3>Title: SceneGen: Single-Image 3D Scene Generation in One Feedforward Pass</h3>
<ul>
<li><strong>Authors: </strong>Yanxu Meng, Haoning Wu, Ya Zhang, Weidi Xie</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.15769">https://arxiv.org/abs/2508.15769</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.15769">https://arxiv.org/pdf/2508.15769</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.15769]] SceneGen: Single-Image 3D Scene Generation in One Feedforward Pass(https://arxiv.org/abs/2508.15769)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, extraction</a></li>
<li><strong>Abstract: </strong>3D content generation has recently attracted significant research interest due to its applications in VR/AR and embodied AI. In this work, we address the challenging task of synthesizing multiple 3D assets within a single scene image. Concretely, our contributions are fourfold: (i) we present SceneGen, a novel framework that takes a scene image and corresponding object masks as input, simultaneously producing multiple 3D assets with geometry and texture. Notably, SceneGen operates with no need for optimization or asset retrieval; (ii) we introduce a novel feature aggregation module that integrates local and global scene information from visual and geometric encoders within the feature extraction module. Coupled with a position head, this enables the generation of 3D assets and their relative spatial positions in a single feedforward pass; (iii) we demonstrate SceneGen's direct extensibility to multi-image input scenarios. Despite being trained solely on single-image inputs, our architectural design enables improved generation performance with multi-image inputs; and (iv) extensive quantitative and qualitative evaluations confirm the efficiency and robust generation abilities of our approach. We believe this paradigm offers a novel solution for high-quality 3D content generation, potentially advancing its practical applications in downstream tasks. The code and model will be publicly available at: this https URL.</li>
</ul>

<h3>Title: Visual Autoregressive Modeling for Instruction-Guided Image Editing</h3>
<ul>
<li><strong>Authors: </strong>Qingyang Mao, Qi Cai, Yehao Li, Yingwei Pan, Mingyue Cheng, Ting Yao, Qi Liu, Tao Mei</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.MM</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.15772">https://arxiv.org/abs/2508.15772</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.15772">https://arxiv.org/pdf/2508.15772</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.15772]] Visual Autoregressive Modeling for Instruction-Guided Image Editing(https://arxiv.org/abs/2508.15772)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>Recent advances in diffusion models have brought remarkable visual fidelity to instruction-guided image editing. However, their global denoising process inherently entangles the edited region with the entire image context, leading to unintended spurious modifications and compromised adherence to editing instructions. In contrast, autoregressive models offer a distinct paradigm by formulating image synthesis as a sequential process over discrete visual tokens. Their causal and compositional mechanism naturally circumvents the adherence challenges of diffusion-based methods. In this paper, we present VAREdit, a visual autoregressive (VAR) framework that reframes image editing as a next-scale prediction problem. Conditioned on source image features and text instructions, VAREdit generates multi-scale target features to achieve precise edits. A core challenge in this paradigm is how to effectively condition the source image tokens. We observe that finest-scale source features cannot effectively guide the prediction of coarser target features. To bridge this gap, we introduce a Scale-Aligned Reference (SAR) module, which injects scale-matched conditioning information into the first self-attention layer. VAREdit demonstrates significant advancements in both editing adherence and efficiency. On standard benchmarks, it outperforms leading diffusion-based methods by 30\%+ higher GPT-Balance score. Moreover, it completes a $512\times512$ editing in 1.2 seconds, making it 2.2$\times$ faster than the similarly sized UltraEdit. The models are available at this https URL.</li>
</ul>

<h3>Title: Scaling Group Inference for Diverse and High-Quality Generation</h3>
<ul>
<li><strong>Authors: </strong>Gaurav Parmar, Or Patashnik, Daniil Ostashev, Kuan-Chieh Wang, Kfir Aberman, Srinivasa Narasimhan, Jun-Yan Zhu</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.GR, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.15773">https://arxiv.org/abs/2508.15773</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.15773">https://arxiv.org/pdf/2508.15773</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.15773]] Scaling Group Inference for Diverse and High-Quality Generation(https://arxiv.org/abs/2508.15773)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>Generative models typically sample outputs independently, and recent inference-time guidance and scaling algorithms focus on improving the quality of individual samples. However, in real-world applications, users are often presented with a set of multiple images (e.g., 4-8) for each prompt, where independent sampling tends to lead to redundant results, limiting user choices and hindering idea exploration. In this work, we introduce a scalable group inference method that improves both the diversity and quality of a group of samples. We formulate group inference as a quadratic integer assignment problem: candidate outputs are modeled as graph nodes, and a subset is selected to optimize sample quality (unary term) while maximizing group diversity (binary term). To substantially improve runtime efficiency, we progressively prune the candidate set using intermediate predictions, allowing our method to scale up to large candidate sets. Extensive experiments show that our method significantly improves group diversity and quality compared to independent sampling baselines and recent inference algorithms. Our framework generalizes across a wide range of tasks, including text-to-image, image-to-image, image prompting, and video generation, enabling generative models to treat multiple outputs as cohesive groups rather than independent samples.</li>
</ul>

<h3>Title: CineScale: Free Lunch in High-Resolution Cinematic Visual Generation</h3>
<ul>
<li><strong>Authors: </strong>Haonan Qiu, Ning Yu, Ziqi Huang, Paul Debevec, Ziwei Liu</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.15774">https://arxiv.org/abs/2508.15774</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.15774">https://arxiv.org/pdf/2508.15774</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.15774]] CineScale: Free Lunch in High-Resolution Cinematic Visual Generation(https://arxiv.org/abs/2508.15774)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>Visual diffusion models achieve remarkable progress, yet they are typically trained at limited resolutions due to the lack of high-resolution data and constrained computation resources, hampering their ability to generate high-fidelity images or videos at higher resolutions. Recent efforts have explored tuning-free strategies to exhibit the untapped potential higher-resolution visual generation of pre-trained models. However, these methods are still prone to producing low-quality visual content with repetitive patterns. The key obstacle lies in the inevitable increase in high-frequency information when the model generates visual content exceeding its training resolution, leading to undesirable repetitive patterns deriving from the accumulated errors. In this work, we propose CineScale, a novel inference paradigm to enable higher-resolution visual generation. To tackle the various issues introduced by the two types of video generation architectures, we propose dedicated variants tailored to each. Unlike existing baseline methods that are confined to high-resolution T2I and T2V generation, CineScale broadens the scope by enabling high-resolution I2V and V2V synthesis, built atop state-of-the-art open-source video generation frameworks. Extensive experiments validate the superiority of our paradigm in extending the capabilities of higher-resolution visual generation for both image and video models. Remarkably, our approach enables 8k image generation without any fine-tuning, and achieves 4k video generation with only minimal LoRA fine-tuning. Generated video samples are available at our website: this https URL.</li>
</ul>

<button id="copy">Copy All</button>
</article>
<script src="../../javascript/clipboard.min.js"></script>
<script src="../../javascript/clipboard.js"></script>
