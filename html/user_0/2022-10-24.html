<link rel="stylesheet" href="../../css/markdown.css" />
<article class="markdown-body">
<h2>secure</h2>
<h3>Title: Proof of Backhaul: Trustfree Measurement of Broadband Bandwidth. (arXiv:2210.11546v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2210.11546">http://arxiv.org/abs/2210.11546</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2210.11546] Proof of Backhaul: Trustfree Measurement of Broadband Bandwidth](http://arxiv.org/abs/2210.11546)</code></li>
<li>Summary: <p>Recent years have seen the emergence of decentralized wireless networks
consisting of nodes hosted by many individuals and small enterprises,
reawakening the decades-old dream of open networking. These networks have been
deployed in an organic, distributed manner and are driven by new economic
models resting on tokenized incentives. A critical requirement for the
incentives to scale is the ability to prove network performance in a
decentralized trustfree manner, i.e., a Byzantine fault tolerant network
telemetry system. In this paper, we present a Proof of Backhaul (PoB) protocol
which measures the bandwidth of the (broadband) backhaul link of a wireless
access point, termed prover, in a decentralized and trustfree manner. In
particular, our proposed protocol is the first one to satisfy the following two
properties: (1) Trustfree. Bandwidth measurement is secure against Byzantine
attacks by collaborations of challenge servers and the prover. (2) Open. The
barrier-to-entry for being a challenge server is low; there is no requirement
of having a low latency and high throughput path to the measured link. At a
high-level, our protocol aggregates the challenge traffic from multiple
challenge servers and uses cryptographic primitives to ensure that a subset of
challengers or, even challengers and provers, cannot maliciously modify results
in their favor. A formal security model allows us to establish guarantees of
accurate bandwidth measurement as a function of the fraction of malicious
actors. Our evaluation shows that our PoB protocol can verify backhaul
bandwidth of up to 1000 Mbps with less than 8% error using measurements lasting
only 100 ms. The measurement accuracy is not affected in the presence of
corrupted challengers. Importantly, the basic verification protocol lends
itself to a minor modification that can measure available bandwidth even in the
presence of cross-traffic.
</p></li>
</ul>

<h3>Title: TrustBoost: Boosting Trust among Interoperable Blockchains. (arXiv:2210.11571v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2210.11571">http://arxiv.org/abs/2210.11571</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2210.11571] TrustBoost: Boosting Trust among Interoperable Blockchains](http://arxiv.org/abs/2210.11571)</code></li>
<li>Summary: <p>Currently there exist many blockchains with weak trust guarantees, limiting
applications and participation. Existing solutions to boost the trust using a
stronger blockchain, e.g., via checkpointing, requires the weaker blockchain to
give up sovereignty. In this paper we propose a family of protocols in which
multiple blockchains interact to create a combined ledger with boosted trust.
We show that even if several of the interacting blockchains cease to provide
security guarantees, the combined ledger continues to be secure - our
TrustBoost protocols achieve the optimal threshold of tolerating the insecure
blockchains. Furthermore, the protocol simply operates via smart contracts and
require no change to the underlying consensus protocols of the participating
blockchains, a form of "consensus on top of consensus". The protocols are
lightweight and can be used on specific (e.g., high value) transactions; we
demonstrate the practicality by implementing and deploying TrustBoost as
cross-chain smart contracts in the Cosmos ecosystem using approximately 3,000
lines of Rust code, made available as open source. Our evaluation shows that
using 10 Cosmos chains in a local testnet, TrustBoost has a gas cost of roughly
$2 with a latency of 2 minutes per request, which is in line with the cost on a
high security chain such as Bitcoin or Ethereum.
</p></li>
</ul>

<h3>Title: SCL: A Secure Concurrency Layer For Paranoid Stateful Lambdas. (arXiv:2210.11703v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2210.11703">http://arxiv.org/abs/2210.11703</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2210.11703] SCL: A Secure Concurrency Layer For Paranoid Stateful Lambdas](http://arxiv.org/abs/2210.11703)</code></li>
<li>Summary: <p>We propose a federated Function-as-a-Service (FaaS) execution model that
provides secure and stateful execution in both Cloud and Edge environments. The
FaaS workers, called Paranoid Stateful Lambdas (PSLs), collaborate with one
another to perform large parallel computations. We exploit cryptographically
hardened and mobile bundles of data, called DataCapsules, to provide persistent
state for our PSLs, whose execution is protected using hardware-secured TEEs.
To make PSLs easy to program and performant, we build the familiar Key-Value
Store interface on top of DataCapsules in a way that allows amortization of
cryptographic operations. We demonstrate PSLs functioning in an edge
environment running on a group of Intel NUCs with SGXv2.
</p></li>
</ul>

<p>As described, our Secure Concurrency Layer (SCL), provides
eventually-consistent semantics over written values using untrusted and
unordered multicast. All SCL communication is encrypted, unforgeable, and
private. For durability, updates are recorded in replicated DataCapsules, which
are append-only cryptographically-hardened blockchain with confidentiality,
integrity, and provenance guarantees. Values for inactive keys are stored in a
log-structured merge-tree (LSM) in the same DataCapsule. SCL features a variety
of communication optimizations, such as an efficient message passing framework
that reduces the latency up to 44x from the Intel SGX SDK, and an actor-based
cryptographic processing architecture that batches cryptographic operations and
increases throughput by 81x.
</p>

<h2>security</h2>
<h3>Title: GaitMAST: Motion-Aware Spatio-Temporal Feature Learning Network for Cross-View Gait Recognition. (arXiv:2210.11817v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2210.11817">http://arxiv.org/abs/2210.11817</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2210.11817] GaitMAST: Motion-Aware Spatio-Temporal Feature Learning Network for Cross-View Gait Recognition](http://arxiv.org/abs/2210.11817)</code></li>
<li>Summary: <p>As a unique biometric that can be perceived at a distance, gait has broad
applications in person authentication, social security and so on. Existing gait
recognition methods pay attention to extracting either spatial or
spatiotemporal representations. However, they barely consider extracting
diverse motion features, a fundamental characteristic in gaits, from gait
sequences. In this paper, we propose a novel motion-aware spatiotemporal
feature learning network for gait recognition, termed GaitMAST, which can
unleash the potential of motion-aware features. In the shallow layer,
specifically, we propose a dual-path frame-level feature extractor, in which
one path extracts overall spatiotemporal features and the other extracts motion
salient features by focusing on dynamic regions. In the deeper layers, we
design a two-branch clip-level feature extractor, in which one focuses on
fine-grained spatial information and the other on motion detail preservation.
Consequently, our GaitMAST preserves the individual's unique walking patterns
well, further enhancing the robustness of spatiotemporal features. Extensive
experimental results on two commonly-used cross-view gait datasets demonstrate
the superior performance of GaitMAST over existing state-of-the-art methods. On
CASIA-B, our model achieves an average rank-1 accuracy of 94.1%. In particular,
GaitMAST achieves rank-1 accuracies of 96.1% and 88.1% under the bag-carry and
coat wearing conditions, respectively, outperforming the second best by a large
margin and demonstrating its robustness against spatial variations.
</p></li>
</ul>

<h3>Title: Trust-as-a-Service: A reputation-enabled trust framework for 5G networks. (arXiv:2210.11501v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2210.11501">http://arxiv.org/abs/2210.11501</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2210.11501] Trust-as-a-Service: A reputation-enabled trust framework for 5G networks](http://arxiv.org/abs/2210.11501)</code></li>
<li>Summary: <p>Trust, security, and privacy are three of the major pillars to assemble the
fifth generation network and beyond. Despite such pillars are principally
interconnected, they arise a multitude of challenges to be addressed
separately. 5G ought to offer flexible and pervasive computing capabilities
across multiple domains according to user demands and assuring trustworthy
network providers. Distributed marketplaces expect to boost the trading of
heterogeneous resources so as to enable the establishment of pervasive service
chains between cross-domains. Nevertheless, the need for reliable parties as
``marketplace operators'' plays a pivotal role to achieving a trustworthy
ecosystem. One of the principal blockages in managing foreseeable networks is
the need of adapting previous trust models to accomplish the new network and
business requirements. In this regard, this article is centered on trust
management of 5G multi-party networks. The design of a reputation-based trust
framework is proposed as a Trust-as-a-Service (TaaS) solution for any
distributed multi-stakeholder environment where zero trust and zero-touch
principles should be met. Besides, a literature review is also conducted to
recognize the network and business requirements currently envisaged. Finally,
the validation of the proposed trust framework is performed in a real research
environment, the 5GBarcelona testbed, leveraging 12% of a 2.1GHz CPU with 20
cores and 2% of the 30GiB memory. In this regard, these outcomes reveal the
feasibility of the TaaS solution in the context of determining reliable network
operators.
</p></li>
</ul>

<h3>Title: A Security and Trust Framework for Decentralized 5G Marketplaces. (arXiv:2210.11517v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2210.11517">http://arxiv.org/abs/2210.11517</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2210.11517] A Security and Trust Framework for Decentralized 5G Marketplaces](http://arxiv.org/abs/2210.11517)</code></li>
<li>Summary: <p>5G networks intend to cover user demands through multi-party collaborations
in a secure and trustworthy manner. To this end, marketplaces play a pivotal
role as enablers for network service consumers and infrastructure providers to
offer, negotiate, and purchase 5G resources and services. Nevertheless,
marketplaces often do not ensure trustworthy networking by analyzing the
security and trust of their members and offers. This paper presents a security
and trust framework to enable the selection of reliable third-party providers
based on their history and reputation. In addition, it also introduces a reward
and punishment mechanism to continuously update trust scores according to
security events. Finally, we showcase a real use case in which the security and
trust framework is being applied.
</p></li>
</ul>

<h3>Title: A critical review of cyber-physical security for building automation systems. (arXiv:2210.11726v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2210.11726">http://arxiv.org/abs/2210.11726</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2210.11726] A critical review of cyber-physical security for building automation systems](http://arxiv.org/abs/2210.11726)</code></li>
<li>Summary: <p>Modern Building Automation Systems (BASs), as the brain that enables the
smartness of a smart building, often require increased connectivity both among
system components as well as with outside entities, such as optimized
automation via outsourced cloud analytics and increased building-grid
integrations. However, increased connectivity and accessibility come with
increased cyber security threats. BASs were historically developed as closed
environments with limited cyber-security considerations. As a result, BASs in
many buildings are vulnerable to cyber-attacks that may cause adverse
consequences, such as occupant discomfort, excessive energy usage, and
unexpected equipment downtime. Therefore, there is a strong need to advance the
state-of-the-art in cyber-physical security for BASs and provide practical
solutions for attack mitigation in buildings. However, an inclusive and
systematic review of BAS vulnerabilities, potential cyber-attacks with impact
assessment, detection &amp; defense approaches, and cyber-secure resilient control
strategies is currently lacking in the literature. This review paper fills the
gap by providing a comprehensive up-to-date review of cyber-physical security
for BASs at three levels in commercial buildings: management level, automation
level, and field level. The general BASs vulnerabilities and protocol-specific
vulnerabilities for the four dominant BAS protocols are reviewed, followed by a
discussion on four attack targets and seven potential attack scenarios. The
impact of cyber-attacks on BASs is summarized as signal corruption, signal
delaying, and signal blocking. The typical cyber-attack detection and defense
approaches are identified at the three levels. Cyber-secure resilient control
strategies for BASs under attack are categorized into passive and active
resilient control schemes. Open challenges and future opportunities are finally
discussed.
</p></li>
</ul>

<h3>Title: $A^2RID$ -- Anonymous Direct Authentication and Remote Identification of Commercial Drones. (arXiv:2210.11743v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2210.11743">http://arxiv.org/abs/2210.11743</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2210.11743] $A^2RID$ -- Anonymous Direct Authentication and Remote Identification of Commercial Drones](http://arxiv.org/abs/2210.11743)</code></li>
<li>Summary: <p>The recent worldwide introduction of RemoteID (RID) regulations forces all
Unmanned Aircrafts (UAs), a.k.a. drones, to broadcast in plaintext on the
wireless channel their identity and real-time location, for accounting and
monitoring purposes. Although improving drones' monitoring and situational
awareness, the RID rule also generates significant privacy concerns for UAs'
operators, threatened by the ease of tracking of UAs and related
confidentiality and privacy concerns connected with the broadcasting of
plaintext identity information. In this paper, we propose $A^2RID$, a protocol
suite for anonymous direct authentication and remote identification of
heterogeneous commercial UAs. $A^2RID$ integrates and adapts protocols for
anonymous message signing to work in the UA domain, coping with the constraints
of commercial drones and the tight real-time requirements imposed by the RID
regulation. Overall, the protocols in the $A^2RID$ suite allow a UA
manufacturer to pick the configuration that best suits the capabilities and
constraints of the drone, i.e., either a processing-intensive but
memory-lightweight solution (namely, $CS-A^2RID$) or a computationally-friendly
but memory-hungry approach (namely, $DS-A^2RID$). Besides formally defining the
protocols and formally proving their security in our setting, we also implement
and test them on real heterogeneous hardware platforms, i.e., the Holybro X-500
and the ESPcopter, releasing open-source the produced code. For all the
protocols, we demonstrated experimentally the capability of generating
anonymous RemoteID messages well below the time bound of $1$ second required by
RID, while at the same time having quite a limited impact on the energy budget
of the drone.
</p></li>
</ul>

<h3>Title: BC-IoDT: Blockchain-based Framework for Authentication in Internet of Drone Things. (arXiv:2210.11745v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2210.11745">http://arxiv.org/abs/2210.11745</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2210.11745] BC-IoDT: Blockchain-based Framework for Authentication in Internet of Drone Things](http://arxiv.org/abs/2210.11745)</code></li>
<li>Summary: <p>We leverage blockchain technology for drone node authentication in internet
of drone things (IoDT). During the authentication procedure, the credentials of
drone nodes are examined to remove malicious nodes from the system. In IoDT,
drones are responsible for gathering data and transmitting it to cluster heads
(CHs) for further processing. The CH collects and organizes data. Due to
computational load, their energy levels rapidly deplete. To overcome this
problem, we present a low-energy adaptive clustering hierarchy (R2D) protocol
based on distance, degree, and residual energy. R2D is used to replace CHs with
normal nodes based on the biggest residual energy, the degree, and the shortest
distance from BS. The cost of keeping a big volume of data on the blockchain is
high. We employ the Interplanetary File System (IPFS), to address this issue.
Moreover, IPFS protects user data using the industry-standard encryption
technique AES-128. This standard compares well to other current encryption
methods. Using a consensus mechanism based on proof of work requires a high
amount of computing resources for transaction verification. The suggested
approach leverages a consensus mechanism known as proof of authority (PoA) to
address this problem . The results of the simulations indicate that the
suggested system model functions effectively and efficiently. A formal security
analysis is conducted to assess the smart contract's resistance to attacks.
</p></li>
</ul>

<h3>Title: An Empirical Study on Real Bug Fixes in Smart Contracts Projects. (arXiv:2210.11990v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2210.11990">http://arxiv.org/abs/2210.11990</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2210.11990] An Empirical Study on Real Bug Fixes in Smart Contracts Projects](http://arxiv.org/abs/2210.11990)</code></li>
<li>Summary: <p>Blockchain uses cryptographic proof to replace trusted third parties to
ensure the correctness of the information, allowing any two willing parties to
transact directly with each other. Smart contracts are pieces of code that
reside inside the blockchains and can be triggered to execute any transaction
when specifically predefined conditions are satisfied. Being commonly used for
commercial transactions in blockchain makes the security of smart contracts
particularly important. Over the last few years, we have seen a great deal of
academic and practical interest in detecting and repairing the vulnerabilities
in smart contracts developed for the Ethereum blockchain. In this paper, we
conduct an empirical study on historical bug fixing versions of 46 real-world
smart contracts projects from Github, providing a multi-faceted discussion. In
this paper, we mainly explore the following four questions: File Type and
Amount, Fix Complexity, Bug distribution, and Fix Patches. By analyzing the
file type, amount, and fix complexity, we find that about 80% of the
bug-related commits modified no more than one solidity source file to fix bugs.
Up to 80% of bugs in solidity source files can be fixed by less than three fix
actions. Modification is the mostly used fix action, which involves three lines
of code on average. By using the analysis tool Mythril to detect the
vulnerabilities, we find that nearly 20% of the solidity files in our dataset
had or have had vulnerabilities. We finally find that the developers may not
put much attention to fixing vulnerabilities reported by Mythril completely or
avoid introducing them again. Because vulnerabilities that have a high repair
percentage usually have a high rate to be introduced again.
</p></li>
</ul>

<h3>Title: Do Content Management Systems Impact the Security of Free Content Websites? A Correlation Analysis. (arXiv:2210.12083v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2210.12083">http://arxiv.org/abs/2210.12083</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2210.12083] Do Content Management Systems Impact the Security of Free Content Websites? A Correlation Analysis](http://arxiv.org/abs/2210.12083)</code></li>
<li>Summary: <p>This paper investigates the potential causes of the vulnerabilities of free
content websites to address risks and maliciousness. Assembling more than 1,500
websites with free and premium content, we identify their content management
system (CMS) and malicious attributes. We use frequency analysis at both the
aggregate and per category of content (books, games, movies, music, and
software), utilizing the unpatched vulnerabilities, total vulnerabilities,
malicious count, and percentiles to uncover trends and affinities of usage and
maliciousness of CMS{'s} and their contribution to those websites. Moreover, we
find that, despite the significant number of custom code websites, the use of
CMS{'s} is pervasive, with varying trends across types and categories. Finally,
we find that even a small number of unpatched vulnerabilities in popular
CMS{'s} could be a potential cause for significant maliciousness.
</p></li>
</ul>

<h3>Title: Global Counterfactual Explainer for Graph Neural Networks. (arXiv:2210.11695v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2210.11695">http://arxiv.org/abs/2210.11695</a></li>
<li>Code URL: <a href="https://github.com/mertkosan/GCFExplainer">https://github.com/mertkosan/GCFExplainer</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2210.11695] Global Counterfactual Explainer for Graph Neural Networks](http://arxiv.org/abs/2210.11695)</code></li>
<li>Summary: <p>Graph neural networks (GNNs) find applications in various domains such as
computational biology, natural language processing, and computer security.
Owing to their popularity, there is an increasing need to explain GNN
predictions since GNNs are black-box machine learning models. One way to
address this is counterfactual reasoning where the objective is to change the
GNN prediction by minimal changes in the input graph. Existing methods for
counterfactual explanation of GNNs are limited to instance-specific local
reasoning. This approach has two major limitations of not being able to offer
global recourse policies and overloading human cognitive ability with too much
information. In this work, we study the global explainability of GNNs through
global counterfactual reasoning. Specifically, we want to find a small set of
representative counterfactual graphs that explains all input graphs. Towards
this goal, we propose GCFExplainer, a novel algorithm powered by
vertex-reinforced random walks on an edit map of graphs with a greedy summary.
Extensive experiments on real graph datasets show that the global explanation
from GCFExplainer provides important high-level insights of the model behavior
and achieves a 46.9% gain in recourse coverage and a 9.5% reduction in recourse
cost compared to the state-of-the-art local counterfactual explainers.
</p></li>
</ul>

<h2>privacy</h2>
<h3>Title: Boomerang: Local sampling on image manifolds using diffusion models. (arXiv:2210.12100v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2210.12100">http://arxiv.org/abs/2210.12100</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2210.12100] Boomerang: Local sampling on image manifolds using diffusion models](http://arxiv.org/abs/2210.12100)</code></li>
<li>Summary: <p>Diffusion models can be viewed as mapping points in a high-dimensional latent
space onto a low-dimensional learned manifold, typically an image manifold. The
intermediate values between the latent space and image manifold can be
interpreted as noisy images which are determined by the noise scheduling scheme
employed during pre-training. We exploit this interpretation to introduce
Boomerang, a local image manifold sampling approach using the dynamics of
diffusion models. We call it Boomerang because we first add noise to an input
image, moving it closer to the latent space, then bring it back to the image
space through diffusion dynamics. We use this method to generate images which
are similar, but nonidentical, to the original input images on the image
manifold. We are able to set how close the generated image is to the original
based on how much noise we add. Additionally, the generated images have a
degree of stochasticity, allowing us to locally sample as many times as we want
without repetition. We show three applications for which Boomerang can be used.
First, we provide a framework for constructing privacy-preserving datasets
having controllable degrees of anonymity. Second, we show how to use Boomerang
for data augmentation while staying on the image manifold. Third, we introduce
a framework for image super-resolution with 8x upsampling. Boomerang does not
require any modification to the training of diffusion models and can be used
with pretrained models on a single, inexpensive GPU.
</p></li>
</ul>

<h3>Title: Unsupervised Text Deidentification. (arXiv:2210.11528v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2210.11528">http://arxiv.org/abs/2210.11528</a></li>
<li>Code URL: <a href="https://github.com/jxmorris12/unsupervised-text-deidentification">https://github.com/jxmorris12/unsupervised-text-deidentification</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2210.11528] Unsupervised Text Deidentification](http://arxiv.org/abs/2210.11528)</code></li>
<li>Summary: <p>Deidentification seeks to anonymize textual data prior to distribution.
Automatic deidentification primarily uses supervised named entity recognition
from human-labeled data points. We propose an unsupervised deidentification
method that masks words that leak personally-identifying information. The
approach utilizes a specially trained reidentification model to identify
individuals from redacted personal documents. Motivated by K-anonymity based
privacy, we generate redactions that ensure a minimum reidentification rank for
the correct profile of the document. To evaluate this approach, we consider the
task of deidentifying Wikipedia Biographies, and evaluate using an adversarial
reidentification metric. Compared to a set of unsupervised baselines, our
approach deidentifies documents more completely while removing fewer words.
Qualitatively, we see that the approach eliminates many identifying aspects
that would fall outside of the common named entity based approach.
</p></li>
</ul>

<h3>Title: Audio-to-Intent Using Acoustic-Textual Subword Representations from End-to-End ASR. (arXiv:2210.12134v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2210.12134">http://arxiv.org/abs/2210.12134</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2210.12134] Audio-to-Intent Using Acoustic-Textual Subword Representations from End-to-End ASR](http://arxiv.org/abs/2210.12134)</code></li>
<li>Summary: <p>Accurate prediction of the user intent to interact with a voice assistant
(VA) on a device (e.g. on the phone) is critical for achieving naturalistic,
engaging, and privacy-centric interactions with the VA. To this end, we present
a novel approach to predict the user's intent (the user speaking to the device
or not) directly from acoustic and textual information encoded at subword
tokens which are obtained via an end-to-end ASR model. Modeling directly the
subword tokens, compared to modeling of the phonemes and/or full words, has at
least two advantages: (i) it provides a unique vocabulary representation, where
each token has a semantic meaning, in contrast to the phoneme-level
representations, (ii) each subword token has a reusable "sub"-word acoustic
pattern (that can be used to construct multiple full words), resulting in a
largely reduced vocabulary space than of the full words. To learn the subword
representations for the audio-to-intent classification, we extract: (i)
acoustic information from an E2E-ASR model, which provides frame-level CTC
posterior probabilities for the subword tokens, and (ii) textual information
from a pre-trained continuous bag-of-words model capturing the semantic meaning
of the subword tokens. The key to our approach is the way it combines acoustic
subword-level posteriors with text information using the notion of
positional-encoding in order to account for multiple ASR hypotheses
simultaneously. We show that our approach provides more robust and richer
representations for audio-to-intent classification, and is highly accurate with
correctly mitigating 93.3% of unintended user audio from invoking the smart
assistant at 99% true positive rate.
</p></li>
</ul>

<h3>Title: TAP: Transparent and Privacy-Preserving Data Services. (arXiv:2210.11702v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2210.11702">http://arxiv.org/abs/2210.11702</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2210.11702] TAP: Transparent and Privacy-Preserving Data Services](http://arxiv.org/abs/2210.11702)</code></li>
<li>Summary: <p>Users today expect more security from services that handle their data. In
addition to traditional data privacy and integrity requirements, they expect
transparency, i.e., that the service's processing of the data is verifiable by
users and trusted auditors. Our goal is to build a multi-user system that
provides data privacy, integrity, and transparency for a large number of
operations, while achieving practical performance.
</p></li>
</ul>

<p>To this end, we first identify the limitations of existing approaches that
use authenticated data structures. We find that they fall into two categories:
1) those that hide each user's data from other users, but have a limited range
of verifiable operations (e.g., CONIKS, Merkle2, and Proofs of Liabilities),
and 2) those that support a wide range of verifiable operations, but make all
data publicly visible (e.g., IntegriDB and FalconDB). We then present TAP to
address the above limitations. The key component of TAP is a novel tree data
structure that supports efficient result verification, and relies on
independent audits that use zero-knowledge range proofs to show that the tree
is constructed correctly without revealing user data. TAP supports a broad
range of verifiable operations, including quantiles and sample standard
deviations. We conduct a comprehensive evaluation of TAP, and compare it
against two state-of-the-art baselines, namely IntegriDB and Merkle2, showing
that the system is practical at scale.
</p>

<h3>Title: Extracted BERT Model Leaks More Information than You Think!. (arXiv:2210.11735v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2210.11735">http://arxiv.org/abs/2210.11735</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2210.11735] Extracted BERT Model Leaks More Information than You Think!](http://arxiv.org/abs/2210.11735)</code></li>
<li>Summary: <p>The collection and availability of big data, combined with advances in
pre-trained models (e.g. BERT), have revolutionized the predictive performance
of natural language processing tasks. This allows corporations to provide
machine learning as a service (MLaaS) by encapsulating fine-tuned BERT-based
models as APIs. Due to significant commercial interest, there has been a surge
of attempts to steal re mote services via model extraction. Although previous
works have made progress in defending against model extraction attacks, there
has been little discussion on their performance in preventing privacy leakage.
This work bridges this gap by launching an attribute inference attack against
the extracted BERT model. Our extensive experiments reveal that model
extraction can cause severe privacy leakage even when victim models are
facilitated with advanced defensive strategies.
</p></li>
</ul>

<h3>Title: The privacy issue of counterfactual explanations: explanation linkage attacks. (arXiv:2210.12051v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2210.12051">http://arxiv.org/abs/2210.12051</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2210.12051] The privacy issue of counterfactual explanations: explanation linkage attacks](http://arxiv.org/abs/2210.12051)</code></li>
<li>Summary: <p>Black-box machine learning models are being used in more and more high-stakes
domains, which creates a growing need for Explainable AI (XAI). Unfortunately,
the use of XAI in machine learning introduces new privacy risks, which
currently remain largely unnoticed. We introduce the explanation linkage
attack, which can occur when deploying instance-based strategies to find
counterfactual explanations. To counter such an attack, we propose k-anonymous
counterfactual explanations and introduce pureness as a new metric to evaluate
the validity of these k-anonymous counterfactual explanations. Our results show
that making the explanations, rather than the whole dataset, k- anonymous, is
beneficial for the quality of the explanations.
</p></li>
</ul>

<h3>Title: Efficient Dataset Distillation Using Random Feature Approximation. (arXiv:2210.12067v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2210.12067">http://arxiv.org/abs/2210.12067</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2210.12067] Efficient Dataset Distillation Using Random Feature Approximation](http://arxiv.org/abs/2210.12067)</code></li>
<li>Summary: <p>Dataset distillation compresses large datasets into smaller synthetic
coresets which retain performance with the aim of reducing the storage and
computational burden of processing the entire dataset. Today's best-performing
algorithm, \textit{Kernel Inducing Points} (KIP), which makes use of the
correspondence between infinite-width neural networks and kernel-ridge
regression, is prohibitively slow due to the exact computation of the neural
tangent kernel matrix, scaling $O(|S|^2)$, with $|S|$ being the coreset size.
To improve this, we propose a novel algorithm that uses a random feature
approximation (RFA) of the Neural Network Gaussian Process (NNGP) kernel, which
reduces the kernel matrix computation to $O(|S|)$. Our algorithm provides at
least a 100-fold speedup over KIP and can run on a single GPU. Our new method,
termed an RFA Distillation (RFAD), performs competitively with KIP and other
dataset condensation algorithms in accuracy over a range of large-scale
datasets, both in kernel regression and finite-width network training. We
demonstrate the effectiveness of our approach on tasks involving model
interpretability and privacy preservation.
</p></li>
</ul>

<h3>Title: A Survey on Graph Counterfactual Explanations: Definitions, Methods, Evaluation. (arXiv:2210.12089v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2210.12089">http://arxiv.org/abs/2210.12089</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2210.12089] A Survey on Graph Counterfactual Explanations: Definitions, Methods, Evaluation](http://arxiv.org/abs/2210.12089)</code></li>
<li>Summary: <p>In recent years, Graph Neural Networks have reported outstanding performance
in tasks like community detection, molecule classification and link prediction.
However, the black-box nature of these models prevents their application in
domains like health and finance, where understanding the models' decisions is
essential. Counterfactual Explanations (CE) provide these understandings
through examples. Moreover, the literature on CE is flourishing with novel
explanation methods which are tailored to graph learning.
</p></li>
</ul>

<p>In this survey, we analyse the existing Graph Counterfactual Explanation
methods, by providing the reader with an organisation of the literature
according to a uniform formal notation for definitions, datasets, and metrics,
thus, simplifying potential comparisons w.r.t to the method advantages and
disadvantages. We discussed seven methods and sixteen synthetic and real
datasets providing details on the possible generation strategies. We highlight
the most common evaluation strategies and formalise nine of the metrics used in
the literature. We first introduce the evaluation framework GRETEL and how it
is possible to extend and use it while providing a further dimension of
comparison encompassing reproducibility aspects. Finally, we provide a
discussion on how counterfactual explanation interplays with privacy and
fairness, before delving into open challenges and future works.
</p>

<h3>Title: Privacy-Preserved Neural Graph Similarity Learning. (arXiv:2210.11730v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2210.11730">http://arxiv.org/abs/2210.11730</a></li>
<li>Code URL: <a href="https://github.com/rucaibox/ppgm">https://github.com/rucaibox/ppgm</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2210.11730] Privacy-Preserved Neural Graph Similarity Learning](http://arxiv.org/abs/2210.11730)</code></li>
<li>Summary: <p>To develop effective and efficient graph similarity learning (GSL) models, a
series of data-driven neural algorithms have been proposed in recent years.
Although GSL models are frequently deployed in privacy-sensitive scenarios, the
user privacy protection of neural GSL models has not drawn much attention. To
comprehensively understand the privacy protection issues, we first introduce
the concept of attackable representation to systematically characterize the
privacy attacks that each model can face. Inspired by the qualitative results,
we propose a novel Privacy-Preserving neural Graph Matching network model,
named PPGM, for graph similarity learning. To prevent reconstruction attacks,
the proposed model does not communicate node-level representations between
devices. Instead, we learn multi-perspective graph representations based on
learnable context vectors. To alleviate the attacks to graph properties, the
obfuscated features that contain information from both graphs are communicated.
In this way, the private properties of each graph can be difficult to infer.
Based on the node-graph matching techniques while calculating the obfuscated
features, PPGM can also be effective in similarity measuring. To quantitatively
evaluate the privacy-preserving ability of neural GSL models, we further
propose an evaluation protocol via training supervised black-box attack models.
Extensive experiments on widely-used benchmarks show the effectiveness and
strong privacy-protection ability of the proposed model PPGM. The code is
available at: https://github.com/RUCAIBox/PPGM.
</p></li>
</ul>

<h2>protect</h2>
<h3>Title: Transferring learned patterns from ground-based field imagery to predict UAV-based imagery for crop and weed semantic segmentation in precision crop farming. (arXiv:2210.11545v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2210.11545">http://arxiv.org/abs/2210.11545</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2210.11545] Transferring learned patterns from ground-based field imagery to predict UAV-based imagery for crop and weed semantic segmentation in precision crop farming](http://arxiv.org/abs/2210.11545)</code></li>
<li>Summary: <p>Weed and crop segmentation is becoming an increasingly integral part of
precision farming that leverages the current computer vision and deep learning
technologies. Research has been extensively carried out based on images
captured with a camera from various platforms. Unmanned aerial vehicles (UAVs)
and ground-based vehicles including agricultural robots are the two popular
platforms for data collection in fields. They all contribute to site-specific
weed management (SSWM) to maintain crop yield. Currently, the data from these
two platforms is processed separately, though sharing the same semantic objects
(weed and crop). In our paper, we have developed a deep convolutional network
that enables to predict both field and aerial images from UAVs for weed
segmentation and mapping with only field images provided in the training phase.
The network learning process is visualized by feature maps at shallow and deep
layers. The results show that the mean intersection of union (IOU) values of
the segmentation for the crop (maize), weeds, and soil background in the
developed model for the field dataset are 0.744, 0.577, 0.979, respectively,
and the performance of aerial images from an UAV with the same model, the IOU
values of the segmentation for the crop (maize), weeds and soil background are
0.596, 0.407, and 0.875, respectively. To estimate the effect on the use of
plant protection agents, we quantify the relationship between herbicide
spraying saving rate and grid size (spraying resolution) based on the predicted
weed map. The spraying saving rate is up to 90% when the spraying resolution is
at 1.78 x 1.78 cm2. The study shows that the developed deep convolutional
neural network could be used to classify weeds from both field and aerial
images and delivers satisfactory results.
</p></li>
</ul>

<h2>defense</h2>
<h3>Title: Distilling the Undistillable: Learning from a Nasty Teacher. (arXiv:2210.11728v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2210.11728">http://arxiv.org/abs/2210.11728</a></li>
<li>Code URL: <a href="https://github.com/surgan12/nastyattacks">https://github.com/surgan12/nastyattacks</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2210.11728] Distilling the Undistillable: Learning from a Nasty Teacher](http://arxiv.org/abs/2210.11728)</code></li>
<li>Summary: <p>The inadvertent stealing of private/sensitive information using Knowledge
Distillation (KD) has been getting significant attention recently and has
guided subsequent defense efforts considering its critical nature. Recent work
Nasty Teacher proposed to develop teachers which can not be distilled or
imitated by models attacking it. However, the promise of confidentiality
offered by a nasty teacher is not well studied, and as a further step to
strengthen against such loopholes, we attempt to bypass its defense and steal
(or extract) information in its presence successfully. Specifically, we analyze
Nasty Teacher from two different directions and subsequently leverage them
carefully to develop simple yet efficient methodologies, named as HTC and SCM,
which increase the learning from Nasty Teacher by upto 68.63% on standard
datasets. Additionally, we also explore an improvised defense method based on
our insights of stealing. Our detailed set of experiments and ablations on
diverse models/settings demonstrate the efficacy of our approach.
</p></li>
</ul>

<h3>Title: Self-Supervised Pretraining on Satellite Imagery: a Case Study on Label-Efficient Vehicle Detection. (arXiv:2210.11815v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2210.11815">http://arxiv.org/abs/2210.11815</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2210.11815] Self-Supervised Pretraining on Satellite Imagery: a Case Study on Label-Efficient Vehicle Detection](http://arxiv.org/abs/2210.11815)</code></li>
<li>Summary: <p>In defense-related remote sensing applications, such as vehicle detection on
satellite imagery, supervised learning requires a huge number of labeled
examples to reach operational performances. Such data are challenging to obtain
as it requires military experts, and some observables are intrinsically rare.
This limited labeling capability, as well as the large number of unlabeled
images available due to the growing number of sensors, make object detection on
remote sensing imagery highly relevant for self-supervised learning. We study
in-domain self-supervised representation learning for object detection on very
high resolution optical satellite imagery, that is yet poorly explored. For the
first time to our knowledge, we study the problem of label efficiency on this
task. We use the large land use classification dataset Functional Map of the
World to pretrain representations with an extension of the Momentum Contrast
framework. We then investigate this model's transferability on a real-world
task of fine-grained vehicle detection and classification on Preligens
proprietary data, which is designed to be representative of an operational use
case of strategic site surveillance. We show that our in-domain self-supervised
learning model is competitive with ImageNet pretraining, and outperforms it in
the low-label regime.
</p></li>
</ul>

<h3>Title: Evolution of Neural Tangent Kernels under Benign and Adversarial Training. (arXiv:2210.12030v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2210.12030">http://arxiv.org/abs/2210.12030</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2210.12030] Evolution of Neural Tangent Kernels under Benign and Adversarial Training](http://arxiv.org/abs/2210.12030)</code></li>
<li>Summary: <p>Two key challenges facing modern deep learning are mitigating deep networks'
vulnerability to adversarial attacks and understanding deep learning's
generalization capabilities. Towards the first issue, many defense strategies
have been developed, with the most common being Adversarial Training (AT).
Towards the second challenge, one of the dominant theories that has emerged is
the Neural Tangent Kernel (NTK) -- a characterization of neural network
behavior in the infinite-width limit. In this limit, the kernel is frozen, and
the underlying feature map is fixed. In finite widths, however, there is
evidence that feature learning happens at the earlier stages of the training
(kernel learning) before a second phase where the kernel remains fixed (lazy
training). While prior work has aimed at studying adversarial vulnerability
through the lens of the frozen infinite-width NTK, there is no work that
studies the adversarial robustness of the empirical/finite NTK during training.
In this work, we perform an empirical study of the evolution of the empirical
NTK under standard and adversarial training, aiming to disambiguate the effect
of adversarial training on kernel learning and lazy training. We find under
adversarial training, the empirical NTK rapidly converges to a different kernel
(and feature map) than standard training. This new kernel provides adversarial
robustness, even when non-robust training is performed on top of it.
Furthermore, we find that adversarial training on top of a fixed kernel can
yield a classifier with $76.1\%$ robust accuracy under PGD attacks with
$\varepsilon = 4/255$ on CIFAR-10.
</p></li>
</ul>

<h2>attack</h2>
<h3>Title: Deep Learning for Diagonal Earlobe Crease Detection. (arXiv:2210.11582v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2210.11582">http://arxiv.org/abs/2210.11582</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2210.11582] Deep Learning for Diagonal Earlobe Crease Detection](http://arxiv.org/abs/2210.11582)</code></li>
<li>Summary: <p>An article published on Medical News Today in June 2022 presented a
fundamental question in its title: Can an earlobe crease predict heart attacks?
The author explained that end arteries supply the heart and ears. In other
words, if they lose blood supply, no other arteries can take over, resulting in
tissue damage. Consequently, some earlobes have a diagonal crease, line, or
deep fold that resembles a wrinkle. In this paper, we take a step toward
detecting this specific marker, commonly known as DELC or Frank's Sign. For
this reason, we have made the first DELC dataset available to the public. In
addition, we have investigated the performance of numerous cutting-edge
backbones on annotated photos. Experimentally, we demonstrate that it is
possible to solve this challenge by combining pre-trained encoders with a
customized classifier to achieve 97.7% accuracy. Moreover, we have analyzed the
backbone trade-off between performance and size, estimating MobileNet as the
most promising encoder.
</p></li>
</ul>

<h3>Title: Identifying Human Strategies for Generating Word-Level Adversarial Examples. (arXiv:2210.11598v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2210.11598">http://arxiv.org/abs/2210.11598</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2210.11598] Identifying Human Strategies for Generating Word-Level Adversarial Examples](http://arxiv.org/abs/2210.11598)</code></li>
<li>Summary: <p>Adversarial examples in NLP are receiving increasing research attention. One
line of investigation is the generation of word-level adversarial examples
against fine-tuned Transformer models that preserve naturalness and
grammaticality. Previous work found that human- and machine-generated
adversarial examples are comparable in their naturalness and grammatical
correctness. Most notably, humans were able to generate adversarial examples
much more effortlessly than automated attacks. In this paper, we provide a
detailed analysis of exactly how humans create these adversarial examples. By
exploring the behavioural patterns of human workers during the generation
process, we identify statistically significant tendencies based on which words
humans prefer to select for adversarial replacement (e.g., word frequencies,
word saliencies, sentiment) as well as where and when words are replaced in an
input sequence. With our findings, we seek to inspire efforts that harness
human strategies for more robust NLP models.
</p></li>
</ul>

<h3>Title: New data poison attacks on machine learning classifiers for mobile exfiltration. (arXiv:2210.11592v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2210.11592">http://arxiv.org/abs/2210.11592</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2210.11592] New data poison attacks on machine learning classifiers for mobile exfiltration](http://arxiv.org/abs/2210.11592)</code></li>
<li>Summary: <p>Most recent studies have shown several vulnerabilities to attacks with the
potential to jeopardize the integrity of the model, opening in a few recent
years a new window of opportunity in terms of cyber-security. The main interest
of this paper is directed towards data poisoning attacks involving
label-flipping, this kind of attacks occur during the training phase, being the
aim of the attacker to compromise the integrity of the targeted machine
learning model by drastically reducing the overall accuracy of the model and/or
achieving the missclassification of determined samples. This paper is conducted
with intention of proposing two new kinds of data poisoning attacks based on
label-flipping, the targeted of the attack is represented by a variety of
machine learning classifiers dedicated for malware detection using mobile
exfiltration data. With that, the proposed attacks are proven to be
model-agnostic, having successfully corrupted a wide variety of machine
learning models; Logistic Regression, Decision Tree, Random Forest and KNN are
some examples. The first attack is performs label-flipping actions randomly
while the second attacks performs label flipping only one of the 2 classes in
particular. The effects of each attack are analyzed in further detail with
special emphasis on the accuracy drop and the misclassification rate. Finally,
this paper pursuits further research direction by suggesting the development of
a defense technique that could promise a feasible detection and/or mitigation
mechanisms; such technique should be capable of conferring a certain level of
robustness to a target model against potential attackers.
</p></li>
</ul>

<h3>Title: RollBack: A New Time-Agnostic Replay Attack Against the Automotive Remote Keyless Entry Systems. (arXiv:2210.11923v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2210.11923">http://arxiv.org/abs/2210.11923</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2210.11923] RollBack: A New Time-Agnostic Replay Attack Against the Automotive Remote Keyless Entry Systems](http://arxiv.org/abs/2210.11923)</code></li>
<li>Summary: <p>Today's RKE systems implement disposable rolling codes, making every key fob
button press unique, effectively preventing simple replay attacks. However, a
prior attack called RollJam was proven to break all rolling code-based systems
in general. By a careful sequence of signal jamming, capturing, and replaying,
an attacker can become aware of the subsequent valid unlock signal that has not
been used yet. RollJam, however, requires continuous deployment indefinitely
until it is exploited. Otherwise, the captured signals become invalid if the
key fob is used again without RollJam in place. We introduce RollBack, a new
replay-and-resynchronize attack against most of today's RKE systems. In
particular, we show that even though the one-time code becomes invalid in
rolling code systems, replaying a few previously captured signals consecutively
can trigger a rollback-like mechanism in the RKE system. Put differently, the
rolling codes become resynchronized back to a previous code used in the past
from where all subsequent yet already used signals work again. Moreover, the
victim can still use the key fob without noticing any difference before and
after the attack. Unlike RollJam, RollBack does not necessitate jamming at all.
Furthermore, it requires signal capturing only once and can be exploited at any
time in the future as many times as desired. This time-agnostic property is
particularly attractive to attackers, especially in car-sharing/renting
scenarios where accessing the key fob is straightforward. However, while
RollJam defeats virtually any rolling code-based system, vehicles might have
additional anti-theft measures against malfunctioning key fobs, hence against
RollBack. Our ongoing analysis (covering Asian vehicle manufacturers for the
time being) against different vehicle makes and models has revealed that ~70%
of them are vulnerable to RollBack.
</p></li>
</ul>

<h3>Title: Virtual Triggering: a Technique to Segment Cryptographic Processes in Side Channel Traces. (arXiv:2210.12059v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2210.12059">http://arxiv.org/abs/2210.12059</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2210.12059] Virtual Triggering: a Technique to Segment Cryptographic Processes in Side Channel Traces](http://arxiv.org/abs/2210.12059)</code></li>
<li>Summary: <p>Side-Channel Attacks (SCAs) exploit data correla-tion in signals leaked from
devices to jeopardize confidentiality. Locating and synchronizing segments of
interest in traces from Cryptographic Processes (CPs) is a key step of the
attack. The most common method consists in generating a trigger signal to
indicate to the attacker the start of a CP. This paper proposes a method called
Virtual Triggering (VT) that removes the need for the trigger signal and
automates trace segmentation. When the time between repetitions is not
constant, further trace alignment techniques are required. Building on VT, we
propose a simple method to learn representative segment templates from a
profiling device similar to the victim, and to automatically locate and pull
out these segments from other victim devices using simple pattern recognition.
We evaluate VT on screaming channel attacks [1], which initially used a
Frequency Component (FC) known to appear at a single time in leaked signals, as
a trigger to segment traces. We demonstrate that VT not only performs
equivalently to FC on a standard attack scenario, but we also show how using VT
with the automatic pullout technique improves the attack efficiency and enables
more realistic attack scenarios. Thanks to VT, screaming channel attacks can
now: (1) succeed with only half of the segments collected compared to the FC
trigger from the original attack; and (2) absorb time variations between CPs.
</p></li>
</ul>

<h3>Title: Modelling Control Arguments via Cooperation Logic in Unforeseen Scenarios. (arXiv:2210.12114v1 [cs.AI])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2210.12114">http://arxiv.org/abs/2210.12114</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2210.12114] Modelling Control Arguments via Cooperation Logic in Unforeseen Scenarios](http://arxiv.org/abs/2210.12114)</code></li>
<li>Summary: <p>The intent of control argumentation frameworks is to specifically model
strategic scenarios from the perspective of an agent by extending the standard
model of argumentation framework in a way that takes unquantified uncertainty
regarding arguments and attacks into account. They do not, however, adequately
account for coalition formation and interactions among a set of agents in an
uncertain environment. To address this challenge, we propose a formalism of a
multi-agent scenario via cooperation logic and investigate agents' strategies
and actions in a dynamic environment.
</p></li>
</ul>

<h2>robust</h2>
<h3>Title: ConfMix: Unsupervised Domain Adaptation for Object Detection via Confidence-based Mixing. (arXiv:2210.11539v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2210.11539">http://arxiv.org/abs/2210.11539</a></li>
<li>Code URL: <a href="https://github.com/giuliomattolin/confmix">https://github.com/giuliomattolin/confmix</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2210.11539] ConfMix: Unsupervised Domain Adaptation for Object Detection via Confidence-based Mixing](http://arxiv.org/abs/2210.11539)</code></li>
<li>Summary: <p>Unsupervised Domain Adaptation (UDA) for object detection aims to adapt a
model trained on a source domain to detect instances from a new target domain
for which annotations are not available. Different from traditional approaches,
we propose ConfMix, the first method that introduces a sample mixing strategy
based on region-level detection confidence for adaptive object detector
learning. We mix the local region of the target sample that corresponds to the
most confident pseudo detections with a source image, and apply an additional
consistency loss term to gradually adapt towards the target data distribution.
In order to robustly define a confidence score for a region, we exploit the
confidence score per pseudo detection that accounts for both the
detector-dependent confidence and the bounding box uncertainty. Moreover, we
propose a novel pseudo labelling scheme that progressively filters the pseudo
target detections using the confidence metric that varies from a loose to
strict manner along the training. We perform extensive experiments with three
datasets, achieving state-of-the-art performance in two of them and approaching
the supervised target model performance in the other. Code is available at:
https://github.com/giuliomattolin/ConfMix.
</p></li>
</ul>

<h3>Title: H4VDM: H.264 Video Device Matching. (arXiv:2210.11549v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2210.11549">http://arxiv.org/abs/2210.11549</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2210.11549] H4VDM: H](http://arxiv.org/abs/2210.11549)</code></li>
<li>Summary: <p>Methods that can determine if two given video sequences are captured by the
same device (e.g., mobile telephone or digital camera) can be used in many
forensics tasks. In this paper we refer to this as "video device matching". In
open-set video forensics scenarios it is easier to determine if two video
sequences were captured with the same device than identifying the specific
device. In this paper, we propose a technique for open-set video device
matching. Given two H.264 compressed video sequences, our method can determine
if they are captured by the same device, even if our method has never
encountered the device in training. We denote our proposed technique as H.264
Video Device Matching (H4VDM). H4VDM uses H.264 compression information
extracted from video sequences to make decisions. It is more robust against
artifacts that alter camera sensor fingerprints, and it can be used to analyze
relatively small fragments of the H.264 sequence. We trained and tested our
method on a publicly available video forensics dataset consisting of 35
devices, where our proposed method demonstrated good performance.
</p></li>
</ul>

<h3>Title: Slippage-robust Gaze Tracking for Near-eye Display. (arXiv:2210.11637v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2210.11637">http://arxiv.org/abs/2210.11637</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2210.11637] Slippage-robust Gaze Tracking for Near-eye Display](http://arxiv.org/abs/2210.11637)</code></li>
<li>Summary: <p>In recent years, head-mounted near-eye display devices have become the key
hardware foundation for virtual reality and augmented reality. Thus
head-mounted gaze tracking technology has received attention as an essential
part of human-computer interaction. However, unavoidable slippage of
head-mounted devices (HMD) often results higher gaze tracking errors and
hinders the practical usage of HMD. To tackle this problem, we propose a
slippage-robust gaze tracking for near-eye display method based on the aspheric
eyeball model and accurately compute the eyeball optical axis and rotation
center. We tested several methods on datasets with slippage and the
experimental results show that the proposed method significantly outperforms
the previous method (almost double the suboptimal method).
</p></li>
</ul>

<h3>Title: Context-Enhanced Stereo Transformer. (arXiv:2210.11719v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2210.11719">http://arxiv.org/abs/2210.11719</a></li>
<li>Code URL: <a href="https://github.com/guoweiyu/context-enhanced-stereo-transformer">https://github.com/guoweiyu/context-enhanced-stereo-transformer</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2210.11719] Context-Enhanced Stereo Transformer](http://arxiv.org/abs/2210.11719)</code></li>
<li>Summary: <p>Stereo depth estimation is of great interest for computer vision research.
However, existing methods struggles to generalize and predict reliably in
hazardous regions, such as large uniform regions. To overcome these
limitations, we propose Context Enhanced Path (CEP). CEP improves the
generalization and robustness against common failure cases in existing
solutions by capturing the long-range global information. We construct our
stereo depth estimation model, Context Enhanced Stereo Transformer (CSTR), by
plugging CEP into the state-of-the-art stereo depth estimation method Stereo
Transformer. CSTR is examined on distinct public datasets, such as Scene Flow,
Middlebury-2014, KITTI-2015, and MPI-Sintel. We find CSTR outperforms prior
approaches by a large margin. For example, in the zero-shot synthetic-to-real
setting, CSTR outperforms the best competing approaches on Middlebury-2014
dataset by 11%. Our extensive experiments demonstrate that the long-range
information is critical for stereo matching task and CEP successfully captures
such information.
</p></li>
</ul>

<h3>Title: Generative Range Imaging for Learning Scene Priors of 3D LiDAR Data. (arXiv:2210.11750v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2210.11750">http://arxiv.org/abs/2210.11750</a></li>
<li>Code URL: <a href="https://github.com/kazuto1011/dusty-gan-v2">https://github.com/kazuto1011/dusty-gan-v2</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2210.11750] Generative Range Imaging for Learning Scene Priors of 3D LiDAR Data](http://arxiv.org/abs/2210.11750)</code></li>
<li>Summary: <p>3D LiDAR sensors are indispensable for the robust vision of autonomous mobile
robots. However, deploying LiDAR-based perception algorithms often fails due to
a domain gap from the training environment, such as inconsistent angular
resolution and missing properties. Existing studies have tackled the issue by
learning inter-domain mapping, while the transferability is constrained by the
training configuration and the training is susceptible to peculiar lossy noises
called ray-drop. To address the issue, this paper proposes a generative model
of LiDAR range images applicable to the data-level domain transfer. Motivated
by the fact that LiDAR measurement is based on point-by-point range imaging, we
train an implicit image representation-based generative adversarial networks
along with a differentiable ray-drop effect. We demonstrate the fidelity and
diversity of our model in comparison with the point-based and image-based
state-of-the-art generative models. We also showcase upsampling and restoration
applications. Furthermore, we introduce a Sim2Real application for LiDAR
semantic segmentation. We demonstrate that our method is effective as a
realistic ray-drop simulator and outperforms state-of-the-art methods.
</p></li>
</ul>

<h3>Title: Diffusion Visual Counterfactual Explanations. (arXiv:2210.11841v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2210.11841">http://arxiv.org/abs/2210.11841</a></li>
<li>Code URL: <a href="https://github.com/valentyn1boreiko/dvces">https://github.com/valentyn1boreiko/dvces</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2210.11841] Diffusion Visual Counterfactual Explanations](http://arxiv.org/abs/2210.11841)</code></li>
<li>Summary: <p>Visual Counterfactual Explanations (VCEs) are an important tool to understand
the decisions of an image classifier. They are 'small' but 'realistic' semantic
changes of the image changing the classifier decision. Current approaches for
the generation of VCEs are restricted to adversarially robust models and often
contain non-realistic artefacts, or are limited to image classification
problems with few classes. In this paper, we overcome this by generating
Diffusion Visual Counterfactual Explanations (DVCEs) for arbitrary ImageNet
classifiers via a diffusion process. Two modifications to the diffusion process
are key for our DVCEs: first, an adaptive parameterization, whose
hyperparameters generalize across images and models, together with distance
regularization and late start of the diffusion process, allow us to generate
images with minimal semantic changes to the original ones but different
classification. Second, our cone regularization via an adversarially robust
model ensures that the diffusion process does not converge to trivial
non-semantic changes, but instead produces realistic images of the target class
which achieve high confidence by the classifier.
</p></li>
</ul>

<h3>Title: Balanced Adversarial Training: Balancing Tradeoffs between Fickleness and Obstinacy in NLP Models. (arXiv:2210.11498v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2210.11498">http://arxiv.org/abs/2210.11498</a></li>
<li>Code URL: <a href="https://github.com/hannahxchen/balanced-adversarial-training">https://github.com/hannahxchen/balanced-adversarial-training</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2210.11498] Balanced Adversarial Training: Balancing Tradeoffs between Fickleness and Obstinacy in NLP Models](http://arxiv.org/abs/2210.11498)</code></li>
<li>Summary: <p>Traditional (fickle) adversarial examples involve finding a small
perturbation that does not change an input's true label but confuses the
classifier into outputting a different prediction. Conversely, obstinate
adversarial examples occur when an adversary finds a small perturbation that
preserves the classifier's prediction but changes the true label of an input.
Adversarial training and certified robust training have shown some
effectiveness in improving the robustness of machine learnt models to fickle
adversarial examples. We show that standard adversarial training methods
focused on reducing vulnerability to fickle adversarial examples may make a
model more vulnerable to obstinate adversarial examples, with experiments for
both natural language inference and paraphrase identification tasks. To counter
this phenomenon, we introduce Balanced Adversarial Training, which incorporates
contrastive learning to increase robustness against both fickle and obstinate
adversarial examples.
</p></li>
</ul>

<h3>Title: Finding Dataset Shortcuts with Grammar Induction. (arXiv:2210.11560v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2210.11560">http://arxiv.org/abs/2210.11560</a></li>
<li>Code URL: <a href="https://github.com/princeton-nlp/shortcutgrammar">https://github.com/princeton-nlp/shortcutgrammar</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2210.11560] Finding Dataset Shortcuts with Grammar Induction](http://arxiv.org/abs/2210.11560)</code></li>
<li>Summary: <p>Many NLP datasets have been found to contain shortcuts: simple decision rules
that achieve surprisingly high accuracy. However, it is difficult to discover
shortcuts automatically. Prior work on automatic shortcut detection has focused
on enumerating features like unigrams or bigrams, which can find only low-level
shortcuts, or relied on post-hoc model interpretability methods like saliency
maps, which reveal qualitative patterns without a clear statistical
interpretation. In this work, we propose to use probabilistic grammars to
characterize and discover shortcuts in NLP datasets. Specifically, we use a
context-free grammar to model patterns in sentence classification datasets and
use a synchronous context-free grammar to model datasets involving sentence
pairs. The resulting grammars reveal interesting shortcut features in a number
of datasets, including both simple and high-level features, and automatically
identify groups of test examples on which conventional classifiers fail.
Finally, we show that the features we discover can be used to generate
diagnostic contrast examples and incorporated into standard robust optimization
methods to improve worst-group accuracy.
</p></li>
</ul>

<h3>Title: Multitasking Models are Robust to Structural Failure: A Neural Model for Bilingual Cognitive Reserve. (arXiv:2210.11618v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2210.11618">http://arxiv.org/abs/2210.11618</a></li>
<li>Code URL: <a href="https://github.com/giannisdaras/multilingual_robustness">https://github.com/giannisdaras/multilingual_robustness</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2210.11618] Multitasking Models are Robust to Structural Failure: A Neural Model for Bilingual Cognitive Reserve](http://arxiv.org/abs/2210.11618)</code></li>
<li>Summary: <p>We find a surprising connection between multitask learning and robustness to
neuron failures. Our experiments show that bilingual language models retain
higher performance under various neuron perturbations, such as random
deletions, magnitude pruning and weight noise compared to equivalent
monolingual ones. We provide a theoretical justification for this robustness by
mathematically analyzing linear representation learning and showing that
multitasking creates more robust representations. Our analysis connects
robustness to spectral properties of the learned representation and proves that
multitasking leads to higher robustness for diverse task vectors. We
open-source our code and models:
https://github.com/giannisdaras/multilingual_robustness
</p></li>
</ul>

<h3>Title: Robustifying Sentiment Classification by Maximally Exploiting Few Counterfactuals. (arXiv:2210.11805v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2210.11805">http://arxiv.org/abs/2210.11805</a></li>
<li>Code URL: <a href="https://github.com/maarten-deraedt/emnlp2022-robustifying-sentiment-classification">https://github.com/maarten-deraedt/emnlp2022-robustifying-sentiment-classification</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2210.11805] Robustifying Sentiment Classification by Maximally Exploiting Few Counterfactuals](http://arxiv.org/abs/2210.11805)</code></li>
<li>Summary: <p>For text classification tasks, finetuned language models perform remarkably
well. Yet, they tend to rely on spurious patterns in training data, thus
limiting their performance on out-of-distribution (OOD) test data. Among recent
models aiming to avoid this spurious pattern problem, adding extra
counterfactual samples to the training data has proven to be very effective.
Yet, counterfactual data generation is costly since it relies on human
annotation. Thus, we propose a novel solution that only requires annotation of
a small fraction (e.g., 1%) of the original training data, and uses automatic
generation of extra counterfactuals in an encoding vector space. We demonstrate
the effectiveness of our approach in sentiment classification, using IMDb data
for training and other sets for OOD tests (i.e., Amazon, SemEval and Yelp). We
achieve noticeable accuracy improvements by adding only 1% manual
counterfactuals: +3% compared to adding +100% in-distribution training samples,
+1.3% compared to alternate counterfactual approaches.
</p></li>
</ul>

<h3>Title: Spectral Probing. (arXiv:2210.11860v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2210.11860">http://arxiv.org/abs/2210.11860</a></li>
<li>Code URL: <a href="https://github.com/mainlp/spectral-probing">https://github.com/mainlp/spectral-probing</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2210.11860] Spectral Probing](http://arxiv.org/abs/2210.11860)</code></li>
<li>Summary: <p>Linguistic information is encoded at varying timescales (subwords, phrases,
etc.) and communicative levels, such as syntax and semantics. Contextualized
embeddings have analogously been found to capture these phenomena at
distinctive layers and frequencies. Leveraging these findings, we develop a
fully learnable frequency filter to identify spectral profiles for any given
task. It enables vastly more granular analyses than prior handcrafted filters,
and improves on efficiency. After demonstrating the informativeness of spectral
probing over manual filters in a monolingual setting, we investigate its
multilingual characteristics across seven diverse NLP tasks in six languages.
Our analyses identify distinctive spectral profiles which quantify cross-task
similarity in a linguistically intuitive manner, while remaining consistent
across languages-highlighting their potential as robust, lightweight task
descriptors.
</p></li>
</ul>

<h3>Title: Optimizing text representations to capture (dis)similarity between political parties. (arXiv:2210.11989v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2210.11989">http://arxiv.org/abs/2210.11989</a></li>
<li>Code URL: <a href="https://github.com/tceron/capture_similarity_between_political_parties">https://github.com/tceron/capture_similarity_between_political_parties</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2210.11989] Optimizing text representations to capture (dis)similarity between political parties](http://arxiv.org/abs/2210.11989)</code></li>
<li>Summary: <p>Even though fine-tuned neural language models have been pivotal in enabling
"deep" automatic text analysis, optimizing text representations for specific
applications remains a crucial bottleneck. In this study, we look at this
problem in the context of a task from computational social science, namely
modeling pairwise similarities between political parties. Our research question
is what level of structural information is necessary to create robust text
representation, contrasting a strongly informed approach (which uses both claim
span and claim category annotations) with approaches that forgo one or both
types of annotation with document structure-based heuristics. Evaluating our
models on the manifestos of German parties for the 2021 federal election. We
find that heuristics that maximize within-party over between-party similarity
along with a normalization step lead to reliable party similarity prediction,
without the need for manual annotation.
</p></li>
</ul>

<h3>Title: A Causal Framework to Quantify the Robustness of Mathematical Reasoning with Language Models. (arXiv:2210.12023v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2210.12023">http://arxiv.org/abs/2210.12023</a></li>
<li>Code URL: <a href="https://github.com/alestolfo/causal-math">https://github.com/alestolfo/causal-math</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2210.12023] A Causal Framework to Quantify the Robustness of Mathematical Reasoning with Language Models](http://arxiv.org/abs/2210.12023)</code></li>
<li>Summary: <p>We have recently witnessed a number of impressive results on hard
mathematical reasoning problems with language models. At the same time, the
robustness of these models has also been called into question; recent works
have shown that models can rely on shallow patterns in the problem description
when predicting a solution. Building on the idea of behavioral testing, we
propose a novel framework, which pins down the causal effect of various factors
in the input, e.g., the surface form of the problem text, the operands and math
operators on the output solution. By grounding the behavioral analysis in a
causal graph describing an intuitive reasoning process, we study the behavior
of language models in terms of robustness and sensitivity to direct
interventions in the input space. We apply our framework on a test bed of
bivariate math word problems. Our analysis shows that robustness does not
appear to continuously improve as a function of scale, but that the recent LLM,
GPT-3-Instruct (175B), achieves a dramatic improvement in both robustness and
sensitivity, compared to all other GPT variants.
</p></li>
</ul>

<h3>Title: Multimodal Neural Network For Demand Forecasting. (arXiv:2210.11502v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2210.11502">http://arxiv.org/abs/2210.11502</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2210.11502] Multimodal Neural Network For Demand Forecasting](http://arxiv.org/abs/2210.11502)</code></li>
<li>Summary: <p>Demand forecasting applications have immensely benefited from the
state-of-the-art Deep Learning methods used for time series forecasting.
Traditional uni-modal models are predominantly seasonality driven which attempt
to model the demand as a function of historic sales along with information on
holidays and promotional events. However, accurate and robust sales forecasting
calls for accommodating multiple other factors, such as natural calamities,
pandemics, elections, etc., impacting the demand for products and product
categories in general. We propose a multi-modal sales forecasting network that
combines real-life events from news articles with traditional data such as
historical sales and holiday information. Further, we fuse information from
general product trends published by Google trends. Empirical results show
statistically significant improvements in the SMAPE error metric with an
average improvement of 7.37% against the existing state-of-the-art sales
forecasting techniques on a real-world supermarket dataset.
</p></li>
</ul>

<h3>Title: Stochastic Adaptive Activation Function. (arXiv:2210.11672v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2210.11672">http://arxiv.org/abs/2210.11672</a></li>
<li>Code URL: <a href="https://github.com/kyungsu-lee-ksl/ash">https://github.com/kyungsu-lee-ksl/ash</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2210.11672] Stochastic Adaptive Activation Function](http://arxiv.org/abs/2210.11672)</code></li>
<li>Summary: <p>The simulation of human neurons and neurotransmission mechanisms has been
realized in deep neural networks based on the theoretical implementations of
activation functions. However, recent studies have reported that the threshold
potential of neurons exhibits different values according to the locations and
types of individual neurons, and that the activation functions have limitations
in terms of representing this variability. Therefore, this study proposes a
simple yet effective activation function that facilitates different thresholds
and adaptive activations according to the positions of units and the contexts
of inputs. Furthermore, the proposed activation function mathematically
exhibits a more generalized form of Swish activation function, and thus we
denoted it as Adaptive SwisH (ASH). ASH highlights informative features that
exhibit large values in the top percentiles in an input, whereas it rectifies
low values. Most importantly, ASH exhibits trainable, adaptive, and
context-aware properties compared to other activation functions. Furthermore,
ASH represents general formula of the previously studied activation function
and provides a reasonable mathematical background for the superior performance.
To validate the effectiveness and robustness of ASH, we implemented ASH into
many deep learning models for various tasks, including classification,
detection, segmentation, and image generation. Experimental analysis
demonstrates that our activation function can provide the benefits of more
accurate prediction and earlier convergence in many deep learning applications.
</p></li>
</ul>

<h3>Title: Fuzzy Granular-Ball Computing Framework and Its Implementation in SVM. (arXiv:2210.11675v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2210.11675">http://arxiv.org/abs/2210.11675</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2210.11675] Fuzzy Granular-Ball Computing Framework and Its Implementation in SVM](http://arxiv.org/abs/2210.11675)</code></li>
<li>Summary: <p>Most existing fuzzy computing methods use points as input, which is the
finest granularity from the perspective of granular computing. Consequently,
these classifiers are neither efficient nor robust to label noise. Therefore,
we propose a framework for a fuzzy granular-ball computational classifier by
introducing granular-ball computing into fuzzy set. The computational framework
is based on the granular-balls input rather than points; therefore, it is more
efficient and robust than traditional fuzzy methods. Furthermore, the framework
is extended to the fuzzy support vector machine (FSVM), and granular ball fuzzy
SVM (GBFSVM) is derived. The experimental results demonstrate the effectiveness
and efficiency of GBFSVM.
</p></li>
</ul>

<h3>Title: Learning Robust Dynamics through Variational Sparse Gating. (arXiv:2210.11698v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2210.11698">http://arxiv.org/abs/2210.11698</a></li>
<li>Code URL: <a href="https://github.com/arnavkj1995/vsg">https://github.com/arnavkj1995/vsg</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2210.11698] Learning Robust Dynamics through Variational Sparse Gating](http://arxiv.org/abs/2210.11698)</code></li>
<li>Summary: <p>Learning world models from their sensory inputs enables agents to plan for
actions by imagining their future outcomes. World models have previously been
shown to improve sample-efficiency in simulated environments with few objects,
but have not yet been applied successfully to environments with many objects.
In environments with many objects, often only a small number of them are moving
or interacting at the same time. In this paper, we investigate integrating this
inductive bias of sparse interactions into the latent dynamics of world models
trained from pixels. First, we introduce Variational Sparse Gating (VSG), a
latent dynamics model that updates its feature dimensions sparsely through
stochastic binary gates. Moreover, we propose a simplified architecture Simple
Variational Sparse Gating (SVSG) that removes the deterministic pathway of
previous models, resulting in a fully stochastic transition function that
leverages the VSG mechanism. We evaluate the two model architectures in the
BringBackShapes (BBS) environment that features a large number of moving
objects and partial observability, demonstrating clear improvements over prior
models.
</p></li>
</ul>

<h3>Title: Explainability in autonomous pedagogically structured scenarios. (arXiv:2210.12140v1 [cs.AI])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2210.12140">http://arxiv.org/abs/2210.12140</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2210.12140] Explainability in autonomous pedagogically structured scenarios](http://arxiv.org/abs/2210.12140)</code></li>
<li>Summary: <p>We present the notion of explainability for decision-making processes in a
pedagogically structured autonomous environment. Multi-agent systems that are
structured pedagogically consist of pedagogical teachers and learners that
operate in environments in which both are sometimes not fully aware of all the
states in the environment and beliefs of other agents thus making it
challenging to explain their decisions and actions with one another. This work
emphasises the need for robust and iterative explanation-based communication
between the pedagogical teacher and the learner. Explaining the rationale
behind multi-agent decisions in an interactive, partially observable
environment is necessary to build trustworthy and reliable communication
between pedagogical teachers and learners. Ongoing research is primarily
focused on explanations of the agents' behaviour towards humans, and there is a
lack of research on inter-agent explainability.
</p></li>
</ul>

<h3>Title: Learning Sample Reweighting for Accuracy and Adversarial Robustness. (arXiv:2210.11513v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2210.11513">http://arxiv.org/abs/2210.11513</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2210.11513] Learning Sample Reweighting for Accuracy and Adversarial Robustness](http://arxiv.org/abs/2210.11513)</code></li>
<li>Summary: <p>There has been great interest in enhancing the robustness of neural network
classifiers to defend against adversarial perturbations through adversarial
training, while balancing the trade-off between robust accuracy and standard
accuracy. We propose a novel adversarial training framework that learns to
reweight the loss associated with individual training samples based on a notion
of class-conditioned margin, with the goal of improving robust generalization.
We formulate weighted adversarial training as a bilevel optimization problem
with the upper-level problem corresponding to learning a robust classifier, and
the lower-level problem corresponding to learning a parametric function that
maps from a sample's \textit{multi-class margin} to an importance weight.
Extensive experiments demonstrate that our approach consistently improves both
clean and robust accuracy compared to related methods and state-of-the-art
baselines.
</p></li>
</ul>

<h3>Title: LOT: Layer-wise Orthogonal Training on Improving l2 Certified Robustness. (arXiv:2210.11620v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2210.11620">http://arxiv.org/abs/2210.11620</a></li>
<li>Code URL: <a href="https://github.com/ai-secure/layerwise-orthogonal-training">https://github.com/ai-secure/layerwise-orthogonal-training</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2210.11620] LOT: Layer-wise Orthogonal Training on Improving l2 Certified Robustness](http://arxiv.org/abs/2210.11620)</code></li>
<li>Summary: <p>Recent studies show that training deep neural networks (DNNs) with Lipschitz
constraints are able to enhance adversarial robustness and other model
properties such as stability. In this paper, we propose a layer-wise orthogonal
training method (LOT) to effectively train 1-Lipschitz convolution layers via
parametrizing an orthogonal matrix with an unconstrained matrix. We then
efficiently compute the inverse square root of a convolution kernel by
transforming the input domain to the Fourier frequency domain. On the other
hand, as existing works show that semi-supervised training helps improve
empirical robustness, we aim to bridge the gap and prove that semi-supervised
learning also improves the certified robustness of Lipschitz-bounded models. We
conduct comprehensive evaluations for LOT under different settings. We show
that LOT significantly outperforms baselines regarding deterministic l2
certified robustness, and scales to deeper neural networks. Under the
supervised scenario, we improve the state-of-the-art certified robustness for
all architectures (e.g. from 59.04% to 63.50% on CIFAR-10 and from 32.57% to
34.59% on CIFAR-100 at radius rho = 36/255 for 40-layer networks). With
semi-supervised learning over unlabelled data, we are able to improve
state-of-the-art certified robustness on CIFAR-10 at rho = 108/255 from 36.04%
to 42.39%. In addition, LOT consistently outperforms baselines on different
model architectures with only 1/3 evaluation time.
</p></li>
</ul>

<h3>Title: Equivariant Networks for Zero-Shot Coordination. (arXiv:2210.12124v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2210.12124">http://arxiv.org/abs/2210.12124</a></li>
<li>Code URL: <a href="https://github.com/gfppoy/equivariant-zsc">https://github.com/gfppoy/equivariant-zsc</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2210.12124] Equivariant Networks for Zero-Shot Coordination](http://arxiv.org/abs/2210.12124)</code></li>
<li>Summary: <p>Successful coordination in Dec-POMDPs requires agents to adopt robust
strategies and interpretable styles of play for their partner. A common failure
mode is symmetry breaking, when agents arbitrarily converge on one out of many
equivalent but mutually incompatible policies. Commonly these examples include
partial observability, e.g. waving your right hand vs. left hand to convey a
covert message. In this paper, we present a novel equivariant network
architecture for use in Dec-POMDPs that prevents the agent from learning
policies which break symmetries, doing so more effectively than prior methods.
Our method also acts as a "coordination-improvement operator" for generic,
pre-trained policies, and thus may be applied at test-time in conjunction with
any self-play algorithm. We provide theoretical guarantees of our work and test
on the AI benchmark task of Hanabi, where we demonstrate our methods
outperforming other symmetry-aware baselines in zero-shot coordination, as well
as able to improve the coordination ability of a variety of pre-trained
policies. In particular, we show our method can be used to improve on the state
of the art for zero-shot coordination on the Hanabi benchmark.
</p></li>
</ul>

<h2>biometric</h2>
<h3>Title: Automatic Cattle Identification using YOLOv5 and Mosaic Augmentation: A Comparative Analysis. (arXiv:2210.11939v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2210.11939">http://arxiv.org/abs/2210.11939</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2210.11939] Automatic Cattle Identification using YOLOv5 and Mosaic Augmentation: A Comparative Analysis](http://arxiv.org/abs/2210.11939)</code></li>
<li>Summary: <p>You Only Look Once (YOLO) is a single-stage object detection model popular
for real-time object detection, accuracy, and speed. This paper investigates
the YOLOv5 model to identify cattle in the yards. The current solution to
cattle identification includes radio-frequency identification (RFID) tags. The
problem occurs when the RFID tag is lost or damaged. A biometric solution
identifies the cattle and helps to assign the lost or damaged tag or replace
the RFID-based system. Muzzle patterns in cattle are unique biometric solutions
like a fingerprint in humans. This paper aims to present our recent research in
utilizing five popular object detection models, looking at the architecture of
YOLOv5, investigating the performance of eight backbones with the YOLOv5 model,
and the influence of mosaic augmentation in YOLOv5 by experimental results on
the available cattle muzzle images. Finally, we concluded with the excellent
potential of using YOLOv5 in automatic cattle identification. Our experiments
show YOLOv5 with transformer performed best with mean Average Precision (mAP)
0.5 (the average of AP when the IoU is greater than 50%) of 0.995, and mAP
0.5:0.95 (the average of AP from 50% to 95% IoU with an interval of 5%) of
0.9366. In addition, our experiments show the increase in accuracy of the model
by using mosaic augmentation in all backbones used in our experiments.
Moreover, we can also detect cattle with partial muzzle images.
</p></li>
</ul>

<h2>steal</h2>
<h2>extraction</h2>
<h3>Title: Improving the Anomaly Detection in GPR Images by Fine-Tuning CNNs with Synthetic Data. (arXiv:2210.11833v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2210.11833">http://arxiv.org/abs/2210.11833</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2210.11833] Improving the Anomaly Detection in GPR Images by Fine-Tuning CNNs with Synthetic Data](http://arxiv.org/abs/2210.11833)</code></li>
<li>Summary: <p>Ground Penetrating Radar (GPR) has been widely used to estimate the healthy
operation of some urban roads and underground facilities. When identifying
subsurface anomalies by GPR in an area, the obtained data could be unbalanced,
and the numbers and types of possible underground anomalies could not be
acknowledged in advance. In this paper, a novel method is proposed to improve
the subsurface anomaly detection from GPR B-scan images. A normal (i.e. without
subsurface objects) GPR image section is firstly collected in the detected
area. Concerning that the GPR image is essentially the representation of
electromagnetic (EM) wave and propagation time, and to preserve both the
subsurface background and objects' details, the normal GPR image is segmented
and then fused with simulated GPR images that contain different kinds of
objects to generate the synthetic data for the detection area based on the
wavelet decompositions. Pre-trained CNNs could then be fine-tuned with the
synthetic data, and utilized to extract features of segmented GPR images
subsequently obtained in the detection area. The extracted features could be
classified by the one-class learning algorithm in the feature space without
pre-set anomaly types or numbers. The conducted experiments demonstrate that
fine-tuning the pre-trained CNN with the proposed synthetic data could
effectively improve the feature extraction of the network for the objects in
the detection area. Besides, the proposed method requires only a section of
normal data that could be easily obtained in the detection area, and could also
meet the timeliness requirements in practical applications.
</p></li>
</ul>

<h3>Title: Improving Semi-supervised End-to-end Automatic Speech Recognition using CycleGAN and Inter-domain Losses. (arXiv:2210.11642v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2210.11642">http://arxiv.org/abs/2210.11642</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2210.11642] Improving Semi-supervised End-to-end Automatic Speech Recognition using CycleGAN and Inter-domain Losses](http://arxiv.org/abs/2210.11642)</code></li>
<li>Summary: <p>We propose a novel method that combines CycleGAN and inter-domain losses for
semi-supervised end-to-end automatic speech recognition. Inter-domain loss
targets the extraction of an intermediate shared representation of speech and
text inputs using a shared network. CycleGAN uses cycle-consistent loss and the
identity mapping loss to preserve relevant characteristics of the input feature
after converting from one domain to another. As such, both approaches are
suitable to train end-to-end models on unpaired speech-text inputs. In this
paper, we exploit the advantages from both inter-domain loss and CycleGAN to
achieve better shared representation of unpaired speech and text inputs and
thus improve the speech-to-text mapping. Our experimental results on the WSJ
eval92 and Voxforge (non English) show 8~8.5% character error rate reduction
over the baseline, and the results on LibriSpeech test_clean also show
noticeable improvement.
</p></li>
</ul>

<h3>Title: Multi-View Reasoning: Consistent Contrastive Learning for Math Word Problem. (arXiv:2210.11694v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2210.11694">http://arxiv.org/abs/2210.11694</a></li>
<li>Code URL: <a href="https://github.com/zwq2018/multi-view-consistency-for-mwp">https://github.com/zwq2018/multi-view-consistency-for-mwp</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2210.11694] Multi-View Reasoning: Consistent Contrastive Learning for Math Word Problem](http://arxiv.org/abs/2210.11694)</code></li>
<li>Summary: <p>Math word problem solver requires both precise relation reasoning about
quantities in the text and reliable generation for the diverse equation.
Current sequence-to-tree or relation extraction methods regard this only from a
fixed view, struggling to simultaneously handle complex semantics and diverse
equations. However, human solving naturally involves two consistent reasoning
views: top-down and bottom-up, just as math equations also can be expressed in
multiple equivalent forms: pre-order and post-order. We propose a multi-view
consistent contrastive learning for a more complete semantics-to-equation
mapping. The entire process is decoupled into two independent but consistent
views: top-down decomposition and bottom-up construction, and the two reasoning
views are aligned in multi-granularity for consistency, enhancing global
generation and precise reasoning. Experiments on multiple datasets across two
languages show our approach significantly outperforms the existing baselines,
especially on complex problems. We also show after consistent alignment,
multi-view can absorb the merits of both views and generate more diverse
results consistent with the mathematical laws.
</p></li>
</ul>

<h3>Title: Detecting Unintended Social Bias in Toxic Language Datasets. (arXiv:2210.11762v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2210.11762">http://arxiv.org/abs/2210.11762</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2210.11762] Detecting Unintended Social Bias in Toxic Language Datasets](http://arxiv.org/abs/2210.11762)</code></li>
<li>Summary: <p>With the rise of online hate speech, automatic detection of Hate Speech,
Offensive texts as a natural language processing task is getting popular.
However, very little research has been done to detect unintended social bias
from these toxic language datasets. This paper introduces a new dataset
ToxicBias curated from the existing dataset of Kaggle competition named "Jigsaw
Unintended Bias in Toxicity Classification". We aim to detect social biases,
their categories, and targeted groups. The dataset contains instances annotated
for five different bias categories, viz., gender, race/ethnicity, religion,
political, and LGBTQ. We train transformer-based models using our curated
datasets and report baseline performance for bias identification, target
generation, and bias implications. Model biases and their mitigation are also
discussed in detail. Our study motivates a systematic extraction of social bias
data from toxic language datasets. All the codes and dataset used for
experiments in this work are publicly available
</p></li>
</ul>

<h3>Title: Rescue Implicit and Long-tail Cases: Nearest Neighbor Relation Extraction. (arXiv:2210.11800v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2210.11800">http://arxiv.org/abs/2210.11800</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2210.11800] Rescue Implicit and Long-tail Cases: Nearest Neighbor Relation Extraction](http://arxiv.org/abs/2210.11800)</code></li>
<li>Summary: <p>Relation extraction (RE) has achieved remarkable progress with the help of
pre-trained language models. However, existing RE models are usually incapable
of handling two situations: implicit expressions and long-tail relation types,
caused by language complexity and data sparsity. In this paper, we introduce a
simple enhancement of RE using $k$ nearest neighbors ($k$NN-RE). $k$NN-RE
allows the model to consult training relations at test time through a
nearest-neighbor search and provides a simple yet effective means to tackle the
two issues above. Additionally, we observe that $k$NN-RE serves as an effective
way to leverage distant supervision (DS) data for RE. Experimental results show
that the proposed $k$NN-RE achieves state-of-the-art performances on a variety
of supervised RE datasets, i.e., ACE05, SciERC, and Wiki80, along with
outperforming the best model to date on the i2b2 and Wiki80 datasets in the
setting of allowing using DS. Our code and models are available at:
https://github.com/YukinoWan/kNN-RE.
</p></li>
</ul>

<h2>membership infer</h2>
<h2>federate</h2>
<h2>fair</h2>
<h3>Title: Boosting vision transformers for image retrieval. (arXiv:2210.11909v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2210.11909">http://arxiv.org/abs/2210.11909</a></li>
<li>Code URL: <a href="https://github.com/dealicious-inc/dtop">https://github.com/dealicious-inc/dtop</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2210.11909] Boosting vision transformers for image retrieval](http://arxiv.org/abs/2210.11909)</code></li>
<li>Summary: <p>Vision transformers have achieved remarkable progress in vision tasks such as
image classification and detection. However, in instance-level image retrieval,
transformers have not yet shown good performance compared to convolutional
networks. We propose a number of improvements that make transformers outperform
the state of the art for the first time. (1) We show that a hybrid architecture
is more effective than plain transformers, by a large margin. (2) We introduce
two branches collecting global (classification token) and local (patch tokens)
information, from which we form a global image representation. (3) In each
branch, we collect multi-layer features from the transformer encoder,
corresponding to skip connections across distant layers. (4) We enhance
locality of interactions at the deeper layers of the encoder, which is the
relative weakness of vision transformers. We train our model on all commonly
used training sets and, for the first time, we make fair comparisons separately
per training set. In all cases, we outperform previous models based on global
representation. Public code is available at
https://github.com/dealicious-inc/DToP.
</p></li>
</ul>

<h3>Title: JRDB-Pose: A Large-scale Dataset for Multi-Person Pose Estimation and Tracking. (arXiv:2210.11940v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2210.11940">http://arxiv.org/abs/2210.11940</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2210.11940] JRDB-Pose: A Large-scale Dataset for Multi-Person Pose Estimation and Tracking](http://arxiv.org/abs/2210.11940)</code></li>
<li>Summary: <p>Autonomous robotic systems operating in human environments must understand
their surroundings to make accurate and safe decisions. In crowded human scenes
with close-up human-robot interaction and robot navigation, a deep
understanding requires reasoning about human motion and body dynamics over time
with human body pose estimation and tracking. However, existing datasets either
do not provide pose annotations or include scene types unrelated to robotic
applications. Many datasets also lack the diversity of poses and occlusions
found in crowded human scenes. To address this limitation we introduce
JRDB-Pose, a large-scale dataset and benchmark for multi-person pose estimation
and tracking using videos captured from a social navigation robot. The dataset
contains challenge scenes with crowded indoor and outdoor locations and a
diverse range of scales and occlusion types. JRDB-Pose provides human pose
annotations with per-keypoint occlusion labels and track IDs consistent across
the scene. A public evaluation server is made available for fair evaluation on
a held-out test set. JRDB-Pose is available at https://jrdb.erc.monash.edu/ .
</p></li>
</ul>

<h3>Title: Towards Human-centered Explainable AI: User Studies for Model Explanations. (arXiv:2210.11584v1 [cs.AI])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2210.11584">http://arxiv.org/abs/2210.11584</a></li>
<li>Code URL: <a href="https://github.com/yaorong0921/hxai-survey">https://github.com/yaorong0921/hxai-survey</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2210.11584] Towards Human-centered Explainable AI: User Studies for Model Explanations](http://arxiv.org/abs/2210.11584)</code></li>
<li>Summary: <p>Explainable AI (XAI) is widely viewed as a sine qua non for ever-expanding AI
research. A better understanding of the needs of XAI users, as well as
human-centered evaluations of explainable models are both a necessity and a
challenge. In this paper, we explore how HCI and AI researchers conduct user
studies in XAI applications based on a systematic literature review. After
identifying and thoroughly analyzing 85 core papers with human-based XAI
evaluations over the past five years, we categorize them along the measured
characteristics of explanatory methods, namely trust, understanding, fairness,
usability, and human-AI team performance. Our research shows that XAI is
spreading more rapidly in certain application domains, such as recommender
systems than in others, but that user evaluations are still rather sparse and
incorporate hardly any insights from cognitive or social sciences. Based on a
comprehensive discussion of best practices, i.e., common models, design
choices, and measures in user studies, we propose practical guidelines on
designing and conducting user studies for XAI researchers and practitioners.
Lastly, this survey also highlights several open research directions,
particularly linking psychological science and human-centered XAI.
</p></li>
</ul>

<h2>interpretability</h2>
<h3>Title: Decoding a Neural Retriever's Latent Space for Query Suggestion. (arXiv:2210.12084v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2210.12084">http://arxiv.org/abs/2210.12084</a></li>
<li>Code URL: <a href="https://github.com/leox1v/query_decoder">https://github.com/leox1v/query_decoder</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2210.12084] Decoding a Neural Retriever's Latent Space for Query Suggestion](http://arxiv.org/abs/2210.12084)</code></li>
<li>Summary: <p>Neural retrieval models have superseded classic bag-of-words methods such as
BM25 as the retrieval framework of choice. However, neural systems lack the
interpretability of bag-of-words models; it is not trivial to connect a query
change to a change in the latent space that ultimately determines the retrieval
results. To shed light on this embedding space, we learn a "query decoder"
that, given a latent representation of a neural search engine, generates the
corresponding query. We show that it is possible to decode a meaningful query
from its latent representation and, when moving in the right direction in
latent space, to decode a query that retrieves the relevant paragraph. In
particular, the query decoder can be useful to understand "what should have
been asked" to retrieve a particular paragraph from the collection. We employ
the query decoder to generate a large synthetic dataset of query reformulations
for MSMarco, leading to improved retrieval performance. On this data, we train
a pseudo-relevance feedback (PRF) T5 model for the application of query
suggestion that outperforms both query reformulation and PRF information
retrieval baselines.
</p></li>
</ul>

<h2>exlainability</h2>
<h2>watermark</h2>
<button id="copy">Copy All</button>
</article>
<script src="../../javascript/clipboard.min.js"></script>
<script src="../../javascript/clipboard.js"></script>
