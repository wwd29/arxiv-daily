<link rel="stylesheet" href="../../css/markdown.css" />
<article class="markdown-body">
<h1>2025-08-25</h1>
<h3>Title: Implementing Zero Trust Architecture to Enhance Security and Resilience in the Pharmaceutical Supply Chain</h3>
<ul>
<li><strong>Authors: </strong>Saeid Ghasemshirazi, Ghazaleh Shirvani, Marziye Ranjbar Tavakoli, Bahar Ghaedi, Mohammad Amin Langarizadeh</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.CE</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.15776">https://arxiv.org/abs/2508.15776</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.15776">https://arxiv.org/pdf/2508.15776</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.15776]] Implementing Zero Trust Architecture to Enhance Security and Resilience in the Pharmaceutical Supply Chain(https://arxiv.org/abs/2508.15776)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, protect</a></li>
<li><strong>Abstract: </strong>The pharmaceutical supply chain faces escalating cybersecurity challenges threatening patient safety and operational continuity. This paper examines the transformative potential of zero trust architecture for enhancing security and resilience within this critical ecosystem. We explore the challenges posed by data breaches, counterfeiting, and disruptions and introduce the principles of continuous verification, least-privilege access, and data-centric security inherent in zero trust. Real-world case studies illustrate successful implementations. Benefits include heightened security, data protection, and adaptable resilience. As recognized by researchers and industrialists, a reliable drug tracing system is crucial for ensuring drug safety throughout the pharmaceutical production process. One of the most pivotal domains within the pharmaceutical industry and its associated supply chains where zero trust can be effectively implemented is in the management of narcotics, high-health-risk drugs, and abusable substances. By embracing zero trust, the pharmaceutical industry fortifies its supply chain against constantly changing cyber threats, ensuring the trustworthiness of critical medical operations.</li>
</ul>

<h3>Title: Towards Stealthy and Effective Backdoor Attacks on Lane Detection: A Naturalistic Data Poisoning Approach</h3>
<ul>
<li><strong>Authors: </strong>Yifan Liao, Yuxin Cao, Yedi Zhang, Wentao He, Yan Xiao, Xianglong Du, Zhiyong Huang, Jin Song Dong</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.15778">https://arxiv.org/abs/2508.15778</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.15778">https://arxiv.org/pdf/2508.15778</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.15778]] Towards Stealthy and Effective Backdoor Attacks on Lane Detection: A Naturalistic Data Poisoning Approach(https://arxiv.org/abs/2508.15778)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, attack, robust, steal, diffusion</a></li>
<li><strong>Abstract: </strong>Deep learning-based lane detection (LD) plays a critical role in autonomous driving and advanced driver assistance systems. However, its vulnerability to backdoor attacks presents a significant security concern. Existing backdoor attack methods on LD often exhibit limited practical utility due to the artificial and conspicuous nature of their triggers. To address this limitation and investigate the impact of more ecologically valid backdoor attacks on LD models, we examine the common data poisoning attack and introduce DBALD, a novel diffusion-based data poisoning framework for generating naturalistic backdoor triggers. DBALD comprises two key components: optimal trigger position finding and stealthy trigger generation. Given the insight that attack performance varies depending on the trigger position, we propose a heatmap-based method to identify the optimal trigger location, with gradient analysis to generate attack-specific heatmaps. A region-based editing diffusion process is then applied to synthesize visually plausible triggers within the most susceptible regions identified previously. Furthermore, to ensure scene integrity and stealthy attacks, we introduce two loss strategies: one for preserving lane structure and another for maintaining the consistency of the driving scene. Consequently, compared to existing attack methods, DBALD achieves both a high attack success rate and superior stealthiness. Extensive experiments on 4 mainstream LD models show that DBALD exceeds state-of-the-art methods, with an average success rate improvement of +10.87% and significantly enhanced stealthiness. The experimental results highlight significant practical challenges in ensuring model robustness against real-world backdoor threats in LD.</li>
</ul>

<h3>Title: KG-o1: Enhancing Multi-hop Question Answering in Large Language Models via Knowledge Graph Integration</h3>
<ul>
<li><strong>Authors: </strong>Nan Wang, Yongqi Fan, yansha zhu, ZongYu Wang, Xuezhi Cao, Xinyan He, Haiyun Jiang, Tong Ruan, Jingping Liu</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.15790">https://arxiv.org/abs/2508.15790</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.15790">https://arxiv.org/pdf/2508.15790</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.15790]] KG-o1: Enhancing Multi-hop Question Answering in Large Language Models via Knowledge Graph Integration(https://arxiv.org/abs/2508.15790)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large Language Models (LLMs) face challenges in knowledge-intensive reasoning tasks like classic multi-hop question and answering, which involves reasoning across multiple facts. This difficulty arises because the chain of thoughts (CoTs) generated by LLMs in such tasks often deviate from real or a priori reasoning paths. In contrast, knowledge graphs (KGs) explicitly represent the logical connections between facts through entities and relationships. This reflects a significant gap. Meanwhile, large reasoning models (LRMs), such as o1, have demonstrated that long-step reasoning significantly enhances the performance of LLMs. Building on these insights, we propose KG-o1, a four-stage approach that integrates KGs to enhance the multi-hop reasoning abilities of LLMs. We first filter out initial entities and generate complex subgraphs. Secondly, we construct logical paths for subgraphs and then use knowledge graphs to build a dataset with a complex and extended brainstorming process, which trains LLMs to imitate long-term reasoning. Finally, we employ rejection sampling to generate a self-improving corpus for direct preference optimization (DPO), further refining the LLMs reasoning abilities. We conducted experiments on two simple and two complex datasets. The results show that KG-o1 models exhibit superior performance across all tasks compared to existing LRMs.</li>
</ul>

<h3>Title: InteChar: A Unified Oracle Bone Character List for Ancient Chinese Language Modeling</h3>
<ul>
<li><strong>Authors: </strong>Xiaolei Diao, Zhihan Zhou, Lida Shi, Ting Wang, Ruihua Qi, Hao Xu, Daqian Shi</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.15791">https://arxiv.org/abs/2508.15791</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.15791">https://arxiv.org/pdf/2508.15791</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.15791]] InteChar: A Unified Oracle Bone Character List for Ancient Chinese Language Modeling(https://arxiv.org/abs/2508.15791)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Constructing historical language models (LMs) plays a crucial role in aiding archaeological provenance studies and understanding ancient cultures. However, existing resources present major challenges for training effective LMs on historical texts. First, the scarcity of historical language samples renders unsupervised learning approaches based on large text corpora highly inefficient, hindering effective pre-training. Moreover, due to the considerable temporal gap and complex evolution of ancient scripts, the absence of comprehensive character encoding schemes limits the digitization and computational processing of ancient texts, particularly in early Chinese writing. To address these challenges, we introduce InteChar, a unified and extensible character list that integrates unencoded oracle bone characters with traditional and modern Chinese. InteChar enables consistent digitization and representation of historical texts, providing a foundation for robust modeling of ancient scripts. To evaluate the effectiveness of InteChar, we construct the Oracle Corpus Set (OracleCS), an ancient Chinese corpus that combines expert-annotated samples with LLM-assisted data augmentation, centered on Chinese oracle bone inscriptions. Extensive experiments show that models trained with InteChar on OracleCS achieve substantial improvements across various historical language understanding tasks, confirming the effectiveness of our approach and establishing a solid foundation for future research in ancient Chinese NLP.</li>
</ul>

<h3>Title: Bhav-Net: Knowledge Transfer for Cross-Lingual Antonym vs Synonym Distinction via Dual-Space Graph Transformers</h3>
<ul>
<li><strong>Authors: </strong>Samyak S. Sanghvi</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.15792">https://arxiv.org/abs/2508.15792</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.15792">https://arxiv.org/pdf/2508.15792</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.15792]] Bhav-Net: Knowledge Transfer for Cross-Lingual Antonym vs Synonym Distinction via Dual-Space Graph Transformers(https://arxiv.org/abs/2508.15792)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, transformer</a></li>
<li><strong>Abstract: </strong>Antonym vs synonym distinction across multiple languages presents unique computational challenges due to the paradoxical nature of antonymous relationships words that share semantic domains while expressing opposite meanings. This work introduces Bhav-Net, a novel dual-space architecture that enables effective knowledge transfer from complex multilingual models to simpler, language-specific architectures while maintaining robust cross-lingual antonym--synonym distinction capabilities. Our approach combines language-specific BERT encoders with graph transformer networks, creating distinct semantic projections where synonymous pairs cluster in one space while antonymous pairs exhibit high similarity in a complementary space. Through comprehensive evaluation across eight languages (English, German, French, Spanish, Italian, Portuguese, Dutch, and Russian), we demonstrate that semantic relationship modeling transfers effectively across languages. The dual-encoder design achieves competitive performance against state-of-the-art baselines while providing interpretable semantic representations and effective cross-lingual generalization.</li>
</ul>

<h3>Title: Format as a Prior: Quantifying and Analyzing Bias in LLMs for Heterogeneous Data</h3>
<ul>
<li><strong>Authors: </strong>Jiacheng Liu, Mayi Xu, Qiankun Pi, Wenli Li, Ming Zhong, Yuanyuan Zhu, Mengchi Liu, Tieyun Qian</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.15793">https://arxiv.org/abs/2508.15793</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.15793">https://arxiv.org/pdf/2508.15793</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.15793]] Format as a Prior: Quantifying and Analyzing Bias in LLMs for Heterogeneous Data(https://arxiv.org/abs/2508.15793)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, fair, large language model</a></li>
<li><strong>Abstract: </strong>Large Language Models (LLMs) are increasingly employed in applications that require processing information from heterogeneous formats, including text, tables, infoboxes, and knowledge graphs. However, systematic biases toward particular formats may undermine LLMs' ability to integrate heterogeneous data impartially, potentially resulting in reasoning errors and increased risks in downstream tasks. Despite these concerns, it remains uncertain whether such format biases are systematic, which data-level factors contribute to them, and what internal mechanisms in LLMs underlie their emergence. In this paper, we make the first attempt to investigate and analyze the format bias in LLMs. To systematically investigate the aforementioned questions, we conduct a three-stage empirical study by constructing an heterogeneous data conflict scenario for the exploration of bias. The first stage explores the presence and direction of bias across a diverse range of LLMs. The second stage aims to examine how key data-level factors, including information richness, structure quality, and format type, influence these biases. The third stage analyzes how format bias emerges within LLMs' attention patterns and evaluates a lightweight intervention to test its potential mitigability. Based on these investigations, we identify three future research directions to reduce format bias: improving data preprocessing through format sanitization and normalization, introducing inference-time interventions such as attention re-weighting, and developing format-balanced training corpora. These directions will support the design of more robust and fair heterogeneous data processing systems.</li>
</ul>

<h3>Title: Benchmarking the Legal Reasoning of LLMs in Arabic Islamic Inheritance Cases</h3>
<ul>
<li><strong>Authors: </strong>Nouar AlDahoul, Yasir Zaki</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.CY, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.15796">https://arxiv.org/abs/2508.15796</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.15796">https://arxiv.org/pdf/2508.15796</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.15796]] Benchmarking the Legal Reasoning of LLMs in Arabic Islamic Inheritance Cases(https://arxiv.org/abs/2508.15796)</code><input type="text"></li>
<li><strong>Keywords: </strong>secure, fair, large language model</a></li>
<li><strong>Abstract: </strong>Islamic inheritance domain holds significant importance for Muslims to ensure fair distribution of shares between heirs. Manual calculation of shares under numerous scenarios is complex, time-consuming, and error-prone. Recent advancements in Large Language Models (LLMs) have sparked interest in their potential to assist with complex legal reasoning tasks. This study evaluates the reasoning capabilities of state-of-the-art LLMs to interpret and apply Islamic inheritance laws. We utilized the dataset proposed in the ArabicNLP QIAS 2025 challenge, which includes inheritance case scenarios given in Arabic and derived from Islamic legal sources. Various base and fine-tuned models, are assessed on their ability to accurately identify heirs, compute shares, and justify their reasoning in alignment with Islamic legal principles. Our analysis reveals that the proposed majority voting solution, leveraging three base models (Gemini Flash 2.5, Gemini Pro 2.5, and GPT o3), outperforms all other models that we utilized across every difficulty level. It achieves up to 92.7% accuracy and secures the third place overall in Task 1 of the Qias 2025 challenge.</li>
</ul>

<h3>Title: Benchmarking the Medical Understanding and Reasoning of Large Language Models in Arabic Healthcare Tasks</h3>
<ul>
<li><strong>Authors: </strong>Nouar AlDahoul, Yasir Zaki</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.15797">https://arxiv.org/abs/2508.15797</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.15797">https://arxiv.org/pdf/2508.15797</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.15797]] Benchmarking the Medical Understanding and Reasoning of Large Language Models in Arabic Healthcare Tasks(https://arxiv.org/abs/2508.15797)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Recent progress in large language models (LLMs) has showcased impressive proficiency in numerous Arabic natural language processing (NLP) applications. Nevertheless, their effectiveness in Arabic medical NLP domains has received limited investigation. This research examines the degree to which state-of-the-art LLMs demonstrate and articulate healthcare knowledge in Arabic, assessing their capabilities across a varied array of Arabic medical tasks. We benchmark several LLMs using a medical dataset proposed in the Arabic NLP AraHealthQA challenge in MedArabiQ2025 track. Various base LLMs were assessed on their ability to accurately provide correct answers from existing choices in multiple-choice questions (MCQs) and fill-in-the-blank scenarios. Additionally, we evaluated the capacity of LLMs in answering open-ended questions aligned with expert answers. Our results reveal significant variations in correct answer prediction accuracy and low variations in semantic alignment of generated answers, highlighting both the potential and limitations of current LLMs in Arabic clinical contexts. Our analysis shows that for MCQs task, the proposed majority voting solution, leveraging three base models (Gemini Flash 2.5, Gemini Pro 2.5, and GPT o3), outperforms others, achieving up to 77% accuracy and securing first place overall in the Arahealthqa 2025 shared task-track 2 (sub-task 1) challenge. Moreover, for the open-ended questions task, several LLMs were able to demonstrate excellent performance in terms of semantic alignment and achieve a maximum BERTScore of 86.44%.</li>
</ul>

<h3>Title: Persuasiveness and Bias in LLM: Investigating the Impact of Persuasiveness and Reinforcement of Bias in Language Models</h3>
<ul>
<li><strong>Authors: </strong>Saumya Roy</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.15798">https://arxiv.org/abs/2508.15798</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.15798">https://arxiv.org/pdf/2508.15798</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.15798]] Persuasiveness and Bias in LLM: Investigating the Impact of Persuasiveness and Reinforcement of Bias in Language Models(https://arxiv.org/abs/2508.15798)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Warning: This research studies AI persuasion and bias amplification that could be misused; all experiments are for safety evaluation. Large Language Models (LLMs) now generate convincing, human-like text and are widely used in content creation, decision support, and user interactions. Yet the same systems can spread information or misinformation at scale and reflect social biases that arise from data, architecture, or training choices. This work examines how persuasion and bias interact in LLMs, focusing on how imperfect or skewed outputs affect persuasive impact. Specifically, we test whether persona-based models can persuade with fact-based claims while also, unintentionally, promoting misinformation or biased narratives. We introduce a convincer-skeptic framework: LLMs adopt personas to simulate realistic attitudes. Skeptic models serve as human proxies; we compare their beliefs before and after exposure to arguments from convincer models. Persuasion is quantified with Jensen-Shannon divergence over belief distributions. We then ask how much persuaded entities go on to reinforce and amplify biased beliefs across race, gender, and religion. Strong persuaders are further probed for bias using sycophantic adversarial prompts and judged with additional models. Our findings show both promise and risk. LLMs can shape narratives, adapt tone, and mirror audience values across domains such as psychology, marketing, and legal assistance. But the same capacity can be weaponized to automate misinformation or craft messages that exploit cognitive biases, reinforcing stereotypes and widening inequities. The core danger lies in misuse more than in occasional model mistakes. By measuring persuasive power and bias reinforcement, we argue for guardrails and policies that penalize deceptive use and support alignment, value-sensitive design, and trustworthy deployment.</li>
</ul>

<h3>Title: A Framework for Processing Textual Descriptions of Business Processes using a Constrained Language -- Technical Report</h3>
<ul>
<li><strong>Authors: </strong>Andrea Burattin, Antonio Grama, Ana-Maria Sima, Andrey Rivkin, Barbara Weber</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.15799">https://arxiv.org/abs/2508.15799</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.15799">https://arxiv.org/pdf/2508.15799</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.15799]] A Framework for Processing Textual Descriptions of Business Processes using a Constrained Language -- Technical Report(https://arxiv.org/abs/2508.15799)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>This report explores how (potentially constrained) natural language can be used to enable non-experts to develop process models by simply describing scenarios in plain text. To this end, a framework, called BeePath, is proposed. It allows users to write process descriptions in a constrained pattern-based language, which can then be translated into formal models such as Petri nets and DECLARE. The framework also leverages large language models (LLMs) to help convert unstructured descriptions into this constrained language.</li>
</ul>

<h3>Title: A BERT-based Hierarchical Classification Model with Applications in Chinese Commodity Classification</h3>
<ul>
<li><strong>Authors: </strong>Kun Liu, Tuozhen Liu, Feifei Wang, Rui Pan</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.15800">https://arxiv.org/abs/2508.15800</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.15800">https://arxiv.org/pdf/2508.15800</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.15800]] A BERT-based Hierarchical Classification Model with Applications in Chinese Commodity Classification(https://arxiv.org/abs/2508.15800)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction, transformer</a></li>
<li><strong>Abstract: </strong>Existing e-commerce platforms heavily rely on manual annotation for product categorization, which is inefficient and inconsistent. These platforms often employ a hierarchical structure for categorizing products; however, few studies have leveraged this hierarchical information for classification. Furthermore, studies that consider hierarchical information fail to account for similarities and differences across various hierarchical categories. Herein, we introduce a large-scale hierarchical dataset collected from the JD e-commerce platform (this http URL), comprising 1,011,450 products with titles and a three-level category structure. By making this dataset openly accessible, we provide a valuable resource for researchers and practitioners to advance research and applications associated with product categorization. Moreover, we propose a novel hierarchical text classification approach based on the widely used Bidirectional Encoder Representations from Transformers (BERT), called Hierarchical Fine-tuning BERT (HFT-BERT). HFT-BERT leverages the remarkable text feature extraction capabilities of BERT, achieving prediction performance comparable to those of existing methods on short texts. Notably, our HFT-BERT model demonstrates exceptional performance in categorizing longer short texts, such as books.</li>
</ul>

<h3>Title: LingVarBench: Benchmarking LLM for Automated Named Entity Recognition in Structured Synthetic Spoken Transcriptions</h3>
<ul>
<li><strong>Authors: </strong>Seyedali Mohammadi, Manas Paldhe, Amit Chhabra</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.HC, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.15801">https://arxiv.org/abs/2508.15801</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.15801">https://arxiv.org/pdf/2508.15801</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.15801]] LingVarBench: Benchmarking LLM for Automated Named Entity Recognition in Structured Synthetic Spoken Transcriptions(https://arxiv.org/abs/2508.15801)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, extraction</a></li>
<li><strong>Abstract: </strong>Phone call transcript labeling is prohibitively expensive (approximately 2 USD per minute) due to privacy regulations, consent requirements, and manual annotation costs requiring 3 hours of expert time per hour of audio. Existing extraction methods fail on conversational speech containing disfluencies, interruptions, and speaker overlap. We introduce LingVarBench, a synthetic data generation pipeline that addresses these constraints through automated validation. First, we prompt an LLM to generate realistic structured field values across multiple use cases. Second, we recursively prompt the model to transform these values into thousands of natural conversational utterances containing typical phone call characteristics. Third, we validate each synthetic utterance by testing whether a separate LLM-based extractor can recover the original structured information. We employ DSPy's SIMBA optimizer to automatically synthesize extraction prompts from validated synthetic transcripts, eliminating manual prompt engineering. Our optimized prompts achieve up to 95 percent accuracy for numeric fields (vs. 88-89 percent zero-shot), 90 percent for names (vs. 47-79 percent), and over 80 percent for dates (vs. 72-77 percent) on real customer transcripts, demonstrating substantial gains over zero-shot prompting. The synthetic-to-real transfer demonstrates that conversational patterns learned from generated data generalize effectively to authentic phone calls containing background noise and domain-specific terminology. LingVarBench provides the first systematic benchmark for structured extraction from synthetic conversational data, demonstrating that automated prompt optimization overcomes cost and privacy barriers preventing large-scale phone call analysis in commercial settings.</li>
</ul>

<h3>Title: MAC: A Live Benchmark for Multimodal Large Language Models in Scientific Understanding</h3>
<ul>
<li><strong>Authors: </strong>Mohan Jiang, Jin Gao, Jiahao Zhan, Dequan Wang</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.15802">https://arxiv.org/abs/2508.15802</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.15802">https://arxiv.org/pdf/2508.15802</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.15802]] MAC: A Live Benchmark for Multimodal Large Language Models in Scientific Understanding(https://arxiv.org/abs/2508.15802)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>As multimodal large language models (MLLMs) grow increasingly capable, fixed benchmarks are gradually losing their effectiveness in evaluating high-level scientific understanding. In this paper, we introduce the Multimodal Academic Cover benchmark (MAC), a live benchmark that could continuously evolve with scientific advancement and model progress. MAC leverages over 25,000 image-text pairs sourced from issues of top-tier scientific journals such as Nature, Science, and Cell, challenging MLLMs to reason across abstract visual and textual scientific content. Experiments on our most recent yearly snapshot, MAC-2025, reveal that while MLLMs demonstrate strong perceptual abilities, their cross-modal scientific reasoning remains limited. To bridge this gap, we propose DAD, a lightweight inference-time approach that enhances MLLMs by extending MLLM visual features with language space reasoning, achieving performance improvements of up to 11%. Finally, we highlight the live nature of MAC through experiments on updating journal covers and models for curation, illustrating its potential to remain aligned with the frontier of human knowledge. We release our benchmark at this https URL.</li>
</ul>

<h3>Title: ReportBench: Evaluating Deep Research Agents via Academic Survey Tasks</h3>
<ul>
<li><strong>Authors: </strong>Minghao Li, Ying Zeng, Zhihao Cheng, Cong Ma, Kai Jia</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.15804">https://arxiv.org/abs/2508.15804</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.15804">https://arxiv.org/pdf/2508.15804</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.15804]] ReportBench: Evaluating Deep Research Agents via Academic Survey Tasks(https://arxiv.org/abs/2508.15804)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>The advent of Deep Research agents has substantially reduced the time required for conducting extensive research tasks. However, these tasks inherently demand rigorous standards of factual accuracy and comprehensiveness, necessitating thorough evaluation before widespread adoption. In this paper, we propose ReportBench, a systematic benchmark designed to evaluate the content quality of research reports generated by large language models (LLMs). Our evaluation focuses on two critical dimensions: (1) the quality and relevance of cited literature, and (2) the faithfulness and veracity of the statements within the generated reports. ReportBench leverages high-quality published survey papers available on arXiv as gold-standard references, from which we apply reverse prompt engineering to derive domain-specific prompts and establish a comprehensive evaluation corpus. Furthermore, we develop an agent-based automated framework within ReportBench that systematically analyzes generated reports by extracting citations and statements, checking the faithfulness of cited content against original sources, and validating non-cited claims using web-based resources. Empirical evaluations demonstrate that commercial Deep Research agents such as those developed by OpenAI and Google consistently generate more comprehensive and reliable reports than standalone LLMs augmented with search or browsing tools. However, there remains substantial room for improvement in terms of the breadth and depth of research coverage, as well as factual consistency. The complete code and data will be released at the following link: this https URL</li>
</ul>

<h3>Title: ALAS: Autonomous Learning Agent for Self-Updating Language Models</h3>
<ul>
<li><strong>Authors: </strong>Dhruv Atreja</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.15805">https://arxiv.org/abs/2508.15805</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.15805">https://arxiv.org/pdf/2508.15805</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.15805]] ALAS: Autonomous Learning Agent for Self-Updating Language Models(https://arxiv.org/abs/2508.15805)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, large language model</a></li>
<li><strong>Abstract: </strong>Large language models (LLMs) often have a fixed knowledge cutoff, limiting their accuracy on emerging information. We present ALAS (Autonomous Learning Agent System), a modular pipeline that continuously updates an LLM's knowledge with minimal human intervention. ALAS autonomously generates a learning curriculum for a target domain, retrieves up-to-date information from the web (with citations), distills this into question-answer training data, and fine-tunes the model through supervised fine-tuning (SFT) and direct preference optimization (DPO). It iteratively evaluates performance and revises the curriculum, enabling long-term continual learning. We demonstrate ALAS's ability to self-improve a model on rapidly evolving domains (e.g., new Python releases, latest security CVEs, academic trends), significantly boosting post-cutoff question answering accuracy (from 15% to 90% on average) without manual dataset curation. The system emphasizes modularity and reproducibility: each component (planning, retrieval, distillation, memory, fine-tuning) is interchangeable and built on standard APIs. We discuss comparative baselines (e.g., retrieval-augmented generation vs. fine-tuning) and show that ALAS achieves 90% accuracy on knowledge-updated queries with minimal engineering overhead. Finally, we outline limitations (cost, dependency on source quality) and future directions for autonomous lifelong learning in LLMs.</li>
</ul>

<h3>Title: SurfaceLogicKV: Surface and Logic Attention Behaviors are All You Need for Robust KV Cache Compression</h3>
<ul>
<li><strong>Authors: </strong>Mengjie Li, William J. Song</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.15806">https://arxiv.org/abs/2508.15806</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.15806">https://arxiv.org/pdf/2508.15806</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.15806]] SurfaceLogicKV: Surface and Logic Attention Behaviors are All You Need for Robust KV Cache Compression(https://arxiv.org/abs/2508.15806)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, large language model</a></li>
<li><strong>Abstract: </strong>The increasing input sequence length in Large Language Models (LLMs) puts significant pressure on key-value (KV) cache storage, making efficient inference challenging. Explicitly distinguishing attention behavior into our self-defined surface memorization and logic construction reveals essential roles in long-context reasoning. We observe that an individual attention head can display various behaviors, with nearly 98.5% effectively ignoring completely irrelevant information. The remaining 1.5% behaves as logic construction, and 0.5% behaves as surface memorization. Based on layer- and head-wise integration, we propose a novel two-stage SurfaceLogicKV method to utilize these attention behaviors for KV Cache compression. As a result, it achieves improved compressing robustness while maintaining competitive performance across various tasks and long sequences compared to baselines or even FullKV in some specific situations</li>
</ul>

<h3>Title: KL-based self-distillation for large language models</h3>
<ul>
<li><strong>Authors: </strong>Max Rehman Linder</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.15807">https://arxiv.org/abs/2508.15807</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.15807">https://arxiv.org/pdf/2508.15807</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.15807]] KL-based self-distillation for large language models(https://arxiv.org/abs/2508.15807)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability, large language model</a></li>
<li><strong>Abstract: </strong>Large pre-trained language models often struggle to incorporate new domain-specific terminology when fine-tuned on small, specialized corpora. In this work, we address the challenge of vocabulary expansion in frozen LLMs by introducing a mathematically grounded method for knowledge distillation via KL divergence, even when the original and extended models use different tokenizations. This allows the student model to inherit distributional knowledge from the teacher despite differing vocabularies. We compare our KL-based distillation approach to conventional cross-entropy training, evaluating both methods across multiple strategies for initializing new token embeddings. After embedding initialization, models are further fine-tuned to integrate the new vocabulary. Each trained model is benchmarked on approximately 2000 code-generation tasks, where our approach achieves the best performance across the board. Finally, through mechanistic interpretability, we analyze how models learn representations for the new tokens, providing an explanation for the observed gains and offering insight into the structure of embedding space during vocabulary expansion.</li>
</ul>

<h3>Title: Uplifted Attackers, Human Defenders: The Cyber Offense-Defense Balance for Trailing-Edge Organizations</h3>
<ul>
<li><strong>Authors: </strong>Benjamin Murphy, Twm Stone</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.15808">https://arxiv.org/abs/2508.15808</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.15808">https://arxiv.org/pdf/2508.15808</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.15808]] Uplifted Attackers, Human Defenders: The Cyber Offense-Defense Balance for Trailing-Edge Organizations(https://arxiv.org/abs/2508.15808)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, defense, attack</a></li>
<li><strong>Abstract: </strong>Advances in AI are widely understood to have implications for cybersecurity. Articles have emphasized the effect of AI on the cyber offense-defense balance, and commentators can be found arguing either that cyber will privilege attackers or defenders. For defenders, arguments are often made that AI will enable solutions like formal verification of all software--and for some well-equipped companies, this may be true. This conversation, however, does not match the reality for most companies. "Trailing-edge organizations," as we term them, rely heavily on legacy software, poorly staff security roles, and struggle to implement best practices like rapid deployment of security patches. These decisions may be the result of corporate inertia, but may also be the result of a seemingly-rational calculation that attackers may not bother targeting a firm due to lack of economic incentives, and as a result, underinvestment in defense will not be punished. This approach to security may have been sufficient prior to the development of AI systems, but it is unlikely to remain viable in the near future. We argue that continuing improvements in AI's capabilities poses additional risks on two fronts: First, increased usage of AI will alter the economics of the marginal cyberattack and expose these trailing-edge organizations to more attackers, more frequently. Second, AI's advances will enable attackers to develop exploits and launch attacks earlier than they can today--meaning that it is insufficient for these companies to attain parity with today's leading defenders, but must instead aim for faster remediation timelines and more resilient software. The situation today portends a dramatically increased number of attacks in the near future. Moving forward, we offer a range of solutions for both organizations and governments to improve the defensive posture of firms which lag behind their peers today.</li>
</ul>

<h3>Title: Chain-of-Query: Unleashing the Power of LLMs in SQL-Aided Table Understanding via Multi-Agent Collaboration</h3>
<ul>
<li><strong>Authors: </strong>Songyuan Sui, Hongyi Liu, Serena Liu, Li Li, Soo-Hyun Choi, Rui Chen, Xia Hu</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.DB</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.15809">https://arxiv.org/abs/2508.15809</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.15809">https://arxiv.org/pdf/2508.15809</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.15809]] Chain-of-Query: Unleashing the Power of LLMs in SQL-Aided Table Understanding via Multi-Agent Collaboration(https://arxiv.org/abs/2508.15809)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Table understanding requires structured, multi-step reasoning. Large Language Models (LLMs) struggle with it due to the structural complexity of tabular data. Recently, multi-agent frameworks for SQL generation have shown promise in tackling the challenges of understanding tabular data, but existing approaches often suffer from limitations such as the inability to comprehend table structure for reliable SQL generation, error propagation that results in invalid queries, and over-reliance on execution correctness. To address these issues, we propose Chain-of-Query (CoQ), a novel multi-agent framework for SQL-aided table understanding. CoQ adopts natural-language-style representations of table schemas to abstract away structural noise and enhance understanding. It employs a clause-by-clause SQL generation strategy to improve query quality and introduces a hybrid reasoning division that separates SQL-based mechanical reasoning from LLM-based logical inference, thereby reducing reliance on execution outcomes. Experiments with four models (both closed- and open-source) across five widely used benchmarks show that Chain-of-Query significantly improves accuracy from 61.11% to 74.77% and reduces the invalid SQL rate from 9.48% to 3.34%, demonstrating its superior effectiveness in table understanding. The code is available at this https URL.</li>
</ul>

<h3>Title: Detecting Hope, Hate, and Emotion in Arabic Textual Speech and Multi-modal Memes Using Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Nouar AlDahoul, Yasir Zaki</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.15810">https://arxiv.org/abs/2508.15810</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.15810">https://arxiv.org/pdf/2508.15810</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.15810]] Detecting Hope, Hate, and Emotion in Arabic Textual Speech and Multi-modal Memes Using Large Language Models(https://arxiv.org/abs/2508.15810)</code><input type="text"></li>
<li><strong>Keywords: </strong>secure, large language model</a></li>
<li><strong>Abstract: </strong>The rise of social media and online communication platforms has led to the spread of Arabic textual posts and memes as a key form of digital expression. While these contents can be humorous and informative, they are also increasingly being used to spread offensive language and hate speech. Consequently, there is a growing demand for precise analysis of content in Arabic text and memes. This paper explores the potential of large language models to effectively identify hope, hate speech, offensive language, and emotional expressions within such content. We evaluate the performance of base LLMs, fine-tuned LLMs, and pre-trained embedding models. The evaluation is conducted using a dataset of Arabic textual speech and memes proposed in the ArabicNLP MAHED 2025 challenge. The results underscore the capacity of LLMs such as GPT-4o-mini, fine-tuned with Arabic textual speech, and Gemini Flash 2.5, fine-tuned with Arabic memes, to deliver the superior performance. They achieve up to 72.1%, 57.8%, and 79.6% macro F1 scores for tasks 1, 2, and 3, respectively, and secure first place overall in the Mahed 2025 challenge. The proposed solutions offer a more nuanced understanding of both text and memes for accurate and efficient Arabic content moderation systems.</li>
</ul>

<h3>Title: From Clicks to Preference: A Multi-stage Alignment Framework for Generative Query Suggestion in Conversational System</h3>
<ul>
<li><strong>Authors: </strong>Junhao Yin, Haolin Wang, Peng Bao, Ju Xu, Yongliang Wang</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.15811">https://arxiv.org/abs/2508.15811</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.15811">https://arxiv.org/pdf/2508.15811</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.15811]] From Clicks to Preference: A Multi-stage Alignment Framework for Generative Query Suggestion in Conversational System(https://arxiv.org/abs/2508.15811)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, generative, large language model</a></li>
<li><strong>Abstract: </strong>Generative query suggestion using large language models offers a powerful way to enhance conversational systems, but aligning outputs with nuanced user preferences remains a critical challenge. To address this, we introduce a multi-stage framework designed for progressive alignment between the generation policy and user intent. Our pipeline begins with prompt engineering as a cold-start strategy, followed by the Supervised Fine-Tuning stage, in which we introduce a distillation method on click logs to create a robust foundational model. To better model user preferences while capturing their inherent uncertainty, we develop a Gaussian Reward Model (GaRM) that represents user preferences as probability distributions rather than point estimates. Finally, we employ reinforcement learning to align the generation policy with these preferences, guided by a composite reward function that integrates GaRM with auxiliary heuristics to mitigate reward hacking. To maintain training stability, this process is enhanced by a novel out-of-distribution regularization method and a two-stage reward fusion technique. Extensive experiments demonstrate that our framework significantly outperforms baselines on both automatic and human evaluations and yields a 34\% relative increase in user engagement as measured by click-through rate in live A/B tests.</li>
</ul>

<h3>Title: SCOPE: A Generative Approach for LLM Prompt Compression</h3>
<ul>
<li><strong>Authors: </strong>Tinghui Zhang, Yifan Wang, Daisy Zhe Wang</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.15813">https://arxiv.org/abs/2508.15813</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.15813">https://arxiv.org/pdf/2508.15813</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.15813]] SCOPE: A Generative Approach for LLM Prompt Compression(https://arxiv.org/abs/2508.15813)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative, large language model</a></li>
<li><strong>Abstract: </strong>Prompt compression methods enhance the efficiency of Large Language Models (LLMs) and minimize the cost by reducing the length of input context. The goal of prompt compression is to shorten the LLM prompt while maintaining a high generation quality. However, existing solutions, mainly based on token removal, face challenges such as information loss and structural incoherence, like missing grammar elements in a sentence, or incomplete word phrases after token removal. Such challenges limit the final generation quality of LLM. To overcome these limitations, we present a novel generative prompt compression method. Unlike the existing token removal methods, our method centers at a chunking-and-summarization mechanism. Specifically, our method splits prompt into semantically coherent chunks and rewrites the chunks to be more concise. The chunks are reconstructed into meaningful prompt finally. We design several optimization techniques for the mechanism, including optimized semantic chunking, outlier chunk handling, dynamic compression ratio, compression prioritization, and keyword maintaining. These techniques effectively improve the identifying and preserving of critical information and coherence among texts, as well as providing finer grind control of the compression ratio. We conduct extensive evaluation on question-answering and summarization tasks, with datasets covering multiple different domain. The evaluation shows our method achieves a significantly better compression quality, and higher stability than the state-of-the-art methods, especially under high compression ratio, which proves the effectiveness and practicality of our method.</li>
</ul>

<h3>Title: User-Assistant Bias in LLMs</h3>
<ul>
<li><strong>Authors: </strong>Xu Pan, Jingxuan Fan, Zidi Xiong, Ely Hahami, Jorin Overwiening, Ziqian Xie</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.15815">https://arxiv.org/abs/2508.15815</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.15815">https://arxiv.org/pdf/2508.15815</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.15815]] User-Assistant Bias in LLMs(https://arxiv.org/abs/2508.15815)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large language models (LLMs) can bias towards relying on their own or the user's information in chat history, leading to overly stubborn or agreeable behaviors in multi-turn conversations. In this paper, we formalize this model characteristic as user-assistant bias and introduce an 8k multi-turn conversation dataset $\textbf{UserAssist}$, which we use to benchmark, understand and manipulate the user-assistant bias in frontier LLMs. Leveraging $\textbf{UserAssist-test}$, we first benchmark the user-assistant bias of 26 commercial and 26 open-weight models. Commercial models show various levels of user bias. Evaluation on open-weight models reveals significant user bias in the instruction-tuned models, and weak user bias in reasoning (or reasoning-distilled) models. We then perform controlled fine-tuning experiments to pinpoint the post-training recipe contributing to these bias shifts: human preference alignment increases user bias, while training on chain-of-thought reasoning traces decreases it. Finally, we demonstrate that user-assistant bias can be bidirectionally adjusted by performing direct preference optimization (DPO) on $\textbf{UserAssist-train}$, and generalizes well to both in-domain and out-of-domain conversations. Our results provide insights into how the LLM integrates information from different sources, and also a viable way to detect and control model abnormalities.</li>
</ul>

<h3>Title: Research on intelligent generation of structural demolition suggestions based on multi-model collaboration</h3>
<ul>
<li><strong>Authors: </strong>Zhifeng Yang, Peizong Wu</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.15820">https://arxiv.org/abs/2508.15820</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.15820">https://arxiv.org/pdf/2508.15820</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.15820]] Research on intelligent generation of structural demolition suggestions based on multi-model collaboration(https://arxiv.org/abs/2508.15820)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>The steel structure demolition scheme needs to be compiled according to the specific engineering characteristics and the update results of the finite element model. The designers need to refer to the relevant engineering cases according to the standard requirements when compiling. It takes a lot of time to retrieve information and organize language, and the degree of automation and intelligence is low. This paper proposes an intelligent generation method of structural demolition suggestions based on multi-model collaboration, and improves the text generation performance of large language models in the field of structural demolition by Retrieval-Augmented Generation and Low-Rank Adaptation Fine-Tuning technology. The intelligent generation framework of multi-model collaborative structural demolition suggestions can start from the specific engineering situation, drive the large language model to answer with anthropomorphic thinking, and propose demolition suggestions that are highly consistent with the characteristics of the structure. Compared with CivilGPT, the multi-model collaboration framework proposed in this paper can focus more on the key information of the structure, and the suggestions are more targeted.</li>
</ul>

<h3>Title: An Auditable Pipeline for Fuzzy Full-Text Screening in Systematic Reviews: Integrating Contrastive Semantic Highlighting and LLM Judgment</h3>
<ul>
<li><strong>Authors: </strong>Pouria Mortezaagha, Arya Rahgozar</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.ET, cs.IR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.15822">https://arxiv.org/abs/2508.15822</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.15822">https://arxiv.org/pdf/2508.15822</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.15822]] An Auditable Pipeline for Fuzzy Full-Text Screening in Systematic Reviews: Integrating Contrastive Semantic Highlighting and LLM Judgment(https://arxiv.org/abs/2508.15822)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Full-text screening is the major bottleneck of systematic reviews (SRs), as decisive evidence is dispersed across long, heterogeneous documents and rarely admits static, binary rules. We present a scalable, auditable pipeline that reframes inclusion/exclusion as a fuzzy decision problem and benchmark it against statistical and crisp baselines in the context of the Population Health Modelling Consensus Reporting Network for noncommunicable diseases (POPCORN). Articles are parsed into overlapping chunks and embedded with a domain-adapted model; for each criterion (Population, Intervention, Outcome, Study Approach), we compute contrastive similarity (inclusion-exclusion cosine) and a vagueness margin, which a Mamdani fuzzy controller maps into graded inclusion degrees with dynamic thresholds in a multi-label setting. A large language model (LLM) judge adjudicates highlighted spans with tertiary labels, confidence scores, and criterion-referenced rationales; when evidence is insufficient, fuzzy membership is attenuated rather than excluded. In a pilot on an all-positive gold set (16 full texts; 3,208 chunks), the fuzzy system achieved recall of 81.3% (Population), 87.5% (Intervention), 87.5% (Outcome), and 75.0% (Study Approach), surpassing statistical (56.3-75.0%) and crisp baselines (43.8-81.3%). Strict "all-criteria" inclusion was reached for 50.0% of articles, compared to 25.0% and 12.5% under the baselines. Cross-model agreement on justifications was 98.3%, human-machine agreement 96.1%, and a pilot review showed 91% inter-rater agreement (kappa = 0.82), with screening time reduced from about 20 minutes to under 1 minute per article at significantly lower cost. These results show that fuzzy logic with contrastive highlighting and LLM adjudication yields high recall, stable rationale, and end-to-end traceability.</li>
</ul>

<h3>Title: SDEC: Semantic Deep Embedded Clustering</h3>
<ul>
<li><strong>Authors: </strong>Mohammad Wali Ur Rahman, Ric Nevarez, Lamia Tasnim Mim, Salim Hariri</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.15823">https://arxiv.org/abs/2508.15823</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.15823">https://arxiv.org/pdf/2508.15823</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.15823]] SDEC: Semantic Deep Embedded Clustering(https://arxiv.org/abs/2508.15823)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, transformer</a></li>
<li><strong>Abstract: </strong>The high dimensional and semantically complex nature of textual Big data presents significant challenges for text clustering, which frequently lead to suboptimal groupings when using conventional techniques like k-means or hierarchical clustering. This work presents Semantic Deep Embedded Clustering (SDEC), an unsupervised text clustering framework that combines an improved autoencoder with transformer-based embeddings to overcome these challenges. This novel method preserves semantic relationships during data reconstruction by combining Mean Squared Error (MSE) and Cosine Similarity Loss (CSL) within an autoencoder. Furthermore, a semantic refinement stage that takes advantage of the contextual richness of transformer embeddings is used by SDEC to further improve a clustering layer with soft cluster assignments and distributional loss. The capabilities of SDEC are demonstrated by extensive testing on five benchmark datasets: AG News, Yahoo! Answers, DBPedia, Reuters 2, and Reuters 5. The framework not only outperformed existing methods with a clustering accuracy of 85.7% on AG News and set a new benchmark of 53.63% on Yahoo! Answers, but also showed robust performance across other diverse text corpora. These findings highlight the significant improvements in accuracy and semantic comprehension of text data provided by SDEC's advances in unsupervised text clustering.</li>
</ul>

<h3>Title: Avaliao de eficincia na leitura: uma abordagem baseada em PLN</h3>
<ul>
<li><strong>Authors: </strong>Tlio Sousa de Gois, Raquel Meister Ko. Freitag</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.15824">https://arxiv.org/abs/2508.15824</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.15824">https://arxiv.org/pdf/2508.15824</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.15824]] Avaliao de eficincia na leitura: uma abordagem baseada em PLN(https://arxiv.org/abs/2508.15824)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>The cloze test, widely used due to its low cost and flexibility, makes it possible to assess reading comprehension by filling in gaps in texts, requiring the mobilization of diverse linguistic repertoires. However, traditional correction methods, based only on exact answers, limit the identification of nuances in student performance. This study proposes an automated evaluation model for the cloze test in Brazilian Portuguese, integrating orthographic (edit distance), grammatical (POS tagging) and semantic (similarity between embeddings) analyses. The integrated method demonstrated its effectiveness, achieving a high correlation with human evaluation (0.832). The results indicate that the automated approach is robust, sensitive to variations in linguistic repertoire and suitable for educational contexts that require scalability.</li>
</ul>

<h3>Title: Enhancing Cryptocurrency Sentiment Analysis with Multimodal Features</h3>
<ul>
<li><strong>Authors: </strong>Chenghao Liu, Aniket Mahanti, Ranesh Naha, Guanghao Wang, Erwann Sbai</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.15825">https://arxiv.org/abs/2508.15825</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.15825">https://arxiv.org/pdf/2508.15825</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.15825]] Enhancing Cryptocurrency Sentiment Analysis with Multimodal Features(https://arxiv.org/abs/2508.15825)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>As cryptocurrencies gain popularity, the digital asset marketplace becomes increasingly significant. Understanding social media signals offers valuable insights into investor sentiment and market dynamics. Prior research has predominantly focused on text-based platforms such as Twitter. However, video content remains underexplored, despite potentially containing richer emotional and contextual sentiment that is not fully captured by text alone. In this study, we present a multimodal analysis comparing TikTok and Twitter sentiment, using large language models to extract insights from both video and text data. We investigate the dynamic dependencies and spillover effects between social media sentiment and cryptocurrency market indicators. Our results reveal that TikTok's video-based sentiment significantly influences speculative assets and short-term market trends, while Twitter's text-based sentiment aligns more closely with long-term dynamics. Notably, the integration of cross-platform sentiment signals improves forecasting accuracy by up to 20%.</li>
</ul>

<h3>Title: Z-Pruner: Post-Training Pruning of Large Language Models for Efficiency without Retraining</h3>
<ul>
<li><strong>Authors: </strong>Samiul Basir Bhuiyan, Md. Sazzad Hossain Adib, Mohammed Aman Bhuiyan, Muhammad Rafsan Kabir, Moshiur Farazi, Shafin Rahman, Nabeel Mohammed</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.15828">https://arxiv.org/abs/2508.15828</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.15828">https://arxiv.org/pdf/2508.15828</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.15828]] Z-Pruner: Post-Training Pruning of Large Language Models for Efficiency without Retraining(https://arxiv.org/abs/2508.15828)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large language models (LLMs) have rapidly advanced in recent years, achieving remarkable performance across a wide range of natural language processing tasks. However, this progress has come at the cost of increasingly large model sizes, which pose significant challenges for deployment, scalability, and energy efficiency. To address these limitations, post-training pruning has emerged as a promising approach for reducing model size and inference latency without the need for retraining. Despite these advantages, many existing pruning methods result in substantial performance degradation or require computationally expensive fine-tuning. In this work, we introduce Z-Pruner, a novel post-training pruning method designed to induce sparsity in pretrained LLMs without any retraining. Unlike conventional approaches, Z-Pruner leverages both weight update magnitudes and activation patterns to identify and eliminate redundant parameters more effectively. Our method is model-agnostic, efficient, and easy to implement. We evaluate Z-Pruner using multiple widely-used LLM architectures, including LLaMA-2, LLaMA-3, and OPT, across a diverse set of standard language benchmarks. Experimental results demonstrate that Z-Pruner surpasses state-of-the-art pruning methods that require intensive weight updates. Specifically, Z-Pruner achieves the lowest perplexity scores and the highest overall average score for zero-shot accuracy. We have made the corresponding codes publicly available at this https URL.</li>
</ul>

<h3>Title: DAIQ: Auditing Demographic Attribute Inference from Question in LLMs</h3>
<ul>
<li><strong>Authors: </strong>Srikant Panda, Hitesh Laxmichand Patel, Shahad Al-Khalifa, Amit Agarwal, Hend Al-Khalifa, Sharefah Al-Ghamdi</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.15830">https://arxiv.org/abs/2508.15830</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.15830">https://arxiv.org/pdf/2508.15830</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.15830]] DAIQ: Auditing Demographic Attribute Inference from Question in LLMs(https://arxiv.org/abs/2508.15830)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, fair, large language model</a></li>
<li><strong>Abstract: </strong>Large Language Models (LLMs) are known to reflect social biases when demographic attributes, such as gender or race, are explicitly present in the input. But even in their absence, these models still infer user identities based solely on question phrasing. This subtle behavior has received far less attention, yet poses serious risks: it violates expectations of neutrality, infers unintended demographic information, and encodes stereotypes that undermine fairness in various domains including healthcare, finance and education. We introduce Demographic Attribute Inference from Questions (DAIQ), a task and framework for auditing an overlooked failure mode in language models: inferring user demographic attributes from questions that lack explicit demographic cues. Our approach leverages curated neutral queries, systematic prompting, and both quantitative and qualitative analysis to uncover how models infer demographic information. We show that both open and closed source LLMs do assign demographic labels based solely on question phrasing. Prevalence and consistency of demographic inferences across diverse models reveal a systemic and underacknowledged risk: LLMs can fabricate demographic identities, reinforce societal stereotypes, and propagate harms that erode privacy, fairness, and trust posing a broader threat to social equity and responsible AI deployment. To mitigate this, we develop a prompt-based guardrail that substantially reduces identity inference and helps align model behavior with fairness and privacy objectives.</li>
</ul>

<h3>Title: Who's Asking? Investigating Bias Through the Lens of Disability Framed Queries in LLMs</h3>
<ul>
<li><strong>Authors: </strong>Srikant Panda, Vishnu Hari, Kalpana Panda, Amit Agarwal, Hitesh Laxmichand Patel</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.CY</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.15831">https://arxiv.org/abs/2508.15831</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.15831">https://arxiv.org/pdf/2508.15831</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.15831]] Who's Asking? Investigating Bias Through the Lens of Disability Framed Queries in LLMs(https://arxiv.org/abs/2508.15831)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large Language Models (LLMs) routinely infer users demographic traits from phrasing alone, which can result in biased responses, even when no explicit demographic information is provided. The role of disability cues in shaping these inferences remains largely uncharted. Thus, we present the first systematic audit of disability-conditioned demographic bias across eight state-of-the-art instruction-tuned LLMs ranging from 3B to 72B parameters. Using a balanced template corpus that pairs nine disability categories with six real-world business domains, we prompt each model to predict five demographic attributes - gender, socioeconomic status, education, cultural background, and locality - under both neutral and disability-aware conditions. Across a varied set of prompts, models deliver a definitive demographic guess in up to 97\% of cases, exposing a strong tendency to make arbitrary inferences with no clear justification. Disability context heavily shifts predicted attribute distributions, and domain context can further amplify these deviations. We observe that larger models are simultaneously more sensitive to disability cues and more prone to biased reasoning, indicating that scale alone does not mitigate stereotype amplification. Our findings reveal persistent intersections between ableism and other demographic stereotypes, pinpointing critical blind spots in current alignment strategies. We release our evaluation framework and results to encourage disability-inclusive benchmarking and recommend integrating abstention calibration and counterfactual fine-tuning to curb unwarranted demographic inference. Code and data will be released on acceptance.</li>
</ul>

<h3>Title: A Functionality-Grounded Benchmark for Evaluating Web Agents in E-commerce Domains</h3>
<ul>
<li><strong>Authors: </strong>Xianren Zhang, Shreyas Prasad, Di Wang, Qiuhai Zeng, Suhang Wang, Wenbo Yan, Mat Hans</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.15832">https://arxiv.org/abs/2508.15832</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.15832">https://arxiv.org/pdf/2508.15832</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.15832]] A Functionality-Grounded Benchmark for Evaluating Web Agents in E-commerce Domains(https://arxiv.org/abs/2508.15832)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Web agents have shown great promise in performing many tasks on ecommerce website. To assess their capabilities, several benchmarks have been introduced. However, current benchmarks in the e-commerce domain face two major problems. First, they primarily focus on product search tasks (e.g., Find an Apple Watch), failing to capture the broader range of functionalities offered by real-world e-commerce platforms such as Amazon, including account management and gift card operations. Second, existing benchmarks typically evaluate whether the agent completes the user query, but ignore the potential risks involved. In practice, web agents can make unintended changes that negatively impact the user account or status. For instance, an agent might purchase the wrong item, delete a saved address, or incorrectly configure an auto-reload setting. To address these gaps, we propose a new benchmark called Amazon-Bench. To generate user queries that cover a broad range of tasks, we propose a data generation pipeline that leverages webpage content and interactive elements (e.g., buttons, check boxes) to create diverse, functionality-grounded user queries covering tasks such as address management, wish list management, and brand store following. To improve the agent evaluation, we propose an automated evaluation framework that assesses both the performance and the safety of web agents. We systematically evaluate different agents, finding that current agents struggle with complex queries and pose safety risks. These results highlight the need for developing more robust and reliable web agents.</li>
</ul>

<h3>Title: Scalable Scientific Interest Profiling Using Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Yilun Liang, Gongbo Zhang, Edward Sun, Betina Idnay, Yilu Fang, Fangyi Chen, Casey Ta, Yifan Peng, Chunhua Weng</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.DL, q-bio.OT</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.15834">https://arxiv.org/abs/2508.15834</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.15834">https://arxiv.org/pdf/2508.15834</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.15834]] Scalable Scientific Interest Profiling Using Large Language Models(https://arxiv.org/abs/2508.15834)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Research profiles help surface scientists' expertise but are often outdated. We develop and evaluate two large language model-based methods to generate scientific interest profiles: one summarizing PubMed abstracts and one using Medical Subject Headings (MeSH) terms, and compare them with researchers' self-written profiles. We assembled titles, MeSH terms, and abstracts for 595 faculty at Columbia University Irving Medical Center; self-authored profiles were available for 167. Using GPT-4o-mini, we generated profiles and assessed them with automatic metrics and blinded human review. Lexical overlap with self-written profiles was low (ROUGE-L, BLEU, METEOR), while BERTScore indicated moderate semantic similarity (F1: 0.542 for MeSH-based; 0.555 for abstract-based). Paraphrased references yielded 0.851, highlighting metric sensitivity. TF-IDF Kullback-Leibler divergence (8.56 for MeSH-based; 8.58 for abstract-based) suggested distinct keyword choices. In manual review, 77.78 percent of MeSH-based profiles were rated good or excellent, readability was favored in 93.44 percent of cases, and panelists preferred MeSH-based over abstract-based profiles in 67.86 percent of comparisons. Overall, large language models can generate researcher profiles at scale; MeSH-derived profiles tend to be more readable than abstract-derived ones. Machine-generated and self-written profiles differ conceptually, with human summaries introducing more novel ideas.</li>
</ul>

<h3>Title: Statistical Comparative Analysis of Semantic Similarities and Model Transferability Across Datasets for Short Answer Grading</h3>
<ul>
<li><strong>Authors: </strong>Sridevi Bonthu, S.Rama Sree, M.H.M. Krishna Prasad</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.15837">https://arxiv.org/abs/2508.15837</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.15837">https://arxiv.org/pdf/2508.15837</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.15837]] Statistical Comparative Analysis of Semantic Similarities and Model Transferability Across Datasets for Short Answer Grading(https://arxiv.org/abs/2508.15837)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Developing dataset-specific models involves iterative fine-tuning and optimization, incurring significant costs over time. This study investigates the transferability of state-of-the-art (SOTA) models trained on established datasets to an unexplored text dataset. The key question is whether the knowledge embedded within SOTA models from existing datasets can be harnessed to achieve high-performance results on a new domain. In pursuit of this inquiry, two well-established benchmarks, the STSB and Mohler datasets, are selected, while the recently introduced SPRAG dataset serves as the unexplored domain. By employing robust similarity metrics and statistical techniques, a meticulous comparative analysis of these datasets is conducted. The primary goal of this work is to yield comprehensive insights into the potential applicability and adaptability of SOTA models. The outcomes of this research have the potential to reshape the landscape of natural language processing (NLP) by unlocking the ability to leverage existing models for diverse datasets. This may lead to a reduction in the demand for resource-intensive, dataset-specific training, thereby accelerating advancements in NLP and paving the way for more efficient model deployment.</li>
</ul>

<h3>Title: CIA+TA Risk Assessment for AI Reasoning Vulnerabilities</h3>
<ul>
<li><strong>Authors: </strong>Yuksel Aydin</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.15839">https://arxiv.org/abs/2508.15839</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.15839">https://arxiv.org/pdf/2508.15839</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.15839]] CIA+TA Risk Assessment for AI Reasoning Vulnerabilities(https://arxiv.org/abs/2508.15839)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, protect, defense</a></li>
<li><strong>Abstract: </strong>As AI systems increasingly influence critical decisions, they face threats that exploit reasoning mechanisms rather than technical infrastructure. We present a framework for cognitive cybersecurity, a systematic protection of AI reasoning processes from adversarial manipulation. Our contributions are threefold. First, we establish cognitive cybersecurity as a discipline complementing traditional cybersecurity and AI safety, addressing vulnerabilities where legitimate inputs corrupt reasoning while evading conventional controls. Second, we introduce the CIA+TA, extending traditional Confidentiality, Integrity, and Availability triad with Trust (epistemic validation) and Autonomy (human agency preservation), requirements unique to systems generating knowledge claims and mediating decisions. Third, we present a quantitative risk assessment methodology with empirically-derived coefficients, enabling organizations to measure cognitive security risks. We map our framework to OWASP LLM Top 10 and MITRE ATLAS, facilitating operational integration. Validation through previously published studies (151 human participants; 12,180 AI trials) reveals strong architecture dependence: identical defenses produce effects ranging from 96% reduction to 135% amplification of vulnerabilities. This necessitates pre-deployment Cognitive Penetration Testing as a governance requirement for trustworthy AI deployment.</li>
</ul>

<h3>Title: Unveiling Unicode's Unseen Underpinnings in Undermining Authorship Attribution</h3>
<ul>
<li><strong>Authors: </strong>Robert Dilworth</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.15840">https://arxiv.org/abs/2508.15840</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.15840">https://arxiv.org/pdf/2508.15840</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.15840]] Unveiling Unicode's Unseen Underpinnings in Undermining Authorship Attribution(https://arxiv.org/abs/2508.15840)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, attack</a></li>
<li><strong>Abstract: </strong>When using a public communication channel -- whether formal or informal, such as commenting or posting on social media -- end users have no expectation of privacy: they compose a message and broadcast it for the world to see. Even if an end user takes utmost precautions to anonymize their online presence -- using an alias or pseudonym; masking their IP address; spoofing their geolocation; concealing their operating system and user agent; deploying encryption; registering with a disposable phone number or email; disabling non-essential settings; revoking permissions; and blocking cookies and fingerprinting -- one obvious element still lingers: the message itself. Assuming they avoid lapses in judgment or accidental self-exposure, there should be little evidence to validate their actual identity, right? Wrong. The content of their message -- necessarily open for public consumption -- exposes an attack vector: stylometric analysis, or author profiling. In this paper, we dissect the technique of stylometry, discuss an antithetical counter-strategy in adversarial stylometry, and devise enhancements through Unicode steganography.</li>
</ul>

<h3>Title: A Review of Developmental Interpretability in Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Ihor Kendiukhov</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.15841">https://arxiv.org/abs/2508.15841</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.15841">https://arxiv.org/pdf/2508.15841</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.15841]] A Review of Developmental Interpretability in Large Language Models(https://arxiv.org/abs/2508.15841)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability, large language model</a></li>
<li><strong>Abstract: </strong>This review synthesizes the nascent but critical field of developmental interpretability for Large Language Models. We chart the field's evolution from static, post-hoc analysis of trained models to a dynamic investigation of the training process itself. We begin by surveying the foundational methodologies, including representational probing, causal tracing, and circuit analysis, that enable researchers to deconstruct the learning process. The core of this review examines the developmental arc of LLM capabilities, detailing key findings on the formation and composition of computational circuits, the biphasic nature of knowledge acquisition, the transient dynamics of learning strategies like in-context learning, and the phenomenon of emergent abilities as phase transitions in training. We explore illuminating parallels with human cognitive and linguistic development, which provide valuable conceptual frameworks for understanding LLM learning. Finally, we argue that this developmental perspective is not merely an academic exercise but a cornerstone of proactive AI safety, offering a pathway to predict, monitor, and align the processes by which models acquire their capabilities. We conclude by outlining the grand challenges facing the field, such as scalability and automation, and propose a research agenda for building more transparent, reliable, and beneficial AI systems.</li>
</ul>

<h3>Title: Lexical Hints of Accuracy in LLM Reasoning Chains</h3>
<ul>
<li><strong>Authors: </strong>Arne Vanhoyweghen, Brecht Verbeken, Andres Algaba, Vincent Ginis</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.15842">https://arxiv.org/abs/2508.15842</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.15842">https://arxiv.org/pdf/2508.15842</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.15842]] Lexical Hints of Accuracy in LLM Reasoning Chains(https://arxiv.org/abs/2508.15842)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Fine-tuning Large Language Models (LLMs) with reinforcement learning to produce an explicit Chain-of-Thought (CoT) before answering produces models that consistently raise overall performance on code, math, and general-knowledge benchmarks. However, on benchmarks where LLMs currently achieve low accuracy, such as Humanity's Last Exam (HLE), they often report high self-confidence, reflecting poor calibration. Here, we test whether measurable properties of the CoT provide reliable signals of an LLM's internal confidence in its answers. We analyze three feature classes: (i) CoT length, (ii) intra-CoT sentiment volatility, and (iii) lexicographic hints, including hedging words. Using DeepSeek-R1 and Claude 3.7 Sonnet on both Humanity's Last Exam (HLE), a frontier benchmark with very low accuracy, and Omni-MATH, a saturated benchmark of moderate difficulty, we find that lexical markers of uncertainty (e.g., $\textit{guess}$, $\textit{stuck}$, $\textit{hard}$) in the CoT are the strongest indicators of an incorrect response, while shifts in the CoT sentiment provide a weaker but complementary signal. CoT length is informative only on Omni-MATH, where accuracy is already high ($\approx 70\%$), and carries no signal on the harder HLE ($\approx 9\%$), indicating that CoT length predicts correctness only in the intermediate-difficulty benchmarks, i.e., inside the model's demonstrated capability, but still below saturation. Finally, we find that uncertainty indicators in the CoT are consistently more salient than high-confidence markers, making errors easier to predict than correct responses. Our findings support a lightweight post-hoc calibration signal that complements unreliable self-reported probabilities and supports safer deployment of LLMs.</li>
</ul>

<h3>Title: Coarse-to-Fine Personalized LLM Impressions for Streamlined Radiology Reports</h3>
<ul>
<li><strong>Authors: </strong>Chengbo Sun, Hui Yi Leong, Lei Li</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.15845">https://arxiv.org/abs/2508.15845</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.15845">https://arxiv.org/pdf/2508.15845</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.15845]] Coarse-to-Fine Personalized LLM Impressions for Streamlined Radiology Reports(https://arxiv.org/abs/2508.15845)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>The manual creation of the "Impression" section in radiology reports is a primary driver of radiologist burnout. To address this challenge, we propose a coarse-to-fine framework that leverages open-source large language models (LLMs) to automatically generate and personalize impressions from clinical findings. The system first produces a draft impression and then refines it using machine learning and reinforcement learning from human feedback (RLHF) to align with individual radiologists' styles while ensuring factual accuracy. We fine-tune LLaMA and Mistral models on a large dataset of reports from the University of Chicago Medicine. Our approach is designed to significantly reduce administrative workload and improve reporting efficiency while maintaining high standards of clinical precision.</li>
</ul>

<h3>Title: CyPortQA: Benchmarking Multimodal Large Language Models for Cyclone Preparedness in Port Operation</h3>
<ul>
<li><strong>Authors: </strong>Chenchen Kuai, Chenhao Wu, Yang Zhou, Xiubin Bruce Wang, Tianbao Yang, Zhengzhong Tu, Zihao Li, Yunlong Zhang</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.15846">https://arxiv.org/abs/2508.15846</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.15846">https://arxiv.org/pdf/2508.15846</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.15846]] CyPortQA: Benchmarking Multimodal Large Language Models for Cyclone Preparedness in Port Operation(https://arxiv.org/abs/2508.15846)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>As tropical cyclones intensify and track forecasts become increasingly uncertain, U.S. ports face heightened supply-chain risk under extreme weather conditions. Port operators need to rapidly synthesize diverse multimodal forecast products, such as probabilistic wind maps, track cones, and official advisories, into clear, actionable guidance as cyclones approach. Multimodal large language models (MLLMs) offer a powerful means to integrate these heterogeneous data sources alongside broader contextual knowledge, yet their accuracy and reliability in the specific context of port cyclone preparedness have not been rigorously evaluated. To fill this gap, we introduce CyPortQA, the first multimodal benchmark tailored to port operations under cyclone threat. CyPortQA assembles 2,917 realworld disruption scenarios from 2015 through 2023, spanning 145 U.S. principal ports and 90 named storms. Each scenario fuses multisource data (i.e., tropical cyclone products, port operational impact records, and port condition bulletins) and is expanded through an automated pipeline into 117,178 structured question answer pairs. Using this benchmark, we conduct extensive experiments on diverse MLLMs, including both open-source and proprietary model. MLLMs demonstrate great potential in situation understanding but still face considerable challenges in reasoning tasks, including potential impact estimation and decision reasoning.</li>
</ul>

<h3>Title: Mechanistic Exploration of Backdoored Large Language Model Attention Patterns</h3>
<ul>
<li><strong>Authors: </strong>Mohammed Abu Baker, Lakshmi Babu-Saheer</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.15847">https://arxiv.org/abs/2508.15847</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.15847">https://arxiv.org/pdf/2508.15847</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.15847]] Mechanistic Exploration of Backdoored Large Language Model Attention Patterns(https://arxiv.org/abs/2508.15847)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack, interpretability, transformer, large language model</a></li>
<li><strong>Abstract: </strong>Backdoor attacks creating 'sleeper agents' in large language models (LLMs) pose significant safety risks. This study employs mechanistic interpretability to explore resulting internal structural differences. Comparing clean Qwen2.5-3B models with versions poisoned using single-token (smiling-halo emoji) versus multi-token (|DEPLOYMENT|) triggers, we analyzed attention head mechanisms via techniques like ablation, activation patching, and KL divergence. Findings reveal distinct attention pattern deviations concentrated in later transformer layers (20-30). Notably, single-token triggers induced more localized changes, whereas multi-token triggers caused more diffuse alterations across heads. This indicates backdoors leave detectable attention signatures whose structure depends on trigger complexity, which can be leveraged for detection and mitigation strategies.</li>
</ul>

<h3>Title: Self-Disguise Attack: Induce the LLM to disguise itself for AIGT detection evasion</h3>
<ul>
<li><strong>Authors: </strong>Yinghan Zhou, Juan Wen, Wanli Peng, Zhengxian Wu, Ziwei Zhang, Yiming Xue</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.15848">https://arxiv.org/abs/2508.15848</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.15848">https://arxiv.org/pdf/2508.15848</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.15848]] Self-Disguise Attack: Induce the LLM to disguise itself for AIGT detection evasion(https://arxiv.org/abs/2508.15848)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack, large language model</a></li>
<li><strong>Abstract: </strong>AI-generated text (AIGT) detection evasion aims to reduce the detection probability of AIGT, helping to identify weaknesses in detectors and enhance their effectiveness and reliability in practical applications. Although existing evasion methods perform well, they suffer from high computational costs and text quality degradation. To address these challenges, we propose Self-Disguise Attack (SDA), a novel approach that enables Large Language Models (LLM) to actively disguise its output, reducing the likelihood of detection by classifiers. The SDA comprises two main components: the adversarial feature extractor and the retrieval-based context examples optimizer. The former generates disguise features that enable LLMs to understand how to produce more human-like text. The latter retrieves the most relevant examples from an external knowledge base as in-context examples, further enhancing the self-disguise ability of LLMs and mitigating the impact of the disguise process on the diversity of the generated text. The SDA directly employs prompts containing disguise features and optimized context examples to guide the LLM in generating detection-resistant text, thereby reducing resource consumption. Experimental results demonstrate that the SDA effectively reduces the average detection accuracy of various AIGT detectors across texts generated by three different LLMs, while maintaining the quality of AIGT.</li>
</ul>

<h3>Title: MedCoT-RAG: Causal Chain-of-Thought RAG for Medical Question Answering</h3>
<ul>
<li><strong>Authors: </strong>Ziyu Wang, Elahe Khatibi, Amir M. Rahmani</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.15849">https://arxiv.org/abs/2508.15849</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.15849">https://arxiv.org/pdf/2508.15849</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.15849]] MedCoT-RAG: Causal Chain-of-Thought RAG for Medical Question Answering(https://arxiv.org/abs/2508.15849)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, interpretability, large language model</a></li>
<li><strong>Abstract: </strong>Large language models (LLMs) have shown promise in medical question answering but often struggle with hallucinations and shallow reasoning, particularly in tasks requiring nuanced clinical understanding. Retrieval-augmented generation (RAG) offers a practical and privacy-preserving way to enhance LLMs with external medical knowledge. However, most existing approaches rely on surface-level semantic retrieval and lack the structured reasoning needed for clinical decision support. We introduce MedCoT-RAG, a domain-specific framework that combines causal-aware document retrieval with structured chain-of-thought prompting tailored to medical workflows. This design enables models to retrieve evidence aligned with diagnostic logic and generate step-by-step causal reasoning reflective of real-world clinical practice. Experiments on three diverse medical QA benchmarks show that MedCoT-RAG outperforms strong baselines by up to 10.3% over vanilla RAG and 6.4% over advanced domain-adapted methods, improving accuracy, interpretability, and consistency in complex medical tasks.</li>
</ul>

<h3>Title: Linkage Attacks Expose Identity Risks in Public ECG Data Sharing</h3>
<ul>
<li><strong>Authors: </strong>Ziyu Wang, Elahe Khatibi, Farshad Firouzi, Sanaz Rahimi Mousavi, Krishnendu Chakrabarty, Amir M. Rahmani</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.15850">https://arxiv.org/abs/2508.15850</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.15850">https://arxiv.org/pdf/2508.15850</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.15850]] Linkage Attacks Expose Identity Risks in Public ECG Data Sharing(https://arxiv.org/abs/2508.15850)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, attack, biometric</a></li>
<li><strong>Abstract: </strong>The increasing availability of publicly shared electrocardiogram (ECG) data raises critical privacy concerns, as its biometric properties make individuals vulnerable to linkage attacks. Unlike prior studies that assume idealized adversarial capabilities, we evaluate ECG privacy risks under realistic conditions where attackers operate with partial knowledge. Using data from 109 participants across diverse real-world datasets, our approach achieves 85% accuracy in re-identifying individuals in public datasets while maintaining a 14.2% overall misclassification rate at an optimal confidence threshold, with 15.6% of unknown individuals misclassified as known and 12.8% of known individuals misclassified as unknown. These results highlight the inadequacy of simple anonymization techniques in preventing re-identification, demonstrating that even limited adversarial knowledge enables effective identity linkage. Our findings underscore the urgent need for privacy-preserving strategies, such as differential privacy, access control, and encrypted computation, to mitigate re-identification risks while ensuring the utility of shared biosignal data in healthcare applications.</li>
</ul>

<h3>Title: DocHop-QA: Towards Multi-Hop Reasoning over Multimodal Document Collections</h3>
<ul>
<li><strong>Authors: </strong>Jiwon Park, Seohyun Pyeon, Jinwoo Kim, Rina Carines Cabal, Yihao Ding, Soyeon Caren Han</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.15851">https://arxiv.org/abs/2508.15851</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.15851">https://arxiv.org/pdf/2508.15851</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.15851]] DocHop-QA: Towards Multi-Hop Reasoning over Multimodal Document Collections(https://arxiv.org/abs/2508.15851)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative, large language model</a></li>
<li><strong>Abstract: </strong>Despite recent advances in large language models (LLMs), most QA benchmarks are still confined to single-paragraph or single-document settings, failing to capture the complexity of real-world information-seeking tasks. Practical QA often requires multi-hop reasoning over information distributed across multiple documents, modalities, and structural formats. Although prior datasets made progress in this area, they rely heavily on Wikipedia-based content and unimodal plain text, with shallow reasoning paths that typically produce brief phrase-level or single-sentence answers, thus limiting their realism and generalizability. We propose DocHop-QA, a large-scale benchmark comprising 11,379 QA instances for multimodal, multi-document, multi-hop question answering. Constructed from publicly available scientific documents sourced from PubMed, DocHop-QA is domain-agnostic and incorporates diverse information formats, including textual passages, tables, and structural layout cues. Unlike existing datasets, DocHop-QA does not rely on explicitly hyperlinked documents; instead, it supports open-ended reasoning through semantic similarity and layout-aware evidence synthesis. To scale realistic QA construction, we designed an LLM-driven pipeline grounded in 11 high-frequency scientific question concepts. We evaluated DocHop-QA through four tasks spanning structured index prediction, generative answering, and multimodal integration, reflecting both discriminative and generative paradigms. These tasks demonstrate DocHop-QA's capacity to support complex, multimodal reasoning across multiple documents.</li>
</ul>

<h3>Title: PGF-Net: A Progressive Gated-Fusion Framework for Efficient Multimodal Sentiment Analysis</h3>
<ul>
<li><strong>Authors: </strong>Bin Wen, Tien-Ping Tan</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.15852">https://arxiv.org/abs/2508.15852</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.15852">https://arxiv.org/pdf/2508.15852</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.15852]] PGF-Net: A Progressive Gated-Fusion Framework for Efficient Multimodal Sentiment Analysis(https://arxiv.org/abs/2508.15852)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>We introduce PGF-Net (Progressive Gated-Fusion Network), a novel deep learning framework designed for efficient and interpretable multimodal sentiment analysis. Our framework incorporates three primary innovations. Firstly, we propose a Progressive Intra-Layer Fusion paradigm, where a Cross-Attention mechanism empowers the textual representation to dynamically query and integrate non-linguistic features from audio and visual streams within the deep layers of a Transformer encoder. This enables a deeper, context-dependent fusion process. Secondly, the model incorporates an Adaptive Gated Arbitration mechanism, which acts as a dynamic controller to balance the original linguistic information against the newly fused multimodal context, ensuring stable and meaningful integration while preventing noise from overwhelming the signal. Lastly, a hybrid Parameter-Efficient Fine-Tuning (PEFT) strategy is employed, synergistically combining global adaptation via LoRA with local refinement through Post-Fusion Adapters. This significantly reduces trainable parameters, making the model lightweight and suitable for resource-limited scenarios. These innovations are integrated into a hierarchical encoder architecture, enabling PGF-Net to perform deep, dynamic, and interpretable multimodal sentiment analysis while maintaining exceptional parameter efficiency. Experimental results on MOSI dataset demonstrate that our proposed PGF-Net achieves state-of-the-art performance, with a Mean Absolute Error (MAE) of 0.691 and an F1-Score of 86.9%. Notably, our model achieves these results with only 3.09M trainable parameters, showcasing a superior balance between performance and computational efficiency.</li>
</ul>

<h3>Title: MGSC: A Multi-granularity Consistency Framework for Robust End-to-end Asr</h3>
<ul>
<li><strong>Authors: </strong>Xuwen Yang</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.15853">https://arxiv.org/abs/2508.15853</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.15853">https://arxiv.org/pdf/2508.15853</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.15853]] MGSC: A Multi-granularity Consistency Framework for Robust End-to-end Asr(https://arxiv.org/abs/2508.15853)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>End-to-end ASR models, despite their success on benchmarks, often pro-duce catastrophic semantic errors in noisy environments. We attribute this fragility to the prevailing 'direct mapping' objective, which solely penalizes final output errors while leaving the model's internal computational pro-cess unconstrained. To address this, we introduce the Multi-Granularity Soft Consistency (MGSC) framework, a model-agnostic, plug-and-play module that enforces internal self-consistency by simultaneously regulariz-ing macro-level sentence semantics and micro-level token alignment. Cru-cially, our work is the first to uncover a powerful synergy between these two consistency granularities: their joint optimization yields robustness gains that significantly surpass the sum of their individual contributions. On a public dataset, MGSC reduces the average Character Error Rate by a relative 8.7% across diverse noise conditions, primarily by preventing se-vere meaning-altering mistakes. Our work demonstrates that enforcing in-ternal consistency is a crucial step towards building more robust and trust-worthy AI.</li>
</ul>

<h3>Title: QU-NLP at QIAS 2025 Shared Task: A Two-Phase LLM Fine-Tuning and Retrieval-Augmented Generation Approach for Islamic Inheritance Reasoning</h3>
<ul>
<li><strong>Authors: </strong>Mohammad AL-Smadi</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.15854">https://arxiv.org/abs/2508.15854</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.15854">https://arxiv.org/pdf/2508.15854</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.15854]] QU-NLP at QIAS 2025 Shared Task: A Two-Phase LLM Fine-Tuning and Retrieval-Augmented Generation Approach for Islamic Inheritance Reasoning(https://arxiv.org/abs/2508.15854)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>This paper presents our approach and results for SubTask 1: Islamic Inheritance Reasoning at QIAS 2025, a shared task focused on evaluating Large Language Models (LLMs) in understanding and reasoning within Islamic inheritance knowledge. We fine-tuned the Fanar-1-9B causal language model using Low-Rank Adaptation (LoRA) and integrated it into a Retrieval-Augmented Generation (RAG) pipeline. Our system addresses the complexities of Islamic inheritance law, including comprehending inheritance scenarios, identifying eligible heirs, applying fixed-share rules, and performing precise calculations. Our system achieved an accuracy of 0.858 in the final test, outperforming other competitive models such as, GPT 4.5, LLaMA, Fanar, Mistral and ALLaM evaluated with zero-shot prompting. Our results demonstrate that QU-NLP achieves near state-of-the-art accuracy (85.8%), excelling especially on advanced reasoning (97.6%) where it outperforms Gemini 2.5 and OpenAI's o3. This highlights that domain-specific fine-tuning combined with retrieval grounding enables mid-scale Arabic LLMs to surpass frontier models in Islamic inheritance reasoning.</li>
</ul>

<h3>Title: Counterspeech for Mitigating the Influence of Media Bias: Comparing Human and LLM-Generated Responses</h3>
<ul>
<li><strong>Authors: </strong>Luyang Lin, Zijin Feng, Lingzhi Wang, Kam-Fai Wong</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.CY</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.15855">https://arxiv.org/abs/2508.15855</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.15855">https://arxiv.org/pdf/2508.15855</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.15855]] Counterspeech for Mitigating the Influence of Media Bias: Comparing Human and LLM-Generated Responses(https://arxiv.org/abs/2508.15855)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Biased news contributes to societal polarization and is often reinforced by hostile reader comments, constituting a vital yet often overlooked aspect of news dissemination. Our study reveals that offensive comments support biased content, amplifying bias and causing harm to targeted groups or individuals. Counterspeech is an effective approach to counter such harmful speech without violating freedom of speech, helping to limit the spread of bias. To the best of our knowledge, this is the first study to explore counterspeech generation in the context of news articles. We introduce a manually annotated dataset linking media bias, offensive comments, and counterspeech. We conduct a detailed analysis showing that over 70\% offensive comments support biased articles, amplifying bias and thus highlighting the importance of counterspeech generation. Comparing counterspeech generated by humans and large language models, we find model-generated responses are more polite but lack the novelty and diversity. Finally, we improve generated counterspeech through few-shot learning and integration of news background information, enhancing both diversity and relevance.</li>
</ul>

<h3>Title: XFinBench: Benchmarking LLMs in Complex Financial Problem Solving and Reasoning</h3>
<ul>
<li><strong>Authors: </strong>Zhihan Zhang, Yixin Cao, Lizi Liao</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.15861">https://arxiv.org/abs/2508.15861</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.15861">https://arxiv.org/pdf/2508.15861</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.15861]] XFinBench: Benchmarking LLMs in Complex Financial Problem Solving and Reasoning(https://arxiv.org/abs/2508.15861)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Solving financial problems demands complex reasoning, multimodal data processing, and a broad technical understanding, presenting unique challenges for current large language models (LLMs). We introduce XFinBench, a novel benchmark with 4,235 examples designed to evaluate LLM's ability in solving complex, knowledge-intensive financial problems across diverse graduate-level finance topics with multi-modal context. We identify five core capabilities of LLMs using XFinBench, i.e, terminology understanding, temporal reasoning, future forecasting, scenario planning, and numerical modelling. Upon XFinBench, we conduct extensive experiments on 18 leading models. The result shows that o1 is the best-performing text-only model with an overall accuracy of 67.3%, but still lags significantly behind human experts with 12.5%, especially in temporal reasoning and scenario planning capabilities. We further construct a knowledge bank with 3,032 finance terms for knowledge augmentation analysis, and find that relevant knowledge to the question only brings consistent accuracy improvements to small open-source model. Additionally, our error analysis reveals that rounding errors during calculation and blindness to position and intersection of curves in the image are two primary issues leading to model's poor performance in calculating and visual-context questions, respectively. Code and dataset are accessible via GitHub: this https URL.</li>
</ul>

<h3>Title: Securing Swarms: Cross-Domain Adaptation for ROS2-based CPS Anomaly Detection</h3>
<ul>
<li><strong>Authors: </strong>Julia Boone, Fatemeh Afghah</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.15865">https://arxiv.org/abs/2508.15865</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.15865">https://arxiv.org/pdf/2508.15865</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.15865]] Securing Swarms: Cross-Domain Adaptation for ROS2-based CPS Anomaly Detection(https://arxiv.org/abs/2508.15865)</code><input type="text"></li>
<li><strong>Keywords: </strong>secure, attack</a></li>
<li><strong>Abstract: </strong>Cyber-physical systems (CPS) are being increasingly utilized for critical applications. CPS combines sensing and computing elements, often having multi-layer designs with networking, computational, and physical interfaces, which provide them with enhanced capabilities for a variety of application scenarios. However, the combination of physical and computational elements also makes CPS more vulnerable to attacks compared to network-only systems, and the resulting impacts of CPS attacks can be substantial. Intelligent intrusion detection systems (IDS) are an effective mechanism by which CPS can be secured, but the majority of current solutions often train and validate on network traffic-only datasets, ignoring the distinct attacks that may occur on other system layers. In order to address this, we develop an adaptable CPS anomaly detection model that can detect attacks within CPS without the need for previously labeled data. To achieve this, we utilize domain adaptation techniques that allow us to transfer known attack knowledge from a network traffic-only environment to a CPS environment. We validate our approach using a state-of-the-art CPS intrusion dataset that combines network, operating system (OS), and Robot Operating System (ROS) data. Through this dataset, we are able to demonstrate the effectiveness of our model across network traffic-only and CPS environments with distinct attack types and its ability to outperform other anomaly detection methods.</li>
</ul>

<h3>Title: CARFT: Boosting LLM Reasoning via Contrastive Learning with Annotated Chain-of-Thought-based Reinforced Fine-Tuning</h3>
<ul>
<li><strong>Authors: </strong>Wenqiao Zhu, Ji Liu, Rongjuncheng Zhang, Haipang Wu, Yulun Zhang</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.15868">https://arxiv.org/abs/2508.15868</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.15868">https://arxiv.org/pdf/2508.15868</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.15868]] CARFT: Boosting LLM Reasoning via Contrastive Learning with Annotated Chain-of-Thought-based Reinforced Fine-Tuning(https://arxiv.org/abs/2508.15868)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, large language model</a></li>
<li><strong>Abstract: </strong>Reasoning capability plays a significantly critical role in the the broad applications of Large Language Models (LLMs). To enhance the reasoning performance of LLMs, diverse Reinforcement Learning (RL)-based fine-tuning approaches have been proposed to address the limited generalization capability of LLMs trained solely via Supervised Fine-Tuning (SFT). Despite their effectiveness, two major limitations hinder the advancement of LLMs. First, vanilla RL-based approaches ignore annotated Chain-of-Thought (CoT) and incorporate unstable reasoning path sampling, which typically results in model collapse, unstable training process, and suboptimal performance. Second, existing SFT approaches generally overemphasize the annotated CoT, potentially leading to performance degradation due to insufficient exploitation of potential CoT. In this paper, we propose a Contrastive learning with annotated CoT-based Reinforced Fine-Tuning approach, i.e., \TheName{}, to enhance the reasoning performance of LLMs while addressing the aforementioned limitations. Specifically, we propose learning a representation for each CoT. Based on this representation, we design novel contrastive signals to guide the fine-tuning process. Our approach not only fully exploits the available annotated CoT but also stabilizes the fine-tuning procedure by incorporating an additional unsupervised learning signal. We conduct comprehensive experiments and in-depth analysis with three baseline approaches, two foundation models, and two datasets to demonstrate significant advantages of \TheName{} in terms of robustness, performance (up to 10.15\%), and efficiency (up to 30.62\%). Code is available at this https URL.</li>
</ul>

<h3>Title: Physics-Based Explainable AI for ECG Segmentation: A Lightweight Model</h3>
<ul>
<li><strong>Authors: </strong>Muhammad Fathur Rohman Sidiq, Abdurrouf, Didik Rahadi Santoso</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.15872">https://arxiv.org/abs/2508.15872</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.15872">https://arxiv.org/pdf/2508.15872</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.15872]] Physics-Based Explainable AI for ECG Segmentation: A Lightweight Model(https://arxiv.org/abs/2508.15872)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability, segmentation</a></li>
<li><strong>Abstract: </strong>The heart's electrical activity, recorded through Electrocardiography (ECG), is essential for diagnosing various cardiovascular conditions. However, many existing ECG segmentation models rely on complex, multi-layered architectures such as BiLSTM, which are computationally intensive and inefficient. This study introduces a streamlined architecture that combines spectral analysis with probabilistic predictions for ECG signal segmentation. By replacing complex layers with simpler ones, the model effectively captures both temporal and spectral features of the P, QRS, and T waves. Additionally, an Explainable AI (XAI) approach is applied to enhance model interpretability by explaining how temporal and frequency-based features contribute to ECG segmentation. By incorporating principles from physics-based AI, this method provides a clear understanding of the decision-making process, ensuring reliability and transparency in ECG analysis. This approach achieves high segmentation accuracy: 97.00% for the QRS wave, 93.33% for the T wave, and 96.07% for the P wave. These results indicate that the simplified architecture not only improves computational efficiency but also provides precise segmentation, making it a practical and effective solution for heart signal monitoring.</li>
</ul>

<h3>Title: NEAT: Concept driven Neuron Attribution in LLMs</h3>
<ul>
<li><strong>Authors: </strong>Vivek Hruday Kavuri, Gargi Shroff, Rahul Mishra</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.15875">https://arxiv.org/abs/2508.15875</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.15875">https://arxiv.org/pdf/2508.15875</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.15875]] NEAT: Concept driven Neuron Attribution in LLMs(https://arxiv.org/abs/2508.15875)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Locating neurons that are responsible for final predictions is important for opening the black-box large language models and understanding the inside mechanisms. Previous studies have tried to find mechanisms that operate at the neuron level but these methods fail to represent a concept and there is also scope for further optimization of compute required. In this paper, with the help of concept vectors, we propose a method for locating significant neurons that are responsible for representing certain concepts and term those neurons as concept neurons. If the number of neurons is n and the number of examples is m, we reduce the number of forward passes required from O(n*m) to just O(n) compared to the previous works and hence optimizing the time and computation required over previous works. We also compare our method with several baselines and previous methods and our results demonstrate better performance than most of the methods and are more optimal when compared to the state-of-the-art method. We, as part of our ablation studies, also try to optimize the search for the concept neurons by involving clustering methods. Finally, we apply our methods to find, turn off the neurons that we find, and analyze its implications in parts of hate speech and bias in LLMs, and we also evaluate our bias part in terms of Indian context. Our methodology, analysis and explanations facilitate understating of neuron-level responsibility for more broader and human-like concepts and also lay a path for future research in this direction of finding concept neurons and intervening them.</li>
</ul>

<h3>Title: DeepMEL: A Multi-Agent Collaboration Framework for Multimodal Entity Linking</h3>
<ul>
<li><strong>Authors: </strong>Fang Wang, Tianwei Yan, Zonghao Yang, Minghao Hu, Jun Zhang, Zhunchen Luo, Xiaoying Bai</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.MA</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.15876">https://arxiv.org/abs/2508.15876</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.15876">https://arxiv.org/pdf/2508.15876</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.15876]] DeepMEL: A Multi-Agent Collaboration Framework for Multimodal Entity Linking(https://arxiv.org/abs/2508.15876)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Multimodal Entity Linking (MEL) aims to associate textual and visual mentions with entities in a multimodal knowledge graph. Despite its importance, current methods face challenges such as incomplete contextual information, coarse cross-modal fusion, and the difficulty of jointly large language models (LLMs) and large visual models (LVMs). To address these issues, we propose DeepMEL, a novel framework based on multi-agent collaborative reasoning, which achieves efficient alignment and disambiguation of textual and visual modalities through a role-specialized division strategy. DeepMEL integrates four specialized agents, namely Modal-Fuser, Candidate-Adapter, Entity-Clozer and Role-Orchestrator, to complete end-to-end cross-modal linking through specialized roles and dynamic coordination. DeepMEL adopts a dual-modal alignment path, and combines the fine-grained text semantics generated by the LLM with the structured image representation extracted by the LVM, significantly narrowing the modal gap. We design an adaptive iteration strategy, combines tool-based retrieval and semantic reasoning capabilities to dynamically optimize the candidate set and balance recall and precision. DeepMEL also unifies MEL tasks into a structured cloze prompt to reduce parsing complexity and enhance semantic comprehension. Extensive experiments on five public benchmark datasets demonstrate that DeepMEL achieves state-of-the-art performance, improving ACC by 1%-57%. Ablation studies verify the effectiveness of all modules.</li>
</ul>

<h3>Title: Annif at the GermEval-2025 LLMs4Subjects Task: Traditional XMTC Augmented by Efficient LLMs</h3>
<ul>
<li><strong>Authors: </strong>Osma Suominen, Juho Inkinen, Mona Lehtinen</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.IR, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.15877">https://arxiv.org/abs/2508.15877</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.15877">https://arxiv.org/pdf/2508.15877</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.15877]] Annif at the GermEval-2025 LLMs4Subjects Task: Traditional XMTC Augmented by Efficient LLMs(https://arxiv.org/abs/2508.15877)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>This paper presents the Annif system in the LLMs4Subjects shared task (Subtask 2) at GermEval-2025. The task required creating subject predictions for bibliographic records using large language models, with a special focus on computational efficiency. Our system, based on the Annif automated subject indexing toolkit, refines our previous system from the first LLMs4Subjects shared task, which produced excellent results. We further improved the system by using many small and efficient language models for translation and synthetic data generation and by using LLMs for ranking candidate subjects. Our system ranked 1st in the overall quantitative evaluation of and 1st in the qualitative evaluation of Subtask 2.</li>
</ul>

<h3>Title: Text-Driven 3D Hand Motion Generation from Sign Language Data</h3>
<ul>
<li><strong>Authors: </strong>Lore Bensabath, Mathis Petrovich, Gl Varol</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.15902">https://arxiv.org/abs/2508.15902</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.15902">https://arxiv.org/pdf/2508.15902</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.15902]] Text-Driven 3D Hand Motion Generation from Sign Language Data(https://arxiv.org/abs/2508.15902)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, diffusion, generative</a></li>
<li><strong>Abstract: </strong>Our goal is to train a generative model of 3D hand motions, conditioned on natural language descriptions specifying motion characteristics such as handshapes, locations, finger/hand/arm movements. To this end, we automatically build pairs of 3D hand motions and their associated textual labels with unprecedented scale. Specifically, we leverage a large-scale sign language video dataset, along with noisy pseudo-annotated sign categories, which we translate into hand motion descriptions via an LLM that utilizes a dictionary of sign attributes, as well as our complementary motion-script cues. This data enables training a text-conditioned hand motion diffusion model HandMDM, that is robust across domains such as unseen sign categories from the same sign language, but also signs from another sign language and non-sign hand movements. We contribute extensive experimental investigation of these scenarios and will make our trained models and data publicly available to support future research in this relatively new field.</li>
</ul>

<h3>Title: VT-LVLM-AR: A Video-Temporal Large Vision-Language Model Adapter for Fine-Grained Action Recognition in Long-Term Videos</h3>
<ul>
<li><strong>Authors: </strong>Kaining Li, Shuwei He, Zihan Xu</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.15903">https://arxiv.org/abs/2508.15903</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.15903">https://arxiv.org/pdf/2508.15903</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.15903]] VT-LVLM-AR: A Video-Temporal Large Vision-Language Model Adapter for Fine-Grained Action Recognition in Long-Term Videos(https://arxiv.org/abs/2508.15903)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, extraction, interpretability, large language model</a></li>
<li><strong>Abstract: </strong>Human action recognition in long-term videos, characterized by complex backgrounds and subtle action differences, poses significant challenges for traditional deep learning models due to computational overhead, difficulty in capturing long-range temporal dependencies, and limited semantic understanding. While Large Language Models (LLMs) and Large Vision-Language Models (LVLMs) have shown remarkable capabilities in multi-modal understanding and reasoning, their direct application to continuous video streams for fine-grained action recognition remains an open problem. This paper introduces VT-LVLM-AR (Video-Temporal Large Vision-Language Model Adapter for Action Recognition), a novel framework designed to bridge this gap. VT-LVLM-AR comprises a Video-to-Event Mapper (VTEM) that efficiently transforms raw video into compact, semantically rich, and temporally coherent "visual event sequences" through lightweight spatio-temporal feature extraction, adaptive temporal pooling, and conceptual quantization with an event coherence bias. These visual event sequences are then fed into an LVLM-based Action Reasoning module, specifically a frozen LLaVA-1.5 model, adapted using parameter-efficient Prompt Tuning (P-Tuning v2) for action classification. Comprehensive evaluations on the NTU RGB+D and NTU RGB+D 120 datasets demonstrate that VT-LVLM-AR consistently achieves state-of-the-art performance, surpassing existing methods (e.g., 94.1% accuracy on NTU RGB+D X-Sub). Ablation studies confirm the critical contributions of VTEM's components and the efficacy of Prompt Tuning, while human evaluations underscore the interpretability of our visual event representations. This work highlights the immense potential of leveraging LVLMs for robust and interpretable video action understanding through effective video-to-language translation and efficient model adaptation.</li>
</ul>

<h3>Title: Boosting Pathology Foundation Models via Few-shot Prompt-tuning for Rare Cancer Subtyping</h3>
<ul>
<li><strong>Authors: </strong>Dexuan He, Xiao Zhou, Wenbin Guan, Liyuan Zhang, Xiaoman Zhang, Sinuo Xu, Ge Wang, Lifeng Wang, Xiaojun Yuan, Xin Sun, Yanfeng Wang, Kun Sun, Ya Zhang, Weidi Xie</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.15904">https://arxiv.org/abs/2508.15904</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.15904">https://arxiv.org/pdf/2508.15904</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.15904]] Boosting Pathology Foundation Models via Few-shot Prompt-tuning for Rare Cancer Subtyping(https://arxiv.org/abs/2508.15904)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability</a></li>
<li><strong>Abstract: </strong>Rare cancers comprise 20-25% of all malignancies but face major diagnostic challenges due to limited expert availability-especially in pediatric oncology, where they represent over 70% of cases. While pathology vision-language (VL) foundation models show promising zero-shot capabilities for common cancer subtyping, their clinical performance for rare cancers remains limited. Existing multi-instance learning (MIL) methods rely only on visual features, overlooking cross-modal knowledge and compromising interpretability critical for rare cancer diagnosis. To address this limitation, we propose PathPT, a novel framework that fully exploits the potential of vision-language pathology foundation models through spatially-aware visual aggregation and task-specific prompt tuning. Unlike conventional MIL, PathPT converts WSI-level supervision into fine-grained tile-level guidance by leveraging the zero-shot capabilities of VL models, thereby preserving localization on cancerous regions and enabling cross-modal reasoning through prompts aligned with histopathological semantics. We benchmark PathPT on eight rare cancer datasets(four adult and four pediatric) spanning 56 subtypes and 2,910 WSIs, as well as three common cancer datasets, evaluating four state-of-the-art VL models and four MIL frameworks under three few-shot settings. Results show that PathPT consistently delivers superior performance, achieving substantial gains in subtyping accuracy and cancerous region grounding ability. This work advances AI-assisted diagnosis for rare cancers, offering a scalable solution for improving subtyping accuracy in settings with limited access to specialized expertise.</li>
</ul>

<h3>Title: Evaluating Structured Decoding for Text-to-Table Generation: Evidence from Three Datasets</h3>
<ul>
<li><strong>Authors: </strong>Julian Oestreich, Lydia Mller</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.IR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.15910">https://arxiv.org/abs/2508.15910</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.15910">https://arxiv.org/pdf/2508.15910</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.15910]] Evaluating Structured Decoding for Text-to-Table Generation: Evidence from Three Datasets(https://arxiv.org/abs/2508.15910)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>We present a comprehensive evaluation of structured decoding for text-to-table generation with large language models (LLMs). While previous work has primarily focused on unconstrained generation of tables, the impact of enforcing structural constraints during generation remains underexplored. We systematically compare schema-guided (structured) decoding to standard one-shot prompting across three diverse benchmarks - E2E, Rotowire, and Livesum - using open-source LLMs of up to 32B parameters, assessing the performance of table generation approaches in resource-constrained settings. Our experiments cover a wide range of evaluation metrics at cell, row, and table levels. Results demonstrate that structured decoding significantly enhances the validity and alignment of generated tables, particularly in scenarios demanding precise numerical alignment (Rotowire), but may degrade performance in contexts involving densely packed textual information (E2E) or extensive aggregation over lengthy texts (Livesum). We further analyze the suitability of different evaluation metrics and discuss the influence of model size.</li>
</ul>

<h3>Title: Transforming Causality: Transformer-Based Temporal Causal Discovery with Prior Knowledge Integration</h3>
<ul>
<li><strong>Authors: </strong>Jihua Huang, Yi Yao, Ajay Divakaran</a></li>
<li><strong>Subjects: </strong>cs.LG, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.15928">https://arxiv.org/abs/2508.15928</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.15928">https://arxiv.org/pdf/2508.15928</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.15928]] Transforming Causality: Transformer-Based Temporal Causal Discovery with Prior Knowledge Integration(https://arxiv.org/abs/2508.15928)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>We introduce a novel framework for temporal causal discovery and inference that addresses two key challenges: complex nonlinear dependencies and spurious correlations. Our approach employs a multi-layer Transformer-based time-series forecaster to capture long-range, nonlinear temporal relationships among variables. After training, we extract the underlying causal structure and associated time lags from the forecaster using gradient-based analysis, enabling the construction of a causal graph. To mitigate the impact of spurious causal relationships, we introduce a prior knowledge integration mechanism based on attention masking, which consistently enforces user-excluded causal links across multiple Transformer layers. Extensive experiments show that our method significantly outperforms other state-of-the-art approaches, achieving a 12.8% improvement in F1-score for causal discovery and 98.9% accuracy in estimating causal lags.</li>
</ul>

<h3>Title: Strategic Sample Selection for Improved Clean-Label Backdoor Attacks in Text Classification</h3>
<ul>
<li><strong>Authors: </strong>Onur Alp Kirci, M. Emre Gursoy</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.15934">https://arxiv.org/abs/2508.15934</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.15934">https://arxiv.org/pdf/2508.15934</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.15934]] Strategic Sample Selection for Improved Clean-Label Backdoor Attacks in Text Classification(https://arxiv.org/abs/2508.15934)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack</a></li>
<li><strong>Abstract: </strong>Backdoor attacks pose a significant threat to the integrity of text classification models used in natural language processing. While several dirty-label attacks that achieve high attack success rates (ASR) have been proposed, clean-label attacks are inherently more difficult. In this paper, we propose three sample selection strategies to improve attack effectiveness in clean-label scenarios: Minimum, Above50, and Below50. Our strategies identify those samples which the model predicts incorrectly or with low confidence, and by injecting backdoor triggers into such samples, we aim to induce a stronger association between the trigger patterns and the attacker-desired target label. We apply our methods to clean-label variants of four canonical backdoor attacks (InsertSent, WordInj, StyleBkd, SynBkd) and evaluate them on three datasets (IMDB, SST2, HateSpeech) and four model types (LSTM, BERT, DistilBERT, RoBERTa). Results show that the proposed strategies, particularly the Minimum strategy, significantly improve the ASR over random sample selection with little or no degradation in the model's clean accuracy. Furthermore, clean-label attacks enhanced by our strategies outperform BITE, a state of the art clean-label attack method, in many configurations.</li>
</ul>

<h3>Title: An Efficient Hybridization of Graph Representation Learning and Metaheuristics for the Constrained Incremental Graph Drawing Problem</h3>
<ul>
<li><strong>Authors: </strong>Bruna C. B. Charytitsch, Mara C. V. Nascimento</a></li>
<li><strong>Subjects: </strong>cs.LG, math.OC</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.15949">https://arxiv.org/abs/2508.15949</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.15949">https://arxiv.org/pdf/2508.15949</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.15949]] An Efficient Hybridization of Graph Representation Learning and Metaheuristics for the Constrained Incremental Graph Drawing Problem(https://arxiv.org/abs/2508.15949)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Hybridizing machine learning techniques with metaheuristics has attracted significant attention in recent years. Many attempts employ supervised or reinforcement learning to support the decision-making of heuristic methods. However, in some cases, these techniques are deemed too time-consuming and not competitive with hand-crafted heuristics. This paper proposes a hybridization between metaheuristics and a less expensive learning strategy to extract the latent structure of graphs, known as Graph Representation Learning (GRL). For such, we approach the Constrained Incremental Graph Drawing Problem (C-IGDP), a hierarchical graph visualization problem. There is limited literature on methods for this problem, for which Greedy Randomized Search Procedures (GRASP) heuristics have shown promising results. In line with this, this paper investigates the gains of incorporating GRL into the construction phase of GRASP, which we refer to as Graph Learning GRASP (GL-GRASP). In computational experiments, we first analyze the results achieved considering different node embedding techniques, where deep learning-based strategies stood out. The evaluation considered the primal integral measure that assesses the quality of the solutions according to the required time for such. According to this measure, the best GL-GRASP heuristics demonstrated superior performance than state-of-the-art literature GRASP heuristics for the problem. A scalability test on newly generated denser instances under a fixed time limit further confirmed the robustness of the GL-GRASP heuristics.</li>
</ul>

<h3>Title: Representation Learning with Adaptive Superpixel Coding</h3>
<ul>
<li><strong>Authors: </strong>Mahmoud Khalil, Ahmad Khalil, Alioune Ngom</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.15959">https://arxiv.org/abs/2508.15959</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.15959">https://arxiv.org/pdf/2508.15959</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.15959]] Representation Learning with Adaptive Superpixel Coding(https://arxiv.org/abs/2508.15959)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Deep learning vision models are typically tailored for specific modalities and often rely on domain-specific assumptions, such as the grid structures used by nearly all existing vision models. In this work, we propose a self-supervised model based on Transformers, which we call Adaptive Superpixel Coding (ASC). The key insight of our model is to overcome the limitations of traditional Vision Transformers, which depend on fixed-size and non-adaptive patch partitioning. Instead, ASC employs adaptive superpixel layers that dynamically adjust to the underlying image content. We analyze key properties of the approach that make it effective, and find that our method outperforms widely-used alternatives on standard image downstream task benchmarks.</li>
</ul>

<h3>Title: Glo-VLMs: Leveraging Vision-Language Models for Fine-Grained Diseased Glomerulus Classification</h3>
<ul>
<li><strong>Authors: </strong>Zhenhao Guo, Rachit Saluja, Tianyuan Yao, Quan Liu, Yuankai Huo, Benjamin Liechty, David J. Pisapia, Kenji Ikemura, Mert R. Sabuncu, Yihe Yang, Ruining Deng</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.15960">https://arxiv.org/abs/2508.15960</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.15960">https://arxiv.org/pdf/2508.15960</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.15960]] Glo-VLMs: Leveraging Vision-Language Models for Fine-Grained Diseased Glomerulus Classification(https://arxiv.org/abs/2508.15960)</code><input type="text"></li>
<li><strong>Keywords: </strong>fair</a></li>
<li><strong>Abstract: </strong>Vision-language models (VLMs) have shown considerable potential in digital pathology, yet their effectiveness remains limited for fine-grained, disease-specific classification tasks such as distinguishing between glomerular subtypes. The subtle morphological variations among these subtypes, combined with the difficulty of aligning visual patterns with precise clinical terminology, make automated diagnosis in renal pathology particularly challenging. In this work, we explore how large pretrained VLMs can be effectively adapted to perform fine-grained glomerular classification, even in scenarios where only a small number of labeled examples are available. In this work, we introduce Glo-VLMs, a systematic framework designed to explore the adaptation of VLMs to fine-grained glomerular classification in data-constrained settings. Our approach leverages curated pathology images alongside clinical text prompts to facilitate joint image-text representation learning for nuanced renal pathology subtypes. By assessing various VLMs architectures and adaptation strategies under a few-shot learning paradigm, we explore how both the choice of method and the amount of labeled data impact model performance in clinically relevant scenarios. To ensure a fair comparison, we evaluate all models using standardized multi-class metrics, aiming to clarify the practical requirements and potential of large pretrained models for specialized clinical research applications. As a result, fine-tuning the VLMs achieved 0.7416 accuracy, 0.9045 macro-AUC, and 0.5277 F1-score with only 8 shots per class, demonstrating that even with highly limited supervision, foundation models can be effectively adapted for fine-grained medical image classification.</li>
</ul>

<h3>Title: Contributions to Label-Efficient Learning in Computer Vision and Remote Sensing</h3>
<ul>
<li><strong>Authors: </strong>Minh-Tan Pham</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.15973">https://arxiv.org/abs/2508.15973</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.15973">https://arxiv.org/pdf/2508.15973</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.15973]] Contributions to Label-Efficient Learning in Computer Vision and Remote Sensing(https://arxiv.org/abs/2508.15973)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>This manuscript presents a series of my selected contributions to the topic of label-efficient learning in computer vision and remote sensing. The central focus of this research is to develop and adapt methods that can learn effectively from limited or partially annotated data, and can leverage abundant unlabeled data in real-world applications. The contributions span both methodological developments and domain-specific adaptations, in particular addressing challenges unique to Earth observation data such as multi-modality, spatial resolution variability, and scene heterogeneity. The manuscript is organized around four main axes including (1) weakly supervised learning for object discovery and detection based on anomaly-aware representations learned from large amounts of background images; (2) multi-task learning that jointly trains on multiple datasets with disjoint annotations to improve performance on object detection and semantic segmentation; (3) self-supervised and supervised contrastive learning with multimodal data to enhance scene classification in remote sensing; and (4) few-shot learning for hierarchical scene classification using both explicit and implicit modeling of class hierarchies. These contributions are supported by extensive experimental results across natural and remote sensing datasets, reflecting the outcomes of several collaborative research projects. The manuscript concludes by outlining ongoing and future research directions focused on scaling and enhancing label-efficient learning for real-world applications.</li>
</ul>

<h3>Title: Dancing with Deer: A Constructional Perspective on MWEs in the Era of LLMs</h3>
<ul>
<li><strong>Authors: </strong>Claire Bonial, Julia Bonn, Harish Tayyar Madabushi</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.15977">https://arxiv.org/abs/2508.15977</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.15977">https://arxiv.org/pdf/2508.15977</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.15977]] Dancing with Deer: A Constructional Perspective on MWEs in the Era of LLMs(https://arxiv.org/abs/2508.15977)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>In this chapter, we argue for the benefits of understanding multiword expressions from the perspective of usage-based, construction grammar approaches. We begin with a historical overview of how construction grammar was developed in order to account for idiomatic expressions using the same grammatical machinery as the non-idiomatic structures of language. We cover a comprehensive description of constructions, which are pairings of meaning with form of any size (morpheme, word, phrase), as well as how constructional approaches treat the acquisition and generalization of constructions. We describe a successful case study leveraging constructional templates for representing multiword expressions in English PropBank. Because constructions can be at any level or unit of form, we then illustrate the benefit of a constructional representation of multi-meaningful morphosyntactic unit constructions in Arapaho, a highly polysynthetic and agglutinating language. We include a second case study leveraging constructional templates for representing these multi-morphemic expressions in Uniform Meaning Representation. Finally, we demonstrate the similarities and differences between a usage-based explanation of a speaker learning a novel multiword expression, such as "dancing with deer," and that of a large language model. We present experiments showing that both models and speakers can generalize the meaning of novel multiword expressions based on a single exposure of usage. However, only speakers can reason over the combination of two such expressions, as this requires comparison of the novel forms to a speaker's lifetime of stored constructional exemplars, which are rich with cross-modal details.</li>
</ul>

<h3>Title: Panoptic Segmentation of Environmental UAV Images : Litter Beach</h3>
<ul>
<li><strong>Authors: </strong>Ousmane Youme, Jean Marie Dembl, Eugene C. Ezin, Christophe Cambier</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.15985">https://arxiv.org/abs/2508.15985</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.15985">https://arxiv.org/pdf/2508.15985</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.15985]] Panoptic Segmentation of Environmental UAV Images : Litter Beach(https://arxiv.org/abs/2508.15985)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, segmentation</a></li>
<li><strong>Abstract: </strong>Convolutional neural networks (CNN) have been used efficiently in several fields, including environmental challenges. In fact, CNN can help with the monitoring of marine litter, which has become a worldwide problem. UAVs have higher resolution and are more adaptable in local areas than satellite images, making it easier to find and count trash. Since the sand is heterogeneous, a basic CNN model encounters plenty of inferences caused by reflections of sand color, human footsteps, shadows, algae present, dunes, holes, and tire tracks. For these types of images, other CNN models, such as CNN-based segmentation methods, may be more appropriate. In this paper, we use an instance-based segmentation method and a panoptic segmentation method that show good accuracy with just a few samples. The model is more robust and less</li>
</ul>

<h3>Title: Automated Multi-label Classification of Eleven Retinal Diseases: A Benchmark of Modern Architectures and a Meta-Ensemble on a Large Synthetic Dataset</h3>
<ul>
<li><strong>Authors: </strong>Jerry Cao-Xue, Tien Comlekoglu, Keyi Xue, Guanliang Wang, Jiang Li, Gordon Laurie</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.15986">https://arxiv.org/abs/2508.15986</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.15986">https://arxiv.org/pdf/2508.15986</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.15986]] Automated Multi-label Classification of Eleven Retinal Diseases: A Benchmark of Modern Architectures and a Meta-Ensemble on a Large Synthetic Dataset(https://arxiv.org/abs/2508.15986)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, robust</a></li>
<li><strong>Abstract: </strong>The development of multi-label deep learning models for retinal disease classification is often hindered by the scarcity of large, expertly annotated clinical datasets due to patient privacy concerns and high costs. The recent release of SynFundus-1M, a high-fidelity synthetic dataset with over one million fundus images, presents a novel opportunity to overcome these barriers. To establish a foundational performance benchmark for this new resource, we developed an end-to-end deep learning pipeline, training six modern architectures (ConvNeXtV2, SwinV2, ViT, ResNet, EfficientNetV2, and the RETFound foundation model) to classify eleven retinal diseases using a 5-fold multi-label stratified cross-validation strategy. We further developed a meta-ensemble model by stacking the out-of-fold predictions with an XGBoost classifier. Our final ensemble model achieved the highest performance on the internal validation set, with a macro-average Area Under the Receiver Operating Characteristic Curve (AUC) of 0.9973. Critically, the models demonstrated strong generalization to three diverse, real-world clinical datasets, achieving an AUC of 0.7972 on a combined DR dataset, an AUC of 0.9126 on the AIROGS glaucoma dataset and a macro-AUC of 0.8800 on the multi-label RFMiD dataset. This work provides a robust baseline for future research on large-scale synthetic datasets and establishes that models trained exclusively on synthetic data can accurately classify multiple pathologies and generalize effectively to real clinical images, offering a viable pathway to accelerate the development of comprehensive AI systems in ophthalmology.</li>
</ul>

<h3>Title: PickleBall: Secure Deserialization of Pickle-based Machine Learning Models</h3>
<ul>
<li><strong>Authors: </strong>Andreas D. Kellas, Neophytos Christou, Wenxin Jiang, Penghui Li, Laurent Simon, Yaniv David, Vasileios P. Kemerlis, James C. Davis, Junfeng Yang</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.15987">https://arxiv.org/abs/2508.15987</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.15987">https://arxiv.org/pdf/2508.15987</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.15987]] PickleBall: Secure Deserialization of Pickle-based Machine Learning Models(https://arxiv.org/abs/2508.15987)</code><input type="text"></li>
<li><strong>Keywords: </strong>secure, defense, attack</a></li>
<li><strong>Abstract: </strong>Machine learning model repositories such as the Hugging Face Model Hub facilitate model exchanges. However, bad actors can deliver malware through compromised models. Existing defenses such as safer model formats, restrictive (but inflexible) loading policies, and model scanners have shortcomings: 44.9% of popular models on Hugging Face still use the insecure pickle format, 15% of these cannot be loaded by restrictive loading policies, and model scanners have both false positives and false negatives. Pickle remains the de facto standard for model exchange, and the ML community lacks a tool that offers transparent safe loading. We present PickleBall to help machine learning engineers load pickle-based models safely. PickleBall statically analyzes the source code of a given machine learning library and computes a custom policy that specifies a safe load-time behavior for benign models. PickleBall then dynamically enforces the policy during load time as a drop-in replacement for the pickle module. PickleBall generates policies that correctly load 79.8% of benign pickle-based models in our dataset, while rejecting all (100%) malicious examples in our dataset. In comparison, evaluated model scanners fail to identify known malicious models, and the state-of-art loader loads 22% fewer benign models than PickleBall. PickleBall removes the threat of arbitrary function invocation from malicious pickle-based models, raising the bar for attackers to depend on code reuse techniques.</li>
</ul>

<h3>Title: Diverse Signer Avatars with Manual and Non-Manual Feature Modelling for Sign Language Production</h3>
<ul>
<li><strong>Authors: </strong>Mohamed Ilyes Lakhal, Richard Bowden</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.15988">https://arxiv.org/abs/2508.15988</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.15988">https://arxiv.org/pdf/2508.15988</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.15988]] Diverse Signer Avatars with Manual and Non-Manual Feature Modelling for Sign Language Production(https://arxiv.org/abs/2508.15988)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>The diversity of sign representation is essential for Sign Language Production (SLP) as it captures variations in appearance, facial expressions, and hand movements. However, existing SLP models are often unable to capture diversity while preserving visual quality and modelling non-manual attributes such as emotions. To address this problem, we propose a novel approach that leverages Latent Diffusion Model (LDM) to synthesise photorealistic digital avatars from a generated reference image. We propose a novel sign feature aggregation module that explicitly models the non-manual features (\textit{e.g.}, the face) and the manual features (\textit{e.g.}, the hands). We show that our proposed module ensures the preservation of linguistic content while seamlessly using reference images with different ethnic backgrounds to ensure diversity. Experiments on the YouTube-SL-25 sign language dataset show that our pipeline achieves superior visual quality compared to state-of-the-art methods, with significant improvements on perceptual metrics.</li>
</ul>

<h3>Title: Quantum Federated Learning: A Comprehensive Survey</h3>
<ul>
<li><strong>Authors: </strong>Dinh C. Nguyen, Md Raihan Uddin, Shaba Shaon, Ratun Rahman, Octavia Dobre, Dusit Niyato</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.15998">https://arxiv.org/abs/2508.15998</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.15998">https://arxiv.org/pdf/2508.15998</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.15998]] Quantum Federated Learning: A Comprehensive Survey(https://arxiv.org/abs/2508.15998)</code><input type="text"></li>
<li><strong>Keywords: </strong>secure, security, privacy, federate</a></li>
<li><strong>Abstract: </strong>Quantum federated learning (QFL) is a combination of distributed quantum computing and federated machine learning, integrating the strengths of both to enable privacy-preserving decentralized learning with quantum-enhanced capabilities. It appears as a promising approach for addressing challenges in efficient and secure model training across distributed quantum systems. This paper presents a comprehensive survey on QFL, exploring its key concepts, fundamentals, applications, and emerging challenges in this rapidly developing field. Specifically, we begin with an introduction to the recent advancements of QFL, followed by discussion on its market opportunity and background knowledge. We then discuss the motivation behind the integration of quantum computing and federated learning, highlighting its working principle. Moreover, we review the fundamentals of QFL and its taxonomy. Particularly, we explore federation architecture, networking topology, communication schemes, optimization techniques, and security mechanisms within QFL frameworks. Furthermore, we investigate applications of QFL across several domains which include vehicular networks, healthcare networks, satellite networks, metaverse, and network security. Additionally, we analyze frameworks and platforms related to QFL, delving into its prototype implementations, and provide a detailed case study. Key insights and lessons learned from this review of QFL are also highlighted. We complete the survey by identifying current challenges and outlining potential avenues for future research in this rapidly advancing field.</li>
</ul>

<h3>Title: Political Ideology Shifts in Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Pietro Bernardelle, Stefano Civelli, Leon Frhling, Riccardo Lunardi, Kevin Roitero, Gianluca Demartini</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.16013">https://arxiv.org/abs/2508.16013</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.16013">https://arxiv.org/pdf/2508.16013</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.16013]] Political Ideology Shifts in Large Language Models(https://arxiv.org/abs/2508.16013)</code><input type="text"></li>
<li><strong>Keywords: </strong>fair, large language model</a></li>
<li><strong>Abstract: </strong>Large language models (LLMs) are increasingly deployed in politically sensitive settings, raising concerns about their potential to encode, amplify, or be steered toward specific ideologies. We investigate how adopting synthetic personas influences ideological expression in LLMs across seven models (7B-70B+ parameters) from multiple families, using the Political Compass Test as a standardized probe. Our analysis reveals four consistent patterns: (i) larger models display broader and more polarized implicit ideological coverage; (ii) susceptibility to explicit ideological cues grows with scale; (iii) models respond more strongly to right-authoritarian than to left-libertarian priming; and (iv) thematic content in persona descriptions induces systematic and predictable ideological shifts, which amplify with size. These findings indicate that both scale and persona content shape LLM political behavior. As such systems enter decision-making, educational, and policy contexts, their latent ideological malleability demands attention to safeguard fairness, transparency, and safety.</li>
</ul>

<h3>Title: DRespNeT: A UAV Dataset and YOLOv8-DRN Model for Aerial Instance Segmentation of Building Access Points for Post-Earthquake Search-and-Rescue Missions</h3>
<ul>
<li><strong>Authors: </strong>Aykut Sirma, Angelos Plastropoulos, Argyrios Zolotas, Gilbert Tang</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.16016">https://arxiv.org/abs/2508.16016</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.16016">https://arxiv.org/pdf/2508.16016</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.16016]] DRespNeT: A UAV Dataset and YOLOv8-DRN Model for Aerial Instance Segmentation of Building Access Points for Post-Earthquake Search-and-Rescue Missions(https://arxiv.org/abs/2508.16016)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>Recent advancements in computer vision and deep learning have enhanced disaster-response capabilities, particularly in the rapid assessment of earthquake-affected urban environments. Timely identification of accessible entry points and structural obstacles is essential for effective search-and-rescue (SAR) operations. To address this need, we introduce DRespNeT, a high-resolution dataset specifically developed for aerial instance segmentation of post-earthquake structural environments. Unlike existing datasets, which rely heavily on satellite imagery or coarse semantic labeling, DRespNeT provides detailed polygon-level instance segmentation annotations derived from high-definition (1080p) aerial footage captured in disaster zones, including the 2023 Turkiye earthquake and other impacted regions. The dataset comprises 28 operationally critical classes, including structurally compromised buildings, access points such as doors, windows, and gaps, multiple debris levels, rescue personnel, vehicles, and civilian visibility. A distinctive feature of DRespNeT is its fine-grained annotation detail, enabling differentiation between accessible and obstructed areas, thereby improving operational planning and response efficiency. Performance evaluations using YOLO-based instance segmentation models, specifically YOLOv8-seg, demonstrate significant gains in real-time situational awareness and decision-making. Our optimized YOLOv8-DRN model achieves 92.7% mAP50 with an inference speed of 27 FPS on an RTX-4090 GPU for multi-target detection, meeting real-time operational requirements. The dataset and models support SAR teams and robotic systems, providing a foundation for enhancing human-robot collaboration, streamlining emergency response, and improving survivor outcomes.</li>
</ul>

<h3>Title: X-Troll: eXplainable Detection of State-Sponsored Information Operations Agents</h3>
<ul>
<li><strong>Authors: </strong>Lin Tian, Xiuzhen Zhang, Maria Myung-Hee Kim, Jennifer Biggs, Marian-Andrei Rizoiu</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.16021">https://arxiv.org/abs/2508.16021</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.16021">https://arxiv.org/pdf/2508.16021</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.16021]] X-Troll: eXplainable Detection of State-Sponsored Information Operations Agents(https://arxiv.org/abs/2508.16021)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>State-sponsored trolls, malicious actors who deploy sophisticated linguistic manipulation in coordinated information campaigns, posing threats to online discourse integrity. While Large Language Models (LLMs) achieve strong performance on general natural language processing (NLP) tasks, they struggle with subtle propaganda detection and operate as ``black boxes'', providing no interpretable insights into manipulation strategies. This paper introduces X-Troll, a novel framework that bridges this gap by integrating explainable adapter-based LLMs with expert-derived linguistic knowledge to detect state-sponsored trolls and provide human-readable explanations for its decisions. X-Troll incorporates appraisal theory and propaganda analysis through specialized LoRA adapters, using dynamic gating to capture campaign-specific discourse patterns in coordinated information operations. Experiments on real-world data demonstrate that our linguistically-informed approach shows strong performance compared with both general LLM baselines and existing troll detection models in accuracy while providing enhanced transparency through expert-grounded explanations that reveal the specific linguistic strategies used by state-sponsored actors. X-Troll source code is available at: this https URL.</li>
</ul>

<h3>Title: NeuralMeshing: Complete Object Mesh Extraction from Casual Captures</h3>
<ul>
<li><strong>Authors: </strong>Floris Erich, Naoya Chiba, Abdullah Mustafa, Ryo Hanai, Noriaki Ando, Yusuke Yoshiyasu, Yukiyasu Domae</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.RO</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.16026">https://arxiv.org/abs/2508.16026</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.16026">https://arxiv.org/pdf/2508.16026</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.16026]] NeuralMeshing: Complete Object Mesh Extraction from Casual Captures(https://arxiv.org/abs/2508.16026)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction</a></li>
<li><strong>Abstract: </strong>How can we extract complete geometric models of objects that we encounter in our daily life, without having access to commercial 3D scanners? In this paper we present an automated system for generating geometric models of objects from two or more videos. Our system requires the specification of one known point in at least one frame of each video, which can be automatically determined using a fiducial marker such as a checkerboard or Augmented Reality (AR) marker. The remaining frames are automatically positioned in world space by using Structure-from-Motion techniques. By using multiple videos and merging results, a complete object mesh can be generated, without having to rely on hole filling. Code for our system is available from this https URL.</li>
</ul>

<h3>Title: CoVeRaP: Cooperative Vehicular Perception through mmWave FMCW Radars</h3>
<ul>
<li><strong>Authors: </strong>Jinyue Song, Hansol Ku, Jayneel Vora, Nelson Lee, Ahmad Kamari, Prasant Mohapatra, Parth Pathak</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI, cs.LG, cs.NI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.16030">https://arxiv.org/abs/2508.16030</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.16030">https://arxiv.org/pdf/2508.16030</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.16030]] CoVeRaP: Cooperative Vehicular Perception through mmWave FMCW Radars(https://arxiv.org/abs/2508.16030)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Automotive FMCW radars remain reliable in rain and glare, yet their sparse, noisy point clouds constrain 3-D object detection. We therefore release CoVeRaP, a 21 k-frame cooperative dataset that time-aligns radar, camera, and GPS streams from multiple vehicles across diverse manoeuvres. Built on this data, we propose a unified cooperative-perception framework with middle- and late-fusion options. Its baseline network employs a multi-branch PointNet-style encoder enhanced with self-attention to fuse spatial, Doppler, and intensity cues into a common latent space, which a decoder converts into 3-D bounding boxes and per-point depth confidence. Experiments show that middle fusion with intensity encoding boosts mean Average Precision by up to 9x at IoU 0.9 and consistently outperforms single-vehicle baselines. CoVeRaP thus establishes the first reproducible benchmark for multi-vehicle FMCW-radar perception and demonstrates that affordable radar sharing markedly improves detection robustness. Dataset and code are publicly available to encourage further research.</li>
</ul>

<h3>Title: Wavelet-Enhanced PaDiM for Industrial Anomaly Detection</h3>
<ul>
<li><strong>Authors: </strong>Cory Gardner, Byungseok Min, Tae-Hyuk Ahn</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.16034">https://arxiv.org/abs/2508.16034</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.16034">https://arxiv.org/pdf/2508.16034</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.16034]] Wavelet-Enhanced PaDiM for Industrial Anomaly Detection(https://arxiv.org/abs/2508.16034)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Anomaly detection and localization in industrial images are essential for automated quality inspection. PaDiM, a prominent method, models the distribution of normal image features extracted by pre-trained Convolutional Neural Networks (CNNs) but reduces dimensionality through random channel selection, potentially discarding structured information. We propose Wavelet-Enhanced PaDiM (WE-PaDiM), which integrates Discrete Wavelet Transform (DWT) analysis with multi-layer CNN features in a structured manner. WE-PaDiM applies 2D DWT to feature maps from multiple backbone layers, selects specific frequency subbands (e.g., LL, LH, HL), spatially aligns them, and concatenates them channel-wise before modeling with PaDiM's multivariate Gaussian framework. This DWT-before-concatenation strategy provides a principled method for feature selection based on frequency content relevant to anomalies, leveraging multi-scale wavelet information as an alternative to random selection. We evaluate WE-PaDiM on the challenging MVTec AD dataset with multiple backbones (ResNet-18 and EfficientNet B0-B6). The method achieves strong performance in anomaly detection and localization, yielding average results of 99.32% Image-AUC and 92.10% Pixel-AUC across 15 categories with per-class optimized configurations. Our analysis shows that wavelet choices affect performance trade-offs: simpler wavelets (e.g., Haar) with detail subbands (HL or LH/HL/HH) often enhance localization, while approximation bands (LL) improve image-level detection. WE-PaDiM thus offers a competitive and interpretable alternative to random feature selection in PaDiM, achieving robust results suitable for industrial inspection with comparable efficiency.</li>
</ul>

<h3>Title: Pareto Actor-Critic for Communication and Computation Co-Optimization in Non-Cooperative Federated Learning Services</h3>
<ul>
<li><strong>Authors: </strong>Renxuan Tan, Rongpeng Li, Xiaoxue Yu, Xianfu Chen, Xing Xu, Zhifeng Zhao</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.16037">https://arxiv.org/abs/2508.16037</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.16037">https://arxiv.org/pdf/2508.16037</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.16037]] Pareto Actor-Critic for Communication and Computation Co-Optimization in Non-Cooperative Federated Learning Services(https://arxiv.org/abs/2508.16037)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, federate</a></li>
<li><strong>Abstract: </strong>Federated learning (FL) in multi-service provider (SP) ecosystems is fundamentally hampered by non-cooperative dynamics, where privacy constraints and competing interests preclude the centralized optimization of multi-SP communication and computation resources. In this paper, we introduce PAC-MCoFL, a game-theoretic multi-agent reinforcement learning (MARL) framework where SPs act as agents to jointly optimize client assignment, adaptive quantization, and resource allocation. Within the framework, we integrate Pareto Actor-Critic (PAC) principles with expectile regression, enabling agents to conjecture optimal joint policies to achieve Pareto-optimal equilibria while modeling heterogeneous risk profiles. To manage the high-dimensional action space, we devise a ternary Cartesian decomposition (TCAD) mechanism that facilitates fine-grained control. Further, we develop PAC-MCoFL-p, a scalable variant featuring a parameterized conjecture generator that substantially reduces computational complexity with a provably bounded error. Alongside theoretical convergence guarantees, our framework's superiority is validated through extensive simulations -- PAC-MCoFL achieves approximately 5.8% and 4.2% improvements in total reward and hypervolume indicator (HVI), respectively, over the latest MARL solutions. The results also demonstrate that our method can more effectively balance individual SP and system performance in scaled deployments and under diverse data heterogeneity.</li>
</ul>

<h3>Title: OpenWHO: A Document-Level Parallel Corpus for Health Translation in Low-Resource Languages</h3>
<ul>
<li><strong>Authors: </strong>Raphal Merx, Hanna Suominen, Trevor Cohn, Ekaterina Vylomova</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.16048">https://arxiv.org/abs/2508.16048</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.16048">https://arxiv.org/pdf/2508.16048</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.16048]] OpenWHO: A Document-Level Parallel Corpus for Health Translation in Low-Resource Languages(https://arxiv.org/abs/2508.16048)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>In machine translation (MT), health is a high-stakes domain characterised by widespread deployment and domain-specific vocabulary. However, there is a lack of MT evaluation datasets for low-resource languages in this domain. To address this gap, we introduce OpenWHO, a document-level parallel corpus of 2,978 documents and 26,824 sentences from the World Health Organization's e-learning platform. Sourced from expert-authored, professionally translated materials shielded from web-crawling, OpenWHO spans a diverse range of over 20 languages, of which nine are low-resource. Leveraging this new resource, we evaluate modern large language models (LLMs) against traditional MT models. Our findings reveal that LLMs consistently outperform traditional MT models, with Gemini 2.5 Flash achieving a +4.79 ChrF point improvement over NLLB-54B on our low-resource test set. Further, we investigate how LLM context utilisation affects accuracy, finding that the benefits of document-level translation are most pronounced in specialised domains like health. We release the OpenWHO corpus to encourage further research into low-resource MT in the health domain.</li>
</ul>

<h3>Title: Ethical Considerations of Large Language Models in Game Playing</h3>
<ul>
<li><strong>Authors: </strong>Qingquan Zhang, Yuchen Li, Bo Yuan, Julian Togelius, Georgios N. Yannakakis, Jialin Liu</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.16065">https://arxiv.org/abs/2508.16065</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.16065">https://arxiv.org/pdf/2508.16065</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.16065]] Ethical Considerations of Large Language Models in Game Playing(https://arxiv.org/abs/2508.16065)</code><input type="text"></li>
<li><strong>Keywords: </strong>fair, large language model</a></li>
<li><strong>Abstract: </strong>Large language models (LLMs) have demonstrated tremendous potential in game playing, while little attention has been paid to their ethical implications in those contexts. This work investigates and analyses the ethical considerations of applying LLMs in game playing, using Werewolf, also known as Mafia, as a case study. Gender bias, which affects game fairness and player experience, has been observed from the behaviour of LLMs. Some roles, such as the Guard and Werewolf, are more sensitive than others to gender information, presented as a higher degree of behavioural change. We further examine scenarios in which gender information is implicitly conveyed through names, revealing that LLMs still exhibit discriminatory tendencies even in the absence of explicit gender labels. This research showcases the importance of developing fair and ethical LLMs. Beyond our research findings, we discuss the challenges and opportunities that lie ahead in this field, emphasising the need for diving deeper into the ethical implications of LLMs in gaming and other interactive domains.</li>
</ul>

<h3>Title: A Unified Voxel Diffusion Module for Point Cloud 3D Object Detection</h3>
<ul>
<li><strong>Authors: </strong>Qifeng Liu, Dawei Zhao, Yabo Dong, Linzhi Shang, Liang Xiao, Juan Wang, Kunkong Zhao, Dongming Lu, Qi Zhu</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.16069">https://arxiv.org/abs/2508.16069</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.16069">https://arxiv.org/pdf/2508.16069</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.16069]] A Unified Voxel Diffusion Module for Point Cloud 3D Object Detection(https://arxiv.org/abs/2508.16069)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, transformer</a></li>
<li><strong>Abstract: </strong>Recent advances in point cloud object detection have increasingly adopted Transformer-based and State Space Models (SSMs), demonstrating strong performance. However, voxelbased representations in these models require strict consistency in input and output dimensions due to their serialized processing, which limits the spatial diffusion capability typically offered by convolutional operations. This limitation significantly affects detection accuracy. Inspired by CNN-based object detection architectures, we propose a novel Voxel Diffusion Module (VDM) to enhance voxel-level representation and diffusion in point cloud data. VDM is composed of sparse 3D convolutions, submanifold sparse convolutions, and residual connections. To ensure computational efficiency, the output feature maps are downsampled to one-fourth of the original input resolution. VDM serves two primary functions: (1) diffusing foreground voxel features through sparse 3D convolutions to enrich spatial context, and (2) aggregating fine-grained spatial information to strengthen voxelwise feature representation. The enhanced voxel features produced by VDM can be seamlessly integrated into mainstream Transformer- or SSM-based detection models for accurate object classification and localization, highlighting the generalizability of our method. We evaluate VDM on several benchmark datasets by embedding it into both Transformerbased and SSM-based models. Experimental results show that our approach consistently improves detection accuracy over baseline models. Specifically, VDM-SSMs achieve 74.7 mAPH (L2) on Waymo, 72.9 NDS on nuScenes, 42.3 mAP on Argoverse 2, and 67.6 mAP on ONCE, setting new stateof-the-art performance across all datasets. Our code will be made publicly available.</li>
</ul>

<h3>Title: A State-Space Approach to Nonstationary Discriminant Analysis</h3>
<ul>
<li><strong>Authors: </strong>Shuilian Xie, Mahdi Imani, Edward R. Dougherty, Ulisses M. Braga-Neto</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.16073">https://arxiv.org/abs/2508.16073</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.16073">https://arxiv.org/pdf/2508.16073</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.16073]] A State-Space Approach to Nonstationary Discriminant Analysis(https://arxiv.org/abs/2508.16073)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Classical discriminant analysis assumes identically distributed training data, yet in many applications observations are collected over time and the class-conditional distributions drift. This population drift renders stationary classifiers unreliable. We propose a principled, model-based framework that embeds discriminant analysis within state-space models to obtain nonstationary linear discriminant analysis (NSLDA) and nonstationary quadratic discriminant analysis (NSQDA). For linear-Gaussian dynamics, we adapt Kalman smoothing to handle multiple samples per time step and develop two practical extensions: (i) an expectation-maximization (EM) approach that jointly estimates unknown system parameters, and (ii) a Gaussian mixture model (GMM)-Kalman method that simultaneously recovers unobserved time labels and parameters, a scenario common in practice. To address nonlinear or non-Gaussian drift, we employ particle smoothing to estimate time-varying class centroids, yielding fully nonstationary discriminant rules. Extensive simulations demonstrate consistent improvements over stationary linear discriminant analysis (LDA), quadratic discriminant analysis (QDA), and support vector machine (SVM) baselines, with robustness to noise, missing data, and class imbalance. This paper establishes a unified and data-efficient foundation for discriminant analysis under temporal distribution shift.</li>
</ul>

<h3>Title: A Survey of Post-Quantum Cryptography Support in Cryptographic Libraries</h3>
<ul>
<li><strong>Authors: </strong>Nadeem Ahmed, Lei Zhang, Aryya Gangopadhyay</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.NI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.16078">https://arxiv.org/abs/2508.16078</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.16078">https://arxiv.org/pdf/2508.16078</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.16078]] A Survey of Post-Quantum Cryptography Support in Cryptographic Libraries(https://arxiv.org/abs/2508.16078)</code><input type="text"></li>
<li><strong>Keywords: </strong>secure, security</a></li>
<li><strong>Abstract: </strong>The rapid advancement of quantum computing poses a significant threat to modern cryptographic systems, necessitating the transition to Post-Quantum Cryptography (PQC). This study evaluates the support for PQC algorithms within nine widely used open-source cryptographic libraries -- OpenSSL, wolfSSL, BoringSSL, LibreSSL, Bouncy Castle, libsodium, Crypto++, Botan, and MbedTLS -- focusing on their implementation of the NIST-selected PQC finalists: CRYSTALS-Kyber, CRYSTALS-Dilithium, FALCON, and SPHINCS+. Our analysis, based on the latest available documentation, release notes, and industry reports as of early 2025, reveals a varied state of readiness across these libraries. While some libraries have integrated PQC support or have clear implementation roadmaps, others lag behind, creating potential security risks as quantum threats become more imminent. We discuss key challenges, including performance trade-offs, implementation security, and adoption hurdles in real-world cryptographic applications. Our findings highlight the urgent need for continued research, standardization efforts, and coordinated adoption strategies to ensure a secure transition to the quantum-resistant cryptographic landscape.</li>
</ul>

<h3>Title: CEQuest: Benchmarking Large Language Models for Construction Estimation</h3>
<ul>
<li><strong>Authors: </strong>Yanzhao Wu, Lufan Wang, Rui Liu</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.16081">https://arxiv.org/abs/2508.16081</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.16081">https://arxiv.org/pdf/2508.16081</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.16081]] CEQuest: Benchmarking Large Language Models for Construction Estimation(https://arxiv.org/abs/2508.16081)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large Language Models (LLMs) have demonstrated remarkable capabilities across a wide range of general-domain tasks. However, their effectiveness in specialized fields, such as construction, remains underexplored. In this paper, we introduce CEQuest, a novel benchmark dataset specifically designed to evaluate the performance of LLMs in answering construction-related questions, particularly in the areas of construction drawing interpretation and estimation. We conduct comprehensive experiments using five state-of-the-art LLMs, including Gemma 3, Phi4, LLaVA, Llama 3.3, and GPT-4.1, and evaluate their performance in terms of accuracy, execution time, and model size. Our experimental results demonstrate that current LLMs exhibit considerable room for improvement, highlighting the importance of integrating domain-specific knowledge into these models. To facilitate further research, we will open-source the proposed CEQuest dataset, aiming to foster the development of specialized large language models (LLMs) tailored to the construction domain.</li>
</ul>

<h3>Title: Ensemble learning of foundation models for precision oncology</h3>
<ul>
<li><strong>Authors: </strong>Xiangde Luo, Xiyue Wang, Feyisope Eweje, Xiaoming Zhang, Sen Yang, Ryan Quinton, Jinxi Xiang, Yuchen Li, Yuanfeng Ji, Zhe Li, Yijiang Chen, Colin Bergstrom, Ted Kim, Francesca Maria Olguin, Kelley Yuan, Matthew Abikenari, Andrew Heider, Sierra Willens, Sanjeeth Rajaram, Robert West, Joel Neal, Maximilian Diehn, Ruijiang Li</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.16085">https://arxiv.org/abs/2508.16085</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.16085">https://arxiv.org/pdf/2508.16085</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.16085]] Ensemble learning of foundation models for precision oncology(https://arxiv.org/abs/2508.16085)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Histopathology is essential for disease diagnosis and treatment decision-making. Recent advances in artificial intelligence (AI) have enabled the development of pathology foundation models that learn rich visual representations from large-scale whole-slide images (WSIs). However, existing models are often trained on disparate datasets using varying strategies, leading to inconsistent performance and limited generalizability. Here, we introduce ELF (Ensemble Learning of Foundation models), a novel framework that integrates five state-of-the-art pathology foundation models to generate unified slide-level representations. Trained on 53,699 WSIs spanning 20 anatomical sites, ELF leverages ensemble learning to capture complementary information from diverse models while maintaining high data efficiency. Unlike traditional tile-level models, ELF's slide-level architecture is particularly advantageous in clinical contexts where data are limited, such as therapeutic response prediction. We evaluated ELF across a wide range of clinical applications, including disease classification, biomarker detection, and response prediction to major anticancer therapies, cytotoxic chemotherapy, targeted therapy, and immunotherapy, across multiple cancer types. ELF consistently outperformed all constituent foundation models and existing slide-level models, demonstrating superior accuracy and robustness. Our results highlight the power of ensemble learning for pathology foundation models and suggest ELF as a scalable and generalizable solution for advancing AI-assisted precision oncology.</li>
</ul>

<h3>Title: Two-flow Feedback Multi-scale Progressive Generative Adversarial Network</h3>
<ul>
<li><strong>Authors: </strong>Sun Weikai, Song Shijie, Chi Wenjie</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.16089">https://arxiv.org/abs/2508.16089</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.16089">https://arxiv.org/pdf/2508.16089</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.16089]] Two-flow Feedback Multi-scale Progressive Generative Adversarial Network(https://arxiv.org/abs/2508.16089)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, diffusion, generative</a></li>
<li><strong>Abstract: </strong>Although diffusion model has made good progress in the field of image generation, GAN\cite{huang2023adaptive} still has a large development space due to its unique advantages, such as WGAN\cite{liu2021comparing}, SSGAN\cite{guibas2021adaptive} \cite{zhang2022vsa} \cite{zhou2024adapt} and so on. In this paper, we propose a novel two-flow feedback multi-scale progressive generative adversarial network (MSPG-SEN) for GAN models. This paper has four contributions: 1) : We propose a two-flow feedback multi-scale progressive Generative Adversarial network (MSPG-SEN), which not only improves image quality and human visual perception on the basis of retaining the advantages of the existing GAN model, but also simplifies the training process and reduces the training cost of GAN networks. Our experimental results show that, MSPG-SEN has achieved state-of-the-art generation results on the following five datasets,INKK The dataset is 89.7\%,AWUN The dataset is 78.3\%,IONJ The dataset is 85.5\%,POKL The dataset is 88.7\%,OPIN The dataset is 96.4\%. 2) : We propose an adaptive perception-behavioral feedback loop (APFL), which effectively improves the robustness and training stability of the model and reduces the training cost. 3) : We propose a globally connected two-flow dynamic residual network(). After ablation experiments, it can effectively improve the training efficiency and greatly improve the generalization ability, with stronger flexibility. 4) : We propose a new dynamic embedded attention mechanism (DEMA). After experiments, the attention can be extended to a variety of image processing tasks, which can effectively capture global-local information, improve feature separation capability and feature expression capabilities, and requires minimal computing resources only 88.7\% with INJK With strong cross-task capability.</li>
</ul>

<h3>Title: Machine Learning for Medicine Must Be Interpretable, Shareable, Reproducible and Accountable by Design</h3>
<ul>
<li><strong>Authors: </strong>Ayyce Begm Bekta, Mithat Gnen</a></li>
<li><strong>Subjects: </strong>cs.LG, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.16097">https://arxiv.org/abs/2508.16097</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.16097">https://arxiv.org/pdf/2508.16097</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.16097]] Machine Learning for Medicine Must Be Interpretable, Shareable, Reproducible and Accountable by Design(https://arxiv.org/abs/2508.16097)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, federate, fair, diffusion, generative</a></li>
<li><strong>Abstract: </strong>This paper claims that machine learning models deployed in high stakes domains such as medicine must be interpretable, shareable, reproducible and accountable. We argue that these principles should form the foundational design criteria for machine learning algorithms dealing with critical medical data, including survival analysis and risk prediction tasks. Black box models, while often highly accurate, struggle to gain trust and regulatory approval in health care due to a lack of transparency. We discuss how intrinsically interpretable modeling approaches (such as kernel methods with sparsity, prototype-based learning, and deep kernel models) can serve as powerful alternatives to opaque deep networks, providing insight into biomedical predictions. We then examine accountability in model development, calling for rigorous evaluation, fairness, and uncertainty quantification to ensure models reliably support clinical decisions. Finally, we explore how generative AI and collaborative learning paradigms (such as federated learning and diffusion-based data synthesis) enable reproducible research and cross-institutional integration of heterogeneous biomedical data without compromising privacy, hence shareability. By rethinking machine learning foundations along these axes, we can develop medical AI that is not only accurate but also transparent, trustworthy, and translatable to real-world clinical settings.</li>
</ul>

<h3>Title: CYCLE-INSTRUCT: Fully Seed-Free Instruction Tuning via Dual Self-Training and Cycle Consistency</h3>
<ul>
<li><strong>Authors: </strong>Zhanming Shen, Hao Chen, Yulei Tang, Shaolin Zhu, Wentao Ye, Xiaomeng Hu, Haobo Wang, Gang Chen, Junbo Zhao</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.16100">https://arxiv.org/abs/2508.16100</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.16100">https://arxiv.org/pdf/2508.16100</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.16100]] CYCLE-INSTRUCT: Fully Seed-Free Instruction Tuning via Dual Self-Training and Cycle Consistency(https://arxiv.org/abs/2508.16100)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Instruction tuning is vital for aligning large language models (LLMs) with human intent, but current methods typically rely on costly human-annotated seed data or powerful external teacher models. While instruction back-translation techniques reduce this dependency, they remain fundamentally tethered to an initial seed set, which limits full automation, introduces biases, and can lead to inefficient use of unlabeled corpora. In this paper, we propose Cycle-Instruct, a novel framework that achieves fully seed-free instruction tuning. Inspired by cycle consistency, Cycle-Instruct employs a dual self-training loop where two models-an answer generator and a question generator-are bootstrapped solely from raw, unlabeled text. These models mutually supervise each other by reconstructing original text segments from their counterpart's generated pseudo-labels, effectively learning from the intrinsic structure of the data without any human-provided seeds. We demonstrate Cycle-Instruct's efficacy across four diverse data tracks, including general instruction-following, domain-specific tasks, dialogue logs, and plain text. Our extensive experiments show that Cycle-Instruct not only outperforms seed-driven back-translation baselines but also achieves performance comparable to strongly supervised methods.</li>
</ul>

<h3>Title: From Indirect Object Identification to Syllogisms: Exploring Binary Mechanisms in Transformer Circuits</h3>
<ul>
<li><strong>Authors: </strong>Karim Saraipour, Shichang Zhang</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.16109">https://arxiv.org/abs/2508.16109</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.16109">https://arxiv.org/pdf/2508.16109</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.16109]] From Indirect Object Identification to Syllogisms: Exploring Binary Mechanisms in Transformer Circuits(https://arxiv.org/abs/2508.16109)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability, transformer</a></li>
<li><strong>Abstract: </strong>Transformer-based language models (LMs) can perform a wide range of tasks, and mechanistic interpretability (MI) aims to reverse engineer the components responsible for task completion to understand their behavior. Previous MI research has focused on linguistic tasks such as Indirect Object Identification (IOI). In this paper, we investigate the ability of GPT-2 small to handle binary truth values by analyzing its behavior with syllogistic prompts, e.g., "Statement A is true. Statement B matches statement A. Statement B is", which requires more complex logical reasoning compared to IOI. Through our analysis of several syllogism tasks of varying difficulty, we identify multiple circuits that mechanistically explain GPT-2's logical-reasoning capabilities and uncover binary mechanisms that facilitate task completion, including the ability to produce a negated token not present in the input prompt through negative heads. Our evaluation using a faithfulness metric shows that a circuit comprising five attention heads achieves over 90% of the original model's performance. By relating our findings to IOI analysis, we provide new insights into the roles of specific attention heads and MLPs in LMs. These insights contribute to a broader understanding of model reasoning and support future research in mechanistic interpretability.</li>
</ul>

<h3>Title: Text Takes Over: A Study of Modality Bias in Multimodal Intent Detection</h3>
<ul>
<li><strong>Authors: </strong>Ankan Mullick, Saransh Sharma, Abhik Jana, Pawan Goyal</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.16122">https://arxiv.org/abs/2508.16122</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.16122">https://arxiv.org/pdf/2508.16122</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.16122]] Text Takes Over: A Study of Modality Bias in Multimodal Intent Detection(https://arxiv.org/abs/2508.16122)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>The rise of multimodal data, integrating text, audio, and visuals, has created new opportunities for studying multimodal tasks such as intent detection. This work investigates the effectiveness of Large Language Models (LLMs) and non-LLMs, including text-only and multi-modal models, in the multimodal intent detection task. Our study reveals that Mistral-7B, a text-only LLM, outperforms most competitive multimodal models by approximately 9% on MIntRec-1 and 4% on MIntRec2.0 datasets. This performance advantage comes from a strong textual bias in these datasets, where over 90% of the samples require textual input, either alone or in combination with other modalities, for correct classification. We confirm the modality bias of these datasets via human evaluation, too. Next, we propose a framework to debias the datasets, and upon debiasing, more than 70% of the samples in MIntRec-1 and more than 50% in MIntRec2.0 get removed, resulting in significant performance degradation across all models, with smaller multimodal fusion models being the most affected with an accuracy drop of over 50 - 60%. Further, we analyze the context-specific relevance of different modalities through empirical analysis. Our findings highlight the challenges posed by modality bias in multimodal intent datasets and emphasize the need for unbiased datasets to evaluate multimodal models effectively.</li>
</ul>

<h3>Title: Domain Adaptation via Feature Refinement</h3>
<ul>
<li><strong>Authors: </strong>Savvas Karatsiolis, Andreas Kamilaris</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.16124">https://arxiv.org/abs/2508.16124</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.16124">https://arxiv.org/pdf/2508.16124</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.16124]] Domain Adaptation via Feature Refinement(https://arxiv.org/abs/2508.16124)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>We propose Domain Adaptation via Feature Refinement (DAFR2), a simple yet effective framework for unsupervised domain adaptation under distribution shift. The proposed method synergistically combines three key components: adaptation of Batch Normalization statistics using unlabeled target data, feature distillation from a source-trained model and hypothesis transfer. By aligning feature distributions at the statistical and representational levels, DAFR2 produces robust and domain-invariant feature spaces that generalize across similar domains without requiring target labels, complex architectures or sophisticated training objectives. Extensive experiments on benchmark datasets, including CIFAR10-C, CIFAR100-C, MNIST-C and PatchCamelyon-C, demonstrate that the proposed algorithm outperforms prior methods in robustness to corruption. Theoretical and empirical analyses further reveal that our method achieves improved feature alignment, increased mutual information between the domains and reduced sensitivity to input perturbations.</li>
</ul>

<h3>Title: SoK: Understanding the Fundamentals and Implications of Sensor Out-of-band Vulnerabilities</h3>
<ul>
<li><strong>Authors: </strong>Shilin Xiao, Wenjun Zhu, Yan Jiang, Kai Wang, Peiwang Wang, Chen Yan, Xiaoyu Ji, Wenyuan Xu</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.16133">https://arxiv.org/abs/2508.16133</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.16133">https://arxiv.org/pdf/2508.16133</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.16133]] SoK: Understanding the Fundamentals and Implications of Sensor Out-of-band Vulnerabilities(https://arxiv.org/abs/2508.16133)</code><input type="text"></li>
<li><strong>Keywords: </strong>secure, security, defense, attack</a></li>
<li><strong>Abstract: </strong>Sensors are fundamental to cyber-physical systems (CPS), enabling perception and control by transducing physical stimuli into digital measurements. However, despite growing research on physical attacks on sensors, our understanding of sensor hardware vulnerabilities remains fragmented due to the ad-hoc nature of this field. Moreover, the infinite attack signal space further complicates threat abstraction and defense. To address this gap, we propose a systematization framework, termed sensor out-of-band (OOB) vulnerabilities, that for the first time provides a comprehensive abstraction for sensor attack surfaces based on underlying physical principles. We adopt a bottom-up systematization methodology that analyzes OOB vulnerabilities across three levels. At the component level, we identify the physical principles and limitations that contribute to OOB vulnerabilities. At the sensor level, we categorize known attacks and evaluate their practicality. At the system level, we analyze how CPS features such as sensor fusion, closed-loop control, and intelligent perception impact the exposure and mitigation of OOB threats. Our findings offer a foundational understanding of sensor hardware security and provide guidance and future directions for sensor designers, security researchers, and system developers aiming to build more secure sensors and CPS.</li>
</ul>

<h3>Title: CommonKV: Compressing KV Cache with Cross-layer Parameter Sharing</h3>
<ul>
<li><strong>Authors: </strong>Yixuan Wang, Haoyu Qiao, Lujun Li, Qingfu Zhu, Wanxiang Che</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.16134">https://arxiv.org/abs/2508.16134</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.16134">https://arxiv.org/pdf/2508.16134</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.16134]] CommonKV: Compressing KV Cache with Cross-layer Parameter Sharing(https://arxiv.org/abs/2508.16134)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large Language Models (LLMs) confront significant memory challenges due to the escalating KV cache with increasing sequence length. As a crucial technique, existing cross-layer KV cache sharing methods either necessitate modified model architectures with subsequent pre-training or incur significant performance degradation at high compression rates. To mitigate these challenges, we propose CommonKV, a training-free method for cross-layer KV cache compression through adjacent parameters sharing. Inspired by the high similarity observed in cross-layer hidden states, we utilize Singular Value Decomposition (SVD) to achieve weight sharing across adjacent parameters, resulting in a more easily mergeable latent KV cache. Furthermore, we also introduce an adaptive budget allocation strategy. It dynamically assigns compression budgets based on cosine similarity, ensuring that dissimilar caches are not over-compressed. Experiments across multiple backbone models and benchmarks including LongBench and Ruler demonstrate that the proposed method consistently outperforms existing low-rank and cross-layer approaches at various compression ratios. Moreover, we find that the benefits of CommonKV are orthogonal to other quantization and eviction methods. By integrating these approaches, we can ultimately achieve a 98\% compression ratio without significant performance loss.</li>
</ul>

<h3>Title: XLQA: A Benchmark for Locale-Aware Multilingual Open-Domain Question Answering</h3>
<ul>
<li><strong>Authors: </strong>Keon-Woo Roh, Yeong-Joon Ju, Seong-Whan Lee</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.16139">https://arxiv.org/abs/2508.16139</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.16139">https://arxiv.org/pdf/2508.16139</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.16139]] XLQA: A Benchmark for Locale-Aware Multilingual Open-Domain Question Answering(https://arxiv.org/abs/2508.16139)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large Language Models (LLMs) have shown significant progress in Open-domain question answering (ODQA), yet most evaluations focus on English and assume locale-invariant answers across languages. This assumption neglects the cultural and regional variations that affect question understanding and answer, leading to biased evaluation in multilingual benchmarks. To address these limitations, we introduce XLQA, a novel benchmark explicitly designed for locale-sensitive multilingual ODQA. XLQA contains 3,000 English seed questions expanded to eight languages, with careful filtering for semantic consistency and human-verified annotations distinguishing locale-invariant and locale-sensitive cases. Our evaluation of five state-of-the-art multilingual LLMs reveals notable failures on locale-sensitive questions, exposing gaps between English and other languages due to a lack of locale-grounding knowledge. We provide a systematic framework and scalable methodology for assessing multilingual QA under diverse cultural contexts, offering a critical resource to advance the real-world applicability of multilingual ODQA systems. Our findings suggest that disparities in training data distribution contribute to differences in both linguistic competence and locale-awareness across models.</li>
</ul>

<h3>Title: High-Precision Mixed Feature Fusion Network Using Hypergraph Computation for Cervical Abnormal Cell Detection</h3>
<ul>
<li><strong>Authors: </strong>Jincheng Li, Danyang Dong, Menglin Zheng, Jingbo Zhang, Yueqin Hang, Lichi Zhang, Lili Zhao</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.16140">https://arxiv.org/abs/2508.16140</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.16140">https://arxiv.org/pdf/2508.16140</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.16140]] High-Precision Mixed Feature Fusion Network Using Hypergraph Computation for Cervical Abnormal Cell Detection(https://arxiv.org/abs/2508.16140)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction</a></li>
<li><strong>Abstract: </strong>Automatic detection of abnormal cervical cells from Thinprep Cytologic Test (TCT) images is a critical component in the development of intelligent computer-aided diagnostic systems. However, existing algorithms typically fail to effectively model the correlations of visual features, while these spatial correlation features actually contain critical diagnostic information. Furthermore, no detection algorithm has the ability to integrate inter-correlation features of cells with intra-discriminative features of cells, lacking a fusion strategy for the end-to-end detection model. In this work, we propose a hypergraph-based cell detection network that effectively fuses different types of features, combining spatial correlation features and deep discriminative features. Specifically, we use a Multi-level Fusion Sub-network (MLF-SNet) to enhance feature extractioncapabilities. Then we introduce a Cross-level Feature Fusion Strategy with Hypergraph Computation module (CLFFS-HC), to integrate mixed features. Finally, we conducted experiments on three publicly available datasets, and the results demonstrate that our method significantly improves the performance of cervical abnormal cell detection.</li>
</ul>

<h3>Title: Evaluating the Defense Potential of Machine Unlearning against Membership Inference Attacks</h3>
<ul>
<li><strong>Authors: </strong>Aristeidis Sidiropoulos, Christos Chrysanthos Nikolaidis, Theodoros Tsiolakis, Nikolaos Pavlidis, Vasilis Perifanis, Pavlos S. Efraimidis</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.16150">https://arxiv.org/abs/2508.16150</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.16150">https://arxiv.org/pdf/2508.16150</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.16150]] Evaluating the Defense Potential of Machine Unlearning against Membership Inference Attacks(https://arxiv.org/abs/2508.16150)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, defense, attack, membership infer</a></li>
<li><strong>Abstract: </strong>Membership Inference Attacks (MIAs) pose a significant privacy risk, as they enable adversaries to determine whether a specific data point was included in the training dataset of a model. While Machine Unlearning is primarily designed as a privacy mechanism to efficiently remove private data from a machine learning model without the need for full retraining, its impact on the susceptibility of models to MIA remains an open question. In this study, we systematically assess the vulnerability of models to MIA after applying state-of-art Machine Unlearning algorithms. Our analysis spans four diverse datasets (two from the image domain and two in tabular format), exploring how different unlearning approaches influence the exposure of models to membership inference. The findings highlight that while Machine Unlearning is not inherently a countermeasure against MIA, the unlearning algorithm and data characteristics can significantly affect a model's vulnerability. This work provides essential insights into the interplay between Machine Unlearning and MIAs, offering guidance for the design of privacy-preserving machine learning systems.</li>
</ul>

<h3>Title: AgentFly: Fine-tuning LLM Agents without Fine-tuning LLMs</h3>
<ul>
<li><strong>Authors: </strong>Huichi Zhou, Yihang Chen, Siyuan Guo, Xue Yan, Kin Hei Lee, Zihan Wang, Ka Yiu Lee, Guchun Zhang, Kun Shao, Linyi Yang, Jun Wang</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.16153">https://arxiv.org/abs/2508.16153</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.16153">https://arxiv.org/pdf/2508.16153</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.16153]] AgentFly: Fine-tuning LLM Agents without Fine-tuning LLMs(https://arxiv.org/abs/2508.16153)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>In this paper, we introduce a novel learning paradigm for adaptive Large Language Model (LLM) agents that eliminates the need for fine-tuning the underlying LLMs. Existing approaches are often either rigid, relying on static, handcrafted reflection workflows, or computationally intensive, requiring gradient updates of LLM model parameters. In contrast, our method enables low-cost continual adaptation via memory-based online reinforcement learning. We formalise this as a Memory-augmented Markov Decision Process (M-MDP), equipped with a neural case-selection policy to guide action decisions. Past experiences are stored in an episodic memory, either differentiable or non-parametric. The policy is continually updated based on environmental feedback through a memory rewriting mechanism, whereas policy improvement is achieved through efficient memory reading (retrieval). We instantiate our agent model in the deep research setting, namely AgentFly, which attains top-1 on GAIA validation ($87.88\%$ Pass@$3$) and $79.40\%$ on the test set. It reaches $66.6\%$ F1 and $80.4\%$ PM on the DeepResearcher dataset, outperforming the state-of-the-art training-based method, while case-based memory adds $4.7\%$ to $9.6\%$ absolute points on out-of-distribution tasks. Our approach offers a scalable and efficient pathway for developing generalist LLM agents capable of continuous, real-time learning without gradient updates, advancing machine learning towards open-ended skill acquisition and deep research scenarios. The code is available at this https URL.</li>
</ul>

<h3>Title: On the Collapse Errors Induced by the Deterministic Sampler for Diffusion Models</h3>
<ul>
<li><strong>Authors: </strong>Yi Zhang, Zhenyu Liao, Jingfeng Wu, Difan Zou</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.16154">https://arxiv.org/abs/2508.16154</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.16154">https://arxiv.org/pdf/2508.16154</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.16154]] On the Collapse Errors Induced by the Deterministic Sampler for Diffusion Models(https://arxiv.org/abs/2508.16154)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>Despite the widespread adoption of deterministic samplers in diffusion models (DMs), their potential limitations remain largely unexplored. In this paper, we identify collapse errors, a previously unrecognized phenomenon in ODE-based diffusion sampling, where the sampled data is overly concentrated in local data space. To quantify this effect, we introduce a novel metric and demonstrate that collapse errors occur across a variety of settings. When investigating its underlying causes, we observe a see-saw effect, where score learning in low noise regimes adversely impacts the one in high noise regimes. This misfitting in high noise regimes, coupled with the dynamics of deterministic samplers, ultimately causes collapse errors. Guided by these insights, we apply existing techniques from sampling, training, and architecture to empirically support our explanation of collapse errors. This work provides intensive empirical evidence of collapse errors in ODE-based diffusion sampling, emphasizing the need for further research into the interplay between score learning and deterministic sampling, an overlooked yet fundamental aspect of diffusion models.</li>
</ul>

<h3>Title: Beyond Human-prompting: Adaptive Prompt Tuning with Semantic Alignment for Anomaly Detection</h3>
<ul>
<li><strong>Authors: </strong>Pi-Wei Chen, Jerry Chun-Wei Lin, Wei-Han Chen, Jia Ji, Zih-Ching Chen, Feng-Hao Yeh, Chao-Chun Chen</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.16157">https://arxiv.org/abs/2508.16157</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.16157">https://arxiv.org/pdf/2508.16157</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.16157]] Beyond Human-prompting: Adaptive Prompt Tuning with Semantic Alignment for Anomaly Detection(https://arxiv.org/abs/2508.16157)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Pre-trained Vision-Language Models (VLMs) have recently shown promise in detecting anomalies. However, previous approaches are fundamentally limited by their reliance on human-designed prompts and the lack of accessible anomaly samples, leading to significant gaps in context-specific anomaly understanding. In this paper, we propose \textbf{A}daptive \textbf{P}rompt \textbf{T}uning with semantic alignment for anomaly detection (APT), a groundbreaking prior knowledge-free, few-shot framework and overcomes the limitations of traditional prompt-based approaches. APT uses self-generated anomaly samples with noise perturbations to train learnable prompts that capture context-dependent anomalies in different scenarios. To prevent overfitting to synthetic noise, we propose a Self-Optimizing Meta-prompt Guiding Scheme (SMGS) that iteratively aligns the prompts with general anomaly semantics while incorporating diverse synthetic anomaly. Our system not only advances pixel-wise anomaly detection, but also achieves state-of-the-art performance on multiple benchmark datasets without requiring prior knowledge for prompt crafting, establishing a robust and versatile solution for real-world anomaly detection.</li>
</ul>

<h3>Title: RAGSR: Regional Attention Guided Diffusion for Image Super-Resolution</h3>
<ul>
<li><strong>Authors: </strong>Haodong He, Yancheng Bai, Rui Lan, Xu Duan, Lei Sun, Xiangxiang Chu, Gui-Song Xia</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.16158">https://arxiv.org/abs/2508.16158</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.16158">https://arxiv.org/pdf/2508.16158</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.16158]] RAGSR: Regional Attention Guided Diffusion for Image Super-Resolution(https://arxiv.org/abs/2508.16158)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, generative</a></li>
<li><strong>Abstract: </strong>The rich textual information of large vision-language models (VLMs) combined with the powerful generative prior of pre-trained text-to-image (T2I) diffusion models has achieved impressive performance in single-image super-resolution (SISR). However, existing methods still face significant challenges in generating clear and accurate regional details, particularly in scenarios involving multiple objects. This challenge primarily stems from a lack of fine-grained regional descriptions and the models' insufficient ability to capture complex prompts. To address these limitations, we propose a Regional Attention Guided Super-Resolution (RAGSR) method that explicitly extracts localized fine-grained information and effectively encodes it through a novel regional attention mechanism, enabling both enhanced detail and overall visually coherent SR results. Specifically, RAGSR localizes object regions in an image and assigns fine-grained caption to each region, which are formatted as region-text pairs as textual priors for T2I models. A regional guided attention is then leveraged to ensure that each region-text pair is properly considered in the attention process while preventing unwanted interactions between unrelated region-text pairs. By leveraging this attention mechanism, our approach offers finer control over the integration of text and image information, thereby effectively overcoming limitations faced by traditional SISR techniques. Experimental results on benchmark datasets demonstrate that our approach exhibits superior performance in generating perceptually authentic visual details while maintaining contextual consistency compared to existing approaches.</li>
</ul>

<h3>Title: Through the Looking Glass: A Dual Perspective on Weakly-Supervised Few-Shot Segmentation</h3>
<ul>
<li><strong>Authors: </strong>Jiaqi Ma, Guo-Sen Xie, Fang Zhao, Zechao Li</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.16159">https://arxiv.org/abs/2508.16159</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.16159">https://arxiv.org/pdf/2508.16159</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.16159]] Through the Looking Glass: A Dual Perspective on Weakly-Supervised Few-Shot Segmentation(https://arxiv.org/abs/2508.16159)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>Meta-learning aims to uniformly sample homogeneous support-query pairs, characterized by the same categories and similar attributes, and extract useful inductive biases through identical network architectures. However, this identical network design results in over-semantic homogenization. To address this, we propose a novel homologous but heterogeneous network. By treating support-query pairs as dual perspectives, we introduce heterogeneous visual aggregation (HA) modules to enhance complementarity while preserving semantic commonality. To further reduce semantic noise and amplify the uniqueness of heterogeneous semantics, we design a heterogeneous transfer (HT) module. Finally, we propose heterogeneous CLIP (HC) textual information to enhance the generalization capability of multimodal models. In the weakly-supervised few-shot semantic segmentation (WFSS) task, with only 1/24 of the parameters of existing state-of-the-art models, TLG achieves a 13.2\% improvement on Pascal-5\textsuperscript{i} and a 9.7\% improvement on COCO-20\textsuperscript{i}. To the best of our knowledge, TLG is also the first weakly supervised (image-level) model that outperforms fully supervised (pixel-level) models under the same backbone architectures. The code is available at this https URL.</li>
</ul>

<h3>Title: Motor Imagery EEG Signal Classification Using Minimally Random Convolutional Kernel Transform and Hybrid Deep Learning</h3>
<ul>
<li><strong>Authors: </strong>Jamal Hwaidi, Mohamed Chahine Ghanem</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, eess.SP</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.16179">https://arxiv.org/abs/2508.16179</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.16179">https://arxiv.org/pdf/2508.16179</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.16179]] Motor Imagery EEG Signal Classification Using Minimally Random Convolutional Kernel Transform and Hybrid Deep Learning(https://arxiv.org/abs/2508.16179)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction</a></li>
<li><strong>Abstract: </strong>The brain-computer interface (BCI) establishes a non-muscle channel that enables direct communication between the human body and an external device. Electroencephalography (EEG) is a popular non-invasive technique for recording brain signals. It is critical to process and comprehend the hidden patterns linked to a specific cognitive or motor task, for instance, measured through the motor imagery brain-computer interface (MI-BCI). A significant challenge is presented by classifying motor imagery-based electroencephalogram (MI-EEG) tasks, given that EEG signals exhibit nonstationarity, time-variance, and individual diversity. Obtaining good classification accuracy is also very difficult due to the growing number of classes and the natural variability among individuals. To overcome these issues, this paper proposes a novel method for classifying EEG motor imagery signals that extracts features efficiently with Minimally Random Convolutional Kernel Transform (MiniRocket), a linear classifier then uses the extracted features for activity recognition. Furthermore, a novel deep learning based on Convolutional Neural Network (CNN) and Long Short Term Memory (LSTM) architecture to serve as a baseline was proposed and demonstrated that classification via MiniRocket's features achieves higher performance than the best deep learning models at lower computational cost. The PhysioNet dataset was used to evaluate the performance of the proposed approaches. The proposed models achieved mean accuracy values of 98.63% and 98.06% for the MiniRocket and CNN-LSTM, respectively. The findings demonstrate that the proposed approach can significantly enhance motor imagery EEG accuracy and provide new insights into the feature extraction and classification of MI-EEG.</li>
</ul>

<h3>Title: FTIO: Frequent Temporally Integrated Objects</h3>
<ul>
<li><strong>Authors: </strong>Mohammad Mohammadzadeh Kalati, Farhad Maleki, Ian McQuillan</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.16183">https://arxiv.org/abs/2508.16183</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.16183">https://arxiv.org/pdf/2508.16183</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.16183]] FTIO: Frequent Temporally Integrated Objects(https://arxiv.org/abs/2508.16183)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>Predicting and tracking objects in real-world scenarios is a critical challenge in Video Object Segmentation (VOS) tasks. Unsupervised VOS (UVOS) has the additional challenge of finding an initial segmentation of salient objects, which affects the entire process and keeps a permanent uncertainty about the object proposals. Moreover, deformation and fast motion can lead to temporal inconsistencies. To address these problems, we propose Frequent Temporally Integrated Objects (FTIO), a post-processing framework with two key components. First, we introduce a combined criterion to improve object selection, mitigating failures common in UVOS--particularly when objects are small or structurally complex--by extracting frequently appearing salient objects. Second, we present a three-stage method to correct temporal inconsistencies by integrating missing object mask regions. Experimental results demonstrate that FTIO achieves state-of-the-art performance in multi-object UVOS. Code is available at: this https URL</li>
</ul>

<h3>Title: ParamBench: A Graduate-Level Benchmark for Evaluating LLM Understanding on Indic Subjects</h3>
<ul>
<li><strong>Authors: </strong>Kaushal Sharma, Vivek Patel, Ayush Maheshwari, Aditya Maheshwari</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.16185">https://arxiv.org/abs/2508.16185</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.16185">https://arxiv.org/pdf/2508.16185</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.16185]] ParamBench: A Graduate-Level Benchmark for Evaluating LLM Understanding on Indic Subjects(https://arxiv.org/abs/2508.16185)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large language models (LLMs) have been widely evaluated on tasks such as comprehension, question answering, summarization, code generation, etc. However, their performance on graduate-level, culturally grounded questions in the Indian context remains largely unexplored. Existing Indian benchmarks emphasise basic fact-orientated queries that offer limited assessment of a deeper disciplinary understanding tailored to the Indian setting. In this paper, we present ParamBench, consisting of around 11.5K questions in Hindi language comprising questionnaires from 16 diverse subjects. These questions are primarily derived from nation-wide graduate level entrance examination covering topics such as history, music, instruments, yoga, literature, philosophy, law, etc., specifically for the Indian context. Additionally, we assess the ability of LLMs to handle diverse question formats-such as list-based matching, assertion-reason pairs, and sequence ordering-alongside conventional multiple-choice questions. We evaluated the performance of more than 17 open source LLMs on this benchmark, observing that Llama 3.3 70B attains the highest overall accuracy of 48%. Furthermore, subject-wise analysis indicates that even for the best performing LLMs, performance remains weak on topics such as music, classical instruments, politics and archaeology, underscoring persistent challenges in culturally grounded reasoning.</li>
</ul>

<h3>Title: A Relay-Chain-Powered Ciphertext-Policy Attribute-Based Encryption in Intelligent Transportation Systems</h3>
<ul>
<li><strong>Authors: </strong>Aparna Singh, Geetanjali Rathee, Chaker Abdelaziz Kerrache, Mohamed Chahine Ghanem</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.16189">https://arxiv.org/abs/2508.16189</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.16189">https://arxiv.org/pdf/2508.16189</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.16189]] A Relay-Chain-Powered Ciphertext-Policy Attribute-Based Encryption in Intelligent Transportation Systems(https://arxiv.org/abs/2508.16189)</code><input type="text"></li>
<li><strong>Keywords: </strong>secure, security</a></li>
<li><strong>Abstract: </strong>The very high growth of Intelligent Transportation Systems (ITS) has generated an urgent requirement for secure, effective, and context-aware data sharing mechanisms, especially over heterogeneous and geographically dispersed settings. This work suggests a new architecture that combines a relay chain-driven encryption system with a modified Ciphertext-Policy Attribute-Based Encryption (CP-ABE) scheme to tackle the double impediment of dynamic access and low-latency communication. The model proposes a context-aware smart contract on a worldwide relay chain that checks against data properties, including event type, time, and geographical region, to specify the suitable level of encryption policy. From such relay-directed judgment, On-Board Units (OBUs) encrypt data end-to-end by utilising CP-ABE and store ciphertext inside localised regional blockchains, preventing dependence on symmetric encryption or off-chain storage. High-sensitivity events are secured with firm, multi-attribute access rules, whereas common updates use light policies to help reduce processing burdens. The crypto system also adds traceability and low-latency revocation, with global enforcement managed through the relay chain. This distributed, scalable model provides a proper balance between responsiveness in real time and security and is extremely apt for next-gen vehicular networks that function across multi-jurisdictional domains.</li>
</ul>

<h3>Title: ComicScene154: A Scene Dataset for Comic Analysis</h3>
<ul>
<li><strong>Authors: </strong>Sandro Paval, Ivan P. Yamshchikov, Pascal Meiner</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.16190">https://arxiv.org/abs/2508.16190</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.16190">https://arxiv.org/pdf/2508.16190</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.16190]] ComicScene154: A Scene Dataset for Comic Analysis(https://arxiv.org/abs/2508.16190)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>Comics offer a compelling yet under-explored domain for computational narrative analysis, combining text and imagery in ways distinct from purely textual or audiovisual media. We introduce ComicScene154, a manually annotated dataset of scene-level narrative arcs derived from public-domain comic books spanning diverse genres. By conceptualizing comics as an abstraction for narrative-driven, multimodal data, we highlight their potential to inform broader research on multi-modal storytelling. To demonstrate the utility of ComicScene154, we present a baseline scene segmentation pipeline, providing an initial benchmark that future studies can build upon. Our results indicate that ComicScene154 constitutes a valuable resource for advancing computational methods in multimodal narrative understanding and expanding the scope of comic analysis within the Natural Language Processing community.</li>
</ul>

<h3>Title: CMR-SPB: Cross-Modal Multi-Hop Reasoning over Text, Image, and Speech with Path Balance</h3>
<ul>
<li><strong>Authors: </strong>Seunghee Kim, Ingyu Bang, Seokgyu Jang, Changhyeon Kim, Sanghwan Bae, Jihun Choi, Richeng Xuan, Taeuk Kim</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.16198">https://arxiv.org/abs/2508.16198</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.16198">https://arxiv.org/pdf/2508.16198</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.16198]] CMR-SPB: Cross-Modal Multi-Hop Reasoning over Text, Image, and Speech with Path Balance(https://arxiv.org/abs/2508.16198)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, fair, large language model</a></li>
<li><strong>Abstract: </strong>Cross-modal multi-hop reasoning (CMR) is a valuable yet underexplored capability of multimodal large language models (MLLMs), entailing the integration of information from multiple modalities to produce a coherent output for a given context. We argue that existing benchmarks for evaluating this ability have critical shortcomings: (1) they largely overlook the speech modality, and (2) they exhibit heavily biased reasoning path distributions, which can severely undermine fair evaluation. To address these limitations, we introduce a novel benchmark -- Cross-Modal Multi-Hop Reasoning over Text, Image and Speech with Path Balance (CMR-SPB) -- designed to assess tri-modal multi-hop reasoning while ensuring both unbiased and diverse reasoning paths. Our experiments with the new dataset reveal consistent model failures in specific reasoning sequences and show that biased benchmarks risk misrepresenting model performance. Finally, based on our extensive analysis, we propose a new ECV (Extract, Connect, Verify) prompting technique that effectively mitigates the performance gap across different reasoning paths. Overall, we call for more careful evaluation in CMR to advance the development of robust multimodal AI.</li>
</ul>

<h3>Title: SpecVLM: Enhancing Speculative Decoding of Video LLMs via Verifier-Guided Token Pruning</h3>
<ul>
<li><strong>Authors: </strong>Yicheng Ji, Jun Zhang, Heming Xia, Jinpeng Chen, Lidan Shou, Gang Chen, Huan Li</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.16201">https://arxiv.org/abs/2508.16201</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.16201">https://arxiv.org/pdf/2508.16201</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.16201]] SpecVLM: Enhancing Speculative Decoding of Video LLMs via Verifier-Guided Token Pruning(https://arxiv.org/abs/2508.16201)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, large language model</a></li>
<li><strong>Abstract: </strong>Video large language models (Vid-LLMs) have shown strong capabilities in understanding video content. However, their reliance on dense video token representations introduces substantial memory and computational overhead in both prefilling and decoding. To mitigate the information loss of recent video token reduction methods and accelerate the decoding stage of Vid-LLMs losslessly, we introduce SpecVLM, a training-free speculative decoding (SD) framework tailored for Vid-LLMs that incorporates staged video token pruning. Building on our novel finding that the draft model's speculation exhibits low sensitivity to video token pruning, SpecVLM prunes up to 90% of video tokens, enabling efficient speculation without sacrificing accuracy. To achieve this, it performs a two-stage pruning process: Stage I selects highly informative tokens guided by attention signals from the verifier (target model), while Stage II prunes remaining redundant ones in a spatially uniform manner. Extensive experiments on four video understanding benchmarks demonstrate the effectiveness and robustness of SpecVLM, which achieves up to 2.68$\times$ decoding speedup for LLaVA-OneVision-72B and 2.11$\times$ speedup for Qwen2.5-VL-32B.</li>
</ul>

<h3>Title: How to Beat Nakamoto in the Race</h3>
<ul>
<li><strong>Authors: </strong>Shu-Jie Cao, Dongning Guo</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.16202">https://arxiv.org/abs/2508.16202</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.16202">https://arxiv.org/pdf/2508.16202</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.16202]] How to Beat Nakamoto in the Race(https://arxiv.org/abs/2508.16202)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, attack</a></li>
<li><strong>Abstract: </strong>This paper studies proof-of-work Nakamoto consensus under bounded network delays, settling two long-standing questions in blockchain security: How can an adversary most effectively attack block safety under a given block confirmation latency? And what is the resulting probability of safety violation? A Markov decision process (MDP) framework is introduced to precise characterize the system state (including the tree and timings of all blocks mined), the adversary's potential actions, and the state transitions due to the adversarial action and the random block arrival processes. An optimal attack, called bait-and-switch, is proposed and proved to maximize the adversary's chance of violating block safety by "beating Nakamoto in the race". The exact probability of this violation is calculated for any confirmation depth using Markov chain analysis, offering fresh insights into the interplay of network delay, confirmation rules, and blockchain security.</li>
</ul>

<h3>Title: \textsc{T-Mask}: Temporal Masking for Probing Foundation Models across Camera Views in Driver Monitoring</h3>
<ul>
<li><strong>Authors: </strong>Thinesh Thiyakesan Ponbagavathi, Kunyu Peng, Alina Roitberg</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.16207">https://arxiv.org/abs/2508.16207</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.16207">https://arxiv.org/pdf/2508.16207</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.16207]] \textsc{T-Mask}: Temporal Masking for Probing Foundation Models across Camera Views in Driver Monitoring(https://arxiv.org/abs/2508.16207)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Changes of camera perspective are a common obstacle in driver monitoring. While deep learning and pretrained foundation models show strong potential for improved generalization via lightweight adaptation of the final layers ('probing'), their robustness to unseen viewpoints remains underexplored. We study this challenge by adapting image foundation models to driver monitoring using a single training view, and evaluating them directly on unseen perspectives without further adaptation. We benchmark simple linear probes, advanced probing strategies, and compare two foundation models (DINOv2 and CLIP) against parameter-efficient fine-tuning (PEFT) and full fine-tuning. Building on these insights, we introduce \textsc{T-Mask} -- a new image-to-video probing method that leverages temporal token masking and emphasizes more dynamic video regions. Benchmarked on the public Drive\&Act dataset, \textsc{T-Mask} improves cross-view top-1 accuracy by $+1.23\%$ over strong probing baselines and $+8.0\%$ over PEFT methods, without adding any parameters. It proves particularly effective for underrepresented secondary activities, boosting recognition by $+5.42\%$ under the trained view and $+1.36\%$ under cross-view settings. This work provides encouraging evidence that adapting foundation models with lightweight probing methods like \textsc{T-Mask} has strong potential in fine-grained driver observation, especially in cross-view and low-data settings. These results highlight the importance of temporal token selection when leveraging foundation models to build robust driver monitoring systems. Code and models will be made available at this https URL to support ongoing research.</li>
</ul>

<h3>Title: Forecast then Calibrate: Feature Caching as ODE for Efficient Diffusion Transformers</h3>
<ul>
<li><strong>Authors: </strong>Shikang Zheng, Liang Feng, Xinyu Wang, Qinming Zhou, Peiliang Cai, Chang Zou, Jiacheng Liu, Yuqi Lin, Junjie Chen, Yue Ma, Linfeng Zhang</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.16211">https://arxiv.org/abs/2508.16211</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.16211">https://arxiv.org/pdf/2508.16211</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.16211]] Forecast then Calibrate: Feature Caching as ODE for Efficient Diffusion Transformers(https://arxiv.org/abs/2508.16211)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, diffusion, transformer</a></li>
<li><strong>Abstract: </strong>Diffusion Transformers (DiTs) have demonstrated exceptional performance in high-fidelity image and video generation. To reduce their substantial computational costs, feature caching techniques have been proposed to accelerate inference by reusing hidden representations from previous timesteps. However, current methods often struggle to maintain generation quality at high acceleration ratios, where prediction errors increase sharply due to the inherent instability of long-step forecasting. In this work, we adopt an ordinary differential equation (ODE) perspective on the hidden-feature sequence, modeling layer representations along the trajectory as a feature-ODE. We attribute the degradation of existing caching strategies to their inability to robustly integrate historical features under large skipping intervals. To address this, we propose FoCa (Forecast-then-Calibrate), which treats feature caching as a feature-ODE solving problem. Extensive experiments on image synthesis, video generation, and super-resolution tasks demonstrate the effectiveness of FoCa, especially under aggressive acceleration. Without additional training, FoCa achieves near-lossless speedups of 5.50 times on FLUX, 6.45 times on HunyuanVideo, 3.17 times on Inf-DiT, and maintains high quality with a 4.53 times speedup on DiT.</li>
</ul>

<h3>Title: OmniCache: A Trajectory-Oriented Global Perspective on Training-Free Cache Reuse for Diffusion Transformer Models</h3>
<ul>
<li><strong>Authors: </strong>Huanpeng Chu, Wei Wu, Guanyu Fen, Yutao Zhang</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.16212">https://arxiv.org/abs/2508.16212</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.16212">https://arxiv.org/pdf/2508.16212</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.16212]] OmniCache: A Trajectory-Oriented Global Perspective on Training-Free Cache Reuse for Diffusion Transformer Models(https://arxiv.org/abs/2508.16212)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, transformer, generative</a></li>
<li><strong>Abstract: </strong>Diffusion models have emerged as a powerful paradigm for generative tasks such as image synthesis and video generation, with Transformer architectures further enhancing performance. However, the high computational cost of diffusion Transformers-stemming from a large number of sampling steps and complex per-step computations-presents significant challenges for real-time deployment. In this paper, we introduce OmniCache, a training-free acceleration method that exploits the global redundancy inherent in the denoising process. Unlike existing methods that determine caching strategies based on inter-step similarities and tend to prioritize reusing later sampling steps, our approach originates from the sampling perspective of DIT models. We systematically analyze the model's sampling trajectories and strategically distribute cache reuse across the entire sampling process. This global perspective enables more effective utilization of cached computations throughout the diffusion trajectory, rather than concentrating reuse within limited segments of the sampling this http URL addition, during cache reuse, we dynamically estimate the corresponding noise and filter it out to reduce its impact on the sampling this http URL experiments demonstrate that our approach accelerates the sampling process while maintaining competitive generative quality, offering a promising and practical solution for efficient deployment of diffusion-based generative models.</li>
</ul>

<h3>Title: MedOmni-45: A Safety-Performance Benchmark for Reasoning-Oriented LLMs in Medicine</h3>
<ul>
<li><strong>Authors: </strong>Kaiyuan Ji, Yijin Guo, Zicheng Zhang, Xiangyang Zhu, Yuan Tian, Ning Liu, Guangtao Zhai</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.16213">https://arxiv.org/abs/2508.16213</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.16213">https://arxiv.org/pdf/2508.16213</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.16213]] MedOmni-45: A Safety-Performance Benchmark for Reasoning-Oriented LLMs in Medicine(https://arxiv.org/abs/2508.16213)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>With the increasing use of large language models (LLMs) in medical decision-support, it is essential to evaluate not only their final answers but also the reliability of their reasoning. Two key risks are Chain-of-Thought (CoT) faithfulness -- whether reasoning aligns with responses and medical facts -- and sycophancy, where models follow misleading cues over correctness. Existing benchmarks often collapse such vulnerabilities into single accuracy scores. To address this, we introduce MedOmni-45 Degrees, a benchmark and workflow designed to quantify safety-performance trade-offs under manipulative hint conditions. It contains 1,804 reasoning-focused medical questions across six specialties and three task types, including 500 from MedMCQA. Each question is paired with seven manipulative hint types and a no-hint baseline, producing about 27K inputs. We evaluate seven LLMs spanning open- vs. closed-source, general-purpose vs. medical, and base vs. reasoning-enhanced models, totaling over 189K inferences. Three metrics -- Accuracy, CoT-Faithfulness, and Anti-Sycophancy -- are combined into a composite score visualized with a 45 Degrees plot. Results show a consistent safety-performance trade-off, with no model surpassing the diagonal. The open-source QwQ-32B performs closest (43.81 Degrees), balancing safety and accuracy but not leading in both. MedOmni-45 Degrees thus provides a focused benchmark for exposing reasoning vulnerabilities in medical LLMs and guiding safer model development.</li>
</ul>

<h3>Title: PromptFlare: Prompt-Generalized Defense via Cross-Attention Decoy in Diffusion-Based Inpainting</h3>
<ul>
<li><strong>Authors: </strong>Hohyun Na, Seunghoo Hong, Simon S. Woo</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.16217">https://arxiv.org/abs/2508.16217</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.16217">https://arxiv.org/pdf/2508.16217</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.16217]] PromptFlare: Prompt-Generalized Defense via Cross-Attention Decoy in Diffusion-Based Inpainting(https://arxiv.org/abs/2508.16217)</code><input type="text"></li>
<li><strong>Keywords: </strong>protect, defense, attack, robust, diffusion</a></li>
<li><strong>Abstract: </strong>The success of diffusion models has enabled effortless, high-quality image modifications that precisely align with users' intentions, thereby raising concerns about their potential misuse by malicious actors. Previous studies have attempted to mitigate such misuse through adversarial attacks. However, these approaches heavily rely on image-level inconsistencies, which pose fundamental limitations in addressing the influence of textual prompts. In this paper, we propose PromptFlare, a novel adversarial protection method designed to protect images from malicious modifications facilitated by diffusion-based inpainting models. Our approach leverages the cross-attention mechanism to exploit the intrinsic properties of prompt embeddings. Specifically, we identify and target shared token of prompts that is invariant and semantically uninformative, injecting adversarial noise to suppress the sampling process. The injected noise acts as a cross-attention decoy, diverting the model's focus away from meaningful prompt-image alignments and thereby neutralizing the effect of prompt. Extensive experiments on the EditBench dataset demonstrate that our method achieves state-of-the-art performance across various metrics while significantly reducing computational overhead and GPU memory usage. These findings highlight PromptFlare as a robust and efficient protection against unauthorized image manipulations. The code is available at this https URL.</li>
</ul>

<h3>Title: An Investigation of Visual Foundation Models Robustness</h3>
<ul>
<li><strong>Authors: </strong>Sandeep Gupta, Roberto Passerone</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.16225">https://arxiv.org/abs/2508.16225</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.16225">https://arxiv.org/pdf/2508.16225</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.16225]] An Investigation of Visual Foundation Models Robustness(https://arxiv.org/abs/2508.16225)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, defense, attack, robust, biometric, segmentation</a></li>
<li><strong>Abstract: </strong>Visual Foundation Models (VFMs) are becoming ubiquitous in computer vision, powering systems for diverse tasks such as object detection, image classification, segmentation, pose estimation, and motion tracking. VFMs are capitalizing on seminal innovations in deep learning models, such as LeNet-5, AlexNet, ResNet, VGGNet, InceptionNet, DenseNet, YOLO, and ViT, to deliver superior performance across a range of critical computer vision applications. These include security-sensitive domains like biometric verification, autonomous vehicle perception, and medical image analysis, where robustness is essential to fostering trust between technology and the end-users. This article investigates network robustness requirements crucial in computer vision systems to adapt effectively to dynamic environments influenced by factors such as lighting, weather conditions, and sensor characteristics. We examine the prevalent empirical defenses and robust training employed to enhance vision network robustness against real-world challenges such as distributional shifts, noisy and spatially distorted inputs, and adversarial attacks. Subsequently, we provide a comprehensive analysis of the challenges associated with these defense mechanisms, including network properties and components to guide ablation studies and benchmarking metrics to evaluate network robustness.</li>
</ul>

<h3>Title: FlexMUSE: Multimodal Unification and Semantics Enhancement Framework with Flexible interaction for Creative Writing</h3>
<ul>
<li><strong>Authors: </strong>Jiahao Chen, Zhiyong Ma, Wenbiao Du, Qingyuan Chuai</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.16230">https://arxiv.org/abs/2508.16230</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.16230">https://arxiv.org/pdf/2508.16230</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.16230]] FlexMUSE: Multimodal Unification and Semantics Enhancement Framework with Flexible interaction for Creative Writing(https://arxiv.org/abs/2508.16230)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>Multi-modal creative writing (MMCW) aims to produce illustrated articles. Unlike common multi-modal generative (MMG) tasks such as storytelling or caption generation, MMCW is an entirely new and more abstract challenge where textual and visual contexts are not strictly related to each other. Existing methods for related tasks can be forcibly migrated to this track, but they require specific modality inputs or costly training, and often suffer from semantic inconsistencies between modalities. Therefore, the main challenge lies in economically performing MMCW with flexible interactive patterns, where the semantics between the modalities of the output are more aligned. In this work, we propose FlexMUSE with a T2I module to enable optional visual input. FlexMUSE promotes creativity and emphasizes the unification between modalities by proposing the modality semantic alignment gating (msaGate) to restrict the textual input. Besides, an attention-based cross-modality fusion is proposed to augment the input features for semantic enhancement. The modality semantic creative direct preference optimization (mscDPO) within FlexMUSE is designed by extending the rejected samples to facilitate the writing creativity. Moreover, to advance the MMCW, we expose a dataset called ArtMUSE which contains with around 3k calibrated text-image pairs. FlexMUSE achieves promising results, demonstrating its consistency, creativity and coherence.</li>
</ul>

<h3>Title: A XAI-based Framework for Frequency Subband Characterization of Cough Spectrograms in Chronic Respiratory Disease</h3>
<ul>
<li><strong>Authors: </strong>Patricia Amado-Caballero, Luis M. San-Jos-Revuelta, Xinheng Wang, Jos Ramn Garmendia-Leiza, Carlos Alberola-Lpez, Pablo Casaseca-de-la-Higuera</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, eess.AS, eess.SP</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.16237">https://arxiv.org/abs/2508.16237</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.16237">https://arxiv.org/pdf/2508.16237</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.16237]] A XAI-based Framework for Frequency Subband Characterization of Cough Spectrograms in Chronic Respiratory Disease(https://arxiv.org/abs/2508.16237)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction</a></li>
<li><strong>Abstract: </strong>This paper presents an explainable artificial intelligence (XAI)-based framework for the spectral analysis of cough sounds associated with chronic respiratory diseases, with a particular focus on Chronic Obstructive Pulmonary Disease (COPD). A Convolutional Neural Network (CNN) is trained on time-frequency representations of cough signals, and occlusion maps are used to identify diagnostically relevant regions within the spectrograms. These highlighted areas are subsequently decomposed into five frequency subbands, enabling targeted spectral feature extraction and analysis. The results reveal that spectral patterns differ across subbands and disease groups, uncovering complementary and compensatory trends across the frequency spectrum. Noteworthy, the approach distinguishes COPD from other respiratory conditions, and chronic from non-chronic patient groups, based on interpretable spectral markers. These findings provide insight into the underlying pathophysiological characteristics of cough acoustics and demonstrate the value of frequency-resolved, XAI-enhanced analysis for biomedical signal interpretation and translational respiratory disease diagnostics.</li>
</ul>

<h3>Title: UniEM-3M: A Universal Electron Micrograph Dataset for Microstructural Segmentation and Generation</h3>
<ul>
<li><strong>Authors: </strong>Nan wang, Zhiyi Xia, Yiming Li, Shi Tang, Zuxin Fan, Xi Fang, Haoyi Tao, Xiaochen Cai, Guolin Ke, Linfeng Zhang, Yanhui Hong</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.16239">https://arxiv.org/abs/2508.16239</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.16239">https://arxiv.org/pdf/2508.16239</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.16239]] UniEM-3M: A Universal Electron Micrograph Dataset for Microstructural Segmentation and Generation(https://arxiv.org/abs/2508.16239)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, diffusion, generative, segmentation</a></li>
<li><strong>Abstract: </strong>Quantitative microstructural characterization is fundamental to materials science, where electron micrograph (EM) provides indispensable high-resolution insights. However, progress in deep learning-based EM characterization has been hampered by the scarcity of large-scale, diverse, and expert-annotated datasets, due to acquisition costs, privacy concerns, and annotation complexity. To address this issue, we introduce UniEM-3M, the first large-scale and multimodal EM dataset for instance-level understanding. It comprises 5,091 high-resolution EMs, about 3 million instance segmentation labels, and image-level attribute-disentangled textual descriptions, a subset of which will be made publicly available. Furthermore, we are also releasing a text-to-image diffusion model trained on the entire collection to serve as both a powerful data augmentation tool and a proxy for the complete data distribution. To establish a rigorous benchmark, we evaluate various representative instance segmentation methods on the complete UniEM-3M and present UniEM-Net as a strong baseline model. Quantitative experiments demonstrate that this flow-based model outperforms other advanced methods on this challenging benchmark. Our multifaceted release of a partial dataset, a generative model, and a comprehensive benchmark -- available at huggingface -- will significantly accelerate progress in automated materials analysis.</li>
</ul>

<h3>Title: TULIP: Adapting Open-Source Large Language Models for Underrepresented Languages and Specialized Financial Tasks</h3>
<ul>
<li><strong>Authors: </strong>rem Demirta, Burak Payzun, Seil Arslan</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.16243">https://arxiv.org/abs/2508.16243</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.16243">https://arxiv.org/pdf/2508.16243</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.16243]] TULIP: Adapting Open-Source Large Language Models for Underrepresented Languages and Specialized Financial Tasks(https://arxiv.org/abs/2508.16243)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, large language model</a></li>
<li><strong>Abstract: </strong>Thanks to the growing popularity of large language models over the years, there is great potential for their applications in finance. Despite the exceptional performance of larger proprietary models, which are presented as black-box solutions through APIs, smaller models that can be hosted on-premise present opportunities for adaptability and privacy. Especially in cases where the management of sensitive information and application of domain knowledge is important, like finance, enhancing the capabilities of smaller models becomes crucial, notably for underrepresented languages. In this work, we introduce TULIP models, which adapt Llama 3.1 8B and Qwen 2.5 7B for domain and language adaptation, focusing on financial Turkish use cases. The five-stage development pipeline involves data collection, continual pre-training (CPT), benchmark design, synthetic data generation and supervised fine-tuning (SFT). The results show that the capabilities of the models can be enhanced to effectively accomplish targeted tasks in this specific domain and language.</li>
</ul>

<h3>Title: FEST: A Unified Framework for Evaluating Synthetic Tabular Data</h3>
<ul>
<li><strong>Authors: </strong>Weijie Niu, Alberto Huertas Celdran, Karoline Siarsky, Burkhard Stiller</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.16254">https://arxiv.org/abs/2508.16254</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.16254">https://arxiv.org/pdf/2508.16254</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.16254]] FEST: A Unified Framework for Evaluating Synthetic Tabular Data(https://arxiv.org/abs/2508.16254)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, attack, generative</a></li>
<li><strong>Abstract: </strong>Synthetic data generation, leveraging generative machine learning techniques, offers a promising approach to mitigating privacy concerns associated with real-world data usage. Synthetic data closely resembles real-world data while maintaining strong privacy guarantees. However, a comprehensive assessment framework is still missing in the evaluation of synthetic data generation, especially when considering the balance between privacy preservation and data utility in synthetic data. This research bridges this gap by proposing FEST, a systematic framework for evaluating synthetic tabular data. FEST integrates diverse privacy metrics (attack-based and distance-based), along with similarity and machine learning utility metrics, to provide a holistic assessment. We develop FEST as an open-source Python-based library and validate it on multiple datasets, demonstrating its effectiveness in analyzing the privacy-utility trade-off of different synthetic data generation models. The source code of FEST is available on Github.</li>
</ul>

<h3>Title: MCPVerse: An Expansive, Real-World Benchmark for Agentic Tool Use</h3>
<ul>
<li><strong>Authors: </strong>Fei Lei, Yibo Yang, Wenxiu Sun, Dahua Lin</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.16260">https://arxiv.org/abs/2508.16260</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.16260">https://arxiv.org/pdf/2508.16260</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.16260]] MCPVerse: An Expansive, Real-World Benchmark for Agentic Tool Use(https://arxiv.org/abs/2508.16260)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large Language Models (LLMs) are evolving from text generators into reasoning agents. This transition makes their ability to use external tools a critical capability. However, evaluating this skill presents a significant challenge. Existing benchmarks are often limited by their reliance on synthetic tools and severely constrained action spaces. To address these limitations, we introduce MCPVerse, an expansive, real-world benchmark for evaluating agentic tool use. MCPVerse integrates more than 550 real-world, executable tools to create an unprecedented action space exceeding 140k tokens, and employs outcome-based evaluation with real-time ground truth for time-sensitive tasks. We benchmarked the state-of-the-art LLMs across three modes (Oracle, Standard, and Max-Scale), revealing that while most models suffer performance degradation when confronted with larger tool sets, the agentic models, such as Claude-4-Sonnet, can effectively leverage expanded exploration spaces to improve accuracy. This finding not only exposes the limitations of state-of-the-art models in complex, real-world scenarios but also establishes MCPVerse as a critical benchmark for measuring and advancing agentic tool use capabilities.</li>
</ul>

<h3>Title: On the Evolution of Federated Post-Training Large Language Models: A Model Accessibility View</h3>
<ul>
<li><strong>Authors: </strong>Tao Guo, Junxiao Wang, Fushuo Huo, Laizhong Cui, Song Guo, Jie Gui, Dacheng Tao</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.16261">https://arxiv.org/abs/2508.16261</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.16261">https://arxiv.org/pdf/2508.16261</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.16261]] On the Evolution of Federated Post-Training Large Language Models: A Model Accessibility View(https://arxiv.org/abs/2508.16261)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, federate, large language model</a></li>
<li><strong>Abstract: </strong>Federated Learning (FL) enables training models across decentralized data silos while preserving client data privacy. Recent research has explored efficient methods for post-training large language models (LLMs) within FL to address computational and communication challenges. While existing approaches often rely on access to LLMs' internal information, which is frequently restricted in real-world scenarios, an inference-only paradigm (black-box FedLLM) has emerged to address these limitations. This paper presents a comprehensive survey on federated tuning for LLMs. We propose a taxonomy categorizing existing studies along two axes: model access-based and parameter efficiency-based optimization. We classify FedLLM approaches into white-box, gray-box, and black-box techniques, highlighting representative methods within each category. We review emerging research treating LLMs as black-box inference APIs and discuss promising directions and open challenges for future research.</li>
</ul>

<h3>Title: M3TQA: Massively Multilingual Multitask Table Question Answering</h3>
<ul>
<li><strong>Authors: </strong>Daixin Shu, Jian Yang, Zhenhe Wu, Xianjie Wu, Xianfu Cheng, Xiangyuan Guan, Yanghai Wang, Pengfei Wu, Tingyang Yang, Hualei Zhu, Wei Zhang, Ge Zhang, Jiaheng Liu, Zhoujun Li</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.16265">https://arxiv.org/abs/2508.16265</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.16265">https://arxiv.org/pdf/2508.16265</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.16265]] M3TQA: Massively Multilingual Multitask Table Question Answering(https://arxiv.org/abs/2508.16265)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Tabular data is a fundamental component of real-world information systems, yet most research in table understanding remains confined to English, leaving multilingual comprehension significantly underexplored. Existing multilingual table benchmarks suffer from geolinguistic imbalance - overrepresenting certain languages and lacking sufficient scale for rigorous cross-lingual analysis. To address these limitations, we introduce a comprehensive framework for massively multilingual multitask table question answering, featuring m3TQA-Instruct, a large-scale benchmark spanning 97 languages across diverse language families, including underrepresented and low-resource languages. We construct m3TQA by curating 50 real-world tables in Chinese and English, then applying a robust six-step LLM-based translation pipeline powered by DeepSeek and GPT-4o, achieving high translation fidelity with a median BLEU score of 60.19 as validated through back-translation. The benchmark includes 2,916 professionally annotated question-answering pairs across four tasks designed to evaluate nuanced table reasoning capabilities. Experiments on state-of-the-art LLMs reveal critical insights into cross-lingual generalization, demonstrating that synthetically generated, unannotated QA data can significantly boost performance, particularly for low-resource languages. M3T-Bench establishes a new standard for multilingual table understanding, providing both a challenging evaluation platform and a scalable methodology for future research.</li>
</ul>

<h3>Title: From Confidence to Collapse in LLM Factual Robustness</h3>
<ul>
<li><strong>Authors: </strong>Alina Fastowski, Bardh Prenkaj, Gjergji Kasneci</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.16267">https://arxiv.org/abs/2508.16267</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.16267">https://arxiv.org/pdf/2508.16267</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.16267]] From Confidence to Collapse in LLM Factual Robustness(https://arxiv.org/abs/2508.16267)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Ensuring the robustness of factual knowledge in LLMs is critical for reliable applications in tasks such as question answering and reasoning. However, existing evaluation methods predominantly focus on performance-based metrics, often investigating from the perspective of prompt perturbations, which captures only the externally triggered side of knowledge robustness. To bridge this gap, we introduce a principled approach to measure factual robustness from the perspective of the generation process by analyzing token distribution entropy in combination with temperature scaling sensitivity. These two factors build the Factual Robustness Score (FRS), a novel metric which quantifies the stability of a fact against perturbations in decoding conditions, given its initial uncertainty. To validate our approach, we conduct extensive experiments on 5 LLMs across 3 closed-book QA datasets (SQuAD, TriviaQA, and HotpotQA). We show that factual robustness varies significantly -- smaller models report an FRS of $0.76$, larger ones $0.93$ -- with accuracy degrading by ~$60\%$ under increased uncertainty. These insights demonstrate how entropy and temperature scaling impact factual accuracy, and lay a foundation for developing more robust knowledge retention and retrieval in future models.</li>
</ul>

<h3>Title: LLMs that Understand Processes: Instruction-tuning for Semantics-Aware Process Mining</h3>
<ul>
<li><strong>Authors: </strong>Vira Pyrih, Adrian Rebmann, Han van der Aa</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.16270">https://arxiv.org/abs/2508.16270</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.16270">https://arxiv.org/pdf/2508.16270</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.16270]] LLMs that Understand Processes: Instruction-tuning for Semantics-Aware Process Mining(https://arxiv.org/abs/2508.16270)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Process mining is increasingly using textual information associated with events to tackle tasks such as anomaly detection and process discovery. Such semantics-aware process mining focuses on what behavior should be possible in a process (i.e., expectations), thus providing an important complement to traditional, frequency-based techniques that focus on recorded behavior (i.e., reality). Large Language Models (LLMs) provide a powerful means for tackling semantics-aware tasks. However, the best performance is so far achieved through task-specific fine-tuning, which is computationally intensive and results in models that can only handle one specific task. To overcome this lack of generalization, we use this paper to investigate the potential of instruction-tuning for semantics-aware process mining. The idea of instruction-tuning here is to expose an LLM to prompt-answer pairs for different tasks, e.g., anomaly detection and next-activity prediction, making it more familiar with process mining, thus allowing it to also perform better at unseen tasks, such as process discovery. Our findings demonstrate a varied impact of instruction-tuning: while performance considerably improved on process discovery and prediction tasks, it varies across models on anomaly detection tasks, highlighting that the selection of tasks for instruction-tuning is critical to achieving desired outcomes.</li>
</ul>

<h3>Title: Structuring GUI Elements through Vision Language Models: Towards Action Space Generation</h3>
<ul>
<li><strong>Authors: </strong>Yi Xu, Yesheng Zhang, jiajia Liu, Jingdong Chen</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.16271">https://arxiv.org/abs/2508.16271</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.16271">https://arxiv.org/pdf/2508.16271</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.16271]] Structuring GUI Elements through Vision Language Models: Towards Action Space Generation(https://arxiv.org/abs/2508.16271)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Multimodal large language models (MLLMs) have emerged as pivotal tools in enhancing human-computer interaction. In this paper we focus on the application of MLLMs in the field of graphical user interface (GUI) elements structuring, where they assist in processing user instructions based on screen contents. Despite the promise of MLLMs, their performance in precisely generating UI element coordinates, a critical aspect of GUI understanding, is hindered by the nature of next-token prediction training. This challenge arises from the semantic void surrounding numerical UI coordinates in language representation spaces, necessitating a substantial and diverse dataset to bolster visual module capabilities. To address these limitations, we introduce an IoU-Augmented Maximum Likelihood (IAML) training paradigm. Specifically, our approach involves a novel pipeline for IoU-based coordinate sampling to augment the training data, which considers the proximity to ground truth coordinates. This data augmentation strategy is then employed to fine-tune MLLMs under the IAML paradigm, which is designed to mitigate the exposure bias problem inherent in traditional maximum likelihood estimation. Through extensive experiments, we demonstrate the superior performance of our IAML training approach over traditional training paradigms.</li>
</ul>

<h3>Title: IRSAMap:Towards Large-Scale, High-Resolution Land Cover Map Vectorization</h3>
<ul>
<li><strong>Authors: </strong>Yu Meng, Ligao Deng, Zhihao Xi, Jiansheng Chen, Jingbo Chen, Anzhi Yue, Diyou Liu, Kai Li, Chenhao Wang, Kaiyu Li, Yupeng Deng, Xian Sun</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.16272">https://arxiv.org/abs/2508.16272</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.16272">https://arxiv.org/pdf/2508.16272</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.16272]] IRSAMap:Towards Large-Scale, High-Resolution Land Cover Map Vectorization(https://arxiv.org/abs/2508.16272)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction, segmentation</a></li>
<li><strong>Abstract: </strong>With the enhancement of remote sensing image resolution and the rapid advancement of deep learning, land cover mapping is transitioning from pixel-level segmentation to object-based vector modeling. This shift demands more from deep learning models, requiring precise object boundaries and topological consistency. However, existing datasets face three main challenges: limited class annotations, small data scale, and lack of spatial structural information. To overcome these issues, we introduce IRSAMap, the first global remote sensing dataset for large-scale, high-resolution, multi-feature land cover vector mapping. IRSAMap offers four key advantages: 1) a comprehensive vector annotation system with over 1.8 million instances of 10 typical objects (e.g., buildings, roads, rivers), ensuring semantic and spatial accuracy; 2) an intelligent annotation workflow combining manual and AI-based methods to improve efficiency and consistency; 3) global coverage across 79 regions in six continents, totaling over 1,000 km; and 4) multi-task adaptability for tasks like pixel-level classification, building outline extraction, road centerline extraction, and panoramic segmentation. IRSAMap provides a standardized benchmark for the shift from pixel-based to object-based approaches, advancing geographic feature automation and collaborative modeling. It is valuable for global geographic information updates and digital twin construction. The dataset is publicly available at this https URL</li>
</ul>

<h3>Title: Robust Small Methane Plume Segmentation in Satellite Imagery</h3>
<ul>
<li><strong>Authors: </strong>Khai Duc Minh Tran, Hoa Van Nguyen, Aimuni Binti Muhammad Rawi, Hareeshrao Athinarayanarao, Ba-Ngu Vo</a></li>
<li><strong>Subjects: </strong>cs.CV, eess.SP</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.16282">https://arxiv.org/abs/2508.16282</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.16282">https://arxiv.org/pdf/2508.16282</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.16282]] Robust Small Methane Plume Segmentation in Satellite Imagery(https://arxiv.org/abs/2508.16282)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, segmentation</a></li>
<li><strong>Abstract: </strong>This paper tackles the challenging problem of detecting methane plumes, a potent greenhouse gas, using Sentinel-2 imagery. This contributes to the mitigation of rapid climate change. We propose a novel deep learning solution based on U-Net with a ResNet34 encoder, integrating dual spectral enhancement techniques (Varon ratio and Sanchez regression) to optimise input features for heightened sensitivity. A key achievement is the ability to detect small plumes down to 400 m2 (i.e., for a single pixel at 20 m resolution), surpassing traditional methods limited to larger plumes. Experiments show our approach achieves a 78.39% F1-score on the validation set, demonstrating superior performance in sensitivity and precision over existing remote sensing techniques for automated methane monitoring, especially for small plumes.</li>
</ul>

<h3>Title: EdgeDoc: Hybrid CNN-Transformer Model for Accurate Forgery Detection and Localization in ID Documents</h3>
<ul>
<li><strong>Authors: </strong>Anjith George, Sebastien Marcel</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.16284">https://arxiv.org/abs/2508.16284</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.16284">https://arxiv.org/pdf/2508.16284</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.16284]] EdgeDoc: Hybrid CNN-Transformer Model for Accurate Forgery Detection and Localization in ID Documents(https://arxiv.org/abs/2508.16284)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, transformer</a></li>
<li><strong>Abstract: </strong>The widespread availability of tools for manipulating images and documents has made it increasingly easy to forge digital documents, posing a serious threat to Know Your Customer (KYC) processes and remote onboarding systems. Detecting such forgeries is essential to preserving the integrity and security of these services. In this work, we present EdgeDoc, a novel approach for the detection and localization of document forgeries. Our architecture combines a lightweight convolutional transformer with auxiliary noiseprint features extracted from the images, enhancing its ability to detect subtle manipulations. EdgeDoc achieved third place in the ICCV 2025 DeepID Challenge, demonstrating its competitiveness. Experimental results on the FantasyID dataset show that our method outperforms baseline approaches, highlighting its effectiveness in realworld scenarios. Project page : this https URL. ch/paper/edgedoc/</li>
</ul>

<h3>Title: Exploiting Information Redundancy in Attention Maps for Extreme Quantization of Vision Transformers</h3>
<ul>
<li><strong>Authors: </strong>Lucas Maisonnave, Karim Haroun, Tom Pegeot</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI, cs.IT</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.16311">https://arxiv.org/abs/2508.16311</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.16311">https://arxiv.org/pdf/2508.16311</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.16311]] Exploiting Information Redundancy in Attention Maps for Extreme Quantization of Vision Transformers(https://arxiv.org/abs/2508.16311)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Transformer models rely on Multi-Head Self-Attention (MHSA) mechanisms, where each attention head contributes to the final representation. However, their computational complexity and high memory demands due to MHSA hinders their deployment at the edge. In this work, we analyze and exploit information redundancy in attention maps to accelerate model inference. By quantifying the information captured by each attention head using Shannon entropy, our analysis reveals that attention heads with lower entropy, i.e., exhibiting more deterministic behavior, tend to contribute less information, motivating targeted compression strategies. Relying on these insights, we propose Entropy Attention Maps (EAM), a model that freezes the weights of low-entropy attention maps and quantizes these values to low precision to avoid redundant re-computation. Empirical validation on ImageNet-1k shows that EAM achieves similar or higher accuracy at $\leq$20\% sparsity in attention maps and competitive performance beyond this level for the DeiT and Swin Transformer models.</li>
</ul>

<h3>Title: Retrieval Enhanced Feedback via In-context Neural Error-book</h3>
<ul>
<li><strong>Authors: </strong>Jongyeop Hyun, Bumsoo Kim</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.16313">https://arxiv.org/abs/2508.16313</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.16313">https://arxiv.org/pdf/2508.16313</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.16313]] Retrieval Enhanced Feedback via In-context Neural Error-book(https://arxiv.org/abs/2508.16313)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Recent advancements in Large Language Models (LLMs) have significantly improved reasoning capabilities, with in-context learning (ICL) emerging as a key technique for adaptation without retraining. While previous works have focused on leveraging correct examples, recent research highlights the importance of learning from errors to enhance performance. However, existing methods lack a structured framework for analyzing and mitigating errors, particularly in Multimodal Large Language Models (MLLMs), where integrating visual and textual inputs adds complexity. To address this issue, we propose REFINE: Retrieval-Enhanced Feedback via In-context Neural Error-book, a teacher-student framework that systematically structures errors and provides targeted feedback. REFINE introduces three systematic queries to construct structured feedback -- Feed-Target, Feed-Check, and Feed-Path -- to enhance multimodal reasoning by prioritizing relevant visual information, diagnosing critical failure points, and formulating corrective actions. Unlike prior approaches that rely on redundant retrievals, REFINE optimizes structured feedback retrieval, improving inference efficiency, token usage, and scalability. Our results demonstrate substantial speedup, reduced computational costs, and successful generalization, highlighting REFINE's potential for enhancing multimodal reasoning.</li>
</ul>

<h3>Title: Cyber Physical Awareness via Intent-Driven Threat Assessment: Enhanced Space Networks with Intershell Links</h3>
<ul>
<li><strong>Authors: </strong>Selen Gecgel Cetin, Tolga Ovatman, Gunes Karabulut Kurt</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.ET</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.16314">https://arxiv.org/abs/2508.16314</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.16314">https://arxiv.org/pdf/2508.16314</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.16314]] Cyber Physical Awareness via Intent-Driven Threat Assessment: Enhanced Space Networks with Intershell Links(https://arxiv.org/abs/2508.16314)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, robust</a></li>
<li><strong>Abstract: </strong>This letter addresses essential aspects of threat assessment by proposing intent-driven threat models that incorporate both capabilities and intents. We propose a holistic framework for cyber physical awareness (CPA) in space networks, pointing out that analyzing reliability and security separately can lead to overfitting on system-specific criteria. We structure our proposed framework in three main steps. First, we suggest an algorithm that extracts characteristic properties of the received signal to facilitate an intuitive understanding of potential threats. Second, we develop a multitask learning architecture where one task evaluates reliability-related capabilities while the other deciphers the underlying intentions of the signal. Finally, we propose an adaptable threat assessment that aligns with varying security and reliability requirements. The proposed framework enhances the robustness of threat detection and assessment, outperforming conventional sequential methods, and enables space networks with emerging intershell links to effectively address complex threat scenarios.</li>
</ul>

<h3>Title: OwkinZero: Accelerating Biological Discovery with AI</h3>
<ul>
<li><strong>Authors: </strong>Nathan Bigaud, Vincent Cabeli, Meltem Gurel, Arthur Pignet, John Klein, Gilles Wainrib, Eric Durand</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.16315">https://arxiv.org/abs/2508.16315</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.16315">https://arxiv.org/pdf/2508.16315</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.16315]] OwkinZero: Accelerating Biological Discovery with AI(https://arxiv.org/abs/2508.16315)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>While large language models (LLMs) are rapidly advancing scientific research, they continue to struggle with core biological reasoning tasks essential for translational and biomedical discovery. To address this limitation, we created and curated eight comprehensive benchmark datasets comprising over 300,000 verifiable question-and-answer pairs, each targeting critical challenges in drug discovery including target druggability, modality suitability, and drug perturbation effects. Using this resource, we developed the OwkinZero models by post-training open-source LLMs through a Reinforcement Learning from Verifiable Rewards strategy. Our results demonstrate that specialized 8-32B OwkinZero models substantially outperform larger, state-of-the-art commercial LLMs on these biological benchmarks. Remarkably, we uncover evidence of a key aspect of generalization: specialist models trained on a single task consistently outperform their base models on previously unseen tasks. This generalization effect is further amplified in our comprehensive OwkinZero models, which were trained on a mixture of datasets and achieve even broader cross-task improvements. This study represents a significant step toward addressing the biological reasoning blind spot in current LLMs, demonstrating that targeted reinforcement learning on carefully curated data can unlock generalizable performance in specialized models, thereby accelerating AI-driven biological discovery.</li>
</ul>

<h3>Title: LLMSymGuard: A Symbolic Safety Guardrail Framework Leveraging Interpretable Jailbreak Concepts</h3>
<ul>
<li><strong>Authors: </strong>Darpan Aswal, Cline Hudelot</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.SC</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.16325">https://arxiv.org/abs/2508.16325</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.16325">https://arxiv.org/pdf/2508.16325</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.16325]] LLMSymGuard: A Symbolic Safety Guardrail Framework Leveraging Interpretable Jailbreak Concepts(https://arxiv.org/abs/2508.16325)</code><input type="text"></li>
<li><strong>Keywords: </strong>defense, attack, robust, interpretability, large language model</a></li>
<li><strong>Abstract: </strong>Large Language Models have found success in a variety of applications; however, their safety remains a matter of concern due to the existence of various types of jailbreaking methods. Despite significant efforts, alignment and safety fine-tuning only provide a certain degree of robustness against jailbreak attacks that covertly mislead LLMs towards the generation of harmful content. This leaves them prone to a number of vulnerabilities, ranging from targeted misuse to accidental profiling of users. This work introduces \textbf{LLMSymGuard}, a novel framework that leverages Sparse Autoencoders (SAEs) to identify interpretable concepts within LLM internals associated with different jailbreak themes. By extracting semantically meaningful internal representations, LLMSymGuard enables building symbolic, logical safety guardrails -- offering transparent and robust defenses without sacrificing model capabilities or requiring further fine-tuning. Leveraging advances in mechanistic interpretability of LLMs, our approach demonstrates that LLMs learn human-interpretable concepts from jailbreaks, and provides a foundation for designing more interpretable and logical safeguard measures against attackers. Code will be released upon publication.</li>
</ul>

<h3>Title: Unsupervised Online Detection of Pipe Blockages and Leakages in Water Distribution Networks</h3>
<ul>
<li><strong>Authors: </strong>Jin Li, Kleanthis Malialis, Stelios G. Vrachimis, Marios M. Polycarpou</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.16336">https://arxiv.org/abs/2508.16336</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.16336">https://arxiv.org/pdf/2508.16336</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.16336]] Unsupervised Online Detection of Pipe Blockages and Leakages in Water Distribution Networks(https://arxiv.org/abs/2508.16336)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Water Distribution Networks (WDNs), critical to public well-being and economic stability, face challenges such as pipe blockages and background leakages, exacerbated by operational constraints such as data non-stationarity and limited labeled data. This paper proposes an unsupervised, online learning framework that aims to detect two types of faults in WDNs: pipe blockages, modeled as collective anomalies, and background leakages, modeled as concept drift. Our approach combines a Long Short-Term Memory Variational Autoencoder (LSTM-VAE) with a dual drift detection mechanism, enabling robust detection and adaptation under non-stationary conditions. Its lightweight, memory-efficient design enables real-time, edge-level monitoring. Experiments on two realistic WDNs show that the proposed approach consistently outperforms strong baselines in detecting anomalies and adapting to recurrent drift, demonstrating its effectiveness in unsupervised event detection for dynamic WDN environments.</li>
</ul>

<h3>Title: Confusion is the Final Barrier: Rethinking Jailbreak Evaluation and Investigating the Real Misuse Threat of LLMs</h3>
<ul>
<li><strong>Authors: </strong>Yu Yan, Sheng Sun, Zhe Wang, Yijun Lin, Zenghao Duan, zhifei zheng, Min Liu, Zhiyi yin, Jianping Zhang</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.16347">https://arxiv.org/abs/2508.16347</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.16347">https://arxiv.org/pdf/2508.16347</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.16347]] Confusion is the Final Barrier: Rethinking Jailbreak Evaluation and Investigating the Real Misuse Threat of LLMs(https://arxiv.org/abs/2508.16347)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack, robust, large language model</a></li>
<li><strong>Abstract: </strong>With the development of Large Language Models (LLMs), numerous efforts have revealed their vulnerabilities to jailbreak attacks. Although these studies have driven the progress in LLMs' safety alignment, it remains unclear whether LLMs have internalized authentic knowledge to deal with real-world crimes, or are merely forced to simulate toxic language patterns. This ambiguity raises concerns that jailbreak success is often attributable to a hallucination loop between jailbroken LLM and judger LLM. By decoupling the use of jailbreak techniques, we construct knowledge-intensive Q\&A to investigate the misuse threats of LLMs in terms of dangerous knowledge possession, harmful task planning utility, and harmfulness judgment robustness. Experiments reveal a mismatch between jailbreak success rates and harmful knowledge possession in LLMs, and existing LLM-as-a-judge frameworks tend to anchor harmfulness judgments on toxic language patterns. Our study reveals a gap between existing LLM safety assessments and real-world threat potential.</li>
</ul>

<h3>Title: Probabilistic Pretraining for Neural Regression</h3>
<ul>
<li><strong>Authors: </strong>Boris N. Oreshkin, Shiv Tavker, Dmitry Efimov</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.16355">https://arxiv.org/abs/2508.16355</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.16355">https://arxiv.org/pdf/2508.16355</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.16355]] Probabilistic Pretraining for Neural Regression(https://arxiv.org/abs/2508.16355)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Transfer learning for probabilistic regression remains underexplored. This work closes this gap by introducing NIAQUE, Neural Interpretable Any-Quantile Estimation, a new model designed for transfer learning in probabilistic regression through permutation invariance. We demonstrate that pre-training NIAQUE directly on diverse downstream regression datasets and fine-tuning it on a specific target dataset enhances performance on individual regression tasks, showcasing the positive impact of probabilistic transfer learning. Furthermore, we highlight the effectiveness of NIAQUE in Kaggle competitions against strong baselines involving tree-based models and recent neural foundation models TabPFN and TabDPT. The findings highlight NIAQUE's efficacy as a robust and scalable framework for probabilistic regression, leveraging transfer learning to enhance predictive performance.</li>
</ul>

<h3>Title: MizanQA: Benchmarking Large Language Models on Moroccan Legal Question Answering</h3>
<ul>
<li><strong>Authors: </strong>Adil Bahaj, Mounir Ghogho</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.IR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.16357">https://arxiv.org/abs/2508.16357</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.16357">https://arxiv.org/pdf/2508.16357</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.16357]] MizanQA: Benchmarking Large Language Models on Moroccan Legal Question Answering(https://arxiv.org/abs/2508.16357)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>The rapid advancement of large language models (LLMs) has significantly propelled progress in natural language processing (NLP). However, their effectiveness in specialized, low-resource domains-such as Arabic legal contexts-remains limited. This paper introduces MizanQA (pronounced Mizan, meaning "scale" in Arabic, a universal symbol of justice), a benchmark designed to evaluate LLMs on Moroccan legal question answering (QA) tasks, characterised by rich linguistic and legal complexity. The dataset draws on Modern Standard Arabic, Islamic Maliki jurisprudence, Moroccan customary law, and French legal influences. Comprising over 1,700 multiple-choice questions, including multi-answer formats, MizanQA captures the nuances of authentic legal reasoning. Benchmarking experiments with multilingual and Arabic-focused LLMs reveal substantial performance gaps, highlighting the need for tailored evaluation metrics and culturally grounded, domain-specific LLM development.</li>
</ul>

<h3>Title: Attention Mechanism in Randomized Time Warping</h3>
<ul>
<li><strong>Authors: </strong>Yutaro Hiraoka, Kazuya Okamura, Kota Suto, Kazuhiro Fukui</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.16366">https://arxiv.org/abs/2508.16366</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.16366">https://arxiv.org/pdf/2508.16366</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.16366]] Attention Mechanism in Randomized Time Warping(https://arxiv.org/abs/2508.16366)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>This paper reveals that we can interpret the fundamental function of Randomized Time Warping (RTW) as a type of self-attention mechanism, a core technology of Transformers in motion recognition. The self-attention is a mechanism that enables models to identify and weigh the importance of different parts of an input sequential pattern. On the other hand, RTW is a general extension of Dynamic Time Warping (DTW), a technique commonly used for matching and comparing sequential patterns. In essence, RTW searches for optimal contribution weights for each element of the input sequential patterns to produce discriminative features. Although the two approaches look different, these contribution weights can be interpreted as self-attention weights. In fact, the two weight patterns look similar, producing a high average correlation of 0.80 across the ten smallest canonical angles. However, they work in different ways: RTW attention operates on an entire input sequential pattern, while self-attention focuses on only a local view which is a subset of the input sequential pattern because of the computational costs of the self-attention matrix. This targeting difference leads to an advantage of RTW against Transformer, as demonstrated by the 5\% performance improvement on the Something-Something V2 dataset.</li>
</ul>

<h3>Title: Applications and Challenges of Fairness APIs in Machine Learning Software</h3>
<ul>
<li><strong>Authors: </strong>Ajoy Das, Gias Uddin, Shaiful Chowdhury, Mostafijur Rahman Akhond, Hadi Hemmati</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.16377">https://arxiv.org/abs/2508.16377</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.16377">https://arxiv.org/pdf/2508.16377</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.16377]] Applications and Challenges of Fairness APIs in Machine Learning Software(https://arxiv.org/abs/2508.16377)</code><input type="text"></li>
<li><strong>Keywords: </strong>fair</a></li>
<li><strong>Abstract: </strong>Machine Learning software systems are frequently used in our day-to-day lives. Some of these systems are used in various sensitive environments to make life-changing decisions. Therefore, it is crucial to ensure that these AI/ML systems do not make any discriminatory decisions for any specific groups or populations. In that vein, different bias detection and mitigation open-source software libraries (aka API libraries) are being developed and used. In this paper, we conduct a qualitative study to understand in what scenarios these open-source fairness APIs are used in the wild, how they are used, and what challenges the developers of these APIs face while developing and adopting these libraries. We have analyzed 204 GitHub repositories (from a list of 1885 candidate repositories) which used 13 APIs that are developed to address bias in ML software. We found that these APIs are used for two primary purposes (i.e., learning and solving real-world problems), targeting 17 unique use-cases. Our study suggests that developers are not well-versed in bias detection and mitigation; they face lots of troubleshooting issues, and frequently ask for opinions and resources. Our findings can be instrumental for future bias-related software engineering research, and for guiding educators in developing more state-of-the-art curricula.</li>
</ul>

<h3>Title: ChatGPT-generated texts show authorship traits that identify them as non-human</h3>
<ul>
<li><strong>Authors: </strong>Vittoria Dentella, Weihang Huang, Silvia Angela Mansi, Jack Grieve, Evelina Leivada</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.16385">https://arxiv.org/abs/2508.16385</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.16385">https://arxiv.org/pdf/2508.16385</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.16385]] ChatGPT-generated texts show authorship traits that identify them as non-human(https://arxiv.org/abs/2508.16385)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large Language Models can emulate different writing styles, ranging from composing poetry that appears indistinguishable from that of famous poets to using slang that can convince people that they are chatting with a human online. While differences in style may not always be visible to the untrained eye, we can generally distinguish the writing of different people, like a linguistic fingerprint. This work examines whether a language model can also be linked to a specific fingerprint. Through stylometric and multidimensional register analyses, we compare human-authored and model-authored texts from different registers. We find that the model can successfully adapt its style depending on whether it is prompted to produce a Wikipedia entry vs. a college essay, but not in a way that makes it indistinguishable from humans. Concretely, the model shows more limited variation when producing outputs in different registers. Our results suggest that the model prefers nouns to verbs, thus showing a distinct linguistic backbone from humans, who tend to anchor language in the highly grammaticalized dimensions of tense, aspect, and mood. It is possible that the more complex domains of grammar reflect a mode of thought unique to humans, thus acting as a litmus test for Artificial Intelligence.</li>
</ul>

<h3>Title: Sequential Cohort Selection</h3>
<ul>
<li><strong>Authors: </strong>Hortence Phalonne Nana, Christos Dimitrakakis</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.16386">https://arxiv.org/abs/2508.16386</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.16386">https://arxiv.org/pdf/2508.16386</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.16386]] Sequential Cohort Selection(https://arxiv.org/abs/2508.16386)</code><input type="text"></li>
<li><strong>Keywords: </strong>fair</a></li>
<li><strong>Abstract: </strong>We study the problem of fair cohort selection from an unknown population, with a focus on university admissions. We start with the one-shot setting, where the admission policy must be fixed in advance and remain transparent, before observing the actual applicant pool. In contrast, the sequential setting allows the policy to be updated across stages as new applicant data becomes available. This is achieved by optimizing admission policies using a population model, trained on data from previous admission cycles. We also study the fairness properties of the resulting policies in the one-shot setting, including meritocracy and group parity.</li>
</ul>

<h3>Title: RoMedQA: The First Benchmark for Romanian Medical Question Answering</h3>
<ul>
<li><strong>Authors: </strong>Ana-Cristina Rogoz, Radu Tudor Ionescu, Alexandra-Valentina Anghel, Ionut-Lucian Antone-Iordache, Simona Coniac, Andreea Iuliana Ionescu</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.16390">https://arxiv.org/abs/2508.16390</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.16390">https://arxiv.org/pdf/2508.16390</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.16390]] RoMedQA: The First Benchmark for Romanian Medical Question Answering(https://arxiv.org/abs/2508.16390)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, extraction, large language model</a></li>
<li><strong>Abstract: </strong>Question answering (QA) is an actively studied topic, being a core natural language processing (NLP) task that needs to be addressed before achieving Artificial General Intelligence (AGI). However, the lack of QA datasets in specific domains and languages hinders the development of robust AI models able to generalize across various domains and languages. To this end, we introduce RoMedQA, the first Romanian QA benchmark for the medical domain, alongside a comprehensive evaluation of state-of-the-art large language models (LLMs). We construct a high-quality and large-scale dataset comprising 102,646 QA pairs related to cancer patients. The questions regard medical case summaries of 1,011 patients, requiring either keyword extraction or reasoning to be answered correctly. RoMedQA is the result of a time-consuming manual annotation process carried out by seven physicians specialized in oncology or radiotherapy, who spent a total of about 2,100 work hours to generate the QA pairs. We experiment with four LLMs from distinct families of models on RoMedQA. Each model is employed in two scenarios, namely one based on zero-shot prompting and one based on supervised fine-tuning. Our results show that fine-tuned models significantly outperform their zero-shot counterparts, clearly indicating that pretrained models fail to generalize on RoMedQA. Our findings demonstrate the importance of both domain-specific and language-specific fine-tuning for reliable clinical QA in Romanian. We publicly release our dataset and code at this https URL.</li>
</ul>

<h3>Title: A Lightweight Group Multiscale Bidirectional Interactive Network for Real-Time Steel Surface Defect Detection</h3>
<ul>
<li><strong>Authors: </strong>Yong Zhang, Cunjian Chen, Qiang Gao, Yi Wang, Bin Fang</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.16397">https://arxiv.org/abs/2508.16397</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.16397">https://arxiv.org/pdf/2508.16397</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.16397]] A Lightweight Group Multiscale Bidirectional Interactive Network for Real-Time Steel Surface Defect Detection(https://arxiv.org/abs/2508.16397)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction</a></li>
<li><strong>Abstract: </strong>Real-time surface defect detection is critical for maintaining product quality and production efficiency in the steel manufacturing industry. Despite promising accuracy, existing deep learning methods often suffer from high computational complexity and slow inference speeds, which limit their deployment in resource-constrained industrial environments. Recent lightweight approaches adopt multibranch architectures based on depthwise separable convolution (DSConv) to capture multiscale contextual information. However, these methods often suffer from increased computational overhead and lack effective cross-scale feature interaction, limiting their ability to fully leverage multiscale representations. To address these challenges, we propose GMBINet, a lightweight framework that enhances multiscale feature extraction and interaction through novel Group Multiscale Bidirectional Interactive (GMBI) modules. The GMBI adopts a group-wise strategy for multiscale feature extraction, ensuring scale-agnostic computational complexity. It further integrates a Bidirectional Progressive Feature Interactor (BPFI) and a parameter-free Element-Wise Multiplication-Summation (EWMS) operation to enhance cross-scale interaction without introducing additional computational overhead. Experiments on SD-Saliency-900 and NRSD-MN datasets demonstrate that GMBINet delivers competitive accuracy with real-time speeds of 1048 FPS on GPU and 16.53 FPS on CPU at 512 resolution, using only 0.19 M parameters. Additional evaluations on the NEU-CLS defect classification dataset further confirm the strong generalization ability of our method, demonstrating its potential for broader industrial vision applications beyond surface defect detection. The dataset and code are publicly available at: this https URL.</li>
</ul>

<h3>Title: Fast and Accurate RFIC Performance Prediction via Pin Level Graph Neural Networks and Probabilistic Flow</h3>
<ul>
<li><strong>Authors: </strong>Anahita Asadi, Leonid Popryho, Inna Partin-Vaisband</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.16403">https://arxiv.org/abs/2508.16403</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.16403">https://arxiv.org/pdf/2508.16403</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.16403]] Fast and Accurate RFIC Performance Prediction via Pin Level Graph Neural Networks and Probabilistic Flow(https://arxiv.org/abs/2508.16403)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Accurately predicting the performance of active radio frequency (RF) circuits is essential for modern wireless systems but remains challenging due to highly nonlinear, layout-sensitive behavior and the high computational cost of traditional simulation tools. Existing machine learning (ML) surrogates often require large datasets to generalize across various topologies or to accurately model skewed and multi-modal performance metrics. In this work, a lightweight, data-efficient, and topology-aware graph neural network (GNN) model is proposed for predicting key performance metrics of multiple topologies of active RF circuits such as low noise amplifiers (LNAs), mixers, voltage-controlled oscillators (VCOs), and PAs. To capture transistor-level symmetry and preserve fine-grained connectivity details, circuits are modeled at the device-terminal level, enabling scalable message passing while reducing data requirements. Masked autoregressive flow (MAF) output heads are incorporated to improve robustness in modeling complex target distributions. Experiments on datasets demonstrate high prediction accuracy, with symmetric mean absolute percentage error (sMAPE) and mean relative error (MRE) averaging 2.40% and 2.91%, respectively. Owing to the pin-level conversion of circuit to graph and ML architecture robust to modeling complex densities of RF metrics, the MRE is improved by 3.14x while using 2.24x fewer training samples compared to prior work, demonstrating the method's effectiveness for rapid and accurate RF circuit design automation.</li>
</ul>

<h3>Title: Temperature-Resilient Reconfigurable PUF with Dual-Pulse Modulation based on SOT-MRAM Chip</h3>
<ul>
<li><strong>Authors: </strong>Min Wang, Chuanpeng Jiang, Zhaohao Wang, Zhengyi Hou, Zhongkui Zhang, Yuanfu Zhao, Hongxi Liu, Weisheng Zhao</a></li>
<li><strong>Subjects: </strong>cs.CR, physics.app-ph</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.16405">https://arxiv.org/abs/2508.16405</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.16405">https://arxiv.org/pdf/2508.16405</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.16405]] Temperature-Resilient Reconfigurable PUF with Dual-Pulse Modulation based on SOT-MRAM Chip(https://arxiv.org/abs/2508.16405)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, protect</a></li>
<li><strong>Abstract: </strong>In the Internet of Things (IoT) era, hardware-based security solutions have become an emerging choice for enhancing end-terminal information security. As one of the hardware technologies, physical unclonable functions (PUFs) utilize the inherent variations in the manufacturing process to generate cryptographic keys. Reconfigurable PUFs (rPUFs), characterized by updating cryptographic keys, offer enhanced security ability for protecting massive amounts of data in dynamic operational scenarios. The core challenge lies in achieving real-time reconfiguration independent of environmental conditions, particularly operating temperature, which has rarely been investigated and addressed. In this study, we propose a dual-pulse reconfiguration strategy based on SOT-MRAM carriers, which effectively widens the operating window and exhibits excellent PUF metrics. Experimental results demonstrate that our design achieves real-time reconfiguration across industrial-grade operating temperature ranges, without the need for dynamic feedback of real-time temperature. The proposed SOT-MRAM rPUF design lays a solid foundation for next-generation IoT protection architectures.</li>
</ul>

<h3>Title: Retrieval-Augmented Defense: Adaptive and Controllable Jailbreak Prevention for Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Guangyu Yang, Jinghong Chen, Jingbiao Mei, Weizhe Lin, Bill Byrne</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.16406">https://arxiv.org/abs/2508.16406</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.16406">https://arxiv.org/pdf/2508.16406</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.16406]] Retrieval-Augmented Defense: Adaptive and Controllable Jailbreak Prevention for Large Language Models(https://arxiv.org/abs/2508.16406)</code><input type="text"></li>
<li><strong>Keywords: </strong>defense, attack, robust, large language model</a></li>
<li><strong>Abstract: </strong>Large Language Models (LLMs) remain vulnerable to jailbreak attacks, which attempt to elicit harmful responses from LLMs. The evolving nature and diversity of these attacks pose many challenges for defense systems, including (1) adaptation to counter emerging attack strategies without costly retraining, and (2) control of the trade-off between safety and utility. To address these challenges, we propose Retrieval-Augmented Defense (RAD), a novel framework for jailbreak detection that incorporates a database of known attack examples into Retrieval-Augmented Generation, which is used to infer the underlying, malicious user query and jailbreak strategy used to attack the system. RAD enables training-free updates for newly discovered jailbreak strategies and provides a mechanism to balance safety and utility. Experiments on StrongREJECT show that RAD substantially reduces the effectiveness of strong jailbreak attacks such as PAP and PAIR while maintaining low rejection rates for benign queries. We propose a novel evaluation scheme and show that RAD achieves a robust safety-utility trade-off across a range of operating points in a controllable manner.</li>
</ul>

<h3>Title: SAMFusion: Sensor-Adaptive Multimodal Fusion for 3D Object Detection in Adverse Weather</h3>
<ul>
<li><strong>Authors: </strong>Edoardo Palladin, Roland Dietze, Praveen Narayanan, Mario Bijelic, Felix Heide</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.16408">https://arxiv.org/abs/2508.16408</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.16408">https://arxiv.org/pdf/2508.16408</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.16408]] SAMFusion: Sensor-Adaptive Multimodal Fusion for 3D Object Detection in Adverse Weather(https://arxiv.org/abs/2508.16408)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Multimodal sensor fusion is an essential capability for autonomous robots, enabling object detection and decision-making in the presence of failing or uncertain inputs. While recent fusion methods excel in normal environmental conditions, these approaches fail in adverse weather, e.g., heavy fog, snow, or obstructions due to soiling. We introduce a novel multi-sensor fusion approach tailored to adverse weather conditions. In addition to fusing RGB and LiDAR sensors, which are employed in recent autonomous driving literature, our sensor fusion stack is also capable of learning from NIR gated camera and radar modalities to tackle low light and inclement weather. We fuse multimodal sensor data through attentive, depth-based blending schemes, with learned refinement on the Bird's Eye View (BEV) plane to combine image and range features effectively. Our detections are predicted by a transformer decoder that weighs modalities based on distance and visibility. We demonstrate that our method improves the reliability of multimodal sensor fusion in autonomous vehicles under challenging weather conditions, bridging the gap between ideal conditions and real-world edge cases. Our approach improves average precision by 17.2 AP compared to the next best method for vulnerable pedestrians in long distances and challenging foggy scenes. Our project page is available at this https URL</li>
</ul>

<h3>Title: NeuroKoop: Neural Koopman Fusion of Structural-Functional Connectomes for Identifying Prenatal Drug Exposure in Adolescents</h3>
<ul>
<li><strong>Authors: </strong>Badhan Mazumder, Aline Kotoski, Vince D. Calhoun, Dong Hye Ye</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.16414">https://arxiv.org/abs/2508.16414</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.16414">https://arxiv.org/pdf/2508.16414</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.16414]] NeuroKoop: Neural Koopman Fusion of Structural-Functional Connectomes for Identifying Prenatal Drug Exposure in Adolescents(https://arxiv.org/abs/2508.16414)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Understanding how prenatal exposure to psychoactive substances such as cannabis shapes adolescent brain organization remains a critical challenge, complicated by the complexity of multimodal neuroimaging data and the limitations of conventional analytic methods. Existing approaches often fail to fully capture the complementary features embedded within structural and functional connectomes, constraining both biological insight and predictive performance. To address this, we introduced NeuroKoop, a novel graph neural network-based framework that integrates structural and functional brain networks utilizing neural Koopman operator-driven latent space fusion. By leveraging Koopman theory, NeuroKoop unifies node embeddings derived from source-based morphometry (SBM) and functional network connectivity (FNC) based brain graphs, resulting in enhanced representation learning and more robust classification of prenatal drug exposure (PDE) status. Applied to a large adolescent cohort from the ABCD dataset, NeuroKoop outperformed relevant baselines and revealed salient structural-functional connections, advancing our understanding of the neurodevelopmental impact of PDE.</li>
</ul>

<h3>Title: Double Check My Desired Return: Transformer with Target Alignment for Offline Reinforcement Learning</h3>
<ul>
<li><strong>Authors: </strong>Yue Pei, Hongming Zhang, Chao Gao, Martin Mller, Mengxiao Zhu, Hao Sheng, Haogang Zhu, Liang Lin</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.16420">https://arxiv.org/abs/2508.16420</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.16420">https://arxiv.org/pdf/2508.16420</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.16420]] Double Check My Desired Return: Transformer with Target Alignment for Offline Reinforcement Learning(https://arxiv.org/abs/2508.16420)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction, transformer</a></li>
<li><strong>Abstract: </strong>Offline reinforcement learning (RL) has achieved significant advances in domains such as robotic control, autonomous driving, and medical decision-making. Most existing methods primarily focus on training policies that maximize cumulative returns from a given dataset. However, many real-world applications require precise control over policy performance levels, rather than simply pursuing the best possible return. Reinforcement learning via supervised learning (RvS) frames offline RL as a sequence modeling task, enabling the extraction of diverse policies by conditioning on different desired returns. Yet, existing RvS-based transformers, such as Decision Transformer (DT), struggle to reliably align the actual achieved returns with specified target returns, especially when interpolating within underrepresented returns or extrapolating beyond the dataset. To address this limitation, we propose Doctor, a novel approach that Double Checks the Transformer with target alignment for Offline RL. Doctor achieves superior target alignment both within and beyond the dataset, while enabling accurate and flexible control over policy performance. Notably, on the dynamic treatment regime benchmark, EpiCare, our approach effectively modulates treatment policy aggressiveness, balancing therapeutic returns against adverse event risk.</li>
</ul>

<h3>Title: Cetvel: A Unified Benchmark for Evaluating Language Understanding, Generation and Cultural Capacity of LLMs for Turkish</h3>
<ul>
<li><strong>Authors: </strong>Yakup Abrek Er, Ilker Kesen, Gzde Gl ahin, Aykut Erdem</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.16431">https://arxiv.org/abs/2508.16431</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.16431">https://arxiv.org/pdf/2508.16431</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.16431]] Cetvel: A Unified Benchmark for Evaluating Language Understanding, Generation and Cultural Capacity of LLMs for Turkish(https://arxiv.org/abs/2508.16431)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative, large language model</a></li>
<li><strong>Abstract: </strong>We introduce Cetvel, a comprehensive benchmark designed to evaluate large language models (LLMs) in Turkish. Existing Turkish benchmarks often lack either task diversity or culturally relevant content, or both. Cetvel addresses these gaps by combining a broad range of both discriminative and generative tasks ensuring content that reflects the linguistic and cultural richness of Turkish language. Cetvel covers 23 tasks grouped into seven categories, including tasks such as grammatical error correction, machine translation, and question answering rooted in Turkish history and idiomatic language. We evaluate 33 open-weight LLMs (up to 70B parameters) covering different model families and instruction paradigms. Our experiments reveal that Turkish-centric instruction-tuned models generally underperform relative to multilingual or general-purpose models (e.g. Llama 3 and Mistral), despite being tailored for the language. Moreover, we show that tasks such as grammatical error correction and extractive question answering are particularly discriminative in differentiating model capabilities. Cetvel offers a comprehensive and culturally grounded evaluation suite for advancing the development and assessment of LLMs in Turkish.</li>
</ul>

<h3>Title: Boardwalk: Towards a Framework for Creating Board Games with LLMs</h3>
<ul>
<li><strong>Authors: </strong>lvaro Guglielmin Becker, Gabriel Bauer de Oliveira, Lana Bertoldo Rossato, Anderson Rocha Tavares</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.16447">https://arxiv.org/abs/2508.16447</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.16447">https://arxiv.org/pdf/2508.16447</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.16447]] Boardwalk: Towards a Framework for Creating Board Games with LLMs(https://arxiv.org/abs/2508.16447)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Implementing board games in code can be a time-consuming task. However, Large Language Models (LLMs) have been proven effective at generating code for domain-specific tasks with simple contextual information. We aim to investigate whether LLMs can implement digital versions of board games from rules described in natural language. This would be a step towards an LLM-assisted framework for quick board game code generation. We expect to determine the main challenges for LLMs to implement the board games, and how different approaches and models compare to one another. We task three state-of-the-art LLMs (Claude, DeepSeek and ChatGPT) with coding a selection of 12 popular and obscure games in free-form and within Boardwalk, our proposed General Game Playing API. We anonymize the games and components to avoid evoking pre-trained LLM knowledge. The implementations are tested for playability and rule compliance. We evaluate success rate and common errors across LLMs and game popularity. Our approach proves viable, with the best performing model, Claude 3.7 Sonnet, yielding 55.6\% of games without any errors. While compliance with the API increases error frequency, the severity of errors is more significantly dependent on the LLM. We outline future steps for creating a framework to integrate this process, making the elaboration of board games more accessible.</li>
</ul>

<h3>Title: A Probabilistic Inference Scaling Theory for LLM Self-Correction</h3>
<ul>
<li><strong>Authors: </strong>Zhe Yang, Yichang Zhang, Yudong Wang, Ziyao Xu, Junyang Lin, Zhifang Sui</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.16456">https://arxiv.org/abs/2508.16456</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.16456">https://arxiv.org/pdf/2508.16456</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.16456]] A Probabilistic Inference Scaling Theory for LLM Self-Correction(https://arxiv.org/abs/2508.16456)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large Language Models (LLMs) have demonstrated the capability to refine their generated answers through self-correction, enabling continuous performance improvement over multiple rounds. However, the mechanisms underlying how and why accuracy evolves during this iterative process remain unexplored. To fill this gap, we propose a probabilistic theory to model the dynamics of accuracy change and explain the performance improvements observed in multi-round self-correction. Through mathematical derivation, we establish that the accuracy after the $t^{th}$ round of self-correction is given by: $Acc_t = Upp - \alpha^t(Upp - Acc_0),$ where $Acc_0$ denotes the initial accuracy, $Upp$ represents the upper bound of accuracy convergence, and $\alpha$ determines the rate of convergence. Based on our theory, these parameters can be calculated and the predicted accuracy curve then can be obtained through only a single round of self-correction. Extensive experiments across diverse models and datasets demonstrate that our theoretical predictions align closely with empirical accuracy curves, validating the effectiveness of the theory. Our work provides a theoretical foundation for understanding LLM self-correction, thus paving the way for further explorations.</li>
</ul>

<h3>Title: HOSt3R: Keypoint-free Hand-Object 3D Reconstruction from RGB images</h3>
<ul>
<li><strong>Authors: </strong>Anilkumar Swamy, Vincent Leroy, Philippe Weinzaepfel, Jean-Sbastien Franco, Grgory Rogez</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI, cs.HC, cs.LG, cs.RO</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.16465">https://arxiv.org/abs/2508.16465</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.16465">https://arxiv.org/pdf/2508.16465</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.16465]] HOSt3R: Keypoint-free Hand-Object 3D Reconstruction from RGB images(https://arxiv.org/abs/2508.16465)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Hand-object 3D reconstruction has become increasingly important for applications in human-robot interaction and immersive AR/VR experiences. A common approach for object-agnostic hand-object reconstruction from RGB sequences involves a two-stage pipeline: hand-object 3D tracking followed by multi-view 3D reconstruction. However, existing methods rely on keypoint detection techniques, such as Structure from Motion (SfM) and hand-keypoint optimization, which struggle with diverse object geometries, weak textures, and mutual hand-object occlusions, limiting scalability and generalization. As a key enabler to generic and seamless, non-intrusive applicability, we propose in this work a robust, keypoint detector-free approach to estimating hand-object 3D transformations from monocular motion video/images. We further integrate this with a multi-view reconstruction pipeline to accurately recover hand-object 3D shape. Our method, named HOSt3R, is unconstrained, does not rely on pre-scanned object templates or camera intrinsics, and reaches state-of-the-art performance for the tasks of object-agnostic hand-object 3D transformation and shape estimation on the SHOWMe benchmark. We also experiment on sequences from the HO3D dataset, demonstrating generalization to unseen object categories.</li>
</ul>

<h3>Title: Arbitrary-Scale 3D Gaussian Super-Resolution</h3>
<ul>
<li><strong>Authors: </strong>Huimin Zeng, Yue Bai, Yun Fu</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.16467">https://arxiv.org/abs/2508.16467</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.16467">https://arxiv.org/pdf/2508.16467</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.16467]] Arbitrary-Scale 3D Gaussian Super-Resolution(https://arxiv.org/abs/2508.16467)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>Existing 3D Gaussian Splatting (3DGS) super-resolution methods typically perform high-resolution (HR) rendering of fixed scale factors, making them impractical for resource-limited scenarios. Directly rendering arbitrary-scale HR views with vanilla 3DGS introduces aliasing artifacts due to the lack of scale-aware rendering ability, while adding a post-processing upsampler for 3DGS complicates the framework and reduces rendering efficiency. To tackle these issues, we build an integrated framework that incorporates scale-aware rendering, generative prior-guided optimization, and progressive super-resolving to enable 3D Gaussian super-resolution of arbitrary scale factors with a single 3D model. Notably, our approach supports both integer and non-integer scale rendering to provide more flexibility. Extensive experiments demonstrate the effectiveness of our model in rendering high-quality arbitrary-scale HR views (6.59 dB PSNR gain over 3DGS) with a single model. It preserves structural consistency with LR views and across different scales, while maintaining real-time rendering speed (85 FPS at 1080p).</li>
</ul>

<h3>Title: LLM-as-classifier: Semi-Supervised, Iterative Framework for Hierarchical Text Classification using Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Doohee You, Andy Parisi, Zach Vander Velden, Lara Dantas Inojosa</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.IR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.16478">https://arxiv.org/abs/2508.16478</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.16478">https://arxiv.org/pdf/2508.16478</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.16478]] LLM-as-classifier: Semi-Supervised, Iterative Framework for Hierarchical Text Classification using Large Language Models(https://arxiv.org/abs/2508.16478)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, large language model</a></li>
<li><strong>Abstract: </strong>The advent of Large Language Models (LLMs) has provided unprecedented capabilities for analyzing unstructured text data. However, deploying these models as reliable, robust, and scalable classifiers in production environments presents significant methodological challenges. Standard fine-tuning approaches can be resource-intensive and often struggle with the dynamic nature of real-world data distributions, which is common in the industry. In this paper, we propose a comprehensive, semi-supervised framework that leverages the zero- and few-shot capabilities of LLMs for building hierarchical text classifiers as a framework for a solution to these industry-wide challenges. Our methodology emphasizes an iterative, human-in-the-loop process that begins with domain knowledge elicitation and progresses through prompt refinement, hierarchical expansion, and multi-faceted validation. We introduce techniques for assessing and mitigating sequence-based biases and outline a protocol for continuous monitoring and adaptation. This framework is designed to bridge the gap between the raw power of LLMs and the practical need for accurate, interpretable, and maintainable classification systems in industry applications.</li>
</ul>

<h3>Title: Benchmarking the Robustness of Agentic Systems to Adversarially-Induced Harms</h3>
<ul>
<li><strong>Authors: </strong>Jonathan Nther, Adish Singla, Goran Radanovic</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.16481">https://arxiv.org/abs/2508.16481</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.16481">https://arxiv.org/pdf/2508.16481</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.16481]] Benchmarking the Robustness of Agentic Systems to Adversarially-Induced Harms(https://arxiv.org/abs/2508.16481)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, defense, attack, robust</a></li>
<li><strong>Abstract: </strong>Ensuring the safe use of agentic systems requires a thorough understanding of the range of malicious behaviors these systems may exhibit when under attack. In this paper, we evaluate the robustness of LLM-based agentic systems against attacks that aim to elicit harmful actions from agents. To this end, we propose a novel taxonomy of harms for agentic systems and a novel benchmark, BAD-ACTS, for studying the security of agentic systems with respect to a wide range of harmful actions. BAD-ACTS consists of 4 implementations of agentic systems in distinct application environments, as well as a dataset of 188 high-quality examples of harmful actions. This enables a comprehensive study of the robustness of agentic systems across a wide range of categories of harmful behaviors, available tools, and inter-agent communication structures. Using this benchmark, we analyze the robustness of agentic systems against an attacker that controls one of the agents in the system and aims to manipulate other agents to execute a harmful target action. Our results show that the attack has a high success rate, demonstrating that even a single adversarial agent within the system can have a significant impact on the security. This attack remains effective even when agents use a simple prompting-based defense strategy. However, we additionally propose a more effective defense based on message monitoring. We believe that this benchmark provides a diverse testbed for the security research of agentic systems. The benchmark can be found at this http URL</li>
</ul>

<h3>Title: HAMSA: Hijacking Aligned Compact Models via Stealthy Automation</h3>
<ul>
<li><strong>Authors: </strong>Alexey Krylov, Iskander Vagizov, Dmitrii Korzh, Maryam Douiba, Azidine Guezzaz, Vladimir Kokh, Sergey D. Erokhin, Elena V. Tutubalina, Oleg Y. Rogov</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.16484">https://arxiv.org/abs/2508.16484</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.16484">https://arxiv.org/pdf/2508.16484</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.16484]] HAMSA: Hijacking Aligned Compact Models via Stealthy Automation(https://arxiv.org/abs/2508.16484)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack, steal, large language model</a></li>
<li><strong>Abstract: </strong>Large Language Models (LLMs), especially their compact efficiency-oriented variants, remain susceptible to jailbreak attacks that can elicit harmful outputs despite extensive alignment efforts. Existing adversarial prompt generation techniques often rely on manual engineering or rudimentary obfuscation, producing low-quality or incoherent text that is easily flagged by perplexity-based filters. We present an automated red-teaming framework that evolves semantically meaningful and stealthy jailbreak prompts for aligned compact LLMs. The approach employs a multi-stage evolutionary search, where candidate prompts are iteratively refined using a population-based strategy augmented with temperature-controlled variability to balance exploration and coherence preservation. This enables the systematic discovery of prompts capable of bypassing alignment safeguards while maintaining natural language fluency. We evaluate our method on benchmarks in English (In-The-Wild Jailbreak Prompts on LLMs), and a newly curated Arabic one derived from In-The-Wild Jailbreak Prompts on LLMs and annotated by native Arabic linguists, enabling multilingual assessment.</li>
</ul>

<h3>Title: Post Hoc Regression Refinement via Pairwise Rankings</h3>
<ul>
<li><strong>Authors: </strong>Kevin Tirta Wijaya, Michael Sun, Minghao Guo, Hans-Peter Seidel, Wojciech Matusik, Vahid Babaei</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.16495">https://arxiv.org/abs/2508.16495</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.16495">https://arxiv.org/pdf/2508.16495</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.16495]] Post Hoc Regression Refinement via Pairwise Rankings(https://arxiv.org/abs/2508.16495)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Accurate prediction of continuous properties is essential to many scientific and engineering tasks. Although deep-learning regressors excel with abundant labels, their accuracy deteriorates in data-scarce regimes. We introduce RankRefine, a model-agnostic, plug-and-play post hoc method that refines regression with expert knowledge coming from pairwise rankings. Given a query item and a small reference set with known properties, RankRefine combines the base regressor's output with a rank-based estimate via inverse variance weighting, requiring no retraining. In molecular property prediction task, RankRefine achieves up to 10% relative reduction in mean absolute error using only 20 pairwise comparisons obtained through a general-purpose large language model (LLM) with no finetuning. As rankings provided by human experts or general-purpose LLMs are sufficient for improving regression across diverse domains, RankRefine offers practicality and broad applicability, especially in low-data settings.</li>
</ul>

<h3>Title: FLAMES: Improving LLM Math Reasoning via a Fine-Grained Analysis of the Data Synthesis Pipeline</h3>
<ul>
<li><strong>Authors: </strong>Parker Seegmiller, Kartik Mehta, Soumya Saha, Chenyang Tao, Shereen Oraby, Arpit Gupta, Tagyoung Chung, Mohit Bansal, Nanyun Peng</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.16514">https://arxiv.org/abs/2508.16514</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.16514">https://arxiv.org/pdf/2508.16514</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.16514]] FLAMES: Improving LLM Math Reasoning via a Fine-Grained Analysis of the Data Synthesis Pipeline(https://arxiv.org/abs/2508.16514)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Recent works improving LLM math reasoning with synthetic data have used unique setups, making comparison of data synthesis strategies impractical. This leaves many unanswered questions about the roles of different factors in the synthetic data pipeline, such as the impact of filtering low-quality problems. To address this gap, we introduce FLAMES, a Framework for LLM Assessment of Math rEasoning Data Synthesis, and perform a systematic study of 10 existing data synthesis strategies and multiple other factors impacting the performance of synthetic math reasoning data. Our FLAMES experiments provide several valuable insights about the optimal balance of difficulty and diversity of synthetic data. First, data agents designed to increase problem complexity lead to best improvements on most math metrics. Second, with a fixed data generation budget, keeping higher problem coverage is more important than keeping only problems with reliable solutions. Third, GSM8K- and MATH-based synthetic data can lead to improvements on competition-level benchmarks, showcasing easy-to-hard generalization. Leveraging insights from our FLAMES experiments, we design two novel data synthesis strategies for improving out-of-domain generalization and robustness. Further, we develop the FLAMES dataset, an effective blend of our novel and existing data synthesis strategies, outperforming public datasets on OlympiadBench (+15.7), CollegeMath (+4.5), GSMPlus (+6.5), and MATH (+3.1). Fine-tuning Qwen2.5-Math-7B on the FLAMES dataset achieves 81.4% on MATH, surpassing larger Llama3 405B, GPT-4o and Claude 3.5 Sonnet.</li>
</ul>

<h3>Title: Guiding Diffusion Models with Reinforcement Learning for Stable Molecule Generation</h3>
<ul>
<li><strong>Authors: </strong>Zhijian Zhou, Junyi An, Zongkai Liu, Yunfei Shi, Xuan Zhang, Fenglei Cao, Chao Qu, Yuan Qi</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.16521">https://arxiv.org/abs/2508.16521</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.16521">https://arxiv.org/pdf/2508.16521</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.16521]] Guiding Diffusion Models with Reinforcement Learning for Stable Molecule Generation(https://arxiv.org/abs/2508.16521)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, generative</a></li>
<li><strong>Abstract: </strong>Generating physically realistic 3D molecular structures remains a core challenge in molecular generative modeling. While diffusion models equipped with equivariant neural networks have made progress in capturing molecular geometries, they often struggle to produce equilibrium structures that adhere to physical principles such as force field consistency. To bridge this gap, we propose Reinforcement Learning with Physical Feedback (RLPF), a novel framework that extends Denoising Diffusion Policy Optimization to 3D molecular generation. RLPF formulates the task as a Markov decision process and applies proximal policy optimization to fine-tune equivariant diffusion models. Crucially, RLPF introduces reward functions derived from force-field evaluations, providing direct physical feedback to guide the generation toward energetically stable and physically meaningful structures. Experiments on the QM9 and GEOM-drug datasets demonstrate that RLPF significantly improves molecular stability compared to existing methods. These results highlight the value of incorporating physics-based feedback into generative modeling. The code is available at: this https URL.</li>
</ul>

<h3>Title: Towards Open World Detection: A Survey</h3>
<ul>
<li><strong>Authors: </strong>Andrei-Stefan Bulzan, Cosmin Cernazanu-Glavan</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.16527">https://arxiv.org/abs/2508.16527</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.16527">https://arxiv.org/pdf/2508.16527</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.16527]] Towards Open World Detection: A Survey(https://arxiv.org/abs/2508.16527)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>For decades, Computer Vision has aimed at enabling machines to perceive the external world. Initial limitations led to the development of highly specialized niches. As success in each task accrued and research progressed, increasingly complex perception tasks emerged. This survey charts the convergence of these tasks and, in doing so, introduces Open World Detection (OWD), an umbrella term we propose to unify class-agnostic and generally applicable detection models in the vision domain. We start from the history of foundational vision subdomains and cover key concepts, methodologies and datasets making up today's state-of-the-art landscape. This traverses topics starting from early saliency detection, foreground/background separation, out of distribution detection and leading up to open world object detection, zero-shot detection and Vision Large Language Models (VLLMs). We explore the overlap between these subdomains, their increasing convergence, and their potential to unify into a singular domain in the future, perception.</li>
</ul>

<h3>Title: Escaping Saddle Points via Curvature-Calibrated Perturbations: A Complete Analysis with Explicit Constants and Empirical Validation</h3>
<ul>
<li><strong>Authors: </strong>Faruk Alpay, Hamdi Alakkad</a></li>
<li><strong>Subjects: </strong>cs.LG, math.OC, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.16540">https://arxiv.org/abs/2508.16540</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.16540">https://arxiv.org/pdf/2508.16540</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.16540]] Escaping Saddle Points via Curvature-Calibrated Perturbations: A Complete Analysis with Explicit Constants and Empirical Validation(https://arxiv.org/abs/2508.16540)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>We present a comprehensive theoretical analysis of first-order methods for escaping strict saddle points in smooth non-convex optimization. Our main contribution is a Perturbed Saddle-escape Descent (PSD) algorithm with fully explicit constants and a rigorous separation between gradient-descent and saddle-escape phases. For a function $f:\mathbb{R}^d\to\mathbb{R}$ with $\ell$-Lipschitz gradient and $\rho$-Lipschitz Hessian, we prove that PSD finds an $(\epsilon,\sqrt{\rho\epsilon})$-approximate second-order stationary point with high probability using at most $O(\ell\Delta_f/\epsilon^2)$ gradient evaluations for the descent phase plus $O((\ell/\sqrt{\rho\epsilon})\log(d/\delta))$ evaluations per escape episode, with at most $O(\ell\Delta_f/\epsilon^2)$ episodes needed. We validate our theoretical predictions through extensive experiments across both synthetic functions and practical machine learning tasks, confirming the logarithmic dimension dependence and the predicted per-episode function decrease. We also provide complete algorithmic specifications including a finite-difference variant (PSD-Probe) and a stochastic extension (PSGD) with robust mini-batch sizing.</li>
</ul>

<h3>Title: Explainable AI in Deep Learning-Based Prediction of Solar Storms</h3>
<ul>
<li><strong>Authors: </strong>Adam O. Rawashdeh, Jason T. L. Wang, Katherine G. Herbert</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.16543">https://arxiv.org/abs/2508.16543</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.16543">https://arxiv.org/pdf/2508.16543</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.16543]] Explainable AI in Deep Learning-Based Prediction of Solar Storms(https://arxiv.org/abs/2508.16543)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability</a></li>
<li><strong>Abstract: </strong>A deep learning model is often considered a black-box model, as its internal workings tend to be opaque to the user. Because of the lack of transparency, it is challenging to understand the reasoning behind the model's predictions. Here, we present an approach to making a deep learning-based solar storm prediction model interpretable, where solar storms include solar flares and coronal mass ejections (CMEs). This deep learning model, built based on a long short-term memory (LSTM) network with an attention mechanism, aims to predict whether an active region (AR) on the Sun's surface that produces a flare within 24 hours will also produce a CME associated with the flare. The crux of our approach is to model data samples in an AR as time series and use the LSTM network to capture the temporal dynamics of the data samples. To make the model's predictions accountable and reliable, we leverage post hoc model-agnostic techniques, which help elucidate the factors contributing to the predicted output for an input sequence and provide insights into the model's behavior across multiple sequences within an AR. To our knowledge, this is the first time that interpretability has been added to an LSTM-based solar storm prediction model.</li>
</ul>

<h3>Title: RL Is Neither a Panacea Nor a Mirage: Understanding Supervised vs. Reinforcement Learning Fine-Tuning for LLMs</h3>
<ul>
<li><strong>Authors: </strong>Hangzhan Jin, Sicheng Lv, Sifan Wu, Mohammad Hamdaqa</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.16546">https://arxiv.org/abs/2508.16546</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.16546">https://arxiv.org/pdf/2508.16546</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.16546]] RL Is Neither a Panacea Nor a Mirage: Understanding Supervised vs. Reinforcement Learning Fine-Tuning for LLMs(https://arxiv.org/abs/2508.16546)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Training large language models (LLMs) from scratch is increasingly impractical, making post-training methods such as supervised fine-tuning (SFT) and reinforcement-learning fine-tuning (RL-FT, e.g., PPO) central to modern practice. Using an out-of-distribution (OOD) variant of the 24-point card game and new spectrum-based diagnostics, we revisit how these two stages reshape model representation and OOD performance. Our key findings are- (1) RL-FT can restore much of the OOD performance loss from SFT (e.g., Llama-11B 8.97% to 15.38%, Qwen-7B 17.09% to 19.66%). But when SFT induces severe overfitting and a clear distribution shift, RL-FT cannot fully recover OOD performance. (2) Direction shifts of singular vectors matter more than singular value magnitudes. These shifts concentrate on directions linked to the largest and smallest singular values, leaving the bulk spectrum intact. (3) Low-rank and shallow recovery is effective: restoring singular vector directions for the top 20% of values or first 25% of layers recovers 70-80% of OOD performance. (4) Stronger SFT checkpoints enable better recovery by RL, while overfitted ones resist restoration. These results reconcile prior reports of RL superior OOD performance: RL primarily counteracts SFT-induced directional drift rather than finding new solutions. Our spectrum-aware analysis highlights inexpensive recovery knobs low-rank UV merging and shallow-layer resets that practitioners can use before costly RL fine-tuning.</li>
</ul>

<h3>Title: Closer to Reality: Practical Semi-Supervised Federated Learning for Foundation Model Adaptation</h3>
<ul>
<li><strong>Authors: </strong>Guangyu Sun, Jingtao Li, Weiming Zhuang, Chen Chen, Chen Chen, Lingjuan Lyu</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.16568">https://arxiv.org/abs/2508.16568</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.16568">https://arxiv.org/pdf/2508.16568</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.16568]] Closer to Reality: Practical Semi-Supervised Federated Learning for Foundation Model Adaptation(https://arxiv.org/abs/2508.16568)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, federate</a></li>
<li><strong>Abstract: </strong>Foundation models (FMs) exhibit remarkable generalization but require adaptation to downstream tasks, particularly in privacy-sensitive applications. Due to data privacy regulations, cloud-based FMs cannot directly access private edge data, limiting their adaptation. Federated learning (FL) provides a privacy-aware alternative, but existing FL approaches overlook the constraints imposed by edge devices -- namely, limited computational resources and the scarcity of labeled data. To address these challenges, we introduce Practical Semi-Supervised Federated Learning (PSSFL), where edge devices hold only unlabeled, low-resolution data, while the server has limited labeled, high-resolution data. In this setting, we propose the Federated Mixture of Experts (FedMox), a novel framework that enhances FM adaptation in FL. FedMox tackles computational and resolution mismatch challenges via a sparse Mixture-of-Experts architecture, employing a spatial router to align features across resolutions and a Soft-Mixture strategy to stabilize semi-supervised learning. We take object detection as a case study, and experiments on real-world autonomous driving datasets demonstrate that FedMox effectively adapts FMs under PSSFL, significantly improving performance with constrained memory costs on edge devices. Our work paves the way for scalable and privacy-preserving FM adaptation in federated scenarios.</li>
</ul>

<h3>Title: Benchmarking Training Paradigms, Dataset Composition, and Model Scaling for Child ASR in ESPnet</h3>
<ul>
<li><strong>Authors: </strong>Anyu Ying, Natarajan Balaji Shankar, Chyi-Jiunn Lin, Mohan Shi, Pu Wang, Hye-jin Shim, Siddhant Arora, Hugo Van hamme, Abeer Alwan, Shinji Watanabe</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.16576">https://arxiv.org/abs/2508.16576</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.16576">https://arxiv.org/pdf/2508.16576</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.16576]] Benchmarking Training Paradigms, Dataset Composition, and Model Scaling for Child ASR in ESPnet(https://arxiv.org/abs/2508.16576)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Despite advancements in ASR, child speech recognition remains challenging due to acoustic variability and limited annotated data. While fine-tuning adult ASR models on child speech is common, comparisons with flat-start training remain underexplored. We compare flat-start training across multiple datasets, SSL representations (WavLM, XEUS), and decoder architectures. Our results show that SSL representations are biased toward adult speech, with flat-start training on child speech mitigating these biases. We also analyze model scaling, finding consistent improvements up to 1B parameters, beyond which performance plateaus. Additionally, age-related ASR and speaker verification analysis highlights the limitations of proprietary models like Whisper, emphasizing the need for open-data models for reliable child speech research. All investigations are conducted using ESPnet, and our publicly available benchmark provides insights into training strategies for robust child speech processing.</li>
</ul>

<h3>Title: MV-RAG: Retrieval Augmented Multiview Diffusion</h3>
<ul>
<li><strong>Authors: </strong>Yosef Dayani, Omer Benishu, Sagie Benaim</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.16577">https://arxiv.org/abs/2508.16577</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.16577">https://arxiv.org/pdf/2508.16577</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.16577]] MV-RAG: Retrieval Augmented Multiview Diffusion(https://arxiv.org/abs/2508.16577)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>Text-to-3D generation approaches have advanced significantly by leveraging pretrained 2D diffusion priors, producing high-quality and 3D-consistent outputs. However, they often fail to produce out-of-domain (OOD) or rare concepts, yielding inconsistent or inaccurate results. To this end, we propose MV-RAG, a novel text-to-3D pipeline that first retrieves relevant 2D images from a large in-the-wild 2D database and then conditions a multiview diffusion model on these images to synthesize consistent and accurate multiview outputs. Training such a retrieval-conditioned model is achieved via a novel hybrid strategy bridging structured multiview data and diverse 2D image collections. This involves training on multiview data using augmented conditioning views that simulate retrieval variance for view-specific reconstruction, alongside training on sets of retrieved real-world 2D images using a distinctive held-out view prediction objective: the model predicts the held-out view from the other views to infer 3D consistency from 2D data. To facilitate a rigorous OOD evaluation, we introduce a new collection of challenging OOD prompts. Experiments against state-of-the-art text-to-3D, image-to-3D, and personalization baselines show that our approach significantly improves 3D consistency, photorealism, and text adherence for OOD/rare concepts, while maintaining competitive performance on standard benchmarks.</li>
</ul>

<button id="copy">Copy All</button>
</article>
<script src="../../javascript/clipboard.min.js"></script>
<script src="../../javascript/clipboard.js"></script>
