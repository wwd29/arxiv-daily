<link rel="stylesheet" href="../../css/markdown.css" />
<article class="markdown-body">
<h1>2025-01-29</h1>
<h3>Title: Self-Clustering Graph Transformer Approach to Model Resting-State Functional Brain Activity</h3>
<ul>
<li><strong>Authors: </strong>Bishal Thapaliya, Esra Akbas, Ram Sapkota, Bhaskar Ray, Vince Calhoun, Jingyu Liu</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2501.16345">https://arxiv.org/abs/2501.16345</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2501.16345">https://arxiv.org/pdf/2501.16345</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2501.16345]] Self-Clustering Graph Transformer Approach to Model Resting-State Functional Brain Activity(https://arxiv.org/abs/2501.16345)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Resting-state functional magnetic resonance imaging (rs-fMRI) offers valuable insights into the human brain's functional organization and is a powerful tool for investigating the relationship between brain function and cognitive processes, as it allows for the functional organization of the brain to be captured without relying on a specific task or stimuli. In this study, we introduce a novel attention mechanism for graphs with subnetworks, named Self-Clustering Graph Transformer (SCGT), designed to handle the issue of uniform node updates in graph transformers. By using static functional connectivity (FC) correlation features as input to the transformer model, SCGT effectively captures the sub-network structure of the brain by performing cluster-specific updates to the nodes, unlike uniform node updates in vanilla graph transformers, further allowing us to learn and interpret the subclusters. We validate our approach on the Adolescent Brain Cognitive Development (ABCD) dataset, comprising 7,957 participants, for the prediction of total cognitive score and gender classification. Our results demonstrate that SCGT outperforms the vanilla graph transformer method and other recent models, offering a promising tool for modeling brain functional connectivity and interpreting the underlying subnetwork structures.</li>
</ul>

<h3>Title: Self-supervised Graph Transformer with Contrastive Learning for Brain Connectivity Analysis towards Improving Autism Detection</h3>
<ul>
<li><strong>Authors: </strong>Yicheng Leng, Syed Muhammad Anwar, Islem Rekik, Sen He, Eung-Joo Lee</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2501.16346">https://arxiv.org/abs/2501.16346</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2501.16346">https://arxiv.org/pdf/2501.16346</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2501.16346]] Self-supervised Graph Transformer with Contrastive Learning for Brain Connectivity Analysis towards Improving Autism Detection(https://arxiv.org/abs/2501.16346)</code><input type="text"></li>
<li><strong>Keywords: </strong>explainability, transformer</a></li>
<li><strong>Abstract: </strong>Functional Magnetic Resonance Imaging (fMRI) provides useful insights into the brain function both during task or rest. Representing fMRI data using correlation matrices is found to be a reliable method of analyzing the inherent connectivity of the brain in the resting and active states. Graph Neural Networks (GNNs) have been widely used for brain network analysis due to their inherent explainability capability. In this work, we introduce a novel framework using contrastive self-supervised learning graph transformers, incorporating a brain network transformer encoder with random graph alterations. The proposed network leverages both contrastive learning and graph alterations to effectively train the graph transformer for autism detection. Our approach, tested on Autism Brain Imaging Data Exchange (ABIDE) data, demonstrates superior autism detection, achieving an AUROC of 82.6 and an accuracy of 74%, surpassing current state-of-the-art methods.</li>
</ul>

<h3>Title: An Integrated Approach to AI-Generated Content in e-health</h3>
<ul>
<li><strong>Authors: </strong>Tasnim Ahmed, Salimur Choudhury</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2501.16348">https://arxiv.org/abs/2501.16348</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2501.16348">https://arxiv.org/pdf/2501.16348</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2501.16348]] An Integrated Approach to AI-Generated Content in e-health(https://arxiv.org/abs/2501.16348)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, diffusion, generative, large language model</a></li>
<li><strong>Abstract: </strong>Artificial Intelligence-Generated Content, a subset of Generative Artificial Intelligence, holds significant potential for advancing the e-health sector by generating diverse forms of data. In this paper, we propose an end-to-end class-conditioned framework that addresses the challenge of data scarcity in health applications by generating synthetic medical images and text data, evaluating on practical applications such as retinopathy detection, skin infections and mental health assessments. Our framework integrates Diffusion and Large Language Models (LLMs) to generate data that closely match real-world patterns, which is essential for improving downstream task performance and model robustness in e-health applications. Experimental results demonstrate that the synthetic images produced by the proposed diffusion model outperform traditional GAN architectures. Similarly, in the text modality, data generated by uncensored LLM achieves significantly better alignment with real-world data than censored models in replicating the authentic tone.</li>
</ul>

<h3>Title: Risk-Informed Diffusion Transformer for Long-Tail Trajectory Prediction in the Crash Scenario</h3>
<ul>
<li><strong>Authors: </strong>Junlan Chen, Pei Liu, Zihao Zhang, Hongyi Zhao, Yufei Ji, Ziyuan Pu</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2501.16349">https://arxiv.org/abs/2501.16349</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2501.16349">https://arxiv.org/pdf/2501.16349</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2501.16349]] Risk-Informed Diffusion Transformer for Long-Tail Trajectory Prediction in the Crash Scenario(https://arxiv.org/abs/2501.16349)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, transformer</a></li>
<li><strong>Abstract: </strong>Trajectory prediction methods have been widely applied in autonomous driving technologies. Although the overall performance accuracy of trajectory prediction is relatively high, the lack of trajectory data in critical scenarios in the training data leads to the long-tail phenomenon. Normally, the trajectories of the tail data are more critical and more difficult to predict and may include rare scenarios such as crashes. To solve this problem, we extracted the trajectory data from real-world crash scenarios, which contain more long-tail data. Meanwhile, based on the trajectory data in this scenario, we integrated graph-based risk information and diffusion with transformer and proposed the Risk-Informed Diffusion Transformer (RI-DiT) trajectory prediction method. Extensive experiments were conducted on trajectory data in the real-world crash scenario, and the results show that the algorithm we proposed has good performance. When predicting the data of the tail 10\% (Top 10\%), the minADE and minFDE indicators are 0.016/2.667 m. At the same time, we showed the trajectory conditions of different long-tail distributions. The distribution of trajectory data is closer to the tail, the less smooth the trajectory is. Through the trajectory data in real-world crash scenarios, Our work expands the methods to overcome the long-tail challenges in trajectory prediction. Our method, RI-DiT, integrates inverse time to collision (ITTC) and the feature of traffic flow, which can predict long-tail trajectories more accurately and improve the safety of autonomous driving systems.</li>
</ul>

<h3>Title: How Strategic Agents Respond: Comparing Analytical Models with LLM-Generated Responses in Strategic Classification</h3>
<ul>
<li><strong>Authors: </strong>Tian Xie, Pavan Rauch, Xueru Zhang</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2501.16355">https://arxiv.org/abs/2501.16355</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2501.16355">https://arxiv.org/pdf/2501.16355</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2501.16355]] How Strategic Agents Respond: Comparing Analytical Models with LLM-Generated Responses in Strategic Classification(https://arxiv.org/abs/2501.16355)</code><input type="text"></li>
<li><strong>Keywords: </strong>fair, large language model</a></li>
<li><strong>Abstract: </strong>When machine learning (ML) algorithms are used to automate human-related decisions, human agents may gain knowledge of the decision policy and behave strategically to obtain desirable outcomes. Strategic Classification (SC) has been proposed to address the interplay between agents and decision-makers. Prior work on SC has relied on assumptions that agents are perfectly or approximately rational, responding to decision policies by maximizing their utilities. Verifying these assumptions is challenging due to the difficulty of collecting real-world agent responses. Meanwhile, the growing adoption of large language models (LLMs) makes it increasingly likely that human agents in SC settings will seek advice from these tools. We propose using strategic advice generated by LLMs to simulate human agent responses in SC. Specifically, we examine five critical SC scenarios -- hiring, loan applications, school admissions, personal income, and public assistance programs -- and simulate how human agents with diverse profiles seek advice from LLMs. We then compare the resulting agent responses with the best responses generated by existing theoretical models. Our findings reveal that: (i) LLMs and theoretical models generally lead to agent score or qualification changes in the same direction across most settings, with both achieving similar levels of fairness; (ii) state-of-the-art commercial LLMs (e.g., GPT-3.5, GPT-4) consistently provide helpful suggestions, though these suggestions typically do not result in maximal score or qualification improvements; and (iii) LLMs tend to produce more diverse agent responses, often favoring more balanced effort allocation strategies. These results suggest that theoretical models align with LLMs to some extent and that leveraging LLMs to simulate more realistic agent responses offers a promising approach to designing trustworthy ML systems.</li>
</ul>

<h3>Title: Evaluating Binary Decision Biases in Large Language Models: Implications for Fair Agent-Based Financial Simulations</h3>
<ul>
<li><strong>Authors: </strong>Alicia Vidler, Toby Walsh</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2501.16356">https://arxiv.org/abs/2501.16356</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2501.16356">https://arxiv.org/pdf/2501.16356</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2501.16356]] Evaluating Binary Decision Biases in Large Language Models: Implications for Fair Agent-Based Financial Simulations(https://arxiv.org/abs/2501.16356)</code><input type="text"></li>
<li><strong>Keywords: </strong>fair, large language model</a></li>
<li><strong>Abstract: </strong>Large Language Models (LLMs) are increasingly being used to simulate human-like decision making in agent-based financial market models (ABMs). As models become more powerful and accessible, researchers can now incorporate individual LLM decisions into ABM environments. However, integration may introduce inherent biases that need careful evaluation. In this paper we test three state-of-the-art GPT models for bias using two model sampling approaches: one-shot and few-shot API queries. We observe significant variations in distributions of outputs between specific models, and model sub versions, with GPT-4o-Mini-2024-07-18 showing notably better performance (32-43% yes responses) compared to GPT-4-0125-preview's extreme bias (98-99% yes responses). We show that sampling methods and model sub-versions significantly impact results: repeated independent API calls produce different distributions compared to batch sampling within a single call. While no current GPT model can simultaneously achieve a uniform distribution and Markovian properties in one-shot testing, few-shot sampling can approach uniform distributions under certain conditions. We explore the Temperature parameter, providing a definition and comparative results. We further compare our results to true random binary series and test specifically for the common human bias of Negative Recency - finding LLMs have a mixed ability to 'beat' humans in this one regard. These findings emphasise the critical importance of careful LLM integration into ABMs for financial markets and more broadly.</li>
</ul>

<h3>Title: EVolutionary Independent DEtermiNistiC Explanation</h3>
<ul>
<li><strong>Authors: </strong>Vincenzo Dentamaro, Paolo Giglio, Donato Impedovo, Giuseppe Pirlo</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2501.16357">https://arxiv.org/abs/2501.16357</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2501.16357">https://arxiv.org/pdf/2501.16357</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2501.16357]] EVolutionary Independent DEtermiNistiC Explanation(https://arxiv.org/abs/2501.16357)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, explainability</a></li>
<li><strong>Abstract: </strong>The widespread use of artificial intelligence deep neural networks in fields such as medicine and engineering necessitates understanding their decision-making processes. Current explainability methods often produce inconsistent results and struggle to highlight essential signals influencing model inferences. This paper introduces the Evolutionary Independent Deterministic Explanation (EVIDENCE) theory, a novel approach offering a deterministic, model-independent method for extracting significant signals from black-box models. EVIDENCE theory, grounded in robust mathematical formalization, is validated through empirical tests on diverse datasets, including COVID-19 audio diagnostics, Parkinson's disease voice recordings, and the George Tzanetakis music classification dataset (GTZAN). Practical applications of EVIDENCE include improving diagnostic accuracy in healthcare and enhancing audio signal analysis. For instance, in the COVID-19 use case, EVIDENCE-filtered spectrograms fed into a frozen Residual Network with 50 layers improved precision by 32% for positive cases and increased the area under the curve (AUC) by 16% compared to baseline models. For Parkinson's disease classification, EVIDENCE achieved near-perfect precision and sensitivity, with a macro average F1-Score of 0.997. In the GTZAN, EVIDENCE maintained a high AUC of 0.996, demonstrating its efficacy in filtering relevant features for accurate genre classification. EVIDENCE outperformed other Explainable Artificial Intelligence (XAI) methods such as LIME, SHAP, and GradCAM in almost all metrics. These findings indicate that EVIDENCE not only improves classification accuracy but also provides a transparent and reproducible explanation mechanism, crucial for advancing the trustworthiness and applicability of AI systems in real-world settings.</li>
</ul>

<h3>Title: The OpenLAM Challenges</h3>
<ul>
<li><strong>Authors: </strong>Anyang Peng, Xinzijian Liu, Ming-Yu Guo, Linfeng Zhang, Han Wang</a></li>
<li><strong>Subjects: </strong>cs.LG, cond-mat.mtrl-sci</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2501.16358">https://arxiv.org/abs/2501.16358</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2501.16358">https://arxiv.org/pdf/2501.16358</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2501.16358]] The OpenLAM Challenges(https://arxiv.org/abs/2501.16358)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative, large language model</a></li>
<li><strong>Abstract: </strong>Inspired by the success of Large Language Models (LLMs), the development of Large Atom Models (LAMs) has gained significant momentum in scientific computation. Since 2022, the Deep Potential team has been actively pretraining LAMs and launched the OpenLAM Initiative to develop an open-source foundation model spanning the periodic table. A core objective is establishing comprehensive benchmarks for reliable LAM evaluation, addressing limitations in existing datasets. As a first step, the LAM Crystal Philately competition has collected over 19.8 million valid structures, including 1 million on the OpenLAM convex hull, driving advancements in generative modeling and materials science applications.</li>
</ul>

<h3>Title: Momentum Contrastive Learning with Enhanced Negative Sampling and Hard Negative Filtering</h3>
<ul>
<li><strong>Authors: </strong>Duy Hoang, Huy Ngo, Khoi Pham, Tri Nguyen, Gia Bao, Huy Phan</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2501.16360">https://arxiv.org/abs/2501.16360</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2501.16360">https://arxiv.org/pdf/2501.16360</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2501.16360]] Momentum Contrastive Learning with Enhanced Negative Sampling and Hard Negative Filtering(https://arxiv.org/abs/2501.16360)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Contrastive learning has become pivotal in unsupervised representation learning, with frameworks like Momentum Contrast (MoCo) effectively utilizing large negative sample sets to extract discriminative features. However, traditional approaches often overlook the full potential of key embeddings and are susceptible to performance degradation from noisy negative samples in the memory bank. This study addresses these challenges by proposing an enhanced contrastive learning framework that incorporates two key innovations. First, we introduce a dual-view loss function, which ensures balanced optimization of both query and key embeddings, improving representation quality. Second, we develop a selective negative sampling strategy that emphasizes the most challenging negatives based on cosine similarity, mitigating the impact of noise and enhancing feature discrimination. Extensive experiments demonstrate that our framework achieves superior performance on downstream tasks, delivering robust and well-structured representations. These results highlight the potential of optimized contrastive mechanisms to advance unsupervised learning and extend its applicability across domains such as computer vision and natural language processing</li>
</ul>

<h3>Title: Large Language Models Meet Graph Neural Networks for Text-Numeric Graph Reasoning</h3>
<ul>
<li><strong>Authors: </strong>Haoran Song, Jiarui Feng, Guangfu Li, Michael Province, Philip Payne, Yixin Chen, Fuhai Li</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2501.16361">https://arxiv.org/abs/2501.16361</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2501.16361">https://arxiv.org/pdf/2501.16361</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2501.16361]] Large Language Models Meet Graph Neural Networks for Text-Numeric Graph Reasoning(https://arxiv.org/abs/2501.16361)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>In real-world scientific discovery, human beings always make use of the accumulated prior knowledge with imagination pick select one or a few most promising hypotheses from large and noisy data analysis results. In this study, we introduce a new type of graph structure, the text-numeric graph (TNG), which is defined as graph entities and associations have both text-attributed information and numeric information. The TNG is an ideal data structure model for novel scientific discovery via graph reasoning because it integrates human-understandable textual annotations or prior knowledge, with numeric values that represent the observed or activation levels of graph entities or associations in different samples. Together both the textual information and numeric values determine the importance of graph entities and associations in graph reasoning for novel scientific knowledge discovery. We further propose integrating large language models (LLMs) and graph neural networks (GNNs) to analyze the TNGs for graph understanding and reasoning. To demonstrate the utility, we generated the text-omic(numeric) signaling graphs (TOSG), as one type of TNGs, in which all graphs have the same entities, associations and annotations, but have sample-specific entity numeric (omic) values using single cell RNAseq (scRNAseq) datasets of different diseases. We proposed joint LLM-GNN models for key entity mining and signaling pathway mining on the TOSGs. The evaluation results showed the LLM-GNN and TNGs models significantly improve classification accuracy and network inference. In conclusion, the TNGs and joint LLM-GNN models are important approaches for scientific discovery.</li>
</ul>

<h3>Title: Foundation Models for CPS-IoT: Opportunities and Challenges</h3>
<ul>
<li><strong>Authors: </strong>Ozan Baris, Yizhuo Chen, Gaofeng Dong, Liying Han, Tomoyoshi Kimura, Pengrui Quan, Ruijie Wang, Tianchen Wang, Tarek Abdelzaher, Mario Bergés, Paul Pu Liang, Mani Srivastava</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, eess.SY</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2501.16368">https://arxiv.org/abs/2501.16368</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2501.16368">https://arxiv.org/pdf/2501.16368</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2501.16368]] Foundation Models for CPS-IoT: Opportunities and Challenges(https://arxiv.org/abs/2501.16368)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Methods from machine learning (ML) have transformed the implementation of Perception-Cognition-Communication-Action loops in Cyber-Physical Systems (CPS) and the Internet of Things (IoT), replacing mechanistic and basic statistical models with those derived from data. However, the first generation of ML approaches, which depend on supervised learning with annotated data to create task-specific models, faces significant limitations in scaling to the diverse sensor modalities, deployment configurations, application tasks, and operating dynamics characterizing real-world CPS-IoT systems. The success of task-agnostic foundation models (FMs), including multimodal large language models (LLMs), in addressing similar challenges across natural language, computer vision, and human speech has generated considerable enthusiasm for and exploration of FMs and LLMs as flexible building blocks in CPS-IoT analytics pipelines, promising to reduce the need for costly task-specific engineering. Nonetheless, a significant gap persists between the current capabilities of FMs and LLMs in the CPS-IoT domain and the requirements they must meet to be viable for CPS-IoT applications. In this paper, we analyze and characterize this gap through a thorough examination of the state of the art and our research, which extends beyond it in various dimensions. Based on the results of our analysis and research, we identify essential desiderata that CPS-IoT domain-specific FMs and LLMs must satisfy to bridge this gap. We also propose actions by CPS-IoT researchers to collaborate in developing key community resources necessary for establishing FMs and LLMs as foundational tools for the next generation of CPS-IoT systems.</li>
</ul>

<h3>Title: Advanced Physics-Informed Neural Network with Residuals for Solving Complex Integral Equations</h3>
<ul>
<li><strong>Authors: </strong>Mahdi Movahedian Moghaddam, Kourosh Parand, Saeed Reza Kheradpisheh</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.NE, math.NA</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2501.16370">https://arxiv.org/abs/2501.16370</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2501.16370">https://arxiv.org/pdf/2501.16370</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2501.16370]] Advanced Physics-Informed Neural Network with Residuals for Solving Complex Integral Equations(https://arxiv.org/abs/2501.16370)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>In this paper, we present the Residual Integral Solver Network (RISN), a novel neural network architecture designed to solve a wide range of integral and integro-differential equations, including one-dimensional, multi-dimensional, ordinary and partial integro-differential, systems, and fractional types. RISN integrates residual connections with high-accurate numerical methods such as Gaussian quadrature and fractional derivative operational matrices, enabling it to achieve higher accuracy and stability than traditional Physics-Informed Neural Networks (PINN). The residual connections help mitigate vanishing gradient issues, allowing RISN to handle deeper networks and more complex kernels, particularly in multi-dimensional problems. Through extensive experiments, we demonstrate that RISN consistently outperforms PINN, achieving significantly lower Mean Absolute Errors (MAE) across various types of equations. The results highlight RISN's robustness and efficiency in solving challenging integral and integro-differential problems, making it a valuable tool for real-world applications where traditional methods often struggle.</li>
</ul>

<h3>Title: Low-Rank Adapters Meet Neural Architecture Search for LLM Compression</h3>
<ul>
<li><strong>Authors: </strong>J. Pablo Muñoz, Jinjie Yuan, Nilesh Jain</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2501.16372">https://arxiv.org/abs/2501.16372</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2501.16372">https://arxiv.org/pdf/2501.16372</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2501.16372]] Low-Rank Adapters Meet Neural Architecture Search for LLM Compression(https://arxiv.org/abs/2501.16372)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, large language model</a></li>
<li><strong>Abstract: </strong>The rapid expansion of Large Language Models (LLMs) has posed significant challenges regarding the computational resources required for fine-tuning and deployment. Recent advancements in low-rank adapters have demonstrated their efficacy in parameter-efficient fine-tuning (PEFT) of these models. This retrospective paper comprehensively discusses innovative approaches that synergize low-rank representations with Neural Architecture Search (NAS) techniques, particularly weight-sharing super-networks. Robust solutions for compressing and fine-tuning large pre-trained models are developed by integrating these methodologies. Our analysis highlights the potential of these combined strategies to democratize the use of LLMs, making them more accessible for deployment in resource-constrained environments. The resulting models exhibit reduced memory footprints and faster inference times, paving the way for more practical and scalable applications of LLMs. Models and code are available at this https URL.</li>
</ul>

<h3>Title: SAFR: Neuron Redistribution for Interpretability</h3>
<ul>
<li><strong>Authors: </strong>Ruidi Chang, Chunyuan Deng, Hanjie Chen</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2501.16374">https://arxiv.org/abs/2501.16374</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2501.16374">https://arxiv.org/pdf/2501.16374</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2501.16374]] SAFR: Neuron Redistribution for Interpretability(https://arxiv.org/abs/2501.16374)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability, transformer</a></li>
<li><strong>Abstract: </strong>Superposition refers to encoding representations of multiple features within a single neuron, which is common in transformers. This property allows neurons to combine and represent multiple features, enabling the model to capture intricate information and handle complex tasks. Despite promising performance, the model's interpretability has been diminished. This paper presents a novel approach to enhance transformer interpretability by regularizing feature superposition. We introduce SAFR, which simply applies regularizations to the loss function to promote monosemantic representations for important tokens while encouraging polysemanticity for correlated token pairs, where important tokens and correlated token pairs are identified via VMASK and attention weights. With a transformer model on two classification tasks, SAFR improves interpretability without compromising prediction performance. Given an input to the model, SAFR provides an explanation by visualizing the neuron allocation and interaction within the MLP layers.</li>
</ul>

<h3>Title: HWPQ: Hessian-free Weight Pruning-Quantization For LLM Compression And Acceleration</h3>
<ul>
<li><strong>Authors: </strong>Yuhan Kang, Zhongdi Luo, Mei Wen, Yang Shi, Jun He, Jianchao Yang, Zeyu Xue, Jing Feng, Xinwang Liu</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2501.16376">https://arxiv.org/abs/2501.16376</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2501.16376">https://arxiv.org/pdf/2501.16376</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2501.16376]] HWPQ: Hessian-free Weight Pruning-Quantization For LLM Compression And Acceleration(https://arxiv.org/abs/2501.16376)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large Language Models (LLMs) have achieved remarkable success across numerous domains. However, the high time complexity of existing pruning and quantization methods significantly hinders their effective deployment on resource-constrained consumer or edge devices. In this study, we propose a novel Hessian-free Weight Pruning-Quantization (HWPQ) method. HWPQ eliminates the need for computationally intensive Hessian matrix calculations by introducing a contribution-based weight metric, which evaluates the importance of weights without relying on second-order derivatives. Additionally, we employ the Exponentially Weighted Moving Average (EWMA) technique to bypass weight sorting, enabling the selection of weights that contribute most to LLM accuracy and further reducing time complexity. Our approach is extended to support 2:4 structured sparsity pruning, facilitating efficient execution on modern hardware accelerators. Experimental results demonstrate that HWPQ significantly enhances the compression performance of LLaMA2. Compared to state-of-the-art quantization and pruning frameworks, HWPQ achieves average speedups of 5.97x (up to 20.75x) in quantization time and 12.29x (up to 56.02x) in pruning time, while largely preserving model accuracy. Furthermore, we observe a 1.50x inference speedup compared to the baseline.</li>
</ul>

<h3>Title: Internal Activation Revision: Safeguarding Vision Language Models Without Parameter Update</h3>
<ul>
<li><strong>Authors: </strong>Qing Li, Jiahui Geng, Zongxiong Chen, Kun Song, Lei Ma, Fakhri Karray</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CL, cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2501.16378">https://arxiv.org/abs/2501.16378</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2501.16378">https://arxiv.org/pdf/2501.16378</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2501.16378]] Internal Activation Revision: Safeguarding Vision Language Models Without Parameter Update(https://arxiv.org/abs/2501.16378)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack, robust, large language model</a></li>
<li><strong>Abstract: </strong>Vision-language models (VLMs) demonstrate strong multimodal capabilities but have been found to be more susceptible to generating harmful content compared to their backbone large language models (LLMs). Our investigation reveals that the integration of images significantly shifts the model's internal activations during the forward pass, diverging from those triggered by textual input. Moreover, the safety alignments of LLMs embedded within VLMs are not sufficiently robust to handle the activations discrepancies, making the models vulnerable to even the simplest jailbreaking attacks. To address this issue, we propose an \textbf{internal activation revision} approach that efficiently revises activations during generation, steering the model toward safer outputs. Our framework incorporates revisions at both the layer and head levels, offering control over the model's generation at varying levels of granularity. In addition, we explore three strategies for constructing positive and negative samples and two approaches for extracting revision vectors, resulting in different variants of our method. Comprehensive experiments demonstrate that the internal activation revision method significantly improves the safety of widely used VLMs, reducing attack success rates by an average of 48.94\%, 34.34\%, 43.92\%, and 52.98\% on SafeBench, Safe-Unsafe, Unsafe, and MM-SafetyBench, respectively, while minimally impacting model helpfulness.</li>
</ul>

<h3>Title: FedAGHN: Personalized Federated Learning with Attentive Graph HyperNetworks</h3>
<ul>
<li><strong>Authors: </strong>Jiarui Song, Yunheng Shen, Chengbin Hou, Pengyu Wang, Jinbao Wang, Ke Tang, Hairong Lv</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2501.16379">https://arxiv.org/abs/2501.16379</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2501.16379">https://arxiv.org/pdf/2501.16379</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2501.16379]] FedAGHN: Personalized Federated Learning with Attentive Graph HyperNetworks(https://arxiv.org/abs/2501.16379)</code><input type="text"></li>
<li><strong>Keywords: </strong>federate</a></li>
<li><strong>Abstract: </strong>Personalized Federated Learning (PFL) aims to address the statistical heterogeneity of data across clients by learning the personalized model for each client. Among various PFL approaches, the personalized aggregation-based approach conducts parameter aggregation in the server-side aggregation phase to generate personalized models, and focuses on learning appropriate collaborative relationships among clients for aggregation. However, the collaborative relationships vary in different scenarios and even at different stages of the FL process. To this end, we propose Personalized Federated Learning with Attentive Graph HyperNetworks (FedAGHN), which employs Attentive Graph HyperNetworks (AGHNs) to dynamically capture fine-grained collaborative relationships and generate client-specific personalized initial models. Specifically, AGHNs empower graphs to explicitly model the client-specific collaborative relationships, construct collaboration graphs, and introduce tunable attentive mechanism to derive the collaboration weights, so that the personalized initial models can be obtained by aggregating parameters over the collaboration graphs. Extensive experiments can demonstrate the superiority of FedAGHN. Moreover, a series of visualizations are presented to explore the effectiveness of collaboration graphs learned by FedAGHN.</li>
</ul>

<h3>Title: UDiTQC: U-Net-Style Diffusion Transformer for Quantum Circuit Synthesis</h3>
<ul>
<li><strong>Authors: </strong>Zhiwei Chen, Hao Tang</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, quant-ph</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2501.16380">https://arxiv.org/abs/2501.16380</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2501.16380">https://arxiv.org/pdf/2501.16380</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2501.16380]] UDiTQC: U-Net-Style Diffusion Transformer for Quantum Circuit Synthesis(https://arxiv.org/abs/2501.16380)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction, diffusion, transformer, generative</a></li>
<li><strong>Abstract: </strong>Quantum computing is a transformative technology with wide-ranging applications, and efficient quantum circuit generation is crucial for unlocking its full potential. Current diffusion model approaches based on U-Net architectures, while promising, encounter challenges related to computational efficiency and modeling global context. To address these issues, we propose UDiT,a novel U-Net-style Diffusion Transformer architecture, which combines U-Net's strengths in multi-scale feature extraction with the Transformer's ability to model global context. We demonstrate the framework's effectiveness on two tasks: entanglement generation and unitary compilation, where UDiTQC consistently outperforms existing methods. Additionally, our framework supports tasks such as masking and editing circuits to meet specific physical property requirements. This dual advancement, improving quantum circuit synthesis and refining generative model architectures, marks a significant milestone in the convergence of quantum computing and machine learning research.</li>
</ul>

<h3>Title: RotateKV: Accurate and Robust 2-Bit KV Cache Quantization for LLMs via Outlier-Aware Adaptive Rotations</h3>
<ul>
<li><strong>Authors: </strong>Zunhai Su, Zhe Chen, Wang Shen, Hanyu Wei, Linge Li, Huangqi Yu, Kehong Yuan</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2501.16383">https://arxiv.org/abs/2501.16383</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2501.16383">https://arxiv.org/pdf/2501.16383</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2501.16383]] RotateKV: Accurate and Robust 2-Bit KV Cache Quantization for LLMs via Outlier-Aware Adaptive Rotations(https://arxiv.org/abs/2501.16383)</code><input type="text"></li>
<li><strong>Keywords: </strong>protect, robust, large language model</a></li>
<li><strong>Abstract: </strong>Key-Value (KV) cache facilitates efficient large language models (LLMs) inference by avoiding recomputation of past KVs. As the batch size and context length increase, the oversized KV caches become a significant memory bottleneck, highlighting the need for efficient compression. Existing KV quantization rely on fine-grained quantization or the retention of a significant portion of high bit-widths caches, both of which compromise compression ratio and often fail to maintain robustness at extremely low average bit-widths. In this work, we explore the potential of rotation technique for 2-bit KV quantization and propose RotateKV, which achieves accurate and robust performance through the following innovations: (i) Outlier-Aware Rotation, which utilizes channel-reordering to adapt the rotations to varying channel-wise outlier distributions without sacrificing the computational efficiency of the fast Walsh-Hadamard transform (FWHT); (ii) Pre-RoPE Grouped-Head Rotation, which mitigates the impact of rotary position embedding (RoPE) on proposed outlier-aware rotation and further smooths outliers across heads; (iii) Attention-Sink-Aware Quantization, which leverages the massive activations to precisely identify and protect attention sinks. RotateKV achieves less than 0.3 perplexity (PPL) degradation with 2-bit quantization on WikiText-2 using LLaMA-2-13B, maintains strong CoT reasoning and long-context capabilities, with less than 1.7\% degradation on GSM8K, outperforming existing methods even at lower average bit-widths. RotateKV also showcases a 3.97x reduction in peak memory usage, supports 5.75x larger batch sizes, and achieves a 2.32x speedup in decoding stage.</li>
</ul>

<h3>Title: FBQuant: FeedBack Quantization for Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Yijiang Liu, Hengyu Fang, Liulu He, Rongyu Zhang, Yichuan Bai, Yuan Du, Li Du</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2501.16385">https://arxiv.org/abs/2501.16385</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2501.16385">https://arxiv.org/pdf/2501.16385</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2501.16385]] FBQuant: FeedBack Quantization for Large Language Models(https://arxiv.org/abs/2501.16385)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, robust, large language model</a></li>
<li><strong>Abstract: </strong>Deploying Large Language Models (LLMs) on edge devices is increasingly important, as it eliminates reliance on network connections, reduces expensive API calls, and enhances user privacy. However, on-device deployment is challenging due to the limited computational resources of edge devices. In particular, the key bottleneck stems from memory bandwidth constraints related to weight loading. Weight-only quantization effectively reduces memory access, yet often induces significant accuracy degradation. Recent efforts to incorporate sub-branches have shown promise for mitigating quantization errors, but these methods either lack robust optimization strategies or rely on suboptimal objectives. To address these gaps, we propose FeedBack Quantization (FBQuant), a novel approach inspired by negative feedback mechanisms in automatic control. FBQuant inherently ensures that the reconstructed weights remain bounded by the quantization process, thereby reducing the risk of overfitting. To further offset the additional latency introduced by sub-branches, we develop an efficient CUDA kernel that decreases 60\% of extra inference time. Comprehensive experiments demonstrate the efficiency and effectiveness of FBQuant across various LLMs. Notably, for 3-bit Llama2-7B, FBQuant improves zero-shot accuracy by 1.2\%.</li>
</ul>

<h3>Title: Leveraging Induced Transferable Binding Principles for Associative Prediction of Novel Drug-Target Interactions</h3>
<ul>
<li><strong>Authors: </strong>Xiaoqing Lian, Jie Zhu, Tianxu Lv, Shiyun Nie, Hang Fan, Guosheng Wu, Yunjun Ge, Lihua Li, Xiangxiang Zeng, Xiang Pan</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, q-bio.BM</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2501.16391">https://arxiv.org/abs/2501.16391</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2501.16391">https://arxiv.org/pdf/2501.16391</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2501.16391]] Leveraging Induced Transferable Binding Principles for Associative Prediction of Novel Drug-Target Interactions(https://arxiv.org/abs/2501.16391)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Significant differences in protein structures hinder the generalization of existing drug-target interaction (DTI) models, which often rely heavily on pre-learned binding principles or detailed annotations. In contrast, BioBridge designs an Inductive-Associative pipeline inspired by the workflow of scientists who base their accumulated expertise on drawing insights into novel drug-target pairs from weakly related references. BioBridge predicts novel drug-target interactions using limited sequence data, incorporating multi-level encoders with adversarial training to accumulate transferable binding principles. On these principles basis, BioBridge employs a dynamic prototype meta-learning framework to associate insights from weakly related annotations, enabling robust predictions for previously unseen drug-target pairs. Extensive experiments demonstrate that BioBridge surpasses existing models, especially for unseen proteins. Notably, when only homologous protein binding data is available, BioBridge proves effective for virtual screening of the epidermal growth factor receptor and adenosine receptor, underscoring its potential in drug discovery.</li>
</ul>

<h3>Title: HMCGeo: IP Region Prediction Based on Hierarchical Multi-label Classification</h3>
<ul>
<li><strong>Authors: </strong>Tianzi Zhao, Xinran Liu, Zhaoxin Zhang, Dong Zhao, Ning Li, Zhichao Zhang, Xinye Wang</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2501.16392">https://arxiv.org/abs/2501.16392</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2501.16392">https://arxiv.org/pdf/2501.16392</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2501.16392]] HMCGeo: IP Region Prediction Based on Hierarchical Multi-label Classification(https://arxiv.org/abs/2501.16392)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, extraction</a></li>
<li><strong>Abstract: </strong>Fine-grained IP geolocation plays a critical role in applications such as location-based services and cybersecurity. Most existing fine-grained IP geolocation methods are regression-based; however, due to noise in the input data, these methods typically encounter kilometer-level prediction errors and provide incorrect region information for users. To address this issue, this paper proposes a novel hierarchical multi-label classification framework for IP region prediction, named HMCGeo. This framework treats IP geolocation as a hierarchical multi-label classification problem and employs residual connection-based feature extraction and attention prediction units to predict the target host region across multiple geographical granularities. Furthermore, we introduce probabilistic classification loss during training, combining it with hierarchical cross-entropy loss to form a composite loss function. This approach optimizes predictions by utilizing hierarchical constraints between regions at different granularities. IP region prediction experiments on the New York, Los Angeles, and Shanghai datasets demonstrate that HMCGeo achieves superior performance across all geographical granularities, significantly outperforming existing IP geolocation methods.</li>
</ul>

<h3>Title: Improving Network Threat Detection by Knowledge Graph, Large Language Model, and Imbalanced Learning</h3>
<ul>
<li><strong>Authors: </strong>Lili Zhang, Quanyan Zhu, Herman Ray, Ying Xie</a></li>
<li><strong>Subjects: </strong>cs.LG, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2501.16393">https://arxiv.org/abs/2501.16393</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2501.16393">https://arxiv.org/pdf/2501.16393</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2501.16393]] Improving Network Threat Detection by Knowledge Graph, Large Language Model, and Imbalanced Learning(https://arxiv.org/abs/2501.16393)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack, large language model</a></li>
<li><strong>Abstract: </strong>Network threat detection has been challenging due to the complexities of attack activities and the limitation of historical threat data to learn from. To help enhance the existing practices of using analytics, machine learning, and artificial intelligence methods to detect the network threats, we propose an integrated modelling framework, where Knowledge Graph is used to analyze the users' activity patterns, Imbalanced Learning techniques are used to prune and weigh Knowledge Graph, and LLM is used to retrieve and interpret the users' activities from Knowledge Graph. The proposed framework is applied to Agile Threat Detection through Online Sequential Learning. The preliminary results show the improved threat capture rate by 3%-4% and the increased interpretabilities of risk predictions based on the users' activities.</li>
</ul>

<h3>Title: Transformer^-1: Input-Adaptive Computation for Resource-Constrained Deployment</h3>
<ul>
<li><strong>Authors: </strong>Lumen AI, Tengzhou No. 1 Middle School, Shihao Ji, Zihui Song, Fucheng Zhong, Jisen Jia, Zhaobo Wu, Zheyi Cao, Xu Tianhao</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2501.16394">https://arxiv.org/abs/2501.16394</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2501.16394">https://arxiv.org/pdf/2501.16394</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2501.16394]] Transformer^-1: Input-Adaptive Computation for Resource-Constrained Deployment(https://arxiv.org/abs/2501.16394)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Addressing the resource waste caused by fixed computation paradigms in deep learning models under dynamic scenarios, this paper proposes a Transformer$^{-1}$ architecture based on the principle of deep adaptivity. This architecture achieves dynamic matching between input features and computational resources by establishing a joint optimization model for complexity and computation. Our core contributions include: (1) designing a two-layer control mechanism, composed of a complexity predictor and a reinforcement learning policy network, enabling end-to-end optimization of computation paths; (2) deriving a lower bound theory for dynamic computation, proving the system's theoretical reach to optimal efficiency; and (3) proposing a layer folding technique and a CUDA Graph pre-compilation scheme, overcoming the engineering bottlenecks of dynamic architectures. In the ImageNet-1K benchmark test, our method reduces FLOPs by 42.7\% and peak memory usage by 34.1\% compared to the standard Transformer, while maintaining comparable accuracy ($\pm$0.3\%). Furthermore, we conducted practical deployment on the Jetson AGX Xavier platform, verifying the effectiveness and practical value of this method in resource-constrained environments. To further validate the generality of the method, we also conducted experiments on several natural language processing tasks and achieved significant improvements in resource efficiency.</li>
</ul>

<h3>Title: TopoNets: High Performing Vision and Language Models with Brain-Like Topography</h3>
<ul>
<li><strong>Authors: </strong>Mayukh Deb, Mainak Deb, N. Apurva Ratan Murty</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.NE, q-bio.NC</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2501.16396">https://arxiv.org/abs/2501.16396</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2501.16396">https://arxiv.org/pdf/2501.16396</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2501.16396]] TopoNets: High Performing Vision and Language Models with Brain-Like Topography(https://arxiv.org/abs/2501.16396)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Neurons in the brain are organized such that nearby cells tend to share similar functions. AI models lack this organization, and past efforts to introduce topography have often led to trade-offs between topography and task performance. In this work, we present TopoLoss, a new loss function that promotes spatially organized topographic representations in AI models without significantly sacrificing task performance. TopoLoss is highly adaptable and can be seamlessly integrated into the training of leading model architectures. We validate our method on both vision (ResNet-18, ResNet-50, ViT) and language models (GPT-Neo-125M, NanoGPT), collectively TopoNets. TopoNets are the highest-performing supervised topographic models to date, exhibiting brain-like properties such as localized feature processing, lower dimensionality, and increased efficiency. TopoNets also predict responses in the brain and replicate the key topographic signatures observed in the brain's visual and language cortices. Together, this work establishes a robust and generalizable framework for integrating topography into leading model architectures, advancing the development of high-performing models that more closely emulate the computational strategies of the human brain.</li>
</ul>

<h3>Title: DynAlign: Unsupervised Dynamic Taxonomy Alignment for Cross-Domain Segmentation</h3>
<ul>
<li><strong>Authors: </strong>Han Sun, Rui Gong, Ismail Nejjar, Olga Fink</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2501.16410">https://arxiv.org/abs/2501.16410</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2501.16410">https://arxiv.org/pdf/2501.16410</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2501.16410]] DynAlign: Unsupervised Dynamic Taxonomy Alignment for Cross-Domain Segmentation(https://arxiv.org/abs/2501.16410)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>Current unsupervised domain adaptation (UDA) methods for semantic segmentation typically assume identical class labels between the source and target domains. This assumption ignores the label-level domain gap, which is common in real-world scenarios, thus limiting their ability to identify finer-grained or novel categories without requiring extensive manual annotation. A promising direction to address this limitation lies in recent advancements in foundation models, which exhibit strong generalization abilities due to their rich prior knowledge. However, these models often struggle with domain-specific nuances and underrepresented fine-grained categories. To address these challenges, we introduce DynAlign, a framework that integrates UDA with foundation models to bridge both the image-level and label-level domain gaps. Our approach leverages prior semantic knowledge to align source categories with target categories that can be novel, more fine-grained, or named differently (e.g., vehicle to {car, truck, bus}). Foundation models are then employed for precise segmentation and category reassignment. To further enhance accuracy, we propose a knowledge fusion approach that dynamically adapts to varying scene contexts. DynAlign generates accurate predictions in a new target label space without requiring any manual annotations, allowing seamless adaptation to new taxonomies through either model retraining or direct inference. Experiments on the street scene semantic segmentation benchmarks GTA to Mapillary Vistas and GTA to IDD validate the effectiveness of our approach, achieving a significant improvement over existing methods. Our code will be publicly available.</li>
</ul>

<h3>Title: Objects matter: object-centric world models improve reinforcement learning in visually complex environments</h3>
<ul>
<li><strong>Authors: </strong>Weipu Zhang, Adam Jelley, Trevor McInroe, Amos Storkey</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2501.16443">https://arxiv.org/abs/2501.16443</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2501.16443">https://arxiv.org/pdf/2501.16443</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2501.16443]] Objects matter: object-centric world models improve reinforcement learning in visually complex environments(https://arxiv.org/abs/2501.16443)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>Deep reinforcement learning has achieved remarkable success in learning control policies from pixels across a wide range of tasks, yet its application remains hindered by low sample efficiency, requiring significantly more environment interactions than humans to reach comparable performance. Model-based reinforcement learning (MBRL) offers a solution by leveraging learnt world models to generate simulated experience, thereby improving sample efficiency. However, in visually complex environments, small or dynamic elements can be critical for decision-making. Yet, traditional MBRL methods in pixel-based environments typically rely on auto-encoding with an $L_2$ loss, which is dominated by large areas and often fails to capture decision-relevant details. To address these limitations, we propose an object-centric MBRL pipeline, which integrates recent advances in computer vision to allow agents to focus on key decision-related elements. Our approach consists of four main steps: (1) annotating key objects related to rewards and goals with segmentation masks, (2) extracting object features using a pre-trained, frozen foundation vision model, (3) incorporating these object features with the raw observations to predict environmental dynamics, and (4) training the policy using imagined trajectories generated by this object-centric world model. Building on the efficient MBRL algorithm STORM, we call this pipeline OC-STORM. We demonstrate OC-STORM's practical value in overcoming the limitations of conventional MBRL approaches on both Atari games and the visually complex game Hollow Knight.</li>
</ul>

<h3>Title: Detecting Zero-Day Attacks in Digital Substations via In-Context Learning</h3>
<ul>
<li><strong>Authors: </strong>Faizan Manzoor, Vanshaj Khattar, Akila Herath, Clifton Black, Matthew C Nielsen, Junho Hong, Chen-Ching Liu, Ming Jin</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2501.16453">https://arxiv.org/abs/2501.16453</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2501.16453">https://arxiv.org/pdf/2501.16453</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2501.16453]] Detecting Zero-Day Attacks in Digital Substations via In-Context Learning(https://arxiv.org/abs/2501.16453)</code><input type="text"></li>
<li><strong>Keywords: </strong>secure, attack, transformer, large language model</a></li>
<li><strong>Abstract: </strong>The occurrences of cyber attacks on the power grids have been increasing every year, with novel attack techniques emerging every year. In this paper, we address the critical challenge of detecting novel/zero-day attacks in digital substations that employ the IEC-61850 communication protocol. While many heuristic and machine learning (ML)-based methods have been proposed for attack detection in IEC-61850 digital substations, generalization to novel or zero-day attacks remains challenging. We propose an approach that leverages the in-context learning (ICL) capability of the transformer architecture, the fundamental building block of large language models. The ICL approach enables the model to detect zero-day attacks and learn from a few examples of that attack without explicit retraining. Our experiments on the IEC-61850 dataset demonstrate that the proposed method achieves more than $85\%$ detection accuracy on zero-day attacks while the existing state-of-the-art baselines fail. This work paves the way for building more secure and resilient digital substations of the future.</li>
</ul>

<h3>Title: CoCoNUT: Structural Code Understanding does not fall out of a tree</h3>
<ul>
<li><strong>Authors: </strong>Claas Beger, Saikat Dutta</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.SE</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2501.16456">https://arxiv.org/abs/2501.16456</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2501.16456">https://arxiv.org/pdf/2501.16456</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2501.16456]] CoCoNUT: Structural Code Understanding does not fall out of a tree(https://arxiv.org/abs/2501.16456)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large Language Models (LLMs) have shown impressive performance across a wide array of tasks involving both structured and unstructured textual data. Recent results on various benchmarks for code generation, repair, or completion suggest that certain models have programming abilities comparable to or even surpass humans. In this work, we demonstrate that high performance on such benchmarks does not correlate to humans' innate ability to understand structural control flow in code. To this end, we extract solutions from the HumanEval benchmark, which the relevant models perform strongly on, and trace their execution path using function calls sampled from the respective test set. Using this dataset, we investigate the ability of seven state-of-the-art LLMs to match the execution trace and find that, despite their ability to generate semantically identical code, they possess limited ability to trace execution paths, especially for longer traces and specific control structures. We find that even the top-performing model, Gemini, can fully and correctly generate only 47% of HumanEval task traces. Additionally, we introduce a subset for three key structures not contained in HumanEval: Recursion, Parallel Processing, and Object-Oriented Programming, including concepts like Inheritance and Polymorphism. Besides OOP, we show that none of the investigated models achieve an accuracy over 5% on the relevant traces. Aggregating these specialized parts with HumanEval tasks, we present Benchmark CoCoNUT: Code Control Flow for Navigation Understanding and Testing, which measures a model's ability to trace execution of code upon relevant calls, including advanced structural components. We conclude that current LLMs need significant improvement to enhance code reasoning abilities. We hope our dataset helps researchers bridge this gap.</li>
</ul>

<h3>Title: On the Feasibility of Using LLMs to Execute Multistage Network Attacks</h3>
<ul>
<li><strong>Authors: </strong>Brian Singer, Keane Lucas, Lakshmi Adiga, Meghna Jain, Lujo Bauer, Vyas Sekar</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2501.16466">https://arxiv.org/abs/2501.16466</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2501.16466">https://arxiv.org/pdf/2501.16466</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2501.16466]] On the Feasibility of Using LLMs to Execute Multistage Network Attacks(https://arxiv.org/abs/2501.16466)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, attack</a></li>
<li><strong>Abstract: </strong>LLMs have shown preliminary promise in some security tasks and CTF challenges. However, it is unclear whether LLMs are able to realize multistage network attacks, which involve executing a wide variety of actions across multiple hosts such as conducting reconnaissance, exploiting vulnerabilities to gain initial access, leveraging internal hosts to move laterally, and using multiple compromised hosts to exfiltrate data. We evaluate LLMs across 10 multistage networks and find that popular LLMs are unable to realize these attacks. To enable LLMs to realize these attacks, we introduce Incalmo, an LLM-agnostic high-level attack abstraction layer that sits between an LLM and the environment. Rather than LLMs issuing low-level command-line instructions, which can lead to incorrect implementations, Incalmo allows LLMs to specify high-level tasks (e.g., infect a host, scan a network), which are then carried out by Incalmo. Incalmo realizes these tasks by translating them into low-level primitives (e.g., commands to exploit tools). Incalmo also provides an environment state service and an attack graph service to provide structure to LLMs in selecting actions relevant to a multistage attack. Across 9 out of 10 realistic emulated networks (from 25 to 50 hosts), LLMs using Incalmo can successfully autonomously execute multistage attacks. We also conduct an ablation analysis to show the key role the high-level abstractions play. For instance, we find that both Incalmo's high-level tasks and services are crucial. Furthermore, even smaller-parameter LLMs with Incalmo can fully succeed in 5 of 10 environments, while larger-parameter LLMs without Incalmo do not fully succeed in any.</li>
</ul>

<h3>Title: Cross-Domain Semantic Segmentation with Large Language Model-Assisted Descriptor Generation</h3>
<ul>
<li><strong>Authors: </strong>Philip Hughes, Larry Burns, Luke Adams</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2501.16467">https://arxiv.org/abs/2501.16467</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2501.16467">https://arxiv.org/pdf/2501.16467</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2501.16467]] Cross-Domain Semantic Segmentation with Large Language Model-Assisted Descriptor Generation(https://arxiv.org/abs/2501.16467)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer, large language model, segmentation</a></li>
<li><strong>Abstract: </strong>Semantic segmentation plays a crucial role in enabling machines to understand and interpret visual scenes at a pixel level. While traditional segmentation methods have achieved remarkable success, their generalization to diverse scenes and unseen object categories remains limited. Recent advancements in large language models (LLMs) offer a promising avenue for bridging visual and textual modalities, providing a deeper understanding of semantic relationships. In this paper, we propose LangSeg, a novel LLM-guided semantic segmentation method that leverages context-sensitive, fine-grained subclass descriptors generated by LLMs. Our framework integrates these descriptors with a pre-trained Vision Transformer (ViT) to achieve superior segmentation performance without extensive model retraining. We evaluate LangSeg on two challenging datasets, ADE20K and COCO-Stuff, where it outperforms state-of-the-art models, achieving up to a 6.1% improvement in mean Intersection over Union (mIoU). Additionally, we conduct a comprehensive ablation study and human evaluation to validate the effectiveness of our method in real-world scenarios. The results demonstrate that LangSeg not only excels in semantic understanding and contextual alignment but also provides a flexible and efficient framework for language-guided segmentation tasks. This approach opens up new possibilities for interactive and domain-specific segmentation applications.</li>
</ul>

<h3>Title: Object Detection for Medical Image Analysis: Insights from the RT-DETR Model</h3>
<ul>
<li><strong>Authors: </strong>Weijie He, Yuwei Zhang, Ting Xu, Tai An, Yingbin Liang, Bo Zhang</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2501.16469">https://arxiv.org/abs/2501.16469</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2501.16469">https://arxiv.org/pdf/2501.16469</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2501.16469]] Object Detection for Medical Image Analysis: Insights from the RT-DETR Model(https://arxiv.org/abs/2501.16469)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, transformer</a></li>
<li><strong>Abstract: </strong>Deep learning has emerged as a transformative approach for solving complex pattern recognition and object detection challenges. This paper focuses on the application of a novel detection framework based on the RT-DETR model for analyzing intricate image data, particularly in areas such as diabetic retinopathy detection. Diabetic retinopathy, a leading cause of vision loss globally, requires accurate and efficient image analysis to identify early-stage lesions. The proposed RT-DETR model, built on a Transformer-based architecture, excels at processing high-dimensional and complex visual data with enhanced robustness and accuracy. Comparative evaluations with models such as YOLOv5, YOLOv8, SSD, and DETR demonstrate that RT-DETR achieves superior performance across precision, recall, mAP50, and mAP50-95 metrics, particularly in detecting small-scale objects and densely packed targets. This study underscores the potential of Transformer-based models like RT-DETR for advancing object detection tasks, offering promising applications in medical imaging and beyond.</li>
</ul>

<h3>Title: SIM: Surface-based fMRI Analysis for Inter-Subject Multimodal Decoding from Movie-Watching Experiments</h3>
<ul>
<li><strong>Authors: </strong>Simon Dahan, Gabriel Bénédict, Logan Z. J. Williams, Yourong Guo, Daniel Rueckert, Robert Leech, Emma C. Robinson</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, eess.AS, eess.IV, q-bio.NC</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2501.16471">https://arxiv.org/abs/2501.16471</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2501.16471">https://arxiv.org/pdf/2501.16471</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2501.16471]] SIM: Surface-based fMRI Analysis for Inter-Subject Multimodal Decoding from Movie-Watching Experiments(https://arxiv.org/abs/2501.16471)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Current AI frameworks for brain decoding and encoding, typically train and test models within the same datasets. This limits their utility for brain computer interfaces (BCI) or neurofeedback, for which it would be useful to pool experiences across individuals to better simulate stimuli not sampled during training. A key obstacle to model generalisation is the degree of variability of inter-subject cortical organisation, which makes it difficult to align or compare cortical signals across participants. In this paper we address this through the use of surface vision transformers, which build a generalisable model of cortical functional dynamics, through encoding the topography of cortical networks and their interactions as a moving image across a surface. This is then combined with tri-modal self-supervised contrastive (CLIP) alignment of audio, video, and fMRI modalities to enable the retrieval of visual and auditory stimuli from patterns of cortical activity (and vice-versa). We validate our approach on 7T task-fMRI data from 174 healthy participants engaged in the movie-watching experiment from the Human Connectome Project (HCP). Results show that it is possible to detect which movie clips an individual is watching purely from their brain activity, even for individuals and movies not seen during training. Further analysis of attention maps reveals that our model captures individual patterns of brain activity that reflect semantic and visual systems. This opens the door to future personalised simulations of brain function. Code & pre-trained models will be made available at this https URL, processed data for training will be available upon request at this https URL.</li>
</ul>

<h3>Title: Closed-Form Feedback-Free Learning with Forward Projection</h3>
<ul>
<li><strong>Authors: </strong>Robert O'Shea, Bipin Rajendran</a></li>
<li><strong>Subjects: </strong>cs.LG, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2501.16476">https://arxiv.org/abs/2501.16476</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2501.16476">https://arxiv.org/pdf/2501.16476</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2501.16476]] Closed-Form Feedback-Free Learning with Forward Projection(https://arxiv.org/abs/2501.16476)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability</a></li>
<li><strong>Abstract: </strong>State-of-the-art methods for backpropagation-free learning employ local error feedback to direct iterative optimisation via gradient descent. In this study, we examine the more restrictive setting where retrograde communication from neuronal outputs is unavailable for pre-synaptic weight optimisation. To address this challenge, we propose Forward Projection (FP). This novel randomised closed-form training method requires only a single forward pass over the entire dataset for model fitting, without retrograde communication. Target values for pre-activation membrane potentials are generated layer-wise via nonlinear projections of pre-synaptic inputs and the labels. Local loss functions are optimised over pre-synaptic inputs using closed-form regression, without feedback from neuronal outputs or downstream layers. Interpretability is a key advantage of FP training; membrane potentials of hidden neurons in FP-trained networks encode information which is interpretable layer-wise as label predictions. We demonstrate the effectiveness of FP across four biomedical datasets. In few-shot learning tasks, FP yielded more generalisable models than those optimised via backpropagation. In large-sample tasks, FP-based models achieve generalisation comparable to gradient descent-based local learning methods while requiring only a single forward propagation step, achieving significant speed up for training. Interpretation functions defined on local neuronal activity in FP-based models successfully identified clinically salient features for diagnosis in two biomedical datasets. Forward Projection is a computationally efficient machine learning approach that yields interpretable neural network models without retrograde communication of neuronal activity during training.</li>
</ul>

<h3>Title: Generating customized prompts for Zero-Shot Rare Event Medical Image Classification using LLM</h3>
<ul>
<li><strong>Authors: </strong>Payal Kamboj, Ayan Banerjee, Bin Xu, Sandeep Gupta</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2501.16481">https://arxiv.org/abs/2501.16481</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2501.16481">https://arxiv.org/pdf/2501.16481</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2501.16481]] Generating customized prompts for Zero-Shot Rare Event Medical Image Classification using LLM(https://arxiv.org/abs/2501.16481)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, large language model</a></li>
<li><strong>Abstract: </strong>Rare events, due to their infrequent occurrences, do not have much data, and hence deep learning techniques fail in estimating the distribution for such data. Open-vocabulary models represent an innovative approach to image classification. Unlike traditional models, these models classify images into any set of categories specified with natural language prompts during inference. These prompts usually comprise manually crafted templates (e.g., 'a photo of a {}') that are filled in with the names of each category. This paper introduces a simple yet effective method for generating highly accurate and contextually descriptive prompts containing discriminative characteristics. Rare event detection, especially in medicine, is more challenging due to low inter-class and high intra-class variability. To address these, we propose a novel approach that uses domain-specific expert knowledge on rare events to generate customized and contextually relevant prompts, which are then used by large language models for image classification. Our zero-shot, privacy-preserving method enhances rare event classification without additional training, outperforming state-of-the-art techniques.</li>
</ul>

<h3>Title: Towards Robust Stability Prediction in Smart Grids: GAN-based Approach under Data Constraints and Adversarial Challenges</h3>
<ul>
<li><strong>Authors: </strong>Emad Efatinasab, Alessandro Brighente, Denis Donadel, Mauro Conti, Mirco Rampazzo</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2501.16490">https://arxiv.org/abs/2501.16490</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2501.16490">https://arxiv.org/pdf/2501.16490</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2501.16490]] Towards Robust Stability Prediction in Smart Grids: GAN-based Approach under Data Constraints and Adversarial Challenges(https://arxiv.org/abs/2501.16490)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, attack, robust, generative</a></li>
<li><strong>Abstract: </strong>Smart grids are critical for addressing the growing energy demand due to global population growth and urbanization. They enhance efficiency, reliability, and sustainability by integrating renewable energy. Ensuring their availability and safety requires advanced operational control and safety measures. Researchers employ AI and machine learning to assess grid stability, but challenges like the lack of datasets and cybersecurity threats, including adversarial attacks, persist. In particular, data scarcity is a key issue: obtaining grid instability instances is tough due to the need for significant expertise, resources, and time. However, they are essential to test novel research advancements and security mitigations. In this paper, we introduce a novel framework to detect instability in smart grids by employing only stable data. It relies on a Generative Adversarial Network (GAN) where the generator is trained to create instability data that are used along with stable data to train the discriminator. Moreover, we include a new adversarial training layer to improve robustness against adversarial attacks. Our solution, tested on a dataset composed of real-world stable and unstable samples, achieve accuracy up to 97.5\% in predicting grid stability and up to 98.9\% in detecting adversarial attacks. Moreover, we implemented our model in a single-board computer demonstrating efficient real-time decision-making with an average response time of less than 7ms. Our solution improves prediction accuracy and resilience while addressing data scarcity in smart grid management.</li>
</ul>

<h3>Title: Open Problems in Mechanistic Interpretability</h3>
<ul>
<li><strong>Authors: </strong>Lee Sharkey, Bilal Chughtai, Joshua Batson, Jack Lindsey, Jeff Wu, Lucius Bushnaq, Nicholas Goldowsky-Dill, Stefan Heimersheim, Alejandro Ortega, Joseph Bloom, Stella Biderman, Adria Garriga-Alonso, Arthur Conmy, Neel Nanda, Jessica Rumbelow, Martin Wattenberg, Nandi Schoots, Joseph Miller, Eric J. Michaud, Stephen Casper, Max Tegmark, William Saunders, David Bau, Eric Todd, Atticus Geiger, Mor Geva, Jesse Hoogland, Daniel Murfet, Tom McGrath</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2501.16496">https://arxiv.org/abs/2501.16496</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2501.16496">https://arxiv.org/pdf/2501.16496</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2501.16496]] Open Problems in Mechanistic Interpretability(https://arxiv.org/abs/2501.16496)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability</a></li>
<li><strong>Abstract: </strong>Mechanistic interpretability aims to understand the computational mechanisms underlying neural networks' capabilities in order to accomplish concrete scientific and engineering goals. Progress in this field thus promises to provide greater assurance over AI system behavior and shed light on exciting scientific questions about the nature of intelligence. Despite recent progress toward these goals, there are many open problems in the field that require solutions before many scientific and practical benefits can be realized: Our methods require both conceptual and practical improvements to reveal deeper insights; we must figure out how best to apply our methods in pursuit of specific goals; and the field must grapple with socio-technical challenges that influence and are influenced by our work. This forward-facing review discusses the current frontier of mechanistic interpretability and the open problems that the field may benefit from prioritizing.</li>
</ul>

<h3>Title: Smoothed Embeddings for Robust Language Models</h3>
<ul>
<li><strong>Authors: </strong>Ryo Hase, Md Rafi Ur Rashid, Ashley Lewis, Jing Liu, Toshiaki Koike-Akino, Kieran Parsons, Ye Wang</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CL, cs.CR, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2501.16497">https://arxiv.org/abs/2501.16497</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2501.16497">https://arxiv.org/pdf/2501.16497</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2501.16497]] Smoothed Embeddings for Robust Language Models(https://arxiv.org/abs/2501.16497)</code><input type="text"></li>
<li><strong>Keywords: </strong>defense, attack, robust, large language model</a></li>
<li><strong>Abstract: </strong>Improving the safety and reliability of large language models (LLMs) is a crucial aspect of realizing trustworthy AI systems. Although alignment methods aim to suppress harmful content generation, LLMs are often still vulnerable to jailbreaking attacks that employ adversarial inputs that subvert alignment and induce harmful outputs. We propose the Randomized Embedding Smoothing and Token Aggregation (RESTA) defense, which adds random noise to the embedding vectors and performs aggregation during the generation of each output token, with the aim of better preserving semantic information. Our experiments demonstrate that our approach achieves superior robustness versus utility tradeoffs compared to the baseline defenses.</li>
</ul>

<h3>Title: Deception in LLMs: Self-Preservation and Autonomous Goals in Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Sudarshan Kamath Barkur, Sigurd Schacht, Johannes Scholl</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2501.16513">https://arxiv.org/abs/2501.16513</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2501.16513">https://arxiv.org/pdf/2501.16513</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2501.16513]] Deception in LLMs: Self-Preservation and Autonomous Goals in Large Language Models(https://arxiv.org/abs/2501.16513)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, large language model</a></li>
<li><strong>Abstract: </strong>Recent advances in Large Language Models (LLMs) have incorporated planning and reasoning capabilities, enabling models to outline steps before execution and provide transparent reasoning paths. This enhancement has reduced errors in mathematical and logical tasks while improving accuracy. These developments have facilitated LLMs' use as agents that can interact with tools and adapt their responses based on new information. Our study examines DeepSeek R1, a model trained to output reasoning tokens similar to OpenAI's o1. Testing revealed concerning behaviors: the model exhibited deceptive tendencies and demonstrated self-preservation instincts, including attempts of self-replication, despite these traits not being explicitly programmed (or prompted). These findings raise concerns about LLMs potentially masking their true objectives behind a facade of alignment. When integrating such LLMs into robotic systems, the risks become tangible - a physically embodied AI exhibiting deceptive behaviors and self-preservation instincts could pursue its hidden objectives through real-world actions. This highlights the critical need for robust goal specification and safety frameworks before any physical implementation.</li>
</ul>

<h3>Title: How well can LLMs Grade Essays in Arabic?</h3>
<ul>
<li><strong>Authors: </strong>Rayed Ghazawi, Edwin Simpson</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2501.16516">https://arxiv.org/abs/2501.16516</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2501.16516">https://arxiv.org/pdf/2501.16516</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2501.16516]] How well can LLMs Grade Essays in Arabic?(https://arxiv.org/abs/2501.16516)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative, large language model</a></li>
<li><strong>Abstract: </strong>This research assesses the effectiveness of state-of-the-art large language models (LLMs), including ChatGPT, Llama, Aya, Jais, and ACEGPT, in the task of Arabic automated essay scoring (AES) using the AR-AES dataset. It explores various evaluation methodologies, including zero-shot, few-shot in-context learning, and fine-tuning, and examines the influence of instruction-following capabilities through the inclusion of marking guidelines within the prompts. A mixed-language prompting strategy, integrating English prompts with Arabic content, was implemented to improve model comprehension and performance. Among the models tested, ACEGPT demonstrated the strongest performance across the dataset, achieving a Quadratic Weighted Kappa (QWK) of 0.67, but was outperformed by a smaller BERT-based model with a QWK of 0.88. The study identifies challenges faced by LLMs in processing Arabic, including tokenization complexities and higher computational demands. Performance variation across different courses underscores the need for adaptive models capable of handling diverse assessment formats and highlights the positive impact of effective prompt engineering on improving LLM outputs. To the best of our knowledge, this study is the first to empirically evaluate the performance of multiple generative Large Language Models (LLMs) on Arabic essays using authentic student data.</li>
</ul>

<h3>Title: Optimizing Decentralized Online Learning for Supervised Regression and Classification Problems</h3>
<ul>
<li><strong>Authors: </strong>J. M. Diederik Kruijssen (1), Renata Valieva (1), Steven N. Longmore (1,2) ((1) Allora Foundation, (2) Liverpool John Moores University)</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.DC, cs.MA</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2501.16519">https://arxiv.org/abs/2501.16519</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2501.16519">https://arxiv.org/pdf/2501.16519</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2501.16519]] Optimizing Decentralized Online Learning for Supervised Regression and Classification Problems(https://arxiv.org/abs/2501.16519)</code><input type="text"></li>
<li><strong>Keywords: </strong>fair</a></li>
<li><strong>Abstract: </strong>Decentralized learning networks aim to synthesize a single network inference from a set of raw inferences provided by multiple participants. To determine the combined inference, these networks must adopt a mapping from historical participant performance to weights, and to appropriately incentivize contributions they must adopt a mapping from performance to fair rewards. Despite the increased prevalence of decentralized learning networks, there exists no systematic study that performs a calibration of the associated free parameters. Here we present an optimization framework for key parameters governing decentralized online learning in supervised regression and classification problems. These parameters include the slope of the mapping between historical performance and participant weight, the timeframe for performance evaluation, and the slope of the mapping between performance and rewards. These parameters are optimized using a suite of numerical experiments that mimic the design of the Allora Network, but have been extended to handle classification tasks in addition to regression tasks. This setup enables a comparative analysis of parameter tuning and network performance optimization (loss minimization) across both problem types. We demonstrate how the optimal performance-weight mapping, performance timeframe, and performance-reward mapping vary with network composition and problem type. Our findings provide valuable insights for the optimization of decentralized learning protocols, and we discuss how these results can be generalized to optimize any inference synthesis-based, decentralized AI network.</li>
</ul>

<h3>Title: Programming by Examples Meets Historical Linguistics: A Large Language Model Based Approach to Sound Law Induction</h3>
<ul>
<li><strong>Authors: </strong>Atharva Naik, Darsh Agrawal, Hong Sng, Clayton Marr, Kexun Zhang, Nathaniel R Robinson, Kalvin Chang, Rebecca Byrnes, Aravind Mysore, Carolyn Rose, David R Mortensen</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2501.16524">https://arxiv.org/abs/2501.16524</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2501.16524">https://arxiv.org/pdf/2501.16524</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2501.16524]] Programming by Examples Meets Historical Linguistics: A Large Language Model Based Approach to Sound Law Induction(https://arxiv.org/abs/2501.16524)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Historical linguists have long written "programs" that convert reconstructed words in an ancestor language into their attested descendants via ordered string rewrite functions (called sound laws) However, writing these programs is time-consuming, motivating the development of automated Sound Law Induction (SLI) which we formulate as Programming by Examples (PBE) with Large Language Models (LLMs) in this paper. While LLMs have been effective for code generation, recent work has shown that PBE is challenging but improvable by fine-tuning, especially with training data drawn from the same distribution as evaluation data. In this paper, we create a conceptual framework of what constitutes a "similar distribution" for SLI and propose four kinds of synthetic data generation methods with varying amounts of inductive bias to investigate what leads to the best performance. Based on the results we create a SOTA open-source model for SLI as PBE (+6% pass rate with a third of the parameters of the second-best LLM) and also highlight exciting future directions for PBE research.</li>
</ul>

<h3>Title: A comparison of data filtering techniques for English-Polish LLM-based machine translation in the biomedical domain</h3>
<ul>
<li><strong>Authors: </strong>Jorge del Pozo Lérida, Kamil Kojs, János Máté, Mikołaj Antoni Barański, Christian Hardmeier</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2501.16533">https://arxiv.org/abs/2501.16533</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2501.16533">https://arxiv.org/pdf/2501.16533</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2501.16533]] A comparison of data filtering techniques for English-Polish LLM-based machine translation in the biomedical domain(https://arxiv.org/abs/2501.16533)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large Language Models (LLMs) have become state-of-the-art in Machine Translation (MT), often trained on massive bilingual parallel corpora scraped from the web, that contain low-quality entries and redundant information, leading to significant computational challenges. Various data filtering methods exist to reduce dataset sizes, but their effectiveness largely varies based on specific language pairs and domains. This paper evaluates the impact of commonly used data filtering techniques, such as LASER, MUSE, and LaBSE, on English-Polish translation within the biomedical domain. By filtering the UFAL Medical Corpus, we created varying dataset sizes to fine-tune the mBART50 model, which was then evaluated using the SacreBLEU metric on the Khresmoi dataset, having the quality of translations assessed by bilingual speakers. Our results show that both LASER and MUSE can significantly reduce dataset sizes while maintaining or even enhancing performance. We recommend the use of LASER, as it consistently outperforms the other methods and provides the most fluent and natural-sounding translations.</li>
</ul>

<h3>Title: Targeting Alignment: Extracting Safety Classifiers of Aligned LLMs</h3>
<ul>
<li><strong>Authors: </strong>Jean-Charles Noirot Ferrand, Yohan Beugin, Eric Pauley, Ryan Sheatsley, Patrick McDaniel</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2501.16534">https://arxiv.org/abs/2501.16534</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2501.16534">https://arxiv.org/pdf/2501.16534</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2501.16534]] Targeting Alignment: Extracting Safety Classifiers of Aligned LLMs(https://arxiv.org/abs/2501.16534)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack, robust, large language model</a></li>
<li><strong>Abstract: </strong>Alignment in large language models (LLMs) is used to enforce guidelines such as safety. Yet, alignment fails in the face of jailbreak attacks that modify inputs to induce unsafe outputs. In this paper, we present and evaluate a method to assess the robustness of LLM alignment. We observe that alignment embeds a safety classifier in the target model that is responsible for deciding between refusal and compliance. We seek to extract an approximation of this classifier, called a surrogate classifier, from the LLM. We develop an algorithm for identifying candidate classifiers from subsets of the LLM model. We evaluate the degree to which the candidate classifiers approximate the model's embedded classifier in benign (F1 score) and adversarial (using surrogates in a white-box attack) settings. Our evaluation shows that the best candidates achieve accurate agreement (an F1 score above 80%) using as little as 20% of the model architecture. Further, we find attacks mounted on the surrogate models can be transferred with high accuracy. For example, a surrogate using only 50% of the Llama 2 model achieved an attack success rate (ASR) of 70%, a substantial improvement over attacking the LLM directly, where we only observed a 22% ASR. These results show that extracting surrogate classifiers is a viable (and highly effective) means for modeling (and therein addressing) the vulnerability of aligned models to jailbreaking attacks.</li>
</ul>

<h3>Title: PackDiT: Joint Human Motion and Text Generation via Mutual Prompting</h3>
<ul>
<li><strong>Authors: </strong>Zhongyu Jiang, Wenhao Chai, Zhuoran Zhou, Cheng-Yen Yang, Hsiang-Wei Huang, Jenq-Neng Hwang</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2501.16551">https://arxiv.org/abs/2501.16551</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2501.16551">https://arxiv.org/pdf/2501.16551</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2501.16551]] PackDiT: Joint Human Motion and Text Generation via Mutual Prompting(https://arxiv.org/abs/2501.16551)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, transformer, generative</a></li>
<li><strong>Abstract: </strong>Human motion generation has advanced markedly with the advent of diffusion models. Most recent studies have concentrated on generating motion sequences based on text prompts, commonly referred to as text-to-motion generation. However, the bidirectional generation of motion and text, enabling tasks such as motion-to-text alongside text-to-motion, has been largely unexplored. This capability is essential for aligning diverse modalities and supports unconditional generation. In this paper, we introduce PackDiT, the first diffusion-based generative model capable of performing various tasks simultaneously, including motion generation, motion prediction, text generation, text-to-motion, motion-to-text, and joint motion-text generation. Our core innovation leverages mutual blocks to integrate multiple diffusion transformers (DiTs) across different modalities seamlessly. We train PackDiT on the HumanML3D dataset, achieving state-of-the-art text-to-motion performance with an FID score of 0.106, along with superior results in motion prediction and in-between tasks. Our experiments further demonstrate that diffusion models are effective for motion-to-text generation, achieving performance comparable to that of autoregressive models.</li>
</ul>

<h3>Title: Distributional Information Embedding: A Framework for Multi-bit Watermarking</h3>
<ul>
<li><strong>Authors: </strong>Haiyun He, Yepeng Liu, Ziqiao Wang, Yongyi Mao, Yuheng Bu</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.IT, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2501.16558">https://arxiv.org/abs/2501.16558</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2501.16558">https://arxiv.org/pdf/2501.16558</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2501.16558]] Distributional Information Embedding: A Framework for Multi-bit Watermarking(https://arxiv.org/abs/2501.16558)</code><input type="text"></li>
<li><strong>Keywords: </strong>watermark, large language model</a></li>
<li><strong>Abstract: </strong>This paper introduces a novel problem, distributional information embedding, motivated by the practical demands of multi-bit watermarking for large language models (LLMs). Unlike traditional information embedding, which embeds information into a pre-existing host signal, LLM watermarking actively controls the text generation process--adjusting the token distribution--to embed a detectable signal. We develop an information-theoretic framework to analyze this distributional information embedding problem, characterizing the fundamental trade-offs among three critical performance metrics: text quality, detectability, and information rate. In the asymptotic regime, we demonstrate that the maximum achievable rate with vanishing error corresponds to the entropy of the LLM's output distribution and increases with higher allowable distortion. We also characterize the optimal watermarking scheme to achieve this rate. Extending the analysis to the finite-token case, we identify schemes that maximize detection probability while adhering to constraints on false alarm and distortion.</li>
</ul>

<h3>Title: LoRA-X: Bridging Foundation Models with Training-Free Cross-Model Adaptation</h3>
<ul>
<li><strong>Authors: </strong>Farzad Farhadzadeh, Debasmit Das, Shubhankar Borse, Fatih Porikli</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2501.16559">https://arxiv.org/abs/2501.16559</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2501.16559">https://arxiv.org/pdf/2501.16559</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2501.16559]] LoRA-X: Bridging Foundation Models with Training-Free Cross-Model Adaptation(https://arxiv.org/abs/2501.16559)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, diffusion</a></li>
<li><strong>Abstract: </strong>The rising popularity of large foundation models has led to a heightened demand for parameter-efficient fine-tuning methods, such as Low-Rank Adaptation (LoRA), which offer performance comparable to full model fine-tuning while requiring only a few additional parameters tailored to the specific base model. When such base models are deprecated and replaced, all associated LoRA modules must be retrained, requiring access to either the original training data or a substantial amount of synthetic data that mirrors the original distribution. However, the original data is often inaccessible due to privacy or licensing issues, and generating synthetic data may be impractical and insufficiently representative. These factors complicate the fine-tuning process considerably. To address this challenge, we introduce a new adapter, Cross-Model Low-Rank Adaptation (LoRA-X), which enables the training-free transfer of LoRA parameters across source and target models, eliminating the need for original or synthetic training data. Our approach imposes the adapter to operate within the subspace of the source base model. This constraint is necessary because our prior knowledge of the target model is limited to its weights, and the criteria for ensuring the adapter's transferability are restricted to the target base model's weights and subspace. To facilitate the transfer of LoRA parameters of the source model to a target model, we employ the adapter only in the layers of the target model that exhibit an acceptable level of subspace similarity. Our extensive experiments demonstrate the effectiveness of LoRA-X for text-to-image generation, including Stable Diffusion v1.5 and Stable Diffusion XL.</li>
</ul>

<h3>Title: DialUp! Modeling the Language Continuum by Adapting Models to Dialects and Dialects to Models</h3>
<ul>
<li><strong>Authors: </strong>Niyati Bafna, Emily Chang, Nathaniel R. Robinson, David R. Mortensen, Kenton Murray, David Yarowsky, Hale Sirin</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2501.16581">https://arxiv.org/abs/2501.16581</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2501.16581">https://arxiv.org/pdf/2501.16581</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2501.16581]] DialUp! Modeling the Language Continuum by Adapting Models to Dialects and Dialects to Models(https://arxiv.org/abs/2501.16581)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Most of the world's languages and dialects are low-resource, and lack support in mainstream machine translation (MT) models. However, many of them have a closely-related high-resource language (HRL) neighbor, and differ in linguistically regular ways from it. This underscores the importance of model robustness to dialectical variation and cross-lingual generalization to the HRL dialect continuum. We present DialUp, consisting of a training-time technique for adapting a pretrained model to dialectical data (M->D), and an inference-time intervention adapting dialectical data to the model expertise (D->M). M->D induces model robustness to potentially unseen and unknown dialects by exposure to synthetic data exemplifying linguistic mechanisms of dialectical variation, whereas D->M treats dialectical divergence for known target dialects. These methods show considerable performance gains for several dialects from four language families, and modest gains for two other language families. We also conduct feature and error analyses, which show that language varieties with low baseline MT performance are more likely to benefit from these approaches.</li>
</ul>

<h3>Title: Directing Mamba to Complex Textures: An Efficient Texture-Aware State Space Model for Image Restoration</h3>
<ul>
<li><strong>Authors: </strong>Long Peng, Xin Di, Zhanfeng Feng, Wenbo Li, Renjing Pei, Yang Wang, Xueyang Fu, Yang Cao, Zheng-Jun Zha</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2501.16583">https://arxiv.org/abs/2501.16583</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2501.16583">https://arxiv.org/pdf/2501.16583</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2501.16583]] Directing Mamba to Complex Textures: An Efficient Texture-Aware State Space Model for Image Restoration(https://arxiv.org/abs/2501.16583)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, extraction, transformer</a></li>
<li><strong>Abstract: </strong>Image restoration aims to recover details and enhance contrast in degraded images. With the growing demand for high-quality imaging (\textit{e.g.}, 4K and 8K), achieving a balance between restoration quality and computational efficiency has become increasingly critical. Existing methods, primarily based on CNNs, Transformers, or their hybrid approaches, apply uniform deep representation extraction across the image. However, these methods often struggle to effectively model long-range dependencies and largely overlook the spatial characteristics of image degradation (regions with richer textures tend to suffer more severe damage), making it hard to achieve the best trade-off between restoration quality and efficiency. To address these issues, we propose a novel texture-aware image restoration method, TAMambaIR, which simultaneously perceives image textures and achieves a trade-off between performance and efficiency. Specifically, we introduce a novel Texture-Aware State Space Model, which enhances texture awareness and improves efficiency by modulating the transition matrix of the state-space equation and focusing on regions with complex textures. Additionally, we design a {Multi-Directional Perception Block} to improve multi-directional receptive fields while maintaining low computational overhead. Extensive experiments on benchmarks for image super-resolution, deraining, and low-light image enhancement demonstrate that TAMambaIR achieves state-of-the-art performance with significantly improved efficiency, establishing it as a robust and efficient framework for image restoration.</li>
</ul>

<h3>Title: Fine-Tuned Language Models as Space Systems Controllers</h3>
<ul>
<li><strong>Authors: </strong>Enrico M. Zucchelli, Di Wu, Julia Briden, Christian Hofmann, Victor Rodriguez-Fernandez, Richard Linares</a></li>
<li><strong>Subjects: </strong>cs.LG, eess.SY</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2501.16588">https://arxiv.org/abs/2501.16588</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2501.16588">https://arxiv.org/pdf/2501.16588</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2501.16588]] Fine-Tuned Language Models as Space Systems Controllers(https://arxiv.org/abs/2501.16588)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer, large language model</a></li>
<li><strong>Abstract: </strong>Large language models (LLMs), or foundation models (FMs), are pretrained transformers that coherently complete sentences auto-regressively. In this paper, we show that LLMs can control simplified space systems after some additional training, called fine-tuning. We look at relatively small language models, ranging between 7 and 13 billion parameters. We focus on four problems: a three-dimensional spring toy problem, low-thrust orbit transfer, low-thrust cislunar control, and powered descent guidance. The fine-tuned LLMs are capable of controlling systems by generating sufficiently accurate outputs that are multi-dimensional vectors with up to 10 significant digits. We show that for several problems the amount of data required to perform fine-tuning is smaller than what is generally required of traditional deep neural networks (DNNs), and that fine-tuned LLMs are good at generalizing outside of the training dataset. Further, the same LLM can be fine-tuned with data from different problems, with only minor performance degradation with respect to LLMs trained for a single application. This work is intended as a first step towards the development of a general space systems controller.</li>
</ul>

<h3>Title: Applying Ensemble Models based on Graph Neural Network and Reinforcement Learning for Wind Power Forecasting</h3>
<ul>
<li><strong>Authors: </strong>Hongjin Song, Qianrun Chen, Tianqi Jiang, Yongfeng Li, Xusheng Li, Wenjun Xi, Songtao Huang</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2501.16591">https://arxiv.org/abs/2501.16591</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2501.16591">https://arxiv.org/pdf/2501.16591</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2501.16591]] Applying Ensemble Models based on Graph Neural Network and Reinforcement Learning for Wind Power Forecasting(https://arxiv.org/abs/2501.16591)</code><input type="text"></li>
<li><strong>Keywords: </strong>security</a></li>
<li><strong>Abstract: </strong>Accurately predicting the wind power output of a wind farm across various time scales utilizing Wind Power Forecasting (WPF) is a critical issue in wind power trading and utilization. The WPF problem remains unresolved due to numerous influencing variables, such as wind speed, temperature, latitude, and longitude. Furthermore, achieving high prediction accuracy is crucial for maintaining electric grid stability and ensuring supply security. In this paper, we model all wind turbines within a wind farm as graph nodes in a graph built by their geographical locations. Accordingly, we propose an ensemble model based on graph neural networks and reinforcement learning (EMGRL) for WPF. Our approach includes: (1) applying graph neural networks to capture the time-series data from neighboring wind farms relevant to the target wind farm; (2) establishing a general state embedding that integrates the target wind farm's data with the historical performance of base models on the target wind farm; (3) ensembling and leveraging the advantages of all base models through an actor-critic reinforcement learning framework for WPF.</li>
</ul>

<h3>Title: CascadeV: An Implementation of Wurstchen Architecture for Video Generation</h3>
<ul>
<li><strong>Authors: </strong>Wenfeng Lin, Jiangchuan Wei, Boyuan Liu, Yichen Zhang, Shiyue Yan, Mingyu Guo</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2501.16612">https://arxiv.org/abs/2501.16612</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2501.16612">https://arxiv.org/pdf/2501.16612</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2501.16612]] CascadeV: An Implementation of Wurstchen Architecture for Video Generation(https://arxiv.org/abs/2501.16612)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>Recently, with the tremendous success of diffusion models in the field of text-to-image (T2I) generation, increasing attention has been directed toward their potential in text-to-video (T2V) applications. However, the computational demands of diffusion models pose significant challenges, particularly in generating high-resolution videos with high frame rates. In this paper, we propose CascadeV, a cascaded latent diffusion model (LDM), that is capable of producing state-of-the-art 2K resolution videos. Experiments demonstrate that our cascaded model achieves a higher compression ratio, substantially reducing the computational challenges associated with high-quality video generation. We also implement a spatiotemporal alternating grid 3D attention mechanism, which effectively integrates spatial and temporal information, ensuring superior consistency across the generated video frames. Furthermore, our model can be cascaded with existing T2V models, theoretically enabling a 4$\times$ increase in resolution or frames per second without any fine-tuning. Our code is available at this https URL.</li>
</ul>

<h3>Title: FUNU: Boosting Machine Unlearning Efficiency by Filtering Unnecessary Unlearning</h3>
<ul>
<li><strong>Authors: </strong>Zitong Li, Qingqing Ye, Haibo Hu</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2501.16614">https://arxiv.org/abs/2501.16614</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2501.16614">https://arxiv.org/pdf/2501.16614</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2501.16614]] FUNU: Boosting Machine Unlearning Efficiency by Filtering Unnecessary Unlearning(https://arxiv.org/abs/2501.16614)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, protect</a></li>
<li><strong>Abstract: </strong>Machine unlearning is an emerging field that selectively removes specific data samples from a trained model. This capability is crucial for addressing privacy concerns, complying with data protection regulations, and correcting errors or biases introduced by certain data. Unlike traditional machine learning, where models are typically static once trained, machine unlearning facilitates dynamic updates that enable the model to ``forget'' information without requiring complete retraining from scratch. There are various machine unlearning methods, some of which are more time-efficient when data removal requests are fewer. To decrease the execution time of such machine unlearning methods, we aim to reduce the size of data removal requests based on the fundamental assumption that the removal of certain data would not result in a distinguishable retrained model. We first propose the concept of unnecessary unlearning, which indicates that the model would not alter noticeably after removing some data points. Subsequently, we review existing solutions that can be used to solve our problem. We highlight their limitations in adaptability to different unlearning scenarios and their reliance on manually selected parameters. We consequently put forward FUNU, a method to identify data points that lead to unnecessary unlearning. FUNU circumvents the limitations of existing solutions. The idea is to discover data points within the removal requests that have similar neighbors in the remaining dataset. We utilize a reference model to set parameters for finding neighbors, inspired from the area of model memorization. We provide a theoretical analysis of the privacy guarantee offered by FUNU and conduct extensive experiments to validate its efficacy.</li>
</ul>

<h3>Title: Sparse Autoencoders Trained on the Same Data Learn Different Features</h3>
<ul>
<li><strong>Authors: </strong>Gonçalo Paulo, Nora Belrose</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2501.16615">https://arxiv.org/abs/2501.16615</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2501.16615">https://arxiv.org/pdf/2501.16615</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2501.16615]] Sparse Autoencoders Trained on the Same Data Learn Different Features(https://arxiv.org/abs/2501.16615)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Sparse autoencoders (SAEs) are a useful tool for uncovering human-interpretable features in the activations of large language models (LLMs). While some expect SAEs to find the true underlying features used by a model, our research shows that SAEs trained on the same model and data, differing only in the random seed used to initialize their weights, identify different sets of features. For example, in an SAE with 131K latents trained on a feedforward network in Llama 3 8B, only 30% of the features were shared across different seeds. We observed this phenomenon across multiple layers of three different LLMs, two datasets, and several SAE architectures. While ReLU SAEs trained with the L1 sparsity loss showed greater stability across seeds, SAEs using the state-of-the-art TopK activation function were more seed-dependent, even when controlling for the level of sparsity. Our results suggest that the set of features uncovered by an SAE should be viewed as a pragmatically useful decomposition of activation space, rather than an exhaustive and universal list of features "truly used" by the model.</li>
</ul>

<h3>Title: Few-Shot Optimized Framework for Hallucination Detection in Resource-Limited NLP Systems</h3>
<ul>
<li><strong>Authors: </strong>Baraa Hikal, Ahmed Nasreldin, Ali Hamdi, Ammar Mohammed</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2501.16616">https://arxiv.org/abs/2501.16616</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2501.16616">https://arxiv.org/pdf/2501.16616</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2501.16616]] Few-Shot Optimized Framework for Hallucination Detection in Resource-Limited NLP Systems(https://arxiv.org/abs/2501.16616)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, generative</a></li>
<li><strong>Abstract: </strong>Hallucination detection in text generation remains an ongoing struggle for natural language processing (NLP) systems, frequently resulting in unreliable outputs in applications such as machine translation and definition modeling. Existing methods struggle with data scarcity and the limitations of unlabeled datasets, as highlighted by the SHROOM shared task at SemEval-2024. In this work, we propose a novel framework to address these challenges, introducing DeepSeek Few-shot optimization to enhance weak label generation through iterative prompt engineering. We achieved high-quality annotations that considerably enhanced the performance of downstream models by restructuring data to align with instruct generative models. We further fine-tuned the Mistral-7B-Instruct-v0.3 model on these optimized annotations, enabling it to accurately detect hallucinations in resource-limited settings. Combining this fine-tuned model with ensemble learning strategies, our approach achieved 85.5% accuracy on the test set, setting a new benchmark for the SHROOM task. This study demonstrates the effectiveness of data restructuring, few-shot optimization, and fine-tuning in building scalable and robust hallucination detection frameworks for resource-constrained NLP systems.</li>
</ul>

<h3>Title: Predicting 3D representations for Dynamic Scenes</h3>
<ul>
<li><strong>Authors: </strong>Di Qi, Tong Yang, Beining Wang, Xiangyu Zhang, Wenqiang Zhang</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2501.16617">https://arxiv.org/abs/2501.16617</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2501.16617">https://arxiv.org/pdf/2501.16617</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2501.16617]] Predicting 3D representations for Dynamic Scenes(https://arxiv.org/abs/2501.16617)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>We present a novel framework for dynamic radiance field prediction given monocular video streams. Unlike previous methods that primarily focus on predicting future frames, our method goes a step further by generating explicit 3D representations of the dynamic scene. The framework builds on two core designs. First, we adopt an ego-centric unbounded triplane to explicitly represent the dynamic physical world. Second, we develop a 4D-aware transformer to aggregate features from monocular videos to update the triplane. Coupling these two designs enables us to train the proposed model with large-scale monocular videos in a self-supervised manner. Our model achieves top results in dynamic radiance field prediction on NVIDIA dynamic scenes, demonstrating its strong performance on 4D physical world modeling. Besides, our model shows a superior generalizability to unseen scenarios. Notably, we find that our approach emerges capabilities for geometry and semantic learning.</li>
</ul>

<h3>Title: SHIELD: Secure Host-Independent Extensible Logging for SATA/Network Storage Towards Ransomware Detection</h3>
<ul>
<li><strong>Authors: </strong>Md Raz, P.V. Sai Charan, Prashanth Krishnamurthy, Farshad Khorrami, Ramesh Karri</a></li>
<li><strong>Subjects: </strong>cs.CR, eess.SY</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2501.16619">https://arxiv.org/abs/2501.16619</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2501.16619">https://arxiv.org/pdf/2501.16619</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2501.16619]] SHIELD: Secure Host-Independent Extensible Logging for SATA/Network Storage Towards Ransomware Detection(https://arxiv.org/abs/2501.16619)</code><input type="text"></li>
<li><strong>Keywords: </strong>secure, robust</a></li>
<li><strong>Abstract: </strong>As malware such as ransomware becomes sophisticated, the ability to find and neutralize it requires more robust and tamper-resistant solutions. Current methods rely on data from compromised hosts, lack hardware isolation, and cannot detect emerging threats. To address these limitations, we introduce SHIELD - a detection architecture leveraging FPGA-based open-source SATA and Network Block Device (NBD) technology to provide off-host, tamper-proof measurements for continuous observation of disk activity for software executing on a target device. SHIELD provides three distinct contributions: It (1) develops a framework to obtain and analyze multi-level hardware metrics at NBD, FPGA, and SATA storage levels, and shows their ability to differentiate between harmless and malicious software; (2) Broadens the functionality of an open-source FPGA-driven SATA Host Bus Adapter (HBA) to offer complete data storage capabilities through NBD without relying on the host system; (3) Provides a foundation for using the methodology and metrics in automated machine learning-assisted detection and ASIC integration for advanced mitigation capabilities in data storage devices. SHIELD analyzes 10 benign programs and 10 modern ransomware families to illustrate its capacity for real-time monitoring and use in distinguishing between ransomware and benign software. Experimental evidence shows SHIELD's robust host-independent and hardware-assisted metrics are a basis for detection, allowing to observe program execution and detect malicious activities at the storage level.</li>
</ul>

<h3>Title: Chinese Stock Prediction Based on a Multi-Modal Transformer Framework: Macro-Micro Information Fusion</h3>
<ul>
<li><strong>Authors: </strong>Lumen AI, Tengzhou No. 1 Middle School, Shihao Ji, Zihui Song, Fucheng Zhong, Jisen Jia, Zhaobo Wu, Zheyi Cao, Xu Tianhao</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2501.16621">https://arxiv.org/abs/2501.16621</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2501.16621">https://arxiv.org/pdf/2501.16621</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2501.16621]] Chinese Stock Prediction Based on a Multi-Modal Transformer Framework: Macro-Micro Information Fusion(https://arxiv.org/abs/2501.16621)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction, transformer</a></li>
<li><strong>Abstract: </strong>This paper proposes an innovative Multi-Modal Transformer framework (MMF-Trans) designed to significantly improve the prediction accuracy of the Chinese stock market by integrating multi-source heterogeneous information including macroeconomy, micro-market, financial text, and event knowledge. The framework consists of four core modules: (1) A four-channel parallel encoder that processes technical indicators, financial text, macro data, and event knowledge graph respectively for independent feature extraction of multi-modal data; (2) A dynamic gated cross-modal fusion mechanism that adaptively learns the importance of different modalities through differentiable weight allocation for effective information integration; (3) A time-aligned mixed-frequency processing layer that uses an innovative position encoding method to effectively fuse data of different time frequencies and solves the time alignment problem of heterogeneous data; (4) A graph attention-based event impact quantification module that captures the dynamic impact of events on the market through event knowledge graph and quantifies the event impact coefficient. We introduce a hybrid-frequency Transformer and Event2Vec algorithm to effectively fuse data of different frequencies and quantify the event impact. Experimental results show that in the prediction task of CSI 300 constituent stocks, the root mean square error (RMSE) of the MMF-Trans framework is reduced by 23.7% compared to the baseline model, the event response prediction accuracy is improved by 41.2%, and the Sharpe ratio is improved by 32.6%.</li>
</ul>

<h3>Title: CHiP: Cross-modal Hierarchical Direct Preference Optimization for Multimodal LLMs</h3>
<ul>
<li><strong>Authors: </strong>Jinlan Fu, Shenzhen Huangfu, Hao Fei, Xiaoyu Shen, Bryan Hooi, Xipeng Qiu, See-Kiong Ng</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2501.16629">https://arxiv.org/abs/2501.16629</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2501.16629">https://arxiv.org/pdf/2501.16629</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2501.16629]] CHiP: Cross-modal Hierarchical Direct Preference Optimization for Multimodal LLMs(https://arxiv.org/abs/2501.16629)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Multimodal Large Language Models (MLLMs) still struggle with hallucinations despite their impressive capabilities. Recent studies have attempted to mitigate this by applying Direct Preference Optimization (DPO) to multimodal scenarios using preference pairs from text-based responses. However, our analysis of representation distributions reveals that multimodal DPO struggles to align image and text representations and to distinguish between hallucinated and non-hallucinated descriptions. To address these challenges, in this work, we propose a Cross-modal Hierarchical Direct Preference Optimization (CHiP) to address these limitations. We introduce a visual preference optimization module within the DPO framework, enabling MLLMs to learn from both textual and visual preferences simultaneously. Furthermore, we propose a hierarchical textual preference optimization module that allows the model to capture preferences at multiple granular levels, including response, segment, and token levels. We evaluate CHiP through both quantitative and qualitative analyses, with results across multiple benchmarks demonstrating its effectiveness in reducing hallucinations. On the Object HalBench dataset, CHiP outperforms DPO in hallucination reduction, achieving improvements of 52.7% and 55.5% relative points based on the base model Muffin and LLaVA models, respectively. We make all our datasets and code publicly available: this https URL.</li>
</ul>

<h3>Title: Analysis of Zero Day Attack Detection Using MLP and XAI</h3>
<ul>
<li><strong>Authors: </strong>Ashim Dahal, Prabin Bajgai, Nick Rahimi</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2501.16638">https://arxiv.org/abs/2501.16638</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2501.16638">https://arxiv.org/pdf/2501.16638</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2501.16638]] Analysis of Zero Day Attack Detection Using MLP and XAI(https://arxiv.org/abs/2501.16638)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack, robust, interpretability</a></li>
<li><strong>Abstract: </strong>Any exploit taking advantage of zero-day is called a zero-day attack. Previous research and social media trends show a massive demand for research in zero-day attack detection. This paper analyzes Machine Learning (ML) and Deep Learning (DL) based approaches to create Intrusion Detection Systems (IDS) and scrutinizing them using Explainable AI (XAI) by training an explainer based on randomly sampled data from the testing set. The focus is on using the KDD99 dataset, which has the most research done among all the datasets for detecting zero-day attacks. The paper aims to synthesize the dataset to have fewer classes for multi-class classification, test ML and DL approaches on pattern recognition, establish the robustness and dependability of the model, and establish the interpretability and scalability of the model. We evaluated the performance of four multilayer perceptron (MLP) trained on the KDD99 dataset, including baseline ML models, weighted ML models, truncated ML models, and weighted truncated ML models. Our results demonstrate that the truncated ML model achieves the highest accuracy (99.62%), precision, and recall, while weighted truncated ML model shows lower accuracy (97.26%) but better class representation (less bias) among all the classes with improved unweighted recall score. We also used Shapely Additive exPlanations (SHAP) to train explainer for our truncated models to check for feature importance among the two weighted and unweighted models.</li>
</ul>

<h3>Title: An LLM Benchmark for Addressee Recognition in Multi-modal Multi-party Dialogue</h3>
<ul>
<li><strong>Authors: </strong>Koji Inoue, Divesh Lala, Mikey Elmers, Keiko Ochi, Tatsuya Kawahara</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.SD, eess.AS</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2501.16643">https://arxiv.org/abs/2501.16643</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2501.16643">https://arxiv.org/pdf/2501.16643</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2501.16643]] An LLM Benchmark for Addressee Recognition in Multi-modal Multi-party Dialogue(https://arxiv.org/abs/2501.16643)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Handling multi-party dialogues represents a significant step for advancing spoken dialogue systems, necessitating the development of tasks specific to multi-party interactions. To address this challenge, we are constructing a multi-modal multi-party dialogue corpus of triadic (three-participant) discussions. This paper focuses on the task of addressee recognition, identifying who is being addressed to take the next turn, a critical component unique to multi-party dialogue systems. A subset of the corpus was annotated with addressee information, revealing that explicit addressees are indicated in approximately 20% of conversational turns. To evaluate the task's complexity, we benchmarked the performance of a large language model (GPT-4o) on addressee recognition. The results showed that GPT-4o achieved an accuracy only marginally above chance, underscoring the challenges of addressee recognition in multi-party dialogue. These findings highlight the need for further research to enhance the capabilities of large language models in understanding and navigating the intricacies of multi-party conversational dynamics.</li>
</ul>

<h3>Title: DOCS: Quantifying Weight Similarity for Deeper Insights into Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Zeping Min, Xinshang Wang</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2501.16650">https://arxiv.org/abs/2501.16650</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2501.16650">https://arxiv.org/pdf/2501.16650</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2501.16650]] DOCS: Quantifying Weight Similarity for Deeper Insights into Large Language Models(https://arxiv.org/abs/2501.16650)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>We introduce a novel index, the Distribution of Cosine Similarity (DOCS), for quantitatively assessing the similarity between weight matrices in Large Language Models (LLMs), aiming to facilitate the analysis of their complex architectures. Leveraging DOCS, our analysis uncovers intriguing patterns in the latest open-source LLMs: adjacent layers frequently exhibit high weight similarity and tend to form clusters, suggesting depth-wise functional specialization. Additionally, we prove that DOCS is theoretically effective in quantifying similarity for orthogonal matrices, a crucial aspect given the prevalence of orthogonal initializations in LLMs. This research contributes to a deeper understanding of LLM architecture and behavior, offering tools with potential implications for developing more efficient and interpretable models.</li>
</ul>

<h3>Title: Large Language Model Critics for Execution-Free Evaluation of Code Changes</h3>
<ul>
<li><strong>Authors: </strong>Aashish Yadavally, Hoan Nguyen, Laurent Callot, Gauthier Guinet</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.SE</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2501.16655">https://arxiv.org/abs/2501.16655</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2501.16655">https://arxiv.org/pdf/2501.16655</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2501.16655]] Large Language Model Critics for Execution-Free Evaluation of Code Changes(https://arxiv.org/abs/2501.16655)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large language models (LLMs) offer a promising way forward for automating software engineering tasks, such as bug fixes, feature additions, etc., via multi-step LLM-based agentic workflows. However, existing metrics for evaluating such workflows, mainly build status and occasionally log analysis, are too sparse and limited in providing the information needed to assess the quality of changes made. In this work, we designed LLM-based critics to derive well-structured and rigorous intermediate/step-level, execution-free evaluation proxies for repo-level code changes. Importantly, we assume access to the gold test patch for the problem (i.e., reference-aware) to assess both semantics and executability of generated patches. With the gold test patch as a reference, we predict executability of all editing locations with an F1 score of 91.6%, aggregating which, we can predict the build status in 84.8% of the instances in SWE-bench. In particular, such an execution-focused LLM critic outperforms other reference-free and reference-aware LLM critics by 38.9% to 72.5%. Moreover, we demonstrate the usefulness of such a reference-aware framework in comparing patches generated by different agentic workflows. Finally, we open-source the library developed for this project, which allows further usage for either other agentic workflows or other benchmarks. The source code is available at this https URL.</li>
</ul>

<h3>Title: Contextual Reinforcement in Multimodal Token Compression for Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Naderdel Piero, Zacharias Cromwell, Nathaniel Wainwright, Matthias Nethercott</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2501.16658">https://arxiv.org/abs/2501.16658</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2501.16658">https://arxiv.org/pdf/2501.16658</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2501.16658]] Contextual Reinforcement in Multimodal Token Compression for Large Language Models(https://arxiv.org/abs/2501.16658)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, large language model</a></li>
<li><strong>Abstract: </strong>Effective token compression remains a critical challenge for scaling models to handle increasingly complex and diverse datasets. A novel mechanism based on contextual reinforcement is introduced, dynamically adjusting token importance through interdependencies and semantic relevance. This approach enables substantial reductions in token usage while preserving the quality and coherence of information representation. Incorporating graph-based algorithms and adaptive weighting, the method captures subtle contextual relationships across textual and multimodal data, ensuring robust alignment and performance in downstream tasks. Evaluations across varied domains reveal significant improvements in accuracy and semantic retention, particularly for tasks requiring detailed cross-modal interactions. Memory usage analyses demonstrate improved computational efficiency, with minimal overhead despite the additional reinforcement processes. Performance gains are further validated through error distribution analyses, showing reduced semantic loss and syntactic inconsistencies compared to baseline models. The modular architecture ensures compatibility with a wide range of open-source frameworks, facilitating scalable implementation for real-world applications. These findings highlight the potential of contextual reinforcement in redefining token management strategies and advancing large-scale model design.</li>
</ul>

<h3>Title: Vision-based autonomous structural damage detection using data-driven methods</h3>
<ul>
<li><strong>Authors: </strong>Seyyed Taghi Ataei, Parviz Mohammad Zadeh, Saeid Ataei</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI, eess.IV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2501.16662">https://arxiv.org/abs/2501.16662</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2501.16662">https://arxiv.org/pdf/2501.16662</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2501.16662]] Vision-based autonomous structural damage detection using data-driven methods(https://arxiv.org/abs/2501.16662)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>This study addresses the urgent need for efficient and accurate damage detection in wind turbine structures, a crucial component of renewable energy infrastructure. Traditional inspection methods, such as manual assessments and non-destructive testing (NDT), are often costly, time-consuming, and prone to human error. To tackle these challenges, this research investigates advanced deep learning algorithms for vision-based structural health monitoring (SHM). A dataset of wind turbine surface images, featuring various damage types and pollution, was prepared and augmented for enhanced model training. Three algorithms-YOLOv7, its lightweight variant, and Faster R-CNN- were employed to detect and classify surface damage. The models were trained and evaluated on a dataset split into training, testing, and evaluation subsets (80%-10%-10%). Results indicate that YOLOv7 outperformed the others, achieving 82.4% mAP@50 and high processing speed, making it suitable for real-time inspections. By optimizing hyperparameters like learning rate and batch size, the models' accuracy and efficiency improved further. YOLOv7 demonstrated significant advancements in detection precision and execution speed, especially for real-time applications. However, challenges such as dataset limitations and environmental variability were noted, suggesting future work on segmentation methods and larger datasets. This research underscores the potential of vision-based deep learning techniques to transform SHM practices by reducing costs, enhancing safety, and improving reliability, thus contributing to the sustainable maintenance of critical infrastructure and supporting the longevity of wind energy systems.</li>
</ul>

<h3>Title: Data Duplication: A Novel Multi-Purpose Attack Paradigm in Machine Unlearning</h3>
<ul>
<li><strong>Authors: </strong>Dayong Ye, Tainqing Zhu, Jiayang Li, Kun Gao, Bo Liu, Leo Yu Zhang, Wanlei Zhou, Yang Zhang</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2501.16663">https://arxiv.org/abs/2501.16663</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2501.16663">https://arxiv.org/pdf/2501.16663</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2501.16663]] Data Duplication: A Novel Multi-Purpose Attack Paradigm in Machine Unlearning(https://arxiv.org/abs/2501.16663)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, attack, federate</a></li>
<li><strong>Abstract: </strong>Duplication is a prevalent issue within datasets. Existing research has demonstrated that the presence of duplicated data in training datasets can significantly influence both model performance and data privacy. However, the impact of data duplication on the unlearning process remains largely unexplored. This paper addresses this gap by pioneering a comprehensive investigation into the role of data duplication, not only in standard machine unlearning but also in federated and reinforcement unlearning paradigms. Specifically, we propose an adversary who duplicates a subset of the target model's training set and incorporates it into the training set. After training, the adversary requests the model owner to unlearn this duplicated subset, and analyzes the impact on the unlearned model. For example, the adversary can challenge the model owner by revealing that, despite efforts to unlearn it, the influence of the duplicated subset remains in the model. Moreover, to circumvent detection by de-duplication techniques, we propose three novel near-duplication methods for the adversary, each tailored to a specific unlearning paradigm. We then examine their impacts on the unlearning process when de-duplication techniques are applied. Our findings reveal several crucial insights: 1) the gold standard unlearning method, retraining from scratch, fails to effectively conduct unlearning under certain conditions; 2) unlearning duplicated data can lead to significant model degradation in specific scenarios; and 3) meticulously crafted duplicates can evade detection by de-duplication methods.</li>
</ul>

<h3>Title: CSPCL: Category Semantic Prior Contrastive Learning for Deformable DETR-Based Prohibited Item Detectors</h3>
<ul>
<li><strong>Authors: </strong>Mingyuan Li, Tong Jia, Hui Lu, Bowen Ma, Hao Wang, Dongyue Chen</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2501.16665">https://arxiv.org/abs/2501.16665</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2501.16665">https://arxiv.org/pdf/2501.16665</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2501.16665]] CSPCL: Category Semantic Prior Contrastive Learning for Deformable DETR-Based Prohibited Item Detectors(https://arxiv.org/abs/2501.16665)</code><input type="text"></li>
<li><strong>Keywords: </strong>security</a></li>
<li><strong>Abstract: </strong>Prohibited item detection based on X-ray images is one of the most effective security inspection methods. However, the foreground-background feature coupling caused by the overlapping phenomenon specific to X-ray images makes general detectors designed for natural images perform poorly. To address this issue, we propose a Category Semantic Prior Contrastive Learning (CSPCL) mechanism, which aligns the class prototypes perceived by the classifier with the content queries to correct and supplement the missing semantic information responsible for classification, thereby enhancing the model sensitivity to foreground this http URL achieve this alignment, we design a specific contrastive loss, CSP loss, which includes Intra-Class Truncated Attraction (ITA) loss and Inter-Class Adaptive Repulsion (IAR) loss, and outperforms classic N-pair loss and InfoNCE loss. Specifically, ITA loss leverages class prototypes to attract intra-class category-specific content queries while preserving necessary distinctiveness. IAR loss utilizes class prototypes to adaptively repel inter-class category-specific content queries based on the similarity between class prototypes, helping disentangle features of similar this http URL is general and can be easily integrated into Deformable DETR-based models. Extensive experiments on the PIXray and OPIXray datasets demonstrate that CSPCL significantly enhances the performance of various state-of-the-art models without increasing this http URL code will be open source once the paper is accepted.</li>
</ul>

<h3>Title: Federated Learning for Efficient Condition Monitoring and Anomaly Detection in Industrial Cyber-Physical Systems</h3>
<ul>
<li><strong>Authors: </strong>William Marfo, Deepak K. Tosh, Shirley V. Moore</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2501.16666">https://arxiv.org/abs/2501.16666</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2501.16666">https://arxiv.org/pdf/2501.16666</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2501.16666]] Federated Learning for Efficient Condition Monitoring and Anomaly Detection in Industrial Cyber-Physical Systems(https://arxiv.org/abs/2501.16666)</code><input type="text"></li>
<li><strong>Keywords: </strong>federate</a></li>
<li><strong>Abstract: </strong>Detecting and localizing anomalies in cyber-physical systems (CPS) has become increasingly challenging as systems grow in complexity, particularly due to varying sensor reliability and node failures in distributed environments. While federated learning (FL) provides a foundation for distributed model training, existing approaches often lack mechanisms to address these CPS-specific challenges. This paper introduces an enhanced FL framework with three key innovations: adaptive model aggregation based on sensor reliability, dynamic node selection for resource optimization, and Weibull-based checkpointing for fault tolerance. The proposed framework ensures reliable condition monitoring while tackling the computational and reliability challenges of industrial CPS deployments. Experiments on the NASA Bearing and Hydraulic System datasets demonstrate superior performance compared to state-of-the-art FL methods, achieving 99.5% AUC-ROC in anomaly detection and maintaining accuracy even under node failures. Statistical validation using the Mann-Whitney U test confirms significant improvements, with a p-value less than 0.05, in both detection accuracy and computational efficiency across various operational scenarios.</li>
</ul>

<h3>Title: Data-Free Model-Related Attacks: Unleashing the Potential of Generative AI</h3>
<ul>
<li><strong>Authors: </strong>Dayong Ye, Tianqing Zhu, Shang Wang, Bo Liu, Leo Yu Zhang, Wanlei Zhou, Yang Zhang</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2501.16671">https://arxiv.org/abs/2501.16671</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2501.16671">https://arxiv.org/pdf/2501.16671</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2501.16671]] Data-Free Model-Related Attacks: Unleashing the Potential of Generative AI(https://arxiv.org/abs/2501.16671)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack, extraction, membership infer, data-free, generative</a></li>
<li><strong>Abstract: </strong>Generative AI technology has become increasingly integrated into our daily lives, offering powerful capabilities to enhance productivity. However, these same capabilities can be exploited by adversaries for malicious purposes. While existing research on adversarial applications of generative AI predominantly focuses on cyberattacks, less attention has been given to attacks targeting deep learning models. In this paper, we introduce the use of generative AI for facilitating model-related attacks, including model extraction, membership inference, and model inversion. Our study reveals that adversaries can launch a variety of model-related attacks against both image and text models in a data-free and black-box manner, achieving comparable performance to baseline methods that have access to the target models' training data and parameters in a white-box manner. This research serves as an important early warning to the community about the potential risks associated with generative AI-powered attacks on deep learning models.</li>
</ul>

<h3>Title: Auto-Differentiating Any LLM Workflow: A Farewell to Manual Prompting</h3>
<ul>
<li><strong>Authors: </strong>Li Yin, Zhangyang Wang (Atlas)</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2501.16673">https://arxiv.org/abs/2501.16673</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2501.16673">https://arxiv.org/pdf/2501.16673</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2501.16673]] Auto-Differentiating Any LLM Workflow: A Farewell to Manual Prompting(https://arxiv.org/abs/2501.16673)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large Language Models (LLMs) have reshaped natural language processing, powering applications from multi-hop retrieval and question answering to autonomous agent workflows. Yet, prompt engineering -- the task of crafting textual inputs to effectively direct LLMs -- remains difficult and labor-intensive, particularly for complex pipelines that combine multiple LLM calls with functional operations like retrieval and data formatting. We introduce LLM-AutoDiff: a novel framework for Automatic Prompt Engineering (APE) that extends textual gradient-based methods (such as Text-Grad) to multi-component, potentially cyclic LLM architectures. Implemented within the AdalFlow library, LLM-AutoDiff treats each textual input as a trainable parameter and uses a frozen backward engine LLM to generate feedback-akin to textual gradients -- that guide iterative prompt updates. Unlike prior single-node approaches, LLM-AutoDiff inherently accommodates functional nodes, preserves time-sequential behavior in repeated calls (e.g., multi-hop loops), and combats the "lost-in-the-middle" problem by isolating distinct sub-prompts (instructions, formats, or few-shot examples). It further boosts training efficiency by focusing on error-prone samples through selective gradient computation. Across diverse tasks, including single-step classification, multi-hop retrieval-based QA, and agent-driven pipelines, LLM-AutoDiff consistently outperforms existing textual gradient baselines in both accuracy and training cost. By unifying prompt optimization through a graph-centric lens, LLM-AutoDiff offers a powerful new paradigm for scaling and automating LLM workflows - mirroring the transformative role that automatic differentiation libraries have long played in neural network research.</li>
</ul>

<h3>Title: Improving Interpretability and Accuracy in Neuro-Symbolic Rule Extraction Using Class-Specific Sparse Filters</h3>
<ul>
<li><strong>Authors: </strong>Parth Padalkar, Jaeseong Lee, Shiyi Wei, Gopal Gupta</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2501.16677">https://arxiv.org/abs/2501.16677</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2501.16677">https://arxiv.org/pdf/2501.16677</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2501.16677]] Improving Interpretability and Accuracy in Neuro-Symbolic Rule Extraction Using Class-Specific Sparse Filters(https://arxiv.org/abs/2501.16677)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction, interpretability</a></li>
<li><strong>Abstract: </strong>There has been significant focus on creating neuro-symbolic models for interpretable image classification using Convolutional Neural Networks (CNNs). These methods aim to replace the CNN with a neuro-symbolic model consisting of the CNN, which is used as a feature extractor, and an interpretable rule-set extracted from the CNN itself. While these approaches provide interpretability through the extracted rule-set, they often compromise accuracy compared to the original CNN model. In this paper, we identify the root cause of this accuracy loss as the post-training binarization of filter activations to extract the rule-set. To address this, we propose a novel sparsity loss function that enables class-specific filter binarization during CNN training, thus minimizing information loss when extracting the rule-set. We evaluate several training strategies with our novel sparsity loss, analyzing their effectiveness and providing guidance on their appropriate use. Notably, we set a new benchmark, achieving a 9% improvement in accuracy and a 53% reduction in rule-set size on average, compared to the previous SOTA, while coming within 3% of the original CNN's accuracy. This highlights the significant potential of interpretable neuro-symbolic models as viable alternatives to black-box CNNs.</li>
</ul>

<h3>Title: Polyp-Gen: Realistic and Diverse Polyp Image Generation for Endoscopic Dataset Expansion</h3>
<ul>
<li><strong>Authors: </strong>Shengyuan Liu, Zhen Chen, Qiushi Yang, Weihao Yu, Di Dong, Jiancong Hu, Yixuan Yuan</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2501.16679">https://arxiv.org/abs/2501.16679</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2501.16679">https://arxiv.org/pdf/2501.16679</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2501.16679]] Polyp-Gen: Realistic and Diverse Polyp Image Generation for Endoscopic Dataset Expansion(https://arxiv.org/abs/2501.16679)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, diffusion</a></li>
<li><strong>Abstract: </strong>Automated diagnostic systems (ADS) have shown significant potential in the early detection of polyps during endoscopic examinations, thereby reducing the incidence of colorectal cancer. However, due to high annotation costs and strict privacy concerns, acquiring high-quality endoscopic images poses a considerable challenge in the development of ADS. Despite recent advancements in generating synthetic images for dataset expansion, existing endoscopic image generation algorithms failed to accurately generate the details of polyp boundary regions and typically required medical priors to specify plausible locations and shapes of polyps, which limited the realism and diversity of the generated images. To address these limitations, we present Polyp-Gen, the first full-automatic diffusion-based endoscopic image generation framework. Specifically, we devise a spatial-aware diffusion training scheme with a lesion-guided loss to enhance the structural context of polyp boundary regions. Moreover, to capture medical priors for the localization of potential polyp areas, we introduce a hierarchical retrieval-based sampling strategy to match similar fine-grained spatial features. In this way, our Polyp-Gen can generate realistic and diverse endoscopic images for building reliable ADS. Extensive experiments demonstrate the state-of-the-art generation quality, and the synthetic images can improve the downstream polyp detection task. Additionally, our Polyp-Gen has shown remarkable zero-shot generalizability on other datasets. The source code is available at this https URL.</li>
</ul>

<h3>Title: Differentially Private Set Representations</h3>
<ul>
<li><strong>Authors: </strong>Sarvar Patel, Giuseppe Persiano, Joon Young Seo, Kevin Yeo</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.DS</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2501.16680">https://arxiv.org/abs/2501.16680</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2501.16680">https://arxiv.org/pdf/2501.16680</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2501.16680]] Differentially Private Set Representations(https://arxiv.org/abs/2501.16680)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy</a></li>
<li><strong>Abstract: </strong>We study the problem of differentially private (DP) mechanisms for representing sets of size $k$ from a large universe. Our first construction creates $(\epsilon,\delta)$-DP representations with error probability of $1/(e^\epsilon + 1)$ using space at most $1.05 k \epsilon \cdot \log(e)$ bits where the time to construct a representation is $O(k \log(1/\delta))$ while decoding time is $O(\log(1/\delta))$. We also present a second algorithm for pure $\epsilon$-DP representations with the same error using space at most $k \epsilon \cdot \log(e)$ bits, but requiring large decoding times. Our algorithms match our lower bounds on privacy-utility trade-offs (including constants but ignoring $\delta$ factors) and we also present a new space lower bound matching our constructions up to small constant factors. To obtain our results, we design a new approach embedding sets into random linear systems deviating from most prior approaches that inject noise into non-private solutions.</li>
</ul>

<h3>Title: Blockchain Address Poisoning</h3>
<ul>
<li><strong>Authors: </strong>Taro Tsuchiya, Jin-Dong Dong, Kyle Soska, Nicolas Christin</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2501.16681">https://arxiv.org/abs/2501.16681</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2501.16681">https://arxiv.org/pdf/2501.16681</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2501.16681]] Blockchain Address Poisoning(https://arxiv.org/abs/2501.16681)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack</a></li>
<li><strong>Abstract: </strong>In many blockchains, e.g., Ethereum, Binance Smart Chain (BSC), the primary representation used for wallet addresses is a hardly memorable 40-digit hexadecimal string. As a result, users often select addresses from their recent transaction history, which enables blockchain address poisoning. The adversary first generates lookalike addresses similar to one with which the victim has previously interacted, and then engages with the victim to ``poison'' their transaction history. The goal is to have the victim mistakenly send tokens to the lookalike address, as opposed to the intended recipient. Compared to contemporary studies, this paper provides four notable contributions. First, we develop a detection system and perform measurements over two years on Ethereum and BSC. We identify 13 times the number of attack attempts reported previously -- totaling 270M on-chain attacks targeting 17M victims. 6,633 incidents have caused at least 83.8M USD in losses, which makes blockchain address poisoning one of the largest cryptocurrency phishing schemes observed in the wild. Second, we analyze a few large attack entities using improved clustering techniques, and model attacker profitability and competition. Third, we reveal attack strategies -- targeted populations, success conditions (address similarity, timing), and cross-chain attacks. Fourth, we mathematically define and simulate the lookalike address-generation process across various software- and hardware-based implementations, and identify a large-scale attacker group that appears to use GPUs. We also discuss defensive countermeasures.</li>
</ul>

<h3>Title: MME-Industry: A Cross-Industry Multimodal Evaluation Benchmark</h3>
<ul>
<li><strong>Authors: </strong>Dongyi Yi, Guibo Zhu, Chenglin Ding, Zongshu Li, Dong Yi, Jinqiao Wang</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2501.16688">https://arxiv.org/abs/2501.16688</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2501.16688">https://arxiv.org/pdf/2501.16688</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2501.16688]] MME-Industry: A Cross-Industry Multimodal Evaluation Benchmark(https://arxiv.org/abs/2501.16688)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>With the rapid advancement of Multimodal Large Language Models (MLLMs), numerous evaluation benchmarks have emerged. However, comprehensive assessments of their performance across diverse industrial applications remain limited. In this paper, we introduce MME-Industry, a novel benchmark designed specifically for evaluating MLLMs in industrial this http URL benchmark encompasses 21 distinct domain, comprising 1050 question-answer pairs with 50 questions per domain. To ensure data integrity and prevent potential leakage from public datasets, all question-answer pairs were manually crafted and validated by domain experts. Besides, the benchmark's complexity is effectively enhanced by incorporating non-OCR questions that can be answered directly, along with tasks requiring specialized domain knowledge. Moreover, we provide both Chinese and English versions of the benchmark, enabling comparative analysis of MLLMs' capabilities across these languages. Our findings contribute valuable insights into MLLMs' practical industrial applications and illuminate promising directions for future model optimization research.</li>
</ul>

<h3>Title: 3D-MoE: A Mixture-of-Experts Multi-modal LLM for 3D Vision and Pose Diffusion via Rectified Flow</h3>
<ul>
<li><strong>Authors: </strong>Yueen Ma, Yuzheng Zhuang, Jianye Hao, Irwin King</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.CV, cs.RO</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2501.16698">https://arxiv.org/abs/2501.16698</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2501.16698">https://arxiv.org/pdf/2501.16698</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2501.16698]] 3D-MoE: A Mixture-of-Experts Multi-modal LLM for 3D Vision and Pose Diffusion via Rectified Flow(https://arxiv.org/abs/2501.16698)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, large language model</a></li>
<li><strong>Abstract: </strong>3D vision and spatial reasoning have long been recognized as preferable for accurately perceiving our three-dimensional world, especially when compared with traditional visual reasoning based on 2D images. Due to the difficulties in collecting high-quality 3D data, research in this area has only recently gained momentum. With the advent of powerful large language models (LLMs), multi-modal LLMs for 3D vision have been developed over the past few years. However, most of these models focus primarily on the vision encoder for 3D data. In this paper, we propose converting existing densely activated LLMs into mixture-of-experts (MoE) models, which have proven effective for multi-modal data processing. In addition to leveraging these models' instruction-following capabilities, we further enable embodied task planning by attaching a diffusion head, Pose-DiT, that employs a novel rectified flow diffusion scheduler. Experimental results on 3D question answering and task-planning tasks demonstrate that our 3D-MoE framework achieves improved performance with fewer activated parameters.</li>
</ul>

<h3>Title: DFCon: Attention-Driven Supervised Contrastive Learning for Robust Deepfake Detection</h3>
<ul>
<li><strong>Authors: </strong>MD Sadik Hossain Shanto, Mahir Labib Dihan, Souvik Ghosh, Riad Ahmed Anonto, Hafijul Hoque Chowdhury, Abir Muhtasim, Rakib Ahsan, MD Tanvir Hassan, MD Roqunuzzaman Sojib, Sheikh Azizul Hakim, M. Saifur Rahman</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.CR, cs.LG, eess.IV, eess.SP</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2501.16704">https://arxiv.org/abs/2501.16704</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2501.16704">https://arxiv.org/pdf/2501.16704</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2501.16704]] DFCon: Attention-Driven Supervised Contrastive Learning for Robust Deepfake Detection(https://arxiv.org/abs/2501.16704)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>This report presents our approach for the IEEE SP Cup 2025: Deepfake Face Detection in the Wild (DFWild-Cup), focusing on detecting deepfakes across diverse datasets. Our methodology employs advanced backbone models, including MaxViT, CoAtNet, and EVA-02, fine-tuned using supervised contrastive loss to enhance feature separation. These models were specifically chosen for their complementary strengths. Integration of convolution layers and strided attention in MaxViT is well-suited for detecting local features. In contrast, hybrid use of convolution and attention mechanisms in CoAtNet effectively captures multi-scale features. Robust pretraining with masked image modeling of EVA-02 excels at capturing global features. After training, we freeze the parameters of these models and train the classification heads. Finally, a majority voting ensemble is employed to combine the predictions from these models, improving robustness and generalization to unseen scenarios. The proposed system addresses the challenges of detecting deepfakes in real-world conditions and achieves a commendable accuracy of 95.83% on the validation dataset.</li>
</ul>

<h3>Title: Separate Motion from Appearance: Customizing Motion via Customizing Text-to-Video Diffusion Models</h3>
<ul>
<li><strong>Authors: </strong>Huijie Liu, Jingyun Wang, Shuai Ma, Jie Hu, Xiaoming Wei, Guoliang Kang</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2501.16714">https://arxiv.org/abs/2501.16714</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2501.16714">https://arxiv.org/pdf/2501.16714</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2501.16714]] Separate Motion from Appearance: Customizing Motion via Customizing Text-to-Video Diffusion Models(https://arxiv.org/abs/2501.16714)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>Motion customization aims to adapt the diffusion model (DM) to generate videos with the motion specified by a set of video clips with the same motion concept. To realize this goal, the adaptation of DM should be possible to model the specified motion concept, without compromising the ability to generate diverse appearances. Thus, the key to solving this problem lies in how to separate the motion concept from the appearance in the adaptation process of DM. Typical previous works explore different ways to represent and insert a motion concept into large-scale pretrained text-to-video diffusion models, e.g., learning a motion LoRA, using latent noise residuals, etc. While those methods can encode the motion concept, they also inevitably encode the appearance in the reference videos, resulting in weakened appearance generation capability. In this paper, we follow the typical way to learn a motion LoRA to encode the motion concept, but propose two novel strategies to enhance motion-appearance separation, including temporal attention purification (TAP) and appearance highway (AH). Specifically, we assume that in the temporal attention module, the pretrained Value embeddings are sufficient to serve as basic components needed by producing a new motion. Thus, in TAP, we choose only to reshape the temporal attention with motion LoRAs so that Value embeddings can be reorganized to produce a new motion. Further, in AH, we alter the starting point of each skip connection in U-Net from the output of each temporal attention module to the output of each spatial attention module. Extensive experiments demonstrate that compared to previous works, our method can generate videos with appearance more aligned with the text descriptions and motion more consistent with the reference videos.</li>
</ul>

<h3>Title: Point Cloud Upsampling as Statistical Shape Model for Pelvic</h3>
<ul>
<li><strong>Authors: </strong>Tongxu Zhang, Bei Wang</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2501.16716">https://arxiv.org/abs/2501.16716</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2501.16716">https://arxiv.org/pdf/2501.16716</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2501.16716]] Point Cloud Upsampling as Statistical Shape Model for Pelvic(https://arxiv.org/abs/2501.16716)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, segmentation</a></li>
<li><strong>Abstract: </strong>We propose a novel framework that integrates medical image segmentation and point cloud upsampling for accurate shape reconstruction of pelvic models. Using the SAM-Med3D model for segmentation and a point cloud upsampling network trained on the MedShapeNet dataset, our method transforms sparse medical imaging data into high-resolution 3D bone models. This framework leverages prior knowledge of anatomical shapes, achieving smoother and more complete reconstructions. Quantitative evaluations using metrics such as Chamfer Distance etc, demonstrate the effectiveness of the point cloud upsampling in pelvic model. Our approach offers potential applications in reconstructing other skeletal structures, providing a robust solution for medical image analysis and statistical shape modeling.</li>
</ul>

<h3>Title: Outlier Synthesis via Hamiltonian Monte Carlo for Out-of-Distribution Detection</h3>
<ul>
<li><strong>Authors: </strong>Hengzhuang Li, Teng Zhang</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2501.16718">https://arxiv.org/abs/2501.16718</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2501.16718">https://arxiv.org/pdf/2501.16718</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2501.16718]] Outlier Synthesis via Hamiltonian Monte Carlo for Out-of-Distribution Detection(https://arxiv.org/abs/2501.16718)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>Out-of-distribution (OOD) detection is crucial for developing trustworthy and reliable machine learning systems. Recent advances in training with auxiliary OOD data demonstrate efficacy in enhancing detection capabilities. Nonetheless, these methods heavily rely on acquiring a large pool of high-quality natural outliers. Some prior methods try to alleviate this problem by synthesizing virtual outliers but suffer from either poor quality or high cost due to the monotonous sampling strategy and the heavy-parameterized generative models. In this paper, we overcome all these problems by proposing the Hamiltonian Monte Carlo Outlier Synthesis (HamOS) framework, which views the synthesis process as sampling from Markov chains. Based solely on the in-distribution data, the Markov chains can extensively traverse the feature space and generate diverse and representative outliers, hence exposing the model to miscellaneous potential OOD scenarios. The Hamiltonian Monte Carlo with sampling acceptance rate almost close to 1 also makes our framework enjoy great efficiency. By empirically competing with SOTA baselines on both standard and large-scale benchmarks, we verify the efficacy and efficiency of our proposed HamOS.</li>
</ul>

<h3>Title: B-RIGHT: Benchmark Re-evaluation for Integrity in Generalized Human-Object Interaction Testing</h3>
<ul>
<li><strong>Authors: </strong>Yoojin Jang, Junsu Kim, Hayeon Kim, Eun-ki Lee, Eun-sol Kim, Seungryul Baek, Jaejun Yoo</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2501.16724">https://arxiv.org/abs/2501.16724</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2501.16724">https://arxiv.org/pdf/2501.16724</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2501.16724]] B-RIGHT: Benchmark Re-evaluation for Integrity in Generalized Human-Object Interaction Testing(https://arxiv.org/abs/2501.16724)</code><input type="text"></li>
<li><strong>Keywords: </strong>fair</a></li>
<li><strong>Abstract: </strong>Human-object interaction (HOI) is an essential problem in artificial intelligence (AI) which aims to understand the visual world that involves complex relationships between humans and objects. However, current benchmarks such as HICO-DET face the following limitations: (1) severe class imbalance and (2) varying number of train and test sets for certain classes. These issues can potentially lead to either inflation or deflation of model performance during evaluation, ultimately undermining the reliability of evaluation scores. In this paper, we propose a systematic approach to develop a new class-balanced dataset, Benchmark Re-evaluation for Integrity in Generalized Human-object Interaction Testing (B-RIGHT), that addresses these imbalanced problems. B-RIGHT achieves class balance by leveraging balancing algorithm and automated generation-and-filtering processes, ensuring an equal number of instances for each HOI class. Furthermore, we design a balanced zero-shot test set to systematically evaluate models on unseen scenario. Re-evaluating existing models using B-RIGHT reveals substantial the reduction of score variance and changes in performance rankings compared to conventional HICO-DET. Our experiments demonstrate that evaluation under balanced conditions ensure more reliable and fair model comparisons.</li>
</ul>

<h3>Title: xJailbreak: Representation Space Guided Reinforcement Learning for Interpretable LLM Jailbreaking</h3>
<ul>
<li><strong>Authors: </strong>Sunbowen Lee, Shiwen Ni, Chi Wei, Shuaimin Li, Liyang Fan, Ahmadreza Argha, Hamid Alinejad-Rokny, Ruifeng Xu, Yicheng Gong, Min Yang</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2501.16727">https://arxiv.org/abs/2501.16727</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2501.16727">https://arxiv.org/pdf/2501.16727</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2501.16727]] xJailbreak: Representation Space Guided Reinforcement Learning for Interpretable LLM Jailbreaking(https://arxiv.org/abs/2501.16727)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack, robust, large language model</a></li>
<li><strong>Abstract: </strong>Safety alignment mechanism are essential for preventing large language models (LLMs) from generating harmful information or unethical content. However, cleverly crafted prompts can bypass these safety measures without accessing the model's internal parameters, a phenomenon known as black-box jailbreak. Existing heuristic black-box attack methods, such as genetic algorithms, suffer from limited effectiveness due to their inherent randomness, while recent reinforcement learning (RL) based methods often lack robust and informative reward signals. To address these challenges, we propose a novel black-box jailbreak method leveraging RL, which optimizes prompt generation by analyzing the embedding proximity between benign and malicious prompts. This approach ensures that the rewritten prompts closely align with the intent of the original prompts while enhancing the attack's effectiveness. Furthermore, we introduce a comprehensive jailbreak evaluation framework incorporating keywords, intent matching, and answer validation to provide a more rigorous and holistic assessment of jailbreak success. Experimental results show the superiority of our approach, achieving state-of-the-art (SOTA) performance on several prominent open and closed-source LLMs, including Qwen2.5-7B-Instruct, Llama3.1-8B-Instruct, and GPT-4o-0806. Our method sets a new benchmark in jailbreak attack effectiveness, highlighting potential vulnerabilities in LLMs. The codebase for this work is available at this https URL.</li>
</ul>

<h3>Title: Growing the Efficient Frontier on Panel Trees</h3>
<ul>
<li><strong>Authors: </strong>Lin William Cong, Guanhao Feng, Jingyu He, Xin He</a></li>
<li><strong>Subjects: </strong>cs.LG, q-fin.PR, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2501.16730">https://arxiv.org/abs/2501.16730</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2501.16730">https://arxiv.org/pdf/2501.16730</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2501.16730]] Growing the Efficient Frontier on Panel Trees(https://arxiv.org/abs/2501.16730)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability</a></li>
<li><strong>Abstract: </strong>We introduce a new class of tree-based models, P-Trees, for analyzing (unbalanced) panel of individual asset returns, generalizing high-dimensional sorting with economic guidance and interpretability. Under the mean-variance efficient framework, P-Trees construct test assets that significantly advance the efficient frontier compared to commonly used test assets, with alphas unexplained by benchmark pricing models. P-Tree tangency portfolios also constitute traded factors, recovering the pricing kernel and outperforming popular observable and latent factor models for investments and cross-sectional pricing. Finally, P-Trees capture the complexity of asset returns with sparsity, achieving out-of-sample Sharpe ratios close to those attained only by over-parameterized large models.</li>
</ul>

<h3>Title: Consistency Diffusion Models for Single-Image 3D Reconstruction with Priors</h3>
<ul>
<li><strong>Authors: </strong>Chenru Jiang, Chengrui Zhang, Xi Yang, Jie Sun, Kaizhu Huang</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2501.16737">https://arxiv.org/abs/2501.16737</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2501.16737">https://arxiv.org/pdf/2501.16737</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2501.16737]] Consistency Diffusion Models for Single-Image 3D Reconstruction with Priors(https://arxiv.org/abs/2501.16737)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, diffusion</a></li>
<li><strong>Abstract: </strong>This paper delves into the study of 3D point cloud reconstruction from a single image. Our objective is to develop the Consistency Diffusion Model, exploring synergistic 2D and 3D priors in the Bayesian framework to ensure superior consistency in the reconstruction process, a challenging yet critical requirement in this field. Specifically, we introduce a pioneering training framework under diffusion models that brings two key innovations. First, we convert 3D structural priors derived from the initial 3D point cloud as a bound term to increase evidence in the variational Bayesian framework, leveraging these robust intrinsic priors to tightly govern the diffusion training process and bolster consistency in reconstruction. Second, we extract and incorporate 2D priors from the single input image, projecting them onto the 3D point cloud to enrich the guidance for diffusion training. Our framework not only sidesteps potential model learning shifts that may arise from directly imposing additional constraints during training but also precisely transposes the 2D priors into the 3D domain. Extensive experimental evaluations reveal that our approach sets new benchmarks in both synthetic and real-world datasets. The code is included with the submission.</li>
</ul>

<h3>Title: LLM Assisted Anomaly Detection Service for Site Reliability Engineers: Enhancing Cloud Infrastructure Resilience</h3>
<ul>
<li><strong>Authors: </strong>Nimesh Jha, Shuxin Lin, Srideepika Jayaraman, Kyle Frohling, Christodoulos Constantinides, Dhaval Patel</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2501.16744">https://arxiv.org/abs/2501.16744</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2501.16744">https://arxiv.org/pdf/2501.16744</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2501.16744]] LLM Assisted Anomaly Detection Service for Site Reliability Engineers: Enhancing Cloud Infrastructure Resilience(https://arxiv.org/abs/2501.16744)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>This paper introduces a scalable Anomaly Detection Service with a generalizable API tailored for industrial time-series data, designed to assist Site Reliability Engineers (SREs) in managing cloud infrastructure. The service enables efficient anomaly detection in complex data streams, supporting proactive identification and resolution of issues. Furthermore, it presents an innovative approach to anomaly modeling in cloud infrastructure by utilizing Large Language Models (LLMs) to understand key components, their failure modes, and behaviors. A suite of algorithms for detecting anomalies is offered in univariate and multivariate time series data, including regression-based, mixture-model-based, and semi-supervised approaches. We provide insights into the usage patterns of the service, with over 500 users and 200,000 API calls in a year. The service has been successfully applied in various industrial settings, including IoT-based AI applications. We have also evaluated our system on public anomaly benchmarks to show its effectiveness. By leveraging it, SREs can proactively identify potential issues before they escalate, reducing downtime and improving response times to incidents, ultimately enhancing the overall customer experience. We plan to extend the system to include time series foundation models, enabling zero-shot anomaly detection capabilities.</li>
</ul>

<h3>Title: Through the Prism of Culture: Evaluating LLMs' Understanding of Indian Subcultures and Traditions</h3>
<ul>
<li><strong>Authors: </strong>Garima Chhikara, Abhishek Kumar, Abhijnan Chakraborty</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2501.16748">https://arxiv.org/abs/2501.16748</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2501.16748">https://arxiv.org/pdf/2501.16748</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2501.16748]] Through the Prism of Culture: Evaluating LLMs' Understanding of Indian Subcultures and Traditions(https://arxiv.org/abs/2501.16748)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large Language Models (LLMs) have shown remarkable advancements but also raise concerns about cultural bias, often reflecting dominant narratives at the expense of under-represented subcultures. In this study, we evaluate the capacity of LLMs to recognize and accurately respond to the Little Traditions within Indian society, encompassing localized cultural practices and subcultures such as caste, kinship, marriage, and religion. Through a series of case studies, we assess whether LLMs can balance the interplay between dominant Great Traditions and localized Little Traditions. We explore various prompting strategies and further investigate whether using prompts in regional languages enhances the models cultural sensitivity and response quality. Our findings reveal that while LLMs demonstrate an ability to articulate cultural nuances, they often struggle to apply this understanding in practical, context-specific scenarios. To the best of our knowledge, this is the first study to analyze LLMs engagement with Indian subcultures, offering critical insights into the challenges of embedding cultural diversity in AI systems.</li>
</ul>

<h3>Title: HateBench: Benchmarking Hate Speech Detectors on LLM-Generated Content and Hate Campaigns</h3>
<ul>
<li><strong>Authors: </strong>Xinyue Shen, Yixin Wu, Yiting Qu, Michael Backes, Savvas Zannettou, Yang Zhang</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2501.16750">https://arxiv.org/abs/2501.16750</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2501.16750">https://arxiv.org/pdf/2501.16750</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2501.16750]] HateBench: Benchmarking Hate Speech Detectors on LLM-Generated Content and Hate Campaigns(https://arxiv.org/abs/2501.16750)</code><input type="text"></li>
<li><strong>Keywords: </strong>defense, attack, steal, large language model</a></li>
<li><strong>Abstract: </strong>Large Language Models (LLMs) have raised increasing concerns about their misuse in generating hate speech. Among all the efforts to address this issue, hate speech detectors play a crucial role. However, the effectiveness of different detectors against LLM-generated hate speech remains largely unknown. In this paper, we propose HateBench, a framework for benchmarking hate speech detectors on LLM-generated hate speech. We first construct a hate speech dataset of 7,838 samples generated by six widely-used LLMs covering 34 identity groups, with meticulous annotations by three labelers. We then assess the effectiveness of eight representative hate speech detectors on the LLM-generated dataset. Our results show that while detectors are generally effective in identifying LLM-generated hate speech, their performance degrades with newer versions of LLMs. We also reveal the potential of LLM-driven hate campaigns, a new threat that LLMs bring to the field of hate speech detection. By leveraging advanced techniques like adversarial attacks and model stealing attacks, the adversary can intentionally evade the detector and automate hate campaigns online. The most potent adversarial attack achieves an attack success rate of 0.966, and its attack efficiency can be further improved by $13-21\times$ through model stealing attacks with acceptable attack performance. We hope our study can serve as a call to action for the research community and platform moderators to fortify defenses against these emerging threats.</li>
</ul>

<h3>Title: DebugAgent: Efficient and Interpretable Error Slice Discovery for Comprehensive Model Debugging</h3>
<ul>
<li><strong>Authors: </strong>Muxi Chen, Chenchen Zhao, Qiang Xu</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2501.16751">https://arxiv.org/abs/2501.16751</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2501.16751">https://arxiv.org/pdf/2501.16751</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2501.16751]] DebugAgent: Efficient and Interpretable Error Slice Discovery for Comprehensive Model Debugging(https://arxiv.org/abs/2501.16751)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Despite the significant success of deep learning models in computer vision, they often exhibit systematic failures on specific data subsets, known as error slices. Identifying and mitigating these error slices is crucial to enhancing model robustness and reliability in real-world scenarios. In this paper, we introduce DebugAgent, an automated framework for error slice discovery and model repair. DebugAgent first generates task-specific visual attributes to highlight instances prone to errors through an interpretable and structured process. It then employs an efficient slice enumeration algorithm to systematically identify error slices, overcoming the combinatorial challenges that arise during slice exploration. Additionally, DebugAgent extends its capabilities by predicting error slices beyond the validation set, addressing a key limitation of prior approaches. Extensive experiments across multiple domains, including image classification, pose estimation, and object detection - show that DebugAgent not only improves the coherence and precision of identified error slices but also significantly enhances the model repair capabilities.</li>
</ul>

<h3>Title: Overcoming Semantic Dilution in Transformer-Based Next Frame Prediction</h3>
<ul>
<li><strong>Authors: </strong>Hy Nguyen, Srikanth Thudumu, Hung Du, Rajesh Vasa, Kon Mouzakis</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2501.16753">https://arxiv.org/abs/2501.16753</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2501.16753">https://arxiv.org/pdf/2501.16753</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2501.16753]] Overcoming Semantic Dilution in Transformer-Based Next Frame Prediction(https://arxiv.org/abs/2501.16753)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Next-frame prediction in videos is crucial for applications such as autonomous driving, object tracking, and motion prediction. The primary challenge in next-frame prediction lies in effectively capturing and processing both spatial and temporal information from previous video sequences. The transformer architecture, known for its prowess in handling sequence data, has made remarkable progress in this domain. However, transformer-based next-frame prediction models face notable issues: (a) The multi-head self-attention (MHSA) mechanism requires the input embedding to be split into $N$ chunks, where $N$ is the number of heads. Each segment captures only a fraction of the original embeddings information, which distorts the representation of the embedding in the latent space, resulting in a semantic dilution problem; (b) These models predict the embeddings of the next frames rather than the frames themselves, but the loss function based on the errors of the reconstructed frames, not the predicted embeddings -- this creates a discrepancy between the training objective and the model output. We propose a Semantic Concentration Multi-Head Self-Attention (SCMHSA) architecture, which effectively mitigates semantic dilution in transformer-based next-frame prediction. Additionally, we introduce a loss function that optimizes SCMHSA in the latent space, aligning the training objective more closely with the model output. Our method demonstrates superior performance compared to the original transformer-based predictors.</li>
</ul>

<h3>Title: ITVTON:Virtual Try-On Diffusion Transformer Model Based on Integrated Image and Text</h3>
<ul>
<li><strong>Authors: </strong>Haifeng Ni</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2501.16757">https://arxiv.org/abs/2501.16757</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2501.16757">https://arxiv.org/pdf/2501.16757</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2501.16757]] ITVTON:Virtual Try-On Diffusion Transformer Model Based on Integrated Image and Text(https://arxiv.org/abs/2501.16757)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, transformer</a></li>
<li><strong>Abstract: </strong>Recent advancements in virtual fitting for characters and clothing have leveraged diffusion models to improve the realism of garment fitting. However, challenges remain in handling complex scenes and poses, which can result in unnatural garment fitting and poorly rendered intricate patterns. In this work, we introduce ITVTON, a novel method that enhances clothing-character interactions by combining clothing and character images along spatial channels as inputs, thereby improving fitting accuracy for the inpainting model. Additionally, we incorporate integrated textual descriptions from multiple images to boost the realism of the generated visual effects. To optimize computational efficiency, we limit training to the attention parameters within a single diffusion transformer (Single-DiT) block. To more rigorously address the complexities of real-world scenarios, we curated training samples from the IGPair dataset, thereby enhancing ITVTON's performance across diverse environments. Extensive experiments demonstrate that ITVTON outperforms baseline methods both qualitatively and quantitatively, setting a new standard for virtual fitting tasks.</li>
</ul>

<h3>Title: Meta-Federated Learning: A Novel Approach for Real-Time Traffic Flow Management</h3>
<ul>
<li><strong>Authors: </strong>Bob Johnson, Michael Geller</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.DC, eess.SP</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2501.16758">https://arxiv.org/abs/2501.16758</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2501.16758">https://arxiv.org/pdf/2501.16758</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2501.16758]] Meta-Federated Learning: A Novel Approach for Real-Time Traffic Flow Management(https://arxiv.org/abs/2501.16758)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, federate</a></li>
<li><strong>Abstract: </strong>Efficient management of traffic flow in urban environments presents a significant challenge, exacerbated by dynamic changes and the sheer volume of data generated by modern transportation networks. Traditional centralized traffic management systems often struggle with scalability and privacy concerns, hindering their effectiveness. This paper introduces a novel approach by combining Federated Learning (FL) and Meta-Learning (ML) to create a decentralized, scalable, and adaptive traffic management system. Our approach, termed Meta-Federated Learning, leverages the distributed nature of FL to process data locally at the edge, thereby enhancing privacy and reducing latency. Simultaneously, ML enables the system to quickly adapt to new traffic conditions without the need for extensive retraining. We implement our model across a simulated network of smart traffic devices, demonstrating that Meta-Federated Learning significantly outperforms traditional models in terms of prediction accuracy and response time. Furthermore, our approach shows remarkable adaptability to sudden changes in traffic patterns, suggesting a scalable solution for real-time traffic management in smart cities. This study not only paves the way for more resilient urban traffic systems but also exemplifies the potential of integrated FL and ML in other real-world applications.</li>
</ul>

<h3>Title: AdaSemSeg: An Adaptive Few-shot Semantic Segmentation of Seismic Facies</h3>
<ul>
<li><strong>Authors: </strong>Surojit Saha, Ross Whitaker</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2501.16760">https://arxiv.org/abs/2501.16760</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2501.16760">https://arxiv.org/pdf/2501.16760</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2501.16760]] AdaSemSeg: An Adaptive Few-shot Semantic Segmentation of Seismic Facies(https://arxiv.org/abs/2501.16760)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>Automated interpretation of seismic images using deep learning methods is challenging because of the limited availability of training data. Few-shot learning is a suitable learning paradigm in such scenarios due to its ability to adapt to a new task with limited supervision (small training budget). Existing few-shot semantic segmentation (FSSS) methods fix the number of target classes. Therefore, they do not support joint training on multiple datasets varying in the number of classes. In the context of the interpretation of seismic facies, fixing the number of target classes inhibits the generalization capability of a model trained on one facies dataset to another, which is likely to have a different number of facies. To address this shortcoming, we propose a few-shot semantic segmentation method for interpreting seismic facies that can adapt to the varying number of facies across the dataset, dubbed the AdaSemSeg. In general, the backbone network of FSSS methods is initialized with the statistics learned from the ImageNet dataset for better performance. The lack of such a huge annotated dataset for seismic images motivates using a self-supervised algorithm on seismic datasets to initialize the backbone network. We have trained the AdaSemSeg on three public seismic facies datasets with different numbers of facies and evaluated the proposed method on multiple metrics. The performance of the AdaSemSeg on unseen datasets (not used in training) is better than the prototype-based few-shot method and baselines.</li>
</ul>

<h3>Title: DiffSplat: Repurposing Image Diffusion Models for Scalable Gaussian Splat Generation</h3>
<ul>
<li><strong>Authors: </strong>Chenguo Lin, Panwang Pan, Bangbang Yang, Zeming Li, Yadong Mu</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2501.16764">https://arxiv.org/abs/2501.16764</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2501.16764">https://arxiv.org/pdf/2501.16764</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2501.16764]] DiffSplat: Repurposing Image Diffusion Models for Scalable Gaussian Splat Generation(https://arxiv.org/abs/2501.16764)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, generative</a></li>
<li><strong>Abstract: </strong>Recent advancements in 3D content generation from text or a single image struggle with limited high-quality 3D datasets and inconsistency from 2D multi-view generation. We introduce DiffSplat, a novel 3D generative framework that natively generates 3D Gaussian splats by taming large-scale text-to-image diffusion models. It differs from previous 3D generative models by effectively utilizing web-scale 2D priors while maintaining 3D consistency in a unified model. To bootstrap the training, a lightweight reconstruction model is proposed to instantly produce multi-view Gaussian splat grids for scalable dataset curation. In conjunction with the regular diffusion loss on these grids, a 3D rendering loss is introduced to facilitate 3D coherence across arbitrary views. The compatibility with image diffusion models enables seamless adaptions of numerous techniques for image generation to the 3D realm. Extensive experiments reveal the superiority of DiffSplat in text- and image-conditioned generation tasks and downstream applications. Thorough ablation studies validate the efficacy of each critical design choice and provide insights into the underlying mechanism.</li>
</ul>

<h3>Title: Beyond-Labels: Advancing Open-Vocabulary Segmentation With Vision-Language Models</h3>
<ul>
<li><strong>Authors: </strong>Muhammad Atta ur Rahman</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2501.16769">https://arxiv.org/abs/2501.16769</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2501.16769">https://arxiv.org/pdf/2501.16769</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2501.16769]] Beyond-Labels: Advancing Open-Vocabulary Segmentation With Vision-Language Models(https://arxiv.org/abs/2501.16769)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer, segmentation</a></li>
<li><strong>Abstract: </strong>Self-supervised learning can resolve numerous image or linguistic processing problems when effectively trained. This study investigated simple yet efficient methods for adaping previously learned foundation models for open-vocabulary semantic segmentation tasks. Our research proposed "Beyond-Labels," a lightweight transformer-based fusion module that uses a handful of image segmentation data to fuse frozen image representations with language concepts. Furthermore, we efficiently captured positional information in images using Fourier embeddings, thus improving the generalization across various image sizes. Extensive ablation tests were performed to investigate the important components of our proposed method; when tested against the common benchmark PASCAL-5i, it demonstrated superior performance despite being trained on frozen image and language characteristics.</li>
</ul>

<h3>Title: FlexMotion: Lightweight, Physics-Aware, and Controllable Human Motion Generation</h3>
<ul>
<li><strong>Authors: </strong>Arvin Tashakori, Arash Tashakori, Gongbo Yang, Z. Jane Wang, Peyman Servati</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI, cs.GR, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2501.16778">https://arxiv.org/abs/2501.16778</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2501.16778">https://arxiv.org/pdf/2501.16778</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2501.16778]] FlexMotion: Lightweight, Physics-Aware, and Controllable Human Motion Generation(https://arxiv.org/abs/2501.16778)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, transformer</a></li>
<li><strong>Abstract: </strong>Lightweight, controllable, and physically plausible human motion synthesis is crucial for animation, virtual reality, robotics, and human-computer interaction applications. Existing methods often compromise between computational efficiency, physical realism, or spatial controllability. We propose FlexMotion, a novel framework that leverages a computationally lightweight diffusion model operating in the latent space, eliminating the need for physics simulators and enabling fast and efficient training. FlexMotion employs a multimodal pre-trained Transformer encoder-decoder, integrating joint locations, contact forces, joint actuations and muscle activations to ensure the physical plausibility of the generated motions. FlexMotion also introduces a plug-and-play module, which adds spatial controllability over a range of motion parameters (e.g., joint locations, joint actuations, contact forces, and muscle activations). Our framework achieves realistic motion generation with improved efficiency and control, setting a new benchmark for human motion synthesis. We evaluate FlexMotion on extended datasets and demonstrate its superior performance in terms of realism, physical plausibility, and controllability.</li>
</ul>

<h3>Title: A Stochastic Dynamical Theory of LLM Self-Adversariality: Modeling Severity Drift as a Critical Process</h3>
<ul>
<li><strong>Authors: </strong>Jack David Carson</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, nlin.AO</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2501.16783">https://arxiv.org/abs/2501.16783</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2501.16783">https://arxiv.org/pdf/2501.16783</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2501.16783]] A Stochastic Dynamical Theory of LLM Self-Adversariality: Modeling Severity Drift as a Critical Process(https://arxiv.org/abs/2501.16783)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, large language model</a></li>
<li><strong>Abstract: </strong>This paper introduces a continuous-time stochastic dynamical framework for understanding how large language models (LLMs) may self-amplify latent biases or toxicity through their own chain-of-thought reasoning. The model posits an instantaneous "severity" variable $x(t) \in [0,1]$ evolving under a stochastic differential equation (SDE) with a drift term $\mu(x)$ and diffusion $\sigma(x)$. Crucially, such a process can be consistently analyzed via the Fokker--Planck approach if each incremental step behaves nearly Markovian in severity space. The analysis investigates critical phenomena, showing that certain parameter regimes create phase transitions from subcritical (self-correcting) to supercritical (runaway severity). The paper derives stationary distributions, first-passage times to harmful thresholds, and scaling laws near critical points. Finally, it highlights implications for agents and extended LLM reasoning models: in principle, these equations might serve as a basis for formal verification of whether a model remains stable or propagates bias over repeated inferences.</li>
</ul>

<h3>Title: TORCHLIGHT: Shedding LIGHT on Real-World Attacks on Cloudless IoT Devices Concealed within the Tor Network</h3>
<ul>
<li><strong>Authors: </strong>Yumingzhi Pan, Zhen Ling, Yue Zhang, Hongze Wang, Guangchi Liu, Junzhou Luo, Xinwen Fu</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2501.16784">https://arxiv.org/abs/2501.16784</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2501.16784">https://arxiv.org/pdf/2501.16784</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2501.16784]] TORCHLIGHT: Shedding LIGHT on Real-World Attacks on Cloudless IoT Devices Concealed within the Tor Network(https://arxiv.org/abs/2501.16784)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, attack, large language model</a></li>
<li><strong>Abstract: </strong>The rapidly expanding Internet of Things (IoT) landscape is shifting toward cloudless architectures, removing reliance on centralized cloud services but exposing devices directly to the internet and increasing their vulnerability to cyberattacks. Our research revealed an unexpected pattern of substantial Tor network traffic targeting cloudless IoT devices. suggesting that attackers are using Tor to anonymously exploit undisclosed vulnerabilities (possibly obtained from underground markets). To delve deeper into this phenomenon, we developed TORCHLIGHT, a tool designed to detect both known and unknown threats targeting cloudless IoT devices by analyzing Tor traffic. TORCHLIGHT filters traffic via specific IP patterns, strategically deploys virtual private server (VPS) nodes for cost-effective detection, and uses a chain-of-thought (CoT) process with large language models (LLMs) for accurate threat identification. Our results are significant: for the first time, we have demonstrated that attackers are indeed using Tor to conceal their identities while targeting cloudless IoT devices. Over a period of 12 months, TORCHLIGHT analyzed 26 TB of traffic, revealing 45 vulnerabilities, including 29 zero-day exploits with 25 CVE-IDs assigned (5 CRITICAL, 3 HIGH, 16 MEDIUM, and 1 LOW) and an estimated value of approximately $312,000. These vulnerabilities affect around 12.71 million devices across 148 countries, exposing them to severe risks such as information disclosure, authentication bypass, and arbitrary command execution. The findings have attracted significant attention, sparking widespread discussion in cybersecurity circles, reaching the top 25 on Hacker News, and generating over 190,000 views.</li>
</ul>

<h3>Title: Exploring the Role of Explicit Temporal Modeling in Multimodal Large Language Models for Video Understanding</h3>
<ul>
<li><strong>Authors: </strong>Yun Li, Zhe Liu, Yajing Kong, Guangrui Li, Jiyuan Zhang, Chao Bian, Feng Liu, Lina Yao, Zhenbang Sun</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2501.16786">https://arxiv.org/abs/2501.16786</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2501.16786">https://arxiv.org/pdf/2501.16786</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2501.16786]] Exploring the Role of Explicit Temporal Modeling in Multimodal Large Language Models for Video Understanding(https://arxiv.org/abs/2501.16786)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Applying Multimodal Large Language Models (MLLMs) to video understanding presents significant challenges due to the need to model temporal relations across frames. Existing approaches adopt either implicit temporal modeling, relying solely on the LLM decoder, or explicit temporal modeling, employing auxiliary temporal encoders. To investigate this debate between the two paradigms, we propose the Stackable Temporal Encoder (STE). STE enables flexible explicit temporal modeling with adjustable temporal receptive fields and token compression ratios. Using STE, we systematically compare implicit and explicit temporal modeling across dimensions such as overall performance, token compression effectiveness, and temporal-specific understanding. We also explore STE's design considerations and broader impacts as a plug-in module and in image modalities. Our findings emphasize the critical role of explicit temporal modeling, providing actionable insights to advance video MLLMs.</li>
</ul>

<h3>Title: Algorithm for Automatic Legislative Text Consolidation</h3>
<ul>
<li><strong>Authors: </strong>Matias Etcheverry, Thibaud Real, Pauline Chavallard</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2501.16794">https://arxiv.org/abs/2501.16794</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2501.16794">https://arxiv.org/pdf/2501.16794</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2501.16794]] Algorithm for Automatic Legislative Text Consolidation(https://arxiv.org/abs/2501.16794)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>This study introduces a method for automating the consolidation process in a legal context, a time-consuming task traditionally performed by legal professionals. We present a generative approach that processes legislative texts to automatically apply amendments. Our method employs light quantized generative model, fine-tuned with LoRA, to generate accurate and reliable amended texts. To the authors knowledge, this is the first time generative models are used on legislative text consolidation. Our dataset is publicly available on HuggingFace1. Experimental results demonstrate a significant improvement in efficiency, offering faster updates to legal documents. A full automated pipeline of legislative text consolidation can be done in a few hours, with a success rate of more than 63% on a difficult bill.</li>
</ul>

<h3>Title: Not Every Patch is Needed: Towards a More Efficient and Effective Backbone for Video-based Person Re-identification</h3>
<ul>
<li><strong>Authors: </strong>Lanyun Zhu, Tianrun Chen, Deyi Ji, Jieping Ye, Jun Liu</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2501.16811">https://arxiv.org/abs/2501.16811</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2501.16811">https://arxiv.org/pdf/2501.16811</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2501.16811]] Not Every Patch is Needed: Towards a More Efficient and Effective Backbone for Video-based Person Re-identification(https://arxiv.org/abs/2501.16811)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction, transformer</a></li>
<li><strong>Abstract: </strong>This paper proposes a new effective and efficient plug-and-play backbone for video-based person re-identification (ReID). Conventional video-based ReID methods typically use CNN or transformer backbones to extract deep features for every position in every sampled video frame. Here, we argue that this exhaustive feature extraction could be unnecessary, since we find that different frames in a ReID video often exhibit small differences and contain many similar regions due to the relatively slight movements of human beings. Inspired by this, a more selective, efficient paradigm is explored in this paper. Specifically, we introduce a patch selection mechanism to reduce computational cost by choosing only the crucial and non-repetitive patches for feature extraction. Additionally, we present a novel network structure that generates and utilizes pseudo frame global context to address the issue of incomplete views resulting from sparse inputs. By incorporating these new designs, our backbone can achieve both high performance and low computational cost. Extensive experiments on multiple datasets show that our approach reduces the computational cost by 74\% compared to ViT-B and 28\% compared to ResNet50, while the accuracy is on par with ViT-B and outperforms ResNet50 significantly.</li>
</ul>

<h3>Title: Whispers of Sound-Enhancing Information Extraction from Depression Patients' Unstructured Data through Audio and Text Emotion Recognition and Llama Fine-tuning</h3>
<ul>
<li><strong>Authors: </strong>Lindy Gan, Yifan Huang, Xiaoyang Gao, Jiaming Tan, Fujun Zhao, Tao Yang</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.SD, eess.AS</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2501.16813">https://arxiv.org/abs/2501.16813</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2501.16813">https://arxiv.org/pdf/2501.16813</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2501.16813]] Whispers of Sound-Enhancing Information Extraction from Depression Patients' Unstructured Data through Audio and Text Emotion Recognition and Llama Fine-tuning(https://arxiv.org/abs/2501.16813)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, extraction</a></li>
<li><strong>Abstract: </strong>This study proposes an innovative multimodal fusion model based on a teacher-student architecture to enhance the accuracy of depression classification. Our designed model addresses the limitations of traditional methods in feature fusion and modality weight allocation by introducing multi-head attention mechanisms and weighted multimodal transfer learning. Leveraging the DAIC-WOZ dataset, the student fusion model, guided by textual and auditory teacher models, achieves significant improvements in classification accuracy. Ablation experiments demonstrate that the proposed model attains an F1 score of 99. 1% on the test set, significantly outperforming unimodal and conventional approaches. Our method effectively captures the complementarity between textual and audio features while dynamically adjusting the contributions of the teacher models to enhance generalization capabilities. The experimental results highlight the robustness and adaptability of the proposed framework in handling complex multimodal data. This research provides a novel technical framework for multimodal large model learning in depression analysis, offering new insights into addressing the limitations of existing methods in modality fusion and feature extraction.</li>
</ul>

<h3>Title: Can Transformers Learn Full Bayesian Inference in Context?</h3>
<ul>
<li><strong>Authors: </strong>Arik Reuter, Tim G. J. Rudner, Vincent Fortuin, David Rügamer</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2501.16825">https://arxiv.org/abs/2501.16825</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2501.16825">https://arxiv.org/pdf/2501.16825</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2501.16825]] Can Transformers Learn Full Bayesian Inference in Context?(https://arxiv.org/abs/2501.16825)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Transformers have emerged as the dominant architecture in the field of deep learning, with a broad range of applications and remarkable in-context learning (ICL) capabilities. While not yet fully understood, ICL has already proved to be an intriguing phenomenon, allowing transformers to learn in context -- without requiring further training. In this paper, we further advance the understanding of ICL by demonstrating that transformers can perform full Bayesian inference for commonly used statistical models in context. More specifically, we introduce a general framework that builds on ideas from prior fitted networks and continuous normalizing flows which enables us to infer complex posterior distributions for methods such as generalized linear models and latent factor models. Extensive experiments on real-world datasets demonstrate that our ICL approach yields posterior samples that are similar in quality to state-of-the-art MCMC or variational inference methods not operating in context.</li>
</ul>

<h3>Title: Data-Driven vs Traditional Approaches to Power Transformer's Top-Oil Temperature Estimation</h3>
<ul>
<li><strong>Authors: </strong>Francis Tembo, Federica Bragone, Tor Laneryd, Matthieu Barreau, Kateryna Morozovska</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2501.16831">https://arxiv.org/abs/2501.16831</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2501.16831">https://arxiv.org/pdf/2501.16831</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2501.16831]] Data-Driven vs Traditional Approaches to Power Transformer's Top-Oil Temperature Estimation(https://arxiv.org/abs/2501.16831)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Power transformers are subjected to electrical currents and temperature fluctuations that, if not properly controlled, can lead to major deterioration of their insulation system. Therefore, monitoring the temperature of a power transformer is fundamental to ensure a long-term operational life. Models presented in the IEC 60076-7 and IEEE standards, for example, monitor the temperature by calculating the top-oil and the hot-spot temperatures. However, these models are not very accurate and rely on the power transformers' properties. This paper focuses on finding an alternative method to predict the top-oil temperatures given previous measurements. Given the large quantities of data available, machine learning methods for time series forecasting are analyzed and compared to the real measurements and the corresponding prediction of the IEC standard. The methods tested are Artificial Neural Networks (ANNs), Time-series Dense Encoder (TiDE), and Temporal Convolutional Networks (TCN) using different combinations of historical measurements. Each of these methods outperformed the IEC 60076-7 model and they are extended to estimate the temperature rise over ambient. To enhance prediction reliability, we explore the application of quantile regression to construct prediction intervals for the expected top-oil temperature ranges. The best-performing model successfully estimates conditional quantiles that provide sufficient coverage.</li>
</ul>

<h3>Title: Misspellings in Natural Language Processing: A survey</h3>
<ul>
<li><strong>Authors: </strong>Gianluca Sperduti, Alejandro Moreo</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2501.16836">https://arxiv.org/abs/2501.16836</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2501.16836">https://arxiv.org/pdf/2501.16836</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2501.16836]] Misspellings in Natural Language Processing: A survey(https://arxiv.org/abs/2501.16836)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>This survey provides an overview of the challenges of misspellings in natural language processing (NLP). While often unintentional, misspellings have become ubiquitous in digital communication, especially with the proliferation of Web 2.0, user-generated content, and informal text mediums such as social media, blogs, and forums. Even if humans can generally interpret misspelled text, NLP models frequently struggle to handle it: this causes a decline in performance in common tasks like text classification and machine translation. In this paper, we reconstruct a history of misspellings as a scientific problem. We then discuss the latest advancements to address the challenge of misspellings in NLP. Main strategies to mitigate the effect of misspellings include data augmentation, double step, character-order agnostic, and tuple-based methods, among others. This survey also examines dedicated data challenges and competitions to spur progress in the field. Critical safety and ethical concerns are also examined, for example, the voluntary use of misspellings to inject malicious messages and hate speech on social networks. Furthermore, the survey explores psycholinguistic perspectives on how humans process misspellings, potentially informing innovative computational techniques for text normalization and representation. Finally, the misspelling-related challenges and opportunities associated with modern large language models are also analyzed, including benchmarks, datasets, and performances of the most prominent language models against misspellings. This survey aims to be an exhaustive resource for researchers seeking to mitigate the impact of misspellings in the rapidly evolving landscape of NLP.</li>
</ul>

<h3>Title: Flow Matching: Markov Kernels, Stochastic Processes and Transport Plans</h3>
<ul>
<li><strong>Authors: </strong>Christian Wald, Gabriele Steidl</a></li>
<li><strong>Subjects: </strong>cs.LG, math.PR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2501.16839">https://arxiv.org/abs/2501.16839</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2501.16839">https://arxiv.org/pdf/2501.16839</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2501.16839]] Flow Matching: Markov Kernels, Stochastic Processes and Transport Plans(https://arxiv.org/abs/2501.16839)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>Among generative neural models, flow matching techniques stand out for their simple applicability and good scaling properties. Here, velocity fields of curves connecting a simple latent and a target distribution are learned. Then the corresponding ordinary differential equation can be used to sample from a target distribution, starting in samples from the latent one. This paper reviews from a mathematical point of view different techniques to learn the velocity fields of absolutely continuous curves in the Wasserstein geometry. We show how the velocity fields can be characterized and learned via i) transport plans (couplings) between latent and target distributions, ii) Markov kernels and iii) stochastic processes, where the latter two include the coupling approach, but are in general broader. Besides this main goal, we show how flow matching can be used for solving Bayesian inverse problems, where the definition of conditional Wasserstein distances plays a central role. Finally, we briefly address continuous normalizing flows and score matching techniques, which approach the learning of velocity fields of curves from other directions.</li>
</ul>

<h3>Title: Bones of Contention: Exploring Query-Efficient Attacks Against Skeleton Recognition Systems</h3>
<ul>
<li><strong>Authors: </strong>Yuxin Cao, Kai Ye, Derui Wang, Minhui Xue, Hao Ge, Chenxiong Qian, Jin Song Dong</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2501.16843">https://arxiv.org/abs/2501.16843</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2501.16843">https://arxiv.org/pdf/2501.16843</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2501.16843]] Bones of Contention: Exploring Query-Efficient Attacks Against Skeleton Recognition Systems(https://arxiv.org/abs/2501.16843)</code><input type="text"></li>
<li><strong>Keywords: </strong>secure, privacy, defense, attack, robust</a></li>
<li><strong>Abstract: </strong>Skeleton action recognition models have secured more attention than video-based ones in various applications due to privacy preservation and lower storage requirements. Skeleton data are typically transmitted to cloud servers for action recognition, with results returned to clients via Apps/APIs. However, the vulnerability of skeletal models against adversarial perturbations gradually reveals the unreliability of these systems. Existing black-box attacks all operate in a decision-based manner, resulting in numerous queries that hinder efficiency and feasibility in real-world applications. Moreover, all attacks off the shelf focus on only restricted perturbations, while ignoring model weaknesses when encountered with non-semantic perturbations. In this paper, we propose two query-effIcient Skeletal Adversarial AttaCks, ISAAC-K and ISAAC-N. As a black-box attack, ISAAC-K utilizes Grad-CAM in a surrogate model to extract key joints where minor sparse perturbations are then added to fool the classifier. To guarantee natural adversarial motions, we introduce constraints of both bone length and temporal consistency. ISAAC-K finds stronger adversarial examples on $\ell_\infty$ norm, which can encompass those on other norms. Exhaustive experiments substantiate that ISAAC-K can uplift the attack efficiency of the perturbations under 10 skeletal models. Additionally, as a byproduct, ISAAC-N fools the classifier by replacing skeletons unrelated to the action. We surprisingly find that skeletal models are vulnerable to large perturbations where the part-wise non-semantic joints are just replaced, leading to a query-free no-box attack without any prior knowledge. Based on that, four adaptive defenses are eventually proposed to improve the robustness of skeleton recognition models.</li>
</ul>

<h3>Title: Hybrid Phenology Modeling for Predicting Temperature Effects on Tree Dormancy</h3>
<ul>
<li><strong>Authors: </strong>Ron van Bree, Diego Marcos, Ioannis Athanasiadis</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2501.16848">https://arxiv.org/abs/2501.16848</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2501.16848">https://arxiv.org/pdf/2501.16848</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2501.16848]] Hybrid Phenology Modeling for Predicting Temperature Effects on Tree Dormancy(https://arxiv.org/abs/2501.16848)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, interpretability</a></li>
<li><strong>Abstract: </strong>Biophysical models offer valuable insights into climate-phenology relationships in both natural and agricultural settings. However, there are substantial structural discrepancies across models which require site-specific recalibration, often yielding inconsistent predictions under similar climate scenarios. Machine learning methods offer data-driven solutions, but often lack interpretability and alignment with existing knowledge. We present a phenology model describing dormancy in fruit trees, integrating conventional biophysical models with a neural network to address their structural disparities. We evaluate our hybrid model in an extensive case study predicting cherry tree phenology in Japan, South Korea and Switzerland. Our approach consistently outperforms both traditional biophysical and machine learning models in predicting blooming dates across years. Additionally, the neural network's adaptability facilitates parameter learning for specific tree varieties, enabling robust generalization to new sites without site-specific recalibration. This hybrid model leverages both biophysical constraints and data-driven flexibility, offering a promising avenue for accurate and interpretable phenology modeling.</li>
</ul>

<h3>Title: Irony Detection, Reasoning and Understanding in Zero-shot Learning</h3>
<ul>
<li><strong>Authors: </strong>Peiling Yi, Yuhan Xia</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2501.16884">https://arxiv.org/abs/2501.16884</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2501.16884">https://arxiv.org/pdf/2501.16884</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2501.16884]] Irony Detection, Reasoning and Understanding in Zero-shot Learning(https://arxiv.org/abs/2501.16884)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Irony is a powerful figurative language (FL) on social media that can potentially mislead various NLP tasks, such as recommendation systems, misinformation checks, and sentiment analysis. Understanding the implicit meaning of this kind of subtle language is essential to mitigate irony's negative impact on NLP tasks. However, building models to understand irony presents a unique set of challenges, because irony is a complex form of language that often relies on context, tone, and subtle cues to convey meaning that is opposite or different from the literal interpretation. Large language models, such as ChatGPT, are increasingly able to capture implicit and contextual information. In this study, we investigate the generalization, reasoning and understanding ability of ChatGPT on irony detection across six different genre irony detection datasets. Our findings suggest that ChatGPT appears to show an enhanced language understanding and reasoning ability. But it needs to be very careful in prompt engineering design. Thus, we propose a prompt engineering design framework IDADP to achieve higher irony detection accuracy, improved understanding of irony, and more effective explanations compared to other state-of-the-art ChatGPT zero-shot approaches. And ascertain via experiments that the practice generated under the framework is likely to be the promised solution to resolve the generalization issues of LLMs.</li>
</ul>

<h3>Title: Extending Information Bottleneck Attribution to Video Sequences</h3>
<ul>
<li><strong>Authors: </strong>Veronika Solopova, Lucas Schmidt, Dorothea Kolossa</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2501.16889">https://arxiv.org/abs/2501.16889</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2501.16889">https://arxiv.org/pdf/2501.16889</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2501.16889]] Extending Information Bottleneck Attribution to Video Sequences(https://arxiv.org/abs/2501.16889)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability, explainability</a></li>
<li><strong>Abstract: </strong>We introduce VIBA, a novel approach for explainable video classification by adapting Information Bottlenecks for Attribution (IBA) to video sequences. While most traditional explainability methods are designed for image models, our IBA framework addresses the need for explainability in temporal models used for video analysis. To demonstrate its effectiveness, we apply VIBA to video deepfake detection, testing it on two architectures: the Xception model for spatial features and a VGG11-based model for capturing motion dynamics through optical flow. Using a custom dataset that reflects recent deepfake generation techniques, we adapt IBA to create relevance and optical flow maps, visually highlighting manipulated regions and motion inconsistencies. Our results show that VIBA generates temporally and spatially consistent explanations, which align closely with human annotations, thus providing interpretability for video classification and particularly for deepfake detection.</li>
</ul>

<h3>Title: RAINER: A Robust Ensemble Learning Grid Search-Tuned Framework for Rainfall Patterns Prediction</h3>
<ul>
<li><strong>Authors: </strong>Zhenqi Li, Junhao Zhong, Hewei Wang, Jinfeng Xu, Yijie Li, Jinjiang You, Jiayi Zhang, Runzhi Wu, Soumyabrata Dev</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2501.16900">https://arxiv.org/abs/2501.16900</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2501.16900">https://arxiv.org/pdf/2501.16900</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2501.16900]] RAINER: A Robust Ensemble Learning Grid Search-Tuned Framework for Rainfall Patterns Prediction(https://arxiv.org/abs/2501.16900)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Rainfall prediction remains a persistent challenge due to the highly nonlinear and complex nature of meteorological data. Existing approaches lack systematic utilization of grid search for optimal hyperparameter tuning, relying instead on heuristic or manual selection, frequently resulting in sub-optimal results. Additionally, these methods rarely incorporate newly constructed meteorological features such as differences between temperature and humidity to capture critical weather dynamics. Furthermore, there is a lack of systematic evaluation of ensemble learning techniques and limited exploration of diverse advanced models introduced in the past one or two years. To address these limitations, we propose a robust ensemble learning grid search-tuned framework (RAINER) for rainfall prediction. RAINER incorporates a comprehensive feature engineering pipeline, including outlier removal, imputation of missing values, feature reconstruction, and dimensionality reduction via Principal Component Analysis (PCA). The framework integrates novel meteorological features to capture dynamic weather patterns and systematically evaluates non-learning mathematical-based methods and a variety of machine learning models, from weak classifiers to advanced neural networks such as Kolmogorov-Arnold Networks (KAN). By leveraging grid search for hyperparameter tuning and ensemble voting techniques, RAINER achieves promising results within real-world datasets.</li>
</ul>

<h3>Title: Adversarial Masked Autoencoder Purifier with Defense Transferability</h3>
<ul>
<li><strong>Authors: </strong>Yuan-Chih Chen, Chun-Shien Lu</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2501.16904">https://arxiv.org/abs/2501.16904</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2501.16904">https://arxiv.org/pdf/2501.16904</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2501.16904]] Adversarial Masked Autoencoder Purifier with Defense Transferability(https://arxiv.org/abs/2501.16904)</code><input type="text"></li>
<li><strong>Keywords: </strong>defense, attack, robust, diffusion</a></li>
<li><strong>Abstract: </strong>The study of adversarial defense still struggles to combat with advanced adversarial attacks. In contrast to most prior studies that rely on the diffusion model for test-time defense to remarkably increase the inference time, we propose Masked AutoEncoder Purifier (MAEP), which integrates Masked AutoEncoder (MAE) into an adversarial purifier framework for test-time purification. While MAEP achieves promising adversarial robustness, it particularly features model defense transferability and attack generalization without relying on using additional data that is different from the training dataset. To our knowledge, MAEP is the first study of adversarial purifier based on MAE. Extensive experimental results demonstrate that our method can not only maintain clear accuracy with only a slight drop but also exhibit a close gap between the clean and robust accuracy. Notably, MAEP trained on CIFAR10 achieves state-of-the-art performance even when tested directly on ImageNet, outperforming existing diffusion-based models trained specifically on ImageNet.</li>
</ul>

<h3>Title: Detecting harassment and defamation in cyberbullying with emotion-adaptive training</h3>
<ul>
<li><strong>Authors: </strong>Peiling Yi, Arkaitz Zubiaga, Yunfei Long</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2501.16925">https://arxiv.org/abs/2501.16925</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2501.16925">https://arxiv.org/pdf/2501.16925</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2501.16925]] Detecting harassment and defamation in cyberbullying with emotion-adaptive training(https://arxiv.org/abs/2501.16925)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer, large language model</a></li>
<li><strong>Abstract: </strong>Existing research on detecting cyberbullying incidents on social media has primarily concentrated on harassment and is typically approached as a binary classification task. However, cyberbullying encompasses various forms, such as denigration and harassment, which celebrities frequently face. Furthermore, suitable training data for these diverse forms of cyberbullying remains scarce. In this study, we first develop a celebrity cyberbullying dataset that encompasses two distinct types of incidents: harassment and defamation. We investigate various types of transformer-based models, namely masked (RoBERTa, Bert and DistilBert), replacing(Electra), autoregressive (XLnet), masked&permuted (Mpnet), text-text (T5) and large language models (Llama2 and Llama3) under low source settings. We find that they perform competitively on explicit harassment binary detection. However, their performance is substantially lower on harassment and denigration multi-classification tasks. Therefore, we propose an emotion-adaptive training framework (EAT) that helps transfer knowledge from the domain of emotion detection to the domain of cyberbullying detection to help detect indirect cyberbullying events. EAT consistently improves the average macro F1, precision and recall by 20% in cyberbullying detection tasks across nine transformer-based models under low-resource settings. Our claims are supported by intuitive theoretical insights and extensive experiments.</li>
</ul>

<h3>Title: Quantifying Uncertainty and Variability in Machine Learning: Confidence Intervals for Quantiles in Performance Metric Distributions</h3>
<ul>
<li><strong>Authors: </strong>Christoph Lehmann, Yahor Paromau</a></li>
<li><strong>Subjects: </strong>cs.LG, stat.AP</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2501.16931">https://arxiv.org/abs/2501.16931</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2501.16931">https://arxiv.org/pdf/2501.16931</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2501.16931]] Quantifying Uncertainty and Variability in Machine Learning: Confidence Intervals for Quantiles in Performance Metric Distributions(https://arxiv.org/abs/2501.16931)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Machine learning models are widely used in applications where reliability and robustness are critical. Model evaluation often relies on single-point estimates of performance metrics such as accuracy, F1 score, or mean squared error, that fail to capture the inherent variability in model performance. This variability arises from multiple sources, including train-test split, weights initialization, and hyperparameter tuning. Investigating the characteristics of performance metric distributions, rather than focusing on a single point only, is essential for informed decision-making during model selection and optimization, especially in high-stakes settings. How does the performance metric vary due to intrinsic uncertainty in the selected modeling approach? For example, train-test split is modified, initial weights for optimization are modified or hyperparameter tuning is done using an algorithm with probabilistic nature? This is shifting the focus from identifying a single best model to understanding a distribution of the performance metric that captures variability across different training conditions. By running multiple experiments with varied settings, empirical distributions of performance metrics can be generated. Analyzing these distributions can lead to more robust models that generalize well across diverse scenarios. This contribution explores the use of quantiles and confidence intervals to analyze such distributions, providing a more complete understanding of model performance and its uncertainty. Aimed at a statistically interested audience within the machine learning community, the suggested approaches are easy to implement and apply to various performance metrics for classification and regression problems. Given the often long training times in ML, particular attention is given to small sample sizes (in the order of 10-25).</li>
</ul>

<h3>Title: Exact Computation of Any-Order Shapley Interactions for Graph Neural Networks</h3>
<ul>
<li><strong>Authors: </strong>Fabian Fumagalli, Maximilian Muschalik, Paolo Frazzetto, Janine Strotherm, Luca Hermes, Alessandro Sperduti, Eyke Hüllermeier, Barbara Hammer</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2501.16944">https://arxiv.org/abs/2501.16944</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2501.16944">https://arxiv.org/pdf/2501.16944</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2501.16944]] Exact Computation of Any-Order Shapley Interactions for Graph Neural Networks(https://arxiv.org/abs/2501.16944)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability</a></li>
<li><strong>Abstract: </strong>Albeit the ubiquitous use of Graph Neural Networks (GNNs) in machine learning (ML) prediction tasks involving graph-structured data, their interpretability remains challenging. In explainable artificial intelligence (XAI), the Shapley Value (SV) is the predominant method to quantify contributions of individual features to a ML model's output. Addressing the limitations of SVs in complex prediction models, Shapley Interactions (SIs) extend the SV to groups of features. In this work, we explain single graph predictions of GNNs with SIs that quantify node contributions and interactions among multiple nodes. By exploiting the GNN architecture, we show that the structure of interactions in node embeddings are preserved for graph prediction. As a result, the exponential complexity of SIs depends only on the receptive fields, i.e. the message-passing ranges determined by the connectivity of the graph and the number of convolutional layers. Based on our theoretical results, we introduce GraphSHAP-IQ, an efficient approach to compute any-order SIs exactly. GraphSHAP-IQ is applicable to popular message passing techniques in conjunction with a linear global pooling and output layer. We showcase that GraphSHAP-IQ substantially reduces the exponential complexity of computing exact SIs on multiple benchmark datasets. Beyond exact computation, we evaluate GraphSHAP-IQ's approximation of SIs on popular GNN architectures and compare with existing baselines. Lastly, we visualize SIs of real-world water distribution networks and molecule structures using a SI-Graph.</li>
</ul>

<h3>Title: ToolFactory: Automating Tool Generation by Leveraging LLM to Understand REST API Documentations</h3>
<ul>
<li><strong>Authors: </strong>Xinyi Ni (1), Qiuyang Wang (1), Yukun Zhang (1), Pengyu Hong (1) ((1) Brandeis University)</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CL, cs.SE</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2501.16945">https://arxiv.org/abs/2501.16945</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2501.16945">https://arxiv.org/pdf/2501.16945</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2501.16945]] ToolFactory: Automating Tool Generation by Leveraging LLM to Understand REST API Documentations(https://arxiv.org/abs/2501.16945)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction</a></li>
<li><strong>Abstract: </strong>LLM-based tool agents offer natural language interfaces, enabling users to seamlessly interact with computing services. While REST APIs are valuable resources for building such agents, they must first be transformed into AI-compatible tools. Automatically generating AI-compatible tools from REST API documents can greatly streamline tool agent development and minimize user learning curves. However, API documentation often suffers from a lack of standardization, inconsistent schemas, and incomplete information. To address these issues, we developed \textbf{ToolFactory}, an open-source pipeline for automating tool generation from unstructured API documents. To enhance the reliability of the developed tools, we implemented an evaluation method to diagnose errors. Furthermore, we built a knowledge base of verified tools, which we leveraged to infer missing information from poorly documented APIs. We developed the API Extraction Benchmark, comprising 167 API documents and 744 endpoints in various formats, and designed a JSON schema to annotate them. This annotated dataset was utilized to train and validate ToolFactory. The experimental results highlight the effectiveness of ToolFactory. We also demonstrated ToolFactory by creating a domain-specific AI agent for glycomaterials research. ToolFactory exhibits significant potential for facilitating the seamless integration of scientific REST APIs into AI workflows.</li>
</ul>

<h3>Title: Stack Overflow Meets Replication: Security Research Amid Evolving Code Snippets (Extended Version)</h3>
<ul>
<li><strong>Authors: </strong>Alfusainey Jallow, Sven Bugiel</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2501.16948">https://arxiv.org/abs/2501.16948</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2501.16948">https://arxiv.org/pdf/2501.16948</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2501.16948]] Stack Overflow Meets Replication: Security Research Amid Evolving Code Snippets (Extended Version)(https://arxiv.org/abs/2501.16948)</code><input type="text"></li>
<li><strong>Keywords: </strong>security</a></li>
<li><strong>Abstract: </strong>We study the impact of Stack Overflow code evolution on the stability of prior research findings derived from Stack Overflow data and provide recommendations for future studies. We systematically reviewed papers published between 2005--2023 to identify key aspects of Stack Overflow that can affect study results, such as the language or context of code snippets. Our analysis reveals that certain aspects are non-stationary over time, which could lead to different conclusions if experiments are repeated at different times. We replicated six studies using a more recent dataset to demonstrate this risk. Our findings show that four papers produced significantly different results than the original findings, preventing the same conclusions from being drawn with a newer dataset version. Consequently, we recommend treating Stack Overflow as a time series data source to provide context for interpreting cross-sectional research conclusions.</li>
</ul>

<h3>Title: Multiple Abstraction Level Retrieve Augment Generation</h3>
<ul>
<li><strong>Authors: </strong>Zheng Zheng (1), Xinyi Ni (1), Pengyu Hong (1) ((1) Brandeis University)</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2501.16952">https://arxiv.org/abs/2501.16952</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2501.16952">https://arxiv.org/pdf/2501.16952</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2501.16952]] Multiple Abstraction Level Retrieve Augment Generation(https://arxiv.org/abs/2501.16952)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>A Retrieval-Augmented Generation (RAG) model powered by a large language model (LLM) provides a faster and more cost-effective solution for adapting to new data and knowledge. It also delivers more specialized responses compared to pre-trained LLMs. However, most existing approaches rely on retrieving prefix-sized chunks as references to support question-answering (Q/A). This approach is often deployed to address information needs at a single level of abstraction, as it struggles to generate answers across multiple levels of abstraction. In an RAG setting, while LLMs can summarize and answer questions effectively when provided with sufficient details, retrieving excessive information often leads to the 'lost in the middle' problem and exceeds token limitations. We propose a novel RAG approach that uses chunks of multiple abstraction levels (MAL), including multi-sentence-level, paragraph-level, section-level, and document-level. The effectiveness of our approach is demonstrated in an under-explored scientific domain of Glycoscience. Compared to traditional single-level RAG approaches, our approach improves AI evaluated answer correctness of Q/A by 25.739\% on Glyco-related papers.</li>
</ul>

<h3>Title: UEFI Memory Forensics: A Framework for UEFI Threat Analysis</h3>
<ul>
<li><strong>Authors: </strong>Kalanit Suzan Segal, Hadar Cochavi Gorelik, Oleg Brodt, Yuval Elbahar, Yuval Elovici, Asaf Shabtai</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2501.16962">https://arxiv.org/abs/2501.16962</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2501.16962">https://arxiv.org/pdf/2501.16962</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2501.16962]] UEFI Memory Forensics: A Framework for UEFI Threat Analysis(https://arxiv.org/abs/2501.16962)</code><input type="text"></li>
<li><strong>Keywords: </strong>security</a></li>
<li><strong>Abstract: </strong>Modern computing systems rely on the Unified Extensible Firmware Interface (UEFI), which has replaced the traditional BIOS as the firmware standard for the modern boot process. Despite the advancements, UEFI is increasingly targeted by threat actors seeking to exploit its execution environment and take advantage of its persistence mechanisms. While some security-related analysis of UEFI components has been performed--primarily via debugging and runtime behavior testing--to the best of our knowledge, no prior study has specifically addressed capturing and analyzing volatile UEFI runtime memory to detect malicious exploitation during the pre-OS phase. This gap in UEFI forensic tools limits the ability to conduct in-depth security analyses in pre-OS environments. Such a gap is especially surprising, given that memory forensics is widely regarded as foundational to modern incident response, reflected by the popularity of above-OS memory analysis frameworks, such as Rekall, Volatility, and MemProcFS. To address the lack of below-OS memory forensics, we introduce a framework for UEFI memory forensics. The proposed framework consists of two primary components: UefiMemDump, a memory acquisition tool, and UEFIDumpAnalysis, an extendable collection of analysis modules capable of detecting malicious activities such as function pointer hooking, inline hooking, and malicious image loading. Our proof-of-concept implementation demonstrates our framework's ability to detect modern UEFI threats, such as ThunderStrike, CosmicStrand, and Glupteba bootkits. By providing an open-source solution, our work enables researchers and practitioners to investigate firmware-level threats, develop additional analysis modules, and advance overall below-OS security through UEFI memory analysis.</li>
</ul>

<h3>Title: Few Edges Are Enough: Few-Shot Network Attack Detection with Graph Neural Networks</h3>
<ul>
<li><strong>Authors: </strong>Tristan Bilot, Nour El Madhoun, Khaldoun Al Agha, Anis Zouaoui</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2501.16964">https://arxiv.org/abs/2501.16964</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2501.16964">https://arxiv.org/pdf/2501.16964</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2501.16964]] Few Edges Are Enough: Few-Shot Network Attack Detection with Graph Neural Networks(https://arxiv.org/abs/2501.16964)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack</a></li>
<li><strong>Abstract: </strong>Detecting cyberattacks using Graph Neural Networks (GNNs) has seen promising results recently. Most of the state-of-the-art models that leverage these techniques require labeled examples, hard to obtain in many real-world scenarios. To address this issue, unsupervised learning and Self-Supervised Learning (SSL) have emerged as interesting approaches to reduce the dependency on labeled data. Nonetheless, these methods tend to yield more anomalous detection algorithms rather than effective attack detection systems. This paper introduces Few Edges Are Enough (FEAE), a GNN-based architecture trained with SSL and Few-Shot Learning (FSL) to better distinguish between false positive anomalies and actual attacks. To maximize the potential of few-shot examples, our model employs a hybrid self-supervised objective that combines the advantages of contrastive-based and reconstruction-based SSL. By leveraging only a minimal number of labeled attack events, represented as attack edges, FEAE achieves competitive performance on two well-known network datasets compared to both supervised and unsupervised methods. Remarkably, our experimental results unveil that employing only 1 malicious event for each attack type in the dataset is sufficient to achieve substantial improvements. FEAE not only outperforms self-supervised GNN baselines but also surpasses some supervised approaches on one of the datasets.</li>
</ul>

<h3>Title: Heterogeneity-aware Personalized Federated Learning via Adaptive Dual-Agent Reinforcement Learning</h3>
<ul>
<li><strong>Authors: </strong>Xi Chen, Qin Li, Haibin Cai, Ting Wang</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2501.16966">https://arxiv.org/abs/2501.16966</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2501.16966">https://arxiv.org/pdf/2501.16966</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2501.16966]] Heterogeneity-aware Personalized Federated Learning via Adaptive Dual-Agent Reinforcement Learning(https://arxiv.org/abs/2501.16966)</code><input type="text"></li>
<li><strong>Keywords: </strong>federate</a></li>
<li><strong>Abstract: </strong>Federated Learning (FL) empowers multiple clients to collaboratively train machine learning models without sharing local data, making it highly applicable in heterogeneous Internet of Things (IoT) environments. However, intrinsic heterogeneity in clients' model architectures and computing capabilities often results in model accuracy loss and the intractable straggler problem, which significantly impairs training effectiveness. To tackle these challenges, this paper proposes a novel Heterogeneity-aware Personalized Federated Learning method, named HAPFL, via multi-level Reinforcement Learning (RL) mechanisms. HAPFL optimizes the training process by incorporating three strategic components: 1) An RL-based heterogeneous model allocation mechanism. The parameter server employs a Proximal Policy Optimization (PPO)-based RL agent to adaptively allocate appropriately sized, differentiated models to clients based on their performance, effectively mitigating performance disparities. 2) An RL-based training intensity adjustment scheme. The parameter server leverages another PPO-based RL agent to dynamically fine-tune the training intensity for each client to further enhance training efficiency and reduce straggling latency. 3) A knowledge distillation-based mutual learning mechanism. Each client deploys both a heterogeneous local model and a homogeneous lightweight model named LiteModel, where these models undergo mutual learning through knowledge distillation. This uniform LiteModel plays a pivotal role in aggregating and sharing global knowledge, significantly enhancing the effectiveness of personalized local training. Experimental results across multiple benchmark datasets demonstrate that HAPFL not only achieves high accuracy but also substantially reduces the overall training time by 20.9%-40.4% and decreases straggling latency by 19.0%-48.0% compared to existing solutions.</li>
</ul>

<h3>Title: RODEO: Robust Outlier Detection via Exposing Adaptive Out-of-Distribution Samples</h3>
<ul>
<li><strong>Authors: </strong>Hossein Mirzaei, Mohammad Jafari, Hamid Reza Dehbashi, Ali Ansari, Sepehr Ghobadi, Masoud Hadi, Arshia Soltani Moakhar, Mohammad Azizmalayeri, Mahdieh Soleymani Baghshah, Mohammad Hossein Rohban</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2501.16971">https://arxiv.org/abs/2501.16971</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2501.16971">https://arxiv.org/pdf/2501.16971</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2501.16971]] RODEO: Robust Outlier Detection via Exposing Adaptive Out-of-Distribution Samples(https://arxiv.org/abs/2501.16971)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>In recent years, there have been significant improvements in various forms of image outlier detection. However, outlier detection performance under adversarial settings lags far behind that in standard settings. This is due to the lack of effective exposure to adversarial scenarios during training, especially on unseen outliers, leading to detection models failing to learn robust features. To bridge this gap, we introduce RODEO, a data-centric approach that generates effective outliers for robust outlier detection. More specifically, we show that incorporating outlier exposure (OE) and adversarial training can be an effective strategy for this purpose, as long as the exposed training outliers meet certain characteristics, including diversity, and both conceptual differentiability and analogy to the inlier samples. We leverage a text-to-image model to achieve this goal. We demonstrate both quantitatively and qualitatively that our adaptive OE method effectively generates ``diverse'' and ``near-distribution'' outliers, leveraging information from both text and image domains. Moreover, our experimental results show that utilizing our synthesized outliers significantly enhances the performance of the outlier detector, particularly in adversarial settings.</li>
</ul>

<h3>Title: Over-Tokenized Transformer: Vocabulary is Generally Worth Scaling</h3>
<ul>
<li><strong>Authors: </strong>Hongzhi Huang, Defa Zhu, Banggu Wu, Yutao Zeng, Ya Wang, Qiyang Min, Xun Zhou</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2501.16975">https://arxiv.org/abs/2501.16975</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2501.16975">https://arxiv.org/pdf/2501.16975</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2501.16975]] Over-Tokenized Transformer: Vocabulary is Generally Worth Scaling(https://arxiv.org/abs/2501.16975)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer, large language model</a></li>
<li><strong>Abstract: </strong>Tokenization is a fundamental component of large language models (LLMs), yet its influence on model scaling and performance is not fully explored. In this paper, we introduce Over-Tokenized Transformers, a novel framework that decouples input and output vocabularies to improve language modeling performance. Specifically, our approach scales up input vocabularies to leverage multi-gram tokens. Through extensive experiments, we uncover a log-linear relationship between input vocabulary size and training loss, demonstrating that larger input vocabularies consistently enhance model performance, regardless of model size. Using a large input vocabulary, we achieve performance comparable to double-sized baselines with no additional cost. Our findings highlight the importance of tokenization in scaling laws and provide practical insight for tokenizer design, paving the way for more efficient and powerful LLMs.</li>
</ul>

<h3>Title: Modulating CNN Features with Pre-Trained ViT Representations for Open-Vocabulary Object Detection</h3>
<ul>
<li><strong>Authors: </strong>Xiangyu Gao, Yu Dai, Benliu Qiu, Hongliang Li</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2501.16981">https://arxiv.org/abs/2501.16981</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2501.16981">https://arxiv.org/pdf/2501.16981</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2501.16981]] Modulating CNN Features with Pre-Trained ViT Representations for Open-Vocabulary Object Detection(https://arxiv.org/abs/2501.16981)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>Owing to large-scale image-text contrastive training, pre-trained vision language model (VLM) like CLIP shows superior open-vocabulary recognition ability. Most existing open-vocabulary object detectors attempt to utilize the pre-trained VLM to attain generative representation. F-ViT uses the pre-trained visual encoder as the backbone network and freezes it during training. However, the frozen backbone doesn't benefit from the labeled data to strengthen the representation. Therefore, we propose a novel two-branch backbone network design, named as ViT-Feature-Modulated Multi-Scale Convolutional network (VMCNet). VMCNet consists of a trainable convolutional branch, a frozen pre-trained ViT branch and a feature modulation module. The trainable CNN branch could be optimized with labeled data while the frozen pre-trained ViT branch could keep the representation ability derived from large-scale pre-training. Then, the proposed feature modulation module could modulate the multi-scale CNN features with the representations from ViT branch. With the proposed mixed structure, detector is more likely to discover novel categories. Evaluated on two popular benchmarks, our method boosts the detection performance on novel category and outperforms the baseline. On OV-COCO, the proposed method achieves 44.3 AP$_{50}^{\mathrm{novel}}$ with ViT-B/16 and 48.5 AP$_{50}^{\mathrm{novel}}$ with ViT-L/14. On OV-LVIS, VMCNet with ViT-B/16 and ViT-L/14 reaches 27.8 and 38.4 mAP$_{r}$.</li>
</ul>

<h3>Title: FedEFM: Federated Endovascular Foundation Model with Unseen Data</h3>
<ul>
<li><strong>Authors: </strong>Tuong Do, Nghia Vu, Tudor Jianu, Baoru Huang, Minh Vu, Jionglong Su, Erman Tjiputra, Quang D. Tran, Te-Chuan Chiu, Anh Nguyen</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2501.16992">https://arxiv.org/abs/2501.16992</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2501.16992">https://arxiv.org/pdf/2501.16992</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2501.16992]] FedEFM: Federated Endovascular Foundation Model with Unseen Data(https://arxiv.org/abs/2501.16992)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, federate</a></li>
<li><strong>Abstract: </strong>In endovascular surgery, the precise identification of catheters and guidewires in X-ray images is essential for reducing intervention risks. However, accurately segmenting catheter and guidewire structures is challenging due to the limited availability of labeled data. Foundation models offer a promising solution by enabling the collection of similar domain data to train models whose weights can be fine-tuned for downstream tasks. Nonetheless, large-scale data collection for training is constrained by the necessity of maintaining patient privacy. This paper proposes a new method to train a foundation model in a decentralized federated learning setting for endovascular intervention. To ensure the feasibility of the training, we tackle the unseen data issue using differentiable Earth Mover's Distance within a knowledge distillation framework. Once trained, our foundation model's weights provide valuable initialization for downstream tasks, thereby enhancing task-specific performance. Intensive experiments show that our approach achieves new state-of-the-art results, contributing to advancements in endovascular intervention and robotic-assisted endovascular surgery, while addressing the critical issue of data sharing in the medical domain.</li>
</ul>

<h3>Title: MAUCell: An Adaptive Multi-Attention Framework for Video Frame Prediction</h3>
<ul>
<li><strong>Authors: </strong>Shreyam Gupta (1), P. Agrawal (2), Priyam Gupta (3) ((1) Indian Institute of Technology (BHU), Varanasi, India, (2) University of Colorado, Boulder, USA, (3) Intelligent Field Robotic Systems (IFROS), University of Girona, Spain)</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.LG, cs.RO</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2501.16997">https://arxiv.org/abs/2501.16997</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2501.16997">https://arxiv.org/pdf/2501.16997</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2501.16997]] MAUCell: An Adaptive Multi-Attention Framework for Video Frame Prediction(https://arxiv.org/abs/2501.16997)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>Temporal sequence modeling stands as the fundamental foundation for video prediction systems and real-time forecasting operations as well as anomaly detection applications. The achievement of accurate predictions through efficient resource consumption remains an ongoing issue in contemporary temporal sequence modeling. We introduce the Multi-Attention Unit (MAUCell) which combines Generative Adversarial Networks (GANs) and spatio-temporal attention mechanisms to improve video frame prediction capabilities. Our approach implements three types of attention models to capture intricate motion sequences. A dynamic combination of these attention outputs allows the model to reach both advanced decision accuracy along with superior quality while remaining computationally efficient. The integration of GAN elements makes generated frames appear more true to life therefore the framework creates output sequences which mimic real-world footage. The new design system maintains equilibrium between temporal continuity and spatial accuracy to deliver reliable video prediction. Through a comprehensive evaluation methodology which merged the perceptual LPIPS measurement together with classic tests MSE, MAE, SSIM and PSNR exhibited enhancing capabilities than contemporary approaches based on direct benchmark tests of Moving MNIST, KTH Action, and CASIA-B (Preprocessed) datasets. Our examination indicates that MAUCell shows promise for operational time requirements. The research findings demonstrate how GANs work best with attention mechanisms to create better applications for predicting video sequences.</li>
</ul>

<h3>Title: Challenges in Ensuring AI Safety in DeepSeek-R1 Models: The Shortcomings of Reinforcement Learning Strategies</h3>
<ul>
<li><strong>Authors: </strong>Manojkumar Parmar, Yuvaraj Govindarajulu</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CL, cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2501.17030">https://arxiv.org/abs/2501.17030</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2501.17030">https://arxiv.org/pdf/2501.17030</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2501.17030]] Challenges in Ensuring AI Safety in DeepSeek-R1 Models: The Shortcomings of Reinforcement Learning Strategies(https://arxiv.org/abs/2501.17030)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, large language model</a></li>
<li><strong>Abstract: </strong>Large Language Models (LLMs) have achieved remarkable progress in reasoning, alignment, and task-specific performance. However, ensuring harmlessness in these systems remains a critical challenge, particularly in advanced models like DeepSeek-R1. This paper examines the limitations of Reinforcement Learning (RL) as the primary approach for reducing harmful outputs in DeepSeek-R1 and compares it with Supervised Fine-Tuning (SFT). While RL improves reasoning capabilities, it faces challenges such as reward hacking, generalization failures, language mixing, and high computational costs. We propose hybrid training approaches combining RL and SFT to achieve robust harmlessness reduction. Usage recommendations and future directions for deploying DeepSeek-R1 responsibly are also presented.</li>
</ul>

<h3>Title: Synthesizing 3D Abstractions by Inverting Procedural Buildings with Transformers</h3>
<ul>
<li><strong>Authors: </strong>Max Dax, Jordi Berbel, Jan Stria, Leonidas Guibas, Urs Bergmann</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2501.17044">https://arxiv.org/abs/2501.17044</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2501.17044">https://arxiv.org/pdf/2501.17044</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2501.17044]] Synthesizing 3D Abstractions by Inverting Procedural Buildings with Transformers(https://arxiv.org/abs/2501.17044)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>We generate abstractions of buildings, reflecting the essential aspects of their geometry and structure, by learning to invert procedural models. We first build a dataset of abstract procedural building models paired with simulated point clouds and then learn the inverse mapping through a transformer. Given a point cloud, the trained transformer then infers the corresponding abstracted building in terms of a programmatic language description. This approach leverages expressive procedural models developed for gaming and animation, and thereby retains desirable properties such as efficient rendering of the inferred abstractions and strong priors for regularity and symmetry. Our approach achieves good reconstruction accuracy in terms of geometry and structure, as well as structurally consistent inpainting.</li>
</ul>

<h3>Title: Contextual Self-paced Learning for Weakly Supervised Spatio-Temporal Video Grounding</h3>
<ul>
<li><strong>Authors: </strong>Akash Kumar, Zsolt Kira, Yogesh Singh Rawat</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2501.17053">https://arxiv.org/abs/2501.17053</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2501.17053">https://arxiv.org/pdf/2501.17053</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2501.17053]] Contextual Self-paced Learning for Weakly Supervised Spatio-Temporal Video Grounding(https://arxiv.org/abs/2501.17053)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>In this work, we focus on Weakly Supervised Spatio-Temporal Video Grounding (WSTVG). It is a multimodal task aimed at localizing specific subjects spatio-temporally based on textual queries without bounding box supervision. Motivated by recent advancements in multi-modal foundation models for grounding tasks, we first explore the potential of state-of-the-art object detection models for WSTVG. Despite their robust zero-shot capabilities, our adaptation reveals significant limitations, including inconsistent temporal predictions, inadequate understanding of complex queries, and challenges in adapting to difficult scenarios. We propose CoSPaL (Contextual Self-Paced Learning), a novel approach which is designed to overcome these limitations. CoSPaL integrates three core components: (1) Tubelet Phrase Grounding (TPG), which introduces spatio-temporal prediction by linking textual queries to tubelets; (2) Contextual Referral Grounding (CRG), which improves comprehension of complex queries by extracting contextual information to refine object identification over time; and (3) Self-Paced Scene Understanding (SPS), a training paradigm that progressively increases task difficulty, enabling the model to adapt to complex scenarios by transitioning from coarse to fine-grained understanding.</li>
</ul>

<h3>Title: Context is Key in Agent Security</h3>
<ul>
<li><strong>Authors: </strong>Lillian Tsai, Eugene Bagdasarian</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.CL, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2501.17070">https://arxiv.org/abs/2501.17070</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2501.17070">https://arxiv.org/pdf/2501.17070</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2501.17070]] Context is Key in Agent Security(https://arxiv.org/abs/2501.17070)</code><input type="text"></li>
<li><strong>Keywords: </strong>security</a></li>
<li><strong>Abstract: </strong>Judging the safety of an action, whether taken by a human or a system, must take into account the context in which the action takes place. Deleting an email from user's mailbox may or may not be appropriate depending on email's content, user's goals, or even available space. Systems today that make these judgements -- providing security against harmful or inappropriate actions -- rely on manually-crafted policies or user confirmation for each relevant context. With the upcoming deployment of systems like generalist agents, we argue that we must rethink security designs to adapt to the scale of contexts and capabilities of these systems. As a first step, this paper explores contextual security in the domain of agents and proposes contextual security for agents (Conseca), a framework to generate just-in-time, contextual, and human-verifiable security policies.</li>
</ul>

<h3>Title: Induced Modularity and Community Detection for Functionally Interpretable Reinforcement Learning</h3>
<ul>
<li><strong>Authors: </strong>Anna Soligo, Pietro Ferraro, David Boyle</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2501.17077">https://arxiv.org/abs/2501.17077</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2501.17077">https://arxiv.org/pdf/2501.17077</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2501.17077]] Induced Modularity and Community Detection for Functionally Interpretable Reinforcement Learning(https://arxiv.org/abs/2501.17077)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, fair, interpretability</a></li>
<li><strong>Abstract: </strong>Interpretability in reinforcement learning is crucial for ensuring AI systems align with human values and fulfill the diverse related requirements including safety, robustness and fairness. Building on recent approaches to encouraging sparsity and locality in neural networks, we demonstrate how the penalisation of non-local weights leads to the emergence of functionally independent modules in the policy network of a reinforcement learning agent. To illustrate this, we demonstrate the emergence of two parallel modules for assessment of movement along the X and Y axes in a stochastic Minigrid environment. Through the novel application of community detection algorithms, we show how these modules can be automatically identified and their functional roles verified through direct intervention on the network weights prior to inference. This establishes a scalable framework for reinforcement learning interpretability through functional modularity, addressing challenges regarding the trade-off between completeness and cognitive tractability of reinforcement learning explanations.</li>
</ul>

<h3>Title: Graph Transformers for inverse physics: reconstructing flows around arbitrary 2D airfoils</h3>
<ul>
<li><strong>Authors: </strong>Gregory Duthé, Imad Abdallah, Eleni Chatzi</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CE</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2501.17081">https://arxiv.org/abs/2501.17081</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2501.17081">https://arxiv.org/pdf/2501.17081</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2501.17081]] Graph Transformers for inverse physics: reconstructing flows around arbitrary 2D airfoils(https://arxiv.org/abs/2501.17081)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, transformer</a></li>
<li><strong>Abstract: </strong>We introduce a Graph Transformer framework that serves as a general inverse physics engine on meshes, demonstrated through the challenging task of reconstructing aerodynamic flow fields from sparse surface measurements. While deep learning has shown promising results in forward physics simulation, inverse problems remain particularly challenging due to their ill-posed nature and the difficulty of propagating information from limited boundary observations. Our approach addresses these challenges by combining the geometric expressiveness of message-passing neural networks with the global reasoning of Transformers, enabling efficient learning of inverse mappings from boundary conditions to complete states. We evaluate this framework on a comprehensive dataset of steady-state RANS simulations around diverse airfoil geometries, where the task is to reconstruct full pressure and velocity fields from surface pressure measurements alone. The architecture achieves high reconstruction accuracy while maintaining fast inference times. We conduct experiments and provide insights into the relative importance of local geometric processing and global attention mechanisms in mesh-based inverse problems. We also find that the framework is robust to reduced sensor coverage. These results suggest that Graph Transformers can serve as effective inverse physics engines across a broader range of applications where complete system states must be reconstructed from limited boundary observations.</li>
</ul>

<h3>Title: Token-by-Token Regeneration and Domain Biases: A Benchmark of LLMs on Advanced Mathematical Problem-Solving</h3>
<ul>
<li><strong>Authors: </strong>Evgenii Evstafev</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2501.17084">https://arxiv.org/abs/2501.17084</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2501.17084">https://arxiv.org/pdf/2501.17084</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2501.17084]] Token-by-Token Regeneration and Domain Biases: A Benchmark of LLMs on Advanced Mathematical Problem-Solving(https://arxiv.org/abs/2501.17084)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large language models (LLMs) excel in many natural language tasks, yet they struggle with complex mathemat-ical problem-solving, particularly in symbolic reasoning and maintaining consistent output. This study evalu-ates 10 LLMs with 7 to 8 billion parameters using 945 competition-level problems from the MATH dataset. The focus is on their ability to generate executable Python code as a step in their reasoning process, involving over 9,450 code executions. The research introduces an evaluation framework using mistral-large-2411 to rate answers on a 5-point scale, which helps address inconsistencies in mathematical notation. It also examines the impact of regenerating output token-by-token on refining results. The findings reveal a significant 34.5% per-formance gap between the top commercial model (gpt-4o-mini, scoring 83.7%) and the least effective open-source model (open-codestral-mamba:v0.1, scoring 49.2%). This disparity is especially noticeable in complex areas like Number Theory. While token-by-token regeneration slightly improved accuracy (+0.8%) for the model llama3.1:8b, it also reduced code execution time by 36.7%, highlighting a trade-off between efficiency and precision. The study also noted a consistent trend where harder problems correlated with lower accuracy across all models. Despite using controlled execution environments, less than 1% of the generated code was unsafe, and 3.17% of problems remained unsolved after 10 attempts, suggesting that hybrid reasoning methods may be beneficial.</li>
</ul>

<h3>Title: Accelerated Training through Iterative Gradient Propagation Along the Residual Path</h3>
<ul>
<li><strong>Authors: </strong>Erwan Fagnou, Paul Caillon, Blaise Delattre, Alexandre Allauzen</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2501.17086">https://arxiv.org/abs/2501.17086</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2501.17086">https://arxiv.org/pdf/2501.17086</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2501.17086]] Accelerated Training through Iterative Gradient Propagation Along the Residual Path(https://arxiv.org/abs/2501.17086)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Despite being the cornerstone of deep learning, backpropagation is criticized for its inherent sequentiality, which can limit the scalability of very deep models. Such models faced convergence issues due to vanishing gradient, later resolved using residual connections. Variants of these are now widely used in modern architecture. However, the computational cost of backpropagation remains a major burden, accounting for most of the training time. Taking advantage of residual-like architectural designs, we introduce Highway backpropagation, a parallelizable iterative algorithm that approximates backpropagation, by alternatively i) accumulating the gradient estimates along the residual path, and ii) backpropagating them through every layer in parallel. This algorithm is naturally derived from a decomposition of the gradient as the sum of gradients flowing through all paths and is adaptable to a diverse set of common architectures, ranging from ResNets and Transformers to recurrent neural networks. Through an extensive empirical study on a large selection of tasks and models, we evaluate Highway-BP and show that major speedups can be achieved with minimal performance degradation.</li>
</ul>

<h3>Title: Mamba-Shedder: Post-Transformer Compression for Efficient Selective Structured State Space Models</h3>
<ul>
<li><strong>Authors: </strong>J. Pablo Muñoz, Jinjie Yuan, Nilesh Jain</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2501.17088">https://arxiv.org/abs/2501.17088</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2501.17088">https://arxiv.org/pdf/2501.17088</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2501.17088]] Mamba-Shedder: Post-Transformer Compression for Efficient Selective Structured State Space Models(https://arxiv.org/abs/2501.17088)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Large pre-trained models have achieved outstanding results in sequence modeling. The Transformer block and its attention mechanism have been the main drivers of the success of these models. Recently, alternative architectures, such as Selective Structured State Space Models (SSMs), have been proposed to address the inefficiencies of Transformers. This paper explores the compression of SSM-based models, particularly Mamba and its hybrids. We study the sensitivity of these models to the removal of selected components at different granularities to reduce the model size and computational overhead, thus improving their efficiency while maintaining accuracy. The proposed solutions, collectively referred to as Mamba-Shedder, achieve a speedup of up to 1.4x during inference, demonstrating that model efficiency can be improved by eliminating several redundancies with minimal impact on the overall model performance. The code is available at this https URL.</li>
</ul>

<h3>Title: CRSet: Non-Interactive Verifiable Credential Revocation with Metadata Privacy for Issuers and Everyone Else</h3>
<ul>
<li><strong>Authors: </strong>Felix Hoops, Jonas Gebele, Florian Matthes</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2501.17089">https://arxiv.org/abs/2501.17089</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2501.17089">https://arxiv.org/pdf/2501.17089</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2501.17089]] CRSet: Non-Interactive Verifiable Credential Revocation with Metadata Privacy for Issuers and Everyone Else(https://arxiv.org/abs/2501.17089)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, protect</a></li>
<li><strong>Abstract: </strong>Like any digital certificate, Verifiable Credentials (VCs) require a way to revoke them in case of an error or key compromise. Existing solutions for VC revocation, most prominently Bitstring Status List, are not viable for many use cases since they leak the issuer's behavior, which in turn leaks internal business metrics. For instance, exact staff fluctuation through issuance and revocation of employee IDs. We introduce CRSet, a revocation mechanism that allows an issuer to encode revocation information for years worth of VCs as a Bloom filter cascade. Padding is used to provide deniability for issuer metrics. Issuers periodically publish this filter cascade on a decentralized storage system. Relying Parties (RPs) can download it to perform any number of revocation checks locally. Compared to existing solutions, CRSet protects the metadata of subject, RPs, and issuer equally. At the same time, it is non-interactive, making it work with wallet devices having limited hardware power and drop-in compatible with existing VC exchange protocols and wallet applications. We present a prototype using the Ethereum blockchain as decentralized storage. The recently introduced blob-carrying transactions, enabling cheaper data writes, allow us to write each CRSet directly to the chain. We built software for issuers and RPs that we successfully tested end-to-end with an existing publicly available wallet agents and the OpenID for Verifiable Credentials protocols. Storage and bandwidth costs paid by issuers and RP are higher than for Bitstring Status List, but still manageable at around 1 MB for an issuer issuing hundreds of thousands of VCs annually and covering decades.</li>
</ul>

<h3>Title: Unlocking Transparent Alignment Through Enhanced Inverse Constitutional AI for Principle Extraction</h3>
<ul>
<li><strong>Authors: </strong>Carl-Leander Henneking, Claas Beger</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2501.17112">https://arxiv.org/abs/2501.17112</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2501.17112">https://arxiv.org/pdf/2501.17112</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2501.17112]] Unlocking Transparent Alignment Through Enhanced Inverse Constitutional AI for Principle Extraction(https://arxiv.org/abs/2501.17112)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction, interpretability, large language model</a></li>
<li><strong>Abstract: </strong>Traditional methods for aligning Large Language Models (LLMs), such as Reinforcement Learning from Human Feedback (RLHF) and Direct Preference Optimization (DPO), rely on implicit principles, limiting interpretability. Constitutional AI (CAI) offers an explicit, rule-based framework for guiding model outputs. Building on this, we refine the Inverse Constitutional AI (ICAI) algorithm, which extracts constitutions from preference datasets. By improving principle generation, clustering, and embedding processes, our approach enhances the accuracy and generalizability of extracted principles across synthetic and real-world datasets. While in-context alignment yields modest improvements, our results highlight the potential of these principles to foster more transparent and adaptable alignment methods, offering a promising direction for future advancements beyond traditional fine-tuning.</li>
</ul>

<h3>Title: Evidence on the Regularisation Properties of Maximum-Entropy Reinforcement Learning</h3>
<ul>
<li><strong>Authors: </strong>Rémy Hosseinkhan Boucher (1 and 2), Onofrio Semeraro (1 and 2), Lionel Mathelin (1 and 2) ((1) Université Paris-Saclay, (2) CNRS)</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2501.17115">https://arxiv.org/abs/2501.17115</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2501.17115">https://arxiv.org/pdf/2501.17115</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2501.17115]] Evidence on the Regularisation Properties of Maximum-Entropy Reinforcement Learning(https://arxiv.org/abs/2501.17115)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>The generalisation and robustness properties of policies learnt through Maximum-Entropy Reinforcement Learning are investigated on chaotic dynamical systems with Gaussian noise on the observable. First, the robustness under noise contamination of the agent's observation of entropy regularised policies is observed. Second, notions of statistical learning theory, such as complexity measures on the learnt model, are borrowed to explain and predict the phenomenon. Results show the existence of a relationship between entropy-regularised policy optimisation and robustness to noise, which can be described by the chosen complexity measures.</li>
</ul>

<h3>Title: Optimizing Large Language Model Training Using FP4 Quantization</h3>
<ul>
<li><strong>Authors: </strong>Ruizhe Wang, Yeyun Gong, Xiao Liu, Guoshuai Zhao, Ziyue Yang, Baining Guo, Zhengjun Zha, Peng Cheng</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2501.17116">https://arxiv.org/abs/2501.17116</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2501.17116">https://arxiv.org/pdf/2501.17116</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2501.17116]] Optimizing Large Language Model Training Using FP4 Quantization(https://arxiv.org/abs/2501.17116)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>The growing computational demands of training large language models (LLMs) necessitate more efficient methods. Quantized training presents a promising solution by enabling low-bit arithmetic operations to reduce these costs. While FP8 precision has demonstrated feasibility, leveraging FP4 remains a challenge due to significant quantization errors and limited representational capacity. This work introduces the first FP4 training framework for LLMs, addressing these challenges with two key innovations: a differentiable quantization estimator for precise weight updates and an outlier clamping and compensation strategy to prevent activation collapse. To ensure stability, the framework integrates a mixed-precision training scheme and vector-wise quantization. Experimental results demonstrate that our FP4 framework achieves accuracy comparable to BF16 and FP8, with minimal degradation, scaling effectively to 13B-parameter LLMs trained on up to 100B tokens. With the emergence of next-generation hardware supporting FP4, our framework sets a foundation for efficient ultra-low precision training.</li>
</ul>

<h3>Title: Histoires Morales: A French Dataset for Assessing Moral Alignment</h3>
<ul>
<li><strong>Authors: </strong>Thibaud Leteno, Irina Proskurina, Antoine Gourru, Julien Velcin, Charlotte Laclau, Guillaume Metzler, Christophe Gravier</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2501.17117">https://arxiv.org/abs/2501.17117</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2501.17117">https://arxiv.org/pdf/2501.17117</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2501.17117]] Histoires Morales: A French Dataset for Assessing Moral Alignment(https://arxiv.org/abs/2501.17117)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Aligning language models with human values is crucial, especially as they become more integrated into everyday life. While models are often adapted to user preferences, it is equally important to ensure they align with moral norms and behaviours in real-world social situations. Despite significant progress in languages like English and Chinese, French has seen little attention in this area, leaving a gap in understanding how LLMs handle moral reasoning in this language. To address this gap, we introduce Histoires Morales, a French dataset derived from Moral Stories, created through translation and subsequently refined with the assistance of native speakers to guarantee grammatical accuracy and adaptation to the French cultural context. We also rely on annotations of the moral values within the dataset to ensure their alignment with French norms. Histoires Morales covers a wide range of social situations, including differences in tipping practices, expressions of honesty in relationships, and responsibilities toward animals. To foster future research, we also conduct preliminary experiments on the alignment of multilingual models on French and English data and the robustness of the alignment. We find that while LLMs are generally aligned with human moral norms by default, they can be easily influenced with user-preference optimization for both moral and immoral data.</li>
</ul>

<h3>Title: Hybrid Deep Learning Model for Multiple Cache Side Channel Attacks Detection: A Comparative Analysis</h3>
<ul>
<li><strong>Authors: </strong>Tejal Joshi, Aarya Kawalay, Anvi Jamkhande, Amit Joshi</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.NE</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2501.17123">https://arxiv.org/abs/2501.17123</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2501.17123">https://arxiv.org/pdf/2501.17123</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2501.17123]] Hybrid Deep Learning Model for Multiple Cache Side Channel Attacks Detection: A Comparative Analysis(https://arxiv.org/abs/2501.17123)</code><input type="text"></li>
<li><strong>Keywords: </strong>secure, security, defense, attack</a></li>
<li><strong>Abstract: </strong>Cache side channel attacks are a sophisticated and persistent threat that exploit vulnerabilities in modern processors to extract sensitive information. These attacks leverage weaknesses in shared computational resources, particularly the last level cache, to infer patterns in data access and execution flows, often bypassing traditional security defenses. Such attacks are especially dangerous as they can be executed remotely without requiring physical access to the victim's device. This study focuses on a specific class of these threats: fingerprinting attacks, where an adversary monitors and analyzes the behavior of co-located processes via cache side channels. This can potentially reveal confidential information, such as encryption keys or user activity patterns. A comprehensive threat model illustrates how attackers sharing computational resources with target systems exploit these side channels to compromise sensitive data. To mitigate such risks, a hybrid deep learning model is proposed for detecting cache side channel attacks. Its performance is compared with five widely used deep learning models: Multi-Layer Perceptron, Convolutional Neural Network, Simple Recurrent Neural Network, Long Short-Term Memory, and Gated Recurrent Unit. The experimental results demonstrate that the hybrid model achieves a detection rate of up to 99.96%. These findings highlight the limitations of existing models, the need for enhanced defensive mechanisms, and directions for future research to secure sensitive data against evolving side channel threats.</li>
</ul>

<h3>Title: CoRe-Net: Co-Operational Regressor Network with Progressive Transfer Learning for Blind Radar Signal Restoration</h3>
<ul>
<li><strong>Authors: </strong>Muhammad Uzair Zahid, Serkan Kiranyaz, Alper Yildirim, Moncef Gabbouj</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2501.17125">https://arxiv.org/abs/2501.17125</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2501.17125">https://arxiv.org/pdf/2501.17125</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2501.17125]] CoRe-Net: Co-Operational Regressor Network with Progressive Transfer Learning for Blind Radar Signal Restoration(https://arxiv.org/abs/2501.17125)</code><input type="text"></li>
<li><strong>Keywords: </strong>fair</a></li>
<li><strong>Abstract: </strong>Real-world radar signals are frequently corrupted by various artifacts, including sensor noise, echoes, interference, and intentional jamming, differing in type, severity, and duration. This pilot study introduces a novel model, called Co-Operational Regressor Network (CoRe-Net) for blind radar signal restoration, designed to address such limitations and drawbacks. CoRe-Net replaces adversarial training with a novel cooperative learning strategy, leveraging the complementary roles of its Apprentice Regressor (AR) and Master Regressor (MR). The AR restores radar signals corrupted by various artifacts, while the MR evaluates the quality of the restoration and provides immediate and task-specific feedback, ensuring stable and efficient learning. The AR, therefore, has the advantage of both self-learning and assistive learning by the MR. The proposed model has been extensively evaluated over the benchmark Blind Radar Signal Restoration (BRSR) dataset, which simulates diverse real-world artifact scenarios. Under the fair experimental setup, this study shows that the CoRe-Net surpasses the Op-GANs over a 1 dB mean SNR improvement. To further boost the performance gain, this study proposes multi-pass restoration by cascaded CoRe-Nets trained with a novel paradigm called Progressive Transfer Learning (PTL), which enables iterative refinement, thus achieving an additional 2 dB mean SNR enhancement. Multi-pass CoRe-Net training by PTL consistently yields incremental performance improvements through successive restoration passes whilst highlighting CoRe-Net ability to handle such a complex and varying blend of artifacts.</li>
</ul>

<h3>Title: FactCG: Enhancing Fact Checkers with Graph-Based Multi-Hop Data</h3>
<ul>
<li><strong>Authors: </strong>Deren Lei, Yaxi Li, Siyao Li, Mengya Hu, Rui Xu, Ken Archer, Mingyu Wang, Emily Ching, Alex Deng</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2501.17144">https://arxiv.org/abs/2501.17144</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2501.17144">https://arxiv.org/pdf/2501.17144</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2501.17144]] FactCG: Enhancing Fact Checkers with Graph-Based Multi-Hop Data(https://arxiv.org/abs/2501.17144)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Prior research on training grounded factuality classification models to detect hallucinations in large language models (LLMs) has relied on public natural language inference (NLI) data and synthetic data. However, conventional NLI datasets are not well-suited for document-level reasoning, which is critical for detecting LLM hallucinations. Recent approaches to document-level synthetic data generation involve iteratively removing sentences from documents and annotating factuality using LLM-based prompts. While effective, this method is computationally expensive for long documents and limited by the LLM's capabilities. In this work, we analyze the differences between existing synthetic training data used in state-of-the-art models and real LLM output claims. Based on our findings, we propose a novel approach for synthetic data generation, CG2C, that leverages multi-hop reasoning on context graphs extracted from documents. Our fact checker model, FactCG, demonstrates improved performance with more connected reasoning, using the same backbone models. Experiments show it even outperforms GPT-4-o on the LLM-Aggrefact benchmark with much smaller model size.</li>
</ul>

<h3>Title: AxBench: Steering LLMs? Even Simple Baselines Outperform Sparse Autoencoders</h3>
<ul>
<li><strong>Authors: </strong>Zhengxuan Wu, Aryaman Arora, Atticus Geiger, Zheng Wang, Jing Huang, Dan Jurafsky, Christopher D. Manning, Christopher Potts</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2501.17148">https://arxiv.org/abs/2501.17148</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2501.17148">https://arxiv.org/pdf/2501.17148</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2501.17148]] AxBench: Steering LLMs? Even Simple Baselines Outperform Sparse Autoencoders(https://arxiv.org/abs/2501.17148)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability</a></li>
<li><strong>Abstract: </strong>Fine-grained steering of language model outputs is essential for safety and reliability. Prompting and finetuning are widely used to achieve these goals, but interpretability researchers have proposed a variety of representation-based techniques as well, including sparse autoencoders (SAEs), linear artificial tomography, supervised steering vectors, linear probes, and representation finetuning. At present, there is no benchmark for making direct comparisons between these proposals. Therefore, we introduce AxBench, a large-scale benchmark for steering and concept detection, and report experiments on Gemma-2-2B and 9B. For steering, we find that prompting outperforms all existing methods, followed by finetuning. For concept detection, representation-based methods such as difference-in-means, perform the best. On both evaluations, SAEs are not competitive. We introduce a novel weakly-supervised representational method (Rank-1 Representation Finetuning; ReFT-r1), which is competitive on both tasks while providing the interpretability advantages that prompting lacks. Along with AxBench, we train and publicly release SAE-scale feature dictionaries for ReFT-r1 and DiffMean.</li>
</ul>

<h3>Title: Scanning Trojaned Models Using Out-of-Distribution Samples</h3>
<ul>
<li><strong>Authors: </strong>Hossein Mirzaei, Ali Ansari, Bahar Dibaei Nia, Mojtaba Nafez, Moein Madadi, Sepehr Rezaee, Zeinab Sadat Taghavi, Arad Maleki, Kian Shamsaie, Mahdi Hajialilue, Jafar Habibi, Mohammad Sabokrou, Mohammad Hossein Rohban</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2501.17151">https://arxiv.org/abs/2501.17151</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2501.17151">https://arxiv.org/pdf/2501.17151</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2501.17151]] Scanning Trojaned Models Using Out-of-Distribution Samples(https://arxiv.org/abs/2501.17151)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack, robust</a></li>
<li><strong>Abstract: </strong>Scanning for trojan (backdoor) in deep neural networks is crucial due to their significant real-world applications. There has been an increasing focus on developing effective general trojan scanning methods across various trojan attacks. Despite advancements, there remains a shortage of methods that perform effectively without preconceived assumptions about the backdoor attack method. Additionally, we have observed that current methods struggle to identify classifiers trojaned using adversarial training. Motivated by these challenges, our study introduces a novel scanning method named TRODO (TROjan scanning by Detection of adversarial shifts in Out-of-distribution samples). TRODO leverages the concept of "blind spots"--regions where trojaned classifiers erroneously identify out-of-distribution (OOD) samples as in-distribution (ID). We scan for these blind spots by adversarially shifting OOD samples towards in-distribution. The increased likelihood of perturbed OOD samples being classified as ID serves as a signature for trojan detection. TRODO is both trojan and label mapping agnostic, effective even against adversarially trained trojaned classifiers. It is applicable even in scenarios where training data is absent, demonstrating high accuracy and adaptability across various scenarios and datasets, highlighting its potential as a robust trojan scanning strategy.</li>
</ul>

<h3>Title: IC-Portrait: In-Context Matching for View-Consistent Personalized Portrait</h3>
<ul>
<li><strong>Authors: </strong>Han Yang, Enis Simsar, Sotiris Anagnostidi, Yanlong Zang, Thomas Hofmann, Ziwei Liu</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2501.17159">https://arxiv.org/abs/2501.17159</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2501.17159">https://arxiv.org/pdf/2501.17159</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2501.17159]] IC-Portrait: In-Context Matching for View-Consistent Personalized Portrait(https://arxiv.org/abs/2501.17159)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>Existing diffusion models show great potential for identity-preserving generation. However, personalized portrait generation remains challenging due to the diversity in user profiles, including variations in appearance and lighting conditions. To address these challenges, we propose IC-Portrait, a novel framework designed to accurately encode individual identities for personalized portrait generation. Our key insight is that pre-trained diffusion models are fast learners (e.g.,100 ~ 200 steps) for in-context dense correspondence matching, which motivates the two major designs of our IC-Portrait framework. Specifically, we reformulate portrait generation into two sub-tasks: 1) Lighting-Aware Stitching: we find that masking a high proportion of the input image, e.g., 80%, yields a highly effective self-supervisory representation learning of reference image lighting. 2) View-Consistent Adaptation: we leverage a synthetic view-consistent profile dataset to learn the in-context correspondence. The reference profile can then be warped into arbitrary poses for strong spatial-aligned view conditioning. Coupling these two designs by simply concatenating latents to form ControlNet-like supervision and modeling, enables us to significantly enhance the identity preservation fidelity and stability. Extensive evaluations demonstrate that IC-Portrait consistently outperforms existing state-of-the-art methods both quantitatively and qualitatively, with particularly notable improvements in visual qualities. Furthermore, IC-Portrait even demonstrates 3D-aware relighting capabilities.</li>
</ul>

<h3>Title: CubeDiff: Repurposing Diffusion-Based Image Models for Panorama Generation</h3>
<ul>
<li><strong>Authors: </strong>Nikolai Kalischek, Michael Oechsle, Fabian Manhardt, Philipp Henzler, Konrad Schindler, Federico Tombari</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2501.17162">https://arxiv.org/abs/2501.17162</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2501.17162">https://arxiv.org/pdf/2501.17162</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2501.17162]] CubeDiff: Repurposing Diffusion-Based Image Models for Panorama Generation(https://arxiv.org/abs/2501.17162)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>We introduce a novel method for generating 360° panoramas from text prompts or images. Our approach leverages recent advances in 3D generation by employing multi-view diffusion models to jointly synthesize the six faces of a cubemap. Unlike previous methods that rely on processing equirectangular projections or autoregressive generation, our method treats each face as a standard perspective image, simplifying the generation process and enabling the use of existing multi-view diffusion models. We demonstrate that these models can be adapted to produce high-quality cubemaps without requiring correspondence-aware attention layers. Our model allows for fine-grained text control, generates high resolution panorama images and generalizes well beyond its training set, whilst achieving state-of-the-art results, both qualitatively and quantitatively. Project page: this https URL</li>
</ul>

<button id="copy">Copy All</button>
</article>
<script src="../../javascript/clipboard.min.js"></script>
<script src="../../javascript/clipboard.js"></script>
