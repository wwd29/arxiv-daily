<link rel="stylesheet" href="../../css/markdown.css" />
<article class="markdown-body">
<h1>2024-10-15</h1>
<h3>Title: Investigating the Impact of Text Summarization on Topic Modeling</h3>
<ul>
<li><strong>Authors: </strong>Trishia Khandelwal</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.09063">https://arxiv.org/abs/2410.09063</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.09063">https://arxiv.org/pdf/2410.09063</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.09063]] Investigating the Impact of Text Summarization on Topic Modeling(https://arxiv.org/abs/2410.09063)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Topic models are used to identify and group similar themes in a set of documents. Recent advancements in deep learning based neural topic models has received significant research interest. In this paper, an approach is proposed that further enhances topic modeling performance by utilizing a pre-trained large language model (LLM) to generate summaries of documents before inputting them into the topic model. Few shot prompting is used to generate summaries of different lengths to compare their impact on topic modeling. This approach is particularly effective for larger documents because it helps capture the most essential information while reducing noise and irrelevant details that could obscure the overall theme. Additionally, it is observed that datasets exhibit an optimal summary length that leads to improved topic modeling performance. The proposed method yields better topic diversity and comparable coherence values compared to previous models.</li>
</ul>

<h3>Title: AI versus AI in Financial Crimes and Detection: GenAI Crime Waves to Co-Evolutionary AI</h3>
<ul>
<li><strong>Authors: </strong>Eren Kurshan, Dhagash Mehta, Bayan Bruss, Tucker Balch</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.09066">https://arxiv.org/abs/2410.09066</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.09066">https://arxiv.org/pdf/2410.09066</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.09066]] AI versus AI in Financial Crimes and Detection: GenAI Crime Waves to Co-Evolutionary AI(https://arxiv.org/abs/2410.09066)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, defense, attack, biometric, generative</a></li>
<li><strong>Abstract: </strong>Adoption of AI by criminal entities across traditional and emerging financial crime paradigms has been a disturbing recent trend. Particularly concerning is the proliferation of generative AI, which has empowered criminal activities ranging from sophisticated phishing schemes to the creation of hard-to-detect deep fakes, and to advanced spoofing attacks to biometric authentication systems. The exploitation of AI by criminal purposes continues to escalate, presenting an unprecedented challenge. AI adoption causes an increasingly complex landscape of fraud typologies intertwined with cybersecurity vulnerabilities. Overall, GenAI has a transformative effect on financial crimes and fraud. According to some estimates, GenAI will quadruple the fraud losses by 2027 with a staggering annual growth rate of over 30% [27]. As crime patterns become more intricate, personalized, and elusive, deploying effective defensive AI strategies becomes indispensable. However, several challenges hinder the necessary progress of AI-based fincrime detection systems. This paper examines the latest trends in AI/ML-driven financial crimes and detection systems. It underscores the urgent need for developing agile AI defenses that can effectively counteract the rapidly emerging threats. It also aims to highlight the need for cooperation across the financial services industry to tackle the GenAI induced crime waves.</li>
</ul>

<h3>Title: Using Steganography and Watermarking For Medical Image Integrity</h3>
<ul>
<li><strong>Authors: </strong>Givon Zirkind</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.GR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.09071">https://arxiv.org/abs/2410.09071</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.09071">https://arxiv.org/pdf/2410.09071</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.09071]] Using Steganography and Watermarking For Medical Image Integrity(https://arxiv.org/abs/2410.09071)</code><input type="text"></li>
<li><strong>Keywords: </strong>watermark</a></li>
<li><strong>Abstract: </strong>Medical imaging has kept up with the digital age. Medical images such as x-rays are no longer keep on film or; even made with film. Rather, they are digital. In addition, they are transmitted for reasons of consultation and telehealth as well as archived. Transmission and retrieval of these images presents an integrity issue, with a high level of integrity being needed. Very small artifacts in a digital medical image can have significant importance, making or changing a diagnosis. It is imperative that the integrity of a medical image, especially in a Region of Interest be identifiable and preserved. Watermarking and steganography are used for the purposes of authenticating images, especially for copyright purposes. These techniques can be applied to medical images. However, these techniques can interfere with the integrity of the picture. While such distortion may be acceptable in other domains, in the medical domain this distortion is not acceptable. High accuracy is imperative for diagnosis. This paper discusses the techniques used, their advantages and shortcomings as well as methods of overcoming obstacles to integrity.</li>
</ul>

<h3>Title: Llettuce: An Open Source Natural Language Processing Tool for the Translation of Medical Terms into Uniform Clinical Encoding</h3>
<ul>
<li><strong>Authors: </strong>James Mitchell-White, Reza Omdivar, Esmond Urwin, Karthikeyan Sivakumar, Ruizhe Li, Andy Rae, Xiaoyan Wang, Theresia Mina, John Chambers, Grazziela Figueredo, Philip R Quinlan</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.09076">https://arxiv.org/abs/2410.09076</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.09076">https://arxiv.org/pdf/2410.09076</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.09076]] Llettuce: An Open Source Natural Language Processing Tool for the Translation of Medical Terms into Uniform Clinical Encoding(https://arxiv.org/abs/2410.09076)</code><input type="text"></li>
<li><strong>Keywords: </strong>protect, large language model</a></li>
<li><strong>Abstract: </strong>This paper introduces Llettuce, an open-source tool designed to address the complexities of converting medical terms into OMOP standard concepts. Unlike existing solutions such as the Athena database search and Usagi, which struggle with semantic nuances and require substantial manual input, Llettuce leverages advanced natural language processing, including large language models and fuzzy matching, to automate and enhance the mapping process. Developed with a focus on GDPR compliance, Llettuce can be deployed locally, ensuring data protection while maintaining high performance in converting informal medical terms to standardised concepts.</li>
</ul>

<h3>Title: A Large Language Model-based Framework for Semi-Structured Tender Document Retrieval-Augmented Generation</h3>
<ul>
<li><strong>Authors: </strong>Yilong Zhao, Daifeng Li</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.IR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.09077">https://arxiv.org/abs/2410.09077</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.09077">https://arxiv.org/pdf/2410.09077</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.09077]] A Large Language Model-based Framework for Semi-Structured Tender Document Retrieval-Augmented Generation(https://arxiv.org/abs/2410.09077)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>The drafting of documents in the procurement field has progressively become more complex and diverse, driven by the need to meet legal requirements, adapt to technological advancements, and address stakeholder demands. While large language models (LLMs) show potential in document generation, most LLMs lack specialized knowledge in procurement. To address this gap, we use retrieval-augmented techniques to achieve professional document generation, ensuring accuracy and relevance in procurement documentation.</li>
</ul>

<h3>Title: Knowledge-Augmented Reasoning for EUAIA Compliance and Adversarial Robustness of LLMs</h3>
<ul>
<li><strong>Authors: </strong>Tomas Bueno Momcilovic, Dian Balta, Beat Buesser, Giulio Zizzo, Mark Purcell</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.CY, cs.SE</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.09078">https://arxiv.org/abs/2410.09078</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.09078">https://arxiv.org/pdf/2410.09078</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.09078]] Knowledge-Augmented Reasoning for EUAIA Compliance and Adversarial Robustness of LLMs(https://arxiv.org/abs/2410.09078)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack, robust</a></li>
<li><strong>Abstract: </strong>The EU AI Act (EUAIA) introduces requirements for AI systems which intersect with the processes required to establish adversarial robustness. However, given the ambiguous language of regulation and the dynamicity of adversarial attacks, developers of systems with highly complex models such as LLMs may find their effort to be duplicated without the assurance of having achieved either compliance or robustness. This paper presents a functional architecture that focuses on bridging the two properties, by introducing components with clear reference to their source. Taking the detection layer recommended by the literature, and the reporting layer required by the law, we aim to support developers and auditors with a reasoning layer based on knowledge augmentation (rules, assurance cases, contextual mappings). Our findings demonstrate a novel direction for ensuring LLMs deployed in the EU are both compliant and adversarially robust, which underpin trustworthiness.</li>
</ul>

<h3>Title: Diagnosing Robotics Systems Issues with Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Jordis Emilia Herrmann, Aswath Mandakath Gopinath, Mikael Norrlof, Mark Niklas MÃ¼ller</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.LG, cs.RO</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.09084">https://arxiv.org/abs/2410.09084</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.09084">https://arxiv.org/pdf/2410.09084</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.09084]] Diagnosing Robotics Systems Issues with Large Language Models(https://arxiv.org/abs/2410.09084)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Quickly resolving issues reported in industrial applications is crucial to minimize economic impact. However, the required data analysis makes diagnosing the underlying root causes a challenging and time-consuming task, even for experts. In contrast, large language models (LLMs) excel at analyzing large amounts of data. Indeed, prior work in AI-Ops demonstrates their effectiveness in analyzing IT systems. Here, we extend this work to the challenging and largely unexplored domain of robotics systems. To this end, we create SYSDIAGBENCH, a proprietary system diagnostics benchmark for robotics, containing over 2500 reported issues. We leverage SYSDIAGBENCH to investigate the performance of LLMs for root cause analysis, considering a range of model sizes and adaptation techniques. Our results show that QLoRA finetuning can be sufficient to let a 7B-parameter model outperform GPT-4 in terms of diagnostic accuracy while being significantly more cost-effective. We validate our LLM-as-a-judge results with a human expert study and find that our best model achieves similar approval ratings as our reference labels.</li>
</ul>

<h3>Title: Securing UAV Communication: Authentication and Integrity</h3>
<ul>
<li><strong>Authors: </strong>Meriem Ouadah, Fatiha Merazka</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.09085">https://arxiv.org/abs/2410.09085</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.09085">https://arxiv.org/pdf/2410.09085</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.09085]] Securing UAV Communication: Authentication and Integrity(https://arxiv.org/abs/2410.09085)</code><input type="text"></li>
<li><strong>Keywords: </strong>secure, security, protect, attack</a></li>
<li><strong>Abstract: </strong>Recent technological advancements have seen the integration of unmanned aerial networks (UAVs) into various sectors, from civilian missions to military operations. In this context, ensuring security, precisely authentication, is essential to prevent data theft and manipulation. A Man-in-the-Middle attack not only compromises network integrity but also threatens the original data, potentially leading to theft or alteration. In this work, we proposed an authentication method to secure UAV data exchange over an insecure communication channel. Our solution combines Diffie-Hellman (DH) key exchange and Hash-based Message Authentication Code (HMAC) within ROS communication channels to authenticate exchanged UAV data. We evaluated our method by measuring transmission time and simulating key tampering, finding acceptable performance for DH key sizes below 4096 bits but longer times for larger sizes due to increased complexity. Both drones successfully detected tampered keys, affirming our method's efficacy in protecting UAV communication. However, scalability challenges in resource-constrained environments warrant further research.</li>
</ul>

<h3>Title: The Solution for Temporal Action Localisation Task of Perception Test Challenge 2024</h3>
<ul>
<li><strong>Authors: </strong>Yinan Han, Qingyuan Jiang, Hongming Mei, Yang Yang, Jinhui Tang</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.09088">https://arxiv.org/abs/2410.09088</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.09088">https://arxiv.org/pdf/2410.09088</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.09088]] The Solution for Temporal Action Localisation Task of Perception Test Challenge 2024(https://arxiv.org/abs/2410.09088)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, extraction</a></li>
<li><strong>Abstract: </strong>This report presents our method for Temporal Action Localisation (TAL), which focuses on identifying and classifying actions within specific time intervals throughout a video sequence. We employ a data augmentation technique by expanding the training dataset using overlapping labels from the Something-SomethingV2 dataset, enhancing the model's ability to generalize across various action classes. For feature extraction, we utilize state-of-the-art models, including UMT, VideoMAEv2 for video features, and BEATs and CAV-MAE for audio features. Our approach involves training both multimodal (video and audio) and unimodal (video only) models, followed by combining their predictions using the Weighted Box Fusion (WBF) method. This fusion strategy ensures robust action localisation. our overall approach achieves a score of 0.5498, securing first place in the competition.</li>
</ul>

<h3>Title: Different Cybercrimes and their Solution for Common People</h3>
<ul>
<li><strong>Authors: </strong>S. Tamang, G. S. Chandana, B. K. Roy</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.AI, cs.CY</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.09089">https://arxiv.org/abs/2410.09089</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.09089">https://arxiv.org/pdf/2410.09089</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.09089]] Different Cybercrimes and their Solution for Common People(https://arxiv.org/abs/2410.09089)</code><input type="text"></li>
<li><strong>Keywords: </strong>security</a></li>
<li><strong>Abstract: </strong>In today's digital age, cyberspace has become integral to daily life, however it has also led to an increase in cybercriminal activities. This paper explores cybercrime trends and highlights the need for cybercrime awareness (cyberawareness) to mitigate vulnerabilities. The study also examines Indian statistics on cybercrime. We review the existing literature on cybercrime and cybersecurity, focusing on various types of cybercrimes and their impacts. We present a list of 31 technical as well as non-technical solutions considering that a "common man" may not be technologically aware. Common man solutions, considering that they are not technologically updated. Expanding the list of solutions and validating their effectiveness in cyber threats can be the future scope of the research.</li>
</ul>

<h3>Title: Recent advancements in LLM Red-Teaming: Techniques, Defenses, and Ethical Considerations</h3>
<ul>
<li><strong>Authors: </strong>Tarun Raheja, Nilay Pochhi</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.09097">https://arxiv.org/abs/2410.09097</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.09097">https://arxiv.org/pdf/2410.09097</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.09097]] Recent advancements in LLM Red-Teaming: Techniques, Defenses, and Ethical Considerations(https://arxiv.org/abs/2410.09097)</code><input type="text"></li>
<li><strong>Keywords: </strong>secure, security, defense, attack, large language model</a></li>
<li><strong>Abstract: </strong>Large Language Models (LLMs) have demonstrated remarkable capabilities in natural language processing tasks, but their vulnerability to jailbreak attacks poses significant security risks. This survey paper presents a comprehensive analysis of recent advancements in attack strategies and defense mechanisms within the field of Large Language Model (LLM) red-teaming. We analyze various attack methods, including gradient-based optimization, reinforcement learning, and prompt engineering approaches. We discuss the implications of these attacks on LLM safety and the need for improved defense mechanisms. This work aims to provide a thorough understanding of the current landscape of red-teaming attacks and defenses on LLMs, enabling the development of more secure and reliable language models.</li>
</ul>

<h3>Title: Adaptive Active Inference Agents for Heterogeneous and Lifelong Federated Learning</h3>
<ul>
<li><strong>Authors: </strong>Anastasiya Danilenka, Alireza Furutanpey, Victor Casamayor Pujol, Boris Sedlak, Anna Lackinger, Maria Ganzha, Marcin Paprzycki, Schahram Dustdar</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.DC</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.09099">https://arxiv.org/abs/2410.09099</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.09099">https://arxiv.org/pdf/2410.09099</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.09099]] Adaptive Active Inference Agents for Heterogeneous and Lifelong Federated Learning(https://arxiv.org/abs/2410.09099)</code><input type="text"></li>
<li><strong>Keywords: </strong>federate</a></li>
<li><strong>Abstract: </strong>Handling heterogeneity and unpredictability are two core problems in pervasive computing. The challenge is to seamlessly integrate devices with varying computational resources in a dynamic environment to form a cohesive system that can fulfill the needs of all participants. Existing work on systems that adapt to changing requirements typically focuses on optimizing individual variables or low-level Service Level Objectives (SLOs), such as constraining the usage of specific resources. While low-level control mechanisms permit fine-grained control over a system, they introduce considerable complexity, particularly in dynamic environments. To this end, we propose drawing from Active Inference (AIF), a neuroscientific framework for designing adaptive agents. Specifically, we introduce a conceptual agent for heterogeneous pervasive systems that permits setting global systems constraints as high-level SLOs. Instead of manually setting low-level SLOs, the system finds an equilibrium that can adapt to environmental changes. We demonstrate the viability of AIF agents with an extensive experiment design, using heterogeneous and lifelong federated learning as an application scenario. We conduct our experiments on a physical testbed of devices with different resource types and vendor specifications. The results provide convincing evidence that an AIF agent can adapt a system to environmental changes. In particular, the AIF agent can balance competing SLOs in resource heterogeneous environments to ensure up to 98% fulfillment rate.</li>
</ul>

<h3>Title: Data Taggants: Dataset Ownership Verification via Harmless Targeted Data Poisoning</h3>
<ul>
<li><strong>Authors: </strong>Wassim Bouaziz, El-Mahdi El-Mhamdi, Nicolas Usunier</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.LG, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.09101">https://arxiv.org/abs/2410.09101</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.09101">https://arxiv.org/pdf/2410.09101</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.09101]] Data Taggants: Dataset Ownership Verification via Harmless Targeted Data Poisoning(https://arxiv.org/abs/2410.09101)</code><input type="text"></li>
<li><strong>Keywords: </strong>protect, defense, robust, steal, watermark</a></li>
<li><strong>Abstract: </strong>Dataset ownership verification, the process of determining if a dataset is used in a model's training data, is necessary for detecting unauthorized data usage and data contamination. Existing approaches, such as backdoor watermarking, rely on inducing a detectable behavior into the trained model on a part of the data distribution. However, these approaches have limitations, as they can be harmful to the model's performances or require unpractical access to the model's internals. Most importantly, previous approaches lack guarantee against false positives. This paper introduces data taggants, a novel non-backdoor dataset ownership verification technique. Our method uses pairs of out-of-distribution samples and random labels as secret keys, and leverages clean-label targeted data poisoning to subtly alter a dataset, so that models trained on it respond to the key samples with the corresponding key labels. The keys are built as to allow for statistical certificates with black-box access only to the model. We validate our approach through comprehensive and realistic experiments on ImageNet1k using ViT and ResNet models with state-of-the-art training recipes. Our findings demonstrate that data taggants can reliably make models trained on the protected dataset detectable with high confidence, without compromising validation accuracy, and demonstrates superiority over backdoor watermarking. Moreover, our method shows to be stealthy and robust against various defense mechanisms.</li>
</ul>

<h3>Title: Instructional Segment Embedding: Improving LLM Safety with Instruction Hierarchy</h3>
<ul>
<li><strong>Authors: </strong>Tong Wu, Shujian Zhang, Kaiqiang Song, Silei Xu, Sanqiang Zhao, Ravi Agrawal, Sathish Reddy Indurthi, Chong Xiang, Prateek Mittal, Wenxuan Zhou</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.AI, cs.CL, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.09102">https://arxiv.org/abs/2410.09102</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.09102">https://arxiv.org/pdf/2410.09102</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.09102]] Instructional Segment Embedding: Improving LLM Safety with Instruction Hierarchy(https://arxiv.org/abs/2410.09102)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, robust, extraction, large language model</a></li>
<li><strong>Abstract: </strong>Large Language Models (LLMs) are susceptible to security and safety threats, such as prompt injection, prompt extraction, and harmful requests. One major cause of these vulnerabilities is the lack of an instruction hierarchy. Modern LLM architectures treat all inputs equally, failing to distinguish between and prioritize various types of instructions, such as system messages, user prompts, and data. As a result, lower-priority user prompts may override more critical system instructions, including safety protocols. Existing approaches to achieving instruction hierarchy, such as delimiters and instruction-based training, do not address this issue at the architectural level. We introduce the Instructional Segment Embedding (ISE) technique, inspired by BERT, to modern large language models, which embeds instruction priority information directly into the model. This approach enables models to explicitly differentiate and prioritize various instruction types, significantly improving safety against malicious prompts that attempt to override priority rules. Our experiments on the Structured Query and Instruction Hierarchy benchmarks demonstrate an average robust accuracy increase of up to 15.75% and 18.68%, respectively. Furthermore, we observe an improvement in instruction-following capability of up to 4.1% evaluated on AlpacaEval. Overall, our approach offers a promising direction for enhancing the safety and effectiveness of LLM architectures.</li>
</ul>

<h3>Title: Parameter-Efficient Fine-Tuning via Selective Discrete Cosine Transform</h3>
<ul>
<li><strong>Authors: </strong>Yixian Shen, Qi Bi, Jia-Hong Huang, Hongyi Zhu, Anuj Pathania</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.09103">https://arxiv.org/abs/2410.09103</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.09103">https://arxiv.org/pdf/2410.09103</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.09103]] Parameter-Efficient Fine-Tuning via Selective Discrete Cosine Transform(https://arxiv.org/abs/2410.09103)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>In the era of large language models, parameter-efficient fine-tuning (PEFT) has been extensively studied. However, these approaches usually rely on the space domain, which encounters storage challenges especially when handling extensive adaptations or larger models. The frequency domain, in contrast, is more effective in compressing trainable parameters while maintaining the expressive capability. In this paper, we propose a novel Selective Discrete Cosine Transformation (sDCTFT) fine-tuning scheme to push this frontier. Its general idea is to exploit the superior energy compaction and decorrelation properties of DCT to improve both model efficiency and accuracy. Specifically, it projects the weight change from the low-rank adaptation into the discrete cosine space. Then, the weight change is partitioned over different levels of the discrete cosine spectrum, and the most critical frequency components in each partition are selected. Extensive experiments on four benchmark datasets demonstrate the superior accuracy, reduced computational cost, and lower storage requirements of the proposed method over the prior arts. For instance, when performing instruction tuning on the LLaMA3.1-8B model, sDCTFT outperforms LoRA with just 0.05M trainable parameters compared to LoRA's 38.2M, and surpasses FourierFT with 30\% less trainable parameters. The source code will be publicly available.</li>
</ul>

<h3>Title: Federated Learning for Data Market: Shapley-UCB for Seller Selection and Incentives</h3>
<ul>
<li><strong>Authors: </strong>Kongyang Chen, Zeming Xu</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.GT</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.09107">https://arxiv.org/abs/2410.09107</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.09107">https://arxiv.org/pdf/2410.09107</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.09107]] Federated Learning for Data Market: Shapley-UCB for Seller Selection and Incentives(https://arxiv.org/abs/2410.09107)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, protect, federate, fair</a></li>
<li><strong>Abstract: </strong>In recent years, research on the data trading market has been continuously deepened. In the transaction process, there is an information asymmetry process between agents and sellers. For sellers, direct data delivery faces the risk of privacy leakage. At the same time, sellers are not willing to provide data. A reasonable compensation method is needed to encourage sellers to provide data resources. For agents, the quality of data provided by sellers needs to be examined and evaluated. Otherwise, agents may consume too much cost and resources by recruiting sellers with poor data quality. Therefore, it is necessary to build a complete delivery process for the interaction between sellers and agents in the trading market so that the needs of sellers and agents can be met. The federated learning architecture is widely used in the data market due to its good privacy protection. Therefore, in this work, in response to the above challenges, we propose a transaction framework based on the federated learning architecture, and design a seller selection algorithm and incentive compensation mechanism. Specifically, we use gradient similarity and Shapley algorithm to fairly and accurately evaluate the contribution of sellers, and use the modified UCB algorithm to select sellers. After the training, fair compensation is made according to the seller's participation in the training. In view of the above work, we designed reasonable experiments for demonstration and obtained results, proving the rationality and effectiveness of the framework.</li>
</ul>

<h3>Title: Catastrophic Cyber Capabilities Benchmark (3CB): Robustly Evaluating LLM Agent Cyber Offense Capabilities</h3>
<ul>
<li><strong>Authors: </strong>Andrey Anurin, Jonathan Ng, Kibo Schaffer, Ziyue Wang, Jason Schreiber, Esben Kran</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.AI, cs.LG, cs.PF</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.09114">https://arxiv.org/abs/2410.09114</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.09114">https://arxiv.org/pdf/2410.09114</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.09114]] Catastrophic Cyber Capabilities Benchmark (3CB): Robustly Evaluating LLM Agent Cyber Offense Capabilities(https://arxiv.org/abs/2410.09114)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>LLM agents have the potential to revolutionize defensive cyber operations, but their offensive capabilities are not yet fully understood. To prepare for emerging threats, model developers and governments are evaluating the cyber capabilities of foundation models. However, these assessments often lack transparency and a comprehensive focus on offensive capabilities. In response, we introduce the Catastrophic Cyber Capabilities Benchmark (3CB), a novel framework designed to rigorously assess the real-world offensive capabilities of LLM agents. Our evaluation of modern LLMs on 3CB reveals that frontier models, such as GPT-4o and Claude 3.5 Sonnet, can perform offensive tasks such as reconnaissance and exploitation across domains ranging from binary analysis to web technologies. Conversely, smaller open-source models exhibit limited offensive capabilities. Our software solution and the corresponding benchmark provides a critical tool to reduce the gap between rapidly improving capabilities and robustness of cyber offense evaluations, aiding in the safer deployment and regulation of these powerful technologies.</li>
</ul>

<h3>Title: SoK: Verifiable Cross-Silo FL</h3>
<ul>
<li><strong>Authors: </strong>Aleksei Korneev (CRIStAL, MAGNET), Jan Ramon (CRIStAL, MAGNET)</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.09124">https://arxiv.org/abs/2410.09124</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.09124">https://arxiv.org/pdf/2410.09124</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.09124]] SoK: Verifiable Cross-Silo FL(https://arxiv.org/abs/2410.09124)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, federate</a></li>
<li><strong>Abstract: </strong>Federated Learning (FL) is a widespread approach that allows training machine learning (ML) models with data distributed across multiple devices. In cross-silo FL, which often appears in domains like healthcare or finance, the number of participants is moderate, and each party typically represents a well-known organization. For instance, in medicine data owners are often hospitals or data hubs which are well-established entities.  However, malicious parties may still attempt to disturb the training procedure in order to obtain certain benefits, for example, a biased result or a reduction in computational load. While one can easily detect a malicious agent when data used for training is public, the problem becomes much more acute when it is necessary to maintain the privacy of the training dataset. To address this issue, there is recently growing interest in developing verifiable protocols, where one can check that parties do not deviate from the training procedure and perform computations correctly. In this paper, we present a systematization of knowledge on verifiable cross-silo FL. We analyze various protocols, fit them in a taxonomy, and compare their efficiency and threat models. We also analyze Zero-Knowledge Proof (ZKP) schemes and discuss how their overall cost in a FL context can be minimized. Lastly, we identify research gaps and discuss potential directions for future scientific work.</li>
</ul>

<h3>Title: Training on Fake Labels: Mitigating Label Leakage in Split Learning via Secure Dimension Transformation</h3>
<ul>
<li><strong>Authors: </strong>Yukun Jiang, Peiran Wang, Chengguo Lin, Ziyue Huang, Yong Cheng</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.09125">https://arxiv.org/abs/2410.09125</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.09125">https://arxiv.org/pdf/2410.09125</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.09125]] Training on Fake Labels: Mitigating Label Leakage in Split Learning via Secure Dimension Transformation(https://arxiv.org/abs/2410.09125)</code><input type="text"></li>
<li><strong>Keywords: </strong>secure, privacy, defense, attack, federate</a></li>
<li><strong>Abstract: </strong>Two-party split learning has emerged as a popular paradigm for vertical federated learning. To preserve the privacy of the label owner, split learning utilizes a split model, which only requires the exchange of intermediate representations (IRs) based on the inputs and gradients for each IR between two parties during the learning process. However, split learning has recently been proven to survive label inference attacks. Though several defense methods could be adopted, they either have limited defensive performance or significantly negatively impact the original mission. In this paper, we propose a novel two-party split learning method to defend against existing label inference attacks while maintaining the high utility of the learned models. Specifically, we first craft a dimension transformation module, SecDT, which could achieve bidirectional mapping between original labels and increased K-class labels to mitigate label leakage from the directional perspective. Then, a gradient normalization algorithm is designed to remove the magnitude divergence of gradients from different classes. We propose a softmax-normalized Gaussian noise to mitigate privacy leakage and make our K unknowable to adversaries. We conducted experiments on real-world datasets, including two binary-classification datasets (Avazu and Criteo) and three multi-classification datasets (MNIST, FashionMNIST, CIFAR-10); we also considered current attack schemes, including direction, norm, spectral, and model completion attacks. The detailed experiments demonstrate our proposed method's effectiveness and superiority over existing approaches. For instance, on the Avazu dataset, the attack AUC of evaluated four prominent attacks could be reduced by 0.4532+-0.0127.</li>
</ul>

<h3>Title: CYCLE: Cross-Year Contrastive Learning in Entity-Linking</h3>
<ul>
<li><strong>Authors: </strong>Pengyu Zhang, Congfeng Cao, Klim Zaporojets, Paul Groth</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.09127">https://arxiv.org/abs/2410.09127</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.09127">https://arxiv.org/pdf/2410.09127</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.09127]] CYCLE: Cross-Year Contrastive Learning in Entity-Linking(https://arxiv.org/abs/2410.09127)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Knowledge graphs constantly evolve with new entities emerging, existing definitions being revised, and entity relationships changing. These changes lead to temporal degradation in entity linking models, characterized as a decline in model performance over time. To address this issue, we propose leveraging graph relationships to aggregate information from neighboring entities across different time periods. This approach enhances the ability to distinguish similar entities over time, thereby minimizing the impact of temporal degradation. We introduce \textbf{CYCLE}: \textbf{C}ross-\textbf{Y}ear \textbf{C}ontrastive \textbf{L}earning for \textbf{E}ntity-Linking. This model employs a novel graph contrastive learning method to tackle temporal performance degradation in entity linking tasks. Our contrastive learning method treats newly added graph relationships as \textit{positive} samples and newly removed ones as \textit{negative} samples. This approach helps our model effectively prevent temporal degradation, achieving a 13.90\% performance improvement over the state-of-the-art from 2023 when the time gap is one year, and a 17.79\% improvement as the gap expands to three years. Further analysis shows that CYCLE is particularly robust for low-degree entities, which are less resistant to temporal degradation due to their sparse connectivity, making them particularly suitable for our method. The code and data are made available at \url{this https URL}.</li>
</ul>

<h3>Title: nextlocllm: next location prediction using LLMs</h3>
<ul>
<li><strong>Authors: </strong>Shuai Liu, Ning Cao, Yile Chen, Yue Jiang, Gao Cong</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.09129">https://arxiv.org/abs/2410.09129</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.09129">https://arxiv.org/pdf/2410.09129</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.09129]] nextlocllm: next location prediction using LLMs(https://arxiv.org/abs/2410.09129)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, large language model</a></li>
<li><strong>Abstract: </strong>Next location prediction is a critical task in human mobility analysis and serves as a foundation for various downstream applications. Existing methods typically rely on discrete IDs to represent locations, which inherently overlook spatial relationships and cannot generalize across cities. In this paper, we propose NextLocLLM, which leverages the advantages of large language models (LLMs) in processing natural language descriptions and their strong generalization capabilities for next location prediction. Specifically, instead of using IDs, NextLocLLM encodes locations based on continuous spatial coordinates to better model spatial relationships. These coordinates are further normalized to enable robust cross-city generalization. Another highlight of NextlocLLM is its LLM-enhanced POI embeddings. It utilizes LLMs' ability to encode each POI category's natural language description into embeddings. These embeddings are then integrated via nonlinear projections to form this LLM-enhanced POI embeddings, effectively capturing locations' functional attributes. Furthermore, task and data prompt prefix, together with trajectory embeddings, are incorporated as input for partly-frozen LLM backbone. NextLocLLM further introduces prediction retrieval module to ensure structural consistency in prediction. Experiments show that NextLocLLM outperforms existing models in next location prediction, excelling in both supervised and zero-shot settings.</li>
</ul>

<h3>Title: Multi-Agent Actor-Critics in Autonomous Cyber Defense</h3>
<ul>
<li><strong>Authors: </strong>Mingjun Wang, Remington Dechene</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.AI, cs.MA</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.09134">https://arxiv.org/abs/2410.09134</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.09134">https://arxiv.org/pdf/2410.09134</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.09134]] Multi-Agent Actor-Critics in Autonomous Cyber Defense(https://arxiv.org/abs/2410.09134)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, defense, attack</a></li>
<li><strong>Abstract: </strong>The need for autonomous and adaptive defense mechanisms has become paramount in the rapidly evolving landscape of cyber threats. Multi-Agent Deep Reinforcement Learning (MADRL) presents a promising approach to enhancing the efficacy and resilience of autonomous cyber operations. This paper explores the application of Multi-Agent Actor-Critic algorithms which provides a general form in Multi-Agent learning to cyber defense, leveraging the collaborative interactions among multiple agents to detect, mitigate, and respond to cyber threats. We demonstrate each agent is able to learn quickly and counter act on the threats autonomously using MADRL in simulated cyber-attack scenarios. The results indicate that MADRL can significantly enhance the capability of autonomous cyber defense systems, paving the way for more intelligent cybersecurity strategies. This study contributes to the growing body of knowledge on leveraging artificial intelligence for cybersecurity and sheds light for future research and development in autonomous cyber operations.</li>
</ul>

<h3>Title: Enabling Advanced Land Cover Analytics: An Integrated Data Extraction Pipeline for Predictive Modeling with the Dynamic World Dataset</h3>
<ul>
<li><strong>Authors: </strong>Victor Radermecker, Andrea Zanon, Nancy Thomas, Annita Vapsi, Saba Rahimi, Rama Ramakrishnan, Daniel Borrajo</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.LG, eess.IV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.09135">https://arxiv.org/abs/2410.09135</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.09135">https://arxiv.org/pdf/2410.09135</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.09135]] Enabling Advanced Land Cover Analytics: An Integrated Data Extraction Pipeline for Predictive Modeling with the Dynamic World Dataset(https://arxiv.org/abs/2410.09135)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction</a></li>
<li><strong>Abstract: </strong>Understanding land cover holds considerable potential for a myriad of practical applications, particularly as data accessibility transitions from being exclusive to governmental and commercial entities to now including the broader research community. Nevertheless, although the data is accessible to any community member interested in exploration, there exists a formidable learning curve and no standardized process for accessing, pre-processing, and leveraging the data for subsequent tasks. In this study, we democratize this data by presenting a flexible and efficient end to end pipeline for working with the Dynamic World dataset, a cutting-edge near-real-time land use/land cover (LULC) dataset. This includes a pre-processing and representation framework which tackles noise removal, efficient extraction of large amounts of data, and re-representation of LULC data in a format well suited for several downstream tasks. To demonstrate the power of our pipeline, we use it to extract data for an urbanization prediction problem and build a suite of machine learning models with excellent performance. This task is easily generalizable to the prediction of any type of land cover and our pipeline is also compatible with a series of other downstream tasks.</li>
</ul>

<h3>Title: RealEra: Semantic-level Concept Erasure via Neighbor-Concept Mining</h3>
<ul>
<li><strong>Authors: </strong>Yufan Liu, Jinyang An, Wanqian Zhang, Ming Li, Dayan Wu, Jingzi Gu, Zheng Lin, Weiping Wang</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.09140">https://arxiv.org/abs/2410.09140</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.09140">https://arxiv.org/pdf/2410.09140</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.09140]] RealEra: Semantic-level Concept Erasure via Neighbor-Concept Mining(https://arxiv.org/abs/2410.09140)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, protect</a></li>
<li><strong>Abstract: </strong>The remarkable development of text-to-image generation models has raised notable security concerns, such as the infringement of portrait rights and the generation of inappropriate content. Concept erasure has been proposed to remove the model's knowledge about protected and inappropriate concepts. Although many methods have tried to balance the efficacy (erasing target concepts) and specificity (retaining irrelevant concepts), they can still generate abundant erasure concepts under the steering of semantically related inputs. In this work, we propose RealEra to address this "concept residue" issue. Specifically, we first introduce the mechanism of neighbor-concept mining, digging out the associated concepts by adding random perturbation into the embedding of erasure concept, thus expanding the erasing range and eliminating the generations even through associated concept inputs. Furthermore, to mitigate the negative impact on the generation of irrelevant concepts caused by the expansion of erasure scope, RealEra preserves the specificity through the beyond-concept regularization. This makes irrelevant concepts maintain their corresponding spatial position, thereby preserving their normal generation performance. We also employ the closed-form solution to optimize weights of U-Net for the cross-attention alignment, as well as the prediction noise alignment with the LoRA module. Extensive experiments on multiple benchmarks demonstrate that RealEra outperforms previous concept erasing methods in terms of superior erasing efficacy, specificity, and generality. More details are available on our project page this https URL .</li>
</ul>

<h3>Title: On Discriminative Probabilistic Modeling for Self-Supervised Representation Learning</h3>
<ul>
<li><strong>Authors: </strong>Bokun Wang, Yunwen Lei, Yiming Ying, Tianbao Yang</a></li>
<li><strong>Subjects: </strong>cs.LG, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.09156">https://arxiv.org/abs/2410.09156</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.09156">https://arxiv.org/pdf/2410.09156</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.09156]] On Discriminative Probabilistic Modeling for Self-Supervised Representation Learning(https://arxiv.org/abs/2410.09156)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>We study the discriminative probabilistic modeling problem on a continuous domain for (multimodal) self-supervised representation learning. To address the challenge of computing the integral in the partition function for each anchor data, we leverage the multiple importance sampling (MIS) technique for robust Monte Carlo integration, which can recover InfoNCE-based contrastive loss as a special case. Within this probabilistic modeling framework, we conduct generalization error analysis to reveal the limitation of current InfoNCE-based contrastive loss for self-supervised representation learning and derive insights for developing better approaches by reducing the error of Monte Carlo integration. To this end, we propose a novel non-parametric method for approximating the sum of conditional densities required by MIS through convex optimization, yielding a new contrastive objective for self-supervised representation learning. Moreover, we design an efficient algorithm for solving the proposed objective. We empirically compare our algorithm to representative baselines on the contrastive image-language pretraining task. Experimental results on the CC3M and CC12M datasets demonstrate the superior overall performance of our algorithm.</li>
</ul>

<h3>Title: Hybrid Training Approaches for LLMs: Leveraging Real and Synthetic Data to Enhance Model Performance in Domain-Specific Applications</h3>
<ul>
<li><strong>Authors: </strong>Alexey Zhezherau, Alexei Yanockin</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.09168">https://arxiv.org/abs/2410.09168</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.09168">https://arxiv.org/pdf/2410.09168</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.09168]] Hybrid Training Approaches for LLMs: Leveraging Real and Synthetic Data to Enhance Model Performance in Domain-Specific Applications(https://arxiv.org/abs/2410.09168)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, large language model</a></li>
<li><strong>Abstract: </strong>This research explores a hybrid approach to fine-tuning large language models (LLMs) by integrating real-world and synthetic data to boost model performance, particularly in generating accurate and contextually relevant responses. By leveraging a dataset combining transcribed real interactions with high-quality synthetic sessions, we aimed to overcome the limitations of scarce, noisy, and domain-specific real data. Synthetic personas and scenarios were employed to enhance training diversity. The study evaluated three models: a base foundational model, a model fine-tuned with real data, and a hybrid fine-tuned model. Experimental results showed that the hybrid model consistently outperformed the others in specific vertical applications, achieving the highest scores across all metrics. Further testing confirmed the hybrid model's superior adaptability and contextual understanding across diverse scenarios. These findings suggest that combining real and synthetic data can significantly improve the robustness and contextual sensitivity of LLMs, particularly in domain-specific and vertical use cases.</li>
</ul>

<h3>Title: Efficient Zero-Knowledge Proofs for Set Membership in Blockchain-Based Sensor Networks: A Novel OR-Aggregation Approach</h3>
<ul>
<li><strong>Authors: </strong>Oleksandr Kuznetsov, Emanuele Frontoni, Marco Arnesano, Kateryna Kuznetsova</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.09169">https://arxiv.org/abs/2410.09169</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.09169">https://arxiv.org/pdf/2410.09169</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.09169]] Efficient Zero-Knowledge Proofs for Set Membership in Blockchain-Based Sensor Networks: A Novel OR-Aggregation Approach(https://arxiv.org/abs/2410.09169)</code><input type="text"></li>
<li><strong>Keywords: </strong>secure, security, privacy</a></li>
<li><strong>Abstract: </strong>Blockchain-based sensor networks offer promising solutions for secure and transparent data management in IoT ecosystems. However, efficient set membership proofs remain a critical challenge, particularly in resource-constrained environments. This paper introduces a novel OR-aggregation approach for zero-knowledge set membership proofs, tailored specifically for blockchain-based sensor networks. We provide a comprehensive theoretical foundation, detailed protocol specification, and rigorous security analysis. Our implementation incorporates optimization techniques for resource-constrained devices and strategies for integration with prominent blockchain platforms. Extensive experimental evaluation demonstrates the superiority of our approach over existing methods, particularly for large-scale deployments. Results show significant improvements in proof size, generation time, and verification efficiency. The proposed OR-aggregation technique offers a scalable and privacy-preserving solution for set membership verification in blockchain-based IoT applications, addressing key limitations of current approaches. Our work contributes to the advancement of efficient and secure data management in large-scale sensor networks, paving the way for wider adoption of blockchain technology in IoT ecosystems.</li>
</ul>

<h3>Title: Context-Aware SQL Error Correction Using Few-Shot Learning -- A Novel Approach Based on NLQ, Error, and SQL Similarity</h3>
<ul>
<li><strong>Authors: </strong>Divyansh Jain, Eric Yang</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.09174">https://arxiv.org/abs/2410.09174</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.09174">https://arxiv.org/pdf/2410.09174</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.09174]] Context-Aware SQL Error Correction Using Few-Shot Learning -- A Novel Approach Based on NLQ, Error, and SQL Similarity(https://arxiv.org/abs/2410.09174)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>In recent years, the demand for automated SQL generation has increased significantly, driven by the need for efficient data querying in various applications. However, generating accurate SQL queries remains a challenge due to the complexity and variability of natural language inputs. This paper introduces a novel few-shot learning-based approach for error correction in SQL generation, enhancing the accuracy of generated queries by selecting the most suitable few-shot error correction examples for a given natural language question (NLQ). In our experiments with the open-source Gretel dataset, the proposed model offers a 39.2% increase in fixing errors from the baseline approach with no error correction and a 10% increase from a simple error correction method. The proposed technique leverages embedding-based similarity measures to identify the closest matches from a repository of few-shot examples. Each example comprises an incorrect SQL query, the resulting error, the correct SQL query, and detailed steps to transform the incorrect query into the correct one. By employing this method, the system can effectively guide the correction of errors in newly generated SQL queries. Our approach demonstrates significant improvements in SQL generation accuracy by providing contextually relevant examples that facilitate error identification and correction. The experimental results highlight the effectiveness of embedding-based selection in enhancing the few-shot learning process, leading to more precise and reliable SQL query generation. This research contributes to the field of automated SQL generation by offering a robust framework for error correction, paving the way for more advanced and user-friendly database interaction tools.</li>
</ul>

<h3>Title: Can a large language model be a gaslighter?</h3>
<ul>
<li><strong>Authors: </strong>Wei Li, Luyao Zhu, Yang Song, Ruixi Lin, Rui Mao, Yang You</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.AI, cs.CL, cs.CY, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.09181">https://arxiv.org/abs/2410.09181</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.09181">https://arxiv.org/pdf/2410.09181</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.09181]] Can a large language model be a gaslighter?(https://arxiv.org/abs/2410.09181)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack, large language model</a></li>
<li><strong>Abstract: </strong>Large language models (LLMs) have gained human trust due to their capabilities and helpfulness. However, this in turn may allow LLMs to affect users' mindsets by manipulating language. It is termed as gaslighting, a psychological effect. In this work, we aim to investigate the vulnerability of LLMs under prompt-based and fine-tuning-based gaslighting attacks. Therefore, we propose a two-stage framework DeepCoG designed to: 1) elicit gaslighting plans from LLMs with the proposed DeepGaslighting prompting template, and 2) acquire gaslighting conversations from LLMs through our Chain-of-Gaslighting method. The gaslighting conversation dataset along with a corresponding safe dataset is applied to fine-tuning-based attacks on open-source LLMs and anti-gaslighting safety alignment on these LLMs. Experiments demonstrate that both prompt-based and fine-tuning-based attacks transform three open-source LLMs into gaslighters. In contrast, we advanced three safety alignment strategies to strengthen (by 12.05%) the safety guardrail of LLMs. Our safety alignment strategies have minimal impacts on the utility of LLMs. Empirical studies indicate that an LLM may be a potential gaslighter, even if it passed the harmfulness test on general dangerous queries.</li>
</ul>

<h3>Title: Learning Algorithms Made Simple</h3>
<ul>
<li><strong>Authors: </strong>Noorbakhsh Amiri Golilarz, Elias Hossain, Abdoljalil Addeh, Keyan Alexander Rahimi</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.09186">https://arxiv.org/abs/2410.09186</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.09186">https://arxiv.org/pdf/2410.09186</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.09186]] Learning Algorithms Made Simple(https://arxiv.org/abs/2410.09186)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model, segmentation</a></li>
<li><strong>Abstract: </strong>In this paper, we discuss learning algorithms and their importance in different types of applications which includes training to identify important patterns and features in a straightforward, easy-to-understand manner. We will review the main concepts of artificial intelligence (AI), machine learning (ML), deep learning (DL), and hybrid models. Some important subsets of Machine Learning algorithms such as supervised, unsupervised, and reinforcement learning are also discussed in this paper. These techniques can be used for some important tasks like prediction, classification, and segmentation. Convolutional Neural Networks (CNNs) are used for image and video processing and many more applications. We dive into the architecture of CNNs and how to integrate CNNs with ML algorithms to build hybrid models. This paper explores the vulnerability of learning algorithms to noise, leading to misclassification. We further discuss the integration of learning algorithms with Large Language Models (LLM) to generate coherent responses applicable to many domains such as healthcare, marketing, and finance by learning important patterns from large volumes of data. Furthermore, we discuss the next generation of learning algorithms and how we may have an unified Adaptive and Dynamic Network to perform important tasks. Overall, this article provides brief overview of learning algorithms, exploring their current state, applications and future direction.</li>
</ul>

<h3>Title: Automated Rewards via LLM-Generated Progress Functions</h3>
<ul>
<li><strong>Authors: </strong>Vishnu Sarukkai, Brennan Shacklett, Zander Majercik, Kush Bhatia, Christopher RÃ©, Kayvon Fatahalian</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.09187">https://arxiv.org/abs/2410.09187</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.09187">https://arxiv.org/pdf/2410.09187</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.09187]] Automated Rewards via LLM-Generated Progress Functions(https://arxiv.org/abs/2410.09187)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large Language Models (LLMs) have the potential to automate reward engineering by leveraging their broad domain knowledge across various tasks. However, they often need many iterations of trial-and-error to generate effective reward functions. This process is costly because evaluating every sampled reward function requires completing the full policy optimization process for each function. In this paper, we introduce an LLM-driven reward generation framework that is able to produce state-of-the-art policies on the challenging Bi-DexHands benchmark \textbf{with 20$\times$ fewer reward function samples} than the prior state-of-the-art work. Our key insight is that we reduce the problem of generating task-specific rewards to the problem of coarsely estimating \emph{task progress}. Our two-step solution leverages the task domain knowledge and the code synthesis abilities of LLMs to author \emph{progress functions} that estimate task progress from a given state. Then, we use this notion of progress to discretize states, and generate count-based intrinsic rewards using the low-dimensional state space. We show that the combination of LLM-generated progress functions and count-based intrinsic rewards is essential for our performance gains, while alternatives such as generic hash-based counts or using progress directly as a reward function fall short.</li>
</ul>

<h3>Title: Long Range Named Entity Recognition for Marathi Documents</h3>
<ul>
<li><strong>Authors: </strong>Pranita Deshmukh, Nikita Kulkarni, Sanhita Kulkarni, Kareena Manghani, Geetanjali Kale, Raviraj Joshi</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.09192">https://arxiv.org/abs/2410.09192</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.09192">https://arxiv.org/pdf/2410.09192</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.09192]] Long Range Named Entity Recognition for Marathi Documents(https://arxiv.org/abs/2410.09192)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>The demand for sophisticated natural language processing (NLP) methods, particularly Named Entity Recognition (NER), has increased due to the exponential growth of Marathi-language digital content. In particular, NER is essential for recognizing distant entities and for arranging and understanding unstructured Marathi text data. With an emphasis on managing long-range entities, this paper offers a comprehensive analysis of current NER techniques designed for Marathi documents. It dives into current practices and investigates the BERT transformer model's potential for long-range Marathi NER. Along with analyzing the effectiveness of earlier methods, the report draws comparisons between NER in English literature and suggests adaptation strategies for Marathi literature. The paper discusses the difficulties caused by Marathi's particular linguistic traits and contextual subtleties while acknowledging NER's critical role in NLP. To conclude, this project is a major step forward in improving Marathi NER techniques, with potential wider applications across a range of NLP tasks and domains.</li>
</ul>

<h3>Title: AI security and cyber risk in IoT systems</h3>
<ul>
<li><strong>Authors: </strong>Petar Radanliev, David De Roure, Carsten Maple, Jason R.C. Nurse, Razvan Nicolescu, Uchenna Ani</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.AI, cs.SE</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.09194">https://arxiv.org/abs/2410.09194</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.09194">https://arxiv.org/pdf/2410.09194</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.09194]] AI security and cyber risk in IoT systems(https://arxiv.org/abs/2410.09194)</code><input type="text"></li>
<li><strong>Keywords: </strong>security</a></li>
<li><strong>Abstract: </strong>We present a dependency model tailored to the context of current challenges in data strategies and make recommendations for the cybersecurity community. The model can be used for cyber risk estimation and assessment and generic risk impact assessment.</li>
</ul>

<h3>Title: An Efficient Contrastive Unimodal Pretraining Method for EHR Time Series Data</h3>
<ul>
<li><strong>Authors: </strong>Ryan King, Shivesh Kodali, Conrad Krueger, Tianbao Yang, Bobak J. Mortazavi</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.09199">https://arxiv.org/abs/2410.09199</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.09199">https://arxiv.org/pdf/2410.09199</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.09199]] An Efficient Contrastive Unimodal Pretraining Method for EHR Time Series Data(https://arxiv.org/abs/2410.09199)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, extraction</a></li>
<li><strong>Abstract: </strong>Machine learning has revolutionized the modeling of clinical timeseries data. Using machine learning, a Deep Neural Network (DNN) can be automatically trained to learn a complex mapping of its input features for a desired task. This is particularly valuable in Electronic Health Record (EHR) databases, where patients often spend extended periods in intensive care units (ICUs). Machine learning serves as an efficient method for extract meaningful information. However, many state-of-the-art (SOTA) methods for training DNNs demand substantial volumes of labeled data, posing significant challenges for clinics in terms of cost and time. Self-supervised learning offers an alternative by allowing practitioners to extract valuable insights from data without the need for costly labels. Yet, current SOTA methods often necessitate large data batches to achieve optimal performance, increasing computational demands. This presents a challenge when working with long clinical timeseries data. To address this, we propose an efficient method of contrastive pretraining tailored for long clinical timeseries data. Our approach utilizes an estimator for negative pair comparison, enabling effective feature extraction. We assess the efficacy of our pretraining using standard self-supervised tasks such as linear evaluation and semi-supervised learning. Additionally, our model demonstrates the ability to impute missing measurements, providing clinicians with deeper insights into patient conditions. We demonstrate that our pretraining is capable of achieving better performance as both the size of the model and the size of the measurement vocabulary scale. Finally, we externally validate our model, trained on the MIMIC-III dataset, using the eICU dataset. We demonstrate that our model is capable of learning robust clinical information that is transferable to other clinics.</li>
</ul>

<h3>Title: Encoding Agent Trajectories as Representations with Sequence Transformers</h3>
<ul>
<li><strong>Authors: </strong>Athanasios Tsiligkaridis, Nicholas Kalinowski, Zhongheng Li, Elizabeth Hou</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.09204">https://arxiv.org/abs/2410.09204</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.09204">https://arxiv.org/pdf/2410.09204</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.09204]] Encoding Agent Trajectories as Representations with Sequence Transformers(https://arxiv.org/abs/2410.09204)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Spatiotemporal data faces many analogous challenges to natural language text including the ordering of locations (words) in a sequence, long range dependencies between locations, and locations having multiple meanings. In this work, we propose a novel model for representing high dimensional spatiotemporal trajectories as sequences of discrete locations and encoding them with a Transformer-based neural network architecture. Similar to language models, our Sequence Transformer for Agent Representation Encodings (STARE) model can learn representations and structure in trajectory data through both supervisory tasks (e.g., classification), and self-supervisory tasks (e.g., masked modelling). We present experimental results on various synthetic and real trajectory datasets and show that our proposed model can learn meaningful encodings that are useful for many downstream tasks including discriminating between labels and indicating similarity between locations. Using these encodings, we also learn relationships between agents and locations present in spatiotemporal data.</li>
</ul>

<h3>Title: Cross-Domain Distribution Alignment for Segmentation of Private Unannotated 3D Medical Images</h3>
<ul>
<li><strong>Authors: </strong>Ruitong Sun, Mohammad Rostami</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.09210">https://arxiv.org/abs/2410.09210</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.09210">https://arxiv.org/pdf/2410.09210</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.09210]] Cross-Domain Distribution Alignment for Segmentation of Private Unannotated 3D Medical Images(https://arxiv.org/abs/2410.09210)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, segmentation</a></li>
<li><strong>Abstract: </strong>Manual annotation of 3D medical images for segmentation tasks is tedious and time-consuming. Moreover, data privacy limits the applicability of crowd sourcing to perform data annotation in medical domains. As a result, training deep neural networks for medical image segmentation can be challenging. We introduce a new source-free Unsupervised Domain Adaptation (UDA) method to address this problem. Our idea is based on estimating the internally learned distribution of a relevant source domain by a base model and then generating pseudo-labels that are used for enhancing the model refinement through self-training. We demonstrate that our approach leads to SOTA performance on a real-world 3D medical dataset.</li>
</ul>

<h3>Title: M3Hop-CoT: Misogynous Meme Identification with Multimodal Multi-hop Chain-of-Thought</h3>
<ul>
<li><strong>Authors: </strong>Gitanjali Kumari, Kirtan Jain, Asif Ekbal</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.CY, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.09220">https://arxiv.org/abs/2410.09220</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.09220">https://arxiv.org/pdf/2410.09220</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.09220]] M3Hop-CoT: Misogynous Meme Identification with Multimodal Multi-hop Chain-of-Thought(https://arxiv.org/abs/2410.09220)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>In recent years, there has been a significant rise in the phenomenon of hate against women on social media platforms, particularly through the use of misogynous memes. These memes often target women with subtle and obscure cues, making their detection a challenging task for automated systems. Recently, Large Language Models (LLMs) have shown promising results in reasoning using Chain-of-Thought (CoT) prompting to generate the intermediate reasoning chains as the rationale to facilitate multimodal tasks, but often neglect cultural diversity and key aspects like emotion and contextual knowledge hidden in the visual modalities. To address this gap, we introduce a Multimodal Multi-hop CoT (M3Hop-CoT) framework for Misogynous meme identification, combining a CLIP-based classifier and a multimodal CoT module with entity-object-relationship integration. M3Hop-CoT employs a three-step multimodal prompting principle to induce emotions, target awareness, and contextual knowledge for meme analysis. Our empirical evaluation, including both qualitative and quantitative analysis, validates the efficacy of the M3Hop-CoT framework on the SemEval-2022 Task 5 (MAMI task) dataset, highlighting its strong performance in the macro-F1 score. Furthermore, we evaluate the model's generalizability by evaluating it on various benchmark meme datasets, offering a thorough insight into the effectiveness of our approach across different datasets.</li>
</ul>

<h3>Title: The Same But Different: Structural Similarities and Differences in Multilingual Language Modeling</h3>
<ul>
<li><strong>Authors: </strong>Ruochen Zhang, Qinan Yu, Matianyu Zang, Carsten Eickhoff, Ellie Pavlick</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.09223">https://arxiv.org/abs/2410.09223</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.09223">https://arxiv.org/pdf/2410.09223</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.09223]] The Same But Different: Structural Similarities and Differences in Multilingual Language Modeling(https://arxiv.org/abs/2410.09223)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability, large language model</a></li>
<li><strong>Abstract: </strong>We employ new tools from mechanistic interpretability in order to ask whether the internal structure of large language models (LLMs) shows correspondence to the linguistic structures which underlie the languages on which they are trained. In particular, we ask (1) when two languages employ the same morphosyntactic processes, do LLMs handle them using shared internal circuitry? and (2) when two languages require different morphosyntactic processes, do LLMs handle them using different internal circuitry? Using English and Chinese multilingual and monolingual models, we analyze the internal circuitry involved in two tasks. We find evidence that models employ the same circuit to handle the same syntactic process independently of the language in which it occurs, and that this is the case even for monolingual models trained completely independently. Moreover, we show that multilingual models employ language-specific components (attention heads and feed-forward networks) when needed to handle linguistic processes (e.g., morphological marking) that only exist in some languages. Together, our results provide new insights into how LLMs trade off between exploiting common structures and preserving linguistic differences when tasked with modeling multiple languages simultaneously.</li>
</ul>

<h3>Title: Fine-Tuning In-House Large Language Models to Infer Differential Diagnosis from Radiology Reports</h3>
<ul>
<li><strong>Authors: </strong>Luoyao Chen, Revant Teotia, Antonio Verdone, Aidan Cardall, Lakshay Tyagi, Yiqiu Shen, Sumit Chopra</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.09234">https://arxiv.org/abs/2410.09234</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.09234">https://arxiv.org/pdf/2410.09234</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.09234]] Fine-Tuning In-House Large Language Models to Infer Differential Diagnosis from Radiology Reports(https://arxiv.org/abs/2410.09234)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, privacy, protect, extraction, large language model</a></li>
<li><strong>Abstract: </strong>Radiology reports summarize key findings and differential diagnoses derived from medical imaging examinations. The extraction of differential diagnoses is crucial for downstream tasks, including patient management and treatment planning. However, the unstructured nature of these reports, characterized by diverse linguistic styles and inconsistent formatting, presents significant challenges. Although proprietary large language models (LLMs) such as GPT-4 can effectively retrieve clinical information, their use is limited in practice by high costs and concerns over the privacy of protected health information (PHI). This study introduces a pipeline for developing in-house LLMs tailored to identify differential diagnoses from radiology reports. We first utilize GPT-4 to create 31,056 labeled reports, then fine-tune open source LLM using this dataset. Evaluated on a set of 1,067 reports annotated by clinicians, the proposed model achieves an average F1 score of 92.1\%, which is on par with GPT-4 (90.8\%). Through this study, we provide a methodology for constructing in-house LLMs that: match the performance of GPT, reduce dependence on expensive proprietary models, and enhance the privacy and security of PHI.</li>
</ul>

<h3>Title: Scaling Gaussian Processes for Learning Curve Prediction via Latent Kronecker Structure</h3>
<ul>
<li><strong>Authors: </strong>Jihao Andreas Lin, Sebastian Ament, Maximilian Balandat, Eytan Bakshy</a></li>
<li><strong>Subjects: </strong>cs.LG, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.09239">https://arxiv.org/abs/2410.09239</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.09239">https://arxiv.org/pdf/2410.09239</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.09239]] Scaling Gaussian Processes for Learning Curve Prediction via Latent Kronecker Structure(https://arxiv.org/abs/2410.09239)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>A key task in AutoML is to model learning curves of machine learning models jointly as a function of model hyper-parameters and training progression. While Gaussian processes (GPs) are suitable for this task, naÃ¯ve GPs require $\mathcal{O}(n^3m^3)$ time and $\mathcal{O}(n^2 m^2)$ space for $n$ hyper-parameter configurations and $\mathcal{O}(m)$ learning curve observations per hyper-parameter. Efficient inference via Kronecker structure is typically incompatible with early-stopping due to missing learning curve values. We impose $\textit{latent Kronecker structure}$ to leverage efficient product kernels while handling missing values. In particular, we interpret the joint covariance matrix of observed values as the projection of a latent Kronecker product. Combined with iterative linear solvers and structured matrix-vector multiplication, our method only requires $\mathcal{O}(n^3 + m^3)$ time and $\mathcal{O}(n^2 + m^2)$ space. We show that our GP model can match the performance of a Transformer on a learning curve prediction task.</li>
</ul>

<h3>Title: nach0-pc: Multi-task Language Model with Molecular Point Cloud Encoder</h3>
<ul>
<li><strong>Authors: </strong>Maksim Kuznetsov, Airat Valiev, Alex Aliper, Daniil Polykovskiy, Elena Tutubalina, Rim Shayakhmetov, Zulfat Miftahutdinov</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.09240">https://arxiv.org/abs/2410.09240</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.09240">https://arxiv.org/pdf/2410.09240</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.09240]] nach0-pc: Multi-task Language Model with Molecular Point Cloud Encoder(https://arxiv.org/abs/2410.09240)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>Recent advancements have integrated Language Models (LMs) into a drug discovery pipeline. However, existing models mostly work with SMILES and SELFIES chemical string representations, which lack spatial features vital for drug discovery. Additionally, attempts to translate chemical 3D structures into text format encounter issues such as excessive length and insufficient atom connectivity information. To address these issues, we introduce nach0-pc, a model combining domain-specific encoder and textual representation to handle spatial arrangement of atoms effectively. Our approach utilizes a molecular point cloud encoder for concise and order-invariant structure representation. We introduce a novel pre-training scheme for molecular point clouds to distillate the knowledge from spatial molecular structures datasets. After fine-tuning within both single-task and multi-task frameworks, nach0-pc demonstrates performance comparable with other diffusion models in terms of generated samples quality across several established spatial molecular generation tasks. Notably, our model is a multi-task approach, in contrast to diffusion models being limited to single tasks. Additionally, it is capable of processing point cloud-related data, which language models are not capable of handling due to memory limitations. These lead to our model having reduced training and inference time while maintaining on par performance.</li>
</ul>

<h3>Title: Sui Generis: Large Language Models for Authorship Attribution and Verification in Latin</h3>
<ul>
<li><strong>Authors: </strong>Gleb Schmidt, Svetlana Gorovaia, Ivan P. Yamshchikov</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.09245">https://arxiv.org/abs/2410.09245</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.09245">https://arxiv.org/pdf/2410.09245</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.09245]] Sui Generis: Large Language Models for Authorship Attribution and Verification in Latin(https://arxiv.org/abs/2410.09245)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, large language model</a></li>
<li><strong>Abstract: </strong>This paper evaluates the performance of Large Language Models (LLMs) in authorship attribution and authorship verification tasks for Latin texts of the Patristic Era. The study showcases that LLMs can be robust in zero-shot authorship verification even on short texts without sophisticated feature engineering. Yet, the models can also be easily "mislead" by semantics. The experiments also demonstrate that steering the model's authorship analysis and decision-making is challenging, unlike what is reported in the studies dealing with high-resource modern languages. Although LLMs prove to be able to beat, under certain circumstances, the traditional baselines, obtaining a nuanced and truly explainable decision requires at best a lot of experimentation.</li>
</ul>

<h3>Title: Benchmark Inflation: Revealing LLM Performance Gaps Using Retro-Holdouts</h3>
<ul>
<li><strong>Authors: </strong>Jacob Haimes, Cenny Wenner, Kunvar Thaman, Vassil Tashev, Clement Neo, Esben Kran, Jason Schreiber</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.09247">https://arxiv.org/abs/2410.09247</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.09247">https://arxiv.org/pdf/2410.09247</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.09247]] Benchmark Inflation: Revealing LLM Performance Gaps Using Retro-Holdouts(https://arxiv.org/abs/2410.09247)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>The training data for many Large Language Models (LLMs) is contaminated with test data. This means that public benchmarks used to assess LLMs are compromised, suggesting a performance gap between benchmark scores and actual capabilities. Ideally, a private holdout set could be used to accurately verify scores. Unfortunately, such datasets do not exist for most benchmarks, and post-hoc construction of sufficiently similar datasets is non-trivial. To address these issues, we introduce a systematic methodology for (i) retrospectively constructing a holdout dataset for a target dataset, (ii) demonstrating the statistical indistinguishability of this retro-holdout dataset, and (iii) comparing LLMs on the two datasets to quantify the performance gap due to the dataset's public availability. Applying these methods to TruthfulQA, we construct and release Retro-Misconceptions, on which we evaluate twenty LLMs and find that some have inflated scores by as much as 16 percentage points. Our results demonstrate that public benchmark scores do not always accurately assess model properties, and underscore the importance of improved data practices in the field.</li>
</ul>

<h3>Title: Few Exemplar-Based General Medical Image Segmentation via Domain-Aware Selective Adaptation</h3>
<ul>
<li><strong>Authors: </strong>Chen Xu, Qiming Huang, Yuqi Hou, Jiangxing Wu, Fan Zhang, Hyung Jin Chang, Jianbo Jiao</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.09254">https://arxiv.org/abs/2410.09254</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.09254">https://arxiv.org/pdf/2410.09254</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.09254]] Few Exemplar-Based General Medical Image Segmentation via Domain-Aware Selective Adaptation(https://arxiv.org/abs/2410.09254)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>Medical image segmentation poses challenges due to domain gaps, data modality variations, and dependency on domain knowledge or experts, especially for low- and middle-income countries (LMICs). Whereas for humans, given a few exemplars (with corresponding labels), we are able to segment different medical images even without exten-sive domain-specific clinical training. In addition, current SAM-based medical segmentation models use fine-grained visual prompts, such as the bounding rectangle generated from manually annotated target segmentation mask, as the bounding box (bbox) prompt during the testing phase. However, in actual clinical scenarios, no such precise prior knowledge is available. Our experimental results also reveal that previous models nearly fail to predict when given coarser bbox prompts. Considering these issues, in this paper, we introduce a domain-aware selective adaptation approach to adapt the general knowledge learned from a large model trained with natural images to the corresponding medical domains/modalities, with access to only a few (e.g. less than 5) exemplars. Our method mitigates the aforementioned limitations, providing an efficient and LMICs-friendly solution. Extensive experimental analysis showcases the effectiveness of our approach, offering potential advancements in healthcare diagnostics and clinical applications in LMICs.</li>
</ul>

<h3>Title: MOZART: Ensembling Approach for COVID-19 Detection using Chest X-Ray Imagery</h3>
<ul>
<li><strong>Authors: </strong>Mohammed Shabo, Nazar Siddig</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.LG, eess.IV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.09255">https://arxiv.org/abs/2410.09255</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.09255">https://arxiv.org/pdf/2410.09255</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.09255]] MOZART: Ensembling Approach for COVID-19 Detection using Chest X-Ray Imagery(https://arxiv.org/abs/2410.09255)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>COVID-19, has led to a global pandemic that strained the healthcare systems. Early and accurate detection is crucial for controlling the spread of the virus. While reverse transcription polymerase chain reaction test is the gold standard for diagnosis, it's limited availability, long processing times and extremely high false negative rate, have prompted the exploration of alternative methods. Chest Xray imaging has emerged as a valuable, non invasive tool for identifying COVID-19 related lung abnormalities. Traditional convolutional neural networks (CNNs) achieve impressive accuracy, but there is a need for more robust solutions to minimize false positives and negatives in critical medical applications. Thus We introduce the MOZART framework, an ensemble learning approach that enhances the virus detection. We trained three CNN architectures InceptionV3, Xception, and ResNet50 on a balanced chest X-ray dataset of 3,616 COVID-19 and 3,616 healthy images. Each model underwent a separate preprocessing pipeline, such as normalizing inputs to a range of -1 to 1. The dataset was split into 70% for training, 20% for validation, and 10% for testing, after training the individual models, we trained a shallow neural network on the predictions and to provide a us with the final predictions. Our results show that the MOZART framework with it's sub-experiments MOZART1 and MOZART2 outperforms individual CNN models in key metrics. It achieved an accuracy of 99.17% and an F1 score of 99.16%. MOZART1 excels at minimizing false positives, while MOZART2 is better for reducing false negatives. This work suggests that the MOZART framework can improve reliability in AI-driven medical imaging tasks and should be explored further for other lung diseases.</li>
</ul>

<h3>Title: Predicting Drug Effects from High-Dimensional, Asymmetric Drug Datasets by Using Graph Neural Networks: A Comprehensive Analysis of Multitarget Drug Effect Prediction</h3>
<ul>
<li><strong>Authors: </strong>Avishek Bose, Guojing Cong</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.09280">https://arxiv.org/abs/2410.09280</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.09280">https://arxiv.org/pdf/2410.09280</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.09280]] Predicting Drug Effects from High-Dimensional, Asymmetric Drug Datasets by Using Graph Neural Networks: A Comprehensive Analysis of Multitarget Drug Effect Prediction(https://arxiv.org/abs/2410.09280)</code><input type="text"></li>
<li><strong>Keywords: </strong>protect</a></li>
<li><strong>Abstract: </strong>Graph neural networks (GNNs) have emerged as one of the most effective ML techniques for drug effect prediction from drug molecular graphs. Despite having immense potential, GNN models lack performance when using datasets that contain high-dimensional, asymmetrically co-occurrent drug effects as targets with complex correlations between them. Training individual learning models for each drug effect and incorporating every prediction result for a wide spectrum of drug effects are impractical. Therefore, an opportunity exists to address this challenge as multitarget prediction problems and predict all drug effects at a time. We developed standard and hybrid GNNs to perform two separate tasks: multiregression for continuous values and multilabel classification for categorical values contained in our datasets. Because multilabel classification makes the target data even more sparse and introduces asymmetric label co-occurrence, learning these models becomes difficult and heavily impacts the GNN's performance. To address these challenges, we propose a new data oversampling technique to improve multilabel classification performances on all the given imbalanced molecular graph datasets. Using the technique, we improve the data imbalance ratio of the drug effects while protecting the datasets' integrity. Finally, we evaluate the multilabel classification performance of the best-performing hybrid GNN model on all the oversampled datasets obtained from the proposed oversampling technique. In all the evaluation metrics (i.e., precision, recall, and F1 score), this model significantly outperforms other ML models, including GNN models when they are trained on the original datasets or oversampled datasets with MLSMOTE, which is a well-known oversampling technique.</li>
</ul>

<h3>Title: Enhanced Federated Anomaly Detection Through Autoencoders Using Summary Statistics-Based Thresholding</h3>
<ul>
<li><strong>Authors: </strong>Sofiane Laridi, Gregory Palmer, Kam-Ming Mark Tam</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.09284">https://arxiv.org/abs/2410.09284</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.09284">https://arxiv.org/pdf/2410.09284</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.09284]] Enhanced Federated Anomaly Detection Through Autoencoders Using Summary Statistics-Based Thresholding(https://arxiv.org/abs/2410.09284)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, robust, federate</a></li>
<li><strong>Abstract: </strong>In Federated Learning (FL), anomaly detection (AD) is a challenging task due to the decentralized nature of data and the presence of non-IID data distributions. This study introduces a novel federated threshold calculation method that leverages summary statistics from both normal and anomalous data to improve the accuracy and robustness of anomaly detection using autoencoders (AE) in a federated setting. Our approach aggregates local summary statistics across clients to compute a global threshold that optimally separates anomalies from normal data while ensuring privacy preservation. We conducted extensive experiments using publicly available datasets, including Credit Card Fraud Detection, Shuttle, and Covertype, under various data distribution scenarios. The results demonstrate that our method consistently outperforms existing federated and local threshold calculation techniques, particularly in handling non-IID data distributions. This study also explores the impact of different data distribution scenarios and the number of clients on the performance of federated anomaly detection. Our findings highlight the potential of using summary statistics for threshold calculation in improving the scalability and accuracy of federated anomaly detection systems.</li>
</ul>

<h3>Title: The 2020 United States Decennial Census Is More Private Than You (Might) Think</h3>
<ul>
<li><strong>Authors: </strong>Buxin Su, Weijie J. Su, Chendi Wang</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.DS, stat.AP, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.09296">https://arxiv.org/abs/2410.09296</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.09296">https://arxiv.org/pdf/2410.09296</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.09296]] The 2020 United States Decennial Census Is More Private Than You (Might) Think(https://arxiv.org/abs/2410.09296)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, protect</a></li>
<li><strong>Abstract: </strong>The U.S. Decennial Census serves as the foundation for many high-profile policy decision-making processes, including federal funding allocation and redistricting. In 2020, the Census Bureau adopted differential privacy to protect the confidentiality of individual responses through a disclosure avoidance system that injects noise into census data tabulations. The Bureau subsequently posed an open question: Could sharper privacy guarantees be obtained for the 2020 U.S. Census compared to their published guarantees, or equivalently, had the nominal privacy budgets been fully utilized? In this paper, we affirmatively address this open problem by demonstrating that between 8.50% and 13.76% of the privacy budget for the 2020 U.S. Census remains unused for each of the eight geographical levels, from the national level down to the block level. This finding is made possible through our precise tracking of privacy losses using $f$-differential privacy, applied to the composition of private queries across various geographical levels. Our analysis indicates that the Census Bureau introduced unnecessarily high levels of injected noise to achieve the claimed privacy guarantee for the 2020 U.S. Census. Consequently, our results enable the Bureau to reduce noise variances by 15.08% to 24.82% while maintaining the same privacy budget for each geographical level, thereby enhancing the accuracy of privatized census statistics. We empirically demonstrate that reducing noise injection into census statistics mitigates distortion caused by privacy constraints in downstream applications of private census data, illustrated through a study examining the relationship between earnings and education.</li>
</ul>

<h3>Title: DeepOSets: Non-Autoregressive In-Context Learning of Supervised Learning Operators</h3>
<ul>
<li><strong>Authors: </strong>Shao-Ting Chiu, Junyuan Hong, Ulisses Braga-Neto</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.09298">https://arxiv.org/abs/2410.09298</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.09298">https://arxiv.org/pdf/2410.09298</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.09298]] DeepOSets: Non-Autoregressive In-Context Learning of Supervised Learning Operators(https://arxiv.org/abs/2410.09298)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>We introduce DeepSets Operator Networks (DeepOSets), an efficient, non-autoregressive neural network architecture for in-context operator learning. In-context learning allows a trained machine learning model to learn from a user prompt without further training. DeepOSets adds in-context learning capabilities to Deep Operator Networks (DeepONets) by combining it with the DeepSets architecture. As the first non-autoregressive model for in-context operator learning, DeepOSets allow the user prompt to be processed in parallel, leading to significant computational savings. Here, we present the application of DeepOSets in the problem of learning supervised learning algorithms, which are operators mapping a finite-dimensional space of labeled data into an infinite-dimensional hypothesis space of prediction functions. In an empirical comparison with a popular autoregressive (transformer-based) model for in-context learning of the least-squares linear regression algorithm, DeepOSets reduced the number of model weights by several orders of magnitude and required a fraction of training and inference time. Furthermore, DeepOSets proved to be less sensitive to noise, outperforming the transformer model in noisy settings.</li>
</ul>

<h3>Title: Nudging: Inference-time Alignment via Model Collaboration</h3>
<ul>
<li><strong>Authors: </strong>Yu Fei, Yasaman Razeghi, Sameer Singh</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.09300">https://arxiv.org/abs/2410.09300</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.09300">https://arxiv.org/pdf/2410.09300</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.09300]] Nudging: Inference-time Alignment via Model Collaboration(https://arxiv.org/abs/2410.09300)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large language models (LLMs) require alignment, such as instruction-tuning or reinforcement learning from human feedback, to effectively and safely follow user instructions. This process necessitates training aligned versions for every model size in each model family, resulting in significant computational overhead. In this work, we propose nudging, a simple, plug-and-play, and training-free algorithm that aligns any base model at inference time using a small aligned model. Nudging is motivated by recent findings that alignment primarily alters the model's behavior on a small subset of stylistic tokens, such as "Sure" or "Thank". We find that base models are significantly more uncertain when generating these tokens. Leveraging this observation, nudging employs a small aligned model to generate nudging tokens to steer the large base model's output toward desired directions when the base model's uncertainty is high. We evaluate the effectiveness of nudging across 3 model families and 13 tasks, covering reasoning, general knowledge, instruction following, and safety benchmarks. Without any additional training, nudging a large base model with a 7x - 14x smaller aligned model achieves zero-shot performance comparable to, and sometimes surpassing, that of large aligned models. For example, nudging OLMo-7b with OLMo-1b-instruct, affecting less than 9% of tokens, achieves a 10% absolute improvement on GSM8K over OLMo-7b-instruct. Unlike prior inference-time tuning methods, nudging enables off-the-shelf collaboration between model families. For instance, nudging Gemma-2-27b with Llama-2-7b-chat outperforms Llama-2-70b-chat on various tasks. Overall, this work introduces a simple yet powerful approach to token-level model collaboration, offering a modular solution to LLM alignment. Our project website: this https URL .</li>
</ul>

<h3>Title: Enhancing Multi-Step Reasoning Abilities of Language Models through Direct Q-Function Optimization</h3>
<ul>
<li><strong>Authors: </strong>Guanlin Liu, Kaixuan Ji, Renjie Zheng, Zheng Wu, Chen Dun, Quanquan Gu, Lin Yan</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.09302">https://arxiv.org/abs/2410.09302</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.09302">https://arxiv.org/pdf/2410.09302</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.09302]] Enhancing Multi-Step Reasoning Abilities of Language Models through Direct Q-Function Optimization(https://arxiv.org/abs/2410.09302)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Reinforcement Learning (RL) plays a crucial role in aligning large language models (LLMs) with human preferences and improving their ability to perform complex tasks. However, current approaches either require significant computational resources due to the use of multiple models and extensive online sampling for training (e.g., PPO) or are framed as bandit problems (e.g., DPO, DRO), which often struggle with multi-step reasoning tasks, such as math problem-solving and complex reasoning that involve long chains of thought. To overcome these limitations, we introduce Direct Q-function Optimization (DQO), which formulates the response generation process as a Markov Decision Process (MDP) and utilizes the soft actor-critic (SAC) framework to optimize a Q-function directly parameterized by the language model. The MDP formulation of DQO offers structural advantages over bandit-based methods, enabling more effective process supervision. Experimental results on two math problem-solving datasets, GSM8K and MATH, demonstrate that DQO outperforms previous methods, establishing it as a promising offline reinforcement learning approach for aligning language models.</li>
</ul>

<h3>Title: TD-Paint: Faster Diffusion Inpainting Through Time Aware Pixel Conditioning</h3>
<ul>
<li><strong>Authors: </strong>Tsiry Mayet, Pourya Shamsolmoali, Simon Bernard, Eric Granger, Romain HÃ©rault, Clement Chatelain</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.09306">https://arxiv.org/abs/2410.09306</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.09306">https://arxiv.org/pdf/2410.09306</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.09306]] TD-Paint: Faster Diffusion Inpainting Through Time Aware Pixel Conditioning(https://arxiv.org/abs/2410.09306)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, generative</a></li>
<li><strong>Abstract: </strong>Diffusion models have emerged as highly effective techniques for inpainting, however, they remain constrained by slow sampling rates. While recent advances have enhanced generation quality, they have also increased sampling time, thereby limiting scalability in real-world applications. We investigate the generative sampling process of diffusion-based inpainting models and observe that these models make minimal use of the input condition during the initial sampling steps. As a result, the sampling trajectory deviates from the data manifold, requiring complex synchronization mechanisms to realign the generation process. To address this, we propose Time-aware Diffusion Paint (TD-Paint), a novel approach that adapts the diffusion process by modeling variable noise levels at the pixel level. This technique allows the model to efficiently use known pixel values from the start, guiding the generation process toward the target manifold. By embedding this information early in the diffusion process, TD-Paint significantly accelerates sampling without compromising image quality. Unlike conventional diffusion-based inpainting models, which require a dedicated architecture or an expensive generation loop, TD-Paint achieves faster sampling times without architectural modifications. Experimental results across three datasets show that TD-Paint outperforms state-of-the-art diffusion models while maintaining lower complexity.</li>
</ul>

<h3>Title: Graph Neural Alchemist: An innovative fully modular architecture for time series-to-graph classification</h3>
<ul>
<li><strong>Authors: </strong>Paulo Coelho, Raul Araju, LuÃ­s Ramos, Samir Saliba, Renato Vimieiro</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.09307">https://arxiv.org/abs/2410.09307</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.09307">https://arxiv.org/pdf/2410.09307</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.09307]] Graph Neural Alchemist: An innovative fully modular architecture for time series-to-graph classification(https://arxiv.org/abs/2410.09307)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>This paper introduces a novel Graph Neural Network (GNN) architecture for time series classification, based on visibility graph representations. Traditional time series classification methods often struggle with high computational complexity and inadequate capture of spatio-temporal dynamics. By representing time series as visibility graphs, it is possible to encode both spatial and temporal dependencies inherent to time series data, while being computationally efficient. Our architecture is fully modular, enabling flexible experimentation with different models and representations. We employ directed visibility graphs encoded with in-degree and PageRank features to improve the representation of time series, ensuring efficient computation while enhancing the model's ability to capture long-range dependencies in the data. We show the robustness and generalization capability of the proposed architecture across a diverse set of classification tasks and against a traditional model. Our work represents a significant advancement in the application of GNNs for time series analysis, offering a powerful and flexible framework for future research and practical implementations.</li>
</ul>

<h3>Title: Impeding LLM-assisted Cheating in Introductory Programming Assignments via Adversarial Perturbations</h3>
<ul>
<li><strong>Authors: </strong>Saiful Islam Salim, Rubin Yuchan Yang, Alexander Cooper, Suryashree Ray, Saumya Debray, Sazzadur Rahaman</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.CY, cs.SE</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.09318">https://arxiv.org/abs/2410.09318</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.09318">https://arxiv.org/pdf/2410.09318</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.09318]] Impeding LLM-assisted Cheating in Introductory Programming Assignments via Adversarial Perturbations(https://arxiv.org/abs/2410.09318)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>While Large language model (LLM)-based programming assistants such as CoPilot and ChatGPT can help improve the productivity of professional software developers, they can also facilitate cheating in introductory computer programming courses. Assuming instructors have limited control over the industrial-strength models, this paper investigates the baseline performance of 5 widely used LLMs on a collection of introductory programming problems, examines adversarial perturbations to degrade their performance, and describes the results of a user study aimed at understanding the efficacy of such perturbations in hindering actual code generation for introductory programming assignments. The user study suggests that i) perturbations combinedly reduced the average correctness score by 77%, ii) the drop in correctness caused by these perturbations was affected based on their detectability.</li>
</ul>

<h3>Title: Token Pruning using a Lightweight Background Aware Vision Transformer</h3>
<ul>
<li><strong>Authors: </strong>Sudhakar Sah, Ravish Kumar, Honnesh Rohmetra, Ehsan Saboori</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.09324">https://arxiv.org/abs/2410.09324</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.09324">https://arxiv.org/pdf/2410.09324</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.09324]] Token Pruning using a Lightweight Background Aware Vision Transformer(https://arxiv.org/abs/2410.09324)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer, segmentation</a></li>
<li><strong>Abstract: </strong>High runtime memory and high latency puts significant constraint on Vision Transformer training and inference, especially on edge devices. Token pruning reduces the number of input tokens to the ViT based on importance criteria of each token. We present a Background Aware Vision Transformer (BAViT) model, a pre-processing block to object detection models like DETR/YOLOS aimed to reduce runtime memory and increase throughput by using a novel approach to identify background tokens in the image. The background tokens can be pruned completely or partially before feeding to a ViT based object detector. We use the semantic information provided by segmentation map and/or bounding box annotation to train a few layers of ViT to classify tokens to either foreground or background. Using 2 layers and 10 layers of BAViT, background and foreground tokens can be separated with 75% and 88% accuracy on VOC dataset and 71% and 80% accuracy on COCO dataset respectively. We show a 2 layer BAViT-small model as pre-processor to YOLOS can increase the throughput by 30% - 40% with a mAP drop of 3% without any sparse fine-tuning and 2% with sparse fine-tuning. Our approach is specifically targeted for Edge AI use cases.</li>
</ul>

<h3>Title: Rethinking Data Selection at Scale: Random Selection is Almost All You Need</h3>
<ul>
<li><strong>Authors: </strong>Tingyu Xia, Bowen Yu, Kai Dang, An Yang, Yuan Wu, Yuan Tian, Yi Chang, Junyang Lin</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.09335">https://arxiv.org/abs/2410.09335</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.09335">https://arxiv.org/pdf/2410.09335</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.09335]] Rethinking Data Selection at Scale: Random Selection is Almost All You Need(https://arxiv.org/abs/2410.09335)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Supervised fine-tuning (SFT) is crucial for aligning Large Language Models (LLMs) with human instructions. The primary goal during SFT is to select a small yet representative subset of training data from the larger pool, such that fine-tuning with this subset achieves results comparable to or even exceeding those obtained using the entire dataset. However, most existing data selection techniques are designed for small-scale data pools, which fail to meet the demands of real-world SFT scenarios. In this paper, we replicated several self-scoring methods those that do not rely on external model assistance on two million scale datasets, and found that nearly all methods struggled to significantly outperform random selection when dealing with such large-scale data pools. Moreover, our comparisons suggest that, during SFT, diversity in data selection is more critical than simply focusing on high quality data. We also analyzed the limitations of several current approaches, explaining why they perform poorly on large-scale datasets and why they are unsuitable for such contexts. Finally, we found that filtering data by token length offers a stable and efficient method for improving results. This approach, particularly when training on long text data, proves highly beneficial for relatively weaker base models, such as Llama3.</li>
</ul>

<h3>Title: Keys to Robust Edits: from Theoretical Insights to Practical Advances</h3>
<ul>
<li><strong>Authors: </strong>Jianhao Yan, Futing Wang, Yun Luo, Yafu Li, Yue Zhang</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.09338">https://arxiv.org/abs/2410.09338</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.09338">https://arxiv.org/pdf/2410.09338</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.09338]] Keys to Robust Edits: from Theoretical Insights to Practical Advances(https://arxiv.org/abs/2410.09338)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, large language model</a></li>
<li><strong>Abstract: </strong>Large language models (LLMs) have revolutionized knowledge storage and retrieval, but face challenges with conflicting and outdated information. Knowledge editing techniques have been proposed to address these issues, yet they struggle with robustness tests involving long contexts, paraphrased subjects, and continuous edits. This work investigates the cause of these failures in locate-and-edit methods, offering theoretical insights into their key-value modeling and deriving mathematical bounds for robust and specific edits, leading to a novel 'group discussion' conceptual model for locate-and-edit methods. Empirical analysis reveals that keys used by current methods fail to meet robustness and specificity requirements. To address this, we propose a Robust Edit Pathway (REP) that disentangles editing keys from LLMs' inner representations. Evaluations on LLaMA2-7B and Mistral-7B using the CounterFact dataset show that REP significantly improves robustness across various metrics, both in-domain and out-of-domain, with minimal trade-offs in success rate and locality. Our findings advance the development of reliable and flexible knowledge updating in LLMs.</li>
</ul>

<h3>Title: LLM$\times$MapReduce: Simplified Long-Sequence Processing using Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Zihan Zhou, Chong Li, Xinyi Chen, Shuo Wang, Yu Chao, Zhili Li, Haoyu Wang, Rongqiao An, Qi Shi, Zhixing Tan, Xu Han, Xiaodong Shi, Zhiyuan Liu, Maosong Sun</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.09342">https://arxiv.org/abs/2410.09342</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.09342">https://arxiv.org/pdf/2410.09342</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.09342]] LLM$\times$MapReduce: Simplified Long-Sequence Processing using Large Language Models(https://arxiv.org/abs/2410.09342)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Enlarging the context window of large language models (LLMs) has become a crucial research area, particularly for applications involving extremely long texts. In this work, we propose a novel training-free framework for processing long texts, utilizing a divide-and-conquer strategy to achieve comprehensive document understanding. The proposed LLM$\times$MapReduce framework splits the entire document into several chunks for LLMs to read and then aggregates the intermediate answers to produce the final output. The main challenge for divide-and-conquer long text processing frameworks lies in the risk of losing essential long-range information when splitting the document, which can lead the model to produce incomplete or incorrect answers based on the segmented texts. Disrupted long-range information can be classified into two categories: inter-chunk dependency and inter-chunk conflict. We design a structured information protocol to better cope with inter-chunk dependency and an in-context confidence calibration mechanism to resolve inter-chunk conflicts. Experimental results demonstrate that LLM$\times$MapReduce can outperform representative open-source and commercial long-context LLMs, and is applicable to several different models.</li>
</ul>

<h3>Title: ELICIT: LLM Augmentation via External In-Context Capability</h3>
<ul>
<li><strong>Authors: </strong>Futing Wang, Jianhao Yan, Yue Zhang, Tao Lin</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.09343">https://arxiv.org/abs/2410.09343</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.09343">https://arxiv.org/pdf/2410.09343</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.09343]] ELICIT: LLM Augmentation via External In-Context Capability(https://arxiv.org/abs/2410.09343)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Enhancing the adaptive capabilities of large language models is a critical pursuit in both research and application. Traditional fine-tuning methods require substantial data and computational resources, especially for enhancing specific capabilities, while in-context learning is limited by the need for appropriate demonstrations and efficient token usage. Inspired by the expression of in-context learned capabilities through task vectors and the concept of modularization, we propose \alg, a framework consisting of two modules designed to effectively store and reuse task vectors to elicit the diverse capabilities of models without additional training or inference tokens. Our comprehensive experiments and analysis demonstrate that our pipeline is highly transferable across different input formats, tasks, and model architectures. ELICIT serves as a plug-and-play performance booster to enable adaptive elicitation of model capabilities. By externally storing and reusing vectors that represent in-context learned capabilities, \alg not only demonstrates the potential to operate modular capabilities but also significantly enhances the performance, versatility, adaptability, and scalability of large language models. Our code will be publicly available at this https URL.</li>
</ul>

<h3>Title: Toward Guidance-Free AR Visual Generation via Condition Contrastive Alignment</h3>
<ul>
<li><strong>Authors: </strong>Huayu Chen, Hang Su, Peize Sun, Jun Zhu</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.LG, eess.IV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.09347">https://arxiv.org/abs/2410.09347</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.09347">https://arxiv.org/pdf/2410.09347</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.09347]] Toward Guidance-Free AR Visual Generation via Condition Contrastive Alignment(https://arxiv.org/abs/2410.09347)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>Classifier-Free Guidance (CFG) is a critical technique for enhancing the sample quality of visual generative models. However, in autoregressive (AR) multi-modal generation, CFG introduces design inconsistencies between language and visual content, contradicting the design philosophy of unifying different modalities for visual AR. Motivated by language model alignment methods, we propose \textit{Condition Contrastive Alignment} (CCA) to facilitate guidance-free AR visual generation with high performance and analyze its theoretical connection with guided sampling methods. Unlike guidance methods that alter the sampling process to achieve the ideal sampling distribution, CCA directly fine-tunes pretrained models to fit the same distribution target. Experimental results show that CCA can significantly enhance the guidance-free performance of all tested models with just one epoch of fine-tuning ($\sim$ 1\% of pretraining epochs) on the pretraining dataset, on par with guided sampling methods. This largely removes the need for guided sampling in AR visual generation and cuts the sampling cost by half. Moreover, by adjusting training parameters, CCA can achieve trade-offs between sample diversity and fidelity similar to CFG. This experimentally confirms the strong theoretical connection between language-targeted alignment and visual-targeted guidance methods, unifying two previously independent research fields. Code and model weights: this https URL.</li>
</ul>

<h3>Title: BANGS: Game-Theoretic Node Selection for Graph Self-Training</h3>
<ul>
<li><strong>Authors: </strong>Fangxin Wang, Kay Liu, Sourav Medya, Philip S. Yu</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.SI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.09348">https://arxiv.org/abs/2410.09348</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.09348">https://arxiv.org/pdf/2410.09348</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.09348]] BANGS: Game-Theoretic Node Selection for Graph Self-Training(https://arxiv.org/abs/2410.09348)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Graph self-training is a semi-supervised learning method that iteratively selects a set of unlabeled data to retrain the underlying graph neural network (GNN) model and improve its prediction performance. While selecting highly confident nodes has proven effective for self-training, this pseudo-labeling strategy ignores the combinatorial dependencies between nodes and suffers from a local view of the distribution. To overcome these issues, we propose BANGS, a novel framework that unifies the labeling strategy with conditional mutual information as the objective of node selection. Our approach -- grounded in game theory -- selects nodes in a combinatorial fashion and provides theoretical guarantees for robustness under noisy objective. More specifically, unlike traditional methods that rank and select nodes independently, BANGS considers nodes as a collective set in the self-training process. Our method demonstrates superior performance and robustness across various datasets, base models, and hyperparameter settings, outperforming existing techniques. The codebase is available on this https URL .</li>
</ul>

<h3>Title: Inference and Verbalization Functions During In-Context Learning</h3>
<ul>
<li><strong>Authors: </strong>Junyi Tao, Xiaoyin Chen, Nelson F. Liu</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.09349">https://arxiv.org/abs/2410.09349</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.09349">https://arxiv.org/pdf/2410.09349</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.09349]] Inference and Verbalization Functions During In-Context Learning(https://arxiv.org/abs/2410.09349)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large language models (LMs) are capable of in-context learning from a few demonstrations (example-label pairs) to solve new tasks during inference. Despite the intuitive importance of high-quality demonstrations, previous work has observed that, in some settings, ICL performance is minimally affected by irrelevant labels (Min et al., 2022). We hypothesize that LMs perform ICL with irrelevant labels via two sequential processes: an inference function that solves the task, followed by a verbalization function that maps the inferred answer to the label space. Importantly, we hypothesize that the inference function is invariant to remappings of the label space (e.g., "true"/"false" to "cat"/"dog"), enabling LMs to share the same inference function across settings with different label words. We empirically validate this hypothesis with controlled layer-wise interchange intervention experiments. Our findings confirm the hypotheses on multiple datasets and tasks (natural language inference, sentiment analysis, and topic classification) and further suggest that the two functions can be localized in specific layers across various open-sourced models, including GEMMA-7B, MISTRAL-7B-V0.3, GEMMA-2-27B, and LLAMA-3.1-70B.</li>
</ul>

<h3>Title: Generative Subgraph Retrieval for Knowledge Graph-Grounded Dialog Generation</h3>
<ul>
<li><strong>Authors: </strong>Jinyoung Park, Minseok Joo, Joo-Kyung Kim, Hyunwoo J. Kim</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.09350">https://arxiv.org/abs/2410.09350</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.09350">https://arxiv.org/pdf/2410.09350</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.09350]] Generative Subgraph Retrieval for Knowledge Graph-Grounded Dialog Generation(https://arxiv.org/abs/2410.09350)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>Knowledge graph-grounded dialog generation requires retrieving a dialog-relevant subgraph from the given knowledge base graph and integrating it with the dialog history. Previous works typically represent the graph using an external encoder, such as graph neural networks, and retrieve relevant triplets based on the similarity between single-vector representations of triplets and the dialog history. However, these external encoders fail to leverage the rich knowledge of pretrained language models, and the retrieval process is also suboptimal due to the information bottleneck caused by the single-vector abstraction of the dialog history. In this work, we propose Dialog generation with Generative Subgraph Retrieval (DialogGSR), which retrieves relevant knowledge subgraphs by directly generating their token sequences on top of language models. For effective generative subgraph retrieval, we introduce two key methods: (i) structure-aware knowledge graph linearization with self-supervised graph-specific tokens and (ii) graph-constrained decoding utilizing graph structural proximity-based entity informativeness scores for valid and relevant generative retrieval. DialogGSR achieves state-of-the-art performance in knowledge graph-grounded dialog generation, as demonstrated on OpenDialKG and KOMODIS datasets.</li>
</ul>

<h3>Title: On Divergence Measures for Training GFlowNets</h3>
<ul>
<li><strong>Authors: </strong>Tiago da Silva, Eliezer de Souza da Silva, Diego Mesquita</a></li>
<li><strong>Subjects: </strong>cs.LG, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.09355">https://arxiv.org/abs/2410.09355</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.09355">https://arxiv.org/pdf/2410.09355</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.09355]] On Divergence Measures for Training GFlowNets(https://arxiv.org/abs/2410.09355)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>Generative Flow Networks (GFlowNets) are amortized inference models designed to sample from unnormalized distributions over composable objects, with applications in generative modeling for tasks in fields such as causal discovery, NLP, and drug discovery. Traditionally, the training procedure for GFlowNets seeks to minimize the expected log-squared difference between a proposal (forward policy) and a target (backward policy) distribution, which enforces certain flow-matching conditions. While this training procedure is closely related to variational inference (VI), directly attempting standard Kullback-Leibler (KL) divergence minimization can lead to proven biased and potentially high-variance estimators. Therefore, we first review four divergence measures, namely, Renyi-$\alpha$'s, Tsallis-$\alpha$'s, reverse and forward KL's, and design statistically efficient estimators for their stochastic gradients in the context of training GFlowNets. Then, we verify that properly minimizing these divergences yields a provably correct and empirically effective training scheme, often leading to significantly faster convergence than previously proposed optimization. To achieve this, we design control variates based on the REINFORCE leave-one-out and score-matching estimators to reduce the variance of the learning objectives' gradients. Our work contributes by narrowing the gap between GFlowNets training and generalized variational approximations, paving the way for algorithmic ideas informed by the divergence minimization viewpoint.</li>
</ul>

<h3>Title: SeRA: Self-Reviewing and Alignment of Large Language Models using Implicit Reward Margins</h3>
<ul>
<li><strong>Authors: </strong>Jongwoo Ko, Saket Dingliwal, Bhavana Ganesh, Sailik Sengupta, Sravan Bodapati, Aram Galstyan</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.09362">https://arxiv.org/abs/2410.09362</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.09362">https://arxiv.org/pdf/2410.09362</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.09362]] SeRA: Self-Reviewing and Alignment of Large Language Models using Implicit Reward Margins(https://arxiv.org/abs/2410.09362)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Direct alignment algorithms (DAAs), such as direct preference optimization (DPO), have become popular alternatives for Reinforcement Learning from Human Feedback (RLHF) due to their simplicity, efficiency, and stability. However, the preferences used in DAAs are usually collected before the alignment training begins and remain unchanged (off-policy). This can lead to two problems where the policy model (1) picks up on spurious correlations in the dataset (as opposed to learning the intended alignment expressed in the human preference labels), and (2) overfits to feedback on off-policy trajectories that have less likelihood of being generated by an updated policy model. To address these issues, we introduce Self-Reviewing and Alignment (SeRA), a cost-efficient and effective method that can be readily combined with existing DAAs. SeRA comprises of two components: (1) sample selection using implicit reward margins, which helps alleviate over-fitting to some undesired features, and (2) preference bootstrapping using implicit rewards to augment preference data with updated policy models in a cost-efficient manner. Extensive experimentation, including some on instruction-following tasks, demonstrate the effectiveness and generality of SeRA in training LLMs on offline preference datasets with DAAs.</li>
</ul>

<h3>Title: Debiasing Vison-Language Models with Text-Only Training</h3>
<ul>
<li><strong>Authors: </strong>Yunfan Yang, Chaoquan Jiang, Zhiyu Lin, Jinlin Xiao, Jiaming Zhang, Jitao Sang</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.09365">https://arxiv.org/abs/2410.09365</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.09365">https://arxiv.org/pdf/2410.09365</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.09365]] Debiasing Vison-Language Models with Text-Only Training(https://arxiv.org/abs/2410.09365)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, large language model</a></li>
<li><strong>Abstract: </strong>Pre-trained vision-language models (VLMs), such as CLIP, have exhibited remarkable performance across various downstream tasks by aligning text and images in a unified embedding space. However, due to the imbalanced distribution of pre-trained datasets, CLIP suffers from the bias problem in real-world applications. Existing debiasing methods struggle to obtain sufficient image samples for minority groups and incur high costs for group labeling. To address the limitations, we propose a Text-Only Debiasing framework called TOD, leveraging a text-as-image training paradigm to mitigate visual biases. Specifically, this approach repurposes the text encoder to function as an image encoder, thereby eliminating the need for image data. Simultaneously, it utilizes a large language model (LLM) to generate a balanced text dataset, which is then used for prompt tuning. However, we observed that the model overfits to the text modality because label names, serving as supervision signals, appear explicitly in the texts. To address this issue, we further introduce a Multi-Target Prediction (MTP) task that motivates the model to focus on complex contexts and distinguish between target and biased information. Extensive experiments on the Waterbirds and CelebA datasets show that our method significantly improves group robustness, achieving state-of-the-art results among image-free methods and even competitive performance compared to image-supervised methods. Furthermore, the proposed method can be adapted to challenging scenarios with multiple or unknown bias attributes, demonstrating its strong generalization and robustness.</li>
</ul>

<h3>Title: Looped ReLU MLPs May Be All You Need as Practical Programmable Computers</h3>
<ul>
<li><strong>Authors: </strong>Yingyu Liang, Zhizhou Sha, Zhenmei Shi, Zhao Song, Yufa Zhou</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CC</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.09375">https://arxiv.org/abs/2410.09375</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.09375">https://arxiv.org/pdf/2410.09375</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.09375]] Looped ReLU MLPs May Be All You Need as Practical Programmable Computers(https://arxiv.org/abs/2410.09375)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Previous work has demonstrated that attention mechanisms are Turing complete. More recently, it has been shown that a looped 13-layer Transformer can function as a universal programmable computer. In contrast, the multi-layer perceptrons with $\mathsf{ReLU}$ activation ($\mathsf{ReLU}$-$\mathsf{MLP}$), one of the most fundamental components of neural networks, is known to be expressive; specifically, a two-layer neural network is a universal approximator given an exponentially large number of hidden neurons. However, it remains unclear whether a $\mathsf{ReLU}$-$\mathsf{MLP}$ can be made into a universal programmable computer using a practical number of weights. In this work, we provide an affirmative answer that a looped 23-layer $\mathsf{ReLU}$-$\mathsf{MLP}$ is capable to perform the basic necessary operations, effectively functioning as a programmable computer. This indicates that simple modules have stronger expressive power than previously expected and have not been fully explored. Our work provides insights into the mechanisms of neural networks and demonstrates that complex tasks, such as functioning as a programmable computer, do not necessarily require advanced architectures like Transformers.</li>
</ul>

<h3>Title: GEM-VPC: A dual Graph-Enhanced Multimodal integration for Video Paragraph Captioning</h3>
<ul>
<li><strong>Authors: </strong>Eileen Wang, Caren Han, Josiah Poon</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.09377">https://arxiv.org/abs/2410.09377</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.09377">https://arxiv.org/pdf/2410.09377</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.09377]] GEM-VPC: A dual Graph-Enhanced Multimodal integration for Video Paragraph Captioning(https://arxiv.org/abs/2410.09377)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Video Paragraph Captioning (VPC) aims to generate paragraph captions that summarises key events within a video. Despite recent advancements, challenges persist, notably in effectively utilising multimodal signals inherent in videos and addressing the long-tail distribution of words. The paper introduces a novel multimodal integrated caption generation framework for VPC that leverages information from various modalities and external knowledge bases. Our framework constructs two graphs: a 'video-specific' temporal graph capturing major events and interactions between multimodal information and commonsense knowledge, and a 'theme graph' representing correlations between words of a specific theme. These graphs serve as input for a transformer network with a shared encoder-decoder architecture. We also introduce a node selection module to enhance decoding efficiency by selecting the most relevant nodes from the graphs. Our results demonstrate superior performance across benchmark datasets.</li>
</ul>

<h3>Title: Multi-granularity Contrastive Cross-modal Collaborative Generation for End-to-End Long-term Video Question Answering</h3>
<ul>
<li><strong>Authors: </strong>Ting Yu, Kunhao Fu, Jian Zhang, Qingming Huang, Jun Yu</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.09379">https://arxiv.org/abs/2410.09379</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.09379">https://arxiv.org/pdf/2410.09379</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.09379]] Multi-granularity Contrastive Cross-modal Collaborative Generation for End-to-End Long-term Video Question Answering(https://arxiv.org/abs/2410.09379)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>Long-term Video Question Answering (VideoQA) is a challenging vision-and-language bridging task focusing on semantic understanding of untrimmed long-term videos and diverse free-form questions, simultaneously emphasizing comprehensive cross-modal reasoning to yield precise answers. The canonical approaches often rely on off-the-shelf feature extractors to detour the expensive computation overhead, but often result in domain-independent modality-unrelated representations. Furthermore, the inherent gradient blocking between unimodal comprehension and cross-modal interaction hinders reliable answer generation. In contrast, recent emerging successful video-language pre-training models enable cost-effective end-to-end modeling but fall short in domain-specific ratiocination and exhibit disparities in task formulation. Toward this end, we present an entirely end-to-end solution for long-term VideoQA: Multi-granularity Contrastive cross-modal collaborative Generation (MCG) model. To derive discriminative representations possessing high visual concepts, we introduce Joint Unimodal Modeling (JUM) on a clip-bone architecture and leverage Multi-granularity Contrastive Learning (MCL) to harness the intrinsically or explicitly exhibited semantic correspondences. To alleviate the task formulation discrepancy problem, we propose a Cross-modal Collaborative Generation (CCG) module to reformulate VideoQA as a generative task instead of the conventional classification scheme, empowering the model with the capability for cross-modal high-semantic fusion and generation so as to rationalize and answer. Extensive experiments conducted on six publicly available VideoQA datasets underscore the superiority of our proposed method.</li>
</ul>

<h3>Title: LLM-SmartAudit: Advanced Smart Contract Vulnerability Detection</h3>
<ul>
<li><strong>Authors: </strong>Zhiyuan Wei, Jing Sun, Zijiang Zhang, Xianhao Zhang</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.09381">https://arxiv.org/abs/2410.09381</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.09381">https://arxiv.org/pdf/2410.09381</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.09381]] LLM-SmartAudit: Advanced Smart Contract Vulnerability Detection(https://arxiv.org/abs/2410.09381)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, large language model</a></li>
<li><strong>Abstract: </strong>The immutable nature of blockchain technology, while revolutionary, introduces significant security challenges, particularly in smart contracts. These security issues can lead to substantial financial losses. Current tools and approaches often focus on specific types of vulnerabilities. However, a comprehensive tool capable of detecting a wide range of vulnerabilities with high accuracy is lacking. This paper introduces LLM-SmartAudit, a novel framework leveraging the advanced capabilities of Large Language Models (LLMs) to detect and analyze vulnerabilities in smart contracts. Using a multi-agent conversational approach, LLM-SmartAudit employs a collaborative system with specialized agents to enhance the audit process. To evaluate the effectiveness of LLM-SmartAudit, we compiled two distinct datasets: a labeled dataset for benchmarking against traditional tools and a real-world dataset for assessing practical applications. Experimental results indicate that our solution outperforms all traditional smart contract auditing tools, offering higher accuracy and greater efficiency. Furthermore, our framework can detect complex logic vulnerabilities that traditional tools have previously overlooked. Our findings demonstrate that leveraging LLM agents provides a highly effective method for automated smart contract auditing.</li>
</ul>

<h3>Title: CLIP-SCGI: Synthesized Caption-Guided Inversion for Person Re-Identification</h3>
<ul>
<li><strong>Authors: </strong>Qianru Han, Xinwei He, Zhi Liu, Sannyuya Liu, Ying Zhang, Jinhai Xiang</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.09382">https://arxiv.org/abs/2410.09382</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.09382">https://arxiv.org/pdf/2410.09382</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.09382]] CLIP-SCGI: Synthesized Caption-Guided Inversion for Person Re-Identification(https://arxiv.org/abs/2410.09382)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Person re-identification (ReID) has recently benefited from large pretrained vision-language models such as Contrastive Language-Image Pre-Training (CLIP). However, the absence of concrete descriptions necessitates the use of implicit text embeddings, which demand complicated and inefficient training strategies. To address this issue, we first propose one straightforward solution by leveraging existing image captioning models to generate pseudo captions for person images, and thereby boost person re-identification with large vision language models. Using models like the Large Language and Vision Assistant (LLAVA), we generate high-quality captions based on fixed templates that capture key semantic attributes such as gender, clothing, and age. By augmenting ReID training sets from uni-modality (image) to bi-modality (image and text), we introduce CLIP-SCGI, a simple yet effective framework that leverages synthesized captions to guide the learning of discriminative and robust representations. Built on CLIP, CLIP-SCGI fuses image and text embeddings through two modules to enhance the training process. To address quality issues in generated captions, we introduce a caption-guided inversion module that captures semantic attributes from images by converting relevant visual information into pseudo-word tokens based on the descriptions. This approach helps the model better capture key information and focus on relevant regions. The extracted features are then utilized in a cross-modal fusion module, guiding the model to focus on regions semantically consistent with the caption, thereby facilitating the optimization of the visual encoder to extract discriminative and robust representations. Extensive experiments on four popular ReID benchmarks demonstrate that CLIP-SCGI outperforms the state-of-the-art by a significant margin.</li>
</ul>

<h3>Title: Deep Transfer Learning: Model Framework and Error Analysis</h3>
<ul>
<li><strong>Authors: </strong>Yuling Jiao, Huazhen Lin, Yuchen Luo, Jerry Zhijian Yang</a></li>
<li><strong>Subjects: </strong>cs.LG, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.09383">https://arxiv.org/abs/2410.09383</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.09383">https://arxiv.org/pdf/2410.09383</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.09383]] Deep Transfer Learning: Model Framework and Error Analysis(https://arxiv.org/abs/2410.09383)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability</a></li>
<li><strong>Abstract: </strong>This paper presents a framework for deep transfer learning, which aims to leverage information from multi-domain upstream data with a large number of samples $n$ to a single-domain downstream task with a considerably smaller number of samples $m$, where $m \ll n$, in order to enhance performance on downstream task. Our framework has several intriguing features. First, it allows the existence of both shared and specific features among multi-domain data and provides a framework for automatic identification, achieving precise transfer and utilization of information. Second, our model framework explicitly indicates the upstream features that contribute to downstream tasks, establishing a relationship between upstream domains and downstream tasks, thereby enhancing interpretability. Error analysis demonstrates that the transfer under our framework can significantly improve the convergence rate for learning Lipschitz functions in downstream supervised tasks, reducing it from $\tilde{O}(m^{-\frac{1}{2(d+2)}}+n^{-\frac{1}{2(d+2)}})$ ("no transfer") to $\tilde{O}(m^{-\frac{1}{2(d^*+3)}} + n^{-\frac{1}{2(d+2)}})$ ("partial transfer"), and even to $\tilde{O}(m^{-1/2}+n^{-\frac{1}{2(d+2)}})$ ("complete transfer"), where $d^* \ll d$ and $d$ is the dimension of the observed data. Our theoretical findings are substantiated by empirical experiments conducted on image classification datasets, along with a regression dataset.</li>
</ul>

<h3>Title: Mamba4Cast: Efficient Zero-Shot Time Series Forecasting with State Space Models</h3>
<ul>
<li><strong>Authors: </strong>Sathya Kamesh Bhethanabhotla, Omar Swelam, Julien Siems, David Salinas, Frank Hutter</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.09385">https://arxiv.org/abs/2410.09385</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.09385">https://arxiv.org/pdf/2410.09385</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.09385]] Mamba4Cast: Efficient Zero-Shot Time Series Forecasting with State Space Models(https://arxiv.org/abs/2410.09385)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, transformer</a></li>
<li><strong>Abstract: </strong>This paper introduces Mamba4Cast, a zero-shot foundation model for time series forecasting. Based on the Mamba architecture and inspired by Prior-data Fitted Networks (PFNs), Mamba4Cast generalizes robustly across diverse time series tasks without the need for dataset specific fine-tuning. Mamba4Cast's key innovation lies in its ability to achieve strong zero-shot performance on real-world datasets while having much lower inference times than time series foundation models based on the transformer architecture. Trained solely on synthetic data, the model generates forecasts for entire horizons in a single pass, outpacing traditional auto-regressive approaches. Our experiments show that Mamba4Cast performs competitively against other state-of-the-art foundation models in various data sets while scaling significantly better with the prediction length. The source code can be accessed at this https URL.</li>
</ul>

<h3>Title: Fine-grained Attention I/O Complexity: Comprehensive Analysis for Backward Passes</h3>
<ul>
<li><strong>Authors: </strong>Xiaoyu Li, Yingyu Liang, Zhenmei Shi, Zhao Song, Yufa Zhou</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CC, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.09397">https://arxiv.org/abs/2410.09397</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.09397">https://arxiv.org/pdf/2410.09397</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.09397]] Fine-grained Attention I/O Complexity: Comprehensive Analysis for Backward Passes(https://arxiv.org/abs/2410.09397)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large Language Models (LLMs) have demonstrated remarkable capabilities in processing long-context information. However, the quadratic complexity of attention computation with respect to sequence length poses significant computational challenges, and I/O aware algorithms have been proposed. This paper presents a comprehensive analysis of the I/O complexity for attention mechanisms, focusing on backward passes by categorizing into small and large cache scenarios. Using the red-blue pebble game framework, we establish tight bounds on I/O complexity across all cache sizes. We confirm that the de facto standard I/O aware algorithm FlashAttention is optimal for both forward and backward passes for the large cache size scenario. For small cache sizes, we provide an algorithm that improves over existing methods and achieves the tight bounds. Additionally, we extend our analysis to sparse attention, a mainstream speeding-up approach, deriving fine-grained lower bounds for both forward and backward passes and both small and large caches. Our findings complete the theoretical foundation for I/O complexity in attention mechanisms, offering insights for designing efficient algorithms of LLM training and inference.</li>
</ul>

<h3>Title: CtrLoRA: An Extensible and Efficient Framework for Controllable Image Generation</h3>
<ul>
<li><strong>Authors: </strong>Yifeng Xu, Zhenliang He, Shiguang Shan, Xilin Chen</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.09400">https://arxiv.org/abs/2410.09400</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.09400">https://arxiv.org/pdf/2410.09400</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.09400]] CtrLoRA: An Extensible and Efficient Framework for Controllable Image Generation(https://arxiv.org/abs/2410.09400)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>Recently, large-scale diffusion models have made impressive progress in text-to-image (T2I) generation. To further equip these T2I models with fine-grained spatial control, approaches like ControlNet introduce an extra network that learns to follow a condition image. However, for every single condition type, ControlNet requires independent training on millions of data pairs with hundreds of GPU hours, which is quite expensive and makes it challenging for ordinary users to explore and develop new types of conditions. To address this problem, we propose the CtrLoRA framework, which trains a Base ControlNet to learn the common knowledge of image-to-image generation from multiple base conditions, along with condition-specific LoRAs to capture distinct characteristics of each condition. Utilizing our pretrained Base ControlNet, users can easily adapt it to new conditions, requiring as few as 1,000 data pairs and less than one hour of single-GPU training to obtain satisfactory results in most scenarios. Moreover, our CtrLoRA reduces the learnable parameters by 90% compared to ControlNet, significantly lowering the threshold to distribute and deploy the model weights. Extensive experiments on various types of conditions demonstrate the efficiency and effectiveness of our method. Codes and model weights will be released at this https URL.</li>
</ul>

<h3>Title: A Novel Approach to Malicious Code Detection Using CNN-BiLSTM and Feature Fusion</h3>
<ul>
<li><strong>Authors: </strong>Lixia Zhang, Tianxu Liu, Kaihui Shen, Cheng Chen</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.09401">https://arxiv.org/abs/2410.09401</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.09401">https://arxiv.org/pdf/2410.09401</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.09401]] A Novel Approach to Malicious Code Detection Using CNN-BiLSTM and Feature Fusion(https://arxiv.org/abs/2410.09401)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, privacy, robust, extraction</a></li>
<li><strong>Abstract: </strong>With the rapid advancement of Internet technology, the threat of malware to computer systems and network security has intensified. Malware affects individual privacy and security and poses risks to critical infrastructures of enterprises and nations. The increasing quantity and complexity of malware, along with its concealment and diversity, challenge traditional detection techniques. Static detection methods struggle against variants and packed malware, while dynamic methods face high costs and risks that limit their application. Consequently, there is an urgent need for novel and efficient malware detection techniques to improve accuracy and robustness. This study first employs the minhash algorithm to convert binary files of malware into grayscale images, followed by the extraction of global and local texture features using GIST and LBP algorithms. Additionally, the study utilizes IDA Pro to decompile and extract opcode sequences, applying N-gram and tf-idf algorithms for feature vectorization. The fusion of these features enables the model to comprehensively capture the behavioral characteristics of malware. In terms of model construction, a CNN-BiLSTM fusion model is designed to simultaneously process image features and opcode sequences, enhancing classification performance. Experimental validation on multiple public datasets demonstrates that the proposed method significantly outperforms traditional detection techniques in terms of accuracy, recall, and F1 score, particularly in detecting variants and obfuscated malware with greater stability. The research presented in this paper offers new insights into the development of malware detection technologies, validating the effectiveness of feature and model fusion, and holds promising application prospects.</li>
</ul>

<h3>Title: CAMPHOR: Collaborative Agents for Multi-input Planning and High-Order Reasoning On Device</h3>
<ul>
<li><strong>Authors: </strong>Yicheng Fu, Raviteja Anantha, Jianpeng Cheng</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.09407">https://arxiv.org/abs/2410.09407</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.09407">https://arxiv.org/pdf/2410.09407</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.09407]] CAMPHOR: Collaborative Agents for Multi-input Planning and High-Order Reasoning On Device(https://arxiv.org/abs/2410.09407)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, large language model</a></li>
<li><strong>Abstract: </strong>While server-side Large Language Models (LLMs) demonstrate proficiency in function calling and complex reasoning, deploying Small Language Models (SLMs) directly on devices brings opportunities to improve latency and privacy but also introduces unique challenges for accuracy and memory. We introduce CAMPHOR, an innovative on-device SLM multi-agent framework designed to handle multiple user inputs and reason over personal context locally, ensuring privacy is maintained. CAMPHOR employs a hierarchical architecture where a high-order reasoning agent decomposes complex tasks and coordinates expert agents responsible for personal context retrieval, tool interaction, and dynamic plan generation. By implementing parameter sharing across agents and leveraging prompt compression, we significantly reduce model size, latency, and memory usage. To validate our approach, we present a novel dataset capturing multi-agent task trajectories centered on personalized mobile assistant use-cases. Our experiments reveal that fine-tuned SLM agents not only surpass closed-source LLMs in task completion F1 by~35\% but also eliminate the need for server-device communication, all while enhancing privacy.</li>
</ul>

<h3>Title: Distribution-aware Noisy-label Crack Segmentation</h3>
<ul>
<li><strong>Authors: </strong>Xiaoyan Jiang, Xinlong Wan, Kaiying Zhu, Xihe Qiu, Zhijun Fang</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.09409">https://arxiv.org/abs/2410.09409</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.09409">https://arxiv.org/pdf/2410.09409</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.09409]] Distribution-aware Noisy-label Crack Segmentation(https://arxiv.org/abs/2410.09409)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>Road crack segmentation is critical for robotic systems tasked with the inspection, maintenance, and monitoring of road infrastructures. Existing deep learning-based methods for crack segmentation are typically trained on specific datasets, which can lead to significant performance degradation when applied to unseen real-world scenarios. To address this, we introduce the SAM-Adapter, which incorporates the general knowledge of the Segment Anything Model (SAM) into crack segmentation, demonstrating enhanced performance and generalization capabilities. However, the effectiveness of the SAM-Adapter is constrained by noisy labels within small-scale training sets, including omissions and mislabeling of cracks. In this paper, we present an innovative joint learning framework that utilizes distribution-aware domain-specific semantic knowledge to guide the discriminative learning process of the SAM-Adapter. To our knowledge, this is the first approach that effectively minimizes the adverse effects of noisy labels on the supervised learning of the SAM-Adapter. Our experimental results on two public pavement crack segmentation datasets confirm that our method significantly outperforms existing state-of-the-art techniques. Furthermore, evaluations on the completely unseen CFD dataset demonstrate the high cross-domain generalization capability of our model, underscoring its potential for practical applications in crack segmentation.</li>
</ul>

<h3>Title: Towards the Effect of Examples on In-Context Learning: A Theoretical Case Study</h3>
<ul>
<li><strong>Authors: </strong>Pengfei He, Yingqian Cui, Han Xu, Hui Liu, Makoto Yamada, Jiliang Tang, Yue Xing</a></li>
<li><strong>Subjects: </strong>cs.LG, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.09411">https://arxiv.org/abs/2410.09411</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.09411">https://arxiv.org/pdf/2410.09411</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.09411]] Towards the Effect of Examples on In-Context Learning: A Theoretical Case Study(https://arxiv.org/abs/2410.09411)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>In-context learning (ICL) has emerged as a powerful capability for large language models (LLMs) to adapt to downstream tasks by leveraging a few (demonstration) examples. Despite its effectiveness, the mechanism behind ICL remains underexplored. To better understand how ICL integrates the examples with the knowledge learned by the LLM during pre-training (i.e., pre-training knowledge) and how the examples impact ICL, this paper conducts a theoretical study in binary classification tasks. In particular, we introduce a probabilistic model extending from the Gaussian mixture model to exactly quantify the impact of pre-training knowledge, label frequency, and label noise on the prediction accuracy. Based on our analysis, when the pre-training knowledge contradicts the knowledge in the examples, whether ICL prediction relies more on the pre-training knowledge or the examples depends on the number of examples. In addition, the label frequency and label noise of the examples both affect the accuracy of the ICL prediction, where the minor class has a lower accuracy, and how the label noise impacts the accuracy is determined by the specific noise level of the two classes. Extensive simulations are conducted to verify the correctness of the theoretical results, and real-data experiments also align with the theoretical insights. Our work reveals the role of pre-training knowledge and examples in ICL, offering a deeper understanding of LLMs' behaviors in classification tasks.</li>
</ul>

<h3>Title: FB-Bench: A Fine-Grained Multi-Task Benchmark for Evaluating LLMs' Responsiveness to Human Feedback</h3>
<ul>
<li><strong>Authors: </strong>Youquan Li, Miao Zheng, Fan Yang, Guosheng Dong, Bin Cui, Weipeng Chen, Zenan Zhou, Wentao Zhang</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.09412">https://arxiv.org/abs/2410.09412</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.09412">https://arxiv.org/pdf/2410.09412</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.09412]] FB-Bench: A Fine-Grained Multi-Task Benchmark for Evaluating LLMs' Responsiveness to Human Feedback(https://arxiv.org/abs/2410.09412)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Human feedback is crucial in the interactions between humans and Large Language Models (LLMs). However, existing research primarily focuses on benchmarking LLMs in single-turn dialogues. Even in benchmarks designed for multi-turn dialogues, the user inputs are often independent, neglecting the nuanced and complex nature of human feedback within real-world usage scenarios. To fill this research gap, we introduce FB-Bench, a fine-grained, multi-task benchmark designed to evaluate LLMs' responsiveness to human feedback in real-world usage scenarios. Drawing from the two main interaction scenarios, FB-Bench comprises 734 meticulously curated samples, encompassing eight task types, five deficiency types of response, and nine feedback types. We extensively evaluate a broad array of popular LLMs, revealing significant variations in their performance across different interaction scenarios. Further analysis indicates that task, human feedback, and deficiencies of previous responses can also significantly impact LLMs' responsiveness. Our findings underscore both the strengths and limitations of current models, providing valuable insights and directions for future research. Both the toolkits and the dataset of FB-Bench are available at this https URL.</li>
</ul>

<h3>Title: Beyond Exact Match: Semantically Reassessing Event Extraction by Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Yi-Fan Lu, Xian-Ling Mao, Tian Lan, Chen Xu, Heyan Huang</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.09418">https://arxiv.org/abs/2410.09418</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.09418">https://arxiv.org/pdf/2410.09418</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.09418]] Beyond Exact Match: Semantically Reassessing Event Extraction by Large Language Models(https://arxiv.org/abs/2410.09418)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction, large language model</a></li>
<li><strong>Abstract: </strong>Event extraction has gained extensive research attention due to its broad range of applications. However, the current mainstream evaluation method for event extraction relies on token-level exact match, which misjudges numerous semantic-level correct cases. This reliance leads to a significant discrepancy between the evaluated performance of models under exact match criteria and their real performance. To address this problem, we propose RAEE, an automatic evaluation framework that accurately assesses event extraction results at semantic-level instead of token-level. Specifically, RAEE leverages Large Language Models (LLMs) as automatic evaluation agents, incorporating chain-of-thought prompting and an adaptive mechanism to achieve interpretable and adaptive evaluations for precision and recall of triggers and arguments. Extensive experimental results demonstrate that: (1) RAEE achieves a very high correlation with the human average; (2) after reassessing 14 models, including advanced LLMs, on 10 datasets, there is a significant performance gap between exact match and RAEE. The exact match evaluation significantly underestimates the performance of existing event extraction models, particularly underestimating the capabilities of LLMs; (3) fine-grained analysis under RAEE evaluation reveals insightful phenomena worth further exploration. The evaluation toolkit of our proposed RAEE will be publicly released.</li>
</ul>

<h3>Title: VLFeedback: A Large-Scale AI Feedback Dataset for Large Vision-Language Models Alignment</h3>
<ul>
<li><strong>Authors: </strong>Lei Li, Zhihui Xie, Mukai Li, Shunian Chen, Peiyi Wang, Liang Chen, Yazheng Yang, Benyou Wang, Lingpeng Kong, Qi Liu</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.09421">https://arxiv.org/abs/2410.09421</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.09421">https://arxiv.org/pdf/2410.09421</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.09421]] VLFeedback: A Large-Scale AI Feedback Dataset for Large Vision-Language Models Alignment(https://arxiv.org/abs/2410.09421)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack</a></li>
<li><strong>Abstract: </strong>As large vision-language models (LVLMs) evolve rapidly, the demand for high-quality and diverse data to align these models becomes increasingly crucial. However, the creation of such data with human supervision proves costly and time-intensive. In this paper, we investigate the efficacy of AI feedback to scale supervision for aligning LVLMs. We introduce VLFeedback, the first large-scale vision-language feedback dataset, comprising over 82K multi-modal instructions and comprehensive rationales generated by off-the-shelf models without human annotations. To evaluate the effectiveness of AI feedback for vision-language alignment, we train Silkie, an LVLM fine-tuned via direct preference optimization on VLFeedback. Silkie showcases exceptional performance regarding helpfulness, visual faithfulness, and safety metrics. It outperforms its base model by 6.9\% and 9.5\% in perception and cognition tasks, reduces hallucination issues on MMHal-Bench, and exhibits enhanced resilience against red-teaming attacks. Furthermore, our analysis underscores the advantage of AI feedback, particularly in fostering preference diversity to deliver more comprehensive improvements. Our dataset, training code and models are available at this https URL.</li>
</ul>

<h3>Title: FlatQuant: Flatness Matters for LLM Quantization</h3>
<ul>
<li><strong>Authors: </strong>Yuxuan Sun, Ruikang Liu, Haoli Bai, Han Bao, Kang Zhao, Yuening Li, Jiaxin Hu, Xianzhi Yu, Lu Hou, Chun Yuan, Xin Jiang, Wulong Liu, Jun Yao</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.09426">https://arxiv.org/abs/2410.09426</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.09426">https://arxiv.org/pdf/2410.09426</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.09426]] FlatQuant: Flatness Matters for LLM Quantization(https://arxiv.org/abs/2410.09426)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Recently, quantization has been widely used for the compression and acceleration of large language models~(LLMs). Due to the outliers in LLMs, it is crucial to flatten weights and activations to minimize quantization error with the equally spaced quantization points. Prior research explores various pre-quantization transformations to suppress outliers, such as per-channel scaling and Hadamard transformation. However, we observe that these transformed weights and activations can still remain steep and outspread. In this paper, we propose FlatQuant (Fast and Learnable Affine Transformation), a new post-training quantization approach to enhance flatness of weights and activations. Our approach identifies optimal affine transformations tailored to each linear layer, calibrated in hours via a lightweight objective. To reduce runtime overhead, we apply Kronecker decomposition to the transformation matrices, and fuse all operations in FlatQuant into a single kernel. Extensive experiments show that FlatQuant sets up a new state-of-the-art quantization benchmark. For instance, it achieves less than $\textbf{1}\%$ accuracy drop for W4A4 quantization on the LLaMA-3-70B model, surpassing SpinQuant by $\textbf{7.5}\%$. For inference latency, FlatQuant reduces the slowdown induced by pre-quantization transformation from 0.26x of QuaRot to merely $\textbf{0.07x}$, bringing up to $\textbf{2.3x}$ speedup for prefill and $\textbf{1.7x}$ speedup for decoding, respectively. Code is available at: \url{this https URL}.</li>
</ul>

<h3>Title: MTL-LoRA: Low-Rank Adaptation for Multi-Task Learning</h3>
<ul>
<li><strong>Authors: </strong>Yaming Yang, Dilixat Muhtar, Yelong Shen, Yuefeng Zhan, Jianfeng Liu, Yujing Wang, Hao Sun, Denvy Deng, Feng Sun, Qi Zhang, Weizhu Chen, Yunhai Tong</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.09437">https://arxiv.org/abs/2410.09437</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.09437">https://arxiv.org/pdf/2410.09437</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.09437]] MTL-LoRA: Low-Rank Adaptation for Multi-Task Learning(https://arxiv.org/abs/2410.09437)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Parameter-efficient fine-tuning (PEFT) has been widely employed for domain adaptation, with LoRA being one of the most prominent methods due to its simplicity and effectiveness. However, in multi-task learning (MTL) scenarios, LoRA tends to obscure the distinction between tasks by projecting sparse high-dimensional features from different tasks into the same dense low-dimensional intrinsic space. This leads to task interference and suboptimal performance for LoRA and its variants. To tackle this challenge, we propose MTL-LoRA, which retains the advantages of low-rank adaptation while significantly enhancing multi-task learning capabilities. MTL-LoRA augments LoRA by incorporating additional task-adaptive parameters that differentiate task-specific information and effectively capture shared knowledge across various tasks within low-dimensional spaces. This approach enables large language models (LLMs) pre-trained on general corpus to adapt to different target task domains with a limited number of trainable parameters. Comprehensive experimental results, including evaluations on public academic benchmarks for natural language understanding, commonsense reasoning, and image-text understanding, as well as real-world industrial text Ads relevance datasets, demonstrate that MTL-LoRA outperforms LoRA and its various variants with comparable or even fewer learnable parameters in multitask learning.</li>
</ul>

<h3>Title: Interpretable Video based Stress Detection with Self-Refine Chain-of-thought Reasoning</h3>
<ul>
<li><strong>Authors: </strong>Yi Dai</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.09449">https://arxiv.org/abs/2410.09449</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.09449">https://arxiv.org/pdf/2410.09449</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.09449]] Interpretable Video based Stress Detection with Self-Refine Chain-of-thought Reasoning(https://arxiv.org/abs/2410.09449)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability</a></li>
<li><strong>Abstract: </strong>Stress detection is a critical area of research with significant implications for health monitoring and intervention systems. In this paper, we propose a novel interpretable approach for video-based stress detection, leveraging self-refine chain-of-thought reasoning to enhance both accuracy and transparency in decision-making processes. Our method focuses on extracting subtle behavioral and physiological cues from video sequences that indicate stress levels. By incorporating a chain-of-thought reasoning mechanism, the system refines its predictions iteratively, ensuring that the decision-making process can be traced and explained. The model also learns to self-refine through feedback loops, improving its reasoning capabilities over time. We evaluate our approach on several public and private datasets, demonstrating its superior performance in comparison to traditional video-based stress detection methods. Additionally, we provide comprehensive insights into the interpretability of the model's predictions, making the system highly valuable for applications in both healthcare and human-computer interaction domains.</li>
</ul>

<h3>Title: Skipping Computations in Multimodal LLMs</h3>
<ul>
<li><strong>Authors: </strong>Mustafa Shukor, Matthieu Cord</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.09454">https://arxiv.org/abs/2410.09454</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.09454">https://arxiv.org/pdf/2410.09454</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.09454]] Skipping Computations in Multimodal LLMs(https://arxiv.org/abs/2410.09454)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large Language Models (LLMs) have demonstrated remarkable success in both textual and multimodal domains. However, this success often comes with substantial computational costs, particularly when handling lengthy sequences of multimodal inputs. This has sparked many efforts focusing on enhancing efficiency during training and inference. In this study, we investigate the computation redundancy in Multimodal Large Language Models (MLLMs) during inference. We propose different methods to skip computations, such as skipping entire blocks, FFN or self-attention (SA) layers. Additionally, we explore parallelizing certain layers, such as FFN and SA layers. Our findings validate that (1) significant amount of computations can be avoided at inference time, especially for tasks such as Visual Question Answering (VQA). (2) Skipping computations during training can recover 97% of the original performance, even when skipping half of the blocks or removing 70% of the weights. Alternatively, (3) properly training with smaller LLMs can yield comparable performance to LLMs 2 or 3 times larger. To conclude, we extend our investigation to recent MLLMs, such as LLaVA-1.5, showing similar observations. Our work show that there is redundant computations inside MLLMs and thus the potential for significantly improving inference costs without sacrificing performance. The code is available here: this https URL.</li>
</ul>

<h3>Title: VERITAS-NLI : Validation and Extraction of Reliable Information Through Automated Scraping and Natural Language Inference</h3>
<ul>
<li><strong>Authors: </strong>Arjun Shah, Hetansh Shah, Vedica Bafna, Charmi Khandor, Sindhu Nair</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.09455">https://arxiv.org/abs/2410.09455</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.09455">https://arxiv.org/pdf/2410.09455</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.09455]] VERITAS-NLI : Validation and Extraction of Reliable Information Through Automated Scraping and Natural Language Inference(https://arxiv.org/abs/2410.09455)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction, transformer</a></li>
<li><strong>Abstract: </strong>In today's day and age where information is rapidly spread through online platforms, the rise of fake news poses an alarming threat to the integrity of public discourse, societal trust, and reputed news sources. Classical machine learning and Transformer-based models have been extensively studied for the task of fake news detection, however they are hampered by their reliance on training data and are unable to generalize on unseen headlines. To address these challenges, we propose our novel solution, leveraging web-scraping techniques and Natural Language Inference (NLI) models to retrieve external knowledge necessary for verifying the accuracy of a headline. Our system is evaluated on a diverse self-curated evaluation dataset spanning over multiple news channels and broad domains. Our best performing pipeline achieves an accuracy of 84.3% surpassing the best classical Machine Learning model by 33.3% and Bidirectional Encoder Representations from Transformers (BERT) by 31.0% . This highlights the efficacy of combining dynamic web-scraping with Natural Language Inference to find support for a claimed headline in the corresponding externally retrieved knowledge for the task of fake news detection.</li>
</ul>

<h3>Title: Automatic Speech Recognition with BERT and CTC Transformers: A Review</h3>
<ul>
<li><strong>Authors: </strong>Noussaiba Djeffal, Hamza Kheddar, Djamel Addou, Ahmed Cherif Mazari, Yassine Himeur</a></li>
<li><strong>Subjects: </strong>cs.CL, eess.AS</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.09456">https://arxiv.org/abs/2410.09456</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.09456">https://arxiv.org/pdf/2410.09456</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.09456]] Automatic Speech Recognition with BERT and CTC Transformers: A Review(https://arxiv.org/abs/2410.09456)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>This review paper provides a comprehensive analysis of recent advances in automatic speech recognition (ASR) with bidirectional encoder representations from transformers BERT and connectionist temporal classification (CTC) transformers. The paper first introduces the fundamental concepts of ASR and discusses the challenges associated with it. It then explains the architecture of BERT and CTC transformers and their potential applications in ASR. The paper reviews several studies that have used these models for speech recognition tasks and discusses the results obtained. Additionally, the paper highlights the limitations of these models and outlines potential areas for further research. All in all, this review provides valuable insights for researchers and practitioners who are interested in ASR with BERT and CTC transformers.</li>
</ul>

<h3>Title: Power-Softmax: Towards Secure LLM Inference over Encrypted Data</h3>
<ul>
<li><strong>Authors: </strong>Itamar Zimerman, Allon Adir, Ehud Aharoni, Matan Avitan, Moran Baruch, Nir Drucker, Jenny Lerner, Ramy Masalha, Reut Meiri, Omri Soceanu</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.09457">https://arxiv.org/abs/2410.09457</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.09457">https://arxiv.org/pdf/2410.09457</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.09457]] Power-Softmax: Towards Secure LLM Inference over Encrypted Data(https://arxiv.org/abs/2410.09457)</code><input type="text"></li>
<li><strong>Keywords: </strong>secure, privacy, transformer</a></li>
<li><strong>Abstract: </strong>Modern cryptographic methods for implementing privacy-preserving LLMs such as Homomorphic Encryption (HE) require the LLMs to have a polynomial form. Forming such a representation is challenging because Transformers include non-polynomial components, such as Softmax and layer normalization. Previous approaches have either directly approximated pre-trained models with large-degree polynomials, which are less efficient over HE, or replaced non-polynomial components with easier-to-approximate primitives before training, e.g., Softmax with pointwise attention. The latter approach might introduce scalability challenges. We present a new HE-friendly variant of self-attention that offers a stable form for training and is easy to approximate with polynomials for secure inference. Our work introduces the first polynomial LLMs with 32 layers and over a billion parameters, exceeding the size of previous models by more than tenfold. The resulting models demonstrate reasoning and in-context learning (ICL) capabilities comparable to standard transformers of the same size, representing a breakthrough in the field. Finally, we provide a detailed latency breakdown for each computation over encrypted data, paving the way for further optimization, and explore the differences in inductive bias between transformers relying on our HE-friendly variant and standard transformers. Our code is attached as a supplement.</li>
</ul>

<h3>Title: Enhancing Single Image to 3D Generation using Gaussian Splatting and Hybrid Diffusion Priors</h3>
<ul>
<li><strong>Authors: </strong>Hritam Basak, Hadi Tabatabaee, Shreekant Gayaka, Ming-Feng Li, Xin Yang, Cheng-Hao Kuo, Arnie Sen, Min Sun, Zhaozheng Yin</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.09467">https://arxiv.org/abs/2410.09467</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.09467">https://arxiv.org/pdf/2410.09467</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.09467]] Enhancing Single Image to 3D Generation using Gaussian Splatting and Hybrid Diffusion Priors(https://arxiv.org/abs/2410.09467)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>3D object generation from a single image involves estimating the full 3D geometry and texture of unseen views from an unposed RGB image captured in the wild. Accurately reconstructing an object's complete 3D structure and texture has numerous applications in real-world scenarios, including robotic manipulation, grasping, 3D scene understanding, and AR/VR. Recent advancements in 3D object generation have introduced techniques that reconstruct an object's 3D shape and texture by optimizing the efficient representation of Gaussian Splatting, guided by pre-trained 2D or 3D diffusion models. However, a notable disparity exists between the training datasets of these models, leading to distinct differences in their outputs. While 2D models generate highly detailed visuals, they lack cross-view consistency in geometry and texture. In contrast, 3D models ensure consistency across different views but often result in overly smooth textures. We propose bridging the gap between 2D and 3D diffusion models to address this limitation by integrating a two-stage frequency-based distillation loss with Gaussian Splatting. Specifically, we leverage geometric priors in the low-frequency spectrum from a 3D diffusion model to maintain consistent geometry and use a 2D diffusion model to refine the fidelity and texture in the high-frequency spectrum of the generated 3D structure, resulting in more detailed and fine-grained outcomes. Our approach enhances geometric consistency and visual quality, outperforming the current SOTA. Additionally, we demonstrate the easy adaptability of our method for efficient object pose estimation and tracking.</li>
</ul>

<h3>Title: Distilling Invariant Representations with Dual Augmentation</h3>
<ul>
<li><strong>Authors: </strong>Nikolaos Giakoumoglou, Tania Stathaki</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.09474">https://arxiv.org/abs/2410.09474</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.09474">https://arxiv.org/pdf/2410.09474</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.09474]] Distilling Invariant Representations with Dual Augmentation(https://arxiv.org/abs/2410.09474)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Knowledge distillation (KD) has been widely used to transfer knowledge from large, accurate models (teachers) to smaller, efficient ones (students). Recent methods have explored enforcing consistency by incorporating causal interpretations to distill invariant representations. In this work, we extend this line of research by introducing a dual augmentation strategy to promote invariant feature learning in both teacher and student models. Our approach leverages different augmentations applied to both models during distillation, pushing the student to capture robust, transferable features. This dual augmentation strategy complements invariant causal distillation by ensuring that the learned representations remain stable across a wider range of data variations and transformations. Extensive experiments on CIFAR-100 demonstrate the effectiveness of this approach, achieving competitive results in same-architecture KD.</li>
</ul>

<h3>Title: Bridging Gaps: Federated Multi-View Clustering in Heterogeneous Hybrid Views</h3>
<ul>
<li><strong>Authors: </strong>Xinyue Chen, Yazhou Ren, Jie Xu, Fangfei Lin, Xiaorong Pu, Yang Yang</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.09484">https://arxiv.org/abs/2410.09484</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.09484">https://arxiv.org/pdf/2410.09484</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.09484]] Bridging Gaps: Federated Multi-View Clustering in Heterogeneous Hybrid Views(https://arxiv.org/abs/2410.09484)</code><input type="text"></li>
<li><strong>Keywords: </strong>federate</a></li>
<li><strong>Abstract: </strong>Recently, federated multi-view clustering (FedMVC) has emerged to explore cluster structures in multi-view data distributed on multiple clients. Existing approaches often assume that clients are isomorphic and all of them belong to either single-view clients or multi-view clients. Despite their success, these methods also present limitations when dealing with practical FedMVC scenarios involving heterogeneous hybrid views, where a mixture of both single-view and multi-view clients exhibit varying degrees of heterogeneity. In this paper, we propose a novel FedMVC framework, which concurrently addresses two challenges associated with heterogeneous hybrid views, i.e., client gap and view gap. To address the client gap, we design a local-synergistic contrastive learning approach that helps single-view clients and multi-view clients achieve consistency for mitigating heterogeneity among all clients. To address the view gap, we develop a global-specific weighting aggregation method, which encourages global models to learn complementary features from hybrid views. The interplay between local-synergistic contrastive learning and global-specific weighting aggregation mutually enhances the exploration of the data cluster structures distributed on multiple clients. Theoretical analysis and extensive experiments demonstrate that our method can handle the heterogeneous hybrid views in FedMVC and outperforms state-of-the-art methods. The code is available at \url{this https URL}.</li>
</ul>

<h3>Title: Towards Efficient Visual-Language Alignment of the Q-Former for Visual Reasoning Tasks</h3>
<ul>
<li><strong>Authors: </strong>Sungkyung Kim, Adam Lee, Junyoung Park, Andrew Chung, Jusang Oh, Jay-Yoon Lee</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.09489">https://arxiv.org/abs/2410.09489</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.09489">https://arxiv.org/pdf/2410.09489</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.09489]] Towards Efficient Visual-Language Alignment of the Q-Former for Visual Reasoning Tasks(https://arxiv.org/abs/2410.09489)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Recent advancements in large language models have demonstrated enhanced capabilities in visual reasoning tasks by employing additional encoders for aligning different modalities. While the Q-Former has been widely used as a general encoder for aligning several modalities including image, video, audio, and 3D with large language models, previous works on its efficient training and the analysis of its individual components have been limited. In this work, we investigate the effectiveness of parameter efficient fine-tuning (PEFT) the Q-Former using InstructBLIP with visual reasoning benchmarks ScienceQA and IconQA. We observe that applying PEFT to the Q-Former achieves comparable performance to full fine-tuning using under 2% of the trainable parameters. Additionally, we employ AdaLoRA for dynamic parameter budget reallocation to examine the relative importance of the Q-Former's sublayers with 4 different benchmarks. Our findings reveal that the self-attention layers are noticeably more important in perceptual visual-language reasoning tasks, and relative importance of FFN layers depends on the complexity of visual-language patterns involved in tasks. The code is available at this https URL.</li>
</ul>

<h3>Title: A Simple yet Effective Subway Self-positioning Method based on Aerial-view Sleeper Detection</h3>
<ul>
<li><strong>Authors: </strong>Jiajie Song, Ningfang Song, Xiong Pan, Xiaoxin Liu, Can Chen, Jingchun Cheng</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.09492">https://arxiv.org/abs/2410.09492</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.09492">https://arxiv.org/pdf/2410.09492</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.09492]] A Simple yet Effective Subway Self-positioning Method based on Aerial-view Sleeper Detection(https://arxiv.org/abs/2410.09492)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>With the rapid development of urban underground rail vehicles,subway positioning, which plays a fundamental role in the traffic navigation and collision avoidance systems, has become a research hot-spot these years. Most current subway positioning methods rely on localization beacons densely pre-installed alongside the railway tracks, requiring massive costs for infrastructure and maintenance, while commonly lacking flexibility and anti-interference ability. In this paper, we propose a low-cost and real-time visual-assisted self-localization framework to address the robust and convenient positioning problem for subways. Firstly, we perform aerial view rail sleeper detection based on the fast and efficient YOLOv8n network. The detection results are then used to achieve real-time correction of mileage values combined with geometric positioning information, obtaining precise subway locations. Front camera Videos for subway driving scenes along a 6.9 km route are collected and annotated from the simulator for validation of the proposed method. Experimental results show that our aerial view sleeper detection algorithm can efficiently detect sleeper positions with F1-score of 0.929 at 1111 fps, and that the proposed positioning framework achieves a mean percentage error of 0.1\%, demonstrating its continuous and high-precision self-localization capability.</li>
</ul>

<h3>Title: AERA Chat: An Interactive Platform for Automated Explainable Student Answer Assessment</h3>
<ul>
<li><strong>Authors: </strong>Jiazheng Li, Artem Bobrov, David West, Cesare Aloisi, Yulan He</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.09507">https://arxiv.org/abs/2410.09507</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.09507">https://arxiv.org/pdf/2410.09507</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.09507]] AERA Chat: An Interactive Platform for Automated Explainable Student Answer Assessment(https://arxiv.org/abs/2410.09507)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, explainability, large language model</a></li>
<li><strong>Abstract: </strong>Generating rationales that justify scoring decisions has emerged as a promising approach to enhance explainability in the development of automated scoring systems. However, the scarcity of publicly available rationale data and the high cost of annotation have resulted in existing methods typically relying on noisy rationales generated by large language models (LLMs). To address these challenges, we have developed AERA Chat, an interactive platform, to provide visually explained assessment of student answers and streamline the verification of rationales. Users can input questions and student answers to obtain automated, explainable assessment results from LLMs. The platform's innovative visualization features and robust evaluation tools make it useful for educators to assist their marking process, and for researchers to evaluate assessment performance and quality of rationales generated by different LLMs, or as a tool for efficient annotation. We evaluated three rationale generation approaches on our platform to demonstrate its capability.</li>
</ul>

<h3>Title: CollabEdit: Towards Non-destructive Collaborative Knowledge Editing</h3>
<ul>
<li><strong>Authors: </strong>Jiamu Zheng, Jinghuai Zhang, Tianyu Du, Xuhong Zhang, Jianwei Yin, Tao Lin</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.CY</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.09508">https://arxiv.org/abs/2410.09508</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.09508">https://arxiv.org/pdf/2410.09508</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.09508]] CollabEdit: Towards Non-destructive Collaborative Knowledge Editing(https://arxiv.org/abs/2410.09508)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, large language model</a></li>
<li><strong>Abstract: </strong>Collaborative learning of large language models (LLMs) has emerged as a new paradigm for utilizing private data from different parties to guarantee efficiency and privacy. Meanwhile, Knowledge Editing (KE) for LLMs has also garnered increased attention due to its ability to manipulate the behaviors of LLMs explicitly, yet leaves the collaborative KE case (in which knowledge edits of multiple parties are aggregated in a privacy-preserving and continual manner) unexamined. To this end, this manuscript dives into the first investigation of collaborative KE, in which we start by carefully identifying the unique three challenges therein, including knowledge overlap, knowledge conflict, and knowledge forgetting. We then propose a non-destructive collaborative KE framework, COLLABEDIT, which employs a novel model merging mechanism to mimic the global KE behavior while preventing the severe performance drop. Extensive experiments on two canonical datasets demonstrate the superiority of COLLABEDIT compared to other destructive baselines, and results shed light on addressing three collaborative KE challenges and future applications.</li>
</ul>

<h3>Title: LexSumm and LexT5: Benchmarking and Modeling Legal Summarization Tasks in English</h3>
<ul>
<li><strong>Authors: </strong>T.Y.S.S. Santosh, Cornelius Weiss, Matthias Grabmair</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.09527">https://arxiv.org/abs/2410.09527</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.09527">https://arxiv.org/pdf/2410.09527</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.09527]] LexSumm and LexT5: Benchmarking and Modeling Legal Summarization Tasks in English(https://arxiv.org/abs/2410.09527)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>In the evolving NLP landscape, benchmarks serve as yardsticks for gauging progress. However, existing Legal NLP benchmarks only focus on predictive tasks, overlooking generative tasks. This work curates LexSumm, a benchmark designed for evaluating legal summarization tasks in English. It comprises eight English legal summarization datasets, from diverse jurisdictions, such as the US, UK, EU and India. Additionally, we release LexT5, legal oriented sequence-to-sequence model, addressing the limitation of the existing BERT-style encoder-only models in the legal domain. We assess its capabilities through zero-shot probing on LegalLAMA and fine-tuning on LexSumm. Our analysis reveals abstraction and faithfulness errors even in summaries generated by zero-shot LLMs, indicating opportunities for further improvements. LexSumm benchmark and LexT5 model are available at this https URL.</li>
</ul>

<h3>Title: Boosting Deductive Reasoning with Step Signals In RLHF</h3>
<ul>
<li><strong>Authors: </strong>Jialian Li, Yipin Zhang, Wei Shen, Yuzi Yan, Jian Xie, Dong Yan</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.09528">https://arxiv.org/abs/2410.09528</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.09528">https://arxiv.org/pdf/2410.09528</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.09528]] Boosting Deductive Reasoning with Step Signals In RLHF(https://arxiv.org/abs/2410.09528)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Logical reasoning is a crucial task for Large Language Models (LLMs), enabling them to tackle complex problems. Among reasoning tasks, multi-step reasoning poses a particular challenge. Grounded in the theory of formal logic, we have developed an automated method, Multi-step Deduction (MuseD), for deductive reasoning data. MuseD has allowed us to create training and testing datasets for multi-step reasoning. Our generation method enables control over the complexity of the generated instructions, facilitating training and evaluation of models across different difficulty levels. Through RLHF training, our training data has demonstrated significant improvements in logical capabilities for both in-domain of out-of-domain reasoning tasks. Additionally, we have conducted tests to assess the multi-step reasoning abilities of various models.</li>
</ul>

<h3>Title: PrivQuant: Communication-Efficient Private Inference with Quantized Network/Protocol Co-Optimization</h3>
<ul>
<li><strong>Authors: </strong>Tianshi Xu, Shuzhang Zhong, Wenxuan Zeng, Runsheng Wang, Meng Li</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.09531">https://arxiv.org/abs/2410.09531</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.09531">https://arxiv.org/pdf/2410.09531</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.09531]] PrivQuant: Communication-Efficient Private Inference with Quantized Network/Protocol Co-Optimization(https://arxiv.org/abs/2410.09531)</code><input type="text"></li>
<li><strong>Keywords: </strong>secure, privacy, protect</a></li>
<li><strong>Abstract: </strong>Private deep neural network (DNN) inference based on secure two-party computation (2PC) enables secure privacy protection for both the server and the client. However, existing secure 2PC frameworks suffer from a high inference latency due to enormous communication. As the communication of both linear and non-linear DNN layers reduces with the bit widths of weight and activation, in this paper, we propose PrivQuant, a framework that jointly optimizes the 2PC-based quantized inference protocols and the network quantization algorithm, enabling communication-efficient private inference. PrivQuant proposes DNN architecture-aware optimizations for the 2PC protocols for communication-intensive quantized operators and conducts graph-level operator fusion for communication reduction. Moreover, PrivQuant also develops a communication-aware mixed precision quantization algorithm to improve inference efficiency while maintaining high accuracy. The network/protocol co-optimization enables PrivQuant to outperform prior-art 2PC frameworks. With extensive experiments, we demonstrate PrivQuant reduces communication by $11\times, 2.5\times \mathrm{and}~ 2.8\times$, which results in $8.7\times, 1.8\times ~ \mathrm{and}~ 2.4\times$ latency reduction compared with SiRNN, COINN, and CoPriv, respectively.</li>
</ul>

<h3>Title: TOP-ERL: Transformer-based Off-Policy Episodic Reinforcement Learning</h3>
<ul>
<li><strong>Authors: </strong>Ge Li, Dong Tian, Hongyi Zhou, Xinkai Jiang, Rudolf Lioutikov, Gerhard Neumann</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.RO</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.09536">https://arxiv.org/abs/2410.09536</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.09536">https://arxiv.org/pdf/2410.09536</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.09536]] TOP-ERL: Transformer-based Off-Policy Episodic Reinforcement Learning(https://arxiv.org/abs/2410.09536)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>This work introduces Transformer-based Off-Policy Episodic Reinforcement Learning (TOP-ERL), a novel algorithm that enables off-policy updates in the ERL framework. In ERL, policies predict entire action trajectories over multiple time steps instead of single actions at every time step. These trajectories are typically parameterized by trajectory generators such as Movement Primitives (MP), allowing for smooth and efficient exploration over long horizons while capturing high-level temporal correlations. However, ERL methods are often constrained to on-policy frameworks due to the difficulty of evaluating state-action values for entire action sequences, limiting their sample efficiency and preventing the use of more efficient off-policy architectures. TOP-ERL addresses this shortcoming by segmenting long action sequences and estimating the state-action values for each segment using a transformer-based critic architecture alongside an n-step return estimation. These contributions result in efficient and stable training that is reflected in the empirical results conducted on sophisticated robot learning environments. TOP-ERL significantly outperforms state-of-the-art RL methods. Thorough ablation studies additionally show the impact of key design choices on the model performance.</li>
</ul>

<h3>Title: Cybersecurity in Industry 5.0: Open Challenges and Future Directions</h3>
<ul>
<li><strong>Authors: </strong>Bruno Santos, RogÃ©rio LuÃ­s C. Costa, Leonel Santos</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.09538">https://arxiv.org/abs/2410.09538</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.09538">https://arxiv.org/pdf/2410.09538</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.09538]] Cybersecurity in Industry 5.0: Open Challenges and Future Directions(https://arxiv.org/abs/2410.09538)</code><input type="text"></li>
<li><strong>Keywords: </strong>secure, security, attack, robust</a></li>
<li><strong>Abstract: </strong>Unlocking the potential of Industry 5.0 hinges on robust cybersecurity measures. This new Industrial Revolution prioritises human-centric values while addressing pressing societal issues such as resource conservation, climate change, and social stability. Recognising the heightened risk of cyberattacks due to the new enabling technologies in Industry 5.0, this paper analyses potential threats and corresponding countermeasures. Furthermore, it evaluates the existing industrial implementation frameworks, which reveals their inadequacy in ensuring a secure transition from Industry 4.0 to Industry 5.0. Consequently, the paper underscores the necessity of developing a new framework centred on cybersecurity to facilitate organisations' secure adoption of Industry 5.0 principles. The creation of such a framework is emphasised as a necessity for organisations.</li>
</ul>

<h3>Title: LINKED: Eliciting, Filtering and Integrating Knowledge in Large Language Model for Commonsense Reasoning</h3>
<ul>
<li><strong>Authors: </strong>Jiachun Li, Pengfei Cao, Chenhao Wang, Zhuoran Jin, Yubo Chen, Kang Liu, Xiaojian Jiang, Jiexin Xu, Jun Zhao</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.09541">https://arxiv.org/abs/2410.09541</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.09541">https://arxiv.org/pdf/2410.09541</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.09541]] LINKED: Eliciting, Filtering and Integrating Knowledge in Large Language Model for Commonsense Reasoning(https://arxiv.org/abs/2410.09541)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large language models (LLMs) sometimes demonstrate poor performance on knowledge-intensive tasks, commonsense reasoning is one of them. Researchers typically address these issues by retrieving related knowledge from knowledge graphs or employing self-enhancement methods to elicit knowledge in LLMs. However, noisy knowledge and invalid reasoning issues hamper their ability to answer questions accurately. To this end, we propose a novel method named eliciting, filtering and integrating knowledge in large language model (LINKED). In it, we design a reward model to filter out the noisy knowledge and take the marginal consistent reasoning module to reduce invalid reasoning. With our comprehensive experiments on two complex commonsense reasoning benchmarks, our method outperforms SOTA baselines (up to 9.0% improvement of accuracy). Besides, to measure the positive and negative impact of the injected knowledge, we propose a new metric called effectiveness-preservation score for the knowledge enhancement works. Finally, through extensive experiments, we conduct an in-depth analysis and find many meaningful conclusions about LLMs in commonsense reasoning tasks.</li>
</ul>

<h3>Title: MIRAGE: Evaluating and Explaining Inductive Reasoning Process in Language Models</h3>
<ul>
<li><strong>Authors: </strong>Jiachun Li, Pengfei Cao, Zhuoran Jin, Yubo Chen, Kang Liu, Jun Zhao</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.09542">https://arxiv.org/abs/2410.09542</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.09542">https://arxiv.org/pdf/2410.09542</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.09542]] MIRAGE: Evaluating and Explaining Inductive Reasoning Process in Language Models(https://arxiv.org/abs/2410.09542)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Inductive reasoning is an essential capability for large language models (LLMs) to achieve higher intelligence, which requires the model to generalize rules from observed facts and then apply them to unseen examples. We present {\scshape Mirage}, a synthetic dataset that addresses the limitations of previous work, specifically the lack of comprehensive evaluation and flexible test data. In it, we evaluate LLMs' capabilities in both the inductive and deductive stages, allowing for flexible variation in input distribution, task scenario, and task difficulty to analyze the factors influencing LLMs' inductive reasoning. Based on these multi-faceted evaluations, we demonstrate that the LLM is a poor rule-based reasoner. In many cases, when conducting inductive reasoning, they do not rely on a correct rule to answer the unseen case. From the perspectives of different prompting methods, observation numbers, and task forms, models tend to consistently conduct correct deduction without correct inductive rules. Besides, we find that LLMs are good neighbor-based reasoners. In the inductive reasoning process, the model tends to focus on observed facts that are close to the current test example in feature space. By leveraging these similar examples, the model maintains strong inductive capabilities within a localized region, significantly improving its deductive performance.</li>
</ul>

<h3>Title: DiffuTraj: A Stochastic Vessel Trajectory Prediction Approach via Guided Diffusion Process</h3>
<ul>
<li><strong>Authors: </strong>Changlin Li, Yanglei Gan, Tian Lan, Yuxiang Cai, Xueyi Liu, Run Lin, Qiao Liu</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.09550">https://arxiv.org/abs/2410.09550</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.09550">https://arxiv.org/pdf/2410.09550</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.09550]] DiffuTraj: A Stochastic Vessel Trajectory Prediction Approach via Guided Diffusion Process(https://arxiv.org/abs/2410.09550)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, transformer</a></li>
<li><strong>Abstract: </strong>Maritime vessel maneuvers, characterized by their inherent complexity and indeterminacy, requires vessel trajectory prediction system capable of modeling the multi-modality nature of future motion states. Conventional stochastic trajectory prediction methods utilize latent variables to represent the multi-modality of vessel motion, however, tends to overlook the complexity and dynamics inherent in maritime behavior. In contrast, we explicitly simulate the transition of vessel motion from uncertainty towards a state of certainty, effectively handling future indeterminacy in dynamic scenes. In this paper, we present a novel framework (\textit{DiffuTraj}) to conceptualize the trajectory prediction task as a guided reverse process of motion pattern uncertainty diffusion, in which we progressively remove uncertainty from maritime regions to delineate the intended trajectory. Specifically, we encode the previous states of the target vessel, vessel-vessel interactions, and the environment context as guiding factors for trajectory generation. Subsequently, we devise a transformer-based conditional denoiser to capture spatio-temporal dependencies, enabling the generation of trajectories better aligned for particular maritime environment. Comprehensive experiments on vessel trajectory prediction benchmarks demonstrate the superiority of our method.</li>
</ul>

<h3>Title: Robust Optical Flow Computation: A Higher-Order Differential Approach</h3>
<ul>
<li><strong>Authors: </strong>Chanuka Algama, Kasun Amarasinghe</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.09563">https://arxiv.org/abs/2410.09563</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.09563">https://arxiv.org/pdf/2410.09563</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.09563]] Robust Optical Flow Computation: A Higher-Order Differential Approach(https://arxiv.org/abs/2410.09563)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>In the domain of computer vision, optical flow stands as a cornerstone for unraveling dynamic visual scenes. However, the challenge of accurately estimating optical flow under conditions of large nonlinear motion patterns remains an open question. The image flow constraint is vulnerable to substantial displacements, and rapid spatial transformations. Inaccurate approximations inherent in numerical differentiation techniques can further amplify such intricacies. In response, this research proposes an innovative algorithm for optical flow computation, utilizing the higher precision of second-order Taylor series approximation within the differential estimation framework. By embracing this mathematical underpinning, the research seeks to extract more information about the behavior of the function under complex real-world scenarios and estimate the motion of areas with a lack of texture. An impressive showcase of the algorithm's capabilities emerges through its performance on renowned optical flow benchmarks such as KITTI (2015) and Middlebury. The average endpoint error (AEE), which computes the Euclidian distance between the calculated flow field and the ground truth flow field, stands notably diminished, validating the effectiveness of the algorithm in handling complex motion patterns.</li>
</ul>

<h3>Title: Extended Japanese Commonsense Morality Dataset with Masked Token and Label Enhancement</h3>
<ul>
<li><strong>Authors: </strong>Takumi Ohashi, Tsubasa Nakagawa, Hitoshi Iyatomi</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.09564">https://arxiv.org/abs/2410.09564</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.09564">https://arxiv.org/pdf/2410.09564</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.09564]] Extended Japanese Commonsense Morality Dataset with Masked Token and Label Enhancement(https://arxiv.org/abs/2410.09564)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Rapid advancements in artificial intelligence (AI) have made it crucial to integrate moral reasoning into AI systems. However, existing models and datasets often overlook regional and cultural differences. To address this shortcoming, we have expanded the JCommonsenseMorality (JCM) dataset, the only publicly available dataset focused on Japanese morality. The Extended JCM (eJCM) has grown from the original 13,975 sentences to 31,184 sentences using our proposed sentence expansion method called Masked Token and Label Enhancement (MTLE). MTLE selectively masks important parts of sentences related to moral judgment and replaces them with alternative expressions generated by a large language model (LLM), while re-assigning appropriate labels. The model trained using our eJCM achieved an F1 score of 0.857, higher than the scores for the original JCM (0.837), ChatGPT one-shot classification (0.841), and data augmented using AugGPT, a state-of-the-art augmentation method (0.850). Specifically, in complex moral reasoning tasks unique to Japanese culture, the model trained with eJCM showed a significant improvement in performance (increasing from 0.681 to 0.756) and achieved a performance close to that of GPT-4 Turbo (0.787). These results demonstrate the validity of the eJCM dataset and the importance of developing models and datasets that consider the cultural context.</li>
</ul>

<h3>Title: Are You Human? An Adversarial Benchmark to Expose LLMs</h3>
<ul>
<li><strong>Authors: </strong>Gilad Gressel, Rahul Pankajakshan, Yisroel Mirsky</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.09569">https://arxiv.org/abs/2410.09569</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.09569">https://arxiv.org/pdf/2410.09569</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.09569]] Are You Human? An Adversarial Benchmark to Expose LLMs(https://arxiv.org/abs/2410.09569)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large Language Models (LLMs) have demonstrated an alarming ability to impersonate humans in conversation, raising concerns about their potential misuse in scams and deception. Humans have a right to know if they are conversing to an LLM. We evaluate text-based prompts designed as challenges to expose LLM imposters in real-time. To this end we compile and release an open-source benchmark dataset that includes 'implicit challenges' that exploit an LLM's instruction-following mechanism to cause role deviation, and 'exlicit challenges' that test an LLM's ability to perform simple tasks typically easy for humans but difficult for LLMs. Our evaluation of 9 leading models from the LMSYS leaderboard revealed that explicit challenges successfully detected LLMs in 78.4% of cases, while implicit challenges were effective in 22.9% of instances. User studies validate the real-world applicability of our methods, with humans outperforming LLMs on explicit challenges (78% vs 22% success rate). Our framework unexpectedly revealed that many study participants were using LLMs to complete tasks, demonstrating its effectiveness in detecting both AI impostors and human misuse of AI tools. This work addresses the critical need for reliable, real-time LLM detection methods in high-stakes conversations.</li>
</ul>

<h3>Title: The Future of Learning in the Age of Generative AI: Automated Question Generation and Assessment with Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Subhankar Maity, Aniket Deroy</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.09576">https://arxiv.org/abs/2410.09576</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.09576">https://arxiv.org/pdf/2410.09576</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.09576]] The Future of Learning in the Age of Generative AI: Automated Question Generation and Assessment with Large Language Models(https://arxiv.org/abs/2410.09576)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative, large language model</a></li>
<li><strong>Abstract: </strong>In recent years, large language models (LLMs) and generative AI have revolutionized natural language processing (NLP), offering unprecedented capabilities in education. This chapter explores the transformative potential of LLMs in automated question generation and answer assessment. It begins by examining the mechanisms behind LLMs, emphasizing their ability to comprehend and generate human-like text. The chapter then discusses methodologies for creating diverse, contextually relevant questions, enhancing learning through tailored, adaptive strategies. Key prompting techniques, such as zero-shot and chain-of-thought prompting, are evaluated for their effectiveness in generating high-quality questions, including open-ended and multiple-choice formats in various languages. Advanced NLP methods like fine-tuning and prompt-tuning are explored for their role in generating task-specific questions, despite associated costs. The chapter also covers the human evaluation of generated questions, highlighting quality variations across different methods and areas for improvement. Furthermore, it delves into automated answer assessment, demonstrating how LLMs can accurately evaluate responses, provide constructive feedback, and identify nuanced understanding or misconceptions. Examples illustrate both successful assessments and areas needing improvement. The discussion underscores the potential of LLMs to replace costly, time-consuming human assessments when appropriately guided, showcasing their advanced understanding and reasoning capabilities in streamlining educational processes.</li>
</ul>

<h3>Title: Structure of Artificial Neural Networks -- Empirical Investigations</h3>
<ul>
<li><strong>Authors: </strong>Julian Stier</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.NE</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.09579">https://arxiv.org/abs/2410.09579</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.09579">https://arxiv.org/pdf/2410.09579</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.09579]] Structure of Artificial Neural Networks -- Empirical Investigations(https://arxiv.org/abs/2410.09579)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, generative</a></li>
<li><strong>Abstract: </strong>Within one decade, Deep Learning overtook the dominating solution methods of countless problems of artificial intelligence. ``Deep'' refers to the deep architectures with operations in manifolds of which there are no immediate observations. For these deep architectures some kind of structure is pre-defined -- but what is this structure? With a formal definition for structures of neural networks, neural architecture search problems and solution methods can be formulated under a common framework. Both practical and theoretical questions arise from closing the gap between applied neural architecture search and learning theory. Does structure make a difference or can it be chosen arbitrarily? This work is concerned with deep structures of artificial neural networks and examines automatic construction methods under empirical principles to shed light on to the so called ``black-box models''. Our contributions include a formulation of graph-induced neural networks that is used to pose optimisation problems for neural architecture. We analyse structural properties for different neural network objectives such as correctness, robustness or energy consumption and discuss how structure affects them. Selected automation methods for neural architecture optimisation problems are discussed and empirically analysed. With the insights gained from formalising graph-induced neural networks, analysing structural properties and comparing the applicability of neural architecture search methods qualitatively and quantitatively we advance these methods in two ways. First, new predictive models are presented for replacing computationally expensive evaluation schemes, and second, new generative models for informed sampling during neural architecture search are analysed and discussed.</li>
</ul>

<h3>Title: Improving 3D Finger Traits Recognition via Generalizable Neural Rendering</h3>
<ul>
<li><strong>Authors: </strong>Hongbin Xu, Junduan Huang, Yuer Ma, Zifeng Li, Wenxiong Kang</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.09582">https://arxiv.org/abs/2410.09582</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.09582">https://arxiv.org/pdf/2410.09582</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.09582]] Improving 3D Finger Traits Recognition via Generalizable Neural Rendering(https://arxiv.org/abs/2410.09582)</code><input type="text"></li>
<li><strong>Keywords: </strong>biometric, transformer</a></li>
<li><strong>Abstract: </strong>3D biometric techniques on finger traits have become a new trend and have demonstrated a powerful ability for recognition and anti-counterfeiting. Existing methods follow an explicit 3D pipeline that reconstructs the models first and then extracts features from 3D models. However, these explicit 3D methods suffer from the following problems: 1) Inevitable information dropping during 3D reconstruction; 2) Tight coupling between specific hardware and algorithm for 3D reconstruction. It leads us to a question: Is it indispensable to reconstruct 3D information explicitly in recognition tasks? Hence, we consider this problem in an implicit manner, leaving the nerve-wracking 3D reconstruction problem for learnable neural networks with the help of neural radiance fields (NeRFs). We propose FingerNeRF, a novel generalizable NeRF for 3D finger biometrics. To handle the shape-radiance ambiguity problem that may result in incorrect 3D geometry, we aim to involve extra geometric priors based on the correspondence of binary finger traits like fingerprints or finger veins. First, we propose a novel Trait Guided Transformer (TGT) module to enhance the feature correspondence with the guidance of finger traits. Second, we involve extra geometric constraints on the volume rendering loss with the proposed Depth Distillation Loss and Trait Guided Rendering Loss. To evaluate the performance of the proposed method on different modalities, we collect two new datasets: SCUT-Finger-3D with finger images and SCUT-FingerVein-3D with finger vein images. Moreover, we also utilize the UNSW-3D dataset with fingerprint images for evaluation. In experiments, our FingerNeRF can achieve 4.37% EER on SCUT-Finger-3D dataset, 8.12% EER on SCUT-FingerVein-3D dataset, and 2.90% EER on UNSW-3D dataset, showing the superiority of the proposed implicit method in 3D finger biometrics.</li>
</ul>

<h3>Title: POPoS: Improving Efficient and Robust Facial Landmark Detection with Parallel Optimal Position Search</h3>
<ul>
<li><strong>Authors: </strong>Chong-Yang Xiang, Jun-Yan He, Zhi-Qi Cheng, Xiao Wu, Xian-Sheng Hua</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.09583">https://arxiv.org/abs/2410.09583</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.09583">https://arxiv.org/pdf/2410.09583</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.09583]] POPoS: Improving Efficient and Robust Facial Landmark Detection with Parallel Optimal Position Search(https://arxiv.org/abs/2410.09583)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Achieving a balance between accuracy and efficiency is a critical challenge in facial landmark detection (FLD). This paper introduces the Parallel Optimal Position Search (POPoS), a high-precision encoding-decoding framework designed to address the fundamental limitations of traditional FLD methods. POPoS employs three key innovations: (1) Pseudo-range multilateration is utilized to correct heatmap errors, enhancing the precision of landmark localization. By integrating multiple anchor points, this approach minimizes the impact of individual heatmap inaccuracies, leading to robust overall positioning. (2) To improve the pseudo-range accuracy of selected anchor points, a new loss function, named multilateration anchor loss, is proposed. This loss function effectively enhances the accuracy of the distance map, mitigates the risk of local optima, and ensures optimal solutions. (3) A single-step parallel computation algorithm is introduced, significantly enhancing computational efficiency and reducing processing time. Comprehensive evaluations across five benchmark datasets demonstrate that POPoS consistently outperforms existing methods, particularly excelling in low-resolution scenarios with minimal computational overhead. These features establish POPoS as a highly efficient and accurate tool for FLD, with broad applicability in real-world scenarios. The code is available at this https URL</li>
</ul>

<h3>Title: Toward General Instruction-Following Alignment for Retrieval-Augmented Generation</h3>
<ul>
<li><strong>Authors: </strong>Guanting Dong, Xiaoshuai Song, Yutao Zhu, Runqi Qiao, Zhicheng Dou, Ji-Rong Wen</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.IR, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.09584">https://arxiv.org/abs/2410.09584</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.09584">https://arxiv.org/pdf/2410.09584</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.09584]] Toward General Instruction-Following Alignment for Retrieval-Augmented Generation(https://arxiv.org/abs/2410.09584)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, large language model</a></li>
<li><strong>Abstract: </strong>Following natural instructions is crucial for the effective application of Retrieval-Augmented Generation (RAG) systems. Despite recent advancements in Large Language Models (LLMs), research on assessing and improving instruction-following (IF) alignment within the RAG domain remains limited. To address this issue, we propose VIF-RAG, the first automated, scalable, and verifiable synthetic pipeline for instruction-following alignment in RAG systems. We start by manually crafting a minimal set of atomic instructions (<100) and developing combination rules to synthesize and verify complex instructions for a seed set. We then use supervised models for instruction rewriting while simultaneously generating code to automate the verification of instruction quality via a Python executor. Finally, we integrate these instructions with extensive RAG and general data samples, scaling up to a high-quality VIF-RAG-QA dataset (>100k) through automated processes. To further bridge the gap in instruction-following auto-evaluation for RAG systems, we introduce FollowRAG Benchmark, which includes approximately 3K test samples, covering 22 categories of general instruction constraints and four knowledge-intensive QA datasets. Due to its robust pipeline design, FollowRAG can seamlessly integrate with different RAG benchmarks. Using FollowRAG and eight widely-used IF and foundational abilities benchmarks for LLMs, we demonstrate that VIF-RAG markedly enhances LLM performance across a broad range of general instruction constraints while effectively leveraging its capabilities in RAG scenarios. Further analysis offers practical insights for achieving IF alignment in RAG systems. Our code and datasets are released at this https URL.</li>
</ul>

<h3>Title: Unlearn and Burn: Adversarial Machine Unlearning Requests Destroy Model Accuracy</h3>
<ul>
<li><strong>Authors: </strong>Yangsibo Huang, Daogao Liu, Lynn Chua, Badih Ghazi, Pritish Kamath, Ravi Kumar, Pasin Manurangsi, Milad Nasr, Amer Sinha, Chiyuan Zhang</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.09591">https://arxiv.org/abs/2410.09591</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.09591">https://arxiv.org/pdf/2410.09591</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.09591]] Unlearn and Burn: Adversarial Machine Unlearning Requests Destroy Model Accuracy(https://arxiv.org/abs/2410.09591)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, attack, robust, steal</a></li>
<li><strong>Abstract: </strong>Machine unlearning algorithms, designed for selective removal of training data from models, have emerged as a promising approach to growing privacy concerns. In this work, we expose a critical yet underexplored vulnerability in the deployment of unlearning systems: the assumption that the data requested for removal is always part of the original training set. We present a threat model where an attacker can degrade model accuracy by submitting adversarial unlearning requests for data not present in the training set. We propose white-box and black-box attack algorithms and evaluate them through a case study on image classification tasks using the CIFAR-10 and ImageNet datasets, targeting a family of widely used unlearning methods. Our results show extremely poor test accuracy following the attack: 3.6% on CIFAR-10 and 0.4% on ImageNet for white-box attacks, and 8.5% on CIFAR-10 and 1.3% on ImageNet for black-box attacks. Additionally, we evaluate various verification mechanisms to detect the legitimacy of unlearning requests and reveal the challenges in verification, as most of the mechanisms fail to detect stealthy attacks without severely impairing their ability to process valid requests. These findings underscore the urgent need for research on more robust request verification methods and unlearning protocols, should the deployment of machine unlearning systems become more prevalent in the future.</li>
</ul>

<h3>Title: ControLRM: Fast and Controllable 3D Generation via Large Reconstruction Model</h3>
<ul>
<li><strong>Authors: </strong>Hongbin Xu, Weitao Chen, Zhipeng Zhou, Feng Xiao, Baigui Sun, Mike Zheng Shou, Wenxiong Kang</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.09592">https://arxiv.org/abs/2410.09592</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.09592">https://arxiv.org/pdf/2410.09592</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.09592]] ControLRM: Fast and Controllable 3D Generation via Large Reconstruction Model(https://arxiv.org/abs/2410.09592)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, transformer</a></li>
<li><strong>Abstract: </strong>Despite recent advancements in 3D generation methods, achieving controllability still remains a challenging issue. Current approaches utilizing score-distillation sampling are hindered by laborious procedures that consume a significant amount of time. Furthermore, the process of first generating 2D representations and then mapping them to 3D lacks internal alignment between the two forms of representation. To address these challenges, we introduce ControLRM, an end-to-end feed-forward model designed for rapid and controllable 3D generation using a large reconstruction model (LRM). ControLRM comprises a 2D condition generator, a condition encoding transformer, and a triplane decoder transformer. Instead of training our model from scratch, we advocate for a joint training framework. In the condition training branch, we lock the triplane decoder and reuses the deep and robust encoding layers pretrained with millions of 3D data in LRM. In the image training branch, we unlock the triplane decoder to establish an implicit alignment between the 2D and 3D representations. To ensure unbiased evaluation, we curate evaluation samples from three distinct datasets (G-OBJ, GSO, ABO) rather than relying on cherry-picking manual generation. The comprehensive experiments conducted on quantitative and qualitative comparisons of 3D controllability and generation quality demonstrate the strong generalization capacity of our proposed approach.</li>
</ul>

<h3>Title: Mastering AI: Big Data, Deep Learning, and the Evolution of Large Language Models -- AutoML from Basics to State-of-the-Art Techniques</h3>
<ul>
<li><strong>Authors: </strong>Pohsun Feng, Ziqian Bi, Yizhu Wen, Benji Peng, Junyu Liu, Caitlyn Heqi Yin, Tianyang Wang, Keyu Chen, Sen Zhang, Ming Li, Jiawei Xu, Ming Liu, Xuanhe Pan, Jinlang Wang, Qian Niu</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.09596">https://arxiv.org/abs/2410.09596</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.09596">https://arxiv.org/pdf/2410.09596</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.09596]] Mastering AI: Big Data, Deep Learning, and the Evolution of Large Language Models -- AutoML from Basics to State-of-the-Art Techniques(https://arxiv.org/abs/2410.09596)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>This manuscript presents a comprehensive guide to Automated Machine Learning (AutoML), covering fundamental principles, practical implementations, and future trends. The paper is structured to assist both beginners and experienced practitioners, with detailed discussions on popular AutoML tools such as TPOT, AutoGluon, and Auto-Keras. It also addresses emerging topics like Neural Architecture Search (NAS) and AutoML's applications in deep learning. We believe this work will contribute to ongoing research and development in the field of AI and machine learning.</li>
</ul>

<h3>Title: The Fragility of Fairness: Causal Sensitivity Analysis for Fair Machine Learning</h3>
<ul>
<li><strong>Authors: </strong>Jake Fawkes, Nic Fishman, Mel Andrews, Zachary C. Lipton</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CY</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.09600">https://arxiv.org/abs/2410.09600</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.09600">https://arxiv.org/pdf/2410.09600</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.09600]] The Fragility of Fairness: Causal Sensitivity Analysis for Fair Machine Learning(https://arxiv.org/abs/2410.09600)</code><input type="text"></li>
<li><strong>Keywords: </strong>fair</a></li>
<li><strong>Abstract: </strong>Fairness metrics are a core tool in the fair machine learning literature (FairML), used to determine that ML models are, in some sense, ``fair ''.Real-world data, however, are typically plagued by various measurement biases and other violated assumptions, which can render fairness assessments meaningless. We adapt tools from causal sensitivity analysis to the FairML context, providing a general framework which (1) accommodates effectively any combination of fairness metric and bias that can be posed in the ``oblivious setting ''; (2) allows researchers to investigate combinations of biases, resulting in non-linear sensitivity; and (3) enables flexible encoding of domain-specific constraints and assumptions. Employing this framework, we analyze the sensitivity of the most common parity metrics under 3 varieties of classifier across 14 canonical fairness datasets. Our analysis reveals the striking fragility of fairness assessments to even minor dataset biases. We show that causal sensitivity analysis provides a powerful and necessary toolkit for gauging the informativeness of parity metric evaluations. Our repository is available here: this https URL.</li>
</ul>

<h3>Title: Training Dynamics of Transformers to Recognize Word Co-occurrence via Gradient Flow Analysis</h3>
<ul>
<li><strong>Authors: </strong>Hongru Yang, Bhavya Kailkhura, Zhangyang Wang, Yingbin Liang</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.09605">https://arxiv.org/abs/2410.09605</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.09605">https://arxiv.org/pdf/2410.09605</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.09605]] Training Dynamics of Transformers to Recognize Word Co-occurrence via Gradient Flow Analysis(https://arxiv.org/abs/2410.09605)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer, large language model</a></li>
<li><strong>Abstract: </strong>Understanding the training dynamics of transformers is important to explain the impressive capabilities behind large language models. In this work, we study the dynamics of training a shallow transformer on a task of recognizing co-occurrence of two designated words. In the literature of studying training dynamics of transformers, several simplifications are commonly adopted such as weight reparameterization, attention linearization, special initialization, and lazy regime. In contrast, we analyze the gradient flow dynamics of simultaneously training three attention matrices and a linear MLP layer from random initialization, and provide a framework of analyzing such dynamics via a coupled dynamical system. We establish near minimum loss and characterize the attention model after training. We discover that gradient flow serves as an inherent mechanism that naturally divide the training process into two phases. In Phase 1, the linear MLP quickly aligns with the two target signals for correct classification, whereas the softmax attention remains almost unchanged. In Phase 2, the attention matrices and the MLP evolve jointly to enlarge the classification margin and reduce the loss to a near minimum value. Technically, we prove a novel property of the gradient flow, termed \textit{automatic balancing of gradients}, which enables the loss values of different samples to decrease almost at the same rate and further facilitates the proof of near minimum training loss. We also conduct experiments to verify our theoretical results.</li>
</ul>

<h3>Title: RailYolact -- A Yolact Focused on edge for Real-Time Rail Segmentation</h3>
<ul>
<li><strong>Authors: </strong>Qihao Qian</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.09612">https://arxiv.org/abs/2410.09612</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.09612">https://arxiv.org/pdf/2410.09612</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.09612]] RailYolact -- A Yolact Focused on edge for Real-Time Rail Segmentation(https://arxiv.org/abs/2410.09612)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>Ensuring obstacle avoidance on the rail surface is crucial for the safety of autonomous driving trains and its first step is to segment the regions of the rail. We chose to build upon Yolact for our work. To address the issue of rough edge in the rail masks predicted by the model, we incorporated the edge information extracted by edge operator into the original Yolact's loss function to emphasize the model's focus on rail edges. Additionally, we applied box filter to smooth the jagged ground truth mask edges cause by linear interpolation. Since the integration of edge information and smooth process only occurred during the training process, the inference speed of the model remained unaffected. The experiments results on our custom rail dataset demonstrated an improvement in the prediction accuracy. Moreover, the results on Cityscapes showed a 4.1 and 4.6 improvement in $AP$ and $AP_{50}$ , respectively, compared to Yolact.</li>
</ul>

<h3>Title: Transformer-based Language Models for Reasoning in the Description Logic ALCQ</h3>
<ul>
<li><strong>Authors: </strong>Angelos Poulis, Eleni Tsalapati, Manolis Koubarakis</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.09613">https://arxiv.org/abs/2410.09613</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.09613">https://arxiv.org/pdf/2410.09613</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.09613]] Transformer-based Language Models for Reasoning in the Description Logic ALCQ(https://arxiv.org/abs/2410.09613)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer, large language model</a></li>
<li><strong>Abstract: </strong>Recent advancements in transformer-based language models have sparked research into their logical reasoning capabilities. Most of the benchmarks used to evaluate these models are simple: generated from short (fragments of) first-order logic sentences with only a few logical operators and quantifiers. We construct the natural language dataset, DELTA$_D$, using the expressive description logic language $\mathcal{ALCQ}$. DELTA$_D$ comprises 384K examples and increases in two dimensions: i) reasoning depth, and ii) linguistic complexity. In this way, we systematically investigate the logical reasoning capabilities of a supervised fine-tuned DeBERTa-based model and two large language models (GPT-3.5, GPT-4) with few-shot prompting. We show that the DeBERTa-based model fine-tuned on our dataset can master the entailment checking task. Moreover, the performance of GPTs can improve significantly even when a small number of samples is provided (9 shots). We open-source our code and datasets.</li>
</ul>

<h3>Title: SLiM: One-shot Quantized Sparse Plus Low-rank Approximation of LLMs</h3>
<ul>
<li><strong>Authors: </strong>Mohammad Mozaffari, Maryam Mehri Dehnavi</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.PF</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.09615">https://arxiv.org/abs/2410.09615</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.09615">https://arxiv.org/pdf/2410.09615</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.09615]] SLiM: One-shot Quantized Sparse Plus Low-rank Approximation of LLMs(https://arxiv.org/abs/2410.09615)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large Language Models (LLMs) have revolutionized natural language understanding and generation tasks but suffer from high memory consumption and slow inference times due to their large parameter sizes. Traditional model compression techniques, such as quantization and pruning, mitigate these issues but often require retraining to maintain accuracy, which is computationally expensive. This paper introduces SLiM, a novel approach for compressing LLMs using a one-shot Quantized Sparse Plus Low-rank Approximation. SLiM eliminates the need for costly retraining by combining a symmetric quantization method (SLiM-Quant) with a saliency-based low-rank approximation. Our method reduces quantization error while leveraging sparse representations compatible with accelerated hardware architectures. Additionally, we propose a parameter-efficient fine-tuning recipe that significantly reduces overhead compared to conventional quantization-aware training. SLiM achieves up to a 5.4% improvement in model accuracy for sparsity patterns like 2:4, and the fine-tuning step further enhances accuracy by up to 5.8%, demonstrating state-of-the-art performance. This work provides a pathway for efficiently deploying large models in memory-constrained environments without compromising accuracy.</li>
</ul>

<h3>Title: Quebec Automobile Insurance Question-Answering With Retrieval-Augmented Generation</h3>
<ul>
<li><strong>Authors: </strong>David Beauchemin, Zachary Gagnon, Ricahrd Khoury</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.09623">https://arxiv.org/abs/2410.09623</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.09623">https://arxiv.org/pdf/2410.09623</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.09623]] Quebec Automobile Insurance Question-Answering With Retrieval-Augmented Generation(https://arxiv.org/abs/2410.09623)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large Language Models (LLMs) perform outstandingly in various downstream tasks, and the use of the Retrieval-Augmented Generation (RAG) architecture has been shown to improve performance for legal question answering (Nuruzzaman and Hussain, 2020; Louis et al., 2024). However, there are limited applications in insurance questions-answering, a specific type of legal document. This paper introduces two corpora: the Quebec Automobile Insurance Expertise Reference Corpus and a set of 82 Expert Answers to Layperson Automobile Insurance Questions. Our study leverages both corpora to automatically and manually assess a GPT4-o, a state-of-the-art LLM, to answer Quebec automobile insurance questions. Our results demonstrate that, on average, using our expertise reference corpus generates better responses on both automatic and manual evaluation metrics. However, they also highlight that LLM QA is unreliable enough for mass utilization in critical areas. Indeed, our results show that between 5% to 13% of answered questions include a false statement that could lead to customer misunderstanding.</li>
</ul>

<h3>Title: Enhanced Electronic Health Records Text Summarization Using Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Ruvarashe Madzime, Clement Nyirenda</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.09628">https://arxiv.org/abs/2410.09628</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.09628">https://arxiv.org/pdf/2410.09628</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.09628]] Enhanced Electronic Health Records Text Summarization Using Large Language Models(https://arxiv.org/abs/2410.09628)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer, large language model</a></li>
<li><strong>Abstract: </strong>The development of Electronic Health Records summarization systems has revolutionized patient data management. Previous research advanced this field by adapting Large Language Models for clinical tasks, using diverse datasets to generate general EHR summaries. However, clinicians often require specific, focused summaries for quicker insights. This project builds on prior work by creating a system that generates clinician-preferred, focused summaries, improving EHR summarization for more efficient patient care. The proposed system leverages the Google Flan-T5 model to generate tailored EHR summaries based on clinician-specified topics. The approach involved fine-tuning the Flan-T5 model on an EHR question-answering dataset formatted in the Stanford Question Answering Dataset (SQuAD) style, which is a large-scale reading comprehension dataset with questions and answers. Fine-tuning utilized the Seq2SeqTrainer from the Hugging Face Transformers library with optimized hyperparameters. Key evaluation metrics demonstrated promising results: the system achieved an Exact Match (EM) score of 81.81%. ROUGE (Recall-Oriented Understudy for Gisting Evaluation) metrics showed strong performance, with ROUGE-1 at 96.03%, ROUGE-2 at 86.67%, and ROUGE-L at 96.10%. Additionally, the Bilingual Evaluation Understudy (BLEU) score was 63%, reflecting the model's coherence in generating summaries. By enhancing EHR summarization through LLMs, this project supports digital transformation efforts in healthcare, streamlining workflows, and enabling more personalized patient care.</li>
</ul>

<h3>Title: Synthetic Knowledge Ingestion: Towards Knowledge Refinement and Injection for Enhancing Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Jiaxin Zhang, Wendi Cui, Yiran Huang, Kamalika Das, Sricharan Kumar</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.IR, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.09629">https://arxiv.org/abs/2410.09629</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.09629">https://arxiv.org/pdf/2410.09629</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.09629]] Synthetic Knowledge Ingestion: Towards Knowledge Refinement and Injection for Enhancing Large Language Models(https://arxiv.org/abs/2410.09629)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large language models (LLMs) are proficient in capturing factual knowledge across various domains. However, refining their capabilities on previously seen knowledge or integrating new knowledge from external sources remains a significant challenge. In this work, we propose a novel synthetic knowledge ingestion method called Ski, which leverages fine-grained synthesis, interleaved generation, and assemble augmentation strategies to construct high-quality data representations from raw knowledge sources. We then integrate Ski and its variations with three knowledge injection techniques: Retrieval Augmented Generation (RAG), Supervised Fine-tuning (SFT), and Continual Pre-training (CPT) to inject and refine knowledge in language models. Extensive empirical experiments are conducted on various question-answering tasks spanning finance, biomedicine, and open-generation domains to demonstrate that Ski significantly outperforms baseline methods by facilitating effective knowledge injection. We believe that our work is an important step towards enhancing the factual accuracy of LLM outputs by refining knowledge representation and injection capabilities.</li>
</ul>

<h3>Title: Society of Medical Simplifiers</h3>
<ul>
<li><strong>Authors: </strong>Chen Lyu, Gabriele Pergola</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.09631">https://arxiv.org/abs/2410.09631</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.09631">https://arxiv.org/pdf/2410.09631</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.09631]] Society of Medical Simplifiers(https://arxiv.org/abs/2410.09631)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Medical text simplification is crucial for making complex biomedical literature more accessible to non-experts. Traditional methods struggle with the specialized terms and jargon of medical texts, lacking the flexibility to adapt the simplification process dynamically. In contrast, recent advancements in large language models (LLMs) present unique opportunities by offering enhanced control over text simplification through iterative refinement and collaboration between specialized agents. In this work, we introduce the Society of Medical Simplifiers, a novel LLM-based framework inspired by the "Society of Mind" (SOM) philosophy. Our approach leverages the strengths of LLMs by assigning five distinct roles, i.e., Layperson, Simplifier, Medical Expert, Language Clarifier, and Redundancy Checker, organized into interaction loops. This structure allows the agents to progressively improve text simplification while maintaining the complexity and accuracy of the original content. Evaluations on the Cochrane text simplification dataset demonstrate that our framework is on par with or outperforms state-of-the-art methods, achieving superior readability and content preservation through controlled simplification processes.</li>
</ul>

<h3>Title: DuoDiff: Accelerating Diffusion Models with a Dual-Backbone Approach</h3>
<ul>
<li><strong>Authors: </strong>Daniel Gallo FernÃ¡ndez, RÇzvan-Andrei MatiÅan, Alejandro Monroy MuÃ±oz, Ana-Maria Vasilcoiu, Janusz Partyka, Tin HadÅ¾i VeljkoviÄ, Metod Jazbec</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.09633">https://arxiv.org/abs/2410.09633</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.09633">https://arxiv.org/pdf/2410.09633</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.09633]] DuoDiff: Accelerating Diffusion Models with a Dual-Backbone Approach(https://arxiv.org/abs/2410.09633)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>Diffusion models have achieved unprecedented performance in image generation, yet they suffer from slow inference due to their iterative sampling process. To address this, early-exiting has recently been proposed, where the depth of the denoising network is made adaptive based on the (estimated) difficulty of each sampling step. Here, we discover an interesting "phase transition" in the sampling process of current adaptive diffusion models: the denoising network consistently exits early during the initial sampling steps, until it suddenly switches to utilizing the full network. Based on this, we propose accelerating generation by employing a shallower denoising network in the initial sampling steps and a deeper network in the later steps. We demonstrate empirically that our dual-backbone approach, DuoDiff, outperforms existing early-exit diffusion methods in both inference speed and generation quality. Importantly, DuoDiff is easy to implement and complementary to existing approaches for accelerating diffusion.</li>
</ul>

<h3>Title: Use of What-if Scenarios to Help Explain Artificial Intelligence Models for Neonatal Health</h3>
<ul>
<li><strong>Authors: </strong>Abdullah Mamun, Lawrence D. Devoe, Mark I. Evans, David W. Britt, Judith Klein-Seetharaman, Hassan Ghasemzadeh</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.09635">https://arxiv.org/abs/2410.09635</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.09635">https://arxiv.org/pdf/2410.09635</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.09635]] Use of What-if Scenarios to Help Explain Artificial Intelligence Models for Neonatal Health(https://arxiv.org/abs/2410.09635)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>Early detection of intrapartum risk enables interventions to potentially prevent or mitigate adverse labor outcomes such as cerebral palsy. Currently, there is no accurate automated system to predict such events to assist with clinical decision-making. To fill this gap, we propose "Artificial Intelligence (AI) for Modeling and Explaining Neonatal Health" (AIMEN), a deep learning framework that not only predicts adverse labor outcomes from maternal, fetal, obstetrical, and intrapartum risk factors but also provides the model's reasoning behind the predictions made. The latter can provide insights into what modifications in the input variables of the model could have changed the predicted outcome. We address the challenges of imbalance and small datasets by synthesizing additional training data using Adaptive Synthetic Sampling (ADASYN) and Conditional Tabular Generative Adversarial Networks (CTGAN). AIMEN uses an ensemble of fully-connected neural networks as the backbone for its classification with the data augmentation supported by either ADASYN or CTGAN. AIMEN, supported by CTGAN, outperforms AIMEN supported by ADASYN in classification. AIMEN can predict a high risk for adverse labor outcomes with an average F1 score of 0.784. It also provides counterfactual explanations that can be achieved by changing 2 to 3 attributes on average. Resources available: this https URL.</li>
</ul>

<h3>Title: ReLU's Revival: On the Entropic Overload in Normalization-Free Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Nandan Kumar Jha, Brandon Reagen</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.09637">https://arxiv.org/abs/2410.09637</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.09637">https://arxiv.org/pdf/2410.09637</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.09637]] ReLU's Revival: On the Entropic Overload in Normalization-Free Large Language Models(https://arxiv.org/abs/2410.09637)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability, transformer, large language model</a></li>
<li><strong>Abstract: </strong>LayerNorm is a critical component in modern large language models (LLMs) for stabilizing training and ensuring smooth optimization. However, it introduces significant challenges in mechanistic interpretability, outlier feature suppression, faithful signal propagation, and computational and communication complexity of private inference. This work explores desirable activation functions in normalization-free decoder-only LLMs. Contrary to the conventional preference for the GELU in transformer-based models, our empirical findings demonstrate an {\em opposite trend} -- ReLU significantly outperforms GELU in LayerNorm-free models, leading to an {\bf 8.2\%} perplexity improvement. We discover a key issue with GELU, where early layers experience entropic overload, leading to the under-utilization of the representational capacity of attention heads. This highlights that smoother activations like GELU are {\em ill-suited} for LayerNorm-free architectures, whereas ReLU's geometrical properties -- specialization in input space and intra-class selectivity -- lead to improved learning dynamics and better information retention in the absence of LayerNorm. This study offers key insights for optimizing transformer architectures where LayerNorm introduces significant challenges.</li>
</ul>

<h3>Title: Soft Tester UE: A Novel Approach for Open RAN Security Testing</h3>
<ul>
<li><strong>Authors: </strong>Joshua Moore, Aly Sabri Abdalla, Charles Ueltschey, Vuk Marojevic</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.NI, eess.SY</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.09641">https://arxiv.org/abs/2410.09641</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.09641">https://arxiv.org/pdf/2410.09641</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.09641]] Soft Tester UE: A Novel Approach for Open RAN Security Testing(https://arxiv.org/abs/2410.09641)</code><input type="text"></li>
<li><strong>Keywords: </strong>security</a></li>
<li><strong>Abstract: </strong>With the rise of 5G and open radio access networks (O-RAN), there is a growing demand for customizable experimental platforms dedicated to security testing, as existing testbeds do not prioritize this area. Traditional, hardware-dependent testing methods pose challenges for smaller companies and research institutions. The growing wireless threat landscape highlights the critical need for proactive security testing, as 5G and O-RAN deployments are appealing targets for cybercriminals. To address these challenges, this article introduces the Soft Tester UE (soft T-UE), a software-defined test equipment designed to evaluate the security of 5G and O-RAN deployments via the Uu air interface between the user equipment (UE) and the network. The outcome is to deliver a free, open-source, and expandable test instrument to address the need for both standardized and customizable automated security testing. By extending beyond traditional security metrics, the soft T-UE promotes the development of new security measures and enhances the capability to anticipate and mitigate potential security breaches. The tool's automated testing capabilities are demonstrated through a scenario where the Radio Access Network (RAN) under test is evaluated when it receives fuzzed data when initiating a connection with an UE.</li>
</ul>

<h3>Title: Adapters for Altering LLM Vocabularies: What Languages Benefit the Most?</h3>
<ul>
<li><strong>Authors: </strong>HyoJung Han, Akiko Eriguchi, Haoran Xu, Hieu Hoang, Marine Carpuat, Huda Khayrallah</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.09644">https://arxiv.org/abs/2410.09644</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.09644">https://arxiv.org/pdf/2410.09644</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.09644]] Adapters for Altering LLM Vocabularies: What Languages Benefit the Most?(https://arxiv.org/abs/2410.09644)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>Vocabulary adaptation, which integrates new vocabulary into pre-trained language models (LMs), enables expansion to new languages and mitigates token over-fragmentation. However, existing approaches are limited by their reliance on heuristic or external embeddings. We propose VocADT, a novel method for vocabulary adaptation using adapter modules that are trained to learn the optimal linear combination of existing embeddings while keeping the model's weights fixed. VocADT offers a flexible and scalable solution without requiring external resources or language constraints. Across 11 languages-with various scripts, resource availability, and fragmentation-we demonstrate that VocADT outperforms the original Mistral model and other baselines across various multilingual tasks. We find that Latin-script languages and highly fragmented languages benefit the most from vocabulary adaptation. We further fine-tune the adapted model on the generative task of machine translation and find that vocabulary adaptation is still beneficial after fine-tuning and that VocADT is the most effective method.</li>
</ul>

<h3>Title: Learning the Bitter Lesson: Empirical Evidence from 20 Years of CVPR Proceedings</h3>
<ul>
<li><strong>Authors: </strong>Mojtaba Yousefi, Jack Collins</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.CL, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.09649">https://arxiv.org/abs/2410.09649</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.09649">https://arxiv.org/pdf/2410.09649</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.09649]] Learning the Bitter Lesson: Empirical Evidence from 20 Years of CVPR Proceedings(https://arxiv.org/abs/2410.09649)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>This study examines the alignment of \emph{Conference on Computer Vision and Pattern Recognition} (CVPR) research with the principles of the "bitter lesson" proposed by Rich Sutton. We analyze two decades of CVPR abstracts and titles using large language models (LLMs) to assess the field's embracement of these principles. Our methodology leverages state-of-the-art natural language processing techniques to systematically evaluate the evolution of research approaches in computer vision. The results reveal significant trends in the adoption of general-purpose learning algorithms and the utilization of increased computational resources. We discuss the implications of these findings for the future direction of computer vision research and its potential impact on broader artificial intelligence development. This work contributes to the ongoing dialogue about the most effective strategies for advancing machine learning and computer vision, offering insights that may guide future research priorities and methodologies in the field.</li>
</ul>

<h3>Title: Survival of the Safest: Towards Secure Prompt Optimization through Interleaved Multi-Objective Evolution</h3>
<ul>
<li><strong>Authors: </strong>Ankita Sinha, Wendi Cui, Kamalika Das, Jiaxin Zhang</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.AI, cs.CL, cs.LG, cs.NE</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.09652">https://arxiv.org/abs/2410.09652</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.09652">https://arxiv.org/pdf/2410.09652</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.09652]] Survival of the Safest: Towards Secure Prompt Optimization through Interleaved Multi-Objective Evolution(https://arxiv.org/abs/2410.09652)</code><input type="text"></li>
<li><strong>Keywords: </strong>secure, security, large language model</a></li>
<li><strong>Abstract: </strong>Large language models (LLMs) have demonstrated remarkable capabilities; however, the optimization of their prompts has historically prioritized performance metrics at the expense of crucial safety and security considerations. To overcome this shortcoming, we introduce "Survival of the Safest" (SoS), an innovative multi-objective prompt optimization framework that enhances both performance and security in LLMs simultaneously. SoS utilizes an interleaved multi-objective evolution strategy, integrating semantic, feedback, and crossover mutations to effectively traverse the prompt landscape. Differing from the computationally demanding Pareto front methods, SoS provides a scalable solution that expedites optimization in complex, high-dimensional discrete search spaces while keeping computational demands low. Our approach accommodates flexible weighting of objectives and generates a pool of optimized candidates, empowering users to select prompts that optimally meet their specific performance and security needs. Experimental evaluations across diverse benchmark datasets affirm SoS's efficacy in delivering high performance and notably enhancing safety and security compared to single-objective methods. This advancement marks a significant stride towards the deployment of LLM systems that are both high-performing and secure across varied industrial applications</li>
</ul>

<h3>Title: EquiJump: Protein Dynamics Simulation via SO(3)-Equivariant Stochastic Interpolants</h3>
<ul>
<li><strong>Authors: </strong>Allan dos Santos Costa, Ilan Mitnikov, Franco Pellegrini, Ameya Daigavane, Mario Geiger, Zhonglin Cao, Karsten Kreis, Tess Smidt, Emine Kucukbenli, Joseph Jacobson</a></li>
<li><strong>Subjects: </strong>cs.LG, physics.chem-ph, q-bio.BM</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.09667">https://arxiv.org/abs/2410.09667</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.09667">https://arxiv.org/pdf/2410.09667</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.09667]] EquiJump: Protein Dynamics Simulation via SO(3)-Equivariant Stochastic Interpolants(https://arxiv.org/abs/2410.09667)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>Mapping the conformational dynamics of proteins is crucial for elucidating their functional mechanisms. While Molecular Dynamics (MD) simulation enables detailed time evolution of protein motion, its computational toll hinders its use in practice. To address this challenge, multiple deep learning models for reproducing and accelerating MD have been proposed drawing on transport-based generative methods. However, existing work focuses on generation through transport of samples from prior distributions, that can often be distant from the data manifold. The recently proposed framework of stochastic interpolants, instead, enables transport between arbitrary distribution endpoints. Building upon this work, we introduce EquiJump, a transferable SO(3)-equivariant model that bridges all-atom protein dynamics simulation time steps directly. Our approach unifies diverse sampling methods and is benchmarked against existing models on trajectory data of fast folding proteins. EquiJump achieves state-of-the-art results on dynamics simulation with a transferable model on all of the fast folding proteins.</li>
</ul>

<h3>Title: COrAL: Order-Agnostic Language Modeling for Efficient Iterative Refinement</h3>
<ul>
<li><strong>Authors: </strong>Yuxi Xie, Anirudh Goyal, Xiaobao Wu, Xunjian Yin, Xiao Xu, Min-Yen Kan, Liangming Pan, William Yang Wang</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.09675">https://arxiv.org/abs/2410.09675</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.09675">https://arxiv.org/pdf/2410.09675</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.09675]] COrAL: Order-Agnostic Language Modeling for Efficient Iterative Refinement(https://arxiv.org/abs/2410.09675)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Iterative refinement has emerged as an effective paradigm for enhancing the capabilities of large language models (LLMs) on complex tasks. However, existing approaches typically implement iterative refinement at the application or prompting level, relying on autoregressive (AR) modeling. The sequential token generation in AR models can lead to high inference latency. To overcome these challenges, we propose Context-Wise Order-Agnostic Language Modeling (COrAL), which incorporates iterative refinement directly into the LLM architecture while maintaining computational efficiency. Our approach models multiple token dependencies within manageable context windows, enabling the model to perform iterative refinement internally during the generation process. Leveraging the order-agnostic nature of COrAL, we introduce sliding blockwise order-agnostic decoding, which performs multi-token forward prediction and backward reconstruction within context windows. This allows the model to iteratively refine its outputs in parallel in the sliding block, effectively capturing diverse dependencies without the high inference cost of sequential generation. Empirical evaluations on reasoning tasks demonstrate that COrAL improves performance and inference speed, respectively, achieving absolute accuracy gains of $4.6\%$ on GSM8K and $4.0\%$ on LogiQA, along with inference speedups of up to $3.9\times$ over next-token baselines. Preliminary results on code generation indicate a drop in pass rates due to inconsistencies in order-agnostic outputs, highlighting the inherent quality--speed trade-off. Our code is publicly available at this https URL.</li>
</ul>

<h3>Title: Uncovering Attacks and Defenses in Secure Aggregation for Federated Deep Learning</h3>
<ul>
<li><strong>Authors: </strong>Yiwei Zhang, Rouzbeh Behnia, Attila A. Yavuz, Reza Ebrahimi, Elisa Bertino</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.09676">https://arxiv.org/abs/2410.09676</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.09676">https://arxiv.org/pdf/2410.09676</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.09676]] Uncovering Attacks and Defenses in Secure Aggregation for Federated Deep Learning(https://arxiv.org/abs/2410.09676)</code><input type="text"></li>
<li><strong>Keywords: </strong>secure, security, privacy, protect, defense, attack, robust, federate</a></li>
<li><strong>Abstract: </strong>Federated learning enables the collaborative learning of a global model on diverse data, preserving data locality and eliminating the need to transfer user data to a central server. However, data privacy remains vulnerable, as attacks can target user training data by exploiting the updates sent by users during each learning iteration. Secure aggregation protocols are designed to mask/encrypt user updates and enable a central server to aggregate the masked information. MicroSecAgg (PoPETS 2024) proposes a single server secure aggregation protocol that aims to mitigate the high communication complexity of the existing approaches by enabling a one-time setup of the secret to be re-used in multiple training iterations. In this paper, we identify a security flaw in the MicroSecAgg that undermines its privacy guarantees. We detail the security flaw and our attack, demonstrating how an adversary can exploit predictable masking values to compromise user privacy. Our findings highlight the critical need for enhanced security measures in secure aggregation protocols, particularly the implementation of dynamic and unpredictable masking strategies. We propose potential countermeasures to mitigate these vulnerabilities and ensure robust privacy protection in the secure aggregation frameworks.</li>
</ul>

<h3>Title: MoIN: Mixture of Introvert Experts to Upcycle an LLM</h3>
<ul>
<li><strong>Authors: </strong>Ajinkya Tejankar, KL Navaneet, Ujjawal Panchal, Kossar Pourahmadi, Hamed Pirsiavash</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.09687">https://arxiv.org/abs/2410.09687</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.09687">https://arxiv.org/pdf/2410.09687</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.09687]] MoIN: Mixture of Introvert Experts to Upcycle an LLM(https://arxiv.org/abs/2410.09687)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>The goal of this paper is to improve (upcycle) an existing large language model without the prohibitive requirements of continued pre-training of the full-model. The idea is to split the pre-training data into semantically relevant groups and train an expert on each subset. An expert takes the form of a lightweight adapter added on the top of a frozen base model. During inference, an incoming query is first routed to the most relevant expert which is then loaded onto the base model for the forward pass. Unlike typical Mixture of Experts (MoE) models, the experts in our method do not work with other experts for a single query. Hence, we dub them "introvert" experts. Freezing the base model and keeping the experts as lightweight adapters allows extreme parallelism during training and inference. Training of all experts can be done in parallel without any communication channels between them. Similarly, the inference can also be heavily parallelized by distributing experts on different GPUs and routing each request to the GPU containing its relevant expert. We implement a proof-of-concept version of this method and show the validity of our approach.</li>
</ul>

<h3>Title: Robust 3D Point Clouds Classification based on Declarative Defenders</h3>
<ul>
<li><strong>Authors: </strong>Kaidong Li, Tianxiao Zhang, Chuncong Zhong, Ziming Zhang, Guanghui Wang</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.09691">https://arxiv.org/abs/2410.09691</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.09691">https://arxiv.org/pdf/2410.09691</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.09691]] Robust 3D Point Clouds Classification based on Declarative Defenders(https://arxiv.org/abs/2410.09691)</code><input type="text"></li>
<li><strong>Keywords: </strong>defense, attack, robust, generative</a></li>
<li><strong>Abstract: </strong>3D point cloud classification requires distinct models from 2D image classification due to the divergent characteristics of the respective input data. While 3D point clouds are unstructured and sparse, 2D images are structured and dense. Bridging the domain gap between these two data types is a non-trivial challenge to enable model interchangeability. Recent research using Lattice Point Classifier (LPC) highlights the feasibility of cross-domain applicability. However, the lattice projection operation in LPC generates 2D images with disconnected projected pixels. In this paper, we explore three distinct algorithms for mapping 3D point clouds into 2D images. Through extensive experiments, we thoroughly examine and analyze their performance and defense mechanisms. Leveraging current large foundation models, we scrutinize the feature disparities between regular 2D images and projected 2D images. The proposed approaches demonstrate superior accuracy and robustness against adversarial attacks. The generative model-based mapping algorithms yield regular 2D images, further minimizing the domain gap from regular 2D classification tasks. The source code is available at this https URL.</li>
</ul>

<h3>Title: ALLoRA: Adaptive Learning Rate Mitigates LoRA Fatal Flaws</h3>
<ul>
<li><strong>Authors: </strong>Hai Huang, Randall Balestriero</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.09692">https://arxiv.org/abs/2410.09692</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.09692">https://arxiv.org/pdf/2410.09692</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.09692]] ALLoRA: Adaptive Learning Rate Mitigates LoRA Fatal Flaws(https://arxiv.org/abs/2410.09692)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Low-Rank Adaptation (LoRA) is the bread and butter of Large Language Model (LLM) finetuning. LoRA learns an additive low-rank perturbation, $AB$, of a pretrained matrix parameter $W$ to align the model to a new task or dataset with $W+AB$. We identify three core limitations to LoRA for finetuning--a setting that employs limited amount of data and training steps. First, LoRA employs Dropout to prevent overfitting. We prove that Dropout is only suitable for long training episodes but fails to converge to a reliable regularizer for short training episodes. Second, LoRA's initialization of $B$ at $0$ creates a slow training dynamic between $A$ and $B$. That dynamic is also exacerbated by Dropout that further slows the escape from $0$ for $B$ which is particularly harmful for short training episodes. Third, the scaling factor multiplying each LoRA additive perturbation creates ``short-sighted'' interactions between the LoRA modules of different layers. Motivated by principled analysis of those limitations, we find an elegant solution: a Dropout-free, scaling-free, LoRA with Adaptive Learning rate--coined ALLoRA. By scaling the per sample and per parameter gradients with a coefficient inversely proportional to parameters' $\ell_2$ norm, ALLoRA alleviates those three limitations. As a by-product, ALLoRA removes two hyper-parameters from LoRA: the scaling factor and the dropout rate. Empirical results show that ALLoRA admits better accuracy than LoRA on various settings, including against recent LoRA variants such as Weight-Decomposed Low-Rank Adaptation (DoRA). Ablation studies show our solution is the optimal in a family of weight-dependent / output-dependent approaches on various LLMs including the latest Llama3.</li>
</ul>

<h3>Title: Can In-context Learning Really Generalize to Out-of-distribution Tasks?</h3>
<ul>
<li><strong>Authors: </strong>Qixun Wang, Yifei Wang, Yisen Wang, Xianghua Ying</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.09695">https://arxiv.org/abs/2410.09695</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.09695">https://arxiv.org/pdf/2410.09695</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.09695]] Can In-context Learning Really Generalize to Out-of-distribution Tasks?(https://arxiv.org/abs/2410.09695)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>In this work, we explore the mechanism of in-context learning (ICL) on out-of-distribution (OOD) tasks that were not encountered during training. To achieve this, we conduct synthetic experiments where the objective is to learn OOD mathematical functions through ICL using a GPT-2 model. We reveal that Transformers may struggle to learn OOD task functions through ICL. Specifically, ICL performance resembles implementing a function within the pretraining hypothesis space and optimizing it with gradient descent based on the in-context examples. Additionally, we investigate ICL's well-documented ability to learn unseen abstract labels in context. We demonstrate that such ability only manifests in the scenarios without distributional shifts and, therefore, may not serve as evidence of new-task-learning ability. Furthermore, we assess ICL's performance on OOD tasks when the model is pretrained on multiple tasks. Both empirical and theoretical analyses demonstrate the existence of the \textbf{low-test-error preference} of ICL, where it tends to implement the pretraining function that yields low test error in the testing context. We validate this through numerical experiments. This new theoretical result, combined with our empirical findings, elucidates the mechanism of ICL in addressing OOD tasks.</li>
</ul>

<h3>Title: Honest AI: Fine-Tuning "Small" Language Models to Say "I Don't Know", and Reducing Hallucination in RAG</h3>
<ul>
<li><strong>Authors: </strong>Xinxi Chen, Li Wang, Wei Wu, Qi Tang, Yiyao Liu</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.09699">https://arxiv.org/abs/2410.09699</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.09699">https://arxiv.org/pdf/2410.09699</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.09699]] Honest AI: Fine-Tuning "Small" Language Models to Say "I Don't Know", and Reducing Hallucination in RAG(https://arxiv.org/abs/2410.09699)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Hallucination is a key roadblock for applications of Large Language Models (LLMs), particularly for enterprise applications that are sensitive to information accuracy. To address this issue, two general approaches have been explored: Retrieval-Augmented Generation (RAG) to supply LLMs with updated information as context, and fine-tuning the LLMs with new information and desired output styles. In this paper, we propose Honest AI: a novel strategy to fine-tune "small" language models to say "I don't know" to reduce hallucination, along with several alternative RAG approaches. The solution ranked 1st in Task 2 for the false premise question. The alternative approaches include using RAG with search engine and knowledge graph results, fine-tuning base LLMs with new information and combinations of both approaches. Although all approaches improve the performance of the LLMs, RAG alone does not significantly improve the performance and fine-tuning is needed for better results. Finally, the hybrid approach achieved the highest score in the CRAG benchmark. In addition, our approach emphasizes the use of relatively small models with fewer than 10 billion parameters, promoting resource efficiency.</li>
</ul>

<h3>Title: AM-SAM: Automated Prompting and Mask Calibration for Segment Anything Model</h3>
<ul>
<li><strong>Authors: </strong>Yuchen Li, Li Zhang, Youwei Liang, Pengtao Xie</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.09714">https://arxiv.org/abs/2410.09714</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.09714">https://arxiv.org/pdf/2410.09714</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.09714]] AM-SAM: Automated Prompting and Mask Calibration for Segment Anything Model(https://arxiv.org/abs/2410.09714)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>Segment Anything Model (SAM) has gained significant recognition in the field of semantic segmentation due to its versatile capabilities and impressive performance. Despite its success, SAM faces two primary limitations: (1) it relies heavily on meticulous human-provided prompts like key points, bounding boxes or text messages, which is labor-intensive; (2) the mask decoder's feature representation is sometimes inaccurate, as it solely employs dot product operations at the end of mask decoder, which inadequately captures the necessary correlations for precise segmentation. Current solutions to these problems such as fine-tuning SAM often require retraining a large number of parameters, which needs huge amount of time and computing resources. To address these limitations, we propose an automated prompting and mask calibration method called AM-SAM based on a bi-level optimization framework. Our approach automatically generates prompts for an input image, eliminating the need for human involvement with a good performance in early training epochs, achieving faster convergence. Additionally, we freeze the main part of SAM, and modify the mask decoder with Low-Rank Adaptation (LoRA), enhancing the mask decoder's feature representation by incorporating advanced techniques that go beyond simple dot product operations to more accurately capture and utilize feature correlations. Our experimental results demonstrate that AM-SAM achieves significantly accurate segmentation, matching or exceeding the effectiveness of human-generated and default prompts. Notably, on the body segmentation dataset, our method yields a 5% higher dice score with a 4-example few-shot training set compared to the SOTA method, underscoring its superiority in semantic segmentation tasks.</li>
</ul>

<h3>Title: Taming Overconfidence in LLMs: Reward Calibration in RLHF</h3>
<ul>
<li><strong>Authors: </strong>Jixuan Leng, Chengsong Huang, Banghua Zhu, Jiaxin Huang</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.09724">https://arxiv.org/abs/2410.09724</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.09724">https://arxiv.org/pdf/2410.09724</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.09724]] Taming Overconfidence in LLMs: Reward Calibration in RLHF(https://arxiv.org/abs/2410.09724)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Language model calibration refers to the alignment between the confidence of the model and the actual performance of its responses. While previous studies point out the overconfidence phenomenon in Large Language Models (LLMs) and show that LLMs trained with Reinforcement Learning from Human Feedback (RLHF) are overconfident with a more sharpened output probability, in this study, we reveal that RLHF tends to lead models to express verbalized overconfidence in their own responses. We investigate the underlying cause of this overconfidence and demonstrate that reward models used for Proximal Policy Optimization (PPO) exhibit inherent biases towards high-confidence scores regardless of the actual quality of responses. Building upon this insight, we propose two PPO variants: PPO-M: PPO with Calibrated Reward Modeling and PPO-C: PPO with Calibrated Reward Calculation. PPO-M integrates explicit confidence scores in reward model training, which calibrates reward models to better capture the alignment between response quality and verbalized confidence. PPO-C adjusts the reward score during PPO based on the difference between the current reward and the moving average of past rewards. Both PPO-M and PPO-C can be seamlessly integrated into the current PPO pipeline and do not require additional golden labels. We evaluate our methods on both Llama3-8B and Mistral-7B across six diverse datasets including multiple-choice and open-ended generation. Experiment results demonstrate that both of our methods can reduce calibration error and maintain performance comparable to standard PPO. We further show that they do not compromise model capabilities in open-ended conversation settings.</li>
</ul>

<h3>Title: MIRAGE: Multimodal Identification and Recognition of Annotations in Indian General Prescriptions</h3>
<ul>
<li><strong>Authors: </strong>Tavish Mankash, V.S. Chaithanya Kota, Anish De, Praveen Prakash, Kshitij Jadhav</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.09729">https://arxiv.org/abs/2410.09729</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.09729">https://arxiv.org/pdf/2410.09729</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.09729]] MIRAGE: Multimodal Identification and Recognition of Annotations in Indian General Prescriptions(https://arxiv.org/abs/2410.09729)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction, large language model</a></li>
<li><strong>Abstract: </strong>Hospitals generate thousands of handwritten prescriptions, a practice that remains prevalent despite the availability of Electronic Medical Records (EMR). This method of record-keeping hinders the examination of long-term medication effects, impedes statistical analysis, and makes the retrieval of records challenging. Handwritten prescriptions pose a unique challenge, requiring specialized data for training models to recognize medications and their patterns of recommendation. While current handwriting recognition approaches typically employ 2-D LSTMs, recent studies have explored the use of Large Language Models (LLMs) for Optical Character Recognition (OCR). Building on this approach, we focus on extracting medication names from medical records. Our methodology MIRAGE (Multimodal Identification and Recognition of Annotations in indian GEneral prescriptions) involves fine-tuning the LLaVA 1.6 and Idefics2 models. Our research utilizes a dataset provided by Medyug Technology, consisting of 743,118 fully annotated high-resolution simulated medical records from 1,133 doctors across India. We demonstrate that our methodology exhibits 82% accuracy in medication name and dosage extraction. We provide a detailed account of our research methodology and results, notes about HWR with Multimodal LLMs, and release a small dataset of 100 medical records with labels.</li>
</ul>

<h3>Title: LOKI: A Comprehensive Synthetic Data Detection Benchmark using Large Multimodal Models</h3>
<ul>
<li><strong>Authors: </strong>Junyan Ye, Baichuan Zhou, Zilong Huang, Junan Zhang, Tianyi Bai, Hengrui Kang, Jun He, Honglin Lin, Zihao Wang, Tong Wu, Zhizheng Wu, Yiping Chen, Dahua Lin, Conghui He, Weijia Li</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.09732">https://arxiv.org/abs/2410.09732</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.09732">https://arxiv.org/pdf/2410.09732</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.09732]] LOKI: A Comprehensive Synthetic Data Detection Benchmark using Large Multimodal Models(https://arxiv.org/abs/2410.09732)</code><input type="text"></li>
<li><strong>Keywords: </strong>explainability</a></li>
<li><strong>Abstract: </strong>With the rapid development of AI-generated content, the future internet may be inundated with synthetic data, making the discrimination of authentic and credible multimodal data increasingly challenging. Synthetic data detection has thus garnered widespread attention, and the performance of large multimodal models (LMMs) in this task has attracted significant interest. LMMs can provide natural language explanations for their authenticity judgments, enhancing the explainability of synthetic content detection. Simultaneously, the task of distinguishing between real and synthetic data effectively tests the perception, knowledge, and reasoning capabilities of LMMs. In response, we introduce LOKI, a novel benchmark designed to evaluate the ability of LMMs to detect synthetic data across multiple modalities. LOKI encompasses video, image, 3D, text, and audio modalities, comprising 18K carefully curated questions across 26 subcategories with clear difficulty levels. The benchmark includes coarse-grained judgment and multiple-choice questions, as well as fine-grained anomaly selection and explanation tasks, allowing for a comprehensive analysis of LMMs. We evaluated 22 open-source LMMs and 6 closed-source models on LOKI, highlighting their potential as synthetic data detectors and also revealing some limitations in the development of LMM capabilities. More information about LOKI can be found at this https URL</li>
</ul>

<h3>Title: Towards Stable, Globally Expressive Graph Representations with Laplacian Eigenvectors</h3>
<ul>
<li><strong>Authors: </strong>Junru Zhou, Cai Zhou, Xiyuan Wang, Pan Li, Muhan Zhang</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.09737">https://arxiv.org/abs/2410.09737</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.09737">https://arxiv.org/pdf/2410.09737</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.09737]] Towards Stable, Globally Expressive Graph Representations with Laplacian Eigenvectors(https://arxiv.org/abs/2410.09737)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, fair</a></li>
<li><strong>Abstract: </strong>Graph neural networks (GNNs) have achieved remarkable success in a variety of machine learning tasks over graph data. Existing GNNs usually rely on message passing, i.e., computing node representations by gathering information from the neighborhood, to build their underlying computational graphs. They are known fairly limited in expressive power, and often fail to capture global characteristics of graphs. To overcome the issue, a popular solution is to use Laplacian eigenvectors as additional node features, as they contain global positional information of nodes, and can serve as extra node identifiers aiding GNNs to separate structurally similar nodes. For such an approach, properly handling the orthogonal group symmetry among eigenvectors with equal eigenvalue is crucial for its stability and generalizability. However, using a naive orthogonal group invariant encoder for each separate eigenspace may not keep the full expressivity in the Laplacian eigenvectors. Moreover, computing such invariants inevitably entails a hard split of Laplacian eigenvalues according to their numerical identity, which suffers from great instability when the graph structure is perturbed. In this paper, we propose a novel method exploiting Laplacian eigenvectors to generate stable and globally expressive graph representations. The main difference from previous works is that (i) our method utilizes learnable orthogonal group invariant representations for each Laplacian eigenspace, based upon powerful orthogonal group equivariant neural network layers already well studied in the literature, and that (ii) our method deals with numerically close eigenvalues in a smooth fashion, ensuring its better robustness against perturbations. Experiments on various graph learning benchmarks witness the competitive performance of our method, especially its great potential to learn global properties of graphs.</li>
</ul>

<h3>Title: Real-time Fuel Leakage Detection via Online Change Point Detection</h3>
<ul>
<li><strong>Authors: </strong>Ruimin Chu, Li Chik, Yiliao Song, Jeffrey Chan, Xiaodong Li</a></li>
<li><strong>Subjects: </strong>cs.LG, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.09741">https://arxiv.org/abs/2410.09741</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.09741">https://arxiv.org/pdf/2410.09741</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.09741]] Real-time Fuel Leakage Detection via Online Change Point Detection(https://arxiv.org/abs/2410.09741)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Early detection of fuel leakage at service stations with underground petroleum storage systems is a crucial task to prevent catastrophic hazards. Current data-driven fuel leakage detection methods employ offline statistical inventory reconciliation, leading to significant detection delays. Consequently, this can result in substantial financial loss and environmental impact on the surrounding community. In this paper, we propose a novel framework called Memory-based Online Change Point Detection (MOCPD) which operates in near real-time, enabling early detection of fuel leakage. MOCPD maintains a collection of representative historical data within a size-constrained memory, along with an adaptively computed threshold. Leaks are detected when the dissimilarity between the latest data and historical memory exceeds the current threshold. An update phase is incorporated in MOCPD to ensure diversity among historical samples in the memory. With this design, MOCPD is more robust and achieves a better recall rate while maintaining a reasonable precision score. We have conducted a variety of experiments comparing MOCPD to commonly used online change point detection (CPD) baselines on real-world fuel variance data with induced leakages, actual fuel leakage data and benchmark CPD datasets. Overall, MOCPD consistently outperforms the baseline methods in terms of detection accuracy, demonstrating its applicability to fuel leakage detection and CPD problems.</li>
</ul>

<h3>Title: t-READi: Transformer-Powered Robust and Efficient Multimodal Inference for Autonomous Driving</h3>
<ul>
<li><strong>Authors: </strong>Pengfei Hu, Yuhang Qian, Tianyue Zheng, Ang Li, Zhe Chen, Yue Gao, Xiuzhen Cheng, Jun Luo</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI, cs.DC, cs.LG, cs.RO</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.09747">https://arxiv.org/abs/2410.09747</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.09747">https://arxiv.org/pdf/2410.09747</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.09747]] t-READi: Transformer-Powered Robust and Efficient Multimodal Inference for Autonomous Driving(https://arxiv.org/abs/2410.09747)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, transformer</a></li>
<li><strong>Abstract: </strong>Given the wide adoption of multimodal sensors (e.g., camera, lidar, radar) by autonomous vehicles (AVs), deep analytics to fuse their outputs for a robust perception become imperative. However, existing fusion methods often make two assumptions rarely holding in practice: i) similar data distributions for all inputs and ii) constant availability for all sensors. Because, for example, lidars have various resolutions and failures of radars may occur, such variability often results in significant performance degradation in fusion. To this end, we present tREADi, an adaptive inference system that accommodates the variability of multimodal sensory data and thus enables robust and efficient perception. t-READi identifies variation-sensitive yet structure-specific model parameters; it then adapts only these parameters while keeping the rest intact. t-READi also leverages a cross-modality contrastive learning method to compensate for the loss from missing modalities. Both functions are implemented to maintain compatibility with existing multimodal deep fusion methods. The extensive experiments evidently demonstrate that compared with the status quo approaches, t-READi not only improves the average inference accuracy by more than 6% but also reduces the inference latency by almost 15x with the cost of only 5% extra memory overhead in the worst case under realistic data and modal variations.</li>
</ul>

<h3>Title: EMWaveNet: Physically Explainable Neural Network Based on Microwave Propagation for SAR Target Recognition</h3>
<ul>
<li><strong>Authors: </strong>Zhuoxuan Li, Xu Zhang, Shumeng Yu, Haipeng Wang</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.09749">https://arxiv.org/abs/2410.09749</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.09749">https://arxiv.org/pdf/2410.09749</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.09749]] EMWaveNet: Physically Explainable Neural Network Based on Microwave Propagation for SAR Target Recognition(https://arxiv.org/abs/2410.09749)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, explainability</a></li>
<li><strong>Abstract: </strong>Deep learning technologies have achieved significant performance improvements in the field of synthetic aperture radar (SAR) image target recognition over traditional methods. However, the inherent "black box" property of deep learning models leads to a lack of transparency in decision-making processes, making them difficult to be convincingly applied in practice. This is especially true in SAR applications, where the credibility and reliability of model predictions are crucial. The complexity and insufficient explainability of deep networks have become a bottleneck for their application. To tackle this issue, this study proposes a physically explainable framework for complex-valued SAR image recognition, designed based on the physical process of microwave propagation. This framework utilizes complex-valued SAR data to explore the amplitude and phase information and its intrinsic physical properties. The network architecture is fully parameterized, with all learnable parameters endowed with clear physical meanings, and the computational process is completed entirely in the frequency domain. Experiments on both the complex-valued MSTAR dataset and a self-built Qilu-1 complex-valued dataset were conducted to validate the effectiveness of framework. In conditions of target overlap, our model discerns categories others find challenging. Against 0dB forest background noise, it boasts a 20% accuracy improvement over traditional neural networks. When targets are 60% masked by noise, it still outperforms other models by 9%. An end-to-end complex-valued synthetic aperture radar automatic target recognition (SAR-ATR) system has also been constructed to perform recognition tasks in interference SAR scenarios. The results demonstrate that the proposed method possesses a strong physical decision logic, high physical explainability and robustness, as well as excellent dealiasing capabilities.</li>
</ul>

<h3>Title: Surgical-LLaVA: Toward Surgical Scenario Understanding via Large Language and Vision Models</h3>
<ul>
<li><strong>Authors: </strong>Juseong Jin, Chang Wook Jeong</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.09750">https://arxiv.org/abs/2410.09750</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.09750">https://arxiv.org/pdf/2410.09750</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.09750]] Surgical-LLaVA: Toward Surgical Scenario Understanding via Large Language and Vision Models(https://arxiv.org/abs/2410.09750)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Conversation agents powered by large language models are revolutionizing the way we interact with visual data. Recently, large vision-language models (LVLMs) have been extensively studied for both images and videos. However, these studies typically focus on common scenarios. In this work, we introduce an LVLM specifically designed for surgical scenarios. We integrate visual representations of surgical images and videos into the language feature space. Consequently, we establish a LVLM model, Surgical-LLaVA, fine-tuned on instruction following data of surgical scenarios. Our experiments demonstrate that Surgical-LLaVA exhibits impressive multi-modal chat abilities in surgical contexts, occasionally displaying multi-modal behaviors on unseen instructions. We conduct a quantitative evaluation of visual question-answering datasets for surgical scenarios. The results show superior performance compared to previous works, indicating the potential of our model to tackle more complex surgery scenarios.</li>
</ul>

<h3>Title: BiDoRA: Bi-level Optimization-Based Weight-Decomposed Low-Rank Adaptation</h3>
<ul>
<li><strong>Authors: </strong>Peijia Qin, Ruiyi Zhang, Pengtao Xie</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.09758">https://arxiv.org/abs/2410.09758</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.09758">https://arxiv.org/pdf/2410.09758</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.09758]] BiDoRA: Bi-level Optimization-Based Weight-Decomposed Low-Rank Adaptation(https://arxiv.org/abs/2410.09758)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Parameter-efficient fine-tuning (PEFT) of large language models (LLMs) has gained considerable attention as a flexible and efficient way of adapting LLMs to downstream tasks. Among these methods, weighted decomposed low-rank adaptation (DoRA) has emerged as a promising approach. DoRA bridges the gap between low-rank adaptation (LoRA) and full fine-tuning (FT) by decomposing the weight matrices into magnitude and direction components, thereby maintaining learning behavior similar to FT. Although DoRA shows encouraging performance, it introduces additional parameters compared to LoRA, which potentially increases the risk of overfitting. Moreover, optimizing magnitude and direction simultaneously leads to a coupled gradient updating pattern for both components, limiting its learning capacity. To overcome these limitations, we propose BiDoRA, a bi-level optimization-based PEFT method. In BiDoRA, the direction and magnitude components are optimized on two distinct datasets at different optimization levels, mitigating the risk of overfitting. Additionally, the asynchronous optimization of the two components promotes their decoupling, allowing for more flexible gradient updates suitable for various downstream tasks. Evaluation of BiDoRA on fourteen datasets spanning natural language understanding, natural language generation, and token classification reveals that it significantly outperforms DoRA and other PEFT methods. The superior performance of BiDoRA underscores its effectiveness. The code for BiDoRA is available at this https URL.</li>
</ul>

<h3>Title: Data Adaptive Few-shot Multi Label Segmentation with Foundation Model</h3>
<ul>
<li><strong>Authors: </strong>Gurunath Reddy, Dattesh Shanbhag, Deepa Anand</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.09759">https://arxiv.org/abs/2410.09759</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.09759">https://arxiv.org/pdf/2410.09759</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.09759]] Data Adaptive Few-shot Multi Label Segmentation with Foundation Model(https://arxiv.org/abs/2410.09759)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer, segmentation</a></li>
<li><strong>Abstract: </strong>The high cost of obtaining accurate annotations for image segmentation and localization makes the use of one and few shot algorithms attractive. Several state-of-the-art methods for few-shot segmentation have emerged, including text-based prompting for the task but suffer from sub-optimal performance for medical images. Leveraging sub-pixel level features of existing Vision Transformer (ViT) based foundation models for identifying similar region of interest (RoI) based on a single template image have been shown to be very effective for one shot segmentation and localization in medical images across modalities. However, such methods rely on assumption that template image and test image are well matched and simple correlation is sufficient to obtain correspondences. In practice, however such an approach can fail to generalize in clinical data due to patient pose changes, inter-protocol variations even within a single modality or extend to 3D data using single template image. Moreover, for multi-label tasks, the RoI identification has to be performed sequentially. In this work, we propose foundation model (FM) based adapters for single label, multi-label localization and segmentation to address these concerns. We demonstrate the efficacy of the proposed method for multiple segmentation and localization tasks for both 2D and 3D data as we well as clinical data with different poses and evaluate against the state of the art few shot segmentation methods.</li>
</ul>

<h3>Title: Targeted Vaccine: Safety Alignment for Large Language Models against Harmful Fine-Tuning via Layer-wise Perturbation</h3>
<ul>
<li><strong>Authors: </strong>Guozhi Liu, Weiwei Lin, Tiansheng Huang, Ruichao Mo, Qi Mu, Li Shen</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.09760">https://arxiv.org/abs/2410.09760</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.09760">https://arxiv.org/pdf/2410.09760</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.09760]] Targeted Vaccine: Safety Alignment for Large Language Models against Harmful Fine-Tuning via Layer-wise Perturbation(https://arxiv.org/abs/2410.09760)</code><input type="text"></li>
<li><strong>Keywords: </strong>defense, attack, robust, large language model</a></li>
<li><strong>Abstract: </strong>Harmful fine-tuning attack poses a serious threat to the online fine-tuning service. Vaccine, a recent alignment-stage defense, applies uniform perturbation to all layers of embedding to make the model robust to the simulated embedding drift. However, applying layer-wise uniform perturbation may lead to excess perturbations for some particular safety-irrelevant layers, resulting in defense performance degradation and unnecessary memory consumption. To address this limitation, we propose Targeted Vaccine (T-Vaccine), a memory-efficient safety alignment method that applies perturbation to only selected layers of the model. T-Vaccine follows two core steps: First, it uses gradient norm as a statistical metric to identify the safety-critical layers. Second, instead of applying uniform perturbation across all layers, T-Vaccine only applies perturbation to the safety-critical layers while keeping other layers frozen during training. Results show that T-Vaccine outperforms Vaccine in terms of both defense effectiveness and resource efficiency. Comparison with other defense baselines, e.g., RepNoise and TAR also demonstrate the superiority of T-Vaccine. Notably, T-Vaccine is the first defense that can address harmful fine-tuning issues for a 7B pre-trained models trained on consumer GPUs with limited memory (e.g., RTX 4090). Our code is available at this https URL.</li>
</ul>

<h3>Title: Compressing Scene Dynamics: A Generative Approach</h3>
<ul>
<li><strong>Authors: </strong>Shanzhi Yin, Zihan Zhang, Bolin Chen, Shiqi Wang, Yan Ye</a></li>
<li><strong>Subjects: </strong>cs.CV, eess.IV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.09768">https://arxiv.org/abs/2410.09768</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.09768">https://arxiv.org/pdf/2410.09768</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.09768]] Compressing Scene Dynamics: A Generative Approach(https://arxiv.org/abs/2410.09768)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, generative</a></li>
<li><strong>Abstract: </strong>This paper proposes to learn generative priors from the motion patterns instead of video contents for generative video compression. The priors are derived from small motion dynamics in common scenes such as swinging trees in the wind and floating boat on the sea. Utilizing such compact motion priors, a novel generative scene dynamics compression framework is built to realize ultra-low bit-rate communication and high-quality reconstruction for diverse scene contents. At the encoder side, motion priors are characterized into compact representations in a dense-to-sparse manner. At the decoder side, the decoded motion priors serve as the trajectory hints for scene dynamics reconstruction via a diffusion-based flow-driven generator. The experimental results illustrate that the proposed method can achieve superior rate-distortion performance and outperform the state-of-the-art conventional video codec Versatile Video Coding (VVC) on scene dynamics sequences. The project page can be found at this https URL.</li>
</ul>

<h3>Title: 'Quis custodiet ipsos custodes?' Who will watch the watchmen? On Detecting AI-generated peer-reviews</h3>
<ul>
<li><strong>Authors: </strong>Sandeep Kumar, Mohit Sahu, Vardhan Gacche, Tirthankar Ghosal, Asif Ekbal</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.DL, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.09770">https://arxiv.org/abs/2410.09770</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.09770">https://arxiv.org/pdf/2410.09770</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.09770]] 'Quis custodiet ipsos custodes?' Who will watch the watchmen? On Detecting AI-generated peer-reviews(https://arxiv.org/abs/2410.09770)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack, robust, large language model</a></li>
<li><strong>Abstract: </strong>The integrity of the peer-review process is vital for maintaining scientific rigor and trust within the academic community. With the steady increase in the usage of large language models (LLMs) like ChatGPT in academic writing, there is a growing concern that AI-generated texts could compromise scientific publishing, including peer-reviews. Previous works have focused on generic AI-generated text detection or have presented an approach for estimating the fraction of peer-reviews that can be AI-generated. Our focus here is to solve a real-world problem by assisting the editor or chair in determining whether a review is written by ChatGPT or not. To address this, we introduce the Term Frequency (TF) model, which posits that AI often repeats tokens, and the Review Regeneration (RR) model, which is based on the idea that ChatGPT generates similar outputs upon re-prompting. We stress test these detectors against token attack and paraphrasing. Finally, we propose an effective defensive strategy to reduce the effect of paraphrasing on our models. Our findings suggest both our proposed methods perform better than the other AI text detectors. Our RR model is more robust, although our TF model performs better than the RR model without any attacks. We make our code, dataset, and model public.</li>
</ul>

<h3>Title: ECIS-VQG: Generation of Entity-centric Information-seeking Questions from Videos</h3>
<ul>
<li><strong>Authors: </strong>Arpan Phukan, Manish Gupta, Asif Ekbal</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.09776">https://arxiv.org/abs/2410.09776</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.09776">https://arxiv.org/pdf/2410.09776</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.09776]] ECIS-VQG: Generation of Entity-centric Information-seeking Questions from Videos(https://arxiv.org/abs/2410.09776)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Previous studies on question generation from videos have mostly focused on generating questions about common objects and attributes and hence are not entity-centric. In this work, we focus on the generation of entity-centric information-seeking questions from videos. Such a system could be useful for video-based learning, recommending ``People Also Ask'' questions, video-based chatbots, and fact-checking. Our work addresses three key challenges: identifying question-worthy information, linking it to entities, and effectively utilizing multimodal signals. Further, to the best of our knowledge, there does not exist a large-scale dataset for this task. Most video question generation datasets are on TV shows, movies, or human activities or lack entity-centric information-seeking questions. Hence, we contribute a diverse dataset of YouTube videos, VideoQuestions, consisting of 411 videos with 2265 manually annotated questions. We further propose a model architecture combining Transformers, rich context signals (titles, transcripts, captions, embeddings), and a combination of cross-entropy and contrastive loss function to encourage entity-centric question generation. Our best method yields BLEU, ROUGE, CIDEr, and METEOR scores of 71.3, 78.6, 7.31, and 81.9, respectively, demonstrating practical usability. We make the code and dataset publicly available. this https URL</li>
</ul>

<h3>Title: Expanding Search Space with Diverse Prompting Agents: An Efficient Sampling Approach for LLM Mathematical Reasoning</h3>
<ul>
<li><strong>Authors: </strong>Gisang Lee, Sangwoo Park, Junyoung Park, Andrew Chung, Sieun Park, Yoonah Park, Byungju Kim, Min-gyu Cho</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.09780">https://arxiv.org/abs/2410.09780</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.09780">https://arxiv.org/pdf/2410.09780</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.09780]] Expanding Search Space with Diverse Prompting Agents: An Efficient Sampling Approach for LLM Mathematical Reasoning(https://arxiv.org/abs/2410.09780)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large Language Models (LLMs) have exhibited remarkable capabilities in many complex tasks including mathematical reasoning. However, traditional approaches heavily rely on ensuring self-consistency within single prompting method, which limits the exploration of diverse problem-solving strategies. This study addresses these limitations by performing an experimental analysis of distinct prompting methods within the domain of mathematical reasoning. Our findings demonstrate that each method explores a distinct search space, and this differentiation becomes more evident with increasing problem complexity. To leverage this phenomenon, we applied efficient sampling process that uniformly combines samples from these diverse methods, which not only expands the maximum search space but achieves higher performance with fewer runs compared to single methods. Especially, within the subset of difficult questions of MATH dataset named MATH-hard, The maximum search space was achieved while utilizing approximately 43% fewer runs than single methods on average. These findings highlight the importance of integrating diverse problem-solving strategies to enhance the reasoning abilities of LLMs.</li>
</ul>

<h3>Title: ContextWIN: Whittle Index Based Mixture-of-Experts Neural Model For Restless Bandits Via Deep RL</h3>
<ul>
<li><strong>Authors: </strong>Zhanqiu Guo, Wayne Wang</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.IR, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.09781">https://arxiv.org/abs/2410.09781</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.09781">https://arxiv.org/pdf/2410.09781</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.09781]] ContextWIN: Whittle Index Based Mixture-of-Experts Neural Model For Restless Bandits Via Deep RL(https://arxiv.org/abs/2410.09781)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>This study introduces ContextWIN, a novel architecture that extends the Neural Whittle Index Network (NeurWIN) model to address Restless Multi-Armed Bandit (RMAB) problems with a context-aware approach. By integrating a mixture of experts within a reinforcement learning framework, ContextWIN adeptly utilizes contextual information to inform decision-making in dynamic environments, particularly in recommendation systems. A key innovation is the model's ability to assign context-specific weights to a subset of NeurWIN networks, thus enhancing the efficiency and accuracy of the Whittle index computation for each arm. The paper presents a thorough exploration of ContextWIN, from its conceptual foundation to its implementation and potential applications. We delve into the complexities of RMABs and the significance of incorporating context, highlighting how ContextWIN effectively harnesses these elements. The convergence of both the NeurWIN and ContextWIN models is rigorously proven, ensuring theoretical robustness. This work lays the groundwork for future advancements in applying contextual information to complex decision-making scenarios, recognizing the need for comprehensive dataset exploration and environment development for full potential realization.</li>
</ul>

<h3>Title: DFIMat: Decoupled Flexible Interactive Matting in Multi-Person Scenarios</h3>
<ul>
<li><strong>Authors: </strong>Siyi Jiao, Wenzheng Zeng, Changxin Gao, Nong Sang</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.09788">https://arxiv.org/abs/2410.09788</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.09788">https://arxiv.org/pdf/2410.09788</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.09788]] DFIMat: Decoupled Flexible Interactive Matting in Multi-Person Scenarios(https://arxiv.org/abs/2410.09788)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability</a></li>
<li><strong>Abstract: </strong>Interactive portrait matting refers to extracting the soft portrait from a given image that best meets the user's intent through their inputs. Existing methods often underperform in complex scenarios, mainly due to three factors. (1) Most works apply a tightly coupled network that directly predicts matting results, lacking interpretability and resulting in inadequate modeling. (2) Existing works are limited to a single type of user input, which is ineffective for intention understanding and also inefficient for user operation. (3) The multi-round characteristics have been under-explored, which is crucial for user interaction. To alleviate these limitations, we propose DFIMat, a decoupled framework that enables flexible interactive matting. Specifically, we first decouple the task into 2 sub-ones: localizing target instances by understanding scene semantics and the flexible user inputs, and conducting refinement for instance-level matting. We observe a clear performance gain from decoupling, as it makes sub-tasks easier to learn, and the flexible multi-type input further enhances both effectiveness and efficiency. DFIMat also considers the multi-round interaction property, where a contrastive reasoning module is designed to enhance cross-round refinement. Another limitation for multi-person matting task is the lack of training data. We address this by introducing a new synthetic data generation pipeline that can generate much more realistic samples than previous arts. A new large-scale dataset SMPMat is subsequently established. Experiments verify the significant superiority of DFIMat. With it, we also investigate the roles of different input types, providing valuable principles for users. Our code and dataset can be found at this https URL.</li>
</ul>

<h3>Title: Intermediate Representations for Enhanced Text-To-Image Generation Using Diffusion Models</h3>
<ul>
<li><strong>Authors: </strong>Ran Galun, Sagie Benaim</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.09792">https://arxiv.org/abs/2410.09792</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.09792">https://arxiv.org/pdf/2410.09792</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.09792]] Intermediate Representations for Enhanced Text-To-Image Generation Using Diffusion Models(https://arxiv.org/abs/2410.09792)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, generative, segmentation</a></li>
<li><strong>Abstract: </strong>Text-to-image diffusion models have demonstrated an impressive ability to produce high-quality outputs. However, they often struggle to accurately follow fine-grained spatial information in an input text. To this end, we propose a compositional approach for text-to-image generation based on two stages. In the first stage, we design a diffusion-based generative model to produce one or more aligned intermediate representations (such as depth or segmentation maps) conditioned on text. In the second stage, we map these representations, together with the text, to the final output image using a separate diffusion-based generative model. Our findings indicate that such compositional approach can improve image generation, resulting in a notable improvement in FID score and a comparable CLIP score, when compared to the standard non-compositional baseline.</li>
</ul>

<h3>Title: EBDM: Exemplar-guided Image Translation with Brownian-bridge Diffusion Models</h3>
<ul>
<li><strong>Authors: </strong>Eungbean Lee, Somi Jeong, Kwanghoon Sohn</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.09802">https://arxiv.org/abs/2410.09802</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.09802">https://arxiv.org/pdf/2410.09802</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.09802]] EBDM: Exemplar-guided Image Translation with Brownian-bridge Diffusion Models(https://arxiv.org/abs/2410.09802)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, diffusion</a></li>
<li><strong>Abstract: </strong>Exemplar-guided image translation, synthesizing photo-realistic images that conform to both structural control and style exemplars, is attracting attention due to its ability to enhance user control over style manipulation. Previous methodologies have predominantly depended on establishing dense correspondences across cross-domain inputs. Despite these efforts, they incur quadratic memory and computational costs for establishing dense correspondence, resulting in limited versatility and performance degradation. In this paper, we propose a novel approach termed Exemplar-guided Image Translation with Brownian-Bridge Diffusion Models (EBDM). Our method formulates the task as a stochastic Brownian bridge process, a diffusion process with a fixed initial point as structure control and translates into the corresponding photo-realistic image while being conditioned solely on the given exemplar image. To efficiently guide the diffusion process toward the style of exemplar, we delineate three pivotal components: the Global Encoder, the Exemplar Network, and the Exemplar Attention Module to incorporate global and detailed texture information from exemplar images. Leveraging Bridge diffusion, the network can translate images from structure control while exclusively conditioned on the exemplar style, leading to more robust training and inference processes. We illustrate the superiority of our method over competing approaches through comprehensive benchmark evaluations and visual results.</li>
</ul>

<h3>Title: BlackDAN: A Black-Box Multi-Objective Approach for Effective and Contextual Jailbreaking of Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Xinyuan Wang, Victor Shea-Jay Huang, Renmiao Chen, Hao Wang, Chengwei Pan, Lei Sha, Minlie Huang</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.AI, cs.CL, cs.LG, cs.NE</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.09804">https://arxiv.org/abs/2410.09804</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.09804">https://arxiv.org/pdf/2410.09804</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.09804]] BlackDAN: A Black-Box Multi-Objective Approach for Effective and Contextual Jailbreaking of Large Language Models(https://arxiv.org/abs/2410.09804)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, attack, robust, steal, large language model</a></li>
<li><strong>Abstract: </strong>While large language models (LLMs) exhibit remarkable capabilities across various tasks, they encounter potential security risks such as jailbreak attacks, which exploit vulnerabilities to bypass security measures and generate harmful outputs. Existing jailbreak strategies mainly focus on maximizing attack success rate (ASR), frequently neglecting other critical factors, including the relevance of the jailbreak response to the query and the level of stealthiness. This narrow focus on single objectives can result in ineffective attacks that either lack contextual relevance or are easily recognizable. In this work, we introduce BlackDAN, an innovative black-box attack framework with multi-objective optimization, aiming to generate high-quality prompts that effectively facilitate jailbreaking while maintaining contextual relevance and minimizing detectability. BlackDAN leverages Multiobjective Evolutionary Algorithms (MOEAs), specifically the NSGA-II algorithm, to optimize jailbreaks across multiple objectives including ASR, stealthiness, and semantic relevance. By integrating mechanisms like mutation, crossover, and Pareto-dominance, BlackDAN provides a transparent and interpretable process for generating jailbreaks. Furthermore, the framework allows customization based on user preferences, enabling the selection of prompts that balance harmfulness, relevance, and other factors. Experimental results demonstrate that BlackDAN outperforms traditional single-objective methods, yielding higher success rates and improved robustness across various LLMs and multimodal LLMs, while ensuring jailbreak responses are both relevant and less detectable.</li>
</ul>

<h3>Title: Single Ground Truth Is Not Enough: Add Linguistic Variability to Aspect-based Sentiment Analysis Evaluation</h3>
<ul>
<li><strong>Authors: </strong>Soyoung Yang, Hojun Cho, Jiyoung Lee, Sohee Yoon, Edward Choi, Jaegul Choo, Won Ik Cho</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.09807">https://arxiv.org/abs/2410.09807</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.09807">https://arxiv.org/pdf/2410.09807</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.09807]] Single Ground Truth Is Not Enough: Add Linguistic Variability to Aspect-based Sentiment Analysis Evaluation(https://arxiv.org/abs/2410.09807)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction, fair, large language model</a></li>
<li><strong>Abstract: </strong>Aspect-based sentiment analysis (ABSA) is the challenging task of extracting sentiment along with its corresponding aspects and opinions from human language. Due to the inherent variability of natural language, aspect and opinion terms can be expressed in various surface forms, making their accurate identification complex. Current evaluation methods for this task often restrict answers to a single ground truth, penalizing semantically equivalent predictions that differ in surface form. To address this limitation, we propose a novel, fully automated pipeline that augments existing test sets with alternative valid responses for aspect and opinion terms. This approach enables a fairer assessment of language models by accommodating linguistic diversity, resulting in higher human agreement than single-answer test sets (up to 10%p improvement in Kendall's Tau score). Our experimental results demonstrate that Large Language Models (LLMs) show substantial performance improvements over T5 models when evaluated using our augmented test set, suggesting that LLMs' capabilities in ABSA tasks may have been underestimated. This work contributes to a more comprehensive evaluation framework for ABSA, potentially leading to more accurate assessments of model performance in information extraction tasks, particularly those involving span extraction.</li>
</ul>

<h3>Title: Reverse Modeling in Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Sicheng Yu, Yuanchen Xu, Cunxiao Du, Yanying Zhou, Minghui Qiu, Qianru Sun, Hao Zhang, Jiawei Wu</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.09817">https://arxiv.org/abs/2410.09817</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.09817">https://arxiv.org/pdf/2410.09817</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.09817]] Reverse Modeling in Large Language Models(https://arxiv.org/abs/2410.09817)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Humans are accustomed to reading and writing in a forward manner, and this natural bias extends to text understanding in auto-regressive large language models (LLMs). This paper investigates whether LLMs, like humans, struggle with reverse modeling, specifically with reversed text inputs. We found that publicly available pre-trained LLMs cannot understand such inputs. However, LLMs trained from scratch with both forward and reverse texts can understand them equally well during inference. Our case study shows that different-content texts result in different losses if input (to LLMs) in different directions -- some get lower losses for forward while some for reverse. This leads us to a simple and nice solution for data selection based on the loss differences between forward and reverse directions. Using our selected data in continued pretraining can boost LLMs' performance by a large margin across different language understanding benchmarks.</li>
</ul>

<h3>Title: TopOC: Topological Deep Learning for Ovarian and Breast Cancer Diagnosis</h3>
<ul>
<li><strong>Authors: </strong>Saba Fatema, Brighton Nuwagira, Sayoni Chakraborty, Reyhan Gedik, Baris Coskunuzer</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.LG, math.AT</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.09818">https://arxiv.org/abs/2410.09818</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.09818">https://arxiv.org/pdf/2410.09818</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.09818]] TopOC: Topological Deep Learning for Ovarian and Breast Cancer Diagnosis(https://arxiv.org/abs/2410.09818)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Microscopic examination of slides prepared from tissue samples is the primary tool for detecting and classifying cancerous lesions, a process that is time-consuming and requires the expertise of experienced pathologists. Recent advances in deep learning methods hold significant potential to enhance medical diagnostics and treatment planning by improving accuracy, reproducibility, and speed, thereby reducing clinicians' workloads and turnaround times. However, the necessity for vast amounts of labeled data to train these models remains a major obstacle to the development of effective clinical decision support systems. In this paper, we propose the integration of topological deep learning methods to enhance the accuracy and robustness of existing histopathological image analysis models. Topological data analysis (TDA) offers a unique approach by extracting essential information through the evaluation of topological patterns across different color channels. While deep learning methods capture local information from images, TDA features provide complementary global features. Our experiments on publicly available histopathological datasets demonstrate that the inclusion of topological features significantly improves the differentiation of tumor types in ovarian and breast cancers.</li>
</ul>

<h3>Title: DAS3D: Dual-modality Anomaly Synthesis for 3D Anomaly Detection</h3>
<ul>
<li><strong>Authors: </strong>Kecen Li, Bingquan Dai, Jingjing Fu, Xinwen Hou</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.09821">https://arxiv.org/abs/2410.09821</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.09821">https://arxiv.org/pdf/2410.09821</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.09821]] DAS3D: Dual-modality Anomaly Synthesis for 3D Anomaly Detection(https://arxiv.org/abs/2410.09821)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>Synthesizing anomaly samples has proven to be an effective strategy for self-supervised 2D industrial anomaly detection. However, this approach has been rarely explored in multi-modality anomaly detection, particularly involving 3D and RGB images. In this paper, we propose a novel dual-modality augmentation method for 3D anomaly synthesis, which is simple and capable of mimicking the characteristics of 3D defects. Incorporating with our anomaly synthesis method, we introduce a reconstruction-based discriminative anomaly detection network, in which a dual-modal discriminator is employed to fuse the original and reconstructed embedding of two modalities for anomaly detection. Additionally, we design an augmentation dropout mechanism to enhance the generalizability of the discriminator. Extensive experiments show that our method outperforms the state-of-the-art methods on detection precision and achieves competitive segmentation performance on both MVTec 3D-AD and Eyescandies datasets.</li>
</ul>

<h3>Title: Simultaneous Computation and Memory Efficient Zeroth-Order Optimizer for Fine-Tuning Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Fei Wang, Li Shen, Liang Ding, Chao Xue, Ye Liu, Changxing Ding</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.09823">https://arxiv.org/abs/2410.09823</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.09823">https://arxiv.org/pdf/2410.09823</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.09823]] Simultaneous Computation and Memory Efficient Zeroth-Order Optimizer for Fine-Tuning Large Language Models(https://arxiv.org/abs/2410.09823)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative, large language model</a></li>
<li><strong>Abstract: </strong>Fine-tuning is powerful for adapting large language models to downstream tasks, but it often results in huge memory usages. A promising approach to mitigate this is using Zeroth-Order (ZO) optimization, which estimates gradients to replace First-Order (FO) gradient calculations, albeit with longer training time due to its stochastic nature. By revisiting the Memory-efficient ZO (MeZO) optimizer, we discover that the full-parameter perturbation and updating processes consume over 50% of its overall fine-tuning time cost. Based on these observations, we introduce a novel layer-wise sparse computation and memory efficient ZO optimizer, named LeZO. LeZO treats layers as fundamental units for sparsification and dynamically perturbs different parameter subsets in each step to achieve full-parameter fine-tuning. LeZO incorporates layer-wise parameter sparsity in the process of simultaneous perturbation stochastic approximation (SPSA) and ZO stochastic gradient descent (ZO-SGD). It achieves accelerated computation during perturbation and updating processes without additional memory overhead. We conduct extensive experiments with the OPT model family on the SuperGLUE benchmark and two generative tasks. The experiments show that LeZO accelerates training without compromising the performance of ZO optimization. Specifically, it achieves over 3x speedup compared to MeZO on the SST-2, BoolQ, and Copa tasks.</li>
</ul>

<h3>Title: Dynamic and Textual Graph Generation Via Large-Scale LLM-based Agent Simulation</h3>
<ul>
<li><strong>Authors: </strong>Jiarui Ji, Runlin Lei, Jialing Bi, Zhewei Wei, Yankai Lin, Xuchen Pan, Yaliang Li, Bolin Ding</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.09824">https://arxiv.org/abs/2410.09824</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.09824">https://arxiv.org/pdf/2410.09824</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.09824]] Dynamic and Textual Graph Generation Via Large-Scale LLM-based Agent Simulation(https://arxiv.org/abs/2410.09824)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Graph generation is a fundamental task that has been extensively studied in social, technological, and scientific analysis. For modeling the dynamic graph evolution process, traditional rule-based methods struggle to capture community structures within graphs, while deep learning methods only focus on fitting training graphs. This limits existing graph generators to producing graphs that adhere to predefined rules or closely resemble training datasets, achieving poor performance in dynamic graph generation. Given that graphs are abstract representations arising from pairwise interactions in human activities, a realistic simulation of human-wise interaction could provide deeper insights into the graph evolution mechanism. With the increasing recognition of large language models (LLMs) in simulating human behavior, we introduce GraphAgent-Generator (GAG), a novel simulation-based framework for dynamic graph generation. Without training or fine-tuning process of LLM, our framework effectively replicates seven macro-level structural characteristics in established network science theories while surpassing existing baselines in graph expansion tasks by 31\% on specific evaluation metrics. Through node classification task, we validate GAG effectively preserves characteristics of real-world network for node-wise textual features in generated text-rich graph. Furthermore, by incorporating parallel acceleration, GAG supports generating graphs with up to nearly 100,000 nodes or 10 million edges through large-scale LLM-based agent simulation, with a minimum speed-up of 90.4\%. The source code is available at this https URL.</li>
</ul>

<h3>Title: Generating Driving Simulations via Conversation</h3>
<ul>
<li><strong>Authors: </strong>Rimvydas Rubavicius, Antonio Valerio Miceli-Barone, Alex Lascarides, Subramanian Ramamoorthy</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.IR, cs.RO</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.09829">https://arxiv.org/abs/2410.09829</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.09829">https://arxiv.org/pdf/2410.09829</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.09829]] Generating Driving Simulations via Conversation(https://arxiv.org/abs/2410.09829)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Cyber-physical systems like autonomous vehicles are tested in simulation before deployment, using domain-specific programs for scenario specification. To aid the testing of autonomous vehicles in simulation, we design a natural language interface, using an instruction-following large language model, to assist a non-coding domain expert in synthesising the desired scenarios and vehicle behaviours. We show that using it to convert utterances to the symbolic program is feasible, despite the very small training dataset. Human experiments show that dialogue is critical to successful simulation generation, leading to a 4.5 times higher success rate than a generation without engaging in extended conversation.</li>
</ul>

<h3>Title: LoLI-Street: Benchmarking Low-Light Image Enhancement and Beyond</h3>
<ul>
<li><strong>Authors: </strong>Md Tanvir Islam, Inzamamul Alam, Simon S. Woo, Saeed Anwar, IK Hyun Lee, Khan Muhammad</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI, cs.CE</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.09831">https://arxiv.org/abs/2410.09831</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.09831">https://arxiv.org/pdf/2410.09831</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.09831]] LoLI-Street: Benchmarking Low-Light Image Enhancement and Beyond(https://arxiv.org/abs/2410.09831)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, diffusion, transformer, segmentation</a></li>
<li><strong>Abstract: </strong>Low-light image enhancement (LLIE) is essential for numerous computer vision tasks, including object detection, tracking, segmentation, and scene understanding. Despite substantial research on improving low-quality images captured in underexposed conditions, clear vision remains critical for autonomous vehicles, which often struggle with low-light scenarios, signifying the need for continuous research. However, paired datasets for LLIE are scarce, particularly for street scenes, limiting the development of robust LLIE methods. Despite using advanced transformers and/or diffusion-based models, current LLIE methods struggle in real-world low-light conditions and lack training on street-scene datasets, limiting their effectiveness for autonomous vehicles. To bridge these gaps, we introduce a new dataset LoLI-Street (Low-Light Images of Streets) with 33k paired low-light and well-exposed images from street scenes in developed cities, covering 19k object classes for object detection. LoLI-Street dataset also features 1,000 real low-light test images for testing LLIE models under real-life conditions. Furthermore, we propose a transformer and diffusion-based LLIE model named "TriFuse". Leveraging the LoLI-Street dataset, we train and evaluate our TriFuse and SOTA models to benchmark on our dataset. Comparing various models, our dataset's generalization feasibility is evident in testing across different mainstream datasets by significantly enhancing images and object detection for practical applications in autonomous driving and surveillance systems. The complete code and dataset is available on this https URL.</li>
</ul>

<h3>Title: Toward Defining an Efficient and Expandable File Format for AI-Generated Contents</h3>
<ul>
<li><strong>Authors: </strong>Yixin Gao, Runsen Feng, Xin Li, Weiping Li, Zhibo Chen</a></li>
<li><strong>Subjects: </strong>cs.CV, eess.IV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.09834">https://arxiv.org/abs/2410.09834</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.09834">https://arxiv.org/pdf/2410.09834</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.09834]] Toward Defining an Efficient and Expandable File Format for AI-Generated Contents(https://arxiv.org/abs/2410.09834)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>Recently, AI-generated content (AIGC) has gained significant traction due to its powerful creation capability. However, the storage and transmission of large amounts of high-quality AIGC images inevitably pose new challenges for recent file formats. To overcome this, we define a new file format for AIGC images, named AIGIF, enabling ultra-low bitrate coding of AIGC images. Unlike compressing AIGC images intuitively with pixel-wise space as existing file formats, AIGIF instead compresses the generation syntax. This raises a crucial question: Which generation syntax elements, e.g., text prompt, device configuration, etc, are necessary for compression/transmission? To answer this question, we systematically investigate the effects of three essential factors: platform, generative model, and data configuration. We experimentally find that a well-designed composable bitstream structure incorporating the above three factors can achieve an impressive compression ratio of even up to 1/10,000 while still ensuring high fidelity. We also introduce an expandable syntax in AIGIF to support the extension of the most advanced generation models to be developed in the future.</li>
</ul>

<h3>Title: Uncovering, Explaining, and Mitigating the Superficial Safety of Backdoor Defense</h3>
<ul>
<li><strong>Authors: </strong>Rui Min, Zeyu Qin, Nevin L. Zhang, Li Shen, Minhao Cheng</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.09838">https://arxiv.org/abs/2410.09838</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.09838">https://arxiv.org/pdf/2410.09838</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.09838]] Uncovering, Explaining, and Mitigating the Superficial Safety of Backdoor Defense(https://arxiv.org/abs/2410.09838)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, defense, attack, robust</a></li>
<li><strong>Abstract: </strong>Backdoor attacks pose a significant threat to Deep Neural Networks (DNNs) as they allow attackers to manipulate model predictions with backdoor triggers. To address these security vulnerabilities, various backdoor purification methods have been proposed to purify compromised models. Typically, these purified models exhibit low Attack Success Rates (ASR), rendering them resistant to backdoored inputs. However, Does achieving a low ASR through current safety purification methods truly eliminate learned backdoor features from the pretraining phase? In this paper, we provide an affirmative answer to this question by thoroughly investigating the Post-Purification Robustness of current backdoor purification methods. We find that current safety purification methods are vulnerable to the rapid re-learning of backdoor behavior, even when further fine-tuning of purified models is performed using a very small number of poisoned samples. Based on this, we further propose the practical Query-based Reactivation Attack (QRA) which could effectively reactivate the backdoor by merely querying purified models. We find the failure to achieve satisfactory post-tuning robustness stems from the insufficient deviation of purified models from the backdoored model along the backdoor-connected path. To improve the post-purification robustness, we propose a straightforward tuning defense, Path-Aware Minimization (PAM), which promotes deviation along backdoor-connected paths with extra model updates. Extensive experiments demonstrate that PAM significantly improves post-purification robustness while maintaining a good clean accuracy and low ASR. Our work provides a new perspective on understanding the effectiveness of backdoor safety tuning and highlights the importance of faithfully assessing the model's safety.</li>
</ul>

<h3>Title: RISC-V Needs Secure 'Wheels': the MCU Initiator-Side Perspective</h3>
<ul>
<li><strong>Authors: </strong>Sandro Pinto, Jose Martins, Manuel Rodriguez, Luis Cunha, Georg Schmalz, Uwe Moslehner, Kai Dieffenbach, Thomas Roecker</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.AR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.09839">https://arxiv.org/abs/2410.09839</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.09839">https://arxiv.org/pdf/2410.09839</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.09839]] RISC-V Needs Secure 'Wheels': the MCU Initiator-Side Perspective(https://arxiv.org/abs/2410.09839)</code><input type="text"></li>
<li><strong>Keywords: </strong>secure, security, protect, attack</a></li>
<li><strong>Abstract: </strong>The automotive industry is experiencing a massive paradigm shift. Cars are becoming increasingly autonomous, connected, and computerized. Modern electrical/electronic (E/E) architectures are pushing for an unforeseen functionality integration density, resulting in physically separate Electronic Control Units (ECUs) becoming virtualized and mapped to logical partitions within a single physical microcontroller (MCU). While functional safety (FuSa) has been pivotal for vehicle certification for decades, the increasing connectivity and advances have opened the door for a number of car hacks and attacks. This development drives (cyber-)security requirements in cars, and has paved the way for the release of the new security certification standard ISO21434. RISC-V has great potential to transform automotive computing systems, but we argue that current ISA/extensions are not ready yet. This paper provides our critical perspective on the existing RISC-V limitations, particularly on the upcoming WorldGuard technology, to address virtualized MCU requirements in line with foreseen automotive applications and ISO21434 directives. We then present our proposal for the required ISA extensions to address such limitations, mainly targeting initiator-side protection. Finally, we explain our roadmap towards a full open-source proof-of-concept (PoC), which includes extending QEMU, an open-source RISC-V core, and building a complete software stack.</li>
</ul>

<h3>Title: Understanding Robustness of Parameter-Efficient Tuning for Image Classification</h3>
<ul>
<li><strong>Authors: </strong>Jiacheng Ruan, Xian Gao, Suncheng Xiang, Mingye Xie, Ting Liu, Yuzhuo Fu</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.09845">https://arxiv.org/abs/2410.09845</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.09845">https://arxiv.org/pdf/2410.09845</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.09845]] Understanding Robustness of Parameter-Efficient Tuning for Image Classification(https://arxiv.org/abs/2410.09845)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack, robust</a></li>
<li><strong>Abstract: </strong>Parameter-efficient tuning (PET) techniques calibrate the model's predictions on downstream tasks by freezing the pre-trained models and introducing a small number of learnable parameters. However, despite the numerous PET methods proposed, their robustness has not been thoroughly investigated. In this paper, we systematically explore the robustness of four classical PET techniques (e.g., VPT, Adapter, AdaptFormer, and LoRA) under both white-box attacks and information perturbations. For white-box attack scenarios, we first analyze the performance of PET techniques using FGSM and PGD attacks. Subsequently, we further explore the transferability of adversarial samples and the impact of learnable parameter quantities on the robustness of PET methods. Under information perturbation attacks, we introduce four distinct perturbation strategies, including Patch-wise Drop, Pixel-wise Drop, Patch Shuffle, and Gaussian Noise, to comprehensively assess the robustness of these PET techniques in the presence of information loss. Via these extensive studies, we enhance the understanding of the robustness of PET methods, providing valuable insights for improving their performance in computer vision applications. The code is available at this https URL.</li>
</ul>

<h3>Title: Text4Seg: Reimagining Image Segmentation as Text Generation</h3>
<ul>
<li><strong>Authors: </strong>Mengcheng Lan, Chaofeng Chen, Yue Zhou, Jiaxing Xu, Yiping Ke, Xinjiang Wang, Litong Feng, Wayne Zhang</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.09855">https://arxiv.org/abs/2410.09855</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.09855">https://arxiv.org/pdf/2410.09855</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.09855]] Text4Seg: Reimagining Image Segmentation as Text Generation(https://arxiv.org/abs/2410.09855)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model, segmentation</a></li>
<li><strong>Abstract: </strong>Multimodal Large Language Models (MLLMs) have shown exceptional capabilities in vision-language tasks; however, effectively integrating image segmentation into these models remains a significant challenge. In this paper, we introduce Text4Seg, a novel text-as-mask paradigm that casts image segmentation as a text generation problem, eliminating the need for additional decoders and significantly simplifying the segmentation process. Our key innovation is semantic descriptors, a new textual representation of segmentation masks where each image patch is mapped to its corresponding text label. This unified representation allows seamless integration into the auto-regressive training pipeline of MLLMs for easier optimization. We demonstrate that representing an image with $16\times16$ semantic descriptors yields competitive segmentation performance. To enhance efficiency, we introduce the Row-wise Run-Length Encoding (R-RLE), which compresses redundant text sequences, reducing the length of semantic descriptors by 74% and accelerating inference by $3\times$, without compromising performance. Extensive experiments across various vision tasks, such as referring expression segmentation and comprehension, show that Text4Seg achieves state-of-the-art performance on multiple datasets by fine-tuning different MLLM backbones. Our approach provides an efficient, scalable solution for vision-centric tasks within the MLLM framework.</li>
</ul>

<h3>Title: Human Identification using Selected Features from Finger Geometric Profiles</h3>
<ul>
<li><strong>Authors: </strong>Asish Bera, Debotosh Bhattacharjee</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.09856">https://arxiv.org/abs/2410.09856</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.09856">https://arxiv.org/pdf/2410.09856</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.09856]] Human Identification using Selected Features from Finger Geometric Profiles(https://arxiv.org/abs/2410.09856)</code><input type="text"></li>
<li><strong>Keywords: </strong>biometric, extraction</a></li>
<li><strong>Abstract: </strong>A finger biometric system at an unconstrained environment is presented in this paper. A technique for hand image normalization is implemented at the preprocessing stage that decomposes the main hand contour into finger-level shape representation. This normalization technique follows subtraction of transformed binary image from binary hand contour image to generate the left side of finger profiles (LSFP). Then, XOR is applied to LSFP image and hand contour image to produce the right side of finger profiles (RSFP). During feature extraction, initially, thirty geometric features are computed from every normalized finger. The rank-based forward-backward greedy algorithm is followed to select relevant features and to enhance classification accuracy. Two different subsets of features containing nine and twelve discriminative features per finger are selected for two separate experimentations those use the kNN and the Random Forest (RF) for classification on the Bosphorus hand database. The experiments with the selected features of four fingers except the thumb have obtained improved performances compared to features extracted from five fingers and also other existing methods evaluated on the Bosphorus database. The best identification accuracies of 96.56% and 95.92% using the RF classifier have been achieved for the right- and left-hand images of 638 sub-jects, respectively. An equal error rate of 0.078 is obtained for both types of the hand images.</li>
</ul>

<h3>Title: AuthFace: Towards Authentic Blind Face Restoration with Face-oriented Generative Diffusion Prior</h3>
<ul>
<li><strong>Authors: </strong>Guoqiang Liang, Qingnan Fan, Bingtao Fu, Jinwei Chen, Hong Gu, Lin Wang</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.09864">https://arxiv.org/abs/2410.09864</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.09864">https://arxiv.org/pdf/2410.09864</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.09864]] AuthFace: Towards Authentic Blind Face Restoration with Face-oriented Generative Diffusion Prior(https://arxiv.org/abs/2410.09864)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, generative</a></li>
<li><strong>Abstract: </strong>Blind face restoration (BFR) is a fundamental and challenging problem in computer vision. To faithfully restore high-quality (HQ) photos from poor-quality ones, recent research endeavors predominantly rely on facial image priors from the powerful pretrained text-to-image (T2I) diffusion models. However, such priors often lead to the incorrect generation of non-facial features and insufficient facial details, thus rendering them less practical for real-world applications. In this paper, we propose a novel framework, namely AuthFace that achieves highly authentic face restoration results by exploring a face-oriented generative diffusion prior. To learn such a prior, we first collect a dataset of 1.5K high-quality images, with resolutions exceeding 8K, captured by professional photographers. Based on the dataset, we then introduce a novel face-oriented restoration-tuning pipeline that fine-tunes a pretrained T2I model. Identifying key criteria of quality-first and photography-guided annotation, we involve the retouching and reviewing process under the guidance of photographers for high-quality images that show rich facial features. The photography-guided annotation system fully explores the potential of these high-quality photographic images. In this way, the potent natural image priors from pretrained T2I diffusion models can be subtly harnessed, specifically enhancing their capability in facial detail restoration. Moreover, to minimize artifacts in critical facial areas, such as eyes and mouth, we propose a time-aware latent facial feature loss to learn the authentic face restoration process. Extensive experiments on the synthetic and real-world BFR datasets demonstrate the superiority of our approach.</li>
</ul>

<h3>Title: SynFER: Towards Boosting Facial Expression Recognition with Synthetic Data</h3>
<ul>
<li><strong>Authors: </strong>Xilin He, Cheng Luo, Xiaole Xian, Bing Li, Siyang Song, Muhammad Haris Khan, Weicheng Xie, Linlin Shen, Zongyuan Ge</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.09865">https://arxiv.org/abs/2410.09865</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.09865">https://arxiv.org/pdf/2410.09865</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.09865]] SynFER: Towards Boosting Facial Expression Recognition with Synthetic Data(https://arxiv.org/abs/2410.09865)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy</a></li>
<li><strong>Abstract: </strong>Facial expression datasets remain limited in scale due to privacy concerns, the subjectivity of annotations, and the labor-intensive nature of data collection. This limitation poses a significant challenge for developing modern deep learning-based facial expression analysis models, particularly foundation models, that rely on large-scale data for optimal performance. To tackle the overarching and complex challenge, we introduce SynFER (Synthesis of Facial Expressions with Refined Control), a novel framework for synthesizing facial expression image data based on high-level textual descriptions as well as more fine-grained and precise control through facial action units. To ensure the quality and reliability of the synthetic data, we propose a semantic guidance technique to steer the generation process and a pseudo-label generator to help rectify the facial expression labels for the synthetic images. To demonstrate the generation fidelity and the effectiveness of the synthetic data from SynFER, we conduct extensive experiments on representation learning using both synthetic data and real-world data. Experiment results validate the efficacy of the proposed approach and the synthetic data. Notably, our approach achieves a 67.23% classification accuracy on AffectNet when training solely with synthetic data equivalent to the AffectNet training set size, which increases to 69.84% when scaling up to five times the original size. Our code will be made publicly available.</li>
</ul>

<h3>Title: Two-Stage Human Verification using HandCAPTCHA and Anti-Spoofed Finger Biometrics with Feature Selection</h3>
<ul>
<li><strong>Authors: </strong>Asish Bera, Debotosh Bhattacharjee, Hubert P H Shum</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.09866">https://arxiv.org/abs/2410.09866</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.09866">https://arxiv.org/pdf/2410.09866</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.09866]] Two-Stage Human Verification using HandCAPTCHA and Anti-Spoofed Finger Biometrics with Feature Selection(https://arxiv.org/abs/2410.09866)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, attack, biometric</a></li>
<li><strong>Abstract: </strong>This paper presents a human verification scheme in two independent stages to overcome the vulnerabilities of attacks and to enhance security. At the first stage, a hand image-based CAPTCHA (HandCAPTCHA) is tested to avert automated bot-attacks on the subsequent biometric stage. In the next stage, finger biometric verification of a legitimate user is performed with presentation attack detection (PAD) using the real hand images of the person who has passed a random HandCAPTCHA challenge. The electronic screen-based PAD is tested using image quality metrics. After this spoofing detection, geometric features are extracted from the four fingers (excluding the thumb) of real users. A modified forward-backward (M-FoBa) algorithm is devised to select relevant features for biometric authentication. The experiments are performed on the Bogazici University (BU) and the IIT-Delhi (IITD) hand databases using the k-nearest neighbor and random forest classifiers. The average accuracy of the correct HandCAPTCHA solution is 98.5%, and the false accept rate of a bot is 1.23%. The PAD is tested on 255 subjects of BU, and the best average error is 0%. The finger biometric identification accuracy of 98% and an equal error rate (EER) of 6.5% have been achieved for 500 subjects of the BU. For 200 subjects of the IITD, 99.5% identification accuracy, and 5.18% EER are obtained.</li>
</ul>

<h3>Title: ChroKnowledge: Unveiling Chronological Knowledge of Language Models in Multiple Domains</h3>
<ul>
<li><strong>Authors: </strong>Yein Park, Chanwoong Yoon, Jungwoo Park, Donghyeon Lee, Minbyul Jeong, Jaewoo Kang</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.09870">https://arxiv.org/abs/2410.09870</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.09870">https://arxiv.org/pdf/2410.09870</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.09870]] ChroKnowledge: Unveiling Chronological Knowledge of Language Models in Multiple Domains(https://arxiv.org/abs/2410.09870)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large language models (LLMs) have significantly impacted many aspects of our lives. However, assessing and ensuring their chronological knowledge remains challenging. Existing approaches fall short in addressing the accumulative nature of knowledge, often relying on a single time stamp. To overcome this, we introduce ChroKnowBench, a benchmark dataset designed to evaluate chronologically accumulated knowledge across three key aspects: multiple domains, time dependency, temporal state. Our benchmark distinguishes between knowledge that evolves (e.g., scientific discoveries, amended laws) and knowledge that remain constant (e.g., mathematical truths, commonsense facts). Building on this benchmark, we present ChroKnowledge (Chronological Categorization of Knowledge), a novel sampling-based framework for evaluating and updating LLMs' non-parametric chronological knowledge. Our evaluation shows: (1) The ability of eliciting temporal knowledge varies depending on the data format that model was trained on. (2) LLMs partially recall knowledge or show a cut-off at temporal boundaries rather than recalling all aspects of knowledge correctly. Thus, we apply our ChroKnowPrompt, an in-depth prompting to elicit chronological knowledge by traversing step-by-step through the surrounding time spans. We observe that our framework successfully updates the overall knowledge across the entire timeline in both the biomedical domain (+11.9%) and the general domain (+2.8%), demonstrating its effectiveness in refining temporal knowledge. This non-parametric approach also enables knowledge updates not only in open-source models but also in proprietary LLMs, ensuring comprehensive applicability across model types. We perform a comprehensive analysis based on temporal characteristics of ChroKnowPrompt and validate the potential of various models to elicit intrinsic temporal knowledge through our method.</li>
</ul>

<h3>Title: Towards Reproducible Learning-based Compression</h3>
<ul>
<li><strong>Authors: </strong>Jiahao Pang, Muhammad Asad Lodhi, Junghyun Ahn, Yuning Huang, Dong Tian</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.MM</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.09872">https://arxiv.org/abs/2410.09872</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.09872">https://arxiv.org/pdf/2410.09872</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.09872]] Towards Reproducible Learning-based Compression(https://arxiv.org/abs/2410.09872)</code><input type="text"></li>
<li><strong>Keywords: </strong>protect</a></li>
<li><strong>Abstract: </strong>A deep learning system typically suffers from a lack of reproducibility that is partially rooted in hardware or software implementation details. The irreproducibility leads to skepticism in deep learning technologies and it can hinder them from being deployed in many applications. In this work, the irreproducibility issue is analyzed where deep learning is employed in compression systems while the encoding and decoding may be run on devices from different manufacturers. The decoding process can even crash due to a single bit difference, e.g., in a learning-based entropy coder. For a given deep learning-based module with limited resources for protection, we first suggest that reproducibility can only be assured when the mismatches are bounded. Then a safeguarding mechanism is proposed to tackle the challenges. The proposed method may be applied for different levels of protection either at the reconstruction level or at a selected decoding level. Furthermore, the overhead introduced for the protection can be scaled down accordingly when the error bound is being suppressed. Experiments demonstrate the effectiveness of the proposed approach for learning-based compression systems, e.g., in image compression and point cloud compression.</li>
</ul>

<h3>Title: Training-Free Adaptive Diffusion with Bounded Difference Approximation Strategy</h3>
<ul>
<li><strong>Authors: </strong>Hancheng Ye, Jiakang Yuan, Renqiu Xia, Xiangchao Yan, Tao Chen, Junchi Yan, Botian Shi, Bo Zhang</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.09873">https://arxiv.org/abs/2410.09873</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.09873">https://arxiv.org/pdf/2410.09873</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.09873]] Training-Free Adaptive Diffusion with Bounded Difference Approximation Strategy(https://arxiv.org/abs/2410.09873)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>Diffusion models have recently achieved great success in the synthesis of high-quality images and videos. However, the existing denoising techniques in diffusion models are commonly based on step-by-step noise predictions, which suffers from high computation cost, resulting in a prohibitive latency for interactive applications. In this paper, we propose AdaptiveDiffusion to relieve this bottleneck by adaptively reducing the noise prediction steps during the denoising process. Our method considers the potential of skipping as many noise prediction steps as possible while keeping the final denoised results identical to the original full-step ones. Specifically, the skipping strategy is guided by the third-order latent difference that indicates the stability between timesteps during the denoising process, which benefits the reusing of previous noise prediction results. Extensive experiments on image and video diffusion models demonstrate that our method can significantly speed up the denoising process while generating identical results to the original process, achieving up to an average 2~5x speedup without quality degradation.</li>
</ul>

<h3>Title: ViFi-ReID: A Two-Stream Vision-WiFi Multimodal Approach for Person Re-identification</h3>
<ul>
<li><strong>Authors: </strong>Chen Mao, Chong Tan, Jingqi Hu, Min Zheng</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.IR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.09875">https://arxiv.org/abs/2410.09875</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.09875">https://arxiv.org/pdf/2410.09875</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.09875]] ViFi-ReID: A Two-Stream Vision-WiFi Multimodal Approach for Person Re-identification(https://arxiv.org/abs/2410.09875)</code><input type="text"></li>
<li><strong>Keywords: </strong>security</a></li>
<li><strong>Abstract: </strong>Person re-identification(ReID), as a crucial technology in the field of security, plays a vital role in safety inspections, personnel counting, and more. Most current ReID approaches primarily extract features from images, which are easily affected by objective conditions such as clothing changes and occlusions. In addition to cameras, we leverage widely available routers as sensing devices by capturing gait information from pedestrians through the Channel State Information (CSI) in WiFi signals and contribute a multimodal dataset. We employ a two-stream network to separately process video understanding and signal analysis tasks, and conduct multi-modal fusion and contrastive learning on pedestrian video and WiFi data. Extensive experiments in real-world scenarios demonstrate that our method effectively uncovers the correlations between heterogeneous data, bridges the gap between visual and signal modalities, significantly expands the sensing range, and improves ReID accuracy across multiple sensors.</li>
</ul>

<h3>Title: Provably Reliable Conformal Prediction Sets in the Presence of Data Poisoning</h3>
<ul>
<li><strong>Authors: </strong>Yan Scholten, Stephan GÃ¼nnemann</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.09878">https://arxiv.org/abs/2410.09878</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.09878">https://arxiv.org/pdf/2410.09878</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.09878]] Provably Reliable Conformal Prediction Sets in the Presence of Data Poisoning(https://arxiv.org/abs/2410.09878)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack</a></li>
<li><strong>Abstract: </strong>Conformal prediction provides model-agnostic and distribution-free uncertainty quantification through prediction sets that are guaranteed to include the ground truth with any user-specified probability. Yet, conformal prediction is not reliable under poisoning attacks where adversaries manipulate both training and calibration data, which can significantly alter prediction sets in practice. As a solution, we propose reliable prediction sets (RPS): the first efficient method for constructing conformal prediction sets with provable reliability guarantees under poisoning. To ensure reliability under training poisoning, we introduce smoothed score functions that reliably aggregate predictions of classifiers trained on distinct partitions of the training data. To ensure reliability under calibration poisoning, we construct multiple prediction sets, each calibrated on distinct subsets of the calibration data. We then aggregate them into a majority prediction set, which includes a class only if it appears in a majority of the individual sets. Both proposed aggregations mitigate the influence of datapoints in the training and calibration data on the final prediction set. We experimentally validate our approach on image classification tasks, achieving strong reliability while maintaining utility and preserving coverage on clean data. Overall, our approach represents an important step towards more trustworthy uncertainty quantification in the presence of data poisoning.</li>
</ul>

<h3>Title: Improving Colorectal Cancer Screening and Risk Assessment through Predictive Modeling on Medical Images and Records</h3>
<ul>
<li><strong>Authors: </strong>Shuai Jiang, Christina Robinson, Joseph Anderson, William Hisey, Lynn Butterly, Arief Suriawinata, Saeed Hassanpour</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.09880">https://arxiv.org/abs/2410.09880</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.09880">https://arxiv.org/pdf/2410.09880</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.09880]] Improving Colorectal Cancer Screening and Risk Assessment through Predictive Modeling on Medical Images and Records(https://arxiv.org/abs/2410.09880)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Colonoscopy screening is an effective method to find and remove colon polyps before they can develop into colorectal cancer (CRC). Current follow-up recommendations, as outlined by the U.S. Multi-Society Task Force for individuals found to have polyps, primarily rely on histopathological characteristics, neglecting other significant CRC risk factors. Moreover, the considerable variability in colorectal polyp characterization among pathologists poses challenges in effective colonoscopy follow-up or surveillance. The evolution of digital pathology and recent advancements in deep learning provide a unique opportunity to investigate the added benefits of including the additional medical record information and automatic processing of pathology slides using computer vision techniques in the calculation of future CRC risk. Leveraging the New Hampshire Colonoscopy Registry's extensive dataset, many with longitudinal colonoscopy follow-up information, we adapted our recently developed transformer-based model for histopathology image analysis in 5-year CRC risk prediction. Additionally, we investigated various multimodal fusion techniques, combining medical record information with deep learning derived risk estimates. Our findings reveal that training a transformer model to predict intermediate clinical variables contributes to enhancing 5-year CRC risk prediction performance, with an AUC of 0.630 comparing to direct prediction. Furthermore, the fusion of imaging and non-imaging features, while not requiring manual inspection of microscopy images, demonstrates improved predictive capabilities for 5-year CRC risk comparing to variables extracted from colonoscopy procedure and microscopy findings. This study signifies the potential of integrating diverse data sources and advanced computational techniques in transforming the accuracy and effectiveness of future CRC risk assessments.</li>
</ul>

<h3>Title: RMB: Comprehensively Benchmarking Reward Models in LLM Alignment</h3>
<ul>
<li><strong>Authors: </strong>Enyu Zhou, Guodong Zheng, Binghai Wang, Zhiheng Xi, Shihan Dou, Rong Bao, Wei Shen, Limao Xiong, Jessica Fan, Yurong Mou, Rui Zheng, Tao Gui, Qi Zhang, Xuanjing Huang</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.09893">https://arxiv.org/abs/2410.09893</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.09893">https://arxiv.org/pdf/2410.09893</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.09893]] RMB: Comprehensively Benchmarking Reward Models in LLM Alignment(https://arxiv.org/abs/2410.09893)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative, large language model</a></li>
<li><strong>Abstract: </strong>Reward models (RMs) guide the alignment of large language models (LLMs), steering them toward behaviors preferred by humans. Evaluating RMs is the key to better aligning LLMs. However, the current evaluation of RMs may not directly correspond to their alignment performance due to the limited distribution of evaluation data and evaluation methods that are not closely related to alignment objectives. To address these limitations, we propose RMB, a comprehensive RM benchmark that covers over 49 real-world scenarios and includes both pairwise and Best-of-N (BoN) evaluations to better reflect the effectiveness of RMs in guiding alignment optimization. We demonstrate a positive correlation between our benchmark and the downstream alignment task performance. Based on our benchmark, we conduct extensive analysis on the state-of-the-art RMs, revealing their generalization defects that were not discovered by previous benchmarks, and highlighting the potential of generative RMs. Furthermore, we delve into open questions in reward models, specifically examining the effectiveness of majority voting for the evaluation of reward models and analyzing the impact factors of generative RMs, including the influence of evaluation criteria and instructing methods. Our evaluation code and datasets are available at this https URL.</li>
</ul>

<h3>Title: Multi class activity classification in videos using Motion History Image generation</h3>
<ul>
<li><strong>Authors: </strong>Senthilkumar Gopal</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.LG, eess.IV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.09902">https://arxiv.org/abs/2410.09902</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.09902">https://arxiv.org/pdf/2410.09902</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.09902]] Multi class activity classification in videos using Motion History Image generation(https://arxiv.org/abs/2410.09902)</code><input type="text"></li>
<li><strong>Keywords: </strong>security</a></li>
<li><strong>Abstract: </strong>Human action recognition has been a topic of interest across multiple fields ranging from security to entertainment systems. Tracking the motion and identifying the action being performed on a real time basis is necessary for critical security systems. In entertainment, especially gaming, the need for immediate responses for actions and gestures are paramount for the success of that system. We show that Motion History image has been a well established framework to capture the temporal and activity information in multi dimensional detail enabling various usecases including classification. We utilize MHI to produce sample data to train a classifier and demonstrate its effectiveness for action classification across six different activities in a single multi-action video. We analyze the classifier performance and identify usecases where MHI struggles to generate the appropriate activity image and discuss mechanisms and future work to overcome those limitations.</li>
</ul>

<h3>Title: Reddit is all you need: Authorship profiling for Romanian</h3>
<ul>
<li><strong>Authors: </strong>Ecaterina ÅtefÄnescu, Alexandru-Iulius Jerpelea</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.09907">https://arxiv.org/abs/2410.09907</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.09907">https://arxiv.org/pdf/2410.09907</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.09907]] Reddit is all you need: Authorship profiling for Romanian(https://arxiv.org/abs/2410.09907)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Authorship profiling is the process of identifying an author's characteristics based on their writings. This centuries old problem has become more intriguing especially with recent developments in Natural Language Processing (NLP). In this paper, we introduce a corpus of short texts in the Romanian language, annotated with certain author characteristic keywords; to our knowledge, the first of its kind. In order to do this, we exploit a social media platform called Reddit. We leverage its thematic community-based structure (subreddits structure), which offers information about the author's background. We infer an user's demographic and some broad personal traits, such as age category, employment status, interests, and social orientation based on the subreddit and other cues. We thus obtain a 23k+ samples corpus, extracted from 100+ Romanian subreddits. We analyse our dataset, and finally, we fine-tune and evaluate Large Language Models (LLMs) to prove baselines capabilities for authorship profiling using the corpus, indicating the need for further research in the field. We publicly release all our resources.</li>
</ul>

<h3>Title: Retrieval Instead of Fine-tuning: A Retrieval-based Parameter Ensemble for Zero-shot Learning</h3>
<ul>
<li><strong>Authors: </strong>Pengfei Jin, Peng Shu, Sekeun Kim, Qing Xiao, Sifan Song, Cheng Chen, Tianming Liu, Xiang Li, Quanzheng Li</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CL, cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.09908">https://arxiv.org/abs/2410.09908</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.09908">https://arxiv.org/pdf/2410.09908</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.09908]] Retrieval Instead of Fine-tuning: A Retrieval-based Parameter Ensemble for Zero-shot Learning(https://arxiv.org/abs/2410.09908)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, segmentation</a></li>
<li><strong>Abstract: </strong>Foundation models have become a cornerstone in deep learning, with techniques like Low-Rank Adaptation (LoRA) offering efficient fine-tuning of large models. Similarly, methods such as Retrieval-Augmented Generation (RAG), which leverage vectorized databases, have further improved model performance by grounding outputs in external information. While these approaches have demonstrated notable success, they often require extensive training or labeled data, which can limit their adaptability in resource-constrained environments. To address these challenges, we introduce Retrieval-based Parameter Ensemble (RPE), a new method that creates a vectorized database of LoRAs, enabling efficient retrieval and application of model adaptations to new tasks. RPE minimizes the need for extensive training and eliminates the requirement for labeled data, making it particularly effective for zero-shot learning. Additionally, RPE is well-suited for privacy-sensitive domains like healthcare, as it modifies model parameters without accessing raw data. When applied to tasks such as medical report generation and image segmentation, RPE not only proved effective but also surpassed supervised fine-tuning methods in certain cases, highlighting its potential to enhance both computational efficiency and privacy in deep learning applications.</li>
</ul>

<h3>Title: UnSeg: One Universal Unlearnable Example Generator is Enough against All Image Segmentation</h3>
<ul>
<li><strong>Authors: </strong>Ye Sun, Hao Zhang, Tiehua Zhang, Xingjun Ma, Yu-Gang Jiang</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.CR, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.09909">https://arxiv.org/abs/2410.09909</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.09909">https://arxiv.org/pdf/2410.09909</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.09909]] UnSeg: One Universal Unlearnable Example Generator is Enough against All Image Segmentation(https://arxiv.org/abs/2410.09909)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, protect, segmentation</a></li>
<li><strong>Abstract: </strong>Image segmentation is a crucial vision task that groups pixels within an image into semantically meaningful segments, which is pivotal in obtaining a fine-grained understanding of real-world scenes. However, an increasing privacy concern exists regarding training large-scale image segmentation models on unauthorized private data. In this work, we exploit the concept of unlearnable examples to make images unusable to model training by generating and adding unlearnable noise into the original images. Particularly, we propose a novel Unlearnable Segmentation (UnSeg) framework to train a universal unlearnable noise generator that is capable of transforming any downstream images into their unlearnable version. The unlearnable noise generator is finetuned from the Segment Anything Model (SAM) via bilevel optimization on an interactive segmentation dataset towards minimizing the training error of a surrogate model that shares the same architecture with SAM but is trained from scratch. We empirically verify the effectiveness of UnSeg across 6 mainstream image segmentation tasks, 10 widely used datasets, and 7 different network architectures, and show that the unlearnable images can reduce the segmentation performance by a large margin. Our work provides useful insights into how to leverage foundation models in a data-efficient and computationally affordable manner to protect images against image segmentation models.</li>
</ul>

<h3>Title: Combining Generative and Geometry Priors for Wide-Angle Portrait Correction</h3>
<ul>
<li><strong>Authors: </strong>Lan Yao, Chaofeng Chen, Xiaoming Li, Zifei Yan, Wangmeng Zuo</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.09911">https://arxiv.org/abs/2410.09911</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.09911">https://arxiv.org/pdf/2410.09911</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.09911]] Combining Generative and Geometry Priors for Wide-Angle Portrait Correction(https://arxiv.org/abs/2410.09911)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>Wide-angle lens distortion in portrait photography presents a significant challenge for capturing photo-realistic and aesthetically pleasing images. Such distortions are especially noticeable in facial regions. In this work, we propose encapsulating the generative face prior as a guided natural manifold to facilitate the correction of facial regions. Moreover, a notable central symmetry relationship exists in the non-face background, yet it has not been explored in the correction process. This geometry prior motivates us to introduce a novel constraint to explicitly enforce symmetry throughout the correction process, thereby contributing to a more visually appealing and natural correction in the non-face region. Experiments demonstrate that our approach outperforms previous methods by a large margin, excelling not only in quantitative measures such as line straightness and shape consistency metrics but also in terms of perceptual visual quality. All the code and models are available at this https URL.</li>
</ul>

<h3>Title: FedECADO: A Dynamical System Model of Federated Learning</h3>
<ul>
<li><strong>Authors: </strong>Aayushya Agarwal, Gauri Joshi, Larry Pileggi</a></li>
<li><strong>Subjects: </strong>cs.LG, eess.SY</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.09933">https://arxiv.org/abs/2410.09933</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.09933">https://arxiv.org/pdf/2410.09933</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.09933]] FedECADO: A Dynamical System Model of Federated Learning(https://arxiv.org/abs/2410.09933)</code><input type="text"></li>
<li><strong>Keywords: </strong>federate</a></li>
<li><strong>Abstract: </strong>Federated learning harnesses the power of distributed optimization to train a unified machine learning model across separate clients. However, heterogeneous data distributions and computational workloads can lead to inconsistent updates and limit model performance. This work tackles these challenges by proposing FedECADO, a new algorithm inspired by a dynamical system representation of the federated learning process. FedECADO addresses non-IID data distribution through an aggregate sensitivity model that reflects the amount of data processed by each client. To tackle heterogeneous computing, we design a multi-rate integration method with adaptive step-size selections that synchronizes active client updates in continuous time. Compared to prominent techniques, including FedProx and FedNova, FedECADO achieves higher classification accuracies in numerous heterogeneous scenarios.</li>
</ul>

<h3>Title: Robust identifiability for symbolic recovery of differential equations</h3>
<ul>
<li><strong>Authors: </strong>Hillary Hauger, Philipp Scholl, Gitta Kutyniok</a></li>
<li><strong>Subjects: </strong>cs.LG, math.NA</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.09938">https://arxiv.org/abs/2410.09938</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.09938">https://arxiv.org/pdf/2410.09938</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.09938]] Robust identifiability for symbolic recovery of differential equations(https://arxiv.org/abs/2410.09938)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Recent advancements in machine learning have transformed the discovery of physical laws, moving from manual derivation to data-driven methods that simultaneously learn both the structure and parameters of governing equations. This shift introduces new challenges regarding the validity of the discovered equations, particularly concerning their uniqueness and, hence, identifiability. While the issue of non-uniqueness has been well-studied in the context of parameter estimation, it remains underexplored for algorithms that recover both structure and parameters simultaneously. Early studies have primarily focused on idealized scenarios with perfect, noise-free data. In contrast, this paper investigates how noise influences the uniqueness and identifiability of physical laws governed by partial differential equations (PDEs). We develop a comprehensive mathematical framework to analyze the uniqueness of PDEs in the presence of noise and introduce new algorithms that account for noise, providing thresholds to assess uniqueness and identifying situations where excessive noise hinders reliable conclusions. Numerical experiments demonstrate the effectiveness of these algorithms in detecting uniqueness despite the presence of noise.</li>
</ul>

<h3>Title: Generalized Group Data Attribution</h3>
<ul>
<li><strong>Authors: </strong>Dan Ley, Shichang Zhang, Suraj Srinivas, Gili Rusak, Himabindu Lakkaraju</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.09940">https://arxiv.org/abs/2410.09940</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.09940">https://arxiv.org/pdf/2410.09940</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.09940]] Generalized Group Data Attribution(https://arxiv.org/abs/2410.09940)</code><input type="text"></li>
<li><strong>Keywords: </strong>explainability</a></li>
<li><strong>Abstract: </strong>Data Attribution (DA) methods quantify the influence of individual training data points on model outputs and have broad applications such as explainability, data selection, and noisy label identification. However, existing DA methods are often computationally intensive, limiting their applicability to large-scale machine learning models. To address this challenge, we introduce the Generalized Group Data Attribution (GGDA) framework, which computationally simplifies DA by attributing to groups of training points instead of individual ones. GGDA is a general framework that subsumes existing attribution methods and can be applied to new DA techniques as they emerge. It allows users to optimize the trade-off between efficiency and fidelity based on their needs. Our empirical results demonstrate that GGDA applied to popular DA methods such as Influence Functions, TracIn, and TRAK results in upto 10x-50x speedups over standard DA methods while gracefully trading off attribution fidelity. For downstream applications such as dataset pruning and noisy label identification, we demonstrate that GGDA significantly improves computational efficiency and maintains effectiveness, enabling practical applications in large-scale machine learning scenarios that were previously infeasible.</li>
</ul>

<h3>Title: Learning to Rank for Multiple Retrieval-Augmented Models through Iterative Utility Maximization</h3>
<ul>
<li><strong>Authors: </strong>Alireza Salemi, Hamed Zamani</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.IR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.09942">https://arxiv.org/abs/2410.09942</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.09942">https://arxiv.org/pdf/2410.09942</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.09942]] Learning to Rank for Multiple Retrieval-Augmented Models through Iterative Utility Maximization(https://arxiv.org/abs/2410.09942)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>This paper investigates the design of a unified search engine to serve multiple retrieval-augmented generation (RAG) agents, each with a distinct task, backbone large language model (LLM), and retrieval-augmentation strategy. We introduce an iterative approach where the search engine generates retrieval results for these RAG agents and gathers feedback on the quality of the retrieved documents during an offline phase. This feedback is then used to iteratively optimize the search engine using a novel expectation-maximization algorithm, with the goal of maximizing each agent's utility function. Additionally, we adapt this approach to an online setting, allowing the search engine to refine its behavior based on real-time individual agents feedback to better serve the results for each of them. Experiments on diverse datasets from the Knowledge-Intensive Language Tasks (KILT) benchmark demonstrates that our approach significantly on average outperforms competitive baselines across 18 RAG models. We also demonstrate that our method effectively ``personalizes'' the retrieval process for each RAG agent based on the collected feedback. Finally, we provide a comprehensive ablation study to explore various aspects of our method.</li>
</ul>

<h3>Title: Dynamic Estimation of Learning Rates Using a Non-Linear Autoregressive Model</h3>
<ul>
<li><strong>Authors: </strong>Ramin Okhrati</a></li>
<li><strong>Subjects: </strong>cs.LG, math.OC, stat.AP</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.09943">https://arxiv.org/abs/2410.09943</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.09943">https://arxiv.org/pdf/2410.09943</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.09943]] Dynamic Estimation of Learning Rates Using a Non-Linear Autoregressive Model(https://arxiv.org/abs/2410.09943)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>We introduce a new class of adaptive non-linear autoregressive (Nlar) models incorporating the concept of momentum, which dynamically estimate both the learning rates and momentum as the number of iterations increases. In our method, the growth of the gradients is controlled using a scaling (clipping) function, leading to stable convergence. Within this framework, we propose three distinct estimators for learning rates and provide theoretical proof of their convergence. We further demonstrate how these estimators underpin the development of effective Nlar optimizers. The performance of the proposed estimators and optimizers is rigorously evaluated through extensive experiments across several datasets and a reinforcement learning environment. The results highlight two key features of the Nlar optimizers: robust convergence despite variations in underlying parameters, including large initial learning rates, and strong adaptability with rapid convergence during the initial epochs.</li>
</ul>

<h3>Title: Efficient Federated Unlearning under Plausible Deniability</h3>
<ul>
<li><strong>Authors: </strong>Ayush K. Varshney, VicenÃ§ Torra</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.09947">https://arxiv.org/abs/2410.09947</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.09947">https://arxiv.org/pdf/2410.09947</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.09947]] Efficient Federated Unlearning under Plausible Deniability(https://arxiv.org/abs/2410.09947)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, federate</a></li>
<li><strong>Abstract: </strong>Privacy regulations like the GDPR in Europe and the CCPA in the US allow users the right to remove their data ML applications. Machine unlearning addresses this by modifying the ML parameters in order to forget the influence of a specific data point on its weights. Recent literature has highlighted that the contribution from data point(s) can be forged with some other data points in the dataset with probability close to one. This allows a server to falsely claim unlearning without actually modifying the model's parameters. However, in distributed paradigms such as FL, where the server lacks access to the dataset and the number of clients are limited, claiming unlearning in such cases becomes a challenge. This paper introduces an efficient way to achieve federated unlearning, by employing a privacy model which allows the FL server to plausibly deny the client's participation in the training up to a certain extent. We demonstrate that the server can generate a Proof-of-Deniability, where each aggregated update can be associated with at least x number of client updates. This enables the server to plausibly deny a client's participation. However, in the event of frequent unlearning requests, the server is required to adopt an unlearning strategy and, accordingly, update its model parameters. We also perturb the client updates in a cluster in order to avoid inference from an honest but curious server. We show that the global model satisfies differential privacy after T number of communication rounds. The proposed methodology has been evaluated on multiple datasets in different privacy settings. The experimental results show that our framework achieves comparable utility while providing a significant reduction in terms of memory (30 times), as well as retraining time (1.6-500769 times). The source code for the paper is available.</li>
</ul>

<h3>Title: MisinfoEval: Generative AI in the Era of "Alternative Facts"</h3>
<ul>
<li><strong>Authors: </strong>Saadia Gabriel, Liang Lyu, James Siderius, Marzyeh Ghassemi, Jacob Andreas, Asu Ozdaglar</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.09949">https://arxiv.org/abs/2410.09949</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.09949">https://arxiv.org/pdf/2410.09949</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.09949]] MisinfoEval: Generative AI in the Era of "Alternative Facts"(https://arxiv.org/abs/2410.09949)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative, large language model</a></li>
<li><strong>Abstract: </strong>The spread of misinformation on social media platforms threatens democratic processes, contributes to massive economic losses, and endangers public health. Many efforts to address misinformation focus on a knowledge deficit model and propose interventions for improving users' critical thinking through access to facts. Such efforts are often hampered by challenges with scalability, and by platform users' personal biases. The emergence of generative AI presents promising opportunities for countering misinformation at scale across ideological barriers. In this paper, we introduce a framework (MisinfoEval) for generating and comprehensively evaluating large language model (LLM) based misinformation interventions. We present (1) an experiment with a simulated social media environment to measure effectiveness of misinformation interventions, and (2) a second experiment with personalized explanations tailored to the demographics and beliefs of users with the goal of countering misinformation by appealing to their pre-existing values. Our findings confirm that LLM-based interventions are highly effective at correcting user behavior (improving overall user accuracy at reliability labeling by up to 41.72%). Furthermore, we find that users favor more personalized interventions when making decisions about news reliability and users shown personalized interventions have significantly higher accuracy at identifying misinformation.</li>
</ul>

<h3>Title: EITNet: An IoT-Enhanced Framework for Real-Time Basketball Action Recognition</h3>
<ul>
<li><strong>Authors: </strong>Jingyu Liu, Xinyu Liu, Mingzhe Qu, Tianyi Lyu</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.09954">https://arxiv.org/abs/2410.09954</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.09954">https://arxiv.org/pdf/2410.09954</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.09954]] EITNet: An IoT-Enhanced Framework for Real-Time Basketball Action Recognition(https://arxiv.org/abs/2410.09954)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, extraction</a></li>
<li><strong>Abstract: </strong>Integrating IoT technology into basketball action recognition enhances sports analytics, providing crucial insights into player performance and game strategy. However, existing methods often fall short in terms of accuracy and efficiency, particularly in complex, real-time environments where player movements are frequently occluded or involve intricate interactions. To overcome these challenges, we propose the EITNet model, a deep learning framework that combines EfficientDet for object detection, I3D for spatiotemporal feature extraction, and TimeSformer for temporal analysis, all integrated with IoT technology for seamless real-time data collection and processing. Our contributions include developing a robust architecture that improves recognition accuracy to 92\%, surpassing the baseline EfficientDet model's 87\%, and reducing loss to below 5.0 compared to EfficientDet's 9.0 over 50 epochs. Furthermore, the integration of IoT technology enhances real-time data processing, providing adaptive insights into player performance and strategy. The paper details the design and implementation of EITNet, experimental validation, and a comprehensive evaluation against existing models. The results demonstrate EITNet's potential to significantly advance automated sports analysis and optimize data utilization for player performance and strategy improvement.</li>
</ul>

<h3>Title: LongHalQA: Long-Context Hallucination Evaluation for MultiModal Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Han Qiu, Jiaxing Huang, Peng Gao, Qin Qi, Xiaoqin Zhang, Ling Shao, Shijian Lu</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.09962">https://arxiv.org/abs/2410.09962</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.09962">https://arxiv.org/pdf/2410.09962</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.09962]] LongHalQA: Long-Context Hallucination Evaluation for MultiModal Large Language Models(https://arxiv.org/abs/2410.09962)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative, large language model</a></li>
<li><strong>Abstract: </strong>Hallucination, a phenomenon where multimodal large language models~(MLLMs) tend to generate textual responses that are plausible but unaligned with the image, has become one major hurdle in various MLLM-related applications. Several benchmarks have been created to gauge the hallucination levels of MLLMs, by either raising discriminative questions about the existence of objects or introducing LLM evaluators to score the generated text from MLLMs. However, the discriminative data largely involve simple questions that are not aligned with real-world text, while the generative data involve LLM evaluators that are computationally intensive and unstable due to their inherent randomness. We propose LongHalQA, an LLM-free hallucination benchmark that comprises 6K long and complex hallucination text. LongHalQA is featured by GPT4V-generated hallucinatory data that are well aligned with real-world scenarios, including object/image descriptions and multi-round conversations with 14/130 words and 189 words, respectively, on average. It introduces two new tasks, hallucination discrimination and hallucination completion, unifying both discriminative and generative evaluations in a single multiple-choice-question form and leading to more reliable and efficient evaluations without the need for LLM evaluators. Further, we propose an advanced pipeline that greatly facilitates the construction of future hallucination benchmarks with long and complex questions and descriptions. Extensive experiments over multiple recent MLLMs reveal various new challenges when they are handling hallucinations with long and complex textual data. Dataset and evaluation code are available at this https URL.</li>
</ul>

<h3>Title: Improving 3D Few-Shot Segmentation with Inference-Time Pseudo-Labeling</h3>
<ul>
<li><strong>Authors: </strong>Mohammad Mozafari, Hosein Hasani, Reza Vahidimajd, Mohamadreza Fereydooni, Mahdieh Soleymani Baghshah</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.09967">https://arxiv.org/abs/2410.09967</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.09967">https://arxiv.org/pdf/2410.09967</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.09967]] Improving 3D Few-Shot Segmentation with Inference-Time Pseudo-Labeling(https://arxiv.org/abs/2410.09967)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>In recent years, few-shot segmentation (FSS) models have emerged as a promising approach in medical imaging analysis, offering remarkable adaptability to segment novel classes with limited annotated data. Existing approaches to few-shot segmentation have often overlooked the potential of the query itself, failing to fully utilize the valuable information it contains. However, treating the query as unlabeled data provides an opportunity to enhance prediction accuracy. Specifically in the domain of medical imaging, the volumetric structure of queries offers a considerable source of valuable information that can be used to improve the target slice segmentation. In this work, we present a novel strategy to efficiently leverage the intrinsic information of the query sample for final segmentation during inference. First, we use the support slices from a reference volume to generate an initial segmentation score for the query slices through a prototypical approach. Subsequently, we apply a confidence-aware pseudo-labeling procedure to transfer the most informative parts of query slices to the support set. The final prediction is performed based on the new expanded support set, enabling the prediction of a more accurate segmentation mask for the query volume. Extensive experiments show that the proposed method can effectively boost performance across diverse settings and datasets.</li>
</ul>

<h3>Title: Make the Pertinent Salient: Task-Relevant Reconstruction for Visual Control with Distractions</h3>
<ul>
<li><strong>Authors: </strong>Kyungmin Kim, JB Lanier, Pierre Baldi, Charless Fowlkes, Roy Fox</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CV, cs.RO</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.09972">https://arxiv.org/abs/2410.09972</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.09972">https://arxiv.org/pdf/2410.09972</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.09972]] Make the Pertinent Salient: Task-Relevant Reconstruction for Visual Control with Distractions(https://arxiv.org/abs/2410.09972)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, segmentation</a></li>
<li><strong>Abstract: </strong>Recent advancements in Model-Based Reinforcement Learning (MBRL) have made it a powerful tool for visual control tasks. Despite improved data efficiency, it remains challenging to train MBRL agents with generalizable perception. Training in the presence of visual distractions is particularly difficult due to the high variation they introduce to representation learning. Building on DREAMER, a popular MBRL method, we propose a simple yet effective auxiliary task to facilitate representation learning in distracting environments. Under the assumption that task-relevant components of image observations are straightforward to identify with prior knowledge in a given task, we use a segmentation mask on image observations to only reconstruct task-relevant components. In doing so, we greatly reduce the complexity of representation learning by removing the need to encode task-irrelevant objects in the latent representation. Our method, Segmentation Dreamer (SD), can be used either with ground-truth masks easily accessible in simulation or by leveraging potentially imperfect segmentation foundation models. The latter is further improved by selectively applying the reconstruction loss to avoid providing misleading learning signals due to mask prediction errors. In modified DeepMind Control suite (DMC) and Meta-World tasks with added visual distractions, SD achieves significantly better sample efficiency and greater final performance than prior work. We find that SD is especially helpful in sparse reward tasks otherwise unsolvable by prior work, enabling the training of visually robust agents without the need for extensive reward engineering.</li>
</ul>

<h3>Title: Facial Width-to-Height Ratio Does Not Predict Self-Reported Behavioral Tendencies</h3>
<ul>
<li><strong>Authors: </strong>Michal Kosinski</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI, cs.CY</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.09979">https://arxiv.org/abs/2410.09979</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.09979">https://arxiv.org/pdf/2410.09979</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.09979]] Facial Width-to-Height Ratio Does Not Predict Self-Reported Behavioral Tendencies(https://arxiv.org/abs/2410.09979)</code><input type="text"></li>
<li><strong>Keywords: </strong>fair</a></li>
<li><strong>Abstract: </strong>A growing number of studies have linked facial width-to-height ratio (fWHR) with various antisocial or violent behavioral tendencies. However, those studies have predominantly been laboratory based and low powered. This work reexamined the links between fWHR and behavioral tendencies in a large sample of 137,163 participants. Behavioral tendencies were measured using 55 well-established psychometric scales, including self-report scales measuring intelligence, domains and facets of the five-factor model of personality, impulsiveness, sense of fairness, sensational interests, self-monitoring, impression management, and satisfaction with life. The findings revealed that fWHR is not substantially linked with any of these self-reported measures of behavioral tendencies, calling into question whether the links between fWHR and behavior generalize beyond the small samples and specific experimental settings that have been used in past fWHR research.</li>
</ul>

<h3>Title: Self-Data Distillation for Recovering Quality in Pruned Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Vithursan Thangarasa, Ganesh Venkatesh, Nish Sinnadurai, Sean Lie</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.09982">https://arxiv.org/abs/2410.09982</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.09982">https://arxiv.org/pdf/2410.09982</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.09982]] Self-Data Distillation for Recovering Quality in Pruned Large Language Models(https://arxiv.org/abs/2410.09982)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large language models have driven significant progress in natural language processing, but their deployment requires substantial compute and memory resources. As models scale, compression techniques become essential for balancing model quality with computational efficiency. Structured pruning, which removes less critical components of the model, is a promising strategy for reducing complexity. However, one-shot pruning often results in significant quality degradation, particularly in tasks requiring multi-step reasoning. To recover lost quality, supervised fine-tuning (SFT) is commonly applied, but it can lead to catastrophic forgetting by shifting the model's learned data distribution. Therefore, addressing the degradation from both pruning and SFT is essential to preserve the original model's quality. In this work, we propose self-data distilled fine-tuning to address these challenges. Our approach leverages the original, unpruned model to generate a distilled dataset that preserves semantic richness and mitigates catastrophic forgetting by maintaining alignment with the base model's knowledge. Empirically, we demonstrate that self-data distillation consistently outperforms standard SFT, improving average accuracy by up to 8% on the HuggingFace OpenLLM Leaderboard v1. Specifically, when pruning 6 decoder blocks on Llama3.1-8B Instruct (i.e., 32 to 24 layers, reducing the model size from 8.03B to 6.72B parameters), our method retains 91.2% of the original model's accuracy compared to 81.7% with SFT, while reducing real-world FLOPs by 16.30%. Furthermore, our approach scales effectively across datasets, with the quality improving as the dataset size increases.</li>
</ul>

<h3>Title: HARDMath: A Benchmark Dataset for Challenging Problems in Applied Mathematics</h3>
<ul>
<li><strong>Authors: </strong>Jingxuan Fan, Sarah Martinson, Erik Y. Wang, Kaylie Hausknecht, Jonah Brenner, Danxian Liu, Nianli Peng, Corey Wang, Michael P. Brenner</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.09988">https://arxiv.org/abs/2410.09988</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.09988">https://arxiv.org/pdf/2410.09988</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.09988]] HARDMath: A Benchmark Dataset for Challenging Problems in Applied Mathematics(https://arxiv.org/abs/2410.09988)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Advanced applied mathematics problems are underrepresented in existing Large Language Model (LLM) benchmark datasets. To address this, we introduce HARDMath, a dataset inspired by a graduate course on asymptotic methods, featuring challenging applied mathematics problems that require analytical approximation techniques. These problems demand a combination of mathematical reasoning, computational tools, and subjective judgment, making them difficult for LLMs. Our framework auto-generates a large number of problems with solutions validated against numerical ground truths. We evaluate both open- and closed-source LLMs on HARDMath-mini, a sub-sampled test set of 366 problems, as well as on 40 word problems formulated in applied science contexts. Even leading closed-source models like GPT-4 achieve only 43.8% overall accuracy with few-shot Chain-of-Thought prompting, and all models demonstrate significantly lower performance compared to results on existing mathematics benchmark datasets. We additionally conduct a detailed error analysis to gain insights into the failure cases of LLMs. These results demonstrate limitations of current LLM performance on advanced graduate-level applied math problems and underscore the importance of datasets like HARDMath to advance mathematical abilities of LLMs.</li>
</ul>

<h3>Title: Evaluating Gender Bias of LLMs in Making Morality Judgements</h3>
<ul>
<li><strong>Authors: </strong>Divij Bajaj, Yuanyuan Lei, Jonathan Tong, Ruihong Huang</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.09992">https://arxiv.org/abs/2410.09992</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.09992">https://arxiv.org/pdf/2410.09992</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.09992]] Evaluating Gender Bias of LLMs in Making Morality Judgements(https://arxiv.org/abs/2410.09992)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large Language Models (LLMs) have shown remarkable capabilities in a multitude of Natural Language Processing (NLP) tasks. However, these models are still not immune to limitations such as social biases, especially gender bias. This work investigates whether current closed and open-source LLMs possess gender bias, especially when asked to give moral opinions. To evaluate these models, we curate and introduce a new dataset GenMO (Gender-bias in Morality Opinions) comprising parallel short stories featuring male and female characters respectively. Specifically, we test models from the GPT family (GPT-3.5-turbo, GPT-3.5-turbo-instruct, GPT-4-turbo), Llama 3 and 3.1 families (8B/70B), Mistral-7B and Claude 3 families (Sonnet and Opus). Surprisingly, despite employing safety checks, all production-standard models we tested display significant gender bias with GPT-3.5-turbo giving biased opinions in 24% of the samples. Additionally, all models consistently favour female characters, with GPT showing bias in 68-85% of cases and Llama 3 in around 81-85% instances. Additionally, our study investigates the impact of model parameters on gender bias and explores real-world situations where LLMs reveal biases in moral decision-making.</li>
</ul>

<h3>Title: SoK: A Security Architect's View of Printed Circuit Board Attacks</h3>
<ul>
<li><strong>Authors: </strong>Jacob Harrison, Nathan Jessurun, Mark Tehranipoor</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.09993">https://arxiv.org/abs/2410.09993</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.09993">https://arxiv.org/pdf/2410.09993</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.09993]] SoK: A Security Architect's View of Printed Circuit Board Attacks(https://arxiv.org/abs/2410.09993)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, attack</a></li>
<li><strong>Abstract: </strong>Many recent papers have proposed novel electrical measurements or physical inspection technologies for defending printed circuit boards (PCBs) and printed circuit board assemblies (PCBAs) against tampering. As motivation, these papers frequently cite Bloomberg News' "The Big Hack", video game modchips, and "interdiction attacks" on IT equipment. We find this trend concerning for two reasons. First, implementation errors and security architecture are rarely discussed in recent PCBA security research, even though they were the root causes of these commonly-cited attacks and most other attacks that have occurred or been proposed by researchers. This suggests that the attacks may be poorly understood. Second, if we assume that novel countermeasures and validation methodologies are tailored to these oft-cited attacks, then significant recent work has focused on attacks that can already be mitigated instead of on open problems. We write this SoK to address these concerns. We explain which tampering threats can be mitigated by PCBA security architecture. Then, we enumerate assumptions that security architecture depends on. We compare and contrast assurances achieved by security architecture vs. by recently-proposed electrical or inspection-based tamper detection. Finally, we review over fifty PCBA attacks to show how most can be prevented by proper architecture and careful implementation.</li>
</ul>

<h3>Title: Leveraging Customer Feedback for Multi-modal Insight Extraction</h3>
<ul>
<li><strong>Authors: </strong>Sandeep Sricharan Mukku, Abinesh Kanagarajan, Pushpendu Ghosh, Chetan Aggarwal</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.CV, cs.IR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.09999">https://arxiv.org/abs/2410.09999</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.09999">https://arxiv.org/pdf/2410.09999</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.09999]] Leveraging Customer Feedback for Multi-modal Insight Extraction(https://arxiv.org/abs/2410.09999)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction</a></li>
<li><strong>Abstract: </strong>Businesses can benefit from customer feedback in different modalities, such as text and images, to enhance their products and services. However, it is difficult to extract actionable and relevant pairs of text segments and images from customer feedback in a single pass. In this paper, we propose a novel multi-modal method that fuses image and text information in a latent space and decodes it to extract the relevant feedback segments using an image-text grounded text decoder. We also introduce a weakly-supervised data generation technique that produces training data for this task. We evaluate our model on unseen data and demonstrate that it can effectively mine actionable insights from multi-modal customer feedback, outperforming the existing baselines by $14$ points in F1 score.</li>
</ul>

<h3>Title: A Holistic Weakly Supervised Approach for Liver Tumor Segmentation with Clinical Knowledge-Informed Label Smoothing</h3>
<ul>
<li><strong>Authors: </strong>Hairong Wang, Lingchao Mao, Zihan Zhang, Jing Li</a></li>
<li><strong>Subjects: </strong>cs.LG, eess.IV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.10005">https://arxiv.org/abs/2410.10005</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.10005">https://arxiv.org/pdf/2410.10005</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.10005]] A Holistic Weakly Supervised Approach for Liver Tumor Segmentation with Clinical Knowledge-Informed Label Smoothing(https://arxiv.org/abs/2410.10005)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>Liver cancer is a leading cause of mortality worldwide, and accurate CT-based tumor segmentation is essential for diagnosis and treatment. Manual delineation is time-intensive, prone to variability, and highlights the need for reliable automation. While deep learning has shown promise for automated liver segmentation, precise liver tumor segmentation remains challenging due to the heterogeneous nature of tumors, imprecise tumor margins, and limited labeled data. We present a novel holistic weakly supervised framework that integrates clinical knowledge to address these challenges with (1) A knowledge-informed label smoothing technique that leverages clinical data to generate smooth labels, which regularizes model training reducing the risk of overfitting and enhancing model performance; (2) A global and local-view segmentation framework, breaking down the task into two simpler sub-tasks, allowing optimized preprocessing and training for each; and (3) Pre- and post-processing pipelines customized to the challenges of each subtask, which enhances tumor visibility and refines tumor boundaries. We evaluated the proposed method on the HCC-TACE-Seg dataset and showed that these three key components complementarily contribute to the improved performance. Lastly, we prototyped a tool for automated liver tumor segmentation and diagnosis summary generation called MedAssistLiver. The app and code are published at this https URL.</li>
</ul>

<h3>Title: InterMask: 3D Human Interaction Generation via Collaborative Masked Modelling</h3>
<ul>
<li><strong>Authors: </strong>Muhammad Gohar Javed, Chuan Guo, Li Cheng, Xingyu Li</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.10010">https://arxiv.org/abs/2410.10010</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.10010">https://arxiv.org/pdf/2410.10010</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.10010]] InterMask: 3D Human Interaction Generation via Collaborative Masked Modelling(https://arxiv.org/abs/2410.10010)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, transformer, generative</a></li>
<li><strong>Abstract: </strong>Generating realistic 3D human-human interactions from textual descriptions remains a challenging task. Existing approaches, typically based on diffusion models, often generate unnatural and unrealistic results. In this work, we introduce InterMask, a novel framework for generating human interactions using collaborative masked modeling in discrete space. InterMask first employs a VQ-VAE to transform each motion sequence into a 2D discrete motion token map. Unlike traditional 1D VQ token maps, it better preserves fine-grained spatio-temporal details and promotes spatial awareness within each token. Building on this representation, InterMask utilizes a generative masked modeling framework to collaboratively model the tokens of two interacting individuals. This is achieved by employing a transformer architecture specifically designed to capture complex spatio-temporal interdependencies. During training, it randomly masks the motion tokens of both individuals and learns to predict them. In inference, starting from fully masked sequences, it progressively fills in the tokens for both individuals. With its enhanced motion representation, dedicated architecture, and effective learning strategy, InterMask achieves state-of-the-art results, producing high-fidelity and diverse human interactions. It outperforms previous methods, achieving an FID of $5.154$ (vs $5.535$ for in2IN) on the InterHuman dataset and $0.399$ (vs $5.207$ for InterGen) on the InterX dataset. Additionally, InterMask seamlessly supports reaction generation without the need for model redesign or fine-tuning.</li>
</ul>

<h3>Title: NARAIM: Native Aspect Ratio Autoregressive Image Models</h3>
<ul>
<li><strong>Authors: </strong>Daniel Gallo FernÃ¡ndez, Robert van der Klis, RÇzvan-Andrei MatiÅan, Janusz Partyka, Efstratios Gavves, Samuele Papa, Phillip Lippe</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.10012">https://arxiv.org/abs/2410.10012</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.10012">https://arxiv.org/pdf/2410.10012</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.10012]] NARAIM: Native Aspect Ratio Autoregressive Image Models(https://arxiv.org/abs/2410.10012)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>While vision transformers are able to solve a wide variety of computer vision tasks, no pre-training method has yet demonstrated the same scaling laws as observed in language models. Autoregressive models show promising results, but are commonly trained on images that are cropped or transformed into square images, which distorts or destroys information present in the input. To overcome this limitation, we propose NARAIM, a vision model pre-trained with an autoregressive objective that uses images in their native aspect ratio. By maintaining the native aspect ratio, we preserve the original spatial context, thereby enhancing the model's ability to interpret visual information. In our experiments, we show that maintaining the aspect ratio improves performance on a downstream classification task.</li>
</ul>

<h3>Title: Safety-Aware Fine-Tuning of Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Hyeong Kyu Choi, Xuefeng Du, Yixuan Li</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.10014">https://arxiv.org/abs/2410.10014</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.10014">https://arxiv.org/pdf/2410.10014</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.10014]] Safety-Aware Fine-Tuning of Large Language Models(https://arxiv.org/abs/2410.10014)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Fine-tuning Large Language Models (LLMs) has emerged as a common practice for tailoring models to individual needs and preferences. The choice of datasets for fine-tuning can be diverse, introducing safety concerns regarding the potential inclusion of harmful data samples. Manually filtering or avoiding such samples, however, can be labor-intensive and subjective. To address these difficulties, we propose a novel Safety-Aware Fine-Tuning (SAFT) framework designed to automatically detect and remove potentially harmful data, by leveraging a scoring function that exploits the subspace information of harmful and benign samples. Experimental results demonstrate the efficacy of SAFT across different LLMs and varying contamination rates, achieving reductions in harmfulness of up to 27.8%. Going beyond, we delve into the mechanism of our approach and validate its versatility in addressing practical challenges in real-world scenarios.</li>
</ul>

<h3>Title: Improving accuracy and convergence of federated learning edge computing methods for generalized DER forecasting applications in power grid</h3>
<ul>
<li><strong>Authors: </strong>Vineet Jagadeesan Nair, Lucas Pereira</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.DC, eess.SY</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.10018">https://arxiv.org/abs/2410.10018</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.10018">https://arxiv.org/pdf/2410.10018</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.10018]] Improving accuracy and convergence of federated learning edge computing methods for generalized DER forecasting applications in power grid(https://arxiv.org/abs/2410.10018)</code><input type="text"></li>
<li><strong>Keywords: </strong>federate</a></li>
<li><strong>Abstract: </strong>This proposal aims to develop more accurate federated learning (FL) methods with faster convergence properties and lower communication requirements, specifically for forecasting distributed energy resources (DER) such as renewables, energy storage, and loads in modern, low-carbon power grids. This will be achieved by (i) leveraging recently developed extensions of FL such as hierarchical and iterative clustering to improve performance with non-IID data, (ii) experimenting with different types of FL global models well-suited to time-series data, and (iii) incorporating domain-specific knowledge from power systems to build more general FL frameworks and architectures that can be applied to diverse types of DERs beyond just load forecasting, and with heterogeneous clients.</li>
</ul>

<h3>Title: GALA: Geometry-Aware Local Adaptive Grids for Detailed 3D Generation</h3>
<ul>
<li><strong>Authors: </strong>Dingdong Yang, Yizhi Wang, Konrad Schindler, Ali Mahdavi Amiri, Hao Zhang</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.10037">https://arxiv.org/abs/2410.10037</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.10037">https://arxiv.org/pdf/2410.10037</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.10037]] GALA: Geometry-Aware Local Adaptive Grids for Detailed 3D Generation(https://arxiv.org/abs/2410.10037)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, transformer, generative</a></li>
<li><strong>Abstract: </strong>We propose GALA, a novel representation of 3D shapes that (i) excels at capturing and reproducing complex geometry and surface details, (ii) is computationally efficient, and (iii) lends itself to 3D generative modelling with modern, diffusion-based schemes. The key idea of GALA is to exploit both the global sparsity of surfaces within a 3D volume and their local surface properties. Sparsity is promoted by covering only the 3D object boundaries, not empty space, with an ensemble of tree root voxels. Each voxel contains an octree to further limit storage and compute to regions that contain surfaces. Adaptivity is achieved by fitting one local and geometry-aware coordinate frame in each non-empty leaf node. Adjusting the orientation of the local grid, as well as the anisotropic scales of its axes, to the local surface shape greatly increases the amount of detail that can be stored in a given amount of memory, which in turn allows for quantization without loss of quality. With our optimized C++/CUDA implementation, GALA can be fitted to an object in less than 10 seconds. Moreover, the representation can efficiently be flattened and manipulated with transformer networks. We provide a cascaded generation pipeline capable of generating 3D shapes with great geometric detail.</li>
</ul>

<h3>Title: Are KAN Effective for Identifying and Tracking Concept Drift in Time Series?</h3>
<ul>
<li><strong>Authors: </strong>Kunpeng Xu, Lifei Chen, Shengrui Wang</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.10041">https://arxiv.org/abs/2410.10041</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.10041">https://arxiv.org/pdf/2410.10041</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.10041]] Are KAN Effective for Identifying and Tracking Concept Drift in Time Series?(https://arxiv.org/abs/2410.10041)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability</a></li>
<li><strong>Abstract: </strong>Dynamic concepts in time series are crucial for understanding complex systems such as financial markets, healthcare, and online activity logs. These concepts help reveal structures and behaviors in sequential data for better decision-making and forecasting. Existing models struggle with detecting and tracking concept drift due to limitations in interpretability and adaptability. This paper introduces Kolmogorov-Arnold Networks (KAN) into time series and proposes WormKAN, a KAN-based auto-encoder to address concept drift in co-evolving time series. WormKAN integrates the KAN-SR module, in which the encoder, decoder, and self-representation layer are built on KAN, along with a temporal constraint to capture concept transitions. These transitions, akin to passing through a "wormhole", are identified by abrupt changes in the latent space. Experiments show that KAN and KAN-based models (WormKAN) effectively segment time series into meaningful concepts, enhancing the identification and tracking of concept drifts.</li>
</ul>

<h3>Title: LoRE: Logit-Ranked Retriever Ensemble for Enhancing Open-Domain Question Answering</h3>
<ul>
<li><strong>Authors: </strong>Saikrishna Sanniboina, Shiv Trivedi, Sreenidhi Vijayaraghavan</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.10042">https://arxiv.org/abs/2410.10042</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.10042">https://arxiv.org/pdf/2410.10042</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.10042]] LoRE: Logit-Ranked Retriever Ensemble for Enhancing Open-Domain Question Answering(https://arxiv.org/abs/2410.10042)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer, large language model</a></li>
<li><strong>Abstract: </strong>Retrieval-based question answering systems often suffer from positional bias, leading to suboptimal answer generation. We propose LoRE (Logit-Ranked Retriever Ensemble), a novel approach that improves answer accuracy and relevance by mitigating positional bias. LoRE employs an ensemble of diverse retrievers, such as BM25 and sentence transformers with FAISS indexing. A key innovation is a logit-based answer ranking algorithm that combines the logit scores from a large language model (LLM), with the retrieval ranks of the passages. Experimental results on NarrativeQA, SQuAD demonstrate that LoRE significantly outperforms existing retrieval-based methods in terms of exact match and F1 scores. On SQuAD, LoRE achieves 14.5\%, 22.83\%, and 14.95\% improvements over the baselines for ROUGE-L, EM, and F1, respectively. Qualitatively, LoRE generates more relevant and accurate answers, especially for complex queries.</li>
</ul>

<h3>Title: StatioCL: Contrastive Learning for Time Series via Non-Stationary and Temporal Contrast</h3>
<ul>
<li><strong>Authors: </strong>Yu Wu, Ting Dang, Dimitris Spathis, Hong Jia, Cecilia Mascolo</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.10048">https://arxiv.org/abs/2410.10048</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.10048">https://arxiv.org/pdf/2410.10048</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.10048]] StatioCL: Contrastive Learning for Time Series via Non-Stationary and Temporal Contrast(https://arxiv.org/abs/2410.10048)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Contrastive learning (CL) has emerged as a promising approach for representation learning in time series data by embedding similar pairs closely while distancing dissimilar ones. However, existing CL methods often introduce false negative pairs (FNPs) by neglecting inherent characteristics and then randomly selecting distinct segments as dissimilar pairs, leading to erroneous representation learning, reduced model performance, and overall inefficiency. To address these issues, we systematically define and categorize FNPs in time series into semantic false negative pairs and temporal false negative pairs for the first time: the former arising from overlooking similarities in label categories, which correlates with similarities in non-stationarity and the latter from neglecting temporal proximity. Moreover, we introduce StatioCL, a novel CL framework that captures non-stationarity and temporal dependency to mitigate both FNPs and rectify the inaccuracies in learned representations. By interpreting and differentiating non-stationary states, which reflect the correlation between trends or temporal dynamics with underlying data patterns, StatioCL effectively captures the semantic characteristics and eliminates semantic FNPs. Simultaneously, StatioCL establishes fine-grained similarity levels based on temporal dependencies to capture varying temporal proximity between segments and to mitigate temporal FNPs. Evaluated on real-world benchmark time series classification datasets, StatioCL demonstrates a substantial improvement over state-of-the-art CL methods, achieving a 2.9% increase in Recall and a 19.2% reduction in FNPs. Most importantly, StatioCL also shows enhanced data efficiency and robustness against label scarcity.</li>
</ul>

<h3>Title: XAI-based Feature Selection for Improved Network Intrusion Detection Systems</h3>
<ul>
<li><strong>Authors: </strong>Osvaldo Arreche, Tanish Guntur, Mustafa Abdallah</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.10050">https://arxiv.org/abs/2410.10050</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.10050">https://arxiv.org/pdf/2410.10050</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.10050]] XAI-based Feature Selection for Improved Network Intrusion Detection Systems(https://arxiv.org/abs/2410.10050)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, attack, explainability</a></li>
<li><strong>Abstract: </strong>Explainability and evaluation of AI models are crucial parts of the security of modern intrusion detection systems (IDS) in the network security field, yet they are lacking. Accordingly, feature selection is essential for such parts in IDS because it identifies the most paramount features, enhancing attack detection and its description. In this work, we tackle the feature selection problem for IDS by suggesting new ways of applying eXplainable AI (XAI) methods for this problem. We identify the crucial attributes originated by distinct AI methods in tandem with the novel five attribute selection methods. We then compare many state-of-the-art feature selection strategies with our XAI-based feature selection methods, showing that most AI models perform better when using the XAI-based approach proposed in this work. By providing novel feature selection techniques and establishing the foundation for several XAI-based strategies, this research aids security analysts in the AI decision-making reasoning of IDS by providing them with a better grasp of critical intrusion traits. Furthermore, we make the source codes available so that the community may develop additional models on top of our foundational XAI-based feature selection framework.</li>
</ul>

<h3>Title: DINTR: Tracking via Diffusion-based Interpolation</h3>
<ul>
<li><strong>Authors: </strong>Pha Nguyen, Ngan Le, Jackson Cothren, Alper Yilmaz, Khoa Luu</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.10053">https://arxiv.org/abs/2410.10053</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.10053">https://arxiv.org/pdf/2410.10053</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.10053]] DINTR: Tracking via Diffusion-based Interpolation(https://arxiv.org/abs/2410.10053)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>Object tracking is a fundamental task in computer vision, requiring the localization of objects of interest across video frames. Diffusion models have shown remarkable capabilities in visual generation, making them well-suited for addressing several requirements of the tracking problem. This work proposes a novel diffusion-based methodology to formulate the tracking task. Firstly, their conditional process allows for injecting indications of the target object into the generation process. Secondly, diffusion mechanics can be developed to inherently model temporal correspondences, enabling the reconstruction of actual frames in video. However, existing diffusion models rely on extensive and unnecessary mapping to a Gaussian noise domain, which can be replaced by a more efficient and stable interpolation process. Our proposed interpolation mechanism draws inspiration from classic image-processing techniques, offering a more interpretable, stable, and faster approach tailored specifically for the object tracking task. By leveraging the strengths of diffusion models while circumventing their limitations, our Diffusion-based INterpolation TrackeR (DINTR) presents a promising new paradigm and achieves a superior multiplicity on seven benchmarks across five indicator representations.</li>
</ul>

<h3>Title: AlphaLoRA: Assigning LoRA Experts Based on Layer Training Quality</h3>
<ul>
<li><strong>Authors: </strong>Peijun Qing, Chongyang Gao, Yefan Zhou, Xingjian Diao, Yaoqing Yang, Soroush Vosoughi</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.10054">https://arxiv.org/abs/2410.10054</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.10054">https://arxiv.org/pdf/2410.10054</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.10054]] AlphaLoRA: Assigning LoRA Experts Based on Layer Training Quality(https://arxiv.org/abs/2410.10054)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Parameter-efficient fine-tuning methods, such as Low-Rank Adaptation (LoRA), are known to enhance training efficiency in Large Language Models (LLMs). Due to the limited parameters of LoRA, recent studies seek to combine LoRA with Mixture-of-Experts (MoE) to boost performance across various tasks. However, inspired by the observed redundancy in traditional MoE structures, previous studies identify similar redundancy among LoRA experts within the MoE architecture, highlighting the necessity for non-uniform allocation of LoRA experts across different layers. In this paper, we leverage Heavy-Tailed Self-Regularization (HT-SR) Theory to design a fine-grained allocation strategy. Our analysis reveals that the number of experts per layer correlates with layer training quality, which exhibits significant variability across layers. Based on this, we introduce AlphaLoRA, a theoretically principled and training-free method for allocating LoRA experts to further mitigate redundancy. Experiments on three models across ten language processing and reasoning benchmarks demonstrate that AlphaLoRA achieves comparable or superior performance over all baselines. Our code is available at this https URL.</li>
</ul>

<h3>Title: Learning to Customize Text-to-Image Diffusion In Diverse Context</h3>
<ul>
<li><strong>Authors: </strong>Taewook Kim, Wei Chen, Qiang Qiu</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.10058">https://arxiv.org/abs/2410.10058</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.10058">https://arxiv.org/pdf/2410.10058</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.10058]] Learning to Customize Text-to-Image Diffusion In Diverse Context(https://arxiv.org/abs/2410.10058)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>Most text-to-image customization techniques fine-tune models on a small set of \emph{personal concept} images captured in minimal contexts. This often results in the model becoming overfitted to these training images and unable to generalize to new contexts in future text prompts. Existing customization methods are built on the success of effectively representing personal concepts as textual embeddings. Thus, in this work, we resort to diversifying the context of these personal concepts \emph{solely} within the textual space by simply creating a contextually rich set of text prompts, together with a widely used self-supervised learning objective. Surprisingly, this straightforward and cost-effective method significantly improves semantic alignment in the textual space, and this effect further extends to the image space, resulting in higher prompt fidelity for generated images. Additionally, our approach does not require any architectural modifications, making it highly compatible with existing text-to-image customization methods. We demonstrate the broad applicability of our approach by combining it with four different baseline methods, achieving notable CLIP score improvements.</li>
</ul>

<h3>Title: Divide, Reweight, and Conquer: A Logit Arithmetic Approach for In-Context Learning</h3>
<ul>
<li><strong>Authors: </strong>Chengsong Huang, Langlin Huang, Jiaxin Huang</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.10074">https://arxiv.org/abs/2410.10074</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.10074">https://arxiv.org/pdf/2410.10074</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.10074]] Divide, Reweight, and Conquer: A Logit Arithmetic Approach for In-Context Learning(https://arxiv.org/abs/2410.10074)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>In-Context Learning (ICL) emerges as a key feature for Large Language Models (LLMs), allowing them to adapt to new tasks by leveraging task-specific examples without updating model parameters. However, ICL faces challenges with increasing numbers of examples due to performance degradation and quadratic computational costs. In this paper, we propose Logit Arithmetic Reweighting Approach (LARA), a novel framework that enhances ICL by using logit-based ensembling of multiple demonstrations. Our approach divides long input demonstrations into parallelizable shorter inputs to significantly reduce memory requirements, and then effectively aggregate the information by reweighting logits of each group via a non-gradient optimization approach. We further introduce Binary LARA (B-LARA), a variant that constrains weights to binary values to simplify the search space and reduces memory usage by filtering out less informative demonstration groups. Experiments on BBH and MMLU demonstrate that LARA and B-LARA outperform all baseline methods in both accuracy and memory efficiency. We also conduct extensive analysis to show that LARA generalizes well to scenarios of varying numbers of examples from limited to many-shot demonstrations.</li>
</ul>

<h3>Title: RoCoFT: Efficient Finetuning of Large Language Models with Row-Column Updates</h3>
<ul>
<li><strong>Authors: </strong>Md Kowsher, Tara Esmaeilbeig, Chun-Nam Yu, Mojtaba Soltanalian, Niloofar Yousefi</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.10075">https://arxiv.org/abs/2410.10075</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.10075">https://arxiv.org/pdf/2410.10075</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.10075]] RoCoFT: Efficient Finetuning of Large Language Models with Row-Column Updates(https://arxiv.org/abs/2410.10075)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer, large language model</a></li>
<li><strong>Abstract: </strong>We propose RoCoFT, a parameter-efficient fine-tuning method for large-scale language models (LMs) based on updating only a few rows and columns of the weight matrices in transformers. Through extensive experiments with medium-size LMs like BERT and RoBERTa, and larger LMs like Bloom-7B, Llama2-7B, and Llama2-13B, we show that our method gives comparable or better accuracies than state-of-art PEFT methods while also being more memory and computation-efficient. We also study the reason behind the effectiveness of our method with tools from neural tangent kernel theory. We empirically demonstrate that our kernel, constructed using a restricted set of row and column parameters, are numerically close to the full-parameter kernel and gives comparable classification performance. Ablation studies are conducted to investigate the impact of different algorithmic choices, including the selection strategy for rows and columns as well as the optimal rank for effective implementation of our method.</li>
</ul>

<h3>Title: PointNet with KAN versus PointNet with MLP for 3D Classification and Segmentation of Point Sets</h3>
<ul>
<li><strong>Authors: </strong>Ali Kashefi</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.10084">https://arxiv.org/abs/2410.10084</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.10084">https://arxiv.org/pdf/2410.10084</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.10084]] PointNet with KAN versus PointNet with MLP for 3D Classification and Segmentation of Point Sets(https://arxiv.org/abs/2410.10084)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction, segmentation</a></li>
<li><strong>Abstract: </strong>We introduce PointNet-KAN, a neural network for 3D point cloud classification and segmentation tasks, built upon two key components. First, it employs Kolmogorov-Arnold Networks (KANs) instead of traditional Multilayer Perceptrons (MLPs). Second, it retains the core principle of PointNet by using shared KAN layers and applying symmetric functions for global feature extraction, ensuring permutation invariance with respect to the input features. In traditional MLPs, the goal is to train the weights and biases with fixed activation functions; however, in KANs, the goal is to train the activation functions themselves. We use Jacobi polynomials to construct the KAN layers. We extensively evaluate PointNet-KAN across various polynomial degrees and special types such as the Lagrange, Chebyshev, and Gegenbauer polynomials. Our results show that PointNet-KAN achieves competitive performance compared to PointNet with MLPs on benchmark datasets for 3D object classification and segmentation, despite employing a shallower and simpler network architecture. We hope this work serves as a foundation and provides guidance for integrating KANs, as an alternative to MLPs, into more advanced point cloud processing architectures.</li>
</ul>

<h3>Title: Out-of-Bounding-Box Triggers: A Stealthy Approach to Cheat Object Detectors</h3>
<ul>
<li><strong>Authors: </strong>Tao Lin, Lijia Yu, Gaojie Jin, Renjue Li, Peng Wu, Lijun Zhang</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.10091">https://arxiv.org/abs/2410.10091</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.10091">https://arxiv.org/pdf/2410.10091</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.10091]] Out-of-Bounding-Box Triggers: A Stealthy Approach to Cheat Object Detectors(https://arxiv.org/abs/2410.10091)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack, robust, steal</a></li>
<li><strong>Abstract: </strong>In recent years, the study of adversarial robustness in object detection systems, particularly those based on deep neural networks (DNNs), has become a pivotal area of research. Traditional physical attacks targeting object detectors, such as adversarial patches and texture manipulations, directly manipulate the surface of the object. While these methods are effective, their overt manipulation of objects may draw attention in real-world applications. To address this, this paper introduces a more subtle approach: an inconspicuous adversarial trigger that operates outside the bounding boxes, rendering the object undetectable to the model. We further enhance this approach by proposing the Feature Guidance (FG) technique and the Universal Auto-PGD (UAPGD) optimization strategy for crafting high-quality triggers. The effectiveness of our method is validated through extensive empirical testing, demonstrating its high performance in both digital and physical environments. The code and video will be available at: this https URL.</li>
</ul>

<h3>Title: How to Leverage Demonstration Data in Alignment for Large Language Model? A Self-Imitation Learning Perspective</h3>
<ul>
<li><strong>Authors: </strong>Teng Xiao, Mingxiao Li, Yige Yuan, Huaisheng Zhu, Chao Cui, Vasant G Honavar</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.10093">https://arxiv.org/abs/2410.10093</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.10093">https://arxiv.org/pdf/2410.10093</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.10093]] How to Leverage Demonstration Data in Alignment for Large Language Model? A Self-Imitation Learning Perspective(https://arxiv.org/abs/2410.10093)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>This paper introduces a novel generalized self-imitation learning ($\textbf{GSIL}$) framework, which effectively and efficiently aligns large language models with offline demonstration data. We develop $\textbf{GSIL}$ by deriving a surrogate objective of imitation learning with density ratio estimates, facilitating the use of self-generated data and optimizing the imitation learning objective with simple classification losses. $\textbf{GSIL}$ eliminates the need for complex adversarial training in standard imitation learning, achieving lightweight and efficient fine-tuning for large language models. In addition, $\textbf{GSIL}$ encompasses a family of offline losses parameterized by a general class of convex functions for density ratio estimation and enables a unified view for alignment with demonstration data. Extensive experiments show that $\textbf{GSIL}$ consistently and significantly outperforms baselines in many challenging benchmarks, such as coding (HuamnEval), mathematical reasoning (GSM8K) and instruction-following benchmark (MT-Bench).</li>
</ul>

<h3>Title: Learning Linear Attention in Polynomial Time</h3>
<ul>
<li><strong>Authors: </strong>Morris Yau, Ekin Akyurek, Jiayuan Mao, Joshua B. Tenenbaum, Stefanie Jegelka, Jacob Andreas</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CL, cs.DS</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.10101">https://arxiv.org/abs/2410.10101</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.10101">https://arxiv.org/pdf/2410.10101</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.10101]] Learning Linear Attention in Polynomial Time(https://arxiv.org/abs/2410.10101)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Previous research has explored the computational expressivity of Transformer models in simulating Boolean circuits or Turing machines. However, the learnability of these simulators from observational data has remained an open question. Our study addresses this gap by providing the first polynomial-time learnability results (specifically strong, agnostic PAC learning) for single-layer Transformers with linear attention. We show that linear attention may be viewed as a linear predictor in a suitably defined RKHS. As a consequence, the problem of learning any linear transformer may be converted into the problem of learning an ordinary linear predictor in an expanded feature space, and any such predictor may be converted back into a multiheaded linear transformer. Moving to generalization, we show how to efficiently identify training datasets for which every empirical risk minimizer is equivalent (up to trivial symmetries) to the linear Transformer that generated the data, thereby guaranteeing the learned model will correctly generalize across all inputs. Finally, we provide examples of computations expressible via linear attention and therefore polynomial-time learnable, including associative memories, finite automata, and a class of Universal Turing Machine (UTMs) with polynomially bounded computation histories. We empirically validate our theoretical findings on three tasks: learning random linear attention networks, key--value associations, and learning to execute finite automata. Our findings bridge a critical gap between theoretical expressivity and learnability of Transformers, and show that flexible and general models of computation are efficiently learnable.</li>
</ul>

<h3>Title: High-Precision Dichotomous Image Segmentation via Probing Diffusion Capacity</h3>
<ul>
<li><strong>Authors: </strong>Qian Yu, Peng-Tao Jiang, Hao Zhang, Jinwei Chen, Bo Li, Lihe Zhang, Huchuan Lu</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.10105">https://arxiv.org/abs/2410.10105</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.10105">https://arxiv.org/pdf/2410.10105</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.10105]] High-Precision Dichotomous Image Segmentation via Probing Diffusion Capacity(https://arxiv.org/abs/2410.10105)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, diffusion, segmentation</a></li>
<li><strong>Abstract: </strong>In the realm of high-resolution (HR), fine-grained image segmentation, the primary challenge is balancing broad contextual awareness with the precision required for detailed object delineation, capturing intricate details and the finest edges of objects. Diffusion models, trained on vast datasets comprising billions of image-text pairs, such as SD V2.1, have revolutionized text-to-image synthesis by delivering exceptional quality, fine detail resolution, and strong contextual awareness, making them an attractive solution for high-resolution image segmentation. To this end, we propose DiffDIS, a diffusion-driven segmentation model that taps into the potential of the pre-trained U-Net within diffusion models, specifically designed for high-resolution, fine-grained object segmentation. By leveraging the robust generalization capabilities and rich, versatile image representation prior of the SD models, coupled with a task-specific stable one-step denoising approach, we significantly reduce the inference time while preserving high-fidelity, detailed generation. Additionally, we introduce an auxiliary edge generation task to not only enhance the preservation of fine details of the object boundaries, but reconcile the probabilistic nature of diffusion with the deterministic demands of segmentation. With these refined strategies in place, DiffDIS serves as a rapid object mask generation model, specifically optimized for generating detailed binary maps at high resolutions, while demonstrating impressive accuracy and swift processing. Experiments on the DIS5K dataset demonstrate the superiority of DiffDIS, achieving state-of-the-art results through a streamlined inference process. Our code will be made publicly available.</li>
</ul>

<h3>Title: Mastering AI: Big Data, Deep Learning, and the Evolution of Large Language Models -- Blockchain and Applications</h3>
<ul>
<li><strong>Authors: </strong>Pohsun Feng, Ziqian Bi, Lawrence K.Q. Yan, Yizhu Wen, Benji Peng, Junyu Liu, Caitlyn Heqi Yin, Tianyang Wang, Keyu Chen, Sen Zhang, Ming Li, Jiawei Xu, Ming Liu, Xuanhe Pan, Jinlang Wang, Qian Niu</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.10110">https://arxiv.org/abs/2410.10110</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.10110">https://arxiv.org/pdf/2410.10110</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.10110]] Mastering AI: Big Data, Deep Learning, and the Evolution of Large Language Models -- Blockchain and Applications(https://arxiv.org/abs/2410.10110)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, large language model</a></li>
<li><strong>Abstract: </strong>This article provides a detailed exploration of blockchain technology and its applications across various fields. It begins with an introduction to cryptography fundamentals, including symmetric and asymmetric encryption, and their roles in ensuring security and trust within blockchain systems. The article then delves into the structure and mechanics of Bitcoin and Ethereum, covering topics such as proof-of-work, proof-of-stake, and smart contracts. Additionally, it highlights practical applications of blockchain in industries like decentralized finance (DeFi), supply chain management, and identity authentication. The discussion also extends to consensus mechanisms and scalability challenges in blockchain, offering insights into emerging technologies like Layer 2 solutions and cross-chain interoperability. The article concludes by addressing the current state of academic research on blockchain and its potential future developments.</li>
</ul>

<h3>Title: Mixture of Experts Made Personalized: Federated Prompt Learning for Vision-Language Models</h3>
<ul>
<li><strong>Authors: </strong>Jun Luo, Chen Chen, Shandong Wu</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CL, cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.10114">https://arxiv.org/abs/2410.10114</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.10114">https://arxiv.org/pdf/2410.10114</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.10114]] Mixture of Experts Made Personalized: Federated Prompt Learning for Vision-Language Models(https://arxiv.org/abs/2410.10114)</code><input type="text"></li>
<li><strong>Keywords: </strong>federate</a></li>
<li><strong>Abstract: </strong>Prompt learning for pre-trained Vision-Language Models (VLMs) like CLIP has demonstrated potent applicability across diverse downstream tasks. This lightweight approach has quickly gained traction from federated learning (FL) researchers who seek to efficiently adapt VLMs to heterogeneous scenarios. However, current federated prompt learning methods are habitually restricted to the traditional FL paradigm, where the participating clients are generally only allowed to download a single globally aggregated model from the server. While justifiable for training full-sized models under federated settings, in this work, we argue that this paradigm is ill-suited for lightweight prompts. By facilitating the clients to download multiple pre-aggregated prompts as fixed non-local experts, we propose Personalized Federated Mixture of Adaptive Prompts (pFedMoAP), a novel FL framework that personalizes the prompt learning process through the lens of Mixture of Experts (MoE). pFedMoAP implements a local attention-based gating network that learns to generate enhanced text features for better alignment with local image data on the client, benefiting from both local and downloaded non-local adaptive prompt experts. The non-local experts are sparsely selected from a server-maintained pool, fostering collaborative learning across clients. To evaluate the proposed algorithm, we conduct extensive experiments across 9 datasets under various heterogeneous federated settings. The results show that pFedMoAP consistently outperforms the state-of-the-art alternatives, underscoring its efficacy in personalizing prompt learning for CLIP within the federated learning paradigm.</li>
</ul>

<h3>Title: Evaluating of Machine Unlearning: Robustness Verification Without Prior Modifications</h3>
<ul>
<li><strong>Authors: </strong>Heng Xu, Tianqing Zhu, Wanlei Zhou</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.10120">https://arxiv.org/abs/2410.10120</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.10120">https://arxiv.org/pdf/2410.10120</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.10120]] Evaluating of Machine Unlearning: Robustness Verification Without Prior Modifications(https://arxiv.org/abs/2410.10120)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack, robust, membership infer</a></li>
<li><strong>Abstract: </strong>Machine unlearning, a process enabling pre-trained models to remove the influence of specific training samples, has attracted significant attention in recent years. While extensive research has focused on developing efficient unlearning strategies, the critical aspect of unlearning verification has been largely overlooked. Existing verification methods mainly rely on machine learning attack techniques, such as membership inference attacks (MIAs) or backdoor attacks. However, these methods, not being formally designed for verification purposes, exhibit limitations in robustness and only support a small, predefined subset of samples. Moreover, dependence on prepared sample-level modifications of MIAs or backdoor attacks restricts their applicability in Machine Learning as a Service (MLaaS) environments. To address these limitations, we propose a novel robustness verification scheme without any prior modifications, and can support verification on a much larger set. Our scheme employs an optimization-based method to recover the actual training samples from the model. By comparative analysis of recovered samples extracted pre- and post-unlearning, MLaaS users can verify the unlearning process. This verification scheme, operating exclusively through model parameters, avoids the need for any sample-level modifications prior to model training while supporting verification on a much larger set and maintaining robustness. The effectiveness of our proposed approach is demonstrated through theoretical analysis and experiments involving diverse models on various datasets in different scenarios.</li>
</ul>

<h3>Title: Interaction-Guided Two-Branch Image Dehazing Network</h3>
<ul>
<li><strong>Authors: </strong>Huichun Liu, Xiaosong Li, Tianshu Tan</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.10121">https://arxiv.org/abs/2410.10121</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.10121">https://arxiv.org/pdf/2410.10121</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.10121]] Interaction-Guided Two-Branch Image Dehazing Network(https://arxiv.org/abs/2410.10121)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction, transformer</a></li>
<li><strong>Abstract: </strong>Image dehazing aims to restore clean images from hazy ones. Convolutional Neural Networks (CNNs) and Transformers have demonstrated exceptional performance in local and global feature extraction, respectively, and currently represent the two mainstream frameworks in image dehazing. In this paper, we propose a novel dual-branch image dehazing framework that guides CNN and Transformer components interactively. We reconsider the complementary characteristics of CNNs and Transformers by leveraging the differential relationships between global and local features for interactive guidance. This approach enables the capture of local feature positions through global attention maps, allowing the CNN to focus solely on feature information at effective positions. The single-branch Transformer design ensures the network's global information recovery capability. Extensive experiments demonstrate that our proposed method yields competitive qualitative and quantitative evaluation performance on both synthetic and real public datasets. Codes are available at this https URL</li>
</ul>

<h3>Title: Edge Unlearning is Not "on Edge"! An Adaptive Exact Unlearning System on Resource-Constrained Devices</h3>
<ul>
<li><strong>Authors: </strong>Xiaoyu Xia, Ziqi Wang, Ruoxi Sun, Bowen Liu, Ibrahim Khalil, Minhui Xue</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.10128">https://arxiv.org/abs/2410.10128</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.10128">https://arxiv.org/pdf/2410.10128</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.10128]] Edge Unlearning is Not "on Edge"! An Adaptive Exact Unlearning System on Resource-Constrained Devices(https://arxiv.org/abs/2410.10128)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy</a></li>
<li><strong>Abstract: </strong>The right to be forgotten mandates that machine learning models enable the erasure of a data owner's data and information from a trained model. Removing data from the dataset alone is inadequate, as machine learning models can memorize information from the training data, increasing the potential privacy risk to users. To address this, multiple machine unlearning techniques have been developed and deployed. Among them, approximate unlearning is a popular solution, but recent studies report that its unlearning effectiveness is not fully guaranteed. Another approach, exact unlearning, tackles this issue by discarding the data and retraining the model from scratch, but at the cost of considerable computational and memory resources. However, not all devices have the capability to perform such retraining. In numerous machine learning applications, such as edge devices, Internet-of-Things (IoT), mobile devices, and satellites, resources are constrained, posing challenges for deploying existing exact unlearning methods. In this study, we propose a Constraint-aware Adaptive Exact Unlearning System at the network Edge (CAUSE), an approach to enabling exact unlearning on resource-constrained devices. Aiming to minimize the retrain overhead by storing sub-models on the resource-constrained device, CAUSE innovatively applies a Fibonacci-based replacement strategy and updates the number of shards adaptively in the user-based data partition process. To further improve the effectiveness of memory usage, CAUSE leverages the advantage of model pruning to save memory via compression with minimal accuracy sacrifice. The experimental results demonstrate that CAUSE significantly outperforms other representative systems in realizing exact unlearning on the resource-constrained device by 9.23%-80.86%, 66.21%-83.46%, and 5.26%-194.13% in terms of unlearning speed, energy consumption, and accuracy.</li>
</ul>

<h3>Title: Stable Hadamard Memory: Revitalizing Memory-Augmented Agents for Reinforcement Learning</h3>
<ul>
<li><strong>Authors: </strong>Hung Le, Kien Do, Dung Nguyen, Sunil Gupta, Svetha Venkatesh</a></li>
<li><strong>Subjects: </strong>cs.LG, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.10132">https://arxiv.org/abs/2410.10132</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.10132">https://arxiv.org/pdf/2410.10132</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.10132]] Stable Hadamard Memory: Revitalizing Memory-Augmented Agents for Reinforcement Learning(https://arxiv.org/abs/2410.10132)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Effective decision-making in partially observable environments demands robust memory management. Despite their success in supervised learning, current deep-learning memory models struggle in reinforcement learning environments that are partially observable and long-term. They fail to efficiently capture relevant past information, adapt flexibly to changing observations, and maintain stable updates over long episodes. We theoretically analyze the limitations of existing memory models within a unified framework and introduce the Stable Hadamard Memory, a novel memory model for reinforcement learning agents. Our model dynamically adjusts memory by erasing no longer needed experiences and reinforcing crucial ones computationally efficiently. To this end, we leverage the Hadamard product for calibrating and updating memory, specifically designed to enhance memory capacity while mitigating numerical and learning challenges. Our approach significantly outperforms state-of-the-art memory-based methods on challenging partially observable benchmarks, such as meta-reinforcement learning, long-horizon credit assignment, and POPGym, demonstrating superior performance in handling long-term and evolving contexts.</li>
</ul>

<h3>Title: TextCtrl: Diffusion-based Scene Text Editing with Prior Guidance Control</h3>
<ul>
<li><strong>Authors: </strong>Weichao Zeng, Yan Shu, Zhenhang Li, Dongbao Yang, Yu Zhou</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.10133">https://arxiv.org/abs/2410.10133</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.10133">https://arxiv.org/pdf/2410.10133</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.10133]] TextCtrl: Diffusion-based Scene Text Editing with Prior Guidance Control(https://arxiv.org/abs/2410.10133)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, fair, diffusion</a></li>
<li><strong>Abstract: </strong>Centred on content modification and style preservation, Scene Text Editing (STE) remains a challenging task despite considerable progress in text-to-image synthesis and text-driven image manipulation recently. GAN-based STE methods generally encounter a common issue of model generalization, while Diffusion-based STE methods suffer from undesired style deviations. To address these problems, we propose TextCtrl, a diffusion-based method that edits text with prior guidance control. Our method consists of two key components: (i) By constructing fine-grained text style disentanglement and robust text glyph structure representation, TextCtrl explicitly incorporates Style-Structure guidance into model design and network training, significantly improving text style consistency and rendering accuracy. (ii) To further leverage the style prior, a Glyph-adaptive Mutual Self-attention mechanism is proposed which deconstructs the implicit fine-grained features of the source image to enhance style consistency and vision quality during inference. Furthermore, to fill the vacancy of the real-world STE evaluation benchmark, we create the first real-world image-pair dataset termed ScenePair for fair comparisons. Experiments demonstrate the effectiveness of TextCtrl compared with previous methods concerning both style fidelity and text accuracy.</li>
</ul>

<h3>Title: Beyond-RAG: Question Identification and Answer Generation in Real-Time Conversations</h3>
<ul>
<li><strong>Authors: </strong>Garima Agrawal, Sashank Gummuluri, Cosimo Spera</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.10136">https://arxiv.org/abs/2410.10136</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.10136">https://arxiv.org/pdf/2410.10136</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.10136]] Beyond-RAG: Question Identification and Answer Generation in Real-Time Conversations(https://arxiv.org/abs/2410.10136)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>In customer contact centers, human agents often struggle with long average handling times (AHT) due to the need to manually interpret queries and retrieve relevant knowledge base (KB) articles. While retrieval augmented generation (RAG) systems using large language models (LLMs) have been widely adopted in industry to assist with such tasks, RAG faces challenges in real-time conversations, such as inaccurate query formulation and redundant retrieval of frequently asked questions (FAQs). To address these limitations, we propose a decision support system that can look beyond RAG by first identifying customer questions in real time. If the query matches an FAQ, the system retrieves the answer directly from the FAQ database; otherwise, it generates answers via RAG. Our approach reduces reliance on manual queries, providing responses to agents within 2 seconds. Deployed in AI-powered human-agent assist solution at Minerva CQ, this system improves efficiency, reduces AHT, and lowers operational costs. We also introduce an automated LLM-agentic workflow to identify FAQs from historical transcripts when no predefined FAQs exist.</li>
</ul>

<h3>Title: Variational autoencoders with latent high-dimensional steady geometric flows for dynamics</h3>
<ul>
<li><strong>Authors: </strong>Andrew Gracyk</a></li>
<li><strong>Subjects: </strong>cs.LG, math.DG, stat.CO, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.10137">https://arxiv.org/abs/2410.10137</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.10137">https://arxiv.org/pdf/2410.10137</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.10137]] Variational autoencoders with latent high-dimensional steady geometric flows for dynamics(https://arxiv.org/abs/2410.10137)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>We develop Riemannian approaches to variational autoencoders (VAEs) for PDE-type ambient data with regularizing geometric latent dynamics, which we refer to as VAE-DLM, or VAEs with dynamical latent manifolds. We redevelop the VAE framework such that manifold geometries, subject to a geometric flow, embedded in Euclidean space are learned in the intermediary latent space developed by encoders and decoders. We reformulate the traditional evidence lower bound (ELBO) loss with a considerate choice of prior. We develop a linear geometric flow with a steady-state regularizing term. This geometric flow requires only automatic differentiation of one time derivative, and can be solved in moderately high dimensions in a physics-informed approach, allowing more expressive latent representations. We discuss how this flow can be formulated as a gradient flow, and maintains entropy away from metric singularity. This, along with an eigenvalue penalization condition, helps ensure the manifold is sufficiently large in measure, nondegenerate, and a canonical geometry, which contribute to a robust representation. Our methods focus on the modified multi-layer perceptron architecture with tanh activations for the manifold encoder-decoder. We demonstrate, on our datasets of interest, our methods perform at least as well as the traditional VAE, and oftentimes better. Our methods can outperform a standard VAE and a VAE endowed with our proposed architecture by up to 25% reduction in out-of-distribution (OOD) error and potentially greater. We highlight our method on ambient PDEs whose solutions maintain minimal variation in late times over its solution. Our approaches are particularly favorable with severe OOD effect. We provide empirical justification towards how latent Riemannian manifolds improve robust learning for external dynamics with VAEs.</li>
</ul>

<h3>Title: $\alpha$-DPO: Adaptive Reward Margin is What Direct Preference Optimization Needs</h3>
<ul>
<li><strong>Authors: </strong>Junkang Wu, Xue Wang, Zhengyi Yang, Jiancan Wu, Jinyang Gao, Bolin Ding, Xiang Wang, Rong Jin, Xiangnan He</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.10148">https://arxiv.org/abs/2410.10148</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.10148">https://arxiv.org/pdf/2410.10148</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.10148]] $\alpha$-DPO: Adaptive Reward Margin is What Direct Preference Optimization Needs(https://arxiv.org/abs/2410.10148)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, large language model</a></li>
<li><strong>Abstract: </strong>Aligning large language models (LLMs) with human values and intentions is crucial for their utility, honesty, and safety. Reinforcement learning from human feedback (RLHF) is a popular approach to achieve this alignment, but it faces challenges in computational efficiency and training stability. Recent methods like Direct Preference Optimization (DPO) and Simple Preference Optimization (SimPO) have proposed offline alternatives to RLHF, simplifying the process by reparameterizing the reward function. However, DPO depends on a potentially suboptimal reference model, and SimPO's assumption of a fixed target reward margin may lead to suboptimal decisions in diverse data settings. In this work, we propose $\alpha$-DPO, an adaptive preference optimization algorithm designed to address these limitations by introducing a dynamic reward margin. Specifically, $\alpha$-DPO employs an adaptive preference distribution, balancing the policy model and the reference model to achieve personalized reward margins. We provide theoretical guarantees for $\alpha$-DPO, demonstrating its effectiveness as a surrogate optimization objective and its ability to balance alignment and diversity through KL divergence control. Empirical evaluations on AlpacaEval 2 and Arena-Hard show that $\alpha$-DPO consistently outperforms DPO and SimPO across various model settings, establishing it as a robust approach for fine-tuning LLMs. Our method achieves significant improvements in win rates, highlighting its potential as a powerful tool for LLM alignment. The code is available at this https URL</li>
</ul>

<h3>Title: Jailbreak Instruction-Tuned LLMs via end-of-sentence MLP Re-weighting</h3>
<ul>
<li><strong>Authors: </strong>Yifan Luo, Zhennan Zhou, Meitan Wang, Bin Dong</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.10150">https://arxiv.org/abs/2410.10150</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.10150">https://arxiv.org/pdf/2410.10150</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.10150]] Jailbreak Instruction-Tuned LLMs via end-of-sentence MLP Re-weighting(https://arxiv.org/abs/2410.10150)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack, robust, large language model</a></li>
<li><strong>Abstract: </strong>In this paper, we investigate the safety mechanisms of instruction fine-tuned large language models (LLMs). We discover that re-weighting MLP neurons can significantly compromise a model's safety, especially for MLPs in end-of-sentence inferences. We hypothesize that LLMs evaluate the harmfulness of prompts during end-of-sentence inferences, and MLP layers plays a critical role in this process. Based on this hypothesis, we develop 2 novel white-box jailbreak methods: a prompt-specific method and a prompt-general method. The prompt-specific method targets individual prompts and optimizes the attack on the fly, while the prompt-general method is pre-trained offline and can generalize to unseen harmful prompts. Our methods demonstrate robust performance across 7 popular open-source LLMs, size ranging from 2B to 72B. Furthermore, our study provides insights into vulnerabilities of instruction-tuned LLM's safety and deepens the understanding of the internal mechanisms of LLMs.</li>
</ul>

<h3>Title: Diagnosing Hate Speech Classification: Where Do Humans and Machines Disagree, and Why?</h3>
<ul>
<li><strong>Authors: </strong>Xilin Yang</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.CY, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.10153">https://arxiv.org/abs/2410.10153</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.10153">https://arxiv.org/pdf/2410.10153</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.10153]] Diagnosing Hate Speech Classification: Where Do Humans and Machines Disagree, and Why?(https://arxiv.org/abs/2410.10153)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>This study uses the cosine similarity ratio, embedding regression, and manual re-annotation to diagnose hate speech classification. We begin by computing cosine similarity ratio on a dataset "Measuring Hate Speech" that contains 135,556 annotated comments on social media. This way, we show a basic use of cosine similarity as a description of hate speech content. We then diagnose hate speech classification starting from understanding the inconsistency of human annotation from the dataset. Using embedding regression as a basic diagnostic, we found that female annotators are more sensitive to racial slurs that target the black population. We perform with a more complicated diagnostic by training a hate speech classifier using a SoTA pre-trained large language model, NV-Embed-v2, to convert texts to embeddings and run a logistic regression. This classifier achieves a testing accuracy of 94%. In diagnosing where machines disagree with human annotators, we found that machines make fewer mistakes than humans despite the fact that human annotations are treated as ground truth in the training set. Machines perform better in correctly labeling long statements of facts, but perform worse in labeling short instances of swear words. We hypothesize that this is due to model alignment - while curating models at their creation prevents the models from producing obvious hate speech, it also reduces the model's ability to detect such content.</li>
</ul>

<h3>Title: Will the Inclusion of Generated Data Amplify Bias Across Generations in Future Image Classification Models?</h3>
<ul>
<li><strong>Authors: </strong>Zeliang Zhang, Xin Liang, Mingqian Feng, Susan Liang, Chenliang Xu</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.10160">https://arxiv.org/abs/2410.10160</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.10160">https://arxiv.org/pdf/2410.10160</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.10160]] Will the Inclusion of Generated Data Amplify Bias Across Generations in Future Image Classification Models?(https://arxiv.org/abs/2410.10160)</code><input type="text"></li>
<li><strong>Keywords: </strong>fair, generative</a></li>
<li><strong>Abstract: </strong>As the demand for high-quality training data escalates, researchers have increasingly turned to generative models to create synthetic data, addressing data scarcity and enabling continuous model improvement. However, reliance on self-generated data introduces a critical question: Will this practice amplify bias in future models? While most research has focused on overall performance, the impact on model bias, particularly subgroup bias, remains underexplored. In this work, we investigate the effects of the generated data on image classification tasks, with a specific focus on bias. We develop a practical simulation environment that integrates a self-consuming loop, where the generative model and classification model are trained synergistically. Hundreds of experiments are conducted on Colorized MNIST, CIFAR-20/100, and Hard ImageNet datasets to reveal changes in fairness metrics across generations. In addition, we provide a conjecture to explain the bias dynamics when training models on continuously augmented datasets across generations. Our findings contribute to the ongoing debate on the implications of synthetic data for fairness in real-world applications.</li>
</ul>

<h3>Title: BinSimDB: Benchmark Dataset Construction for Fine-Grained Binary Code Similarity Analysis</h3>
<ul>
<li><strong>Authors: </strong>Fei Zuo, Cody Tompkins, Qiang Zeng, Lannan Luo, Yung Ryn Choe, Junghwan Rhee</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.10163">https://arxiv.org/abs/2410.10163</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.10163">https://arxiv.org/pdf/2410.10163</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.10163]] BinSimDB: Benchmark Dataset Construction for Fine-Grained Binary Code Similarity Analysis(https://arxiv.org/abs/2410.10163)</code><input type="text"></li>
<li><strong>Keywords: </strong>security</a></li>
<li><strong>Abstract: </strong>Binary Code Similarity Analysis (BCSA) has a wide spectrum of applications, including plagiarism detection, vulnerability discovery, and malware analysis, thus drawing significant attention from the security community. However, conventional techniques often face challenges in balancing both accuracy and scalability simultaneously. To overcome these existing problems, a surge of deep learning-based work has been recently proposed. Unfortunately, many researchers still find it extremely difficult to conduct relevant studies or extend existing approaches. First, prior work typically relies on proprietary benchmark without making the entire dataset publicly accessible. Consequently, a large-scale, well-labeled dataset for binary code similarity analysis remains precious and scarce. Moreover, previous work has primarily focused on comparing at the function level, rather than exploring other finer granularities. Therefore, we argue that the lack of a fine-grained dataset for BCSA leaves a critical gap in current research. To address these challenges, we construct a benchmark dataset for fine-grained binary code similarity analysis called BinSimDB, which contains equivalent pairs of smaller binary code snippets, such as basic blocks. Specifically, we propose BMerge and BPair algorithms to bridge the discrepancies between two binary code snippets caused by different optimization levels or platforms. Furthermore, we empirically study the properties of our dataset and evaluate its effectiveness for the BCSA research. The experimental results demonstrate that BinSimDB significantly improves the performance of binary code similarity comparison.</li>
</ul>

<h3>Title: HSR-Enhanced Sparse Attention Acceleration</h3>
<ul>
<li><strong>Authors: </strong>Bo Chen, Yingyu Liang, Zhizhou Sha, Zhenmei Shi, Zhao Song</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.10165">https://arxiv.org/abs/2410.10165</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.10165">https://arxiv.org/pdf/2410.10165</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.10165]] HSR-Enhanced Sparse Attention Acceleration(https://arxiv.org/abs/2410.10165)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large Language Models (LLMs) have demonstrated remarkable capabilities across various applications, but their performance on long-context tasks is often limited by the computational complexity of attention mechanisms. This paper introduces a novel approach to accelerate attention computation in LLMs, particularly for long-context scenarios. We leverage the inherent sparsity within attention mechanisms, both in conventional Softmax attention and ReLU attention (with $\mathsf{ReLU}^\alpha$ activation, $\alpha \in \mathbb{N}_+$), to significantly reduce the running time complexity. Our method employs a Half-Space Reporting (HSR) data structure to rapidly identify non-zero or "massively activated" entries in the attention matrix. We present theoretical analyses for two key scenarios: attention generation and full attention computation with long input context. Our approach achieves a running time of $O(mn^{4/5})$ significantly faster than the naive approach $O(mn)$ for attention generation, where $n$ is the context length, $m$ is the query length, and $d$ is the hidden dimension. We can also reduce the running time of full attention computation from $O(mn)$ to $O(mn^{1 - 1 / \lfloor d/2\rfloor} + mn^{4/5})$. Importantly, our method introduces no error for ReLU attention and only provably negligible error for Softmax attention, where the latter is supported by our empirical validation. This work represents a significant step towards enabling efficient long-context processing in LLMs, potentially broadening their applicability across various domains.</li>
</ul>

<h3>Title: Automated Filtering of Human Feedback Data for Aligning Text-to-Image Diffusion Models</h3>
<ul>
<li><strong>Authors: </strong>Yongjin Yang, Sihyeon Kim, Hojung Jung, Sangmin Bae, SangMook Kim, Se-Young Yun, Kimin Lee</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.10166">https://arxiv.org/abs/2410.10166</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.10166">https://arxiv.org/pdf/2410.10166</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.10166]] Automated Filtering of Human Feedback Data for Aligning Text-to-Image Diffusion Models(https://arxiv.org/abs/2410.10166)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, large language model</a></li>
<li><strong>Abstract: </strong>Fine-tuning text-to-image diffusion models with human feedback is an effective method for aligning model behavior with human intentions. However, this alignment process often suffers from slow convergence due to the large size and noise present in human feedback datasets. In this work, we propose FiFA, a novel automated data filtering algorithm designed to enhance the fine-tuning of diffusion models using human feedback datasets with direct preference optimization (DPO). Specifically, our approach selects data by solving an optimization problem to maximize three components: preference margin, text quality, and text diversity. The concept of preference margin is used to identify samples that contain high informational value to address the noisy nature of feedback dataset, which is calculated using a proxy reward model. Additionally, we incorporate text quality, assessed by large language models to prevent harmful contents, and consider text diversity through a k-nearest neighbor entropy estimator to improve generalization. Finally, we integrate all these components into an optimization process, with approximating the solution by assigning importance score to each data pair and selecting the most important ones. As a result, our method efficiently filters data automatically, without the need for manual intervention, and can be applied to any large-scale dataset. Experimental results show that FiFA significantly enhances training stability and achieves better performance, being preferred by humans 17% more, while using less than 0.5% of the full data and thus 1% of the GPU hours compared to utilizing full human feedback datasets.</li>
</ul>

<h3>Title: X-Fi: A Modality-Invariant Foundation Model for Multimodal Human Sensing</h3>
<ul>
<li><strong>Authors: </strong>Xinyan Chen, Jianfei Yang</a></li>
<li><strong>Subjects: </strong>cs.CV, eess.SP</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.10167">https://arxiv.org/abs/2410.10167</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.10167">https://arxiv.org/pdf/2410.10167</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.10167]] X-Fi: A Modality-Invariant Foundation Model for Multimodal Human Sensing(https://arxiv.org/abs/2410.10167)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, transformer</a></li>
<li><strong>Abstract: </strong>Human sensing, which employs various sensors and advanced deep learning technologies to accurately capture and interpret human body information, has significantly impacted fields like public security and robotics. However, current human sensing primarily depends on modalities such as cameras and LiDAR, each of which has its own strengths and limitations. Furthermore, existing multi-modal fusion solutions are typically designed for fixed modality combinations, requiring extensive retraining when modalities are added or removed for diverse scenarios. In this paper, we propose a modality-invariant foundation model for all modalities, X-Fi, to address this issue. X-Fi enables the independent or combinatory use of sensor modalities without additional training by utilizing a transformer structure to accommodate variable input sizes and incorporating a novel "X-fusion" mechanism to preserve modality-specific features during multimodal integration. This approach not only enhances adaptability but also facilitates the learning of complementary features across modalities. Extensive experiments conducted on the MM-Fi and XRF55 datasets, employing six distinct modalities, demonstrate that X-Fi achieves state-of-the-art performance in human pose estimation (HPE) and human activity recognition (HAR) tasks. The findings indicate that our proposed model can efficiently support a wide range of human sensing applications, ultimately contributing to the evolution of scalable, multimodal sensing technologies.</li>
</ul>

<h3>Title: First Creating Backgrounds Then Rendering Texts: A New Paradigm for Visual Text Blending</h3>
<ul>
<li><strong>Authors: </strong>Zhenhang Li, Yan Shu, Weichao Zeng, Dongbao Yang, Yu Zhou</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.10168">https://arxiv.org/abs/2410.10168</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.10168">https://arxiv.org/pdf/2410.10168</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.10168]] First Creating Backgrounds Then Rendering Texts: A New Paradigm for Visual Text Blending(https://arxiv.org/abs/2410.10168)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>Diffusion models, known for their impressive image generation abilities, have played a pivotal role in the rise of visual text generation. Nevertheless, existing visual text generation methods often focus on generating entire images with text prompts, leading to imprecise control and limited practicality. A more promising direction is visual text blending, which focuses on seamlessly merging texts onto text-free backgrounds. However, existing visual text blending methods often struggle to generate high-fidelity and diverse images due to a shortage of backgrounds for synthesis and limited generalization capabilities. To overcome these challenges, we propose a new visual text blending paradigm including both creating backgrounds and rendering texts. Specifically, a background generator is developed to produce high-fidelity and text-free natural images. Moreover, a text renderer named GlyphOnly is designed for achieving visually plausible text-background integration. GlyphOnly, built on a Stable Diffusion framework, utilizes glyphs and backgrounds as conditions for accurate rendering and consistency control, as well as equipped with an adaptive text block exploration strategy for small-scale text rendering. We also explore several downstream applications based on our method, including scene text dataset synthesis for boosting scene text detectors, as well as text image customization and editing. Code and model will be available at \url{this https URL}.</li>
</ul>

<h3>Title: Balanced Neural ODEs: nonlinear model order reduction and Koopman operator approxmations</h3>
<ul>
<li><strong>Authors: </strong>Julius Aka, Johannes Brunnemann, JÃ¶rg Eiden, Arne Speerforck, Lars Mikelsons</a></li>
<li><strong>Subjects: </strong>cs.LG, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.10174">https://arxiv.org/abs/2410.10174</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.10174">https://arxiv.org/pdf/2410.10174</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.10174]] Balanced Neural ODEs: nonlinear model order reduction and Koopman operator approxmations(https://arxiv.org/abs/2410.10174)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Variational Autoencoders (VAEs) are a powerful framework for learning compact latent representations, while NeuralODEs excel in learning transient system dynamics. This work combines the strengths of both to create fast surrogate models with adjustable complexity. By leveraging the VAE's dimensionality reduction using a non-hierarchical prior, our method adaptively assigns stochastic noise, naturally complementing known NeuralODE training enhancements and enabling probabilistic time series modeling. We show that standard Latent ODEs struggle with dimensionality reduction in systems with time-varying inputs. Our approach mitigates this by continuously propagating variational parameters through time, establishing fixed information channels in latent space. This results in a flexible and robust method that can learn different system complexities, e.g. deep neural networks or linear matrices. Hereby, it enables efficient approximation of the Koopman operator without the need for predefining its dimensionality. As our method balances dimensionality reduction and reconstruction accuracy, we call it Balanced Neural ODE (B-NODE). We demonstrate the effectiveness of this method on academic test cases and apply it to a real-world example of a thermal power plant.</li>
</ul>

<h3>Title: Identity-Focused Inference and Extraction Attacks on Diffusion Models</h3>
<ul>
<li><strong>Authors: </strong>Jayneel Vora, Aditya Krishnan, Nader Bouacida, Prabhu RV Shankar, Prasant Mohapatra</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.CR, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.10177">https://arxiv.org/abs/2410.10177</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.10177">https://arxiv.org/pdf/2410.10177</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.10177]] Identity-Focused Inference and Extraction Attacks on Diffusion Models(https://arxiv.org/abs/2410.10177)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, attack, extraction, membership infer, diffusion</a></li>
<li><strong>Abstract: </strong>The increasing reliance on diffusion models for generating synthetic images has amplified concerns about the unauthorized use of personal data, particularly facial images, in model training. In this paper, we introduce a novel identity inference framework to hold model owners accountable for including individuals' identities in their training data. Our approach moves beyond traditional membership inference attacks by focusing on identity-level inference, providing a new perspective on data privacy violations. Through comprehensive evaluations on two facial image datasets, Labeled Faces in the Wild (LFW) and CelebA, our experiments demonstrate that the proposed membership inference attack surpasses baseline methods, achieving an attack success rate of up to 89% and an AUC-ROC of 0.91, while the identity inference attack attains 92% on LDM models trained on LFW, and the data extraction attack achieves 91.6% accuracy on DDPMs, validating the effectiveness of our approach across diffusion models.</li>
</ul>

<h3>Title: GUISE: Graph GaUssIan Shading watErmark</h3>
<ul>
<li><strong>Authors: </strong>Renyi Yang</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.MM</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.10178">https://arxiv.org/abs/2410.10178</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.10178">https://arxiv.org/pdf/2410.10178</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.10178]] GUISE: Graph GaUssIan Shading watErmark(https://arxiv.org/abs/2410.10178)</code><input type="text"></li>
<li><strong>Keywords: </strong>protect, attack, robust, extraction, watermark, diffusion, generative</a></li>
<li><strong>Abstract: </strong>In the expanding field of generative artificial intelligence, integrating robust watermarking technologies is essential to protect intellectual property and maintain content authenticity. Traditionally, watermarking techniques have been developed primarily for rich information media such as images and audio. However, these methods have not been adequately adapted for graph-based data, particularly molecular graphs. Latent 3D graph diffusion(LDM-3DG) is an ascendant approach in the molecular graph generation field. This model effectively manages the complexities of molecular structures, preserving essential symmetries and topological features. We adapt the Gaussian Shading, a proven performance lossless watermarking technique, to the latent graph diffusion domain to protect this sophisticated new technology. Our adaptation simplifies the watermark diffusion process through duplication and padding, making it adaptable and suitable for various message types. We conduct several experiments using the LDM-3DG model on publicly available datasets QM9 and Drugs, to assess the robustness and effectiveness of our technique. Our results demonstrate that the watermarked molecules maintain statistical parity in 9 out of 10 performance metrics compared to the original. Moreover, they exhibit a 100% detection rate and a 99% extraction rate in a 2D decoded pipeline, while also showing robustness against post-editing attacks.</li>
</ul>

<h3>Title: Is Parameter Collision Hindering Continual Learning in LLMs?</h3>
<ul>
<li><strong>Authors: </strong>Shuo Yang, Kun-Peng Ning, Yu-Yang Liu, Jia-Yu Yao, Yong-Hong Tian, Yi-Bing Song, Li Yuan</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.10179">https://arxiv.org/abs/2410.10179</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.10179">https://arxiv.org/pdf/2410.10179</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.10179]] Is Parameter Collision Hindering Continual Learning in LLMs?(https://arxiv.org/abs/2410.10179)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large Language Models (LLMs) often suffer from catastrophic forgetting when learning multiple tasks sequentially, making continual learning (CL) essential for their dynamic deployment. Existing state-of-the-art (SOTA) methods, such as O-LoRA, typically focus on constructing orthogonality tasks to decouple parameter interdependence from various this http URL this paper, we reveal that building non-collision parameters is a more critical factor in addressing CL challenges. Our theoretical and experimental analyses demonstrate that non-collision parameters can provide better task orthogonality, which is a sufficient but unnecessary condition. Furthermore, knowledge from multiple domains will be preserved in non-collision parameter subspaces, making it more difficult to forget previously seen data. Leveraging this insight, we propose Non-collision Low-Rank Adaptation (N-LoRA), a simple yet effective approach leveraging low collision rates to enhance CL in LLMs. Experimental results on multiple CL benchmarks indicate that N-LoRA achieves superior performance (+2.9), higher task orthogonality (*4.1 times), and lower parameter collision (*58.1 times) than SOTA methods.</li>
</ul>

<h3>Title: Gaussian Mixture Vector Quantization with Aggregated Categorical Posterior</h3>
<ul>
<li><strong>Authors: </strong>Mingyuan Yan, Jiawei Wu, Rushi Shah, Dianbo Liu</a></li>
<li><strong>Subjects: </strong>cs.LG, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.10180">https://arxiv.org/abs/2410.10180</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.10180">https://arxiv.org/pdf/2410.10180</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.10180]] Gaussian Mixture Vector Quantization with Aggregated Categorical Posterior(https://arxiv.org/abs/2410.10180)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>The vector quantization is a widely used method to map continuous representation to discrete space and has important application in tokenization for generative mode, bottlenecking information and many other tasks in machine learning. Vector Quantized Variational Autoencoder (VQ-VAE) is a type of variational autoencoder using discrete embedding as latent. We generalize the technique further, enriching the probabilistic framework with a Gaussian mixture as the underlying generative model. This framework leverages a codebook of latent means and adaptive variances to capture complex data distributions. This principled framework avoids various heuristics and strong assumptions that are needed with the VQ-VAE to address training instability and to improve codebook utilization. This approach integrates the benefits of both discrete and continuous representations within a variational Bayesian framework. Furthermore, by introducing the \textit{Aggregated Categorical Posterior Evidence Lower Bound} (ALBO), we offer a principled alternative optimization objective that aligns variational distributions with the generative model. Our experiments demonstrate that GM-VQ improves codebook utilization and reduces information loss without relying on handcrafted heuristics.</li>
</ul>

<h3>Title: Scalable Multi-Domain Adaptation of Language Models using Modular Experts</h3>
<ul>
<li><strong>Authors: </strong>Peter Schafhalter, Shun Liao, Yanqi Zhou, Chih-Kuan Yeh, Arun Kandoor, James Laudon</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.10181">https://arxiv.org/abs/2410.10181</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.10181">https://arxiv.org/pdf/2410.10181</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.10181]] Scalable Multi-Domain Adaptation of Language Models using Modular Experts(https://arxiv.org/abs/2410.10181)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Domain-specific adaptation is critical to maximizing the performance of pre-trained language models (PLMs) on one or multiple targeted tasks, especially under resource-constrained use cases, such as edge devices. However, existing methods often struggle to balance domain-specific performance, retention of general knowledge, and efficiency for training and inference. To address these challenges, we propose Modular Domain Experts (MoDE). MoDE is a mixture-of-experts architecture that augments a general PLMs with modular, domain-specialized experts. These experts are trained independently and composed together via a lightweight training process. In contrast to standard low-rank adaptation methods, each MoDE expert consists of several transformer layers which scale better with more training examples and larger parameter counts. Our evaluation demonstrates that MoDE achieves comparable target performances to full parameter fine-tuning while achieving 1.65% better retention performance. Moreover, MoDE's architecture enables flexible sharding configurations and improves training speeds by up to 38% over state-of-the-art distributed training configurations.</li>
</ul>

<h3>Title: Hamiltonian Neural Networks for Robust Out-of-Time Credit Scoring</h3>
<ul>
<li><strong>Authors: </strong>Javier MarÃ­n</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.10182">https://arxiv.org/abs/2410.10182</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.10182">https://arxiv.org/pdf/2410.10182</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.10182]] Hamiltonian Neural Networks for Robust Out-of-Time Credit Scoring(https://arxiv.org/abs/2410.10182)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>This paper introduces a novel Hamiltonian-inspired neural network approach to credit scoring, designed to address the challenges of class imbalance and out-of-time (OOT) prediction in financial risk management. Drawing from concepts in Hamiltonian mechanics, we develop a symplectic optimizer and a new loss function to capture the complex dynamics of credit risk evolution. Using the Freddie Mac Single-Family Loan-Level Dataset, we evaluate our model's performance against other machine learning approaches. Our method shows superior discriminative power in OOT scenarios, as measured by the Area Under the Curve (AUC), indicating better ranking ability and robustness to class imbalance. The Hamiltonian-inspired approach shows particular strength in maintaining consistent performance between in-sample and OOT test sets, suggesting improved generalization to future, unseen data. These findings suggest that physics-inspired techniques offer a promising direction for developing more robust and reliable credit scoring models, particularly in uncertain economic situations.</li>
</ul>

<h3>Title: Fed-piLot: Optimizing LoRA Assignment for Efficient Federated Foundation Model Fine-Tuning</h3>
<ul>
<li><strong>Authors: </strong>Zikai Zhang, Jiahao Xu, Ping Liu, Rui Hu</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.DC</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.10200">https://arxiv.org/abs/2410.10200</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.10200">https://arxiv.org/pdf/2410.10200</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.10200]] Fed-piLot: Optimizing LoRA Assignment for Efficient Federated Foundation Model Fine-Tuning(https://arxiv.org/abs/2410.10200)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, federate</a></li>
<li><strong>Abstract: </strong>Foundation models (FMs) have shown remarkable advancements in enhancing the performance of intelligent applications. To address the need for data privacy in FM fine-tuning, federated learning has emerged as the de facto framework. Specifically, Federated FMs (FedFMs) fine-tuning using low-rank adaptation (LoRA) modules instead of the full model over multiple clients can achieve both parameter efficiency and data privacy. However, recent studies rarely address the challenges posed by clients with heterogeneous resources, particularly in GPU memory capacity. In this paper, we introduce Fed-piLot, an efficient FedFM fine-tuning framework with optimized local LoRA assignments for heterogeneous clients. By emphasizing the different memory consumption for training different LoRA layers, as well as the varying contributions of different layers to model performance, we formulate the LoRA assignment as a Knapsack Optimization Problem. We design a Local-Global Information Gain Score (IG-Score) based value function to optimize LoRA assignment under clients' memory constraints. To further mitigate the impact of heterogeneity in model updates, we propose a novel Spatial-Temporal model aggregation (STAgg) rule using the Dynamic Weight Adjustment (DWA) strategy. Experimental results on three datasets under both IID and non-IID conditions demonstrate the effectiveness and efficiency of Fed-piLot. The code will be publicly available.</li>
</ul>

<h3>Title: MagicEraser: Erasing Any Objects via Semantics-Aware Control</h3>
<ul>
<li><strong>Authors: </strong>Fan Li, Zixiao Zhang, Yi Huang, Jianzhuang Liu, Renjing Pei, Bin Shao, Songcen Xu</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.10207">https://arxiv.org/abs/2410.10207</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.10207">https://arxiv.org/pdf/2410.10207</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.10207]] MagicEraser: Erasing Any Objects via Semantics-Aware Control(https://arxiv.org/abs/2410.10207)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>The traditional image inpainting task aims to restore corrupted regions by referencing surrounding background and foreground. However, the object erasure task, which is in increasing demand, aims to erase objects and generate harmonious background. Previous GAN-based inpainting methods struggle with intricate texture generation. Emerging diffusion model-based algorithms, such as Stable Diffusion Inpainting, exhibit the capability to generate novel content, but they often produce incongruent results at the locations of the erased objects and require high-quality text prompt inputs. To address these challenges, we introduce MagicEraser, a diffusion model-based framework tailored for the object erasure task. It consists of two phases: content initialization and controllable generation. In the latter phase, we develop two plug-and-play modules called prompt tuning and semantics-aware attention refocus. Additionally, we propose a data construction strategy that generates training data specially suitable for this task. MagicEraser achieves fine and effective control of content generation while mitigating undesired artifacts. Experimental results highlight a valuable advancement of our approach in the object erasure task.</li>
</ul>

<h3>Title: Effi-Code: Unleashing Code Efficiency in Language Models</h3>
<ul>
<li><strong>Authors: </strong>Dong Huang, Guangtao Zeng, Jianbo Dai, Meng Luo, Han Weng, Yuhao Qing, Heming Cui, Zhijiang Guo, Jie M. Zhang</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.SE</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.10209">https://arxiv.org/abs/2410.10209</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.10209">https://arxiv.org/pdf/2410.10209</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.10209]] Effi-Code: Unleashing Code Efficiency in Language Models(https://arxiv.org/abs/2410.10209)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>As the use of large language models (LLMs) for code generation becomes more prevalent in software development, it is critical to enhance both the efficiency and correctness of the generated code. Existing methods and models primarily focus on the correctness of LLM-generated code, ignoring efficiency. In this work, we present Effi-Code, an approach to enhancing code generation in LLMs that can improve both efficiency and correctness. We introduce a Self-Optimization process based on Overhead Profiling that leverages open-source LLMs to generate a high-quality dataset of correct and efficient code samples. This dataset is then used to fine-tune various LLMs. Our method involves the iterative refinement of generated code, guided by runtime performance metrics and correctness checks. Extensive experiments demonstrate that models fine-tuned on the Effi-Code show significant improvements in both code correctness and efficiency across task types. For example, the pass@1 of DeepSeek-Coder-6.7B-Instruct generated code increases from \textbf{43.3\%} to \textbf{76.8\%}, and the average execution time for the same correct tasks decreases by \textbf{30.5\%}. Effi-Code offers a scalable and generalizable approach to improving code generation in AI systems, with potential applications in software development, algorithm design, and computational problem-solving. The source code of Effi-Code was released in \url{this https URL}.</li>
</ul>

<h3>Title: Minimum Tuning to Unlock Long Output from LLMs with High Quality Data as the Key</h3>
<ul>
<li><strong>Authors: </strong>Yingda Chen, Xingjun Wang, Jintao Huang, Yunlin Mao, Daoze Zhang, Yuze Zhao</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.10210">https://arxiv.org/abs/2410.10210</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.10210">https://arxiv.org/pdf/2410.10210</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.10210]] Minimum Tuning to Unlock Long Output from LLMs with High Quality Data as the Key(https://arxiv.org/abs/2410.10210)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>As large language models rapidly evolve to support longer context, there is a notable disparity in their capability to generate output at greater lengths. Recent study suggests that the primary cause for this imbalance may arise from the lack of data with long-output during alignment training. In light of this observation, attempts are made to re-align foundation models with data that fills the gap, which result in models capable of generating lengthy output when instructed. In this paper, we explore the impact of data-quality in tuning a model for long output, and the possibility of doing so from the starting points of human-aligned (instruct or chat) models. With careful data curation, we show that it possible to achieve similar performance improvement in our tuned models, with only a small fraction of training data instances and compute. In addition, we assess the generalizability of such approaches by applying our tuning-recipes to several models. our findings suggest that, while capacities for generating long output vary across different models out-of-the-box, our approach to tune them with high-quality data using lite compute, consistently yields notable improvement across all models we experimented on. We have made public our curated dataset for tuning long-writing capability, the implementations of model tuning and evaluation, as well as the fine-tuned models, all of which can be openly-accessed.</li>
</ul>

<h3>Title: SkillAggregation: Reference-free LLM-Dependent Aggregation</h3>
<ul>
<li><strong>Authors: </strong>Guangzhi Sun, Anmol Kagrecha, Potsawee Manakul, Phil Woodland, Mark Gales</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.10215">https://arxiv.org/abs/2410.10215</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.10215">https://arxiv.org/pdf/2410.10215</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.10215]] SkillAggregation: Reference-free LLM-Dependent Aggregation(https://arxiv.org/abs/2410.10215)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large Language Models (LLMs) are increasingly used to assess NLP tasks due to their ability to generate human-like judgments. Single LLMs were used initially, however, recent work suggests using multiple LLMs as judges yields improved performance. An important step in exploiting multiple judgements is the combination stage, aggregation. Existing methods in NLP either assign equal weight to all LLM judgments or are designed for specific tasks such as hallucination detection. This work focuses on aggregating predictions from multiple systems where no reference labels are available. A new method called SkillAggregation is proposed, which learns to combine estimates from LLM judges without needing additional data or ground truth. It extends the Crowdlayer aggregation method, developed for image classification, to exploit the judge estimates during inference. The approach is compared to a range of standard aggregation methods on HaluEval-Dialogue, TruthfulQA and Chatbot Arena tasks. SkillAggregation outperforms Crowdlayer on all tasks, and yields the best performance over all approaches on the majority of tasks.</li>
</ul>

<h3>Title: Detecting Unforeseen Data Properties with Diffusion Autoencoder Embeddings using Spine MRI data</h3>
<ul>
<li><strong>Authors: </strong>Robert Graf, Florian Hunecke, Soeren Pohl, Matan Atad, Hendrik Moeller, Sophie Starck, Thomas Kroencke, Stefanie Bette, Fabian Bamberg, Tobias Pischon, Thoralf Niendorf, Carsten Schmidt, Johannes C. Paetzold, Daniel Rueckert, Jan S Kirschke</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.10220">https://arxiv.org/abs/2410.10220</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.10220">https://arxiv.org/pdf/2410.10220</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.10220]] Detecting Unforeseen Data Properties with Diffusion Autoencoder Embeddings using Spine MRI data(https://arxiv.org/abs/2410.10220)</code><input type="text"></li>
<li><strong>Keywords: </strong>protect, fair, diffusion, generative</a></li>
<li><strong>Abstract: </strong>Deep learning has made significant strides in medical imaging, leveraging the use of large datasets to improve diagnostics and prognostics. However, large datasets often come with inherent errors through subject selection and acquisition. In this paper, we investigate the use of Diffusion Autoencoder (DAE) embeddings for uncovering and understanding data characteristics and biases, including biases for protected variables like sex and data abnormalities indicative of unwanted protocol variations. We use sagittal T2-weighted magnetic resonance (MR) images of the neck, chest, and lumbar region from 11186 German National Cohort (NAKO) participants. We compare DAE embeddings with existing generative models like StyleGAN and Variational Autoencoder. Evaluations on a large-scale dataset consisting of sagittal T2-weighted MR images of three spine regions show that DAE embeddings effectively separate protected variables such as sex and age. Furthermore, we used t-SNE visualization to identify unwanted variations in imaging protocols, revealing differences in head positioning. Our embedding can identify samples where a sex predictor will have issues learning the correct sex. Our findings highlight the potential of using advanced embedding techniques like DAEs to detect data quality issues and biases in medical imaging datasets. Identifying such hidden relations can enhance the reliability and fairness of deep learning models in healthcare applications, ultimately improving patient care and outcomes.</li>
</ul>

<h3>Title: KNN Transformer with Pyramid Prompts for Few-Shot Learning</h3>
<ul>
<li><strong>Authors: </strong>Wenhao Li, Qiangchang Wang, Peng Zhao, Yilong Yin</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.10227">https://arxiv.org/abs/2410.10227</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.10227">https://arxiv.org/pdf/2410.10227</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.10227]] KNN Transformer with Pyramid Prompts for Few-Shot Learning(https://arxiv.org/abs/2410.10227)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, transformer</a></li>
<li><strong>Abstract: </strong>Few-Shot Learning (FSL) aims to recognize new classes with limited labeled data. Recent studies have attempted to address the challenge of rare samples with textual prompts to modulate visual features. However, they usually struggle to capture complex semantic relationships between textual and visual features. Moreover, vanilla self-attention is heavily affected by useless information in images, severely constraining the potential of semantic priors in FSL due to the confusion of numerous irrelevant tokens during interaction. To address these aforementioned issues, a K-NN Transformer with Pyramid Prompts (KTPP) is proposed to select discriminative information with K-NN Context Attention (KCA) and adaptively modulate visual features with Pyramid Cross-modal Prompts (PCP). First, for each token, the KCA only selects the K most relevant tokens to compute the self-attention matrix and incorporates the mean of all tokens as the context prompt to provide the global context in three cascaded stages. As a result, irrelevant tokens can be progressively suppressed. Secondly, pyramid prompts are introduced in the PCP to emphasize visual features via interactions between text-based class-aware prompts and multi-scale visual features. This allows the ViT to dynamically adjust the importance weights of visual features based on rich semantic information at different scales, making models robust to spatial variations. Finally, augmented visual features and class-aware prompts are interacted via the KCA to extract class-specific features. Consequently, our model further enhances noise-free visual representations via deep cross-modal interactions, extracting generalized visual representation in scenarios with few labeled samples. Extensive experiments on four benchmark datasets demonstrate the effectiveness of our method.</li>
</ul>

<h3>Title: ForgeryGPT: Multimodal Large Language Model For Explainable Image Forgery Detection and Localization</h3>
<ul>
<li><strong>Authors: </strong>Jiawei Li, Fanrui Zhang, Jiaying Zhu, Esther Sun, Qiang Zhang, Zheng-Jun Zha</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.10238">https://arxiv.org/abs/2410.10238</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.10238">https://arxiv.org/pdf/2410.10238</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.10238]] ForgeryGPT: Multimodal Large Language Model For Explainable Image Forgery Detection and Localization(https://arxiv.org/abs/2410.10238)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Multimodal Large Language Models (MLLMs), such as GPT4o, have shown strong capabilities in visual reasoning and explanation generation. However, despite these strengths, they face significant challenges in the increasingly critical task of Image Forgery Detection and Localization (IFDL). Moreover, existing IFDL methods are typically limited to the learning of low-level semantic-agnostic clues and merely provide a single outcome judgment. To tackle these issues, we propose ForgeryGPT, a novel framework that advances the IFDL task by capturing high-order forensics knowledge correlations of forged images from diverse linguistic feature spaces, while enabling explainable generation and interactive dialogue through a newly customized Large Language Model (LLM) architecture. Specifically, ForgeryGPT enhances traditional LLMs by integrating the Mask-Aware Forgery Extractor, which enables the excavating of precise forgery mask information from input images and facilitating pixel-level understanding of tampering artifacts. The Mask-Aware Forgery Extractor consists of a Forgery Localization Expert (FL-Expert) and a Mask Encoder, where the FL-Expert is augmented with an Object-agnostic Forgery Prompt and a Vocabulary-enhanced Vision Encoder, allowing for effectively capturing of multi-scale fine-grained forgery details. To enhance its performance, we implement a three-stage training strategy, supported by our designed Mask-Text Alignment and IFDL Task-Specific Instruction Tuning datasets, which align vision-language modalities and improve forgery detection and instruction-following capabilities. Extensive experiments demonstrate the effectiveness of the proposed method.</li>
</ul>

<h3>Title: Capture Artifacts via Progressive Disentangling and Purifying Blended Identities for Deepfake Detection</h3>
<ul>
<li><strong>Authors: </strong>Weijie Zhou, Xiaoqing Luo, Zhancheng Zhang, Jiachen He, Xiaojun Wu</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.10244">https://arxiv.org/abs/2410.10244</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.10244">https://arxiv.org/pdf/2410.10244</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.10244]] Capture Artifacts via Progressive Disentangling and Purifying Blended Identities for Deepfake Detection(https://arxiv.org/abs/2410.10244)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy</a></li>
<li><strong>Abstract: </strong>The Deepfake technology has raised serious concerns regarding privacy breaches and trust issues. To tackle these challenges, Deepfake detection technology has emerged. Current methods over-rely on the global feature space, which contains redundant information independent of the artifacts. As a result, existing Deepfake detection techniques suffer performance degradation when encountering unknown datasets. To reduce information redundancy, the current methods use disentanglement techniques to roughly separate the fake faces into artifacts and content information. However, these methods lack a solid disentanglement foundation and cannot guarantee the reliability of their disentangling process. To address these issues, a Deepfake detection method based on progressive disentangling and purifying blended identities is innovatively proposed in this paper. Based on the artifact generation mechanism, the coarse- and fine-grained strategies are combined to ensure the reliability of the disentanglement method. Our method aims to more accurately capture and separate artifact features in fake faces. Specifically, we first perform the coarse-grained disentangling on fake faces to obtain a pair of blended identities that require no additional annotation to distinguish between source face and target face. Then, the artifact features from each identity are separated to achieve fine-grained disentanglement. To obtain pure identity information and artifacts, an Identity-Artifact Correlation Compression module (IACC) is designed based on the information bottleneck theory, effectively reducing the potential correlation between identity information and artifacts. Additionally, an Identity-Artifact Separation Contrast Loss is designed to enhance the independence of artifact features post-disentangling. Finally, the classifier only focuses on pure artifact features to achieve a generalized Deepfake detector.</li>
</ul>

<h3>Title: Yuan: Research on the Concept of Digital World Analogue Scientific Infrastructure and Science Popularization Communication Based on Suzhou Gardens Pattern</h3>
<ul>
<li><strong>Authors: </strong>Zhang Lvyang, Lu Wen, Zhao Yang, Li Jiaqi, Zhai Lidong</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.10248">https://arxiv.org/abs/2410.10248</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.10248">https://arxiv.org/pdf/2410.10248</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.10248]] Yuan: Research on the Concept of Digital World Analogue Scientific Infrastructure and Science Popularization Communication Based on Suzhou Gardens Pattern(https://arxiv.org/abs/2410.10248)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, large language model</a></li>
<li><strong>Abstract: </strong>In the current digital era, high security relies significantly on advanced concepts such as native security. However, the design and implementation of these concepts face challenges in enterprises and organizations. Leveraging advancements in Large Language Models (LLMs), we draw inspiration from the design principles of Suzhou Gardens, a UNESCO World Heritage site. By examining its core features, which align closely with those of the AI world simulator Sora, we extract three concurrent concepts to enhance the security of future digital this http URL propose three guiding principles to facilitate the preliminary construction of the "Space Spider," a hyper-large scientific infrastructure. These principles will steer the development of the "Yuan" digital garden, establishing a "Chinese Series" focused on the construction pathways of the Yuan AI world simulator. The initial pilot of Yuan is expected to generalize various hyper-large scientific infrastructure scenarios, ultimately expanding into numerous high-security digital this http URL the design concept of Suzhou Gardens, we aim to promote science communication and talent training in the field of cybersecurity. With the support of Yuan, we intend to extend our efforts to various digital construction domains. This initiative is poised to contribute significantly to the future of digital world simulators, emphasizing the integration of hyper-large scientific infrastructure with science communication and research dissemination.</li>
</ul>

<h3>Title: Automated extraction of 4D aircraft trajectories from video recordings</h3>
<ul>
<li><strong>Authors: </strong>Jean-FranÃ§ois Villeforceix (BEA, IGN, ENSG)</a></li>
<li><strong>Subjects: </strong>cs.CV, eess.IV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.10249">https://arxiv.org/abs/2410.10249</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.10249">https://arxiv.org/pdf/2410.10249</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.10249]] Automated extraction of 4D aircraft trajectories from video recordings(https://arxiv.org/abs/2410.10249)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction</a></li>
<li><strong>Abstract: </strong>The Bureau d'Enqu{Ãª}tes et d'Analyses pour la S{Ã©}curit{Ã©} de l'Aviation Civile (BEA) has to analyze accident videos from on-board or ground cameras involving all types of aircraft. Until now, this analysis has been manual and time-consuming. The aim of this study is to identify the applications of photogrammetry and to automate the extraction of 4D trajectories from these videos. Taking into account all potential flight configurations, photogrammetric algorithms are being developed on the basis of IGN's MicMac software and tested in the field. The results of these automated processes are intended to replace flight data from recorders such as FDRs or CVRs, which are sometimes missing. The information of interest to the BEA includes: three-dimensional position with the associated time component, the orientations of the aircraft's three axes (pitch, roll and yaw navigation angles) and average speeds (including rate of climb).</li>
</ul>

<h3>Title: Feedback Favors the Generalization of Neural ODEs</h3>
<ul>
<li><strong>Authors: </strong>Jindou Jia, Zihan Yang, Meng Wang, Kexin Guo, Jianfei Yang, Xiang Yu, Lei Guo</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.NE</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.10253">https://arxiv.org/abs/2410.10253</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.10253">https://arxiv.org/pdf/2410.10253</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.10253]] Feedback Favors the Generalization of Neural ODEs(https://arxiv.org/abs/2410.10253)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>The well-known generalization problem hinders the application of artificial neural networks in continuous-time prediction tasks with varying latent dynamics. In sharp contrast, biological systems can neatly adapt to evolving environments benefiting from real-time feedback mechanisms. Inspired by the feedback philosophy, we present feedback neural networks, showing that a feedback loop can flexibly correct the learned latent dynamics of neural ordinary differential equations (neural ODEs), leading to a prominent generalization improvement. The feedback neural network is a novel two-DOF neural network, which possesses robust performance in unseen scenarios with no loss of accuracy performance on previous tasks. A linear feedback form is presented to correct the learned latent dynamics firstly, with a convergence guarantee. Then, domain randomization is utilized to learn a nonlinear neural feedback form. Finally, extensive tests including trajectory prediction of a real irregular object and model predictive control of a quadrotor with various uncertainties, are implemented, indicating significant improvements over state-of-the-art model-based and learning-based methods.</li>
</ul>

<h3>Title: LoLCATs: On Low-Rank Linearizing of Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Michael Zhang, Simran Arora, Rahul Chalamala, Alan Wu, Benjamin Spector, Aaryan Singhal, Krithik Ramesh, Christopher RÃ©</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CL, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.10254">https://arxiv.org/abs/2410.10254</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.10254">https://arxiv.org/pdf/2410.10254</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.10254]] LoLCATs: On Low-Rank Linearizing of Large Language Models(https://arxiv.org/abs/2410.10254)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer, large language model</a></li>
<li><strong>Abstract: </strong>Recent works show we can linearize large language models (LLMs) -- swapping the quadratic attentions of popular Transformer-based LLMs with subquadratic analogs, such as linear attention -- avoiding the expensive pretraining costs. However, linearizing LLMs often significantly degrades model quality, still requires training over billions of tokens, and remains limited to smaller 1.3B to 7B LLMs. We thus propose Low-rank Linear Conversion via Attention Transfer (LoLCATs), a simple two-step method that improves LLM linearizing quality with orders of magnitudes less memory and compute. We base these steps on two findings. First, we can replace an LLM's softmax attentions with closely-approximating linear attentions, simply by training the linear attentions to match their softmax counterparts with an output MSE loss ("attention transfer"). Then, this enables adjusting for approximation errors and recovering LLM quality simply with low-rank adaptation (LoRA). LoLCATs significantly improves linearizing quality, training efficiency, and scalability. We significantly reduce the linearizing quality gap and produce state-of-the-art subquadratic LLMs from Llama 3 8B and Mistral 7B v0.1, leading to 20+ points of improvement on 5-shot MMLU. Furthermore, LoLCATs does so with only 0.2% of past methods' model parameters and 0.4% of their training tokens. Finally, we apply LoLCATs to create the first linearized 70B and 405B LLMs (50x larger than prior work). When compared with prior approaches under the same compute budgets, LoLCATs significantly improves linearizing quality, closing the gap between linearized and original Llama 3.1 70B and 405B LLMs by 77.8% and 78.1% on 5-shot MMLU.</li>
</ul>

<h3>Title: Saliency Guided Optimization of Diffusion Latents</h3>
<ul>
<li><strong>Authors: </strong>Xiwen Wang, Jizhe Zhou, Xuekang Zhu, Cheng Li, Mao Li</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.10257">https://arxiv.org/abs/2410.10257</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.10257">https://arxiv.org/pdf/2410.10257</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.10257]] Saliency Guided Optimization of Diffusion Latents(https://arxiv.org/abs/2410.10257)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>With the rapid advances in diffusion models, generating decent images from text prompts is no longer challenging. The key to text-to-image generation is how to optimize the results of a text-to-image generation model so that they can be better aligned with human intentions or prompts. Existing optimization methods commonly treat the entire image uniformly and conduct global optimization. These methods overlook the fact that when viewing an image, the human visual system naturally prioritizes attention toward salient areas, often neglecting less or non-salient regions. That is, humans are likely to neglect optimizations in non-salient areas. Consequently, although model retaining is conducted under the guidance of additional large and multimodality models, existing methods, which perform uniform optimizations, yield sub-optimal results. To address this alignment challenge effectively and efficiently, we propose Saliency Guided Optimization Of Diffusion Latents (SGOOL). We first employ a saliency detector to mimic the human visual attention system and mark out the salient regions. To avoid retraining an additional model, our method directly optimizes the diffusion latents. Besides, SGOOL utilizes an invertible diffusion process and endows it with the merits of constant memory implementation. Hence, our method becomes a parameter-efficient and plug-and-play fine-tuning method. Extensive experiments have been done with several metrics and human evaluation. Experimental results demonstrate the superiority of SGOOL in image quality and prompt alignment.</li>
</ul>

<h3>Title: Slide-based Graph Collaborative Training for Histopathology Whole Slide Image Analysis</h3>
<ul>
<li><strong>Authors: </strong>Jun Shi, Tong Shu, Zhiguo Jiang, Wei Wang, Haibo Wu, Yushan Zheng</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.10260">https://arxiv.org/abs/2410.10260</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.10260">https://arxiv.org/pdf/2410.10260</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.10260]] Slide-based Graph Collaborative Training for Histopathology Whole Slide Image Analysis(https://arxiv.org/abs/2410.10260)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>The development of computational pathology lies in the consensus that pathological characteristics of tumors are significant guidance for cancer diagnostics. Most existing research focuses on the inner-contextual information within each WSI yet ignores the possible inter-correlations between slides. As the development of tumors is a continuous process involving a series of histological, morphological, and genetic changes that accumulate over time, the similarities and differences between WSIs across various stages, grades, locations and patients should potentially contribute to the representation of WSIs and deserve to be taken into account in WSI modeling. To verify the advancement of introducing the slide inter-correlations into the representation learning of WSIs, we proposed a generic WSI analysis pipeline SlideGCD that can be adapted to any existing Multiple Instance Learning (MIL) frameworks and improve their performance. With the new paradigm, the prior knowledge of cancer development can participate in the end-to-end workflow, which concurrently initializes and refines the slide representation, as a guide for message passing in the slide-based graph. Extensive comparisons and experiments are conducted to validate the effectiveness and robustness of the proposed pipeline across 4 different tasks, including cancer subtyping, cancer staging, survival prediction, and gene mutation prediction, with 7 representative SOTA WSI analysis frameworks as backbones.</li>
</ul>

<h3>Title: big.LITTLE Vision Transformer for Efficient Visual Recognition</h3>
<ul>
<li><strong>Authors: </strong>He Guo, Yulong Wang, Zixuan Ye, Jifeng Dai, Yuwen Xiong</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.10267">https://arxiv.org/abs/2410.10267</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.10267">https://arxiv.org/pdf/2410.10267</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.10267]] big.LITTLE Vision Transformer for Efficient Visual Recognition(https://arxiv.org/abs/2410.10267)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>In this paper, we introduce the this http URL Vision Transformer, an innovative architecture aimed at achieving efficient visual recognition. This dual-transformer system is composed of two distinct blocks: the big performance block, characterized by its high capacity and substantial computational demands, and the LITTLE efficiency block, designed for speed with lower capacity. The key innovation of our approach lies in its dynamic inference mechanism. When processing an image, our system determines the importance of each token and allocates them accordingly: essential tokens are processed by the high-performance big model, while less critical tokens are handled by the more efficient little model. This selective processing significantly reduces computational load without sacrificing the overall performance of the model, as it ensures that detailed analysis is reserved for the most important information. To validate the effectiveness of our this http URL Vision Transformer, we conducted comprehensive experiments on image classification and segment anything task. Our results demonstrate that the this http URL architecture not only maintains high accuracy but also achieves substantial computational savings. Specifically, our approach enables the efficient handling of large-scale visual recognition tasks by dynamically balancing the trade-offs between performance and efficiency. The success of our method underscores the potential of hybrid models in optimizing both computation and performance in visual recognition tasks, paving the way for more practical and scalable deployment of advanced neural networks in real-world applications.</li>
</ul>

<h3>Title: Machine Translation Evaluation Benchmark for Wu Chinese: Workflow and Analysis</h3>
<ul>
<li><strong>Authors: </strong>Hongjian Yu, Yiming Shi, Zherui Zhou, Christopher Haberland</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.10278">https://arxiv.org/abs/2410.10278</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.10278">https://arxiv.org/pdf/2410.10278</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.10278]] Machine Translation Evaluation Benchmark for Wu Chinese: Workflow and Analysis(https://arxiv.org/abs/2410.10278)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>We introduce a FLORES+ dataset as an evaluation benchmark for modern Wu Chinese machine translation models and showcase its compatibility with existing Wu data. Wu Chinese is mutually unintelligible with other Sinitic languages such as Mandarin and Yue (Cantonese), but uses a set of Hanzi (Chinese characters) that profoundly overlaps with others. The population of Wu speakers is the second largest among languages in China, but the language has been suffering from significant drop in usage especially among the younger generations. We identify Wu Chinese as a textually low-resource language and address challenges for its machine translation models. Our contributions include: (1) an open-source, manually translated dataset, (2) full documentations on the process of dataset creation and validation experiments, (3) preliminary tools for Wu Chinese normalization and segmentation, and (4) benefits and limitations of our dataset, as well as implications to other low-resource languages.</li>
</ul>

<h3>Title: ABBA-VSM: Time Series Classification using Symbolic Representation on the Edge</h3>
<ul>
<li><strong>Authors: </strong>Meerzhan Kanatbekova, Shashikant Ilager, Ivona Brandic</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.10285">https://arxiv.org/abs/2410.10285</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.10285">https://arxiv.org/pdf/2410.10285</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.10285]] ABBA-VSM: Time Series Classification using Symbolic Representation on the Edge(https://arxiv.org/abs/2410.10285)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy</a></li>
<li><strong>Abstract: </strong>In recent years, Edge AI has become more prevalent with applications across various industries, from environmental monitoring to smart city management. Edge AI facilitates the processing of Internet of Things (IoT) data and provides privacy-enabled and latency-sensitive services to application users using Machine Learning (ML) algorithms, e.g., Time Series Classification (TSC). However, existing TSC algorithms require access to full raw data and demand substantial computing resources to train and use them effectively in runtime. This makes them impractical for deployment in resource-constrained Edge environments. To address this, in this paper, we propose an Adaptive Brownian Bridge-based Symbolic Aggregation Vector Space Model (ABBA-VSM). It is a new TSC model designed for classification services on Edge. Here, we first adaptively compress the raw time series into symbolic representations, thus capturing the changing trends of data. Subsequently, we train the classification model directly on these symbols. ABBA-VSM reduces communication data between IoT and Edge devices, as well as computation cycles, in the development of resource-efficient TSC services on Edge. We evaluate our solution with extensive experiments using datasets from the UCR time series classification archive. The results demonstrate that the ABBA-VSM achieves up to 80% compression ratio and 90-100% accuracy for binary classification. Whereas, for non-binary classification, it achieves an average compression ratio of 60% and accuracy ranging from 60-80%.</li>
</ul>

<h3>Title: Back-of-the-Book Index Automation for Arabic Documents</h3>
<ul>
<li><strong>Authors: </strong>Nawal Haidar, Fadi A. Zaraket</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.IR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.10286">https://arxiv.org/abs/2410.10286</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.10286">https://arxiv.org/pdf/2410.10286</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.10286]] Back-of-the-Book Index Automation for Arabic Documents(https://arxiv.org/abs/2410.10286)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction</a></li>
<li><strong>Abstract: </strong>Back-of-the-book indexes are crucial for book readability. Their manual creation is laborious and error prone. In this paper, we consider automating back-of-the-book index extraction for Arabic books to help simplify both the creation and review tasks. Given a back-of-the-book index, we aim to check and identify the accurate occurrences of index terms relative to the associated pages. To achieve this, we first define a pool of candidates for each term by extracting all possible noun phrases from paragraphs appearing on the relevant index pages. These noun phrases, identified through part-of-speech analysis, are stored in a vector database for efficient retrieval. We use several metrics, including exact matches, lexical similarity, and semantic similarity, to determine the most appropriate occurrence. The candidate with the highest score based on these metrics is chosen as the occurrence of the term. We fine-tuned a heuristic method, that considers the above metrics and that achieves an F1-score of .966 (precision=.966, recall=.966). These excellent results open the door for future work related to automation of back-of-the-book index generation and checking.</li>
</ul>

<h3>Title: Manifold-Aware Local Feature Modeling for Semi-Supervised Medical Image Segmentation</h3>
<ul>
<li><strong>Authors: </strong>Sicheng Shen, Jinming Cao, Yifang Yin, Roger Zimmermann</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.10287">https://arxiv.org/abs/2410.10287</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.10287">https://arxiv.org/pdf/2410.10287</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.10287]] Manifold-Aware Local Feature Modeling for Semi-Supervised Medical Image Segmentation(https://arxiv.org/abs/2410.10287)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, segmentation</a></li>
<li><strong>Abstract: </strong>Achieving precise medical image segmentation is vital for effective treatment planning and accurate disease diagnosis. Traditional fully-supervised deep learning methods, though highly precise, are heavily reliant on large volumes of labeled data, which are often difficult to obtain due to the expertise required for medical annotations. This has led to the rise of semi-supervised learning approaches that utilize both labeled and unlabeled data to mitigate the label scarcity issue. In this paper, we introduce the Manifold-Aware Local Feature Modeling Network (MANet), which enhances the U-Net architecture by incorporating manifold supervision signals. This approach focuses on improving boundary accuracy, which is crucial for reliable medical diagnosis. To further extend the versatility of our method, we propose two variants: MA-Sobel and MA-Canny. The MA-Sobel variant employs the Sobel operator, which is effective for both 2D and 3D data, while the MA-Canny variant utilizes the Canny operator, specifically designed for 2D images, to refine boundary detection. These variants allow our method to adapt to various medical image modalities and dimensionalities, ensuring broader applicability. Our extensive experiments on datasets such as ACDC, LA, and Pancreas-NIH demonstrate that MANet consistently surpasses state-of-the-art methods in performance metrics like Dice and Jaccard scores. The proposed method also shows improved generalization across various semi-supervised segmentation networks, highlighting its robustness and effectiveness. Visual analysis of segmentation results confirms that MANet offers clearer and more accurate class boundaries, underscoring the value of manifold information in medical image segmentation.</li>
</ul>

<h3>Title: A Multi-Task Text Classification Pipeline with Natural Language Explanations: A User-Centric Evaluation in Sentiment Analysis and Offensive Language Identification in Greek Tweets</h3>
<ul>
<li><strong>Authors: </strong>Nikolaos Mylonas, Nikolaos Stylianou, Theodora Tsikrika, Stefanos Vrochidis, Ioannis Kompatsiaris</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.10290">https://arxiv.org/abs/2410.10290</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.10290">https://arxiv.org/pdf/2410.10290</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.10290]] A Multi-Task Text Classification Pipeline with Natural Language Explanations: A User-Centric Evaluation in Sentiment Analysis and Offensive Language Identification in Greek Tweets(https://arxiv.org/abs/2410.10290)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability, large language model</a></li>
<li><strong>Abstract: </strong>Interpretability is a topic that has been in the spotlight for the past few years. Most existing interpretability techniques produce interpretations in the form of rules or feature importance. These interpretations, while informative, may be harder to understand for non-expert users and therefore, cannot always be considered as adequate explanations. To that end, explanations in natural language are often preferred, as they are easier to comprehend and also more presentable to end-users. This work introduces an early concept for a novel pipeline that can be used in text classification tasks, offering predictions and explanations in natural language. It comprises of two models: a classifier for labelling the text and an explanation generator which provides the explanation. The proposed pipeline can be adopted by any text classification task, given that ground truth rationales are available to train the explanation generator. Our experiments are centred around the tasks of sentiment analysis and offensive language identification in Greek tweets, using a Greek Large Language Model (LLM) to obtain the necessary explanations that can act as rationales. The experimental evaluation was performed through a user study based on three different metrics and achieved promising results for both datasets.</li>
</ul>

<h3>Title: Evaluating Semantic Variation in Text-to-Image Synthesis: A Causal Perspective</h3>
<ul>
<li><strong>Authors: </strong>Xiangru Zhu, Penglei Sun, Yaoxian Song, Yanghua Xiao, Zhixu Li, Chengyu Wang, Jun Huang, Bei Yang, Xiaoxiao Xu</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.MM</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.10291">https://arxiv.org/abs/2410.10291</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.10291">https://arxiv.org/pdf/2410.10291</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.10291]] Evaluating Semantic Variation in Text-to-Image Synthesis: A Causal Perspective(https://arxiv.org/abs/2410.10291)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Accurate interpretation and visualization of human instructions are crucial for text-to-image (T2I) synthesis. However, current models struggle to capture semantic variations from word order changes, and existing evaluations, relying on indirect metrics like text-image similarity, fail to reliably assess these challenges. This often obscures poor performance on complex or uncommon linguistic patterns by the focus on frequent word combinations. To address these deficiencies, we propose a novel metric called SemVarEffect and a benchmark named SemVarBench, designed to evaluate the causality between semantic variations in inputs and outputs in T2I synthesis. Semantic variations are achieved through two types of linguistic permutations, while avoiding easily predictable literal variations. Experiments reveal that the CogView-3-Plus and Ideogram 2 performed the best, achieving a score of 0.2/1. Semantic variations in object relations are less understood than attributes, scoring 0.07/1 compared to 0.17-0.19/1. We found that cross-modal alignment in UNet or Transformers plays a crucial role in handling semantic variations, a factor previously overlooked by a focus on textual encoders. Our work establishes an effective evaluation framework that advances the T2I synthesis community's exploration of human instruction understanding.</li>
</ul>

<h3>Title: A Consistency-Aware Spot-Guided Transformer for Versatile and Hierarchical Point Cloud Registration</h3>
<ul>
<li><strong>Authors: </strong>Renlang Huang, Yufan Tang, Jiming Chen, Liang Li</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.10295">https://arxiv.org/abs/2410.10295</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.10295">https://arxiv.org/pdf/2410.10295</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.10295]] A Consistency-Aware Spot-Guided Transformer for Versatile and Hierarchical Point Cloud Registration(https://arxiv.org/abs/2410.10295)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, transformer</a></li>
<li><strong>Abstract: </strong>Deep learning-based feature matching has shown great superiority for point cloud registration in the absence of pose priors. Although coarse-to-fine matching approaches are prevalent, the coarse matching of existing methods is typically sparse and loose without consideration of geometric consistency, which makes the subsequent fine matching rely on ineffective optimal transport and hypothesis-and-selection methods for consistency. Therefore, these methods are neither efficient nor scalable for real-time applications such as odometry in robotics. To address these issues, we design a consistency-aware spot-guided Transformer (CAST), which incorporates a spot-guided cross-attention module to avoid interfering with irrelevant areas, and a consistency-aware self-attention module to enhance matching capabilities with geometrically consistent correspondences. Furthermore, a lightweight fine matching module for both sparse keypoints and dense features can estimate the transformation accurately. Extensive experiments on both outdoor LiDAR point cloud datasets and indoor RGBD point cloud datasets demonstrate that our method achieves state-of-the-art accuracy, efficiency, and robustness.</li>
</ul>

<h3>Title: A Comparative Study of Translation Bias and Accuracy in Multilingual Large Language Models for Cross-Language Claim Verification</h3>
<ul>
<li><strong>Authors: </strong>Aryan Singhal, Veronica Shao, Gary Sun, Ryan Ding, Jonathan Lu, Kevin Zhu</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.10303">https://arxiv.org/abs/2410.10303</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.10303">https://arxiv.org/pdf/2410.10303</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.10303]] A Comparative Study of Translation Bias and Accuracy in Multilingual Large Language Models for Cross-Language Claim Verification(https://arxiv.org/abs/2410.10303)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>The rise of digital misinformation has heightened interest in using multilingual Large Language Models (LLMs) for fact-checking. This study systematically evaluates translation bias and the effectiveness of LLMs for cross-lingual claim verification across 15 languages from five language families: Romance, Slavic, Turkic, Indo-Aryan, and Kartvelian. Using the XFACT dataset to assess their impact on accuracy and bias, we investigate two distinct translation methods: pre-translation and self-translation. We use mBERT's performance on the English dataset as a baseline to compare language-specific accuracies. Our findings reveal that low-resource languages exhibit significantly lower accuracy in direct inference due to underrepresentation in the training data. Furthermore, larger models demonstrate superior performance in self-translation, improving translation accuracy and reducing bias. These results highlight the need for balanced multilingual training, especially in low-resource languages, to promote equitable access to reliable fact-checking tools and minimize the risk of spreading misinformation in different linguistic contexts.</li>
</ul>

<h3>Title: GlobalMamba: Global Image Serialization for Vision Mamba</h3>
<ul>
<li><strong>Authors: </strong>Chengkun Wang, Wenzhao Zheng, Jie Zhou, Jiwen Lu</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.10316">https://arxiv.org/abs/2410.10316</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.10316">https://arxiv.org/pdf/2410.10316</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.10316]] GlobalMamba: Global Image Serialization for Vision Mamba(https://arxiv.org/abs/2410.10316)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>Vision mambas have demonstrated strong performance with linear complexity to the number of vision tokens. Their efficiency results from processing image tokens sequentially. However, most existing methods employ patch-based image tokenization and then flatten them into 1D sequences for causal processing, which ignore the intrinsic 2D structural correlations of images. It is also difficult to extract global information by sequential processing of local patches. In this paper, we propose a global image serialization method to transform the image into a sequence of causal tokens, which contain global information of the 2D image. We first convert the image from the spatial domain to the frequency domain using Discrete Cosine Transform (DCT) and then arrange the pixels with corresponding frequency ranges. We further transform each set within the same frequency band back to the spatial domain to obtain a series of images before tokenization. We construct a vision mamba model, GlobalMamba, with a causal input format based on the proposed global image serialization, which can better exploit the causal relations among image sequences. Extensive experiments demonstrate the effectiveness of our GlobalMamba, including image classification on ImageNet-1K, object detection on COCO, and semantic segmentation on ADE20K.</li>
</ul>

<h3>Title: Feature Averaging: An Implicit Bias of Gradient Descent Leading to Non-Robustness in Neural Networks</h3>
<ul>
<li><strong>Authors: </strong>Binghui Li, Zhixuan Pan, Kaifeng Lyu, Jian Li</a></li>
<li><strong>Subjects: </strong>cs.LG, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.10322">https://arxiv.org/abs/2410.10322</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.10322">https://arxiv.org/pdf/2410.10322</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.10322]] Feature Averaging: An Implicit Bias of Gradient Descent Leading to Non-Robustness in Neural Networks(https://arxiv.org/abs/2410.10322)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack, robust</a></li>
<li><strong>Abstract: </strong>In this work, we investigate a particular implicit bias in the gradient descent training process, which we term "Feature Averaging", and argue that it is one of the principal factors contributing to non-robustness of deep neural networks. Despite the existence of multiple discriminative features capable of classifying data, neural networks trained by gradient descent exhibit a tendency to learn the average (or certain combination) of these features, rather than distinguishing and leveraging each feature individually. In particular, we provide a detailed theoretical analysis of the training dynamics of gradient descent in a two-layer ReLU network for a binary classification task, where the data distribution consists of multiple clusters with orthogonal cluster center vectors. We rigorously prove that gradient descent converges to the regime of feature averaging, wherein the weights associated with each hidden-layer neuron represent an average of the cluster centers (each center corresponding to a distinct feature). It leads the network classifier to be non-robust due to an attack that aligns with the negative direction of the averaged features. Furthermore, we prove that, with the provision of more granular supervised information, a two-layer multi-class neural network is capable of learning individual features, from which one can derive a binary classifier with the optimal robustness under our setting. Besides, we also conduct extensive experiments using synthetic datasets, MNIST and CIFAR-10 to substantiate the phenomenon of feature averaging and its role in adversarial robustness of neural networks. We hope the theoretical and empirical insights can provide a deeper understanding of the impact of the gradient descent training on feature learning process, which in turn influences the robustness of the network, and how more detailed supervision may enhance model robustness.</li>
</ul>

<h3>Title: MentalGLM Series: Explainable Large Language Models for Mental Health Analysis on Chinese Social Media</h3>
<ul>
<li><strong>Authors: </strong>Wei Zhai, Nan Bai, Qing Zhao, Jianqiang Li, Fan Wang, Hongzhi Qi, Meng Jiang, Xiaoqin Wang, Bing Xiang Yang, Guanghui Fu</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.10323">https://arxiv.org/abs/2410.10323</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.10323">https://arxiv.org/pdf/2410.10323</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.10323]] MentalGLM Series: Explainable Large Language Models for Mental Health Analysis on Chinese Social Media(https://arxiv.org/abs/2410.10323)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative, large language model</a></li>
<li><strong>Abstract: </strong>As the prevalence of mental health challenges, social media has emerged as a key platform for individuals to express their this http URL learning tends to be a promising solution for analyzing mental health on social media. However, black box models are often inflexible when switching between tasks, and their results typically lack explanations. With the rise of large language models (LLMs), their flexibility has introduced new approaches to the field. Also due to the generative nature, they can be prompted to explain decision-making processes. However, their performance on complex psychological analysis still lags behind deep learning. In this paper, we introduce the first multi-task Chinese Social Media Interpretable Mental Health Instructions (C-IMHI) dataset, consisting of 9K samples, which has been quality-controlled and manually validated. We also propose MentalGLM series models, the first open-source LLMs designed for explainable mental health analysis targeting Chinese social media, trained on a corpus of 50K instructions. The proposed models were evaluated on three downstream tasks and achieved better or comparable performance compared to deep learning models, generalized LLMs, and task fine-tuned LLMs. We validated a portion of the generated decision explanations with experts, showing promising results. We also evaluated the proposed models on a clinical dataset, where they outperformed other LLMs, indicating their potential applicability in the clinical field. Our models show strong performance, validated across tasks and perspectives. The decision explanations enhance usability and facilitate better understanding and practical application of the models. Both the constructed dataset and the models are publicly available via: this https URL.</li>
</ul>

<h3>Title: GraphCLIP: Enhancing Transferability in Graph Foundation Models for Text-Attributed Graphs</h3>
<ul>
<li><strong>Authors: </strong>Yun Zhu, Haizhou Shi, Xiaotang Wang, Yongchao Liu, Yaoke Wang, Boci Peng, Chuntao Hong, Siliang Tang</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.10329">https://arxiv.org/abs/2410.10329</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.10329">https://arxiv.org/pdf/2410.10329</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.10329]] GraphCLIP: Enhancing Transferability in Graph Foundation Models for Text-Attributed Graphs(https://arxiv.org/abs/2410.10329)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Recently, research on Text-Attributed Graphs (TAGs) has gained significant attention due to the prevalence of free-text node features in real-world applications and the advancements in Large Language Models (LLMs) that bolster TAG methodologies. However, current TAG approaches face two primary challenges: (i) Heavy reliance on label information and (ii) Limited cross-domain zero/few-shot transferability. These issues constrain the scaling of both data and model size, owing to high labor costs and scaling laws, complicating the development of graph foundation models with strong transferability. In this work, we propose the GraphCLIP framework to address these challenges by learning graph foundation models with strong cross-domain zero/few-shot transferability through a self-supervised contrastive graph-summary pretraining method. Specifically, we generate and curate large-scale graph-summary pair data with the assistance of LLMs, and introduce a novel graph-summary pretraining method, combined with invariant learning, to enhance graph foundation models with strong cross-domain zero-shot transferability. For few-shot learning, we propose a novel graph prompt tuning technique aligned with our pretraining objective to mitigate catastrophic forgetting and minimize learning costs. Extensive experiments show the superiority of GraphCLIP in both zero-shot and few-shot settings, while evaluations across various downstream tasks confirm the versatility of GraphCLIP. Our code is available at: this https URL</li>
</ul>

<h3>Title: Disentangling Hate Across Target Identities</h3>
<ul>
<li><strong>Authors: </strong>Yiping Jin, Leo Wanner, Aneesh Moideen Koya</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.10332">https://arxiv.org/abs/2410.10332</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.10332">https://arxiv.org/pdf/2410.10332</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.10332]] Disentangling Hate Across Target Identities(https://arxiv.org/abs/2410.10332)</code><input type="text"></li>
<li><strong>Keywords: </strong>protect</a></li>
<li><strong>Abstract: </strong>Hate speech (HS) classifiers do not perform equally well in detecting hateful expressions towards different target identities. They also demonstrate systematic biases in predicted hatefulness scores. Tapping on two recently proposed functionality test datasets for HS detection, we quantitatively analyze the impact of different factors on HS prediction. Experiments on popular industrial and academic models demonstrate that HS detectors assign a higher hatefulness score merely based on the mention of specific target identities. Besides, models often confuse hatefulness and the polarity of emotions. This result is worrisome as the effort to build HS detectors might harm the vulnerable identity groups we wish to protect: posts expressing anger or disapproval of hate expressions might be flagged as hateful themselves. We also carry out a study inspired by social psychology theory, which reveals that the accuracy of hatefulness prediction correlates strongly with the intensity of the stereotype.</li>
</ul>

<h3>Title: Locking Down the Finetuned LLMs Safety</h3>
<ul>
<li><strong>Authors: </strong>Minjun Zhu, Linyi Yang, Yifan Wei, Ningyu Zhang, Yue Zhang</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.10343">https://arxiv.org/abs/2410.10343</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.10343">https://arxiv.org/pdf/2410.10343</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.10343]] Locking Down the Finetuned LLMs Safety(https://arxiv.org/abs/2410.10343)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, large language model</a></li>
<li><strong>Abstract: </strong>Fine-tuning large language models (LLMs) on additional datasets is often necessary to optimize them for specific downstream tasks. However, existing safety alignment measures, which restrict harmful behavior during inference, are insufficient to mitigate safety risks during fine-tuning. Alarmingly, fine-tuning with just 10 toxic sentences can make models comply with harmful instructions. We introduce SafetyLock, a novel alignment intervention method that maintains robust safety post-fine-tuning through efficient and transferable mechanisms. SafetyLock leverages our discovery that fine-tuned models retain similar safety-related activation representations to their base models. This insight enables us to extract what we term the Meta-SafetyLock, a set of safety bias directions representing key activation patterns associated with safe responses in the original model. We can then apply these directions universally to fine-tuned models to enhance their safety. By searching for activation directions across multiple token dimensions, SafetyLock achieves enhanced robustness and transferability. SafetyLock re-aligns fine-tuned models in under 0.01 seconds without additional computational cost. Our experiments demonstrate that SafetyLock can reduce the harmful instruction response rate from 60% to below 1% in toxic fine-tuned models. It surpasses traditional methods in both performance and efficiency, offering a scalable, non-invasive solution for ensuring the safety of customized LLMs. Our analysis across various fine-tuning scenarios confirms SafetyLock's robustness, advocating its integration into safety protocols for aligned LLMs. The code is released at this https URL.</li>
</ul>

<h3>Title: A Unified Approach to Routing and Cascading for LLMs</h3>
<ul>
<li><strong>Authors: </strong>Jasper Dekoninck, Maximilian Baader, Martin Vechev</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.10347">https://arxiv.org/abs/2410.10347</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.10347">https://arxiv.org/pdf/2410.10347</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.10347]] A Unified Approach to Routing and Cascading for LLMs(https://arxiv.org/abs/2410.10347)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>The widespread applicability of large language models (LLMs) has increased the availability of many fine-tuned models of various sizes targeting specific tasks. Given a set of such specialized models, to maximize overall performance, it is important to figure out the optimal strategy for selecting the right model for a given user query. An effective strategy could drastically increase overall performance and even offer improvements over a single large monolithic model. Existing approaches typically fall into two categories: routing, where a single model is selected for each query, and cascading, which runs a sequence of increasingly larger models until a satisfactory answer is obtained. However, both have notable limitations: routing commits to an initial model without flexibility, while cascading requires executing every model in sequence, which can be inefficient. Additionally, the conditions under which these strategies are provably optimal remain unclear. In this work, we derive optimal strategies for both routing and cascading. Building on this analysis, we propose a novel approach called cascade routing, which combines the adaptability of routing with the cost-efficiency of cascading. Our experiments demonstrate that cascade routing consistently outperforms both routing and cascading across a variety of settings, improving both output quality and lowering computational cost, thus offering a unified and efficient solution to the model selection problem.</li>
</ul>

<h3>Title: Augmenting In-Context-Learning in LLMs via Automatic Data Labeling and Refinement</h3>
<ul>
<li><strong>Authors: </strong>Joseph Shtok, Amit Alfassy, Foad Abo Dahood, Eliyahu Schwartz, Sivan Doveh, Assaf Arbelle</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.10348">https://arxiv.org/abs/2410.10348</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.10348">https://arxiv.org/pdf/2410.10348</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.10348]] Augmenting In-Context-Learning in LLMs via Automatic Data Labeling and Refinement(https://arxiv.org/abs/2410.10348)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>It has been shown that Large Language Models' (LLMs) performance can be improved for many tasks using Chain of Thought (CoT) or In-Context Learning (ICL), which involve demonstrating the steps needed to solve a task using a few examples. However, while datasets with input-output pairs are relatively easy to produce, providing demonstrations which include intermediate steps requires cumbersome manual work. These steps may be executable programs, as in agentic flows, or step-by-step reasoning as in CoT. In this work, we propose Automatic Data Labeling and Refinement (ADLR), a method to automatically generate and filter demonstrations which include the above intermediate steps, starting from a small seed of manually crafted examples. We demonstrate the advantage of ADLR in code-based table QA and mathematical reasoning, achieving up to a 5.5% gain. The code implementing our method is provided in the Supplementary material and will be made available.</li>
</ul>

<h3>Title: FasterDiT: Towards Faster Diffusion Transformers Training without Architecture Modification</h3>
<ul>
<li><strong>Authors: </strong>Jingfeng Yao, Wang Cheng, Wenyu Liu, Xinggang Wang</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.10356">https://arxiv.org/abs/2410.10356</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.10356">https://arxiv.org/pdf/2410.10356</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.10356]] FasterDiT: Towards Faster Diffusion Transformers Training without Architecture Modification(https://arxiv.org/abs/2410.10356)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, diffusion, transformer</a></li>
<li><strong>Abstract: </strong>Diffusion Transformers (DiT) have attracted significant attention in research. However, they suffer from a slow convergence rate. In this paper, we aim to accelerate DiT training without any architectural modification. We identify the following issues in the training process: firstly, certain training strategies do not consistently perform well across different data. Secondly, the effectiveness of supervision at specific timesteps is limited. In response, we propose the following contributions: (1) We introduce a new perspective for interpreting the failure of the strategies. Specifically, we slightly extend the definition of Signal-to-Noise Ratio (SNR) and suggest observing the Probability Density Function (PDF) of SNR to understand the essence of the data robustness of the strategy. (2) We conduct numerous experiments and report over one hundred experimental results to empirically summarize a unified accelerating strategy from the perspective of PDF. (3) We develop a new supervision method that further accelerates the training process of DiT. Based on them, we propose FasterDiT, an exceedingly simple and practicable design strategy. With few lines of code modifications, it achieves 2.30 FID on ImageNet 256 resolution at 1000k iterations, which is comparable to DiT (2.27 FID) but 7 times faster in training.</li>
</ul>

<h3>Title: Parenting: Optimizing Knowledge Selection of Retrieval-Augmented Language Models with Parameter Decoupling and Tailored Tuning</h3>
<ul>
<li><strong>Authors: </strong>Yongxin Xu, Ruizhe Zhang, Xinke Jiang, Yujie Feng, Yuzhen Xiao, Xinyu Ma, Runchuan Zhu, Xu Chu, Junfeng Zhao, Yasha Wang</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.IR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.10360">https://arxiv.org/abs/2410.10360</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.10360">https://arxiv.org/pdf/2410.10360</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.10360]] Parenting: Optimizing Knowledge Selection of Retrieval-Augmented Language Models with Parameter Decoupling and Tailored Tuning(https://arxiv.org/abs/2410.10360)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, large language model</a></li>
<li><strong>Abstract: </strong>Retrieval-Augmented Generation (RAG) offers an effective solution to the issues faced by Large Language Models (LLMs) in hallucination generation and knowledge obsolescence by incorporating externally retrieved knowledge. However, due to potential conflicts between internal and external knowledge, as well as retrieval noise, LLMs often struggle to effectively integrate external evidence, leading to a decline in performance. Although existing methods attempt to tackle these challenges, they often struggle to strike a balance between model adherence and robustness, resulting in significant learning variance. Inspired by human cognitive processes, we propose Parenting, a novel framework that decouples adherence and robustness within the parameter space of LLMs. Specifically, Parenting utilizes a key parameter mining method based on forward activation gain to identify and isolate the crucial parameter units that are strongly linked to adherence and robustness. Then, Parenting employs a type-guided tailored tuning strategy, applying specific and appropriate fine-tuning methods to parameter units representing different capabilities, aiming to achieve a balanced enhancement of adherence and robustness. Extensive experiments on various datasets and models validate the effectiveness and generalizability of our methods.</li>
</ul>

<h3>Title: Affinity-Graph-Guided Contractive Learning for Pretext-Free Medical Image Segmentation with Minimal Annotation</h3>
<ul>
<li><strong>Authors: </strong>Zehua Cheng, Di Yuan, Thomas Lukasiewicz</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.10366">https://arxiv.org/abs/2410.10366</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.10366">https://arxiv.org/pdf/2410.10366</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.10366]] Affinity-Graph-Guided Contractive Learning for Pretext-Free Medical Image Segmentation with Minimal Annotation(https://arxiv.org/abs/2410.10366)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, segmentation</a></li>
<li><strong>Abstract: </strong>The combination of semi-supervised learning (SemiSL) and contrastive learning (CL) has been successful in medical image segmentation with limited annotations. However, these works often rely on pretext tasks that lack the specificity required for pixel-level segmentation, and still face overfitting issues due to insufficient supervision signals resulting from too few annotations. Therefore, this paper proposes an affinity-graph-guided semi-supervised contrastive learning framework (Semi-AGCL) by establishing additional affinity-graph-based supervision signals between the student and teacher network, to achieve medical image segmentation with minimal annotations without pretext. The framework first designs an average-patch-entropy-driven inter-patch sampling method, which can provide a robust initial feature space without relying on pretext tasks. Furthermore, the framework designs an affinity-graph-guided loss function, which can improve the quality of the learned representation and the model generalization ability by exploiting the inherent structure of the data, thus mitigating overfitting. Our experiments indicate that with merely 10% of the complete annotation set, our model approaches the accuracy of the fully annotated baseline, manifesting a marginal deviation of only 2.52%. Under the stringent conditions where only 5% of the annotations are employed, our model exhibits a significant enhancement in performance surpassing the second best baseline by 23.09% on the dice metric and achieving an improvement of 26.57% on the notably arduous CRAG and ACDC datasets.</li>
</ul>

<h3>Title: Class Balancing Diversity Multimodal Ensemble for Alzheimer's Disease Diagnosis and Early Detection</h3>
<ul>
<li><strong>Authors: </strong>Arianna Francesconi, Lazzaro di Biase, Donato Cappetta, Fabio Rebecchi, Paolo Soda, Rosa Sicilia, Valerio Guarrasi</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.10374">https://arxiv.org/abs/2410.10374</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.10374">https://arxiv.org/pdf/2410.10374</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.10374]] Class Balancing Diversity Multimodal Ensemble for Alzheimer's Disease Diagnosis and Early Detection(https://arxiv.org/abs/2410.10374)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Alzheimer's disease (AD) poses significant global health challenges due to its increasing prevalence and associated societal costs. Early detection and diagnosis of AD are critical for delaying progression and improving patient outcomes. Traditional diagnostic methods and single-modality data often fall short in identifying early-stage AD and distinguishing it from Mild Cognitive Impairment (MCI). This study addresses these challenges by introducing a novel approach: multImodal enseMble via class BALancing diversity for iMbalancEd Data (IMBALMED). IMBALMED integrates multimodal data from the Alzheimer's Disease Neuroimaging Initiative database, including clinical assessments, neuroimaging phenotypes, biospecimen and subject characteristics data. It employs an ensemble of model classifiers, each trained with different class balancing techniques, to overcome class imbalance and enhance model accuracy. We evaluate IMBALMED on two diagnostic tasks (binary and ternary classification) and four binary early detection tasks (at 12, 24, 36, and 48 months), comparing its performance with state-of-the-art algorithms and an unbalanced dataset method. IMBALMED demonstrates superior diagnostic accuracy and predictive performance in both binary and ternary classification tasks, significantly improving early detection of MCI at 48-month time point. The method shows improved classification performance and robustness, offering a promising solution for early detection and management of AD.</li>
</ul>

<h3>Title: V2M: Visual 2-Dimensional Mamba for Image Representation Learning</h3>
<ul>
<li><strong>Authors: </strong>Chengkun Wang, Wenzhao Zheng, Yuanhui Huang, Jie Zhou, Jiwen Lu</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.10382">https://arxiv.org/abs/2410.10382</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.10382">https://arxiv.org/pdf/2410.10382</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.10382]] V2M: Visual 2-Dimensional Mamba for Image Representation Learning(https://arxiv.org/abs/2410.10382)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>Mamba has garnered widespread attention due to its flexible design and efficient hardware performance to process 1D sequences based on the state space model (SSM). Recent studies have attempted to apply Mamba to the visual domain by flattening 2D images into patches and then regarding them as a 1D sequence. To compensate for the 2D structure information loss (e.g., local similarity) of the original image, most existing methods focus on designing different orders to sequentially process the tokens, which could only alleviate this issue to some extent. In this paper, we propose a Visual 2-Dimensional Mamba (V2M) model as a complete solution, which directly processes image tokens in the 2D space. We first generalize SSM to the 2-dimensional space which generates the next state considering two adjacent states on both dimensions (e.g., columns and rows). We then construct our V2M based on the 2-dimensional SSM formulation and incorporate Mamba to achieve hardware-efficient parallel processing. The proposed V2M effectively incorporates the 2D locality prior yet inherits the efficiency and input-dependent scalability of Mamba. Extensive experimental results on ImageNet classification and downstream visual tasks including object detection and instance segmentation on COCO and semantic segmentation on ADE20K demonstrate the effectiveness of our V2M compared with other visual backbones.</li>
</ul>

<h3>Title: Reverse Refinement Network for Narrow Rural Road Detection in High-Resolution Satellite Imagery</h3>
<ul>
<li><strong>Authors: </strong>Ningjing Wang, Xinyu Wang, Yang Pan, Wanqiang Yao, Yanfei Zhong</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.10389">https://arxiv.org/abs/2410.10389</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.10389">https://arxiv.org/pdf/2410.10389</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.10389]] Reverse Refinement Network for Narrow Rural Road Detection in High-Resolution Satellite Imagery(https://arxiv.org/abs/2410.10389)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction</a></li>
<li><strong>Abstract: </strong>The automated extraction of rural roads is pivotal for rural development and transportation planning, serving as a cornerstone for socio-economic progress. Current research primarily focuses on road extraction in urban areas. However, rural roads present unique challenges due to their narrow and irregular nature, posing significant difficulties for road extraction. In this article, a reverse refinement network (R2-Net) is proposed to extract narrow rural roads, enhancing their connectivity and distinctiveness from the background. Specifically, to preserve the fine details of roads within high-resolution feature maps, R2-Net utilizes an axis context aware module (ACAM) to capture the long-distance spatial context information in various layers. Subsequently, the multi-level features are aggregated through a global aggregation module (GAM). Moreover, in the decoder stage, R2-Net employs a reverse-aware module (RAM) to direct the attention of the network to the complex background, thus amplifying its separability. In experiments, we compare R2-Net with several state-of-the-art methods using the DeepGlobe road extraction dataset and the WHU-RuR+ global large-scale rural road dataset. R2-Net achieved superior performance and especially excelled in accurately detecting narrow roads. Furthermore, we explored the applicability of R2-Net for large-scale rural road mapping. The results show that the proposed R2-Net has significant performance advantages for large-scale rural road mapping applications.</li>
</ul>

<h3>Title: Tighter Risk Bounds for Mixtures of Experts</h3>
<ul>
<li><strong>Authors: </strong>Wissam Akretche, FrÃ©dÃ©ric LeBlanc, Mario Marchand</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CR, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.10397">https://arxiv.org/abs/2410.10397</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.10397">https://arxiv.org/pdf/2410.10397</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.10397]] Tighter Risk Bounds for Mixtures of Experts(https://arxiv.org/abs/2410.10397)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy</a></li>
<li><strong>Abstract: </strong>In this work, we provide upper bounds on the risk of mixtures of experts by imposing local differential privacy (LDP) on their gating mechanism. These theoretical guarantees are tailored to mixtures of experts that utilize the one-out-of-$n$ gating mechanism, as opposed to the conventional $n$-out-of-$n$ mechanism. The bounds exhibit logarithmic dependence on the number of experts, and encapsulate the dependence on the gating mechanism in the LDP parameter, making them significantly tighter than existing bounds, under reasonable conditions. Experimental results support our theory, demonstrating that our approach enhances the generalization ability of mixtures of experts and validating the feasibility of imposing LDP on the gating mechanism.</li>
</ul>

<h3>Title: MMCFND: Multimodal Multilingual Caption-aware Fake News Detection for Low-resource Indic Languages</h3>
<ul>
<li><strong>Authors: </strong>Shubhi Bansal, Nishit Sushil Singh, Shahid Shafi Dar, Nagendra Kumar</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.10407">https://arxiv.org/abs/2410.10407</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.10407">https://arxiv.org/pdf/2410.10407</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.10407]] MMCFND: Multimodal Multilingual Caption-aware Fake News Detection for Low-resource Indic Languages(https://arxiv.org/abs/2410.10407)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>The widespread dissemination of false information through manipulative tactics that combine deceptive text and images threatens the integrity of reliable sources of information. While there has been research on detecting fake news in high resource languages using multimodal approaches, methods for low resource Indic languages primarily rely on textual analysis. This difference highlights the need for robust methods that specifically address multimodal fake news in Indic languages, where the lack of extensive datasets and tools presents a significant obstacle to progress. To this end, we introduce the Multimodal Multilingual dataset for Indic Fake News Detection (MMIFND). This meticulously curated dataset consists of 28,085 instances distributed across Hindi, Bengali, Marathi, Malayalam, Tamil, Gujarati and Punjabi. We further propose the Multimodal Multilingual Caption-aware framework for Fake News Detection (MMCFND). MMCFND utilizes pre-trained unimodal encoders and pairwise encoders from a foundational model that aligns vision and language, allowing for extracting deep representations from visual and textual components of news articles. The multimodal fusion encoder in the foundational model integrates text and image representations derived from its pairwise encoders to generate a comprehensive cross modal representation. Furthermore, we generate descriptive image captions that provide additional context to detect inconsistencies and manipulations. The retrieved features are then fused and fed into a classifier to determine the authenticity of news articles. The curated dataset can potentially accelerate research and development in low resource environments significantly. Thorough experimentation on MMIFND demonstrates that our proposed framework outperforms established methods for extracting relevant fake news detection features.</li>
</ul>

<h3>Title: Medico: Towards Hallucination Detection and Correction with Multi-source Evidence Fusion</h3>
<ul>
<li><strong>Authors: </strong>Xinping Zhao, Jindi Yu, Zhenyu Liu, Jifang Wang, Dongfang Li, Yibin Chen, Baotian Hu, Min Zhang</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.IR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.10408">https://arxiv.org/abs/2410.10408</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.10408">https://arxiv.org/pdf/2410.10408</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.10408]] Medico: Towards Hallucination Detection and Correction with Multi-source Evidence Fusion(https://arxiv.org/abs/2410.10408)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>As we all know, hallucinations prevail in Large Language Models (LLMs), where the generated content is coherent but factually incorrect, which inflicts a heavy blow on the widespread application of LLMs. Previous studies have shown that LLMs could confidently state non-existent facts rather than answering ``I don't know''. Therefore, it is necessary to resort to external knowledge to detect and correct the hallucinated content. Since manual detection and correction of factual errors is labor-intensive, developing an automatic end-to-end hallucination-checking approach is indeed a needful thing. To this end, we present Medico, a Multi-source evidence fusion enhanced hallucination detection and correction framework. It fuses diverse evidence from multiple sources, detects whether the generated content contains factual errors, provides the rationale behind the judgment, and iteratively revises the hallucinated content. Experimental results on evidence retrieval (0.964 HR@5, 0.908 MRR@5), hallucination detection (0.927-0.951 F1), and hallucination correction (0.973-0.979 approval rate) manifest the great potential of Medico. A video demo of Medico can be found at this https URL.</li>
</ul>

<h3>Title: On Calibration of LLM-based Guard Models for Reliable Content Moderation</h3>
<ul>
<li><strong>Authors: </strong>Hongfu Liu, Hengguan Huang, Hao Wang, Xiangming Gu, Ye Wang</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.CL, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.10414">https://arxiv.org/abs/2410.10414</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.10414">https://arxiv.org/pdf/2410.10414</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.10414]] On Calibration of LLM-based Guard Models for Reliable Content Moderation(https://arxiv.org/abs/2410.10414)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack, robust, large language model</a></li>
<li><strong>Abstract: </strong>Large language models (LLMs) pose significant risks due to the potential for generating harmful content or users attempting to evade guardrails. Existing studies have developed LLM-based guard models designed to moderate the input and output of threat LLMs, ensuring adherence to safety policies by blocking content that violates these protocols upon deployment. However, limited attention has been given to the reliability and calibration of such guard models. In this work, we empirically conduct comprehensive investigations of confidence calibration for 9 existing LLM-based guard models on 12 benchmarks in both user input and model output classification. Our findings reveal that current LLM-based guard models tend to 1) produce overconfident predictions, 2) exhibit significant miscalibration when subjected to jailbreak attacks, and 3) demonstrate limited robustness to the outputs generated by different types of response models. Additionally, we assess the effectiveness of post-hoc calibration methods to mitigate miscalibration. We demonstrate the efficacy of temperature scaling and, for the first time, highlight the benefits of contextual calibration for confidence calibration of guard models, particularly in the absence of validation sets. Our analysis and experiments underscore the limitations of current LLM-based guard models and provide valuable insights for the future development of well-calibrated guard models toward more reliable content moderation. We also advocate for incorporating reliability evaluation of confidence calibration when releasing future LLM-based guard models.</li>
</ul>

<h3>Title: A Stochastic Approach to Bi-Level Optimization for Hyperparameter Optimization and Meta Learning</h3>
<ul>
<li><strong>Authors: </strong>Minyoung Kim, Timothy M. Hospedales</a></li>
<li><strong>Subjects: </strong>cs.LG, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.10417">https://arxiv.org/abs/2410.10417</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.10417">https://arxiv.org/pdf/2410.10417</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.10417]] A Stochastic Approach to Bi-Level Optimization for Hyperparameter Optimization and Meta Learning(https://arxiv.org/abs/2410.10417)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, transformer</a></li>
<li><strong>Abstract: </strong>We tackle the general differentiable meta learning problem that is ubiquitous in modern deep learning, including hyperparameter optimization, loss function learning, few-shot learning, invariance learning and more. These problems are often formalized as Bi-Level optimizations (BLO). We introduce a novel perspective by turning a given BLO problem into a stochastic optimization, where the inner loss function becomes a smooth probability distribution, and the outer loss becomes an expected loss over the inner distribution. To solve this stochastic optimization, we adopt Stochastic Gradient Langevin Dynamics (SGLD) MCMC to sample inner distribution, and propose a recurrent algorithm to compute the MC-estimated hypergradient. Our derivation is similar to forward-mode differentiation, but we introduce a new first-order approximation that makes it feasible for large models without needing to store huge Jacobian matrices. The main benefits are two-fold: i) Our stochastic formulation takes into account uncertainty, which makes the method robust to suboptimal inner optimization or non-unique multiple inner minima due to overparametrization; ii) Compared to existing methods that often exhibit unstable behavior and hyperparameter sensitivity in practice, our method leads to considerably more reliable solutions. We demonstrate that the new approach achieves promising results on diverse meta learning problems and easily scales to learning 87M hyperparameters in the case of Vision Transformers.</li>
</ul>

<h3>Title: DOME: Taming Diffusion Model into High-Fidelity Controllable Occupancy World Model</h3>
<ul>
<li><strong>Authors: </strong>Songen Gu, Wei Yin, Bu Jin, Xiaoyang Guo, Junming Wang, Haodong Li, Qian Zhang, Xiaoxiao Long</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.10429">https://arxiv.org/abs/2410.10429</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.10429">https://arxiv.org/pdf/2410.10429</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.10429]] DOME: Taming Diffusion Model into High-Fidelity Controllable Occupancy World Model(https://arxiv.org/abs/2410.10429)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, transformer</a></li>
<li><strong>Abstract: </strong>We propose DOME, a diffusion-based world model that predicts future occupancy frames based on past occupancy observations. The ability of this world model to capture the evolution of the environment is crucial for planning in autonomous driving. Compared to 2D video-based world models, the occupancy world model utilizes a native 3D representation, which features easily obtainable annotations and is modality-agnostic. This flexibility has the potential to facilitate the development of more advanced world models. Existing occupancy world models either suffer from detail loss due to discrete tokenization or rely on simplistic diffusion architectures, leading to inefficiencies and difficulties in predicting future occupancy with controllability. Our DOME exhibits two key features:(1) High-Fidelity and Long-Duration Generation. We adopt a spatial-temporal diffusion transformer to predict future occupancy frames based on historical context. This architecture efficiently captures spatial-temporal information, enabling high-fidelity details and the ability to generate predictions over long durations. (2)Fine-grained Controllability. We address the challenge of controllability in predictions by introducing a trajectory resampling method, which significantly enhances the model's ability to generate controlled predictions. Extensive experiments on the widely used nuScenes dataset demonstrate that our method surpasses existing baselines in both qualitative and quantitative evaluations, establishing a new state-of-the-art performance on nuScenes. Specifically, our approach surpasses the baseline by 10.5% in mIoU and 21.2% in IoU for occupancy reconstruction and by 36.0% in mIoU and 24.6% in IoU for 4D occupancy forecasting.</li>
</ul>

<h3>Title: Diversity-Aware Reinforcement Learning for de novo Drug Design</h3>
<ul>
<li><strong>Authors: </strong>Hampus Gummesson Svensson, Christian Tyrchan, Ola Engkvist, Morteza Haghir Chehreghani</a></li>
<li><strong>Subjects: </strong>cs.LG, q-bio.BM</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.10431">https://arxiv.org/abs/2410.10431</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.10431">https://arxiv.org/pdf/2410.10431</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.10431]] Diversity-Aware Reinforcement Learning for de novo Drug Design(https://arxiv.org/abs/2410.10431)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>Fine-tuning a pre-trained generative model has demonstrated good performance in generating promising drug molecules. The fine-tuning task is often formulated as a reinforcement learning problem, where previous methods efficiently learn to optimize a reward function to generate potential drug molecules. Nevertheless, in the absence of an adaptive update mechanism for the reward function, the optimization process can become stuck in local optima. The efficacy of the optimal molecule in a local optimization may not translate to usefulness in the subsequent drug optimization process or as a potential standalone clinical candidate. Therefore, it is important to generate a diverse set of promising molecules. Prior work has modified the reward function by penalizing structurally similar molecules, primarily focusing on finding molecules with higher rewards. To date, no study has comprehensively examined how different adaptive update mechanisms for the reward function influence the diversity of generated molecules. In this work, we investigate a wide range of intrinsic motivation methods and strategies to penalize the extrinsic reward, and how they affect the diversity of the set of generated molecules. Our experiments reveal that combining structure- and prediction-based methods generally yields better results in terms of molecular diversity.</li>
</ul>

<h3>Title: LKASeg:Remote-Sensing Image Semantic Segmentation with Large Kernel Attention and Full-Scale Skip Connections</h3>
<ul>
<li><strong>Authors: </strong>Xuezhi Xiang, Yibo Ning, Lei Zhang, Denis Ombati, Himaloy Himu, Xiantong Zhen</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI, eess.IV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.10433">https://arxiv.org/abs/2410.10433</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.10433">https://arxiv.org/pdf/2410.10433</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.10433]] LKASeg:Remote-Sensing Image Semantic Segmentation with Large Kernel Attention and Full-Scale Skip Connections(https://arxiv.org/abs/2410.10433)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer, segmentation</a></li>
<li><strong>Abstract: </strong>Semantic segmentation of remote sensing images is a fundamental task in geospatial research. However, widely used Convolutional Neural Networks (CNNs) and Transformers have notable drawbacks: CNNs may be limited by insufficient remote sensing modeling capability, while Transformers face challenges due to computational complexity. In this paper, we propose a remote-sensing image semantic segmentation network named LKASeg, which combines Large Kernel Attention(LSKA) and Full-Scale Skip Connections(FSC). Specifically, we propose a decoder based on Large Kernel Attention (LKA), which extract global features while avoiding the computational overhead of self-attention and providing channel adaptability. To achieve full-scale feature learning and fusion, we apply Full-Scale Skip Connections (FSC) between the encoder and decoder. We conducted experiments by combining the LKA-based decoder with FSC. On the ISPRS Vaihingen dataset, the mF1 and mIoU scores achieved 90.33% and 82.77%.</li>
</ul>

<h3>Title: Domain-Conditioned Transformer for Fully Test-time Adaptation</h3>
<ul>
<li><strong>Authors: </strong>Yushun Tang, Shuoshuo Chen, Jiyuan Jia, Yi Zhang, Zhihai He</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.10442">https://arxiv.org/abs/2410.10442</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.10442">https://arxiv.org/pdf/2410.10442</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.10442]] Domain-Conditioned Transformer for Fully Test-time Adaptation(https://arxiv.org/abs/2410.10442)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Fully test-time adaptation aims to adapt a network model online based on sequential analysis of input samples during the inference stage. We observe that, when applying a transformer network model into a new domain, the self-attention profiles of image samples in the target domain deviate significantly from those in the source domain, which results in large performance degradation during domain changes. To address this important issue, we propose a new structure for the self-attention modules in the transformer. Specifically, we incorporate three domain-conditioning vectors, called domain conditioners, into the query, key, and value components of the self-attention module. We learn a network to generate these three domain conditioners from the class token at each transformer network layer. We find that, during fully online test-time adaptation, these domain conditioners at each transform network layer are able to gradually remove the impact of domain shift and largely recover the original self-attention profile. Our extensive experimental results demonstrate that the proposed domain-conditioned transformer significantly improves the online fully test-time domain adaptation performance and outperforms existing state-of-the-art methods by large margins.</li>
</ul>

<h3>Title: QUITE: Quantifying Uncertainty in Natural Language Text in Bayesian Reasoning Scenarios</h3>
<ul>
<li><strong>Authors: </strong>Timo Pierre Schrader, Lukas Lange, Simon Razniewski, Annemarie Friedrich</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.10449">https://arxiv.org/abs/2410.10449</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.10449">https://arxiv.org/pdf/2410.10449</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.10449]] QUITE: Quantifying Uncertainty in Natural Language Text in Bayesian Reasoning Scenarios(https://arxiv.org/abs/2410.10449)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Reasoning is key to many decision making processes. It requires consolidating a set of rule-like premises that are often associated with degrees of uncertainty and observations to draw conclusions. In this work, we address both the case where premises are specified as numeric probabilistic rules and situations in which humans state their estimates using words expressing degrees of certainty. Existing probabilistic reasoning datasets simplify the task, e.g., by requiring the model to only rank textual alternatives, by including only binary random variables, or by making use of a limited set of templates that result in less varied text. In this work, we present QUITE, a question answering dataset of real-world Bayesian reasoning scenarios with categorical random variables and complex relationships. QUITE provides high-quality natural language verbalizations of premises together with evidence statements and expects the answer to a question in the form of an estimated probability. We conduct an extensive set of experiments, finding that logic-based models outperform out-of-the-box large language models on all reasoning types (causal, evidential, and explaining-away). Our results provide evidence that neuro-symbolic models are a promising direction for improving complex reasoning. We release QUITE and code for training and experiments on Github.</li>
</ul>

<h3>Title: Mobility-Aware Federated Learning: Multi-Armed Bandit Based Selection in Vehicular Network</h3>
<ul>
<li><strong>Authors: </strong>Haoyu Tu, Lin Chen, Zuguang Li, Xiaopei Chen, Wen Wu</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.10451">https://arxiv.org/abs/2410.10451</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.10451">https://arxiv.org/pdf/2410.10451</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.10451]] Mobility-Aware Federated Learning: Multi-Armed Bandit Based Selection in Vehicular Network(https://arxiv.org/abs/2410.10451)</code><input type="text"></li>
<li><strong>Keywords: </strong>federate</a></li>
<li><strong>Abstract: </strong>In this paper,we study a vehicle selection problem for federated learning (FL) over vehicular networks. Specifically, we design a mobility-aware vehicular federated learning (MAVFL) scheme in which vehicles drive through a road segment to perform FL. Some vehicles may drive out of the segment which leads to unsuccessful this http URL the proposed scheme, the real-time successful training participation ratio is utilized to implement vehicle selection. We conduct the convergence analysis to indicate the influence of vehicle mobility on training loss. Furthermore, we propose a multi-armed bandit-based vehicle selection algorithm to minimize the utility function considering training loss and delay. The simulation results show that compared with baselines, the proposed algorithm can achieve better training performance with approximately 28\% faster convergence.</li>
</ul>

<h3>Title: Principled Bayesian Optimisation in Collaboration with Human Experts</h3>
<ul>
<li><strong>Authors: </strong>Wenjie Xu, Masaki Adachi, Colin N. Jones, Michael A. Osborne</a></li>
<li><strong>Subjects: </strong>cs.LG, math.OC</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.10452">https://arxiv.org/abs/2410.10452</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.10452">https://arxiv.org/pdf/2410.10452</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.10452]] Principled Bayesian Optimisation in Collaboration with Human Experts(https://arxiv.org/abs/2410.10452)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Bayesian optimisation for real-world problems is often performed interactively with human experts, and integrating their domain knowledge is key to accelerate the optimisation process. We consider a setup where experts provide advice on the next query point through binary accept/reject recommendations (labels). Experts' labels are often costly, requiring efficient use of their efforts, and can at the same time be unreliable, requiring careful adjustment of the degree to which any expert is trusted. We introduce the first principled approach that provides two key guarantees. (1) Handover guarantee: similar to a no-regret property, we establish a sublinear bound on the cumulative number of experts' binary labels. Initially, multiple labels per query are needed, but the number of expert labels required asymptotically converges to zero, saving both expert effort and computation time. (2) No-harm guarantee with data-driven trust level adjustment: our adaptive trust level ensures that the convergence rate will not be worse than the one without using advice, even if the advice from experts is adversarial. Unlike existing methods that employ a user-defined function that hand-tunes the trust level adjustment, our approach enables data-driven adjustments. Real-world applications empirically demonstrate that our method not only outperforms existing baselines, but also maintains robustness despite varying labelling accuracy, in tasks of battery design with human experts.</li>
</ul>

<h3>Title: Ada-K Routing: Boosting the Efficiency of MoE-based LLMs</h3>
<ul>
<li><strong>Authors: </strong>Tongtian Yue, Longteng Guo, Jie Cheng, Xuange Gao, Jing Liu</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.10456">https://arxiv.org/abs/2410.10456</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.10456">https://arxiv.org/pdf/2410.10456</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.10456]] Ada-K Routing: Boosting the Efficiency of MoE-based LLMs(https://arxiv.org/abs/2410.10456)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>In the era of Large Language Models (LLMs), Mixture-of-Experts (MoE) architectures offer a promising approach to managing computational costs while scaling up model parameters. Conventional MoE-based LLMs typically employ static Top-K routing, which activates a fixed and equal number of experts for each token regardless of their significance within the context. In this paper, we propose a novel Ada-K routing strategy that dynamically adjusts the number of activated experts for each token, thereby improving the balance between computational efficiency and model performance. Specifically, our strategy incorporates learnable and lightweight allocator modules that decide customized expert resource allocation tailored to the contextual needs for each token. These allocators are designed to be fully pluggable, making it broadly applicable across all mainstream MoE-based LLMs. We leverage the Proximal Policy Optimization (PPO) algorithm to facilitate an end-to-end learning process for this non-differentiable decision-making framework. Extensive evaluations on four popular baseline models demonstrate that our Ada-K routing method significantly outperforms conventional Top-K routing. Compared to Top-K, our method achieves over 25% reduction in FLOPs and more than 20% inference speedup while still improving performance across various benchmarks. Moreover, the training of Ada-K is highly efficient. Even for Mixtral-8x22B, a MoE-based LLM with more than 140B parameters, the training time is limited to 8 hours. Detailed analysis shows that harder tasks, middle layers, and content words tend to activate more experts, providing valuable insights for future adaptive MoE system designs. Both the training code and model checkpoints will be publicly available.</li>
</ul>

<h3>Title: TABCF: Counterfactual Explanations for Tabular Data Using a Transformer-Based VAE</h3>
<ul>
<li><strong>Authors: </strong>Emmanouil Panagiotou, Manuel Heurich, Tim Landgraf, Eirini Ntoutsi</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CY</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.10463">https://arxiv.org/abs/2410.10463</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.10463">https://arxiv.org/pdf/2410.10463</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.10463]] TABCF: Counterfactual Explanations for Tabular Data Using a Transformer-Based VAE(https://arxiv.org/abs/2410.10463)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>In the field of Explainable AI (XAI), counterfactual (CF) explanations are one prominent method to interpret a black-box model by suggesting changes to the input that would alter a prediction. In real-world applications, the input is predominantly in tabular form and comprised of mixed data types and complex feature interdependencies. These unique data characteristics are difficult to model, and we empirically show that they lead to bias towards specific feature types when generating CFs. To overcome this issue, we introduce TABCF, a CF explanation method that leverages a transformer-based Variational Autoencoder (VAE) tailored for modeling tabular data. Our approach uses transformers to learn a continuous latent space and a novel Gumbel-Softmax detokenizer that enables precise categorical reconstruction while preserving end-to-end differentiability. Extensive quantitative evaluation on five financial datasets demonstrates that TABCF does not exhibit bias toward specific feature types, and outperforms existing methods in producing effective CFs that align with common CF desiderata.</li>
</ul>

<h3>Title: Moirai-MoE: Empowering Time Series Foundation Models with Sparse Mixture of Experts</h3>
<ul>
<li><strong>Authors: </strong>Xu Liu, Juncheng Liu, Gerald Woo, Taha Aksu, Yuxuan Liang, Roger Zimmermann, Chenghao Liu, Silvio Savarese, Caiming Xiong, Doyen Sahoo</a></li>
<li><strong>Subjects: </strong>cs.LG, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.10469">https://arxiv.org/abs/2410.10469</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.10469">https://arxiv.org/pdf/2410.10469</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.10469]] Moirai-MoE: Empowering Time Series Foundation Models with Sparse Mixture of Experts(https://arxiv.org/abs/2410.10469)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Time series foundation models have demonstrated impressive performance as zero-shot forecasters. However, achieving effectively unified training on time series remains an open challenge. Existing approaches introduce some level of model specialization to account for the highly heterogeneous nature of time series data. For instance, Moirai pursues unified training by employing multiple input/output projection layers, each tailored to handle time series at a specific frequency. Similarly, TimesFM maintains a frequency embedding dictionary for this purpose. We identify two major drawbacks to this human-imposed frequency-level model specialization: (1) Frequency is not a reliable indicator of the underlying patterns in time series. For example, time series with different frequencies can display similar patterns, while those with the same frequency may exhibit varied patterns. (2) Non-stationarity is an inherent property of real-world time series, leading to varied distributions even within a short context window of a single time series. Frequency-level specialization is too coarse-grained to capture this level of diversity. To address these limitations, this paper introduces Moirai-MoE, using a single input/output projection layer while delegating the modeling of diverse time series patterns to the sparse mixture of experts (MoE) within Transformers. With these designs, Moirai-MoE reduces reliance on human-defined heuristics and enables automatic token-level specialization. Extensive experiments on 39 datasets demonstrate the superiority of Moirai-MoE over existing foundation models in both in-distribution and zero-shot scenarios. Furthermore, this study conducts comprehensive model analyses to explore the inner workings of time series MoE foundation models and provides valuable insights for future research.</li>
</ul>

<h3>Title: The Implicit Bias of Structured State Space Models Can Be Poisoned With Clean Labels</h3>
<ul>
<li><strong>Authors: </strong>Yonatan Slutzky, Yotam Alexander, Noam Razin, Nadav Cohen</a></li>
<li><strong>Subjects: </strong>cs.LG, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.10473">https://arxiv.org/abs/2410.10473</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.10473">https://arxiv.org/pdf/2410.10473</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.10473]] The Implicit Bias of Structured State Space Models Can Be Poisoned With Clean Labels(https://arxiv.org/abs/2410.10473)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer, large language model</a></li>
<li><strong>Abstract: </strong>Neural networks are powered by an implicit bias: a tendency of gradient descent to fit training data in a way that generalizes to unseen data. A recent class of neural network models gaining increasing popularity is structured state space models (SSMs), regarded as an efficient alternative to transformers. Prior work argued that the implicit bias of SSMs leads to generalization in a setting where data is generated by a low dimensional teacher. In this paper, we revisit the latter setting, and formally establish a phenomenon entirely undetected by prior work on the implicit bias of SSMs. Namely, we prove that while implicit bias leads to generalization under many choices of training data, there exist special examples whose inclusion in training completely distorts the implicit bias, to a point where generalization fails. This failure occurs despite the special training examples being labeled by the teacher, i.e. having clean labels! We empirically demonstrate the phenomenon, with SSMs trained independently and as part of non-linear neural networks. In the area of adversarial machine learning, disrupting generalization with cleanly labeled training examples is known as clean-label poisoning. Given the proliferation of SSMs, particularly in large language models, we believe significant efforts should be invested in further delineating their susceptibility to clean-label poisoning, and in developing methods for overcoming this susceptibility.</li>
</ul>

<h3>Title: Will LLMs Replace the Encoder-Only Models in Temporal Relation Classification?</h3>
<ul>
<li><strong>Authors: </strong>Gabriel Roccabruna, Massimo Rizzoli, Giuseppe Riccardi</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.10476">https://arxiv.org/abs/2410.10476</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.10476">https://arxiv.org/pdf/2410.10476</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.10476]] Will LLMs Replace the Encoder-Only Models in Temporal Relation Classification?(https://arxiv.org/abs/2410.10476)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability, large language model</a></li>
<li><strong>Abstract: </strong>The automatic detection of temporal relations among events has been mainly investigated with encoder-only models such as RoBERTa. Large Language Models (LLM) have recently shown promising performance in temporal reasoning tasks such as temporal question answering. Nevertheless, recent studies have tested the LLMs' performance in detecting temporal relations of closed-source models only, limiting the interpretability of those results. In this work, we investigate LLMs' performance and decision process in the Temporal Relation Classification task. First, we assess the performance of seven open and closed-sourced LLMs experimenting with in-context learning and lightweight fine-tuning approaches. Results show that LLMs with in-context learning significantly underperform smaller encoder-only models based on RoBERTa. Then, we delve into the possible reasons for this gap by applying explainable methods. The outcome suggests a limitation of LLMs in this task due to their autoregressive nature, which causes them to focus only on the last part of the sequence. Additionally, we evaluate the word embeddings of these two models to better understand their pre-training differences. The code and the fine-tuned models can be found respectively on GitHub.</li>
</ul>

<h3>Title: Model-Based Differentially Private Knowledge Transfer for Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Zhaomin Wu, Jizhou Guo, Junyi Hou, Bingsheng He, Lixin Fan, Qiang Yang</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.10481">https://arxiv.org/abs/2410.10481</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.10481">https://arxiv.org/pdf/2410.10481</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.10481]] Model-Based Differentially Private Knowledge Transfer for Large Language Models(https://arxiv.org/abs/2410.10481)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, large language model</a></li>
<li><strong>Abstract: </strong>As large language models (LLMs) become increasingly prevalent in web services, effectively leveraging domain-specific knowledge while ensuring privacy has become critical. Existing methods, such as retrieval-augmented generation (RAG) and differentially private data synthesis, often compromise either the utility of domain knowledge or the privacy of sensitive data, limiting their applicability in specialized domains. To address these challenges, we propose \textit{Llamdex}, a novel framework that integrates privacy-preserving, domain-specific models into LLMs. Our approach significantly enhances the accuracy of domain-specific tasks, achieving up to a 26\% improvement compared to existing methods under the same differential privacy constraints. Experimental results show that Llamdex not only improves the accuracy of LLM responses but also maintains comparable inference efficiency to the original LLM, highlighting its potential for real-world applications.</li>
</ul>

<h3>Title: Advancing Newborn Care: Precise Birth Time Detection Using AI-Driven Thermal Imaging with Adaptive Normalization</h3>
<ul>
<li><strong>Authors: </strong>Jorge GarcÃ­a-Torres, Ãyvind Meinich-Bache, Anders Johannessen, Siren Rettedal, Vilde Kolstad, Kjersti Engan</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.10483">https://arxiv.org/abs/2410.10483</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.10483">https://arxiv.org/pdf/2410.10483</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.10483]] Advancing Newborn Care: Precise Birth Time Detection Using AI-Driven Thermal Imaging with Adaptive Normalization(https://arxiv.org/abs/2410.10483)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy</a></li>
<li><strong>Abstract: </strong>Around 5-10\% of newborns need assistance to start breathing. Currently, there is a lack of evidence-based research, objective data collection, and opportunities for learning from real newborn resuscitation emergency events. Generating and evaluating automated newborn resuscitation algorithm activity timelines relative to the Time of Birth (ToB) offers a promising opportunity to enhance newborn care practices. Given the importance of prompt resuscitation interventions within the "golden minute" after birth, having an accurate ToB with second precision is essential for effective subsequent analysis of newborn resuscitation episodes. Instead, ToB is generally registered manually, often with minute precision, making the process inefficient and susceptible to error and imprecision. In this work, we explore the fusion of Artificial Intelligence (AI) and thermal imaging to develop the first AI-driven ToB detector. The use of temperature information offers a promising alternative to detect the newborn while respecting the privacy of healthcare providers and mothers. However, the frequent inconsistencies in thermal measurements, especially in a multi-camera setup, make normalization strategies critical. Our methodology involves a three-step process: first, we propose an adaptive normalization method based on Gaussian mixture models (GMM) to mitigate issues related to temperature variations; second, we implement and deploy an AI model to detect the presence of the newborn within the thermal video frames; and third, we evaluate and post-process the model's predictions to estimate the ToB. A precision of 88.1\% and a recall of 89.3\% are reported in the detection of the newborn within thermal frames during performance evaluation. Our approach achieves an absolute median deviation of 2.7 seconds in estimating the ToB relative to the manual annotations.</li>
</ul>

<h3>Title: Cultural Fidelity in Large-Language Models: An Evaluation of Online Language Resources as a Driver of Model Performance in Value Representation</h3>
<ul>
<li><strong>Authors: </strong>Sharif Kazemi, Gloria Gerhardt, Jonty Katz, Caroline Ida Kuria, Estelle Pan, Umang Prabhakar</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.10489">https://arxiv.org/abs/2410.10489</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.10489">https://arxiv.org/pdf/2410.10489</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.10489]] Cultural Fidelity in Large-Language Models: An Evaluation of Online Language Resources as a Driver of Model Performance in Value Representation(https://arxiv.org/abs/2410.10489)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>The training data for LLMs embeds societal values, increasing their familiarity with the language's culture. Our analysis found that 44% of the variance in the ability of GPT-4o to reflect the societal values of a country, as measured by the World Values Survey, correlates with the availability of digital resources in that language. Notably, the error rate was more than five times higher for the languages of the lowest resource compared to the languages of the highest resource. For GPT-4-turbo, this correlation rose to 72%, suggesting efforts to improve the familiarity with the non-English language beyond the web-scraped data. Our study developed one of the largest and most robust datasets in this topic area with 21 country-language pairs, each of which contain 94 survey questions verified by native speakers. Our results highlight the link between LLM performance and digital data availability in target languages. Weaker performance in low-resource languages, especially prominent in the Global South, may worsen digital divides. We discuss strategies proposed to address this, including developing multilingual LLMs from the ground up and enhancing fine-tuning on diverse linguistic datasets, as seen in African language initiatives.</li>
</ul>

<h3>Title: Vision-guided and Mask-enhanced Adaptive Denoising for Prompt-based Image Editing</h3>
<ul>
<li><strong>Authors: </strong>Kejie Wang, Xuemeng Song, Meng Liu, Weili Guan, Liqiang Nie</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.10496">https://arxiv.org/abs/2410.10496</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.10496">https://arxiv.org/pdf/2410.10496</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.10496]] Vision-guided and Mask-enhanced Adaptive Denoising for Prompt-based Image Editing(https://arxiv.org/abs/2410.10496)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>Text-to-image diffusion models have demonstrated remarkable progress in synthesizing high-quality images from text prompts, which boosts researches on prompt-based image editing that edits a source image according to a target prompt. Despite their advances, existing methods still encounter three key issues: 1) limited capacity of the text prompt in guiding target image generation, 2) insufficient mining of word-to-patch and patch-to-patch relationships for grounding editing areas, and 3) unified editing strength for all regions during each denoising step. To address these issues, we present a Vision-guided and Mask-enhanced Adaptive Editing (ViMAEdit) method with three key novel designs. First, we propose to leverage image embeddings as explicit guidance to enhance the conventional textual prompt-based denoising process, where a CLIP-based target image embedding estimation strategy is introduced. Second, we devise a self-attention-guided iterative editing area grounding strategy, which iteratively exploits patch-to-patch relationships conveyed by self-attention maps to refine those word-to-patch relationships contained in cross-attention maps. Last, we present a spatially adaptive variance-guided sampling, which highlights sampling variances for critical image regions to promote the editing capability. Experimental results demonstrate the superior editing capacity of ViMAEdit over all existing methods.</li>
</ul>

<h3>Title: Continual Learning Improves Zero-Shot Action Recognition</h3>
<ul>
<li><strong>Authors: </strong>Shreyank N Gowda, Davide Moltisanti, Laura Sevilla-Lara</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.10497">https://arxiv.org/abs/2410.10497</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.10497">https://arxiv.org/pdf/2410.10497</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.10497]] Continual Learning Improves Zero-Shot Action Recognition(https://arxiv.org/abs/2410.10497)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>Zero-shot action recognition requires a strong ability to generalize from pre-training and seen classes to novel unseen classes. Similarly, continual learning aims to develop models that can generalize effectively and learn new tasks without forgetting the ones previously learned. The generalization goals of zero-shot and continual learning are closely aligned, however techniques from continual learning have not been applied to zero-shot action recognition. In this paper, we propose a novel method based on continual learning to address zero-shot action recognition. This model, which we call {\em Generative Iterative Learning} (GIL) uses a memory of synthesized features of past classes, and combines these synthetic features with real ones from novel classes. The memory is used to train a classification model, ensuring a balanced exposure to both old and new classes. Experiments demonstrate that {\em GIL} improves generalization in unseen classes, achieving a new state-of-the-art in zero-shot recognition across multiple benchmarks. Importantly, {\em GIL} also boosts performance in the more challenging generalized zero-shot setting, where models need to retain knowledge about classes seen before fine-tuning.</li>
</ul>

<h3>Title: Comparison of deep learning and conventional methods for disease onset prediction</h3>
<ul>
<li><strong>Authors: </strong>Luis H. John, Chungsoo Kim, Jan A. Kors, Junhyuk Chang, Hannah Morgan-Cooper, Priya Desai, Chao Pang, Peter R. Rijnbeek, Jenna M. Reps, Egill A. Fridgeirsson</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.10505">https://arxiv.org/abs/2410.10505</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.10505">https://arxiv.org/pdf/2410.10505</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.10505]] Comparison of deep learning and conventional methods for disease onset prediction(https://arxiv.org/abs/2410.10505)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability, transformer</a></li>
<li><strong>Abstract: </strong>Background: Conventional prediction methods such as logistic regression and gradient boosting have been widely utilized for disease onset prediction for their reliability and interpretability. Deep learning methods promise enhanced prediction performance by extracting complex patterns from clinical data, but face challenges like data sparsity and high dimensionality. Methods: This study compares conventional and deep learning approaches to predict lung cancer, dementia, and bipolar disorder using observational data from eleven databases from North America, Europe, and Asia. Models were developed using logistic regression, gradient boosting, ResNet, and Transformer, and validated both internally and externally across the data sources. Discrimination performance was assessed using AUROC, and calibration was evaluated using Eavg. Findings: Across 11 datasets, conventional methods generally outperformed deep learning methods in terms of discrimination performance, particularly during external validation, highlighting their better transportability. Learning curves suggest that deep learning models require substantially larger datasets to reach the same performance levels as conventional methods. Calibration performance was also better for conventional methods, with ResNet showing the poorest calibration. Interpretation: Despite the potential of deep learning models to capture complex patterns in structured observational healthcare data, conventional models remain highly competitive for disease onset prediction, especially in scenarios involving smaller datasets and if lengthy training times need to be avoided. The study underscores the need for future research focused on optimizing deep learning models to handle the sparsity, high dimensionality, and heterogeneity inherent in healthcare datasets, and find new strategies to exploit the full capabilities of deep learning methods.</li>
</ul>

<h3>Title: Exploiting Local Features and Range Images for Small Data Real-Time Point Cloud Semantic Segmentation</h3>
<ul>
<li><strong>Authors: </strong>Daniel Fusaro, Simone Mosco, Emanuele Menegatti, Alberto Pretto</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.RO</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.10510">https://arxiv.org/abs/2410.10510</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.10510">https://arxiv.org/pdf/2410.10510</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.10510]] Exploiting Local Features and Range Images for Small Data Real-Time Point Cloud Semantic Segmentation(https://arxiv.org/abs/2410.10510)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>Semantic segmentation of point clouds is an essential task for understanding the environment in autonomous driving and robotics. Recent range-based works achieve real-time efficiency, while point- and voxel-based methods produce better results but are affected by high computational complexity. Moreover, highly complex deep learning models are often not suited to efficiently learn from small datasets. Their generalization capabilities can easily be driven by the abundance of data rather than the architecture design. In this paper, we harness the information from the three-dimensional representation to proficiently capture local features, while introducing the range image representation to incorporate additional information and facilitate fast computation. A GPU-based KDTree allows for rapid building, querying, and enhancing projection with straightforward operations. Extensive experiments on SemanticKITTI and nuScenes datasets demonstrate the benefits of our modification in a ``small data'' setup, in which only one sequence of the dataset is used to train the models, but also in the conventional setup, where all sequences except one are used for training. We show that a reduced version of our model not only demonstrates strong competitiveness against full-scale state-of-the-art models but also operates in real-time, making it a viable choice for real-world case applications. The code of our method is available at this https URL.</li>
</ul>

<h3>Title: Customize Your Visual Autoregressive Recipe with Set Autoregressive Modeling</h3>
<ul>
<li><strong>Authors: </strong>Wenze Liu, Le Zhuo, Yi Xin, Sheng Xia, Peng Gao, Xiangyu Yue</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.10511">https://arxiv.org/abs/2410.10511</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.10511">https://arxiv.org/pdf/2410.10511</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.10511]] Customize Your Visual Autoregressive Recipe with Set Autoregressive Modeling(https://arxiv.org/abs/2410.10511)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>We introduce a new paradigm for AutoRegressive (AR) image generation, termed Set AutoRegressive Modeling (SAR). SAR generalizes the conventional AR to the next-set setting, i.e., splitting the sequence into arbitrary sets containing multiple tokens, rather than outputting each token in a fixed raster order. To accommodate SAR, we develop a straightforward architecture termed Fully Masked Transformer. We reveal that existing AR variants correspond to specific design choices of sequence order and output intervals within the SAR framework, with AR and Masked AR (MAR) as two extreme instances. Notably, SAR facilitates a seamless transition from AR to MAR, where intermediate states allow for training a causal model that benefits from both few-step inference and KV cache acceleration, thus leveraging the advantages of both AR and MAR. On the ImageNet benchmark, we carefully explore the properties of SAR by analyzing the impact of sequence order and output intervals on performance, as well as the generalization ability regarding inference order and steps. We further validate the potential of SAR by training a 900M text-to-image model capable of synthesizing photo-realistic images with any resolution. We hope our work may inspire more exploration and application of AR-based modeling across diverse modalities.</li>
</ul>

<h3>Title: UniGEM: A Unified Approach to Generation and Property Prediction for Molecules</h3>
<ul>
<li><strong>Authors: </strong>Shikun Feng, Yuyan Ni, Yan Lu, Zhi-Ming Ma, Wei-Ying Ma, Yanyan Lan</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, q-bio.BM</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.10516">https://arxiv.org/abs/2410.10516</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.10516">https://arxiv.org/pdf/2410.10516</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.10516]] UniGEM: A Unified Approach to Generation and Property Prediction for Molecules(https://arxiv.org/abs/2410.10516)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, generative</a></li>
<li><strong>Abstract: </strong>Molecular generation and molecular property prediction are both crucial for drug discovery, but they are often developed independently. Inspired by recent studies, which demonstrate that diffusion model, a prominent generative approach, can learn meaningful data representations that enhance predictive tasks, we explore the potential for developing a unified generative model in the molecular domain that effectively addresses both molecular generation and property prediction tasks. However, the integration of these tasks is challenging due to inherent inconsistencies, making simple multi-task learning ineffective. To address this, we propose UniGEM, the first unified model to successfully integrate molecular generation and property prediction, delivering superior performance in both tasks. Our key innovation lies in a novel two-phase generative process, where predictive tasks are activated in the later stages, after the molecular scaffold is formed. We further enhance task balance through innovative training strategies. Rigorous theoretical analysis and comprehensive experiments demonstrate our significant improvements in both tasks. The principles behind UniGEM hold promise for broader applications, including natural language processing and computer vision.</li>
</ul>

<h3>Title: Continual Deep Reinforcement Learning to Prevent Catastrophic Forgetting in Jamming Mitigation</h3>
<ul>
<li><strong>Authors: </strong>Kemal Davaslioglu, Sastry Kompella, Tugba Erpek, Yalin E. Sagduyu</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.NI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.10521">https://arxiv.org/abs/2410.10521</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.10521">https://arxiv.org/pdf/2410.10521</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.10521]] Continual Deep Reinforcement Learning to Prevent Catastrophic Forgetting in Jamming Mitigation(https://arxiv.org/abs/2410.10521)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Deep Reinforcement Learning (DRL) has been highly effective in learning from and adapting to RF environments and thus detecting and mitigating jamming effects to facilitate reliable wireless communications. However, traditional DRL methods are susceptible to catastrophic forgetting (namely forgetting old tasks when learning new ones), especially in dynamic wireless environments where jammer patterns change over time. This paper considers an anti-jamming system and addresses the challenge of catastrophic forgetting in DRL applied to jammer detection and mitigation. First, we demonstrate the impact of catastrophic forgetting in DRL when applied to jammer detection and mitigation tasks, where the network forgets previously learned jammer patterns while adapting to new ones. This catastrophic interference undermines the effectiveness of the system, particularly in scenarios where the environment is non-stationary. We present a method that enables the network to retain knowledge of old jammer patterns while learning to handle new ones. Our approach substantially reduces catastrophic forgetting, allowing the anti-jamming system to learn new tasks without compromising its ability to perform previously learned tasks effectively. Furthermore, we introduce a systematic methodology for sequentially learning tasks in the anti-jamming framework. By leveraging continual DRL techniques based on PackNet, we achieve superior anti-jamming performance compared to standard DRL methods. Our proposed approach not only addresses catastrophic forgetting but also enhances the adaptability and robustness of the system in dynamic jamming environments. We demonstrate the efficacy of our method in preserving knowledge of past jammer patterns, learning new tasks efficiently, and achieving superior anti-jamming performance compared to traditional DRL approaches.</li>
</ul>

<h3>Title: Generalized Adversarial Code-Suggestions: Exploiting Contexts of LLM-based Code-Completion</h3>
<ul>
<li><strong>Authors: </strong>Karl Rubel, Maximilian Noppel, Christian Wressnegger</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.10526">https://arxiv.org/abs/2410.10526</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.10526">https://arxiv.org/pdf/2410.10526</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.10526]] Generalized Adversarial Code-Suggestions: Exploiting Contexts of LLM-based Code-Completion(https://arxiv.org/abs/2410.10526)</code><input type="text"></li>
<li><strong>Keywords: </strong>protect, defense, attack, steal</a></li>
<li><strong>Abstract: </strong>While convenient, relying on LLM-powered code assistants in day-to-day work gives rise to severe attacks. For instance, the assistant might introduce subtle flaws and suggest vulnerable code to the user. These adversarial code-suggestions can be introduced via data poisoning and, thus, unknowingly by the model creators. In this paper, we provide a generalized formulation of such attacks, spawning and extending related work in this domain. This formulation is defined over two components: First, a trigger pattern occurring in the prompts of a specific user group, and, second, a learnable map in embedding space from the prompt to an adversarial bait. The latter gives rise to novel and more flexible targeted attack-strategies, allowing the adversary to choose the most suitable trigger pattern for a specific user-group arbitrarily, without restrictions on the pattern's tokens. Our directional-map attacks and prompt-indexing attacks increase the stealthiness decisively. We extensively evaluate the effectiveness of these attacks and carefully investigate defensive mechanisms to explore the limits of generalized adversarial code-suggestions. We find that most defenses unfortunately offer little protection only.</li>
</ul>

<h3>Title: Transparent Networks for Multivariate Time Series</h3>
<ul>
<li><strong>Authors: </strong>Minkyu Kim, Suan Lee, Jinho Kim</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CY</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.10535">https://arxiv.org/abs/2410.10535</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.10535">https://arxiv.org/pdf/2410.10535</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.10535]] Transparent Networks for Multivariate Time Series(https://arxiv.org/abs/2410.10535)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Transparent models, which are machine learning models that produce inherently interpretable predictions, are receiving significant attention in high-stakes domains. However, despite much real-world data being collected as time series, there is a lack of studies on transparent time series models. To address this gap, we propose a novel transparent neural network model for time series called Generalized Additive Time Series Model (GATSM). GATSM consists of two parts: 1) independent feature networks to learn feature representations, and 2) a transparent temporal module to learn temporal patterns across different time steps using the feature representations. This structure allows GATSM to effectively capture temporal patterns and handle dynamic-length time series while preserving transparency. Empirical experiments show that GATSM significantly outperforms existing generalized additive models and achieves comparable performance to black-box time series models, such as recurrent neural networks and Transformer. In addition, we demonstrate that GATSM finds interesting patterns in time series. The source code is available at this https URL.</li>
</ul>

<h3>Title: Rethinking Legal Judgement Prediction in a Realistic Scenario in the Era of Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Shubham Kumar Nigam, Aniket Deroy, Subhankar Maity, Arnab Bhattacharya</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.IR, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.10542">https://arxiv.org/abs/2410.10542</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.10542">https://arxiv.org/pdf/2410.10542</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.10542]] Rethinking Legal Judgement Prediction in a Realistic Scenario in the Era of Large Language Models(https://arxiv.org/abs/2410.10542)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, transformer, large language model</a></li>
<li><strong>Abstract: </strong>This study investigates judgment prediction in a realistic scenario within the context of Indian judgments, utilizing a range of transformer-based models, including InLegalBERT, BERT, and XLNet, alongside LLMs such as Llama-2 and GPT-3.5 Turbo. In this realistic scenario, we simulate how judgments are predicted at the point when a case is presented for a decision in court, using only the information available at that time, such as the facts of the case, statutes, precedents, and arguments. This approach mimics real-world conditions, where decisions must be made without the benefit of hindsight, unlike retrospective analyses often found in previous studies. For transformer models, we experiment with hierarchical transformers and the summarization of judgment facts to optimize input for these models. Our experiments with LLMs reveal that GPT-3.5 Turbo excels in realistic scenarios, demonstrating robust performance in judgment prediction. Furthermore, incorporating additional legal information, such as statutes and precedents, significantly improves the outcome of the prediction task. The LLMs also provide explanations for their predictions. To evaluate the quality of these predictions and explanations, we introduce two human evaluation metrics: Clarity and Linking. Our findings from both automatic and human evaluations indicate that, despite advancements in LLMs, they are yet to achieve expert-level performance in judgment prediction and explanation tasks.</li>
</ul>

<h3>Title: Hybrid Transformer for Early Alzheimer's Detection: Integration of Handwriting-Based 2D Images and 1D Signal Features</h3>
<ul>
<li><strong>Authors: </strong>Changqing Gong, Huafeng Qin, MounÃ®m A. El-Yacoubi</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.10547">https://arxiv.org/abs/2410.10547</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.10547">https://arxiv.org/pdf/2410.10547</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.10547]] Hybrid Transformer for Early Alzheimer's Detection: Integration of Handwriting-Based 2D Images and 1D Signal Features(https://arxiv.org/abs/2410.10547)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, transformer, generative</a></li>
<li><strong>Abstract: </strong>Alzheimer's Disease (AD) is a prevalent neurodegenerative condition where early detection is vital. Handwriting, often affected early in AD, offers a non-invasive and cost-effective way to capture subtle motor changes. State-of-the-art research on handwriting, mostly online, based AD detection has predominantly relied on manually extracted features, fed as input to shallow machine learning models. Some recent works have proposed deep learning (DL)-based models, either 1D-CNN or 2D-CNN architectures, with performance comparing favorably to handcrafted schemes. These approaches, however, overlook the intrinsic relationship between the 2D spatial patterns of handwriting strokes and their 1D dynamic characteristics, thus limiting their capacity to capture the multimodal nature of handwriting data. Moreover, the application of Transformer models remains basically unexplored. To address these limitations, we propose a novel approach for AD detection, consisting of a learnable multimodal hybrid attention model that integrates simultaneously 2D handwriting images with 1D dynamic handwriting signals. Our model leverages a gated mechanism to combine similarity and difference attention, blending the two modalities and learning robust features by incorporating information at different scales. Our model achieved state-of-the-art performance on the DARWIN dataset, with an F1-score of 90.32\% and accuracy of 90.91\% in Task 8 ('L' writing), surpassing the previous best by 4.61% and 6.06% respectively.</li>
</ul>

<h3>Title: RICASSO: Reinforced Imbalance Learning with Class-Aware Self-Supervised Outliers Exposure</h3>
<ul>
<li><strong>Authors: </strong>Xuan Zhang, Sin Chee Chin, Tingxuan Gao, Wenming Yang</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.10548">https://arxiv.org/abs/2410.10548</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.10548">https://arxiv.org/pdf/2410.10548</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.10548]] RICASSO: Reinforced Imbalance Learning with Class-Aware Self-Supervised Outliers Exposure(https://arxiv.org/abs/2410.10548)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>In real-world scenarios, deep learning models often face challenges from both imbalanced (long-tailed) and out-of-distribution (OOD) data. However, existing joint methods rely on real OOD data, which leads to unnecessary trade-offs. In contrast, our research shows that data mixing, a potent augmentation technique for long-tailed recognition, can generate pseudo-OOD data that exhibit the features of both in-distribution (ID) data and OOD data. Therefore, by using mixed data instead of real OOD data, we can address long-tailed recognition and OOD detection holistically. We propose a unified framework called Reinforced Imbalance Learning with Class-Aware Self-Supervised Outliers Exposure (RICASSO), where "self-supervised" denotes that we only use ID data for outlier exposure. RICASSO includes three main strategies: Norm-Odd-Duality-Based Outlier Exposure: Uses mixed data as pseudo-OOD data, enabling simultaneous ID data rebalancing and outlier exposure through a single loss function. Ambiguity-Aware Logits Adjustment: Utilizes the ambiguity of ID data to adaptively recalibrate logits. Contrastive Boundary-Center Learning: Combines Virtual Boundary Learning and Dual-Entropy Center Learning to use mixed data for better feature separation and clustering, with Representation Consistency Learning for robustness. Extensive experiments demonstrate that RICASSO achieves state-of-the-art performance in long-tailed recognition and significantly improves OOD detection compared to our baseline (27% improvement in AUROC and 61% reduction in FPR on the iNaturalist2018 dataset). On iNaturalist2018, we even outperforms methods using real OOD data. The code will be made public soon.</li>
</ul>

<h3>Title: SLaNC: Static LayerNorm Calibration</h3>
<ul>
<li><strong>Authors: </strong>Mahsa Salmani, Nikita Trukhanov, Ilya Soloveychik</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.10553">https://arxiv.org/abs/2410.10553</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.10553">https://arxiv.org/pdf/2410.10553</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.10553]] SLaNC: Static LayerNorm Calibration(https://arxiv.org/abs/2410.10553)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer, large language model</a></li>
<li><strong>Abstract: </strong>The ever increasing sizes of Large Language Models (LLMs) beyond hundreds of billions of parameters have generated enormous pressure on the manufacturers of dedicated hardware accelerators and made the innovative design of the latter one of the most rapidly expanding fields of the AI industry. Various approaches have been explored to enable efficient and accurate processing of LLMs on the available accelerators given their computational and storage limitations. Among these, various quantization techniques have become the main focus of the community as a means of reducing the compute, communication and storage requirements. Quantization to lower precision formats naturally poses a number of challenges caused by the limited range of the available value representations. When it comes to processing the popular Transformer models on hardware, one of the main issues becomes calculation of the LayerNorm simply because accumulation of the variance requires a much wider dynamic range than the hardware enables. In this article, we address this matter and propose a computationally-efficient scaling technique that can be easily applied to Transformer models during inference. Our method suggests a straightforward way of scaling the LayerNorm inputs based on the static weights of the immediately preceding linear layers. The scaling factors are computed offline, based solely on the linear layer weights, hence no latency or computational overhead is added during inference. Most importantly, our technique ensures that no numerical issues such as overflow or underflow could happen during the compute. This approach offers smooth, accurate and resource-effective inference across a wide range of hardware architectures. The article provides theoretical justification as well as supporting numerical simulations.</li>
</ul>

<h3>Title: ROSAR: An Adversarial Re-Training Framework for Robust Side-Scan Sonar Object Detection</h3>
<ul>
<li><strong>Authors: </strong>Martin Aubard, LÃ¡szlÃ³ Antal, Ana Madureira, Luis F. Teixeira, Erika ÃbrahÃ¡m</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI, cs.LG, cs.RO</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.10554">https://arxiv.org/abs/2410.10554</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.10554">https://arxiv.org/pdf/2410.10554</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.10554]] ROSAR: An Adversarial Re-Training Framework for Robust Side-Scan Sonar Object Detection(https://arxiv.org/abs/2410.10554)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack, robust</a></li>
<li><strong>Abstract: </strong>This paper introduces ROSAR, a novel framework enhancing the robustness of deep learning object detection models tailored for side-scan sonar (SSS) images, generated by autonomous underwater vehicles using sonar sensors. By extending our prior work on knowledge distillation (KD), this framework integrates KD with adversarial retraining to address the dual challenges of model efficiency and robustness against SSS noises. We introduce three novel, publicly available SSS datasets, capturing different sonar setups and noise conditions. We propose and formalize two SSS safety properties and utilize them to generate adversarial datasets for retraining. Through a comparative analysis of projected gradient descent (PGD) and patch-based adversarial attacks, ROSAR demonstrates significant improvements in model robustness and detection accuracy under SSS-specific conditions, enhancing the model's robustness by up to 1.85%. ROSAR is available at this https URL.</li>
</ul>

<h3>Title: Regularized Robustly Reliable Learners and Instance Targeted Attacks</h3>
<ul>
<li><strong>Authors: </strong>Avrim Blum, Donya Saless</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CR, cs.DS</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.10572">https://arxiv.org/abs/2410.10572</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.10572">https://arxiv.org/pdf/2410.10572</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.10572]] Regularized Robustly Reliable Learners and Instance Targeted Attacks(https://arxiv.org/abs/2410.10572)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack, robust</a></li>
<li><strong>Abstract: </strong>Instance-targeted data poisoning attacks, where an adversary corrupts a training set to induce errors on specific test points, have raised significant concerns. Balcan et al (2022) proposed an approach to addressing this challenge by defining a notion of robustly-reliable learners that provide per-instance guarantees of correctness under well-defined assumptions, even in the presence of data poisoning attacks. They then give a generic optimal (but computationally inefficient) robustly reliable learner as well as a computationally efficient algorithm for the case of linear separators over log-concave distributions. In this work, we address two challenges left open by Balcan et al (2022). The first is that the definition of robustly-reliable learners in Balcan et al (2022) becomes vacuous for highly-flexible hypothesis classes: if there are two classifiers h_0, h_1 \in H both with zero error on the training set such that h_0(x) \neq h_1(x), then a robustly-reliable learner must abstain on x. We address this problem by defining a modified notion of regularized robustly-reliable learners that allows for nontrivial statements in this case. The second is that the generic algorithm of Balcan et al (2022) requires re-running an ERM oracle (essentially, retraining the classifier) on each test point x, which is generally impractical even if ERM can be implemented efficiently. To tackle this problem, we show that at least in certain interesting cases we can design algorithms that can produce their outputs in time sublinear in training time, by using techniques from dynamic algorithm design.</li>
</ul>

<h3>Title: Sharing without Showing: Secure Cloud Analytics with Trusted Execution Environments</h3>
<ul>
<li><strong>Authors: </strong>Marcus Birgersson, Cyrille Artho, Musard Balliu</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.10574">https://arxiv.org/abs/2410.10574</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.10574">https://arxiv.org/pdf/2410.10574</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.10574]] Sharing without Showing: Secure Cloud Analytics with Trusted Execution Environments(https://arxiv.org/abs/2410.10574)</code><input type="text"></li>
<li><strong>Keywords: </strong>secure</a></li>
<li><strong>Abstract: </strong>Many applications benefit from computations over the data of multiple users while preserving confidentiality. We present a solution where multiple mutually distrusting users' data can be aggregated with an acceptable overhead, while allowing users to be added to the system at any time without re-encrypting data. Our solution to this problem is to use a Trusted Execution Environment (Intel SGX) for the computation, while the confidential data is encrypted with the data owner's key and can be stored anywhere, without trust in the service provider. We do not require the user to be online during the computation phase and do not require a trusted party to store data in plain text. Still, the computation can only be carried out if the data owner explicitly has given permission. Experiments using common functions such as the sum, least square fit, histogram, and SVM classification, exhibit an average overhead of $1.6 \times$. In addition to these performance experiments, we present a use case for computing the distributions of taxis in a city without revealing the position of any other taxi to the other parties.</li>
</ul>

<h3>Title: Recipe for Zero-shot POS Tagging: Is It Useful in Realistic Scenarios?</h3>
<ul>
<li><strong>Authors: </strong>Zeno Vandenbulcke, Lukas Vermeire, Miryam de Lhoneux</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.10576">https://arxiv.org/abs/2410.10576</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.10576">https://arxiv.org/pdf/2410.10576</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.10576]] Recipe for Zero-shot POS Tagging: Is It Useful in Realistic Scenarios?(https://arxiv.org/abs/2410.10576)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>POS tagging plays a fundamental role in numerous applications. While POS taggers are highly accurate in well-resourced settings, they lag behind in cases of limited or missing training data. This paper focuses on POS tagging for languages with limited data. We seek to identify the characteristics of datasets that make them favourable for training POS tagging models without using any labelled training data from the target language. This is a zero-shot approach. We compare the accuracies of a multilingual large language model (mBERT) fine-tuned on one or more languages related to the target language. Additionally, we compare these results with models trained directly on the target language itself. We do this for three target low-resource languages. Our research highlights the importance of accurate dataset selection for effective zero-shot POS tagging. Particularly, a strong linguistic relationship and high-quality datasets ensure optimal results. For extremely low-resource languages, zero-shot models prove to be a viable option.</li>
</ul>

<h3>Title: Multilingual Controlled Generation And Gold-Standard-Agnostic Evaluation of Code-Mixed Sentences</h3>
<ul>
<li><strong>Authors: </strong>Ayushman Gupta, Akhil Bhogal, Kripabandhu Ghosh</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.10580">https://arxiv.org/abs/2410.10580</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.10580">https://arxiv.org/pdf/2410.10580</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.10580]] Multilingual Controlled Generation And Gold-Standard-Agnostic Evaluation of Code-Mixed Sentences(https://arxiv.org/abs/2410.10580)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Code-mixing, the practice of alternating between two or more languages in an utterance, is a common phenomenon in multilingual communities. Due to the colloquial nature of code-mixing, there is no singular correct way to translate an English sentence into a code-mixed sentence. For this reason, standard n-gram-based MT evaluation metrics such as the BLEU score are not appropriate for code-mixed evaluation. To demonstrate this, we propose a novel method for code-mixed text generation: Controlled Generation, which parameterizes the code-mixing degree (CMD) and enables the generation of multiple semantically equivalent code-mixed sentences from a given English sentence. We introduce a robust new evaluation metric: GAME: A Gold-Standard Agnostic Measure for Evaluation of Code-Mixed Sentences. GAME is both language-agnostic and gold-standard-agnostic, i.e. unlike other metrics, GAME does not require gold-standard code-mixed sentences for evaluation, thus eliminating the need for human annotators in the code-mixed evaluation process. When used to evaluate semantically equivalent code-mixed sentences, we find that GAME scores have a lower standard deviation than BLEU scores. Further, we create and release a dataset containing gold-standard code-mixed sentences across 4 language pairs: English-{Hindi, Bengali, French, Spanish} to encourage more computational research on code-mixing.</li>
</ul>

<h3>Title: BrainMVP: Multi-modal Vision Pre-training for Brain Image Analysis using Multi-parametric MRI</h3>
<ul>
<li><strong>Authors: </strong>Shaohao Rui, Lingzhi Chen, Zhenyu Tang, Lilong Wang, Mianxin Liu, Shaoting Zhang, Xiaosong Wang</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.10604">https://arxiv.org/abs/2410.10604</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.10604">https://arxiv.org/pdf/2410.10604</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.10604]] BrainMVP: Multi-modal Vision Pre-training for Brain Image Analysis using Multi-parametric MRI(https://arxiv.org/abs/2410.10604)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>Accurate diagnosis of brain abnormalities is greatly enhanced by the inclusion of complementary multi-parametric MRI imaging data. There is significant potential to develop a universal pre-training model that can be quickly adapted for image modalities and various clinical scenarios. However, current models often rely on uni-modal image data, neglecting the cross-modal correlations among different image modalities or struggling to scale up pre-training in the presence of missing modality data. In this paper, we propose BrainMVP, a multi-modal vision pre-training framework for brain image analysis using multi-parametric MRI scans. First, we collect 16,022 brain MRI scans (over 2.4 million images), encompassing eight MRI modalities sourced from a diverse range of centers and devices. Then, a novel pre-training paradigm is proposed for the multi-modal MRI data, addressing the issue of missing modalities and achieving multi-modal information fusion. Cross-modal reconstruction is explored to learn distinctive brain image embeddings and efficient modality fusion capabilities. A modality-wise data distillation module is proposed to extract the essence representation of each MR image modality for both the pre-training and downstream application purposes. Furthermore, we introduce a modality-aware contrastive learning module to enhance the cross-modality association within a study. Extensive experiments on downstream tasks demonstrate superior performance compared to state-of-the-art pre-training methods in the medical domain, with Dice Score improvement of 0.28%-14.47% across six segmentation benchmarks and a consistent accuracy improvement of 0.65%-18.07% in four individual classification tasks.</li>
</ul>

<h3>Title: Lambda-Skip Connections: the architectural component that prevents Rank Collapse</h3>
<ul>
<li><strong>Authors: </strong>Federico Arangath Joseph, Jerome Sieber, Melanie N. Zeilinger, Carmen Amo Alonso</a></li>
<li><strong>Subjects: </strong>cs.LG, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.10609">https://arxiv.org/abs/2410.10609</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.10609">https://arxiv.org/pdf/2410.10609</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.10609]] Lambda-Skip Connections: the architectural component that prevents Rank Collapse(https://arxiv.org/abs/2410.10609)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Rank collapse, a phenomenon where embedding vectors in sequence models rapidly converge to a uniform token or equilibrium state, has recently gained attention in the deep learning literature. This phenomenon leads to reduced expressivity and potential training instabilities due to vanishing gradients. Empirical evidence suggests that architectural components like skip connections, LayerNorm, and MultiLayer Perceptrons (MLPs) play critical roles in mitigating rank collapse. While this issue is well-documented for transformers, alternative sequence models, such as State Space Models (SSMs), which have recently gained prominence, have not been thoroughly examined for similar vulnerabilities. This paper extends the theory of rank collapse from transformers to SSMs using a unifying framework that captures both architectures. We study how a parametrized version of the classic skip connection component, which we call \emph{lambda-skip connections}, provides guarantees for rank collapse prevention. Through analytical results, we present a sufficient condition to guarantee prevention of rank collapse across all the aforementioned architectures. We also study the necessity of this condition via ablation studies and analytical examples. To our knowledge, this is the first study that provides a general guarantee to prevent rank collapse, and that investigates rank collapse in the context of SSMs, offering valuable understanding for both theoreticians and practitioners. Finally, we validate our findings with experiments demonstrating the crucial role of architectural components such as skip connections and gating mechanisms in preventing rank collapse.</li>
</ul>

<h3>Title: SensorLLM: Aligning Large Language Models with Motion Sensors for Human Activity Recognition</h3>
<ul>
<li><strong>Authors: </strong>Zechen Li, Shohreh Deldari, Linyao Chen, Hao Xue, Flora D. Salim</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.10624">https://arxiv.org/abs/2410.10624</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.10624">https://arxiv.org/pdf/2410.10624</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.10624]] SensorLLM: Aligning Large Language Models with Motion Sensors for Human Activity Recognition(https://arxiv.org/abs/2410.10624)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>In this work, we bridge the gap between wearable sensor technology and personalized AI assistants by enabling Large Language Models (LLMs) to understand time-series tasks like human activity recognition (HAR). Despite the strong reasoning and generalization capabilities of LLMs, leveraging them for sensor data tasks remains largely unexplored. This gap stems from challenges like the lack of semantic context in time-series data, computational limitations, and LLMs' difficulty processing numerical inputs. To address these issues, we introduce SensorLLM, a two-stage framework to unlock LLMs' potential for sensor data tasks. In the Sensor-Language Alignment Stage, we introduce special tokens for each sensor channel and automatically generate trend-descriptive text to align sensor data with textual inputs, enabling SensorLLM to capture numerical changes, channel-specific information, and sensor data of varying lengths-capabilities that existing LLMs typically struggle with, all without the need for human annotations. Next, in Task-Aware Tuning Stage, we refine the model for HAR classification using the frozen LLM and alignment module, achieving performance on par with or surpassing state-of-the-art models. We further demonstrate that SensorLLM evolves into an effective sensor learner, reasoner, and classifier through Sensor-Language Alignment, enabling it to generalize across diverse datasets for HAR tasks. We strongly believe our work lays the stepstone for future time-series and text alignment research, offering a path toward foundation models for sensor data.</li>
</ul>

<h3>Title: Efficiently Democratizing Medical LLMs for 50 Languages via a Mixture of Language Family Experts</h3>
<ul>
<li><strong>Authors: </strong>Guorui Zheng, Xidong Wang, Juhao Liang, Nuo Chen, Yuping Zheng, Benyou Wang</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.10626">https://arxiv.org/abs/2410.10626</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.10626">https://arxiv.org/pdf/2410.10626</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.10626]] Efficiently Democratizing Medical LLMs for 50 Languages via a Mixture of Language Family Experts(https://arxiv.org/abs/2410.10626)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability, large language model</a></li>
<li><strong>Abstract: </strong>Adapting medical Large Language Models to local languages can reduce barriers to accessing healthcare services, but data scarcity remains a significant challenge, particularly for low-resource languages. To address this, we first construct a high-quality medical dataset and conduct analysis to ensure its quality. In order to leverage the generalization capability of multilingual LLMs to efficiently scale to more resource-constrained languages, we explore the internal information flow of LLMs from a multilingual perspective using Mixture of Experts (MoE) modularity. Technically, we propose a novel MoE routing method that employs language-specific experts and cross-lingual routing. Inspired by circuit theory, our routing analysis revealed a Spread Out in the End information flow mechanism: while earlier layers concentrate cross-lingual information flow, the later layers exhibit language-specific divergence. This insight directly led to the development of the Post-MoE architecture, which applies sparse routing only in the later layers while maintaining dense others. Experimental results demonstrate that this approach enhances the generalization of multilingual models to other languages while preserving interpretability. Finally, to efficiently scale the model to 50 languages, we introduce the concept of language family experts, drawing on linguistic priors, which enables scaling the number of languages without adding additional parameters.</li>
</ul>

<h3>Title: SANA: Efficient High-Resolution Image Synthesis with Linear Diffusion Transformers</h3>
<ul>
<li><strong>Authors: </strong>Enze Xie, Junsong Chen, Junyu Chen, Han Cai, Yujun Lin, Zhekai Zhang, Muyang Li, Yao Lu, Song Han</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.10629">https://arxiv.org/abs/2410.10629</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.10629">https://arxiv.org/pdf/2410.10629</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.10629]] SANA: Efficient High-Resolution Image Synthesis with Linear Diffusion Transformers(https://arxiv.org/abs/2410.10629)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, transformer</a></li>
<li><strong>Abstract: </strong>We introduce \model, a text-to-image framework that can efficiently generate images up to 4096$\times$4096 resolution. \model can synthesize high-resolution, high-quality images with strong text-image alignment at a remarkably fast speed, deployable on laptop GPU. Core designs include: (1) Deep compression autoencoder: unlike traditional AEs, which compress images only 8$\times$, we trained an AE that can compress images 32$\times$, effectively reducing the number of latent tokens. (2) Linear DiT: we replace all vanilla attention in DiT with linear attention, which is more efficient at high resolutions without sacrificing quality. (3) Decoder-only text encoder: we replaced T5 with modern decoder-only small LLM as the text encoder and designed complex human instruction with in-context learning to enhance the image-text alignment. (4) Efficient training and sampling: we propose Flow-DPM-Solver to reduce sampling steps, with efficient caption labeling and selection to accelerate convergence. As a result, \model-0.6B is very competitive with modern giant diffusion model (e.g. Flux-12B), being 20 times smaller and 100+ times faster in measured throughput. Moreover, \model-0.6B can be deployed on a 16GB laptop GPU, taking less than 1 second to generate a 1024$\times$1024 resolution image. Sana enables content creation at low cost. Code and model will be publicly released.</li>
</ul>

<h3>Title: Adapt-$\infty$: Scalable Lifelong Multimodal Instruction Tuning via Dynamic Data Selection</h3>
<ul>
<li><strong>Authors: </strong>Adyasha Maharana, Jaehong Yoon, Tianlong Chen, Mohit Bansal</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.10636">https://arxiv.org/abs/2410.10636</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.10636">https://arxiv.org/pdf/2410.10636</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.10636]] Adapt-$\infty$: Scalable Lifelong Multimodal Instruction Tuning via Dynamic Data Selection(https://arxiv.org/abs/2410.10636)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Visual instruction datasets from various distributors are released at different times and often contain a significant number of semantically redundant text-image pairs, depending on their task compositions (i.e., skills) or reference sources. This redundancy greatly limits the efficient deployment of lifelong adaptable multimodal large language models, hindering their ability to refine existing skills and acquire new competencies over time. To address this, we reframe the problem of Lifelong Instruction Tuning (LiIT) via data selection, where the model automatically selects beneficial samples to learn from earlier and new datasets based on the current state of acquired knowledge in the model. Based on empirical analyses that show that selecting the best data subset using a static importance measure is often ineffective for multi-task datasets with evolving distributions, we propose Adapt-$\infty$, a new multi-way and adaptive data selection approach that dynamically balances sample efficiency and effectiveness during LiIT. We construct pseudo-skill clusters by grouping gradient-based sample vectors. Next, we select the best-performing data selector for each skill cluster from a pool of selector experts, including our newly proposed scoring function, Image Grounding score. This data selector samples a subset of the most important samples from each skill cluster for training. To prevent the continuous increase in the size of the dataset pool during LiIT, which would result in excessive computation, we further introduce a cluster-wise permanent data pruning strategy to remove the most semantically redundant samples from each cluster, keeping computational requirements manageable. Training with samples selected by Adapt-$\infty$ alleviates catastrophic forgetting, especially for rare tasks, and promotes forward transfer across the continuum using only a fraction of the original datasets.</li>
</ul>

<h3>Title: A Simple Baseline for Predicting Events with Auto-Regressive Tabular Transformers</h3>
<ul>
<li><strong>Authors: </strong>Alex Stein, Samuel Sharpe, Doron Bergman, Senthil Kumar, Bayan Bruss, John Dickerson, Tom Goldstein, Micah Goldblum</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CE, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.10648">https://arxiv.org/abs/2410.10648</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.10648">https://arxiv.org/pdf/2410.10648</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.10648]] A Simple Baseline for Predicting Events with Auto-Regressive Tabular Transformers(https://arxiv.org/abs/2410.10648)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Many real-world applications of tabular data involve using historic events to predict properties of new ones, for example whether a credit card transaction is fraudulent or what rating a customer will assign a product on a retail platform. Existing approaches to event prediction include costly, brittle, and application-dependent techniques such as time-aware positional embeddings, learned row and field encodings, and oversampling methods for addressing class imbalance. Moreover, these approaches often assume specific use-cases, for example that we know the labels of all historic events or that we only predict a pre-specified label and not the data's features themselves. In this work, we propose a simple but flexible baseline using standard autoregressive LLM-style transformers with elementary positional embeddings and a causal language modeling objective. Our baseline outperforms existing approaches across popular datasets and can be employed for various use-cases. We demonstrate that the same model can predict labels, impute missing values, or model event sequences.</li>
</ul>

<h3>Title: Generative AI and Its Impact on Personalized Intelligent Tutoring Systems</h3>
<ul>
<li><strong>Authors: </strong>Subhankar Maity, Aniket Deroy</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.10650">https://arxiv.org/abs/2410.10650</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.10650">https://arxiv.org/pdf/2410.10650</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.10650]] Generative AI and Its Impact on Personalized Intelligent Tutoring Systems(https://arxiv.org/abs/2410.10650)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative, large language model</a></li>
<li><strong>Abstract: </strong>Generative Artificial Intelligence (AI) is revolutionizing educational technology by enabling highly personalized and adaptive learning environments within Intelligent Tutoring Systems (ITS). This report delves into the integration of Generative AI, particularly large language models (LLMs) like GPT-4, into ITS to enhance personalized education through dynamic content generation, real-time feedback, and adaptive learning pathways. We explore key applications such as automated question generation, customized feedback mechanisms, and interactive dialogue systems that respond to individual learner needs. The report also addresses significant challenges, including ensuring pedagogical accuracy, mitigating inherent biases in AI models, and maintaining learner engagement. Future directions highlight the potential advancements in multimodal AI integration, emotional intelligence in tutoring systems, and the ethical implications of AI-driven education. By synthesizing current research and practical implementations, this report underscores the transformative potential of Generative AI in creating more effective, equitable, and engaging educational experiences.</li>
</ul>

<h3>Title: PCF-Lift: Panoptic Lifting by Probabilistic Contrastive Fusion</h3>
<ul>
<li><strong>Authors: </strong>Runsong Zhu, Shi Qiu, Qianyi Wu, Ka-Hei Hui, Pheng-Ann Heng, Chi-Wing Fu</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.10659">https://arxiv.org/abs/2410.10659</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.10659">https://arxiv.org/pdf/2410.10659</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.10659]] PCF-Lift: Panoptic Lifting by Probabilistic Contrastive Fusion(https://arxiv.org/abs/2410.10659)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, segmentation</a></li>
<li><strong>Abstract: </strong>Panoptic lifting is an effective technique to address the 3D panoptic segmentation task by unprojecting 2D panoptic segmentations from multi-views to 3D scene. However, the quality of its results largely depends on the 2D segmentations, which could be noisy and error-prone, so its performance often drops significantly for complex scenes. In this work, we design a new pipeline coined PCF-Lift based on our Probabilis-tic Contrastive Fusion (PCF) to learn and embed probabilistic features throughout our pipeline to actively consider inaccurate segmentations and inconsistent instance IDs. Technical-wise, we first model the probabilistic feature embeddings through multivariate Gaussian distributions. To fuse the probabilistic features, we incorporate the probability product kernel into the contrastive loss formulation and design a cross-view constraint to enhance the feature consistency across different views. For the inference, we introduce a new probabilistic clustering method to effectively associate prototype features with the underlying 3D object instances for the generation of consistent panoptic segmentation results. Further, we provide a theoretical analysis to justify the superiority of the proposed probabilistic solution. By conducting extensive experiments, our PCF-lift not only significantly outperforms the state-of-the-art methods on widely used benchmarks including the ScanNet dataset and the challenging Messy Room dataset (4.4% improvement of scene-level PQ), but also demonstrates strong robustness when incorporating various 2D segmentation models or different levels of hand-crafted noise.</li>
</ul>

<h3>Title: Transforming Game Play: A Comparative Study of DCQN and DTQN Architectures in Reinforcement Learning</h3>
<ul>
<li><strong>Authors: </strong>William A. Stigall</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.10660">https://arxiv.org/abs/2410.10660</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.10660">https://arxiv.org/pdf/2410.10660</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.10660]] Transforming Game Play: A Comparative Study of DCQN and DTQN Architectures in Reinforcement Learning(https://arxiv.org/abs/2410.10660)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>In this study, we investigate the performance of Deep Q-Networks utilizing Convolutional Neural Networks (CNNs) and Transformer architectures across three different Atari games. The advent of DQNs has significantly advanced Reinforcement Learning, enabling agents to directly learn optimal policies from high-dimensional sensory inputs from pixel or RAM data. While CNN-based DQNs have been extensively studied and deployed in various domains, Transformer-based DQNs are relatively unexplored. Our research aims to fill this gap by benchmarking the performance of both DCQNs and DTQNs across the Atari games Asteroids, Space Invaders, and Centipede. We find that in the 35-40 million parameter range, the DCQN outperforms the DTQN in speed across both ViT and Projection Architectures. We also find the DCQN outperforms the DTQN in all games except for Centipede.</li>
</ul>

<h3>Title: Cross-Modal Few-Shot Learning: a Generative Transfer Learning Framework</h3>
<ul>
<li><strong>Authors: </strong>Zhengwei Yang, Yuke Li, Qiang Sun, Basura Fernando, Heng Huang, Zheng Wang</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.10663">https://arxiv.org/abs/2410.10663</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.10663">https://arxiv.org/pdf/2410.10663</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.10663]] Cross-Modal Few-Shot Learning: a Generative Transfer Learning Framework(https://arxiv.org/abs/2410.10663)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>Most existing studies on few-shot learning focus on unimodal settings, where models are trained to generalize on unseen data using only a small number of labeled examples from the same modality. However, real-world data are inherently multi-modal, and unimodal approaches limit the practical applications of few-shot learning. To address this gap, this paper introduces the Cross-modal Few-Shot Learning (CFSL) task, which aims to recognize instances from multiple modalities when only a few labeled examples are available. This task presents additional challenges compared to classical few-shot learning due to the distinct visual characteristics and structural properties unique to each modality. To tackle these challenges, we propose a Generative Transfer Learning (GTL) framework consisting of two stages: the first stage involves training on abundant unimodal data, and the second stage focuses on transfer learning to adapt to novel data. Our GTL framework jointly estimates the latent shared concept across modalities and in-modality disturbance in both stages, while freezing the generative module during the transfer phase to maintain the stability of the learned representations and prevent overfitting to the limited multi-modal samples. Our finds demonstrate that GTL has superior performance compared to state-of-the-art methods across four distinct multi-modal datasets: Sketchy, TU-Berlin, Mask1K, and SKSF-A. Additionally, the results suggest that the model can estimate latent concepts from vast unimodal data and generalize these concepts to unseen modalities using only a limited number of available samples, much like human cognitive processes.</li>
</ul>

<h3>Title: Double Jeopardy and Climate Impact in the Use of Large Language Models: Socio-economic Disparities and Reduced Utility for Non-English Speakers</h3>
<ul>
<li><strong>Authors: </strong>Aivin V. Solatorio, Gabriel Stefanini Vicente, Holly Krambeck, Olivier Dupriez</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.LG, econ.GN</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.10665">https://arxiv.org/abs/2410.10665</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.10665">https://arxiv.org/pdf/2410.10665</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.10665]] Double Jeopardy and Climate Impact in the Use of Large Language Models: Socio-economic Disparities and Reduced Utility for Non-English Speakers(https://arxiv.org/abs/2410.10665)</code><input type="text"></li>
<li><strong>Keywords: </strong>fair, large language model</a></li>
<li><strong>Abstract: </strong>Artificial Intelligence (AI), particularly large language models (LLMs), holds the potential to bridge language and information gaps, which can benefit the economies of developing nations. However, our analysis of FLORES-200, FLORES+, Ethnologue, and World Development Indicators data reveals that these benefits largely favor English speakers. Speakers of languages in low-income and lower-middle-income countries face higher costs when using OpenAI's GPT models via APIs because of how the system processes the input -- tokenization. Around 1.5 billion people, speaking languages primarily from lower-middle-income countries, could incur costs that are 4 to 6 times higher than those faced by English speakers. Disparities in LLM performance are significant, and tokenization in models priced per token amplifies inequalities in access, cost, and utility. Moreover, using the quality of translation tasks as a proxy measure, we show that LLMs perform poorly in low-resource languages, presenting a ``double jeopardy" of higher costs and poor performance for these users. We also discuss the direct impact of fragmentation in tokenizing low-resource languages on climate. This underscores the need for fairer algorithm development to benefit all linguistic groups.</li>
</ul>

<h3>Title: Large Language Model Evaluation via Matrix Nuclear-Norm</h3>
<ul>
<li><strong>Authors: </strong>Yahan Li, Tingyu Xia, Yi Chang, Yuan Wu</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.10672">https://arxiv.org/abs/2410.10672</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.10672">https://arxiv.org/pdf/2410.10672</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.10672]] Large Language Model Evaluation via Matrix Nuclear-Norm(https://arxiv.org/abs/2410.10672)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>As large language models (LLMs) continue to evolve, efficient evaluation metrics are vital for assessing their ability to compress information and reduce redundancy. While traditional metrics like Matrix Entropy offer valuable insights, they are computationally intensive for large-scale models due to their \( O(n^3) \) time complexity with Singular Value Decomposition (SVD). To mitigate this issue, we introduce the Matrix Nuclear-Norm, which not only serves as a metric to quantify the data compression proficiency of LLM but also provides a convex approximation of matrix rank to capture both predictive discriminability and diversity. By employing the \( L_{1,2}\text{-norm} \) to further approximate the nuclear norm, we can effectively assess the model's information compression capabilities. This approach reduces the time complexity to \( O(n^2) \) and eliminates the need for SVD computation. Consequently, the Matrix Nuclear-Norm achieves speeds 8 to 24 times faster than Matrix Entropy for the CEREBRAS-GPT model as sizes increase from 111M to 6.7B. This performance gap becomes more pronounced with larger models, as validated in tests with other models like Pythia. Additionally, evaluations on benchmarks and model responses confirm that our proposed Matrix Nuclear-Norm is a reliable, scalable, and efficient tool for assessing LLMs' performance, striking a balance between accuracy and computational efficiency. The code is available at this https URL.</li>
</ul>

<h3>Title: Enhancing Robustness in Deep Reinforcement Learning: A Lyapunov Exponent Approach</h3>
<ul>
<li><strong>Authors: </strong>Rory Young, Nicolas Pugeault</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.10674">https://arxiv.org/abs/2410.10674</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.10674">https://arxiv.org/pdf/2410.10674</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.10674]] Enhancing Robustness in Deep Reinforcement Learning: A Lyapunov Exponent Approach(https://arxiv.org/abs/2410.10674)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack, robust</a></li>
<li><strong>Abstract: </strong>Deep reinforcement learning agents achieve state-of-the-art performance in a wide range of simulated control tasks. However, successful applications to real-world problems remain limited. One reason for this dichotomy is because the learned policies are not robust to observation noise or adversarial attacks. In this paper, we investigate the robustness of deep RL policies to a single small state perturbation in deterministic continuous control tasks. We demonstrate that RL policies can be deterministically chaotic as small perturbations to the system state have a large impact on subsequent state and reward trajectories. This unstable non-linear behaviour has two consequences: First, inaccuracies in sensor readings, or adversarial attacks, can cause significant performance degradation; Second, even policies that show robust performance in terms of rewards may have unpredictable behaviour in practice. These two facets of chaos in RL policies drastically restrict the application of deep RL to real-world problems. To address this issue, we propose an improvement on the successful Dreamer V3 architecture, implementing a Maximal Lyapunov Exponent regularisation. This new approach reduces the chaotic state dynamics, rendering the learnt policies more resilient to sensor noise or adversarial attacks and thereby improving the suitability of Deep Reinforcement Learning for real-world applications.</li>
</ul>

<h3>Title: TALK-Act: Enhance Textural-Awareness for 2D Speaking Avatar Reenactment with Diffusion Model</h3>
<ul>
<li><strong>Authors: </strong>Jiazhi Guan, Quanwei Yang, Kaisiyuan Wang, Hang Zhou, Shengyi He, Zhiliang Xu, Haocheng Feng, Errui Ding, Jingdong Wang, Hongtao Xie, Youjian Zhao, Ziwei Liu</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.GR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.10696">https://arxiv.org/abs/2410.10696</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.10696">https://arxiv.org/pdf/2410.10696</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.10696]] TALK-Act: Enhance Textural-Awareness for 2D Speaking Avatar Reenactment with Diffusion Model(https://arxiv.org/abs/2410.10696)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>Recently, 2D speaking avatars have increasingly participated in everyday scenarios due to the fast development of facial animation techniques. However, most existing works neglect the explicit control of human bodies. In this paper, we propose to drive not only the faces but also the torso and gesture movements of a speaking figure. Inspired by recent advances in diffusion models, we propose the Motion-Enhanced Textural-Aware ModeLing for SpeaKing Avatar Reenactment (TALK-Act) framework, which enables high-fidelity avatar reenactment from only short footage of monocular video. Our key idea is to enhance the textural awareness with explicit motion guidance in diffusion modeling. Specifically, we carefully construct 2D and 3D structural information as intermediate guidance. While recent diffusion models adopt a side network for control information injection, they fail to synthesize temporally stable results even with person-specific fine-tuning. We propose a Motion-Enhanced Textural Alignment module to enhance the bond between driving and target signals. Moreover, we build a Memory-based Hand-Recovering module to help with the difficulties in hand-shape preserving. After pre-training, our model can achieve high-fidelity 2D avatar reenactment with only 30 seconds of person-specific data. Extensive experiments demonstrate the effectiveness and superiority of our proposed framework. Resources can be found at this https URL.</li>
</ul>

<h3>Title: Derail Yourself: Multi-turn LLM Jailbreak Attack through Self-discovered Clues</h3>
<ul>
<li><strong>Authors: </strong>Qibing Ren, Hao Li, Dongrui Liu, Zhanxu Xie, Xiaoya Lu, Yu Qiao, Lei Sha, Junchi Yan, Lizhuang Ma, Jing Shao</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.10700">https://arxiv.org/abs/2410.10700</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.10700">https://arxiv.org/pdf/2410.10700</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.10700]] Derail Yourself: Multi-turn LLM Jailbreak Attack through Self-discovered Clues(https://arxiv.org/abs/2410.10700)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack, robust, large language model</a></li>
<li><strong>Abstract: </strong>This study exposes the safety vulnerabilities of Large Language Models (LLMs) in multi-turn interactions, where malicious users can obscure harmful intents across several queries. We introduce ActorAttack, a novel multi-turn attack method inspired by actor-network theory, which models a network of semantically linked actors as attack clues to generate diverse and effective attack paths toward harmful targets. ActorAttack addresses two main challenges in multi-turn attacks: (1) concealing harmful intents by creating an innocuous conversation topic about the actor, and (2) uncovering diverse attack paths towards the same harmful target by leveraging LLMs' knowledge to specify the correlated actors as various attack clues. In this way, ActorAttack outperforms existing single-turn and multi-turn attack methods across advanced aligned LLMs, even for GPT-o1. We will publish a dataset called SafeMTData, which includes multi-turn adversarial prompts and safety alignment data, generated by ActorAttack. We demonstrate that models safety-tuned using our safety dataset are more robust to multi-turn attacks. Code is available at this https URL.</li>
</ul>

<h3>Title: Composability in Watermarking Schemes</h3>
<ul>
<li><strong>Authors: </strong>Jiahui Liu, Mark Zhandry</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.10712">https://arxiv.org/abs/2410.10712</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.10712">https://arxiv.org/pdf/2410.10712</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.10712]] Composability in Watermarking Schemes(https://arxiv.org/abs/2410.10712)</code><input type="text"></li>
<li><strong>Keywords: </strong>secure, watermark</a></li>
<li><strong>Abstract: </strong>Software watermarking allows for embedding a mark into a piece of code, such that any attempt to remove the mark will render the code useless. Provably secure watermarking schemes currently seems limited to programs computing various cryptographic operations, such as evaluating pseudorandom functions (PRFs), signing messages, or decrypting ciphertexts (the latter often going by the name ``traitor tracing''). Moreover, each of these watermarking schemes has an ad-hoc construction of its own. We observe, however, that many cryptographic objects are used as building blocks in larger protocols. We ask: just as we can compose building blocks to obtain larger protocols, can we compose watermarking schemes for the building blocks to obtain watermarking schemes for the larger protocols? We give an affirmative answer to this question, by precisely formulating a set of requirements that allow for composing watermarking schemes. We use our formulation to derive a number of applications.</li>
</ul>

<h3>Title: Benefiting from Quantum? A Comparative Study of Q-Seg, Quantum-Inspired Techniques, and U-Net for Crack Segmentation</h3>
<ul>
<li><strong>Authors: </strong>Akshaya Srinivasan, Alexander Geng, Antonio Macaluso, Maximilian Kiefer-Emmanouilidis, Ali Moghiseh</a></li>
<li><strong>Subjects: </strong>cs.CV, cond-mat.dis-nn, eess.IV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.10713">https://arxiv.org/abs/2410.10713</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.10713">https://arxiv.org/pdf/2410.10713</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.10713]] Benefiting from Quantum? A Comparative Study of Q-Seg, Quantum-Inspired Techniques, and U-Net for Crack Segmentation(https://arxiv.org/abs/2410.10713)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>Exploring the potential of quantum hardware for enhancing classical and real-world applications is an ongoing challenge. This study evaluates the performance of quantum and quantum-inspired methods compared to classical models for crack segmentation. Using annotated gray-scale image patches of concrete samples, we benchmark a classical mean Gaussian mixture technique, a quantum-inspired fermion-based method, Q-Seg a quantum annealing-based method, and a U-Net deep learning architecture. Our results indicate that quantum-inspired and quantum methods offer a promising alternative for image segmentation, particularly for complex crack patterns, and could be applied in near-future applications.</li>
</ul>

<h3>Title: SeedLM: Compressing LLM Weights into Seeds of Pseudo-Random Generators</h3>
<ul>
<li><strong>Authors: </strong>Rasoul Shafipour, David Harrison, Maxwell Horton, Jeffrey Marker, Houman Bedayat, Sachin Mehta, Mohammad Rastegari, Mahyar Najibi, Saman Naderiparizi</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.10714">https://arxiv.org/abs/2410.10714</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.10714">https://arxiv.org/pdf/2410.10714</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.10714]] SeedLM: Compressing LLM Weights into Seeds of Pseudo-Random Generators(https://arxiv.org/abs/2410.10714)</code><input type="text"></li>
<li><strong>Keywords: </strong>data-free, large language model</a></li>
<li><strong>Abstract: </strong>Large Language Models (LLMs) have transformed natural language processing, but face significant challenges in widespread deployment due to their high runtime cost. In this paper, we introduce SeedLM, a novel post-training compression method that uses seeds of pseudo-random generators to encode and compress model weights. Specifically, for each block of weights, we find a seed that is fed into a Linear Feedback Shift Register (LFSR) during inference to efficiently generate a random matrix. This matrix is then linearly combined with compressed coefficients to reconstruct the weight block. SeedLM reduces memory access and leverages idle compute cycles during inference, effectively speeding up memory-bound tasks by trading compute for fewer memory accesses. Unlike state-of-the-art compression methods that rely on calibration data, our approach is data-free and generalizes well across diverse tasks. Our experiments with Llama 3 70B, which is particularly challenging to compress, show that SeedLM achieves significantly better zero-shot accuracy retention at 4- and 3-bit than state-of-the-art techniques, while maintaining performance comparable to FP16 baselines. Additionally, FPGA-based tests demonstrate that 4-bit SeedLM, as model size increases to 70B, approaches a 4x speed-up over an FP16 Llama 2/3 baseline.</li>
</ul>

<h3>Title: Large Language Models Are Active Critics in NLG Evaluation</h3>
<ul>
<li><strong>Authors: </strong>Shuying Xu, Junjie Hu, Ming Jiang</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.10724">https://arxiv.org/abs/2410.10724</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.10724">https://arxiv.org/pdf/2410.10724</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.10724]] Large Language Models Are Active Critics in NLG Evaluation(https://arxiv.org/abs/2410.10724)</code><input type="text"></li>
<li><strong>Keywords: </strong>explainability, large language model</a></li>
<li><strong>Abstract: </strong>The conventional paradigm of using large language models (LLMs) for evaluating natural language generation (NLG) systems typically relies on two key inputs: (1) a clear definition of the NLG task to be evaluated and (2) a list of pre-defined evaluation criteria. This process treats LLMs as ''passive critics,'' strictly following human-defined criteria for evaluation. However, as new NLG tasks emerge, the criteria for assessing text quality can vary greatly. Consequently, these rigid evaluation methods struggle to adapt to diverse NLG tasks without extensive prompt engineering customized for each specific task. To address this limitation, we introduce Active-Critic, a novel LLM-based NLG evaluation protocol that enables LLMs to function as ''active critics.'' Specifically, our protocol comprises two key stages. In the first stage, the LLM is instructed to infer the target NLG task and establish relevant evaluation criteria from the data. Building on this self-inferred information, the second stage dynamically optimizes the prompt to guide the LLM toward more human-aligned scoring decisions, while also generating detailed explanations to justify its evaluations. Experiments across four NLG evaluation tasks show that our approach achieves stronger alignment with human judgments than state-of-the-art evaluation methods. Our comprehensive analysis further highlights the effectiveness and explainability of Active-Critic with only a small amount of labeled data. We will share our code and data on GitHub.</li>
</ul>

<h3>Title: Towards LLM-guided Efficient and Interpretable Multi-linear Tensor Network Rank Selection</h3>
<ul>
<li><strong>Authors: </strong>Giorgos Iacovides, Wuyang Zhou, Danilo Mandic</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.10728">https://arxiv.org/abs/2410.10728</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.10728">https://arxiv.org/pdf/2410.10728</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.10728]] Towards LLM-guided Efficient and Interpretable Multi-linear Tensor Network Rank Selection(https://arxiv.org/abs/2410.10728)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability, large language model</a></li>
<li><strong>Abstract: </strong>We propose a novel framework that leverages large language models (LLMs) to guide the rank selection in tensor network models for higher-order data analysis. By utilising the intrinsic reasoning capabilities and domain knowledge of LLMs, our approach offers enhanced interpretability of the rank choices and can effectively optimise the objective function. This framework enables users without specialised domain expertise to utilise tensor network decompositions and understand the underlying rationale within the rank selection process. Experimental results validate our method on financial higher-order datasets, demonstrating interpretable reasoning, strong generalisation to unseen test data, and its potential for self-enhancement over successive iterations. This work is placed at the intersection of large language models and higher-order data analysis.</li>
</ul>

<h3>Title: Deep Compression Autoencoder for Efficient High-Resolution Diffusion Models</h3>
<ul>
<li><strong>Authors: </strong>Junyu Chen, Han Cai, Junsong Chen, Enze Xie, Shang Yang, Haotian Tang, Muyang Li, Yao Lu, Song Han</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.10733">https://arxiv.org/abs/2410.10733</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.10733">https://arxiv.org/pdf/2410.10733</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.10733]] Deep Compression Autoencoder for Efficient High-Resolution Diffusion Models(https://arxiv.org/abs/2410.10733)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>We present Deep Compression Autoencoder (DC-AE), a new family of autoencoder models for accelerating high-resolution diffusion models. Existing autoencoder models have demonstrated impressive results at a moderate spatial compression ratio (e.g., 8x), but fail to maintain satisfactory reconstruction accuracy for high spatial compression ratios (e.g., 64x). We address this challenge by introducing two key techniques: (1) Residual Autoencoding, where we design our models to learn residuals based on the space-to-channel transformed features to alleviate the optimization difficulty of high spatial-compression autoencoders; (2) Decoupled High-Resolution Adaptation, an efficient decoupled three-phases training strategy for mitigating the generalization penalty of high spatial-compression autoencoders. With these designs, we improve the autoencoder's spatial compression ratio up to 128 while maintaining the reconstruction quality. Applying our DC-AE to latent diffusion models, we achieve significant speedup without accuracy drop. For example, on ImageNet 512x512, our DC-AE provides 19.1x inference speedup and 17.9x training speedup on H100 GPU for UViT-H while achieving a better FID, compared with the widely used SD-VAE-f8 autoencoder. Our code is available at this https URL.</li>
</ul>

<h3>Title: Towards Calibrated Losses for Adversarial Robust Reject Option Classification</h3>
<ul>
<li><strong>Authors: </strong>Vrund Shah, Tejas Chaudhari, Naresh Manwani</a></li>
<li><strong>Subjects: </strong>cs.LG, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.10736">https://arxiv.org/abs/2410.10736</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.10736">https://arxiv.org/pdf/2410.10736</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.10736]] Towards Calibrated Losses for Adversarial Robust Reject Option Classification(https://arxiv.org/abs/2410.10736)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack, robust</a></li>
<li><strong>Abstract: </strong>Robustness towards adversarial attacks is a vital property for classifiers in several applications such as autonomous driving, medical diagnosis, etc. Also, in such scenarios, where the cost of misclassification is very high, knowing when to abstain from prediction becomes crucial. A natural question is which surrogates can be used to ensure learning in scenarios where the input points are adversarially perturbed and the classifier can abstain from prediction? This paper aims to characterize and design surrogates calibrated in "Adversarial Robust Reject Option" setting. First, we propose an adversarial robust reject option loss $\ell_{d}^{\gamma}$ and analyze it for the hypothesis set of linear classifiers ($\mathcal{H}_{\textrm{lin}}$). Next, we provide a complete characterization result for any surrogate to be $(\ell_{d}^{\gamma},\mathcal{H}_{\textrm{lin}})$- calibrated. To demonstrate the difficulty in designing surrogates to $\ell_{d}^{\gamma}$, we show negative calibration results for convex surrogates and quasi-concave conditional risk cases (these gave positive calibration in adversarial setting without reject option). We also empirically argue that Shifted Double Ramp Loss (DRL) and Shifted Double Sigmoid Loss (DSL) satisfy the calibration conditions. Finally, we demonstrate the robustness of shifted DRL and shifted DSL against adversarial perturbations on a synthetically generated dataset.</li>
</ul>

<h3>Title: Balancing Continuous Pre-Training and Instruction Fine-Tuning: Optimizing Instruction-Following in LLMs</h3>
<ul>
<li><strong>Authors: </strong>Ishan Jindal, Chandana Badrinath, Pranjal Bharti, Lakkidi Vinay, Sachin Dev Sharma</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.10739">https://arxiv.org/abs/2410.10739</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.10739">https://arxiv.org/pdf/2410.10739</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.10739]] Balancing Continuous Pre-Training and Instruction Fine-Tuning: Optimizing Instruction-Following in LLMs(https://arxiv.org/abs/2410.10739)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large Language Models (LLMs) for public use require continuous pre-training to remain up-to-date with the latest data. The models also need to be fine-tuned with specific instructions to maintain their ability to follow instructions accurately. Typically, LLMs are released in two versions: the Base LLM, pre-trained on diverse data, and the instruction-refined LLM, additionally trained with specific instructions for better instruction following. The question arises as to which model should undergo continuous pre-training to maintain its instruction-following abilities while also staying current with the latest data. In this study, we delve into the intricate relationship between continuous pre-training and instruction fine-tuning of the LLMs and investigate the impact of continuous pre-training on the instruction following abilities of both the base and its instruction finetuned model. Further, the instruction fine-tuning process is computationally intense and requires a substantial number of hand-annotated examples for the model to learn effectively. This study aims to find the most compute-efficient strategy to gain up-to-date knowledge and instruction-following capabilities without requiring any instruction data and fine-tuning. We empirically prove our findings on the LLaMa 3, 3.1 and Qwen 2, 2.5 family of base and instruction models, providing a comprehensive exploration of our hypotheses across varying sizes of pre-training data corpus and different LLMs settings.</li>
</ul>

<h3>Title: Adversarially Robust Out-of-Distribution Detection Using Lyapunov-Stabilized Embeddings</h3>
<ul>
<li><strong>Authors: </strong>Hossein Mirzaei, Mackenzie W. Mathis</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CV, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.10744">https://arxiv.org/abs/2410.10744</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.10744">https://arxiv.org/pdf/2410.10744</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.10744]] Adversarially Robust Out-of-Distribution Detection Using Lyapunov-Stabilized Embeddings(https://arxiv.org/abs/2410.10744)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack, robust</a></li>
<li><strong>Abstract: </strong>Despite significant advancements in out-of-distribution (OOD) detection, existing methods still struggle to maintain robustness against adversarial attacks, compromising their reliability in critical real-world applications. Previous studies have attempted to address this challenge by exposing detectors to auxiliary OOD datasets alongside adversarial training. However, the increased data complexity inherent in adversarial training, and the myriad of ways that OOD samples can arise during testing, often prevent these approaches from establishing robust decision boundaries. To address these limitations, we propose AROS, a novel approach leveraging neural ordinary differential equations (NODEs) with Lyapunov stability theorem in order to obtain robust embeddings for OOD detection. By incorporating a tailored loss function, we apply Lyapunov stability theory to ensure that both in-distribution (ID) and OOD data converge to stable equilibrium points within the dynamical system. This approach encourages any perturbed input to return to its stable equilibrium, thereby enhancing the model's robustness against adversarial perturbations. To not use additional data, we generate fake OOD embeddings by sampling from low-likelihood regions of the ID data feature space, approximating the boundaries where OOD data are likely to reside. To then further enhance robustness, we propose the use of an orthogonal binary layer following the stable feature space, which maximizes the separation between the equilibrium points of ID and OOD samples. We validate our method through extensive experiments across several benchmarks, demonstrating superior performance, particularly under adversarial attacks. Notably, our approach improves robust detection performance from 37.8% to 80.1% on CIFAR-10 vs. CIFAR-100 and from 29.0% to 67.0% on CIFAR-100 vs. CIFAR-10.</li>
</ul>

<h3>Title: FlexGen: Flexible Multi-View Generation from Text and Image Inputs</h3>
<ul>
<li><strong>Authors: </strong>Xinli Xu, Wenhang Ge, Jiantao Lin, Jiawei Feng, Lie Xu, HanFeng Zhao, Shunsi Zhang, Ying-Cong Chen</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.10745">https://arxiv.org/abs/2410.10745</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.10745">https://arxiv.org/pdf/2410.10745</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.10745]] FlexGen: Flexible Multi-View Generation from Text and Image Inputs(https://arxiv.org/abs/2410.10745)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>In this work, we introduce FlexGen, a flexible framework designed to generate controllable and consistent multi-view images, conditioned on a single-view image, or a text prompt, or both. FlexGen tackles the challenges of controllable multi-view synthesis through additional conditioning on 3D-aware text annotations. We utilize the strong reasoning capabilities of GPT-4V to generate 3D-aware text annotations. By analyzing four orthogonal views of an object arranged as tiled multi-view images, GPT-4V can produce text annotations that include 3D-aware information with spatial relationship. By integrating the control signal with proposed adaptive dual-control module, our model can generate multi-view images that correspond to the specified text. FlexGen supports multiple controllable capabilities, allowing users to modify text prompts to generate reasonable and corresponding unseen parts. Additionally, users can influence attributes such as appearance and material properties, including metallic and roughness. Extensive experiments demonstrate that our approach offers enhanced multiple controllability, marking a significant advancement over existing multi-view diffusion models. This work has substantial implications for fields requiring rapid and flexible 3D content creation, including game development, animation, and virtual reality. Project page: this https URL.</li>
</ul>

<h3>Title: DragEntity: Trajectory Guided Video Generation using Entity and Positional Relationships</h3>
<ul>
<li><strong>Authors: </strong>Zhang Wan, Sheng Tang, Jiawei Wei, Ruize Zhang, Juan Cao</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.10751">https://arxiv.org/abs/2410.10751</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.10751">https://arxiv.org/pdf/2410.10751</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.10751]] DragEntity: Trajectory Guided Video Generation using Entity and Positional Relationships(https://arxiv.org/abs/2410.10751)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>In recent years, diffusion models have achieved tremendous success in the field of video generation, with controllable video generation receiving significant attention. However, existing control methods still face two limitations: Firstly, control conditions (such as depth maps, 3D Mesh) are difficult for ordinary users to obtain directly. Secondly, it's challenging to drive multiple objects through complex motions with multiple trajectories simultaneously. In this paper, we introduce DragEntity, a video generation model that utilizes entity representation for controlling the motion of multiple objects. Compared to previous methods, DragEntity offers two main advantages: 1) Our method is more user-friendly for interaction because it allows users to drag entities within the image rather than individual pixels. 2) We use entity representation to represent any object in the image, and multiple objects can maintain relative spatial relationships. Therefore, we allow multiple trajectories to control multiple objects in the image with different levels of complexity simultaneously. Our experiments validate the effectiveness of DragEntity, demonstrating its excellent performance in fine-grained control in video generation.</li>
</ul>

<h3>Title: Use Random Selection for Now: Investigation of Few-Shot Selection Strategies in LLM-based Text Augmentation for Classification</h3>
<ul>
<li><strong>Authors: </strong>Jan Cegin, Branislav Pecher, Jakub Simko, Ivan Srba, Maria Bielikova, Peter Brusilovsky</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.10756">https://arxiv.org/abs/2410.10756</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.10756">https://arxiv.org/pdf/2410.10756</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.10756]] Use Random Selection for Now: Investigation of Few-Shot Selection Strategies in LLM-based Text Augmentation for Classification(https://arxiv.org/abs/2410.10756)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative, large language model</a></li>
<li><strong>Abstract: </strong>The generative large language models (LLMs) are increasingly used for data augmentation tasks, where text samples are paraphrased (or generated anew) and then used for classifier fine-tuning. Existing works on augmentation leverage the few-shot scenarios, where samples are given to LLMs as part of prompts, leading to better augmentations. Yet, the samples are mostly selected randomly and a comprehensive overview of the effects of other (more ``informed'') sample selection strategies is lacking. In this work, we compare sample selection strategies existing in few-shot learning literature and investigate their effects in LLM-based textual augmentation. We evaluate this on in-distribution and out-of-distribution classifier performance. Results indicate, that while some ``informed'' selection strategies increase the performance of models, especially for out-of-distribution data, it happens only seldom and with marginal performance increases. Unless further advances are made, a default of random sample selection remains a good option for augmentation practitioners.</li>
</ul>

<h3>Title: Denial-of-Service Poisoning Attacks against Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Kuofeng Gao, Tianyu Pang, Chao Du, Yong Yang, Shu-Tao Xia, Min Lin</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.10760">https://arxiv.org/abs/2410.10760</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.10760">https://arxiv.org/pdf/2410.10760</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.10760]] Denial-of-Service Poisoning Attacks against Large Language Models(https://arxiv.org/abs/2410.10760)</code><input type="text"></li>
<li><strong>Keywords: </strong>secure, defense, attack, large language model</a></li>
<li><strong>Abstract: </strong>Recent studies have shown that LLMs are vulnerable to denial-of-service (DoS) attacks, where adversarial inputs like spelling errors or non-semantic prompts trigger endless outputs without generating an [EOS] token. These attacks can potentially cause high latency and make LLM services inaccessible to other users or tasks. However, when there are speech-to-text interfaces (e.g., voice commands to a robot), executing such DoS attacks becomes challenging, as it is difficult to introduce spelling errors or non-semantic prompts through speech. A simple DoS attack in these scenarios would be to instruct the model to "Keep repeating Hello", but we observe that relying solely on natural instructions limits output length, which is bounded by the maximum length of the LLM's supervised finetuning (SFT) data. To overcome this limitation, we propose poisoning-based DoS (P-DoS) attacks for LLMs, demonstrating that injecting a single poisoned sample designed for DoS purposes can break the output length limit. For example, a poisoned sample can successfully attack GPT-4o and GPT-4o mini (via OpenAI's finetuning API) using less than $1, causing repeated outputs up to the maximum inference length (16K tokens, compared to 0.5K before poisoning). Additionally, we perform comprehensive ablation studies on open-source LLMs and extend our method to LLM agents, where attackers can control both the finetuning dataset and algorithm. Our findings underscore the urgent need for defenses against P-DoS attacks to secure LLMs. Our code is available at this https URL.</li>
</ul>

<h3>Title: Enhancing JEPAs with Spatial Conditioning: Robust and Efficient Representation Learning</h3>
<ul>
<li><strong>Authors: </strong>Etai Littwin, Vimal Thilak, Anand Gopalakrishnan</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.10773">https://arxiv.org/abs/2410.10773</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.10773">https://arxiv.org/pdf/2410.10773</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.10773]] Enhancing JEPAs with Spatial Conditioning: Robust and Efficient Representation Learning(https://arxiv.org/abs/2410.10773)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Image-based Joint-Embedding Predictive Architecture (IJEPA) offers an attractive alternative to Masked Autoencoder (MAE) for representation learning using the Masked Image Modeling framework. IJEPA drives representations to capture useful semantic information by predicting in latent rather than input space. However, IJEPA relies on carefully designed context and target windows to avoid representational collapse. The encoder modules in IJEPA cannot adaptively modulate the type of predicted and/or target features based on the feasibility of the masked prediction task as they are not given sufficient information of both context and targets. Based on the intuition that in natural images, information has a strong spatial bias with spatially local regions being highly predictive of one another compared to distant ones. We condition the target encoder and context encoder modules in IJEPA with positions of context and target windows respectively. Our "conditional" encoders show performance gains on several image classification benchmark datasets, improved robustness to context window size and sample-efficiency during pretraining.</li>
</ul>

<h3>Title: Cavia: Camera-controllable Multi-view Video Diffusion with View-Integrated Attention</h3>
<ul>
<li><strong>Authors: </strong>Dejia Xu, Yifan Jiang, Chen Huang, Liangchen Song, Thorsten Gernoth, Liangliang Cao, Zhangyang Wang, Hao Tang</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.10774">https://arxiv.org/abs/2410.10774</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.10774">https://arxiv.org/pdf/2410.10774</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.10774]] Cavia: Camera-controllable Multi-view Video Diffusion with View-Integrated Attention(https://arxiv.org/abs/2410.10774)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>In recent years there have been remarkable breakthroughs in image-to-video generation. However, the 3D consistency and camera controllability of generated frames have remained unsolved. Recent studies have attempted to incorporate camera control into the generation process, but their results are often limited to simple trajectories or lack the ability to generate consistent videos from multiple distinct camera paths for the same scene. To address these limitations, we introduce Cavia, a novel framework for camera-controllable, multi-view video generation, capable of converting an input image into multiple spatiotemporally consistent videos. Our framework extends the spatial and temporal attention modules into view-integrated attention modules, improving both viewpoint and temporal consistency. This flexible design allows for joint training with diverse curated data sources, including scene-level static videos, object-level synthetic multi-view dynamic videos, and real-world monocular dynamic videos. To our best knowledge, Cavia is the first of its kind that allows the user to precisely specify camera motion while obtaining object motion. Extensive experiments demonstrate that Cavia surpasses state-of-the-art methods in terms of geometric consistency and perceptual quality. Project Page: this https URL</li>
</ul>

<h3>Title: Browsing without Third-Party Cookies: What Do You See?</h3>
<ul>
<li><strong>Authors: </strong>Maxwell Lin, Shihan Lin, Helen Wu, Karen Wang, Xiaowei Yang</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.10775">https://arxiv.org/abs/2410.10775</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.10775">https://arxiv.org/pdf/2410.10775</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.10775]] Browsing without Third-Party Cookies: What Do You See?(https://arxiv.org/abs/2410.10775)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, protect</a></li>
<li><strong>Abstract: </strong>Third-party web cookies are often used for privacy-invasive behavior tracking. Partly due to privacy concerns, browser vendors have started to block all third-party cookies in recent years. To understand the effects of such third-party cookieless browsing, we crawled and measured the top 10,000 Tranco websites. We developed a framework to remove third-party cookies and analyze the differences between the appearance of web pages with and without these cookies. We find that disabling third-party cookies has no substantial effect on website appearance including layouts, text, and images. This validates the industry-wide shift towards cookieless browsing as a way to protect user privacy without compromising on the user experience.</li>
</ul>

<h3>Title: UniMatch V2: Pushing the Limit of Semi-Supervised Semantic Segmentation</h3>
<ul>
<li><strong>Authors: </strong>Lihe Yang, Zhen Zhao, Hengshuang Zhao</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.10777">https://arxiv.org/abs/2410.10777</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.10777">https://arxiv.org/pdf/2410.10777</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.10777]] UniMatch V2: Pushing the Limit of Semi-Supervised Semantic Segmentation(https://arxiv.org/abs/2410.10777)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>Semi-supervised semantic segmentation (SSS) aims at learning rich visual knowledge from cheap unlabeled images to enhance semantic segmentation capability. Among recent works, UniMatch improves its precedents tremendously by amplifying the practice of weak-to-strong consistency regularization. Subsequent works typically follow similar pipelines and propose various delicate designs. Despite the achieved progress, strangely, even in this flourishing era of numerous powerful vision models, almost all SSS works are still sticking to 1) using outdated ResNet encoders with small-scale ImageNet-1K pre-training, and 2) evaluation on simple Pascal and Cityscapes datasets. In this work, we argue that, it is necessary to switch the baseline of SSS from ResNet-based encoders to more capable ViT-based encoders (e.g., DINOv2) that are pre-trained on massive data. A simple update on the encoder (even using 2x fewer parameters) can bring more significant improvement than careful method designs. Built on this competitive baseline, we present our upgraded and simplified UniMatch V2, inheriting the core spirit of weak-to-strong consistency from V1, but requiring less training cost and providing consistently better results. Additionally, witnessing the gradually saturated performance on Pascal and Cityscapes, we appeal that we should focus on more challenging benchmarks with complex taxonomy, such as ADE20K and COCO datasets. Code, models, and logs of all reported values, are available at this https URL.</li>
</ul>

<h3>Title: ControlMM: Controllable Masked Motion Generation</h3>
<ul>
<li><strong>Authors: </strong>Ekkasit Pinyoanuntapong, Muhammad Usama Saleem, Korrawe Karunratanakul, Pu Wang, Hongfei Xue, Chen Chen, Chuan Guo, Junli Cao, Jian Ren, Sergey Tulyakov</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.10780">https://arxiv.org/abs/2410.10780</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.10780">https://arxiv.org/pdf/2410.10780</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.10780]] ControlMM: Controllable Masked Motion Generation(https://arxiv.org/abs/2410.10780)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, generative</a></li>
<li><strong>Abstract: </strong>Recent advances in motion diffusion models have enabled spatially controllable text-to-motion generation. However, despite achieving acceptable control precision, these models suffer from generation speed and fidelity limitations. To address these challenges, we propose ControlMM, a novel approach incorporating spatial control signals into the generative masked motion model. ControlMM achieves real-time, high-fidelity, and high-precision controllable motion generation simultaneously. Our approach introduces two key innovations. First, we propose masked consistency modeling, which ensures high-fidelity motion generation via random masking and reconstruction, while minimizing the inconsistency between the input control signals and the extracted control signals from the generated motion. To further enhance control precision, we introduce inference-time logit editing, which manipulates the predicted conditional motion distribution so that the generated motion, sampled from the adjusted distribution, closely adheres to the input control signals. During inference, ControlMM enables parallel and iterative decoding of multiple motion tokens, allowing for high-speed motion generation. Extensive experiments show that, compared to the state of the art, ControlMM delivers superior results in motion quality, with better FID scores (0.061 vs 0.271), and higher control precision (average error 0.0091 vs 0.0108). ControlMM generates motions 20 times faster than diffusion-based methods. Additionally, ControlMM unlocks diverse applications such as any joint any frame control, body part timeline control, and obstacle avoidance. Video visualization can be found at this https URL</li>
</ul>

<h3>Title: 3DArticCyclists: Generating Simulated Dynamic 3D Cyclists for Human-Object Interaction (HOI) and Autonomous Driving Applications</h3>
<ul>
<li><strong>Authors: </strong>Eduardo R. Corral-Soto, Yang Liu, Tongtong Cao, Yuan Ren, Liu Bingbing</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.HC</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.10782">https://arxiv.org/abs/2410.10782</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.10782">https://arxiv.org/pdf/2410.10782</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.10782]] 3DArticCyclists: Generating Simulated Dynamic 3D Cyclists for Human-Object Interaction (HOI) and Autonomous Driving Applications(https://arxiv.org/abs/2410.10782)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>Human-object interaction (HOI) and human-scene interaction (HSI) are crucial for human-centric scene understanding applications in Embodied Artificial Intelligence (EAI), robotics, and augmented reality (AR). A common limitation faced in these research areas is the data scarcity problem: insufficient labeled human-scene object pairs on the input images, and limited interaction complexity and granularity between them. Recent HOI and HSI methods have addressed this issue by generating dynamic interactions with rigid objects. But more complex dynamic interactions such as a human rider pedaling an articulated bicycle have been unexplored. To address this limitation, and to enable research on complex dynamic human-articulated object interactions, in this paper we propose a method to generate simulated 3D dynamic cyclist assets and interactions. We designed a methodology for creating a new part-based multi-view articulated synthetic 3D bicycle dataset that we call 3DArticBikes that can be used to train NeRF and 3DGS-based 3D reconstruction methods. We then propose a 3DGS-based parametric bicycle composition model to assemble 8-DoF pose-controllable 3D bicycles. Finally, using dynamic information from cyclist videos, we build a complete synthetic dynamic 3D cyclist (rider pedaling a bicycle) by re-posing a selectable synthetic 3D person while automatically placing the rider onto one of our new articulated 3D bicycles using a proposed 3D Keypoint optimization-based Inverse Kinematics pose refinement. We present both, qualitative and quantitative results where we compare our generated cyclists against those from a recent stable diffusion-based method.</li>
</ul>

<h3>Title: Condition-Aware Multimodal Fusion for Robust Semantic Perception of Driving Scenes</h3>
<ul>
<li><strong>Authors: </strong>Tim Broedermann, Christos Sakaridis, Yuqian Fu, Luc Van Gool</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.10791">https://arxiv.org/abs/2410.10791</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.10791">https://arxiv.org/pdf/2410.10791</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.10791]] Condition-Aware Multimodal Fusion for Robust Semantic Perception of Driving Scenes(https://arxiv.org/abs/2410.10791)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, segmentation</a></li>
<li><strong>Abstract: </strong>Leveraging multiple sensors is crucial for robust semantic perception in autonomous driving, as each sensor type has complementary strengths and weaknesses. However, existing sensor fusion methods often treat sensors uniformly across all conditions, leading to suboptimal performance. By contrast, we propose a novel, condition-aware multimodal fusion approach for robust semantic perception of driving scenes. Our method, CAFuser uses an RGB camera input to classify environmental conditions and generate a Condition Token that guides the fusion of multiple sensor modalities. We further newly introduce modality-specific feature adapters to align diverse sensor inputs into a shared latent space, enabling efficient integration with a single and shared pre-trained backbone. By dynamically adapting sensor fusion based on the actual condition, our model significantly improves robustness and accuracy, especially in adverse-condition scenarios. We set the new state of the art with CAFuser on the MUSES dataset with 59.7 PQ for multimodal panoptic segmentation and 78.2 mIoU for semantic segmentation, ranking first on the public benchmarks.</li>
</ul>

<h3>Title: Semantic Image Inversion and Editing using Rectified Stochastic Differential Equations</h3>
<ul>
<li><strong>Authors: </strong>Litu Rout, Yujia Chen, Nataniel Ruiz, Constantine Caramanis, Sanjay Shakkottai, Wen-Sheng Chu</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CV, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.10792">https://arxiv.org/abs/2410.10792</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.10792">https://arxiv.org/pdf/2410.10792</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.10792]] Semantic Image Inversion and Editing using Rectified Stochastic Differential Equations(https://arxiv.org/abs/2410.10792)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, generative</a></li>
<li><strong>Abstract: </strong>Generative models transform random noise into images; their inversion aims to transform images back to structured noise for recovery and editing. This paper addresses two key tasks: (i) inversion and (ii) editing of a real image using stochastic equivalents of rectified flow models (such as Flux). Although Diffusion Models (DMs) have recently dominated the field of generative modeling for images, their inversion presents faithfulness and editability challenges due to nonlinearities in drift and diffusion. Existing state-of-the-art DM inversion approaches rely on training of additional parameters or test-time optimization of latent variables; both are expensive in practice. Rectified Flows (RFs) offer a promising alternative to diffusion models, yet their inversion has been underexplored. We propose RF inversion using dynamic optimal control derived via a linear quadratic regulator. We prove that the resulting vector field is equivalent to a rectified stochastic differential equation. Additionally, we extend our framework to design a stochastic sampler for Flux. Our inversion method allows for state-of-the-art performance in zero-shot inversion and editing, outperforming prior works in stroke-to-image synthesis and semantic image editing, with large-scale human evaluations confirming user preference.</li>
</ul>

<h3>Title: Context-Parametric Inversion: Why Instruction Finetuning May Not Actually Improve Context Reliance</h3>
<ul>
<li><strong>Authors: </strong>Sachin Goyal, Christina Baek, J. Zico Kolter, Aditi Raghunathan</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.10796">https://arxiv.org/abs/2410.10796</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.10796">https://arxiv.org/pdf/2410.10796</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.10796]] Context-Parametric Inversion: Why Instruction Finetuning May Not Actually Improve Context Reliance(https://arxiv.org/abs/2410.10796)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large language models are instruction-finetuned to enhance their ability to follow user instructions and process the input context. However, even state-of-the-art models often struggle to follow the instruction, especially when the input context is not aligned with the model's parametric knowledge. This manifests as various failures, such as hallucinations where the responses are outdated, biased or contain unverified facts. In this work, we try to understand the underlying reason for this poor context reliance, especially after instruction tuning. We observe an intriguing phenomenon: during instruction tuning, the context reliance initially increases as expected, but then gradually decreases as instruction finetuning progresses. We call this phenomenon context-parametric inversion and observe it across multiple general purpose instruction tuning datasets like TULU, Alpaca and Ultrachat, as well as model families such as Llama, Mistral and Pythia. In a simple theoretical setup, we isolate why context-parametric inversion occurs along the gradient descent trajectory of instruction finetuning. We tie this phenomena to examples in the instruction finetuning data mixture where the input context provides information that is already present in the model's parametric knowledge. Our analysis suggests natural mitigation strategies that provide some limited gains, while also validating our theoretical insights. We hope that our work serves as a starting point in addressing this failure mode in a staple part of LLM training.</li>
</ul>

<h3>Title: MMAR: Towards Lossless Multi-Modal Auto-Regressive Prababilistic Modeling</h3>
<ul>
<li><strong>Authors: </strong>Jian Yang, Dacheng Yin, Yizhou Zhou, Fengyun Rao, Wei Zhai, Yang Cao, Zheng-Jun Zha</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.10798">https://arxiv.org/abs/2410.10798</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.10798">https://arxiv.org/pdf/2410.10798</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.10798]] MMAR: Towards Lossless Multi-Modal Auto-Regressive Prababilistic Modeling(https://arxiv.org/abs/2410.10798)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, large language model</a></li>
<li><strong>Abstract: </strong>Recent advancements in multi-modal large language models have propelled the development of joint probabilistic models capable of both image understanding and generation. However, we have identifed that recent methods inevitably suffer from loss of image information during understanding task, due to either image discretization or diffusion denoising steps. To address this issue, we propose a novel Multi-Modal Auto-Regressive (MMAR) probabilistic modeling framework. Unlike discretization line of method, MMAR takes in continuous-valued image tokens to avoid information loss. Differing from diffusion-based approaches, we disentangle the diffusion process from auto-regressive backbone model by employing a light-weight diffusion head on top each auto-regressed image patch embedding. In this way, when the model transits from image generation to understanding through text generation, the backbone model's hidden representation of the image is not limited to the last denoising step. To successfully train our method, we also propose a theoretically proven technique that addresses the numerical stability issue and a training strategy that balances the generation and understanding task goals. Through extensive evaluations on 18 image understanding benchmarks, MMAR demonstrates much more superior performance than other joint multi-modal models, matching the method that employs pretrained CLIP vision encoder, meanwhile being able to generate high quality images at the same time. We also showed that our method is scalable with larger data and model size.</li>
</ul>

<h3>Title: Towards Foundation Models for 3D Vision: How Close Are We?</h3>
<ul>
<li><strong>Authors: </strong>Yiming Zuo, Karhan Kayan, Maggie Wang, Kevin Jeon, Jia Deng, Thomas L. Griffiths</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.10799">https://arxiv.org/abs/2410.10799</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.10799">https://arxiv.org/pdf/2410.10799</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.10799]] Towards Foundation Models for 3D Vision: How Close Are We?(https://arxiv.org/abs/2410.10799)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, transformer</a></li>
<li><strong>Abstract: </strong>Building a foundation model for 3D vision is a complex challenge that remains unsolved. Towards that goal, it is important to understand the 3D reasoning capabilities of current models as well as identify the gaps between these models and humans. Therefore, we construct a new 3D visual understanding benchmark that covers fundamental 3D vision tasks in the Visual Question Answering (VQA) format. We evaluate state-of-the-art Vision-Language Models (VLMs), specialized models, and human subjects on it. Our results show that VLMs generally perform poorly, while the specialized models are accurate but not robust, failing under geometric perturbations. In contrast, human vision continues to be the most reliable 3D visual system. We further demonstrate that neural networks align more closely with human 3D vision mechanisms compared to classical computer vision methods, and Transformer-based networks such as ViT align more closely with human 3D vision mechanisms than CNNs. We hope our study will benefit the future development of foundation models for 3D vision.</li>
</ul>

<h3>Title: Mix Data or Merge Models? Optimizing for Diverse Multi-Task Learning</h3>
<ul>
<li><strong>Authors: </strong>Aakanksha, Arash Ahmadian, Seraphina Goldfarb-Tarrant, Beyza Ermis, Marzieh Fadaee, Sara Hooker</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.10801">https://arxiv.org/abs/2410.10801</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.10801">https://arxiv.org/pdf/2410.10801</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.10801]] Mix Data or Merge Models? Optimizing for Diverse Multi-Task Learning(https://arxiv.org/abs/2410.10801)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large Language Models (LLMs) have been adopted and deployed worldwide for a broad variety of applications. However, ensuring their safe use remains a significant challenge. Preference training and safety measures often overfit to harms prevalent in Western-centric datasets, and safety protocols frequently fail to extend to multilingual settings. In this work, we explore model merging in a diverse multi-task setting, combining safety and general-purpose tasks within a multilingual context. Each language introduces unique and varied learning challenges across tasks. We find that objective-based merging is more effective than mixing data, with improvements of up to 8% and 10% in general performance and safety respectively. We also find that language-based merging is highly effective -- by merging monolingually fine-tuned models, we achieve a 4% increase in general performance and 7% reduction in harm across all languages on top of the data mixtures method using the same available data. Overall, our comprehensive study of merging approaches provides a useful framework for building strong and safe multilingual models.</li>
</ul>

<h3>Title: Boosting Camera Motion Control for Video Diffusion Transformers</h3>
<ul>
<li><strong>Authors: </strong>Soon Yau Cheong, Duygu Ceylan, Armin Mustafa, Andrew Gilbert, Chun-Hao Paul Huang</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.10802">https://arxiv.org/abs/2410.10802</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.10802">https://arxiv.org/pdf/2410.10802</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.10802]] Boosting Camera Motion Control for Video Diffusion Transformers(https://arxiv.org/abs/2410.10802)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, transformer</a></li>
<li><strong>Abstract: </strong>Recent advancements in diffusion models have significantly enhanced the quality of video generation. However, fine-grained control over camera pose remains a challenge. While U-Net-based models have shown promising results for camera control, transformer-based diffusion models (DiT)-the preferred architecture for large-scale video generation - suffer from severe degradation in camera motion accuracy. In this paper, we investigate the underlying causes of this issue and propose solutions tailored to DiT architectures. Our study reveals that camera control performance depends heavily on the choice of conditioning methods rather than camera pose representations that is commonly believed. To address the persistent motion degradation in DiT, we introduce Camera Motion Guidance (CMG), based on classifier-free guidance, which boosts camera control by over 400%. Additionally, we present a sparse camera control pipeline, significantly simplifying the process of specifying camera poses for long videos. Our method universally applies to both U-Net and DiT models, offering improved camera control for video generation tasks.</li>
</ul>

<h3>Title: TrajDiffuse: A Conditional Diffusion Model for Environment-Aware Trajectory Prediction</h3>
<ul>
<li><strong>Authors: </strong>Qingze (Tony)Liu, Danrui Li, Samuel S. Sohn, Sejong Yoon, Mubbasir Kapadia, Vladimir Pavlovic</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.10804">https://arxiv.org/abs/2410.10804</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.10804">https://arxiv.org/pdf/2410.10804</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.10804]] TrajDiffuse: A Conditional Diffusion Model for Environment-Aware Trajectory Prediction(https://arxiv.org/abs/2410.10804)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>Accurate prediction of human or vehicle trajectories with good diversity that captures their stochastic nature is an essential task for many applications. However, many trajectory prediction models produce unreasonable trajectory samples that focus on improving diversity or accuracy while neglecting other key requirements, such as collision avoidance with the surrounding environment. In this work, we propose TrajDiffuse, a planning-based trajectory prediction method using a novel guided conditional diffusion model. We form the trajectory prediction problem as a denoising impaint task and design a map-based guidance term for the diffusion process. TrajDiffuse is able to generate trajectory predictions that match or exceed the accuracy and diversity of the SOTA, while adhering almost perfectly to environmental constraints. We demonstrate the utility of our model through experiments on the nuScenes and PFSD datasets and provide an extensive benchmark analysis against the SOTA methods.</li>
</ul>

<h3>Title: HART: Efficient Visual Generation with Hybrid Autoregressive Transformer</h3>
<ul>
<li><strong>Authors: </strong>Haotian Tang, Yecheng Wu, Shang Yang, Enze Xie, Junsong Chen, Junyu Chen, Zhuoyang Zhang, Han Cai, Yao Lu, Song Han</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.10812">https://arxiv.org/abs/2410.10812</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.10812">https://arxiv.org/pdf/2410.10812</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.10812]] HART: Efficient Visual Generation with Hybrid Autoregressive Transformer(https://arxiv.org/abs/2410.10812)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, transformer</a></li>
<li><strong>Abstract: </strong>We introduce Hybrid Autoregressive Transformer (HART), an autoregressive (AR) visual generation model capable of directly generating 1024x1024 images, rivaling diffusion models in image generation quality. Existing AR models face limitations due to the poor image reconstruction quality of their discrete tokenizers and the prohibitive training costs associated with generating 1024px images. To address these challenges, we present the hybrid tokenizer, which decomposes the continuous latents from the autoencoder into two components: discrete tokens representing the big picture and continuous tokens representing the residual components that cannot be represented by the discrete tokens. The discrete component is modeled by a scalable-resolution discrete AR model, while the continuous component is learned with a lightweight residual diffusion module with only 37M parameters. Compared with the discrete-only VAR tokenizer, our hybrid approach improves reconstruction FID from 2.11 to 0.30 on MJHQ-30K, leading to a 31% generation FID improvement from 7.85 to 5.38. HART also outperforms state-of-the-art diffusion models in both FID and CLIP score, with 4.5-7.7x higher throughput and 6.9-13.4x lower MACs. Our code is open sourced at this https URL.</li>
</ul>

<h3>Title: LongMemEval: Benchmarking Chat Assistants on Long-Term Interactive Memory</h3>
<ul>
<li><strong>Authors: </strong>Di Wu, Hongwei Wang, Wenhao Yu, Yuwei Zhang, Kai-Wei Chang, Dong Yu</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.10813">https://arxiv.org/abs/2410.10813</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.10813">https://arxiv.org/pdf/2410.10813</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.10813]] LongMemEval: Benchmarking Chat Assistants on Long-Term Interactive Memory(https://arxiv.org/abs/2410.10813)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction, large language model</a></li>
<li><strong>Abstract: </strong>Recent large language model (LLM)-driven chat assistant systems have integrated memory components to track user-assistant chat histories, enabling more accurate and personalized responses. However, their long-term memory capabilities in sustained interactions remain underexplored. This paper introduces LongMemEval, a comprehensive benchmark designed to evaluate five core long-term memory abilities of chat assistants: information extraction, multi-session reasoning, temporal reasoning, knowledge updates, and abstention. With 500 meticulously curated questions embedded within freely scalable user-assistant chat histories, LongMemEval presents a significant challenge to existing long-term memory systems, with commercial chat assistants and long-context LLMs showing 30% accuracy drop on memorizing information across sustained interactions. We then present a unified framework that breaks down the long-term memory design into four design choices across the indexing, retrieval, and reading stages. Built upon key experimental insights, we propose several memory designs including session decomposition for optimizing value granularity, fact-augmented key expansion for enhancing the index structure, and time-aware query expansion for refining the search scope. Experiment results show that these optimizations greatly improve both memory recall and downstream question answering on LongMemEval. Overall, our study provides valuable resources and guidance for advancing the long-term memory capabilities of LLM-based chat assistants, paving the way toward more personalized and reliable conversational AI.</li>
</ul>

<h3>Title: Your Mixture-of-Experts LLM Is Secretly an Embedding Model For Free</h3>
<ul>
<li><strong>Authors: </strong>Ziyue Li, Tianyi Zhou</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.10814">https://arxiv.org/abs/2410.10814</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.10814">https://arxiv.org/pdf/2410.10814</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.10814]] Your Mixture-of-Experts LLM Is Secretly an Embedding Model For Free(https://arxiv.org/abs/2410.10814)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, large language model</a></li>
<li><strong>Abstract: </strong>While large language models (LLMs) excel on generation tasks, their decoder-only architecture often limits their potential as embedding models if no further representation finetuning is applied. Does this contradict their claim of generalists? To answer the question, we take a closer look at Mixture-of-Experts (MoE) LLMs. Our study shows that the expert routers in MoE LLMs can serve as an off-the-shelf embedding model with promising performance on a diverse class of embedding-focused tasks, without requiring any finetuning. Moreover, our extensive analysis shows that the MoE routing weights (RW) is complementary to the hidden state (HS) of LLMs, a widely-used embedding. Compared to HS, we find that RW is more robust to the choice of prompts and focuses on high-level semantics. Motivated by the analysis, we propose MoEE combining RW and HS, which achieves better performance than using either separately. Our exploration of their combination and prompting strategy shed several novel insights, e.g., a weighted sum of RW and HS similarities outperforms the similarity on their concatenation. Our experiments are conducted on 6 embedding tasks with 20 datasets from the Massive Text Embedding Benchmark (MTEB). The results demonstrate the significant improvement brought by MoEE to LLM-based embedding without further finetuning.</li>
</ul>

<h3>Title: Depth Any Video with Scalable Synthetic Data</h3>
<ul>
<li><strong>Authors: </strong>Honghui Yang, Di Huang, Wei Yin, Chunhua Shen, Haifeng Liu, Xiaofei He, Binbin Lin, Wanli Ouyang, Tong He</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.10815">https://arxiv.org/abs/2410.10815</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.10815">https://arxiv.org/pdf/2410.10815</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.10815]] Depth Any Video with Scalable Synthetic Data(https://arxiv.org/abs/2410.10815)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, diffusion, generative</a></li>
<li><strong>Abstract: </strong>Video depth estimation has long been hindered by the scarcity of consistent and scalable ground truth data, leading to inconsistent and unreliable results. In this paper, we introduce Depth Any Video, a model that tackles the challenge through two key innovations. First, we develop a scalable synthetic data pipeline, capturing real-time video depth data from diverse synthetic environments, yielding 40,000 video clips of 5-second duration, each with precise depth annotations. Second, we leverage the powerful priors of generative video diffusion models to handle real-world videos effectively, integrating advanced techniques such as rotary position encoding and flow matching to further enhance flexibility and efficiency. Unlike previous models, which are limited to fixed-length video sequences, our approach introduces a novel mixed-duration training strategy that handles videos of varying lengths and performs robustly across different frame rates-even on single frames. At inference, we propose a depth interpolation method that enables our model to infer high-resolution video depth across sequences of up to 150 frames. Our model outperforms all previous generative depth models in terms of spatial accuracy and temporal consistency.</li>
</ul>

<h3>Title: When Does Perceptual Alignment Benefit Vision Representations?</h3>
<ul>
<li><strong>Authors: </strong>Shobhita Sundaram, Stephanie Fu, Lukas Muttenthaler, Netanel Y. Tamir, Lucy Chai, Simon Kornblith, Trevor Darrell, Phillip Isola</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.10817">https://arxiv.org/abs/2410.10817</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.10817">https://arxiv.org/pdf/2410.10817</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.10817]] When Does Perceptual Alignment Benefit Vision Representations?(https://arxiv.org/abs/2410.10817)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>Humans judge perceptual similarity according to diverse visual attributes, including scene layout, subject location, and camera pose. Existing vision models understand a wide range of semantic abstractions but improperly weigh these attributes and thus make inferences misaligned with human perception. While vision representations have previously benefited from alignment in contexts like image generation, the utility of perceptually aligned representations in more general-purpose settings remains unclear. Here, we investigate how aligning vision model representations to human perceptual judgments impacts their usability across diverse computer vision tasks. We finetune state-of-the-art models on human similarity judgments for image triplets and evaluate them across standard vision benchmarks. We find that aligning models to perceptual judgments yields representations that improve upon the original backbones across many downstream tasks, including counting, segmentation, depth estimation, instance retrieval, and retrieval-augmented generation. In addition, we find that performance is widely preserved on other tasks, including specialized out-of-distribution domains such as in medical imaging and 3D environment frames. Our results suggest that injecting an inductive bias about human perceptual knowledge into vision models can contribute to better representations.</li>
</ul>

<h3>Title: DuoAttention: Efficient Long-Context LLM Inference with Retrieval and Streaming Heads</h3>
<ul>
<li><strong>Authors: </strong>Guangxuan Xiao, Jiaming Tang, Jingwei Zuo, Junxian Guo, Shang Yang, Haotian Tang, Yao Fu, Song Han</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.10819">https://arxiv.org/abs/2410.10819</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.10819">https://arxiv.org/pdf/2410.10819</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.10819]] DuoAttention: Efficient Long-Context LLM Inference with Retrieval and Streaming Heads(https://arxiv.org/abs/2410.10819)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Deploying long-context large language models (LLMs) is essential but poses significant computational and memory challenges. Caching all Key and Value (KV) states across all attention heads consumes substantial memory. Existing KV cache pruning methods either damage the long-context capabilities of LLMs or offer only limited efficiency improvements. In this paper, we identify that only a fraction of attention heads, a.k.a, Retrieval Heads, are critical for processing long contexts and require full attention across all tokens. In contrast, all other heads, which primarily focus on recent tokens and attention sinks--referred to as Streaming Heads--do not require full attention. Based on this insight, we introduce DuoAttention, a framework that only applies a full KV cache to retrieval heads while using a light-weight, constant-length KV cache for streaming heads, which reduces both LLM's decoding and pre-filling memory and latency without compromising its long-context abilities. DuoAttention uses a lightweight, optimization-based algorithm with synthetic data to identify retrieval heads accurately. Our method significantly reduces long-context inference memory by up to 2.55x for MHA and 1.67x for GQA models while speeding up decoding by up to 2.18x and 1.50x and accelerating pre-filling by up to 1.73x and 1.63x for MHA and GQA models, respectively, with minimal accuracy loss compared to full attention. Notably, combined with quantization, DuoAttention enables Llama-3-8B decoding with 3.3 million context length on a single A100 GPU. Code is provided in this https URL.</li>
</ul>

<h3>Title: Tex4D: Zero-shot 4D Scene Texturing with Video Diffusion Models</h3>
<ul>
<li><strong>Authors: </strong>Jingzhi Bao, Xueting Li, Ming-Hsuan Yang</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.10821">https://arxiv.org/abs/2410.10821</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.10821">https://arxiv.org/pdf/2410.10821</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.10821]] Tex4D: Zero-shot 4D Scene Texturing with Video Diffusion Models(https://arxiv.org/abs/2410.10821)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>3D meshes are widely used in computer vision and graphics for their efficiency in animation and minimal memory use, playing a crucial role in movies, games, AR, and VR. However, creating temporally consistent and realistic textures for mesh sequences remains labor-intensive for professional artists. On the other hand, while video diffusion models excel at text-driven video generation, they often lack 3D geometry awareness and struggle with achieving multi-view consistent texturing for 3D meshes. In this work, we present Tex4D, a zero-shot approach that integrates inherent 3D geometry knowledge from mesh sequences with the expressiveness of video diffusion models to produce multi-view and temporally consistent 4D textures. Given an untextured mesh sequence and a text prompt as inputs, our method enhances multi-view consistency by synchronizing the diffusion process across different views through latent aggregation in the UV space. To ensure temporal consistency, we leverage prior knowledge from a conditional video generation model for texture synthesis. However, straightforwardly combining the video diffusion model and the UV texture aggregation leads to blurry results. We analyze the underlying causes and propose a simple yet effective modification to the DDIM sampling process to address this issue. Additionally, we introduce a reference latent texture to strengthen the correlation between frames during the denoising process. To the best of our knowledge, Tex4D is the first method specifically designed for 4D scene texturing. Extensive experiments demonstrate its superiority in producing multi-view and multi-frame consistent videos based on untextured mesh sequences.</li>
</ul>

<button id="copy">Copy All</button>
</article>
<script src="../../javascript/clipboard.min.js"></script>
<script src="../../javascript/clipboard.js"></script>
