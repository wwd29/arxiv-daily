<link rel="stylesheet" href="../../css/markdown.css" />
<article class="markdown-body">
<h2>secure</h2>
<h3>Title: AutoFHE: Automated Adaption of CNNs for Efficient Evaluation over FHE. (arXiv:2310.08012v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.08012">http://arxiv.org/abs/2310.08012</a></li>
<li>Code URL: https://github.com/human-analysis/AutoFHE</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.08012]] AutoFHE: Automated Adaption of CNNs for Efficient Evaluation over FHE(http://arxiv.org/abs/2310.08012)</code></li>
<li>Summary: <p>Secure inference of deep convolutional neural networks (CNNs) under RNS-CKKS
involves polynomial approximation of unsupported non-linear activation
functions. However, existing approaches have three main limitations: 1)
Inflexibility: The polynomial approximation and associated homomorphic
evaluation architecture are customized manually for each CNN architecture and
do not generalize to other networks. 2) Suboptimal Approximation: Each
activation function is approximated instead of the function represented by the
CNN. 3) Restricted Design: Either high-degree or low-degree polynomial
approximations are used. The former retains high accuracy but slows down
inference due to bootstrapping operations, while the latter accelerates
ciphertext inference but compromises accuracy. To address these limitations, we
present AutoFHE, which automatically adapts standard CNNs for secure inference
under RNS-CKKS. The key idea is to adopt layerwise mixed-degree polynomial
activation functions, which are optimized jointly with the homomorphic
evaluation architecture in terms of the placement of bootstrapping operations.
The problem is modeled within a multi-objective optimization framework to
maximize accuracy and minimize the number of bootstrapping operations. AutoFHE
can be applied flexibly on any CNN architecture, and it provides diverse
solutions that span the trade-off between accuracy and latency. Experimental
evaluation over RNS-CKKS encrypted CIFAR datasets shows that AutoFHE
accelerates secure inference by $1.32\times$ to $1.8\times$ compared to methods
employing high-degree polynomials. It also improves accuracy by up to 2.56%
compared to methods using low-degree polynomials. Lastly, AutoFHE accelerates
inference and improves accuracy by $103\times$ and 3.46%, respectively,
compared to CNNs under TFHE.
</p></li>
</ul>

<h2>security</h2>
<h3>Title: Self-supervised visual learning for analyzing firearms trafficking activities on the Web. (arXiv:2310.07975v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.07975">http://arxiv.org/abs/2310.07975</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.07975]] Self-supervised visual learning for analyzing firearms trafficking activities on the Web(http://arxiv.org/abs/2310.07975)</code></li>
<li>Summary: <p>Automated visual firearms classification from RGB images is an important
real-world task with applications in public space security, intelligence
gathering and law enforcement investigations. When applied to images massively
crawled from the World Wide Web (including social media and dark Web sites), it
can serve as an important component of systems that attempt to identify
criminal firearms trafficking networks, by analyzing Big Data from open-source
intelligence. Deep Neural Networks (DNN) are the state-of-the-art methodology
for achieving this, with Convolutional Neural Networks (CNN) being typically
employed. The common transfer learning approach consists of pretraining on a
large-scale, generic annotated dataset for whole-image classification, such as
ImageNet-1k, and then finetuning the DNN on a smaller, annotated,
task-specific, downstream dataset for visual firearms classification. Neither
Visual Transformer (ViT) neural architectures nor Self-Supervised Learning
(SSL) approaches have been so far evaluated on this critical task. SSL
essentially consists of replacing the traditional supervised pretraining
objective with an unsupervised pretext task that does not require ground-truth
labels..
</p></li>
</ul>

<h3>Title: Beyond Sharing Weights in Decoupling Feature Learning Network for UAV RGB-Infrared Vehicle Re-Identification. (arXiv:2310.08026v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.08026">http://arxiv.org/abs/2310.08026</a></li>
<li>Code URL: https://github.com/moonstarL/UAV-CM-VeID</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.08026]] Beyond Sharing Weights in Decoupling Feature Learning Network for UAV RGB-Infrared Vehicle Re-Identification(http://arxiv.org/abs/2310.08026)</code></li>
<li>Summary: <p>Owing to the capacity of performing full-time target search, cross-modality
vehicle re-identification (Re-ID) based on unmanned aerial vehicle (UAV) is
gaining more attention in both video surveillance and public security. However,
this promising and innovative research has not been studied sufficiently due to
the data inadequacy issue. Meanwhile, the cross-modality discrepancy and
orientation discrepancy challenges further aggravate the difficulty of this
task. To this end, we pioneer a cross-modality vehicle Re-ID benchmark named
UAV Cross-Modality Vehicle Re-ID (UCM-VeID), containing 753 identities with
16015 RGB and 13913 infrared images. Moreover, to meet cross-modality
discrepancy and orientation discrepancy challenges, we present a hybrid weights
decoupling network (HWDNet) to learn the shared discriminative
orientation-invariant features. For the first challenge, we proposed a hybrid
weights siamese network with a well-designed weight restrainer and its
corresponding objective function to learn both modality-specific and modality
shared information. In terms of the second challenge, three effective
decoupling structures with two pretext tasks are investigated to learn
orientation-invariant feature. Comprehensive experiments are carried out to
validate the effectiveness of the proposed method. The dataset and codes will
be released at https://github.com/moonstarL/UAV-CM-VeID.
</p></li>
</ul>

<h3>Title: Combining Decentralized IDentifiers with Proof of Membership to Enable Trust in IoT Networks. (arXiv:2310.08163v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.08163">http://arxiv.org/abs/2310.08163</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.08163]] Combining Decentralized IDentifiers with Proof of Membership to Enable Trust in IoT Networks(http://arxiv.org/abs/2310.08163)</code></li>
<li>Summary: <p>The Self-Sovereign Identity (SSI) is a decentralized paradigm enabling full
control over the data used to build and prove the identity. In Internet of
Things networks with security requirements, the Self-Sovereign Identity can
play a key role and bring benefits with respect to centralized identity
solutions. The challenge is to make the SSI compatible with resource-constraint
IoT networks. In line with this objective, the paper proposes and discusses an
alternative (mutual) authentication process for IoT nodes under the same
administration domain. The main idea is to combine the Decentralized IDentifier
(DID)-based verification of private key ownership with the verification of a
proof that the DID belongs to an evolving trusted set. The solution is built
around the proof of membership notion. The paper analyzes two membership
solutions, a novel solution designed by the Authors based on Merkle trees and a
second one based on the adaptation of Boneh, Boyen and Shacham (BBS) group
signature scheme. The paper concludes with a performance estimation and a
comparative analysis.
</p></li>
</ul>

<h3>Title: Harnessing the Power of LLM to Support Binary Taint Analysis. (arXiv:2310.08275v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.08275">http://arxiv.org/abs/2310.08275</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.08275]] Harnessing the Power of LLM to Support Binary Taint Analysis(http://arxiv.org/abs/2310.08275)</code></li>
<li>Summary: <p>This paper proposes LATTE, the first static binary taint analysis that is
powered by a large language model (LLM). LATTE is superior to the state of the
art (e.g., Emtaint, Arbiter, Karonte) in three aspects. First, LATTE is fully
automated while prior static binary taint analyzers need rely on human
expertise to manually customize taint propagation rules and vulnerability
inspection rules. Second, LATTE is significantly effective in vulnerability
detection, demonstrated by our comprehensive evaluations. For example, LATTE
has found 37 new bugs in real-world firmware which the baselines failed to
find, and 7 of them have been assigned CVE numbers. Lastly, LATTE incurs
remarkably low engineering cost, making it a cost-efficient and scalable
solution for security researchers and practitioners. We strongly believe that
LATTE opens up a new direction to harness the recent advance in LLMs to improve
vulnerability analysis for binary programs.
</p></li>
</ul>

<h2>privacy</h2>
<h3>Title: Defending Our Privacy With Backdoors. (arXiv:2310.08320v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.08320">http://arxiv.org/abs/2310.08320</a></li>
<li>Code URL: https://github.com/D0miH/Defending-Our-Privacy-With-Backdoors</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.08320]] Defending Our Privacy With Backdoors(http://arxiv.org/abs/2310.08320)</code></li>
<li>Summary: <p>The proliferation of large AI models trained on uncurated, often sensitive
web-scraped data has raised significant privacy concerns. One of the concerns
is that adversaries can extract information about the training data using
privacy attacks. Unfortunately, the task of removing specific information from
the models without sacrificing performance is not straightforward and has
proven to be challenging. We propose a rather easy yet effective defense based
on backdoor attacks to remove private information such as names of individuals
from models, and focus in this work on text encoders. Specifically, through
strategic insertion of backdoors, we align the embeddings of sensitive phrases
with those of neutral terms-"a person" instead of the person's name. Our
empirical results demonstrate the effectiveness of our backdoor-based defense
on CLIP by assessing its performance using a specialized privacy attack for
zero-shot classifiers. Our approach provides not only a new "dual-use"
perspective on backdoor attacks, but also presents a promising avenue to
enhance the privacy of individuals within models trained on uncurated
web-scraped data.
</p></li>
</ul>

<h3>Title: A Transfer-Learning-Based Prognosis Prediction Paradigm that Bridges Data Distribution Shift across EMR Datasets. (arXiv:2310.07799v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.07799">http://arxiv.org/abs/2310.07799</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.07799]] A Transfer-Learning-Based Prognosis Prediction Paradigm that Bridges Data Distribution Shift across EMR Datasets(http://arxiv.org/abs/2310.07799)</code></li>
<li>Summary: <p>Due to the limited information about emerging diseases, symptoms are hard to
be noticed and recognized, so that the window for clinical intervention could
be ignored. An effective prognostic model is expected to assist doctors in
making right diagnosis and designing personalized treatment plan, so to
promptly prevent unfavorable outcomes. However, in the early stage of a
disease, limited data collection and clinical experiences, plus the concern out
of privacy and ethics, may result in restricted data availability for
reference, to the extent that even data labels are difficult to mark correctly.
In addition, Electronic Medical Record (EMR) data of different diseases or of
different sources of the same disease can prove to be having serious
cross-dataset feature misalignment problems, greatly mutilating the efficiency
of deep learning models. This article introduces a transfer learning method to
build a transition model from source dataset to target dataset. By way of
constraining the distribution shift of features generated in disparate domains,
domain-invariant features that are exclusively relative to downstream tasks are
captured, so to cultivate a unified domain-invariant encoder across various
task domains to achieve better feature representation. Experimental results of
several target tasks demonstrate that our proposed model outperforms competing
baseline methods and has higher rate of training convergence, especially in
dealing with limited data amount. A multitude of experiences have proven the
efficacy of our method to provide more accurate predictions concerning newly
emergent pandemics and other diseases.
</p></li>
</ul>

<h3>Title: Learning from Label Proportions: Bootstrapping Supervised Learners via Belief Propagation. (arXiv:2310.08056v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.08056">http://arxiv.org/abs/2310.08056</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.08056]] Learning from Label Proportions: Bootstrapping Supervised Learners via Belief Propagation(http://arxiv.org/abs/2310.08056)</code></li>
<li>Summary: <p>Learning from Label Proportions (LLP) is a learning problem where only
aggregate level labels are available for groups of instances, called bags,
during training, and the aim is to get the best performance at the
instance-level on the test data. This setting arises in domains like
advertising and medicine due to privacy considerations. We propose a novel
algorithmic framework for this problem that iteratively performs two main
steps. For the first step (Pseudo Labeling) in every iteration, we define a
Gibbs distribution over binary instance labels that incorporates a) covariate
information through the constraint that instances with similar covariates
should have similar labels and b) the bag level aggregated label. We then use
Belief Propagation (BP) to marginalize the Gibbs distribution to obtain pseudo
labels. In the second step (Embedding Refinement), we use the pseudo labels to
provide supervision for a learner that yields a better embedding. Further, we
iterate on the two steps again by using the second step's embeddings as new
covariates for the next iteration. In the final iteration, a classifier is
trained using the pseudo labels. Our algorithm displays strong gains against
several SOTA baselines (up to 15%) for the LLP Binary Classification problem on
various dataset types - tabular and Image. We achieve these improvements with
minimal computational overhead above standard supervised learning due to Belief
Propagation, for large bag sizes, even for a million samples.
</p></li>
</ul>

<h2>protect</h2>
<h3>Title: A Systematic Evaluation of Automated Tools for Side-Channel Vulnerabilities Detection in Cryptographic Libraries. (arXiv:2310.08153v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.08153">http://arxiv.org/abs/2310.08153</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.08153]] A Systematic Evaluation of Automated Tools for Side-Channel Vulnerabilities Detection in Cryptographic Libraries(http://arxiv.org/abs/2310.08153)</code></li>
<li>Summary: <p>To protect cryptographic implementations from side-channel vulnerabilities,
developers must adopt constant-time programming practices. As these can be
error-prone, many side-channel detection tools have been proposed. Despite
this, such vulnerabilities are still manually found in cryptographic libraries.
While a recent paper by Jancar et al. shows that developers rarely perform
side-channel detection, it is unclear if existing detection tools could have
found these vulnerabilities in the first place. To answer this question, we
surveyed the literature to build a classification of 34 side-channel detection
frameworks. The classification we offer compares multiple criteria, including
the methods used, the scalability of the analysis or the threat model
considered. We then built a unified common benchmark of representative
cryptographic operations on a selection of 5 promising detection tools. This
benchmark allows us to better compare the capabilities of each tool, and the
scalability of their analysis. Additionally, we offer a classification of
recently published side-channel vulnerabilities. We then test each of the
selected tools on benchmarks reproducing a subset of these vulnerabilities as
well as the context in which they appear. We find that existing tools can
struggle to find vulnerabilities for a variety of reasons, mainly the lack of
support for SIMD instructions, implicit flows, and internal secret generation.
Based on our findings, we develop a set of recommendations for the research
community and cryptographic library developers, with the goal to improve the
effectiveness of side-channel detection tools.
</p></li>
</ul>

<h2>defense</h2>
<h2>attack</h2>
<h3>Title: Samples on Thin Ice: Re-Evaluating Adversarial Pruning of Neural Networks. (arXiv:2310.08073v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.08073">http://arxiv.org/abs/2310.08073</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.08073]] Samples on Thin Ice: Re-Evaluating Adversarial Pruning of Neural Networks(http://arxiv.org/abs/2310.08073)</code></li>
<li>Summary: <p>Neural network pruning has shown to be an effective technique for reducing
the network size, trading desirable properties like generalization and
robustness to adversarial attacks for higher sparsity. Recent work has claimed
that adversarial pruning methods can produce sparse networks while also
preserving robustness to adversarial examples. In this work, we first
re-evaluate three state-of-the-art adversarial pruning methods, showing that
their robustness was indeed overestimated. We then compare pruned and dense
versions of the same models, discovering that samples on thin ice, i.e., closer
to the unpruned model's decision boundary, are typically misclassified after
pruning. We conclude by discussing how this intuition may lead to designing
more effective adversarial pruning methods in future work.
</p></li>
</ul>

<h3>Title: Fine-Grained Annotation for Face Anti-Spoofing. (arXiv:2310.08142v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.08142">http://arxiv.org/abs/2310.08142</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.08142]] Fine-Grained Annotation for Face Anti-Spoofing(http://arxiv.org/abs/2310.08142)</code></li>
<li>Summary: <p>Face anti-spoofing plays a critical role in safeguarding facial recognition
systems against presentation attacks. While existing deep learning methods show
promising results, they still suffer from the lack of fine-grained annotations,
which lead models to learn task-irrelevant or unfaithful features. In this
paper, we propose a fine-grained annotation method for face anti-spoofing.
Specifically, we first leverage the Segment Anything Model (SAM) to obtain
pixel-wise segmentation masks by utilizing face landmarks as point prompts. The
face landmarks provide segmentation semantics, which segments the face into
regions. We then adopt these regions as masks and assemble them into three
separate annotation maps: spoof, living, and background maps. Finally, we
combine three separate maps into a three-channel map as annotations for model
training. Furthermore, we introduce the Multi-Channel Region Exchange
Augmentation (MCREA) to diversify training data and reduce overfitting.
Experimental results demonstrate that our method outperforms existing
state-of-the-art approaches in both intra-dataset and cross-dataset
evaluations.
</p></li>
</ul>

<h3>Title: Improving Fast Minimum-Norm Attacks with Hyperparameter Optimization. (arXiv:2310.08177v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.08177">http://arxiv.org/abs/2310.08177</a></li>
<li>Code URL: https://github.com/pralab/HO-FMN</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.08177]] Improving Fast Minimum-Norm Attacks with Hyperparameter Optimization(http://arxiv.org/abs/2310.08177)</code></li>
<li>Summary: <p>Evaluating the adversarial robustness of machine learning models using
gradient-based attacks is challenging. In this work, we show that
hyperparameter optimization can improve fast minimum-norm attacks by automating
the selection of the loss function, the optimizer and the step-size scheduler,
along with the corresponding hyperparameters. Our extensive evaluation
involving several robust models demonstrates the improved efficacy of fast
minimum-norm attacks when hyper-up with hyperparameter optimization. We release
our open-source code at https://github.com/pralab/HO-FMN.
</p></li>
</ul>

<h3>Title: Invisible Threats: Backdoor Attack in OCR Systems. (arXiv:2310.08259v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.08259">http://arxiv.org/abs/2310.08259</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.08259]] Invisible Threats: Backdoor Attack in OCR Systems(http://arxiv.org/abs/2310.08259)</code></li>
<li>Summary: <p>Optical Character Recognition (OCR) is a widely used tool to extract text
from scanned documents. Today, the state-of-the-art is achieved by exploiting
deep neural networks. However, the cost of this performance is paid at the
price of system vulnerability. For instance, in backdoor attacks, attackers
compromise the training phase by inserting a backdoor in the victim's model
that will be activated at testing time by specific patterns while leaving the
overall model performance intact. This work proposes a backdoor attack for OCR
resulting in the injection of non-readable characters from malicious input
images. This simple but effective attack exposes the state-of-the-art OCR
weakness, making the extracted text correct to human eyes but simultaneously
unusable for the NLP application that uses OCR as a preprocessing step.
Experimental results show that the attacked models successfully output
non-readable characters for around 90% of the poisoned instances without
harming their performance for the remaining instances.
</p></li>
</ul>

<h3>Title: Deep Reinforcement Learning for Autonomous Cyber Operations: A Survey. (arXiv:2310.07745v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.07745">http://arxiv.org/abs/2310.07745</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.07745]] Deep Reinforcement Learning for Autonomous Cyber Operations: A Survey(http://arxiv.org/abs/2310.07745)</code></li>
<li>Summary: <p>The rapid increase in the number of cyber-attacks in recent years raises the
need for principled methods for defending networks against malicious actors.
Deep reinforcement learning (DRL) has emerged as a promising approach for
mitigating these attacks. However, while DRL has shown much potential for
cyber-defence, numerous challenges must be overcome before DRL can be applied
to autonomous cyber-operations (ACO) at scale. Principled methods are required
for environments that confront learners with very high-dimensional state
spaces, large multi-discrete action spaces, and adversarial learning. Recent
works have reported success in solving these problems individually. There have
also been impressive engineering efforts towards solving all three for
real-time strategy games. However, applying DRL to the full ACO problem remains
an open challenge. Here, we survey the relevant DRL literature and
conceptualize an idealised ACO-DRL agent. We provide: i.) A summary of the
domain properties that define the ACO problem; ii.) A comprehensive evaluation
of the extent to which domains used for benchmarking DRL approaches are
comparable to ACO; iii.) An overview of state-of-the-art approaches for scaling
DRL to domains that confront learners with the curse of dimensionality, and;
iv.) A survey and critique of current methods for limiting the exploitability
of agents within adversarial settings from the perspective of ACO. We conclude
with open research questions that we hope will motivate future directions for
researchers and practitioners working on ACO.
</p></li>
</ul>

<h3>Title: GRASP: Accelerating Shortest Path Attacks via Graph Attention. (arXiv:2310.07980v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.07980">http://arxiv.org/abs/2310.07980</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.07980]] GRASP: Accelerating Shortest Path Attacks via Graph Attention(http://arxiv.org/abs/2310.07980)</code></li>
<li>Summary: <p>Recent advances in machine learning (ML) have shown promise in aiding and
accelerating classical combinatorial optimization algorithms. ML-based speed
ups that aim to learn in an end to end manner (i.e., directly output the
solution) tend to trade off run time with solution quality. Therefore,
solutions that are able to accelerate existing solvers while maintaining their
performance guarantees, are of great interest. We consider an APX-hard problem,
where an adversary aims to attack shortest paths in a graph by removing the
minimum number of edges. We propose the GRASP algorithm: Graph Attention
Accelerated Shortest Path Attack, an ML aided optimization algorithm that
achieves run times up to 10x faster, while maintaining the quality of solution
generated. GRASP uses a graph attention network to identify a smaller subgraph
containing the combinatorial solution, thus effectively reducing the input
problem size. Additionally, we demonstrate how careful representation of the
input graph, including node features that correlate well with the optimization
task, can highlight important structure in the optimization solution.
</p></li>
</ul>

<h2>robust</h2>
<h3>Title: Extreme Image Transformations Facilitate Robust Latent Object Representations. (arXiv:2310.07725v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.07725">http://arxiv.org/abs/2310.07725</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.07725]] Extreme Image Transformations Facilitate Robust Latent Object Representations(http://arxiv.org/abs/2310.07725)</code></li>
<li>Summary: <p>Adversarial attacks can affect the object recognition capabilities of
machines in wild. These can often result from spurious correlations between
input and class labels, and are prone to memorization in large networks. While
networks are expected to do automated feature selection, it is not effective at
the scale of the object. Humans, however, are able to select the minimum set of
features required to form a robust representation of an object. In this work,
we show that finetuning any pretrained off-the-shelf network with Extreme Image
Transformations (EIT) not only helps in learning a robust latent
representation, it also improves the performance of these networks against
common adversarial attacks of various intensities. Our EIT trained networks
show strong activations in the object regions even when tested with more
intense noise, showing promising generalizations across different kinds of
adversarial attacks.
</p></li>
</ul>

<h3>Title: A Survey of Feature Types and Their Contributions for Camera Tampering Detection. (arXiv:2310.07886v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.07886">http://arxiv.org/abs/2310.07886</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.07886]] A Survey of Feature Types and Their Contributions for Camera Tampering Detection(http://arxiv.org/abs/2310.07886)</code></li>
<li>Summary: <p>Camera tamper detection is the ability to detect unauthorized and
unintentional alterations in surveillance cameras by analyzing the video.
Camera tampering can occur due to natural events or it can be caused
intentionally to disrupt surveillance. We cast tampering detection as a change
detection problem, and perform a review of the existing literature with
emphasis on feature types. We formulate tampering detection as a time series
analysis problem, and design experiments to study the robustness and capability
of various feature types. We compute ten features on real-world surveillance
video and apply time series analysis to ascertain their predictability, and
their capability to detect tampering. Finally, we quantify the performance of
various time series models using each feature type to detect tampering.
</p></li>
</ul>

<h3>Title: Point-NeuS: Point-Guided Neural Implicit Surface Reconstruction by Volume Rendering. (arXiv:2310.07997v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.07997">http://arxiv.org/abs/2310.07997</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.07997]] Point-NeuS: Point-Guided Neural Implicit Surface Reconstruction by Volume Rendering(http://arxiv.org/abs/2310.07997)</code></li>
<li>Summary: <p>Recently, learning neural implicit surface by volume rendering has been a
promising way for multi-view reconstruction. However, limited accuracy and
excessive time complexity remain bottlenecks that current methods urgently need
to overcome. To address these challenges, we propose a new method called
Point-NeuS, utilizing point-guided mechanisms to achieve accurate and efficient
reconstruction. Point modeling is organically embedded into the volume
rendering to enhance and regularize the representation of implicit surface.
Specifically, to achieve precise point guidance and noise robustness, aleatoric
uncertainty of the point cloud is modeled to capture the distribution of noise
and estimate the reliability of points. Additionally, a Neural Projection
module connecting points and images is introduced to add geometric constraints
to the Signed Distance Function (SDF). To better compensate for geometric bias
between volume rendering and point modeling, high-fidelity points are filtered
into an Implicit Displacement Network to improve the representation of SDF.
Benefiting from our effective point guidance, lightweight networks are employed
to achieve an impressive 11x speedup compared to NeuS. Extensive experiments
show that our method yields high-quality surfaces, especially for fine-grained
details and smooth regions. Moreover, it exhibits strong robustness to both
noisy and sparse data.
</p></li>
</ul>

<h3>Title: Continual Learning via Manifold Expansion Replay. (arXiv:2310.08038v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.08038">http://arxiv.org/abs/2310.08038</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.08038]] Continual Learning via Manifold Expansion Replay(http://arxiv.org/abs/2310.08038)</code></li>
<li>Summary: <p>In continual learning, the learner learns multiple tasks in sequence, with
data being acquired only once for each task. Catastrophic forgetting is a major
challenge to continual learning. To reduce forgetting, some existing
rehearsal-based methods use episodic memory to replay samples of previous
tasks. However, in the process of knowledge integration when learning a new
task, this strategy also suffers from catastrophic forgetting due to an
imbalance between old and new knowledge. To address this problem, we propose a
novel replay strategy called Manifold Expansion Replay (MaER). We argue that
expanding the implicit manifold of the knowledge representation in the episodic
memory helps to improve the robustness and expressiveness of the model. To this
end, we propose a greedy strategy to keep increasing the diameter of the
implicit manifold represented by the knowledge in the buffer during memory
management. In addition, we introduce Wasserstein distance instead of cross
entropy as distillation loss to preserve previous knowledge. With extensive
experimental validation on MNIST, CIFAR10, CIFAR100, and TinyImageNet, we show
that the proposed method significantly improves the accuracy in continual
learning setup, outperforming the state of the arts.
</p></li>
</ul>

<h3>Title: EC-Depth: Exploring the consistency of self-supervised monocular depth estimation under challenging scenes. (arXiv:2310.08044v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.08044">http://arxiv.org/abs/2310.08044</a></li>
<li>Code URL: https://github.com/RuijieZhu94/EC-Depth</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.08044]] EC-Depth: Exploring the consistency of self-supervised monocular depth estimation under challenging scenes(http://arxiv.org/abs/2310.08044)</code></li>
<li>Summary: <p>Self-supervised monocular depth estimation holds significant importance in
the fields of autonomous driving and robotics. However, existing methods are
typically designed to train and test on clear and pristine datasets,
overlooking the impact of various adverse conditions prevalent in real-world
scenarios. As a result, it is commonly observed that most self-supervised
monocular depth estimation methods struggle to perform adequately under
challenging conditions. To address this issue, we present EC-Depth, a novel
self-supervised two-stage training framework to achieve a robust depth
estimation, starting from the foundation of depth prediction consistency under
different perturbations. Leveraging the proposed perturbation-invariant depth
consistency constraint module and the consistency-based pseudo-label selection
module, our model attains accurate and consistent depth predictions in both
standard and challenging scenarios. Extensive experiments substantiate the
effectiveness of the proposed method. Moreover, our method surpasses existing
state-of-the-art methods on KITTI, KITTI-C and DrivingStereo benchmarks,
demonstrating its potential for enhancing the reliability of self-supervised
monocular depth estimation models in real-world applications.
</p></li>
</ul>

<h3>Title: XIMAGENET-12: An Explainable AI Benchmark Dataset for Model Robustness Evaluation. (arXiv:2310.08182v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.08182">http://arxiv.org/abs/2310.08182</a></li>
<li>Code URL: https://github.com/xiaohai12/explainable-ai-imagenet-12</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.08182]] XIMAGENET-12: An Explainable AI Benchmark Dataset for Model Robustness Evaluation(http://arxiv.org/abs/2310.08182)</code></li>
<li>Summary: <p>The lack of standardized robustness metrics and the widespread reliance on
numerous unrelated benchmark datasets for testing have created a gap between
academically validated robust models and their often problematic practical
adoption. To address this, we introduce XIMAGENET-12, an explainable benchmark
dataset with over 200K images and 15,600 manual semantic annotations. Covering
12 categories from ImageNet to represent objects commonly encountered in
practical life and simulating six diverse scenarios, including overexposure,
blurring, color changing, etc., we further propose a novel robustness criterion
that extends beyond model generation ability assessment. This benchmark
dataset, along with related code, is available at
https://sites.google.com/view/ximagenet-12/home. Researchers and practitioners
can leverage this resource to evaluate the robustness of their visual models
under challenging conditions and ultimately benefit from the demands of
practical computer vision systems.
</p></li>
</ul>

<h3>Title: Lifelong Audio-video Masked Autoencoder with Forget-robust Localized Alignments. (arXiv:2310.08204v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.08204">http://arxiv.org/abs/2310.08204</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.08204]] Lifelong Audio-video Masked Autoencoder with Forget-robust Localized Alignments(http://arxiv.org/abs/2310.08204)</code></li>
<li>Summary: <p>We present a lifelong audio-video masked autoencoder that continually learns
the multimodal representations from a video stream containing audio-video
pairs, while its distribution continually shifts over time. Specifically, we
propose two novel ideas to tackle the problem: (1) Localized Alignment: We
introduce a small trainable multimodal encoder that predicts the audio and
video tokens that are well-aligned with each other. This allows the model to
learn only the highly correlated audiovisual patches with accurate multimodal
relationships. (2) Forget-robust multimodal patch selection: We compare the
relative importance of each audio-video patch between the current and past data
pair to mitigate unintended drift of the previously learned audio-video
representations. Our proposed method, FLAVA (Forget-robust Localized
Audio-Video Alignment), therefore, captures the complex relationships between
the audio and video modalities during training on a sequence of pre-training
tasks while alleviating the forgetting of learned audiovisual correlations. Our
experiments validate that FLAVA outperforms the state-of-the-art continual
learning methods on several benchmark datasets under continual audio-video
representation learning scenarios.
</p></li>
</ul>

<h3>Title: Extended target tracking utilizing machine-learning software -- with applications to animal classification. (arXiv:2310.08316v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.08316">http://arxiv.org/abs/2310.08316</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.08316]] Extended target tracking utilizing machine-learning software -- with applications to animal classification(http://arxiv.org/abs/2310.08316)</code></li>
<li>Summary: <p>This paper considers the problem of detecting and tracking objects in a
sequence of images. The problem is formulated in a filtering framework, using
the output of object-detection algorithms as measurements. An extension to the
filtering formulation is proposed that incorporates class information from the
previous frame to robustify the classification, even if the object-detection
algorithm outputs an incorrect prediction. Further, the properties of the
object-detection algorithm are exploited to quantify the uncertainty of the
bounding box detection in each frame. The complete filtering method is
evaluated on camera trap images of the four large Swedish carnivores, bear,
lynx, wolf, and wolverine. The experiments show that the class tracking
formulation leads to a more robust classification.
</p></li>
</ul>

<h3>Title: NSM4D: Neural Scene Model Based Online 4D Point Cloud Sequence Understanding. (arXiv:2310.08326v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.08326">http://arxiv.org/abs/2310.08326</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.08326]] NSM4D: Neural Scene Model Based Online 4D Point Cloud Sequence Understanding(http://arxiv.org/abs/2310.08326)</code></li>
<li>Summary: <p>Understanding 4D point cloud sequences online is of significant practical
value in various scenarios such as VR/AR, robotics, and autonomous driving. The
key goal is to continuously analyze the geometry and dynamics of a 3D scene as
unstructured and redundant point cloud sequences arrive. And the main challenge
is to effectively model the long-term history while keeping computational costs
manageable. To tackle these challenges, we introduce a generic online 4D
perception paradigm called NSM4D. NSM4D serves as a plug-and-play strategy that
can be adapted to existing 4D backbones, significantly enhancing their online
perception capabilities for both indoor and outdoor scenarios. To efficiently
capture the redundant 4D history, we propose a neural scene model that
factorizes geometry and motion information by constructing geometry tokens
separately storing geometry and motion features. Exploiting the history becomes
as straightforward as querying the neural scene model. As the sequence
progresses, the neural scene model dynamically deforms to align with new
observations, effectively providing the historical context and updating itself
with the new observations. By employing token representation, NSM4D also
exhibits robustness to low-level sensor noise and maintains a compact size
through a geometric sampling scheme. We integrate NSM4D with state-of-the-art
4D perception backbones, demonstrating significant improvements on various
online perception benchmarks in indoor and outdoor settings. Notably, we
achieve a 9.6% accuracy improvement for HOI4D online action segmentation and a
3.4% mIoU improvement for SemanticKITTI online semantic segmentation.
Furthermore, we show that NSM4D inherently offers excellent scalability to
longer sequences beyond the training set, which is crucial for real-world
applications.
</p></li>
</ul>

<h3>Title: Non-autoregressive Text Editing with Copy-aware Latent Alignments. (arXiv:2310.07821v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.07821">http://arxiv.org/abs/2310.07821</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.07821]] Non-autoregressive Text Editing with Copy-aware Latent Alignments(http://arxiv.org/abs/2310.07821)</code></li>
<li>Summary: <p>Recent work has witnessed a paradigm shift from Seq2Seq to Seq2Edit in the
field of text editing, with the aim of addressing the slow autoregressive
inference problem posed by the former. Despite promising results, Seq2Edit
approaches still face several challenges such as inflexibility in generation
and difficulty in generalizing to other languages. In this work, we propose a
novel non-autoregressive text editing method to circumvent the above issues, by
modeling the edit process with latent CTC alignments. We make a crucial
extension to CTC by introducing the copy operation into the edit space, thus
enabling more efficient management of textual overlap in editing. We conduct
extensive experiments on GEC and sentence fusion tasks, showing that our
proposed method significantly outperforms existing Seq2Edit models and achieves
similar or even better results than Seq2Seq with over $4\times$ speedup.
Moreover, it demonstrates good generalizability on German and Russian. In-depth
analyses reveal the strengths of our method in terms of the robustness under
various scenarios and generating fluent and flexible outputs.
</p></li>
</ul>

<h3>Title: MProto: Multi-Prototype Network with Denoised Optimal Transport for Distantly Supervised Named Entity Recognition. (arXiv:2310.08298v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.08298">http://arxiv.org/abs/2310.08298</a></li>
<li>Code URL: https://github.com/XiPotatonium/mproto</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.08298]] MProto: Multi-Prototype Network with Denoised Optimal Transport for Distantly Supervised Named Entity Recognition(http://arxiv.org/abs/2310.08298)</code></li>
<li>Summary: <p>Distantly supervised named entity recognition (DS-NER) aims to locate entity
mentions and classify their types with only knowledge bases or gazetteers and
unlabeled corpus. However, distant annotations are noisy and degrade the
performance of NER models. In this paper, we propose a noise-robust prototype
network named MProto for the DS-NER task. Different from previous
prototype-based NER methods, MProto represents each entity type with multiple
prototypes to characterize the intra-class variance among entity
representations. To optimize the classifier, each token should be assigned an
appropriate ground-truth prototype and we consider such token-prototype
assignment as an optimal transport (OT) problem. Furthermore, to mitigate the
noise from incomplete labeling, we propose a novel denoised optimal transport
(DOT) algorithm. Specifically, we utilize the assignment result between Other
class tokens and all prototypes to distinguish unlabeled entity tokens from
true negatives. Experiments on several DS-NER benchmarks demonstrate that our
MProto achieves state-of-the-art performance. The source code is now available
on Github.
</p></li>
</ul>

<h3>Title: 2SFGL: A Simple And Robust Protocol For Graph-Based Fraud Detection. (arXiv:2310.08335v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.08335">http://arxiv.org/abs/2310.08335</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.08335]] 2SFGL: A Simple And Robust Protocol For Graph-Based Fraud Detection(http://arxiv.org/abs/2310.08335)</code></li>
<li>Summary: <p>Financial crime detection using graph learning improves financial safety and
efficiency. However, criminals may commit financial crimes across different
institutions to avoid detection, which increases the difficulty of detection
for financial institutions which use local data for graph learning. As most
financial institutions are subject to strict regulations in regards to data
privacy protection, the training data is often isolated and conventional
learning technology cannot handle the problem. Federated learning (FL) allows
multiple institutions to train a model without revealing their datasets to each
other, hence ensuring data privacy protection. In this paper, we proposes a
novel two-stage approach to federated graph learning (2SFGL): The first stage
of 2SFGL involves the virtual fusion of multiparty graphs, and the second
involves model training and inference on the virtual graph. We evaluate our
framework on a conventional fraud detection task based on the
FraudAmazonDataset and FraudYelpDataset. Experimental results show that
integrating and applying a GCN (Graph Convolutional Network) with our 2SFGL
framework to the same task results in a 17.6\%-30.2\% increase in performance
on several typical metrics compared to the case only using FedAvg, while
integrating GraphSAGE with 2SFGL results in a 6\%-16.2\% increase in
performance compared to the case only using FedAvg. We conclude that our
proposed framework is a robust and simple protocol which can be simply
integrated to pre-existing graph-based fraud detection methods.
</p></li>
</ul>

<h3>Title: Promoting Robustness of Randomized Smoothing: Two Cost-Effective Approaches. (arXiv:2310.07780v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.07780">http://arxiv.org/abs/2310.07780</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.07780]] Promoting Robustness of Randomized Smoothing: Two Cost-Effective Approaches(http://arxiv.org/abs/2310.07780)</code></li>
<li>Summary: <p>Randomized smoothing has recently attracted attentions in the field of
adversarial robustness to provide provable robustness guarantees on smoothed
neural network classifiers. However, existing works show that vanilla
randomized smoothing usually does not provide good robustness performance and
often requires (re)training techniques on the base classifier in order to boost
the robustness of the resulting smoothed classifier. In this work, we propose
two cost-effective approaches to boost the robustness of randomized smoothing
while preserving its clean performance. The first approach introduces a new
robust training method AdvMacerwhich combines adversarial training and
robustness certification maximization for randomized smoothing. We show that
AdvMacer can improve the robustness performance of randomized smoothing
classifiers compared to SOTA baselines, while being 3x faster to train than
MACER baseline. The second approach introduces a post-processing method EsbRS
which greatly improves the robustness certificate based on building model
ensembles. We explore different aspects of model ensembles that has not been
studied by prior works and propose a novel design methodology to further
improve robustness of the ensemble based on our theoretical analysis.
</p></li>
</ul>

<h3>Title: Exploring the Relationship Between Model Architecture and In-Context Learning Ability. (arXiv:2310.08049v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.08049">http://arxiv.org/abs/2310.08049</a></li>
<li>Code URL: https://github.com/ivnle/synth-icl</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.08049]] Exploring the Relationship Between Model Architecture and In-Context Learning Ability(http://arxiv.org/abs/2310.08049)</code></li>
<li>Summary: <p>What is the relationship between model architecture and the ability to
perform in-context learning? In this empirical study, we take the first steps
towards answering this question. In particular, we evaluate fifteen model
architectures across a suite of synthetic in-context learning tasks. The
selected architectures represent a broad range of paradigms, including
recurrent and convolution-based neural networks, transformers, and emerging
attention alternatives. We discover that all considered architectures can
perform in-context learning under certain conditions. However, contemporary
architectures are found to be the best performing, especially as task
complexity grows. Additionally, our follow-up experiments delve into various
factors that influence in-context learning. We observe varied sensitivities
among architectures with respect to hyperparameter settings. Our study of
training dynamics reveals that certain architectures exhibit a smooth,
progressive learning trajectory, while others demonstrate periods of stagnation
followed by abrupt mastery of the task. Finally, and somewhat surprisingly, we
find that several emerging attention alternatives are more robust in-context
learners than transformers; since such approaches have constant-sized memory
footprints at inference time, this result opens the future possibility of
scaling up in-context learning to vastly larger numbers of in-context examples.
</p></li>
</ul>

<h3>Title: LGL-BCI: A Lightweight Geometric Learning Framework for Motor Imagery-Based Brain-Computer Interfaces. (arXiv:2310.08051v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.08051">http://arxiv.org/abs/2310.08051</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.08051]] LGL-BCI: A Lightweight Geometric Learning Framework for Motor Imagery-Based Brain-Computer Interfaces(http://arxiv.org/abs/2310.08051)</code></li>
<li>Summary: <p>Brain-Computer Interfaces (BCIs) are a groundbreaking technology for
interacting with external devices using brain signals. Despite advancements,
electroencephalogram (EEG)-based Motor Imagery (MI) tasks face challenges like
amplitude and phase variability, and complex spatial correlations, with a need
for smaller model size and faster inference. This study introduces the LGL-BCI
framework, employing a Geometric Deep Learning Framework for EEG processing in
non-Euclidean metric spaces, particularly the Symmetric Positive Definite (SPD)
Manifold space. LGL-BCI offers robust EEG data representation and captures
spatial correlations. We propose an EEG channel selection solution via a
feature decomposition algorithm to reduce SPD matrix dimensionality, with a
lossless transformation boosting inference speed. Extensive experiments show
LGL-BCI's superior accuracy and efficiency compared to current solutions,
highlighting geometric deep learning's potential in MI-BCI applications. The
efficiency, assessed on two public EEG datasets and two real-world EEG devices,
significantly outperforms the state-of-the-art solution in accuracy ($82.54\%$
versus $62.22\%$) with fewer parameters (64.9M compared to 183.7M).
</p></li>
</ul>

<h2>biometric</h2>
<h3>Title: Cost-Driven Hardware-Software Co-Optimization of Machine Learning Pipelines. (arXiv:2310.07940v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.07940">http://arxiv.org/abs/2310.07940</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.07940]] Cost-Driven Hardware-Software Co-Optimization of Machine Learning Pipelines(http://arxiv.org/abs/2310.07940)</code></li>
<li>Summary: <p>Researchers have long touted a vision of the future enabled by a
proliferation of internet-of-things devices, including smart sensors, homes,
and cities. Increasingly, embedding intelligence in such devices involves the
use of deep neural networks. However, their storage and processing requirements
make them prohibitive for cheap, off-the-shelf platforms. Overcoming those
requirements is necessary for enabling widely-applicable smart devices. While
many ways of making models smaller and more efficient have been developed,
there is a lack of understanding of which ones are best suited for particular
scenarios. More importantly for edge platforms, those choices cannot be
analyzed in isolation from cost and user experience. In this work, we
holistically explore how quantization, model scaling, and multi-modality
interact with system components such as memory, sensors, and processors. We
perform this hardware/software co-design from the cost, latency, and
user-experience perspective, and develop a set of guidelines for optimal system
design and model deployment for the most cost-constrained platforms. We
demonstrate our approach using an end-to-end, on-device, biometric user
authentication system using a $20 ESP-EYE board.
</p></li>
</ul>

<h2>steal</h2>
<h2>extraction</h2>
<h3>Title: Dual-Stream Knowledge-Preserving Hashing for Unsupervised Video Retrieval. (arXiv:2310.08009v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.08009">http://arxiv.org/abs/2310.08009</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.08009]] Dual-Stream Knowledge-Preserving Hashing for Unsupervised Video Retrieval(http://arxiv.org/abs/2310.08009)</code></li>
<li>Summary: <p>Unsupervised video hashing usually optimizes binary codes by learning to
reconstruct input videos. Such reconstruction constraint spends much effort on
frame-level temporal context changes without focusing on video-level global
semantics that are more useful for retrieval. Hence, we address this problem by
decomposing video information into reconstruction-dependent and
semantic-dependent information, which disentangles the semantic extraction from
reconstruction constraint. Specifically, we first design a simple dual-stream
structure, including a temporal layer and a hash layer. Then, with the help of
semantic similarity knowledge obtained from self-supervision, the hash layer
learns to capture information for semantic retrieval, while the temporal layer
learns to capture the information for reconstruction. In this way, the model
naturally preserves the disentangled semantics into binary codes. Validated by
comprehensive experiments, our method consistently outperforms the
state-of-the-arts on three video benchmarks.
</p></li>
</ul>

<h3>Title: Structural analysis of Hindi online handwritten characters for character recognition. (arXiv:2310.08222v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.08222">http://arxiv.org/abs/2310.08222</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.08222]] Structural analysis of Hindi online handwritten characters for character recognition(http://arxiv.org/abs/2310.08222)</code></li>
<li>Summary: <p>Direction properties of online strokes are used to analyze them in terms of
homogeneous regions or sub-strokes with points satisfying common geometric
properties. Such sub-strokes are called sub-units. These properties are used to
extract sub-units from Hindi ideal online characters. These properties along
with some heuristics are used to extract sub-units from Hindi online
handwritten characters.\\ A method is developed to extract point stroke,
clockwise curve stroke, counter-clockwise curve stroke and loop stroke segments
as sub-units from Hindi online handwritten characters. These extracted
sub-units are close in structure to the sub-units of the corresponding Hindi
online ideal characters.\\ Importance of local representation of online
handwritten characters in terms of sub-units is assessed by training a
classifier with sub-unit level local and character level global features
extracted from characters for character recognition. The classifier has the
recognition accuracy of 93.5\% on the testing set. This accuracy is the highest
when compared with that of the classifiers trained only with global features
extracted from characters in the same training set and evaluated on the same
testing set.\\ Sub-unit extraction algorithm and the sub-unit based character
classifier are tested on Hindi online handwritten character dataset. This
dataset consists of samples from 96 different characters. There are 12832 and
2821 samples in the training and testing sets, respectively.
</p></li>
</ul>

<h3>Title: EIPE-text: Evaluation-Guided Iterative Plan Extraction for Long-Form Narrative Text Generation. (arXiv:2310.08185v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.08185">http://arxiv.org/abs/2310.08185</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.08185]] EIPE-text: Evaluation-Guided Iterative Plan Extraction for Long-Form Narrative Text Generation(http://arxiv.org/abs/2310.08185)</code></li>
<li>Summary: <p>Plan-and-Write is a common hierarchical approach in long-form narrative text
generation, which first creates a plan to guide the narrative writing.
Following this approach, several studies rely on simply prompting large
language models for planning, which often yields suboptimal results. In this
paper, we propose a new framework called Evaluation-guided Iterative Plan
Extraction for long-form narrative text generation (EIPE-text), which extracts
plans from the corpus of narratives and utilizes the extracted plans to
construct a better planner. EIPE-text has three stages: plan extraction,
learning, and inference. In the plan extraction stage, it iteratively extracts
and improves plans from the narrative corpus and constructs a plan corpus. We
propose a question answer (QA) based evaluation mechanism to automatically
evaluate the plans and generate detailed plan refinement instructions to guide
the iterative improvement. In the learning stage, we build a better planner by
fine-tuning with the plan corpus or in-context learning with examples in the
plan corpus. Finally, we leverage a hierarchical approach to generate long-form
narratives. We evaluate the effectiveness of EIPE-text in the domains of novels
and storytelling. Both GPT-4-based evaluations and human evaluations
demonstrate that our method can generate more coherent and relevant long-form
narratives. Our code will be released in the future.
</p></li>
</ul>

<h3>Title: SimCKP: Simple Contrastive Learning of Keyphrase Representations. (arXiv:2310.08221v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.08221">http://arxiv.org/abs/2310.08221</a></li>
<li>Code URL: https://github.com/brightjade/SimCKP</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.08221]] SimCKP: Simple Contrastive Learning of Keyphrase Representations(http://arxiv.org/abs/2310.08221)</code></li>
<li>Summary: <p>Keyphrase generation (KG) aims to generate a set of summarizing words or
phrases given a source document, while keyphrase extraction (KE) aims to
identify them from the text. Because the search space is much smaller in KE, it
is often combined with KG to predict keyphrases that may or may not exist in
the corresponding document. However, current unified approaches adopt sequence
labeling and maximization-based generation that primarily operate at a token
level, falling short in observing and scoring keyphrases as a whole. In this
work, we propose SimCKP, a simple contrastive learning framework that consists
of two stages: 1) An extractor-generator that extracts keyphrases by learning
context-aware phrase-level representations in a contrastive manner while also
generating keyphrases that do not appear in the document; 2) A reranker that
adapts scores for each generated phrase by likewise aligning their
representations with the corresponding document. Experimental results on
multiple benchmark datasets demonstrate the effectiveness of our proposed
approach, which outperforms the state-of-the-art models by a significant
margin.
</p></li>
</ul>

<h2>membership infer</h2>
<h3>Title: Why Train More? Effective and Efficient Membership Inference via Memorization. (arXiv:2310.08015v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.08015">http://arxiv.org/abs/2310.08015</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.08015]] Why Train More? Effective and Efficient Membership Inference via Memorization(http://arxiv.org/abs/2310.08015)</code></li>
<li>Summary: <p>Membership Inference Attacks (MIAs) aim to identify specific data samples
within the private training dataset of machine learning models, leading to
serious privacy violations and other sophisticated threats. Many practical
black-box MIAs require query access to the data distribution (the same
distribution where the private data is drawn) to train shadow models. By doing
so, the adversary obtains models trained "with" or "without" samples drawn from
the distribution, and analyzes the characteristics of the samples under
consideration. The adversary is often required to train more than hundreds of
shadow models to extract the signals needed for MIAs; this becomes the
computational overhead of MIAs. In this paper, we propose that by strategically
choosing the samples, MI adversaries can maximize their attack success while
minimizing the number of shadow models. First, our motivational experiments
suggest memorization as the key property explaining disparate sample
vulnerability to MIAs. We formalize this through a theoretical bound that
connects MI advantage with memorization. Second, we show sample complexity
bounds that connect the number of shadow models needed for MIAs with
memorization. Lastly, we confirm our theoretical arguments with comprehensive
experiments; by utilizing samples with high memorization scores, the adversary
can (a) significantly improve its efficacy regardless of the MIA used, and (b)
reduce the number of shadow models by nearly two orders of magnitude compared
to state-of-the-art approaches.
</p></li>
</ul>

<h2>federate</h2>
<h3>Title: FedSym: Unleashing the Power of Entropy for Benchmarking the Algorithms for Federated Learning. (arXiv:2310.07807v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.07807">http://arxiv.org/abs/2310.07807</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.07807]] FedSym: Unleashing the Power of Entropy for Benchmarking the Algorithms for Federated Learning(http://arxiv.org/abs/2310.07807)</code></li>
<li>Summary: <p>Federated learning (FL) is a decentralized machine learning approach where
independent learners process data privately. Its goal is to create a robust and
accurate model by aggregating and retraining local models over multiple rounds.
However, FL faces challenges regarding data heterogeneity and model aggregation
effectiveness. In order to simulate real-world data, researchers use methods
for data partitioning that transform a dataset designated for centralized
learning into a group of sub-datasets suitable for distributed machine learning
with different data heterogeneity. In this paper, we study the currently
popular data partitioning techniques and visualize their main disadvantages:
the lack of precision in the data diversity, which leads to unreliable
heterogeneity indexes, and the inability to incrementally challenge the FL
algorithms. To resolve this problem, we propose a method that leverages entropy
and symmetry to construct 'the most challenging' and controllable data
distributions with gradual difficulty. We introduce a metric to measure data
heterogeneity among the learning agents and a transformation technique that
divides any dataset into splits with precise data diversity. Through a
comparative study, we demonstrate the superiority of our method over existing
FL data partitioning approaches, showcasing its potential to challenge model
aggregation algorithms. Experimental results indicate that our approach
gradually challenges the FL strategies, and the models trained on FedSym
distributions are more distinct.
</p></li>
</ul>

<h3>Title: RandCom: Random Communication Skipping Method for Decentralized Stochastic Optimization. (arXiv:2310.07983v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.07983">http://arxiv.org/abs/2310.07983</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.07983]] RandCom: Random Communication Skipping Method for Decentralized Stochastic Optimization(http://arxiv.org/abs/2310.07983)</code></li>
<li>Summary: <p>Distributed optimization methods with random communication skips are gaining
increasing attention due to their proven benefits in accelerating communication
complexity. Nevertheless, existing research mainly focuses on centralized
communication protocols for strongly convex deterministic settings. In this
work, we provide a decentralized optimization method called RandCom, which
incorporates probabilistic local updates. We analyze the performance of RandCom
in stochastic non-convex, convex, and strongly convex settings and demonstrate
its ability to asymptotically reduce communication overhead by the probability
of communication. Additionally, we prove that RandCom achieves linear speedup
as the number of nodes increases. In stochastic strongly convex settings, we
further prove that RandCom can achieve linear speedup with network-independent
stepsizes. Moreover, we apply RandCom to federated learning and provide
positive results concerning the potential for achieving linear speedup and the
suitability of the probabilistic local update approach for non-convex settings.
</p></li>
</ul>

<h2>fair</h2>
<h2>interpretability</h2>
<h3>Title: Who Wrote it and Why? Prompting Large-Language Models for Authorship Verification. (arXiv:2310.08123v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.08123">http://arxiv.org/abs/2310.08123</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.08123]] Who Wrote it and Why? Prompting Large-Language Models for Authorship Verification(http://arxiv.org/abs/2310.08123)</code></li>
<li>Summary: <p>Authorship verification (AV) is a fundamental task in natural language
processing (NLP) and computational linguistics, with applications in forensic
analysis, plagiarism detection, and identification of deceptive content.
Existing AV techniques, including traditional stylometric and deep learning
approaches, face limitations in terms of data requirements and lack of
explainability. To address these limitations, this paper proposes PromptAV, a
novel technique that leverages Large-Language Models (LLMs) for AV by providing
step-by-step stylometric explanation prompts. PromptAV outperforms
state-of-the-art baselines, operates effectively with limited training data,
and enhances interpretability through intuitive explanations, showcasing its
potential as an effective and interpretable solution for the AV task.
</p></li>
</ul>

<h3>Title: Contextualized Policy Recovery: Modeling and Interpreting Medical Decisions with Adaptive Imitation Learning. (arXiv:2310.07918v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.07918">http://arxiv.org/abs/2310.07918</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.07918]] Contextualized Policy Recovery: Modeling and Interpreting Medical Decisions with Adaptive Imitation Learning(http://arxiv.org/abs/2310.07918)</code></li>
<li>Summary: <p>Interpretable policy learning seeks to estimate intelligible decision
policies from observed actions; however, existing models fall short by forcing
a tradeoff between accuracy and interpretability. This tradeoff limits
data-driven interpretations of human decision-making process. e.g. to audit
medical decisions for biases and suboptimal practices, we require models of
decision processes which provide concise descriptions of complex behaviors.
Fundamentally, existing approaches are burdened by this tradeoff because they
represent the underlying decision process as a universal policy, when in fact
human decisions are dynamic and can change drastically with contextual
information. Thus, we propose Contextualized Policy Recovery (CPR), which
re-frames the problem of modeling complex decision processes as a multi-task
learning problem in which complex decision policies are comprised of
context-specific policies. CPR models each context-specific policy as a linear
observation-to-action mapping, and generates new decision models
$\textit{on-demand}$ as contexts are updated with new observations. CPR is
compatible with fully offline and partially observable decision environments,
and can be tailored to incorporate any recurrent black-box model or
interpretable decision model. We assess CPR through studies on simulated and
real data, achieving state-of-the-art performance on the canonical tasks of
predicting antibiotic prescription in intensive care units ($+22\%$ AUROC vs.
previous SOTA) and predicting MRI prescription for Alzheimer's patients
($+7.7\%$ AUROC vs. previous SOTA). With this improvement in predictive
performance, CPR closes the accuracy gap between interpretable and black-box
methods for policy learning, allowing high-resolution exploration and analysis
of context-specific decision models.
</p></li>
</ul>

<h2>explainability</h2>
<h3>Title: Trustworthy Machine Learning. (arXiv:2310.08215v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.08215">http://arxiv.org/abs/2310.08215</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.08215]] Trustworthy Machine Learning(http://arxiv.org/abs/2310.08215)</code></li>
<li>Summary: <p>As machine learning technology gets applied to actual products and solutions,
new challenges have emerged. Models unexpectedly fail to generalize to small
changes in the distribution, tend to be confident on novel data they have never
seen, or cannot communicate the rationale behind their decisions effectively
with the end users. Collectively, we face a trustworthiness issue with the
current machine learning technology. This textbook on Trustworthy Machine
Learning (TML) covers a theoretical and technical background of four key topics
in TML: Out-of-Distribution Generalization, Explainability, Uncertainty
Quantification, and Evaluation of Trustworthiness. We discuss important
classical and contemporary research papers of the aforementioned fields and
uncover and connect their underlying intuitions. The book evolved from the
homonymous course at the University of T\"ubingen, first offered in the Winter
Semester of 2022/23. It is meant to be a stand-alone product accompanied by
code snippets and various pointers to further sources on topics of TML. The
dedicated website of the book is https://trustworthyml.io/.
</p></li>
</ul>

<h2>watermark</h2>
<h3>Title: Towards the Vulnerability of Watermarking Artificial Intelligence Generated Content. (arXiv:2310.07726v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.07726">http://arxiv.org/abs/2310.07726</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.07726]] Towards the Vulnerability of Watermarking Artificial Intelligence Generated Content(http://arxiv.org/abs/2310.07726)</code></li>
<li>Summary: <p>Artificial Intelligence Generated Content (AIGC) is gaining great popularity
in social media, with many commercial services available. These services
leverage advanced generative models, such as latent diffusion models and large
language models, to generate creative content (e.g., realistic images, fluent
sentences) for users. The usage of such generated content needs to be highly
regulated, as the service providers need to ensure the users do not violate the
usage policies (e.g., abuse for commercialization, generating and distributing
unsafe content).
</p>
<p>Numerous watermarking approaches have been proposed recently. However, in
this paper, we show that an adversary can easily break these watermarking
mechanisms. Specifically, we consider two possible attacks. (1) Watermark
removal: the adversary can easily erase the embedded watermark from the
generated content and then use it freely without the regulation of the service
provider. (2) Watermark forge: the adversary can create illegal content with
forged watermarks from another user, causing the service provider to make wrong
attributions. We propose WMaGi, a unified framework to achieve both attacks in
a holistic way. The key idea is to leverage a pre-trained diffusion model for
content processing, and a generative adversarial network for watermark removing
or forging. We evaluate WMaGi on different datasets and embedding setups. The
results prove that it can achieve high success rates while maintaining the
quality of the generated content. Compared with existing diffusion model-based
attacks, WMaGi is 5,050$\sim$11,000$\times$ faster.
</p></li>
</ul>

<h2>diffusion</h2>
<h3>Title: DrivingDiffusion: Layout-Guided multi-view driving scene video generation with latent diffusion model. (arXiv:2310.07771v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.07771">http://arxiv.org/abs/2310.07771</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.07771]] DrivingDiffusion: Layout-Guided multi-view driving scene video generation with latent diffusion model(http://arxiv.org/abs/2310.07771)</code></li>
<li>Summary: <p>With the increasing popularity of autonomous driving based on the powerful
and unified bird's-eye-view (BEV) representation, a demand for high-quality and
large-scale multi-view video data with accurate annotation is urgently
required. However, such large-scale multi-view data is hard to obtain due to
expensive collection and annotation costs. To alleviate the problem, we propose
a spatial-temporal consistent diffusion framework DrivingDiffusion, to generate
realistic multi-view videos controlled by 3D layout. There are three challenges
when synthesizing multi-view videos given a 3D layout: How to keep 1)
cross-view consistency and 2) cross-frame consistency? 3) How to guarantee the
quality of the generated instances? Our DrivingDiffusion solves the problem by
cascading the multi-view single-frame image generation step, the single-view
video generation step shared by multiple cameras, and post-processing that can
handle long video generation. In the multi-view model, the consistency of
multi-view images is ensured by information exchange between adjacent cameras.
In the temporal model, we mainly query the information that needs attention in
subsequent frame generation from the multi-view images of the first frame. We
also introduce the local prompt to effectively improve the quality of generated
instances. In post-processing, we further enhance the cross-view consistency of
subsequent frames and extend the video length by employing temporal sliding
window algorithm. Without any extra cost, our model can generate large-scale
realistic multi-camera driving videos in complex urban scenes, fueling the
downstream driving tasks. The code will be made publicly available.
</p></li>
</ul>

<h3>Title: Efficient Integrators for Diffusion Generative Models. (arXiv:2310.07894v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.07894">http://arxiv.org/abs/2310.07894</a></li>
<li>Code URL: https://github.com/mandt-lab/PSLD</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.07894]] Efficient Integrators for Diffusion Generative Models(http://arxiv.org/abs/2310.07894)</code></li>
<li>Summary: <p>Diffusion models suffer from slow sample generation at inference time.
Therefore, developing a principled framework for fast deterministic/stochastic
sampling for a broader class of diffusion models is a promising direction. We
propose two complementary frameworks for accelerating sample generation in
pre-trained models: Conjugate Integrators and Splitting Integrators. Conjugate
integrators generalize DDIM, mapping the reverse diffusion dynamics to a more
amenable space for sampling. In contrast, splitting-based integrators, commonly
used in molecular dynamics, reduce the numerical simulation error by cleverly
alternating between numerical updates involving the data and auxiliary
variables. After extensively studying these methods empirically and
theoretically, we present a hybrid method that leads to the best-reported
performance for diffusion models in augmented spaces. Applied to Phase Space
Langevin Diffusion [Pandey &amp; Mandt, 2023] on CIFAR-10, our deterministic and
stochastic samplers achieve FID scores of 2.11 and 2.36 in only 100 network
function evaluations (NFE) as compared to 2.57 and 2.63 for the best-performing
baselines, respectively. Our code and model checkpoints will be made publicly
available at \url{https://github.com/mandt-lab/PSLD}.
</p></li>
</ul>

<h3>Title: Consistent123: Improve Consistency for One Image to 3D Object Synthesis. (arXiv:2310.08092v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.08092">http://arxiv.org/abs/2310.08092</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.08092]] Consistent123: Improve Consistency for One Image to 3D Object Synthesis(http://arxiv.org/abs/2310.08092)</code></li>
<li>Summary: <p>Large image diffusion models enable novel view synthesis with high quality
and excellent zero-shot capability. However, such models based on
image-to-image translation have no guarantee of view consistency, limiting the
performance for downstream tasks like 3D reconstruction and image-to-3D
generation. To empower consistency, we propose Consistent123 to synthesize
novel views simultaneously by incorporating additional cross-view attention
layers and the shared self-attention mechanism. The proposed attention
mechanism improves the interaction across all synthesized views, as well as the
alignment between the condition view and novel views. In the sampling stage,
such architecture supports simultaneously generating an arbitrary number of
views while training at a fixed length. We also introduce a progressive
classifier-free guidance strategy to achieve the trade-off between texture and
geometry for synthesized object views. Qualitative and quantitative experiments
show that Consistent123 outperforms baselines in view consistency by a large
margin. Furthermore, we demonstrate a significant improvement of Consistent123
on varying downstream tasks, showing its great potential in the 3D generation
field. The project page is available at consistent-123.github.io.
</p></li>
</ul>

<h3>Title: Interpretable Diffusion via Information Decomposition. (arXiv:2310.07972v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.07972">http://arxiv.org/abs/2310.07972</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.07972]] Interpretable Diffusion via Information Decomposition(http://arxiv.org/abs/2310.07972)</code></li>
<li>Summary: <p>Denoising diffusion models enable conditional generation and density modeling
of complex relationships like images and text. However, the nature of the
learned relationships is opaque making it difficult to understand precisely
what relationships between words and parts of an image are captured, or to
predict the effect of an intervention. We illuminate the fine-grained
relationships learned by diffusion models by noticing a precise relationship
between diffusion and information decomposition. Exact expressions for mutual
information and conditional mutual information can be written in terms of the
denoising model. Furthermore, pointwise estimates can be easily estimated as
well, allowing us to ask questions about the relationships between specific
images and captions. Decomposing information even further to understand which
variables in a high-dimensional space carry information is a long-standing
problem. For diffusion models, we show that a natural non-negative
decomposition of mutual information emerges, allowing us to quantify
informative relationships between words and pixels in an image. We exploit
these new relations to measure the compositional understanding of diffusion
models, to do unsupervised localization of objects in images, and to measure
effects when selectively editing images through prompt interventions.
</p></li>
</ul>

<h3>Title: Local Graph Clustering with Noisy Labels. (arXiv:2310.08031v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.08031">http://arxiv.org/abs/2310.08031</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.08031]] Local Graph Clustering with Noisy Labels(http://arxiv.org/abs/2310.08031)</code></li>
<li>Summary: <p>The growing interest in machine learning problems over graphs with additional
node information such as texts, images, or labels has popularized methods that
require the costly operation of processing the entire graph. Yet, little effort
has been made to the development of fast local methods (i.e. without accessing
the entire graph) that extract useful information from such data. To that end,
we propose a study of local graph clustering using noisy node labels as a proxy
for additional node information. In this setting, nodes receive initial binary
labels based on cluster affiliation: 1 if they belong to the target cluster and
0 otherwise. Subsequently, a fraction of these labels is flipped. We
investigate the benefits of incorporating noisy labels for local graph
clustering. By constructing a weighted graph with such labels, we study the
performance of graph diffusion-based local clustering method on both the
original and the weighted graphs. From a theoretical perspective, we consider
recovering an unknown target cluster with a single seed node in a random graph
with independent noisy node labels. We provide sufficient conditions on the
label noise under which, with high probability, using diffusion in the weighted
graph yields a more accurate recovery of the target cluster. This approach
proves more effective than using the given labels alone or using diffusion in
the label-free original graph. Empirically, we show that reliable node labels
can be obtained with just a few samples from an attributed graph. Moreover,
utilizing these labels via diffusion in the weighted graph leads to
significantly better local clustering performance across several real-world
datasets, improving F1 scores by up to 13%.
</p></li>
</ul>

<h3>Title: Neural Diffusion Models. (arXiv:2310.08337v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.08337">http://arxiv.org/abs/2310.08337</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.08337]] Neural Diffusion Models(http://arxiv.org/abs/2310.08337)</code></li>
<li>Summary: <p>Diffusion models have shown remarkable performance on many generative tasks.
Despite recent success, most diffusion models are restricted in that they only
allow linear transformation of the data distribution. In contrast, broader
family of transformations can potentially help train generative distributions
more efficiently, simplifying the reverse process and closing the gap between
the true negative log-likelihood and the variational approximation. In this
paper, we present Neural Diffusion Models (NDMs), a generalization of
conventional diffusion models that enables defining and learning time-dependent
non-linear transformations of data. We show how to optimise NDMs using a
variational bound in a simulation-free setting. Moreover, we derive a
time-continuous formulation of NDMs, which allows fast and reliable inference
using off-the-shelf numerical ODE and SDE solvers. Finally, we demonstrate the
utility of NDMs with learnable transformations through experiments on standard
image generation benchmarks, including CIFAR-10, downsampled versions of
ImageNet and CelebA-HQ. NDMs outperform conventional diffusion models in terms
of likelihood and produce high-quality samples.
</p></li>
</ul>

<h2>noise learning</h2>
<h2>data-free</h2>
<h2>transformer</h2>
<h3>Title: 3D TransUNet: Advancing Medical Image Segmentation through Vision Transformers. (arXiv:2310.07781v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.07781">http://arxiv.org/abs/2310.07781</a></li>
<li>Code URL: https://github.com/Beckschen/3D-TransUNet</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.07781]] 3D TransUNet: Advancing Medical Image Segmentation through Vision Transformers(http://arxiv.org/abs/2310.07781)</code></li>
<li>Summary: <p>Medical image segmentation plays a crucial role in advancing healthcare
systems for disease diagnosis and treatment planning. The u-shaped
architecture, popularly known as U-Net, has proven highly successful for
various medical image segmentation tasks. However, U-Net's convolution-based
operations inherently limit its ability to model long-range dependencies
effectively. To address these limitations, researchers have turned to
Transformers, renowned for their global self-attention mechanisms, as
alternative architectures. One popular network is our previous TransUNet, which
leverages Transformers' self-attention to complement U-Net's localized
information with the global context. In this paper, we extend the 2D TransUNet
architecture to a 3D network by building upon the state-of-the-art nnU-Net
architecture, and fully exploring Transformers' potential in both the encoder
and decoder design. We introduce two key components: 1) A Transformer encoder
that tokenizes image patches from a convolution neural network (CNN) feature
map, enabling the extraction of global contexts, and 2) A Transformer decoder
that adaptively refines candidate regions by utilizing cross-attention between
candidate proposals and U-Net features. Our investigations reveal that
different medical tasks benefit from distinct architectural designs. The
Transformer encoder excels in multi-organ segmentation, where the relationship
among organs is crucial. On the other hand, the Transformer decoder proves more
beneficial for dealing with small and challenging segmented targets such as
tumor segmentation. Extensive experiments showcase the significant potential of
integrating a Transformer-based encoder and decoder into the u-shaped medical
image segmentation architecture. TransUNet outperforms competitors in various
medical applications.
</p></li>
</ul>

<h3>Title: Age Estimation Based on Graph Convolutional Networks and Multi-head Attention Mechanisms. (arXiv:2310.08064v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.08064">http://arxiv.org/abs/2310.08064</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.08064]] Age Estimation Based on Graph Convolutional Networks and Multi-head Attention Mechanisms(http://arxiv.org/abs/2310.08064)</code></li>
<li>Summary: <p>Age estimation technology is a part of facial recognition and has been
applied to identity authentication. This technology achieves the development
and application of a juvenile anti-addiction system by authenticating users in
the game. Convolutional Neural Network (CNN) and Transformer algorithms are
widely used in this application scenario. However, these two models cannot
flexibly extract and model features of faces with irregular shapes, and they
are ineffective in capturing key information. Furthermore, the above methods
will contain a lot of background information while extracting features, which
will interfere with the model. In consequence, it is easy to extract redundant
information from images. In this paper, a new modeling idea is proposed to
solve this problem, which can flexibly model irregular objects. The Graph
Convolutional Network (GCN) is used to extract features from irregular face
images effectively, and multi-head attention mechanisms are added to avoid
redundant features and capture key region information in the image. This model
can effectively improve the accuracy of age estimation and reduce the MAE error
value to about 3.64, which is better than the effect of today's age estimation
model, to improve the accuracy of face recognition and identity authentication.
</p></li>
</ul>

<h3>Title: Pit One Against Many: Leveraging Attention-head Embeddings for Parameter-efficient Multi-head Attention. (arXiv:2310.07911v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.07911">http://arxiv.org/abs/2310.07911</a></li>
<li>Code URL: https://github.com/HUIYINXUE/simpleMHE</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.07911]] Pit One Against Many: Leveraging Attention-head Embeddings for Parameter-efficient Multi-head Attention(http://arxiv.org/abs/2310.07911)</code></li>
<li>Summary: <p>Scaling pre-trained language models has resulted in large performance gains
in various natural language processing tasks but comes with a large cost in
memory requirements. Inspired by the position embeddings in transformers, we
aim to simplify and reduce the memory footprint of the multi-head attention
(MHA) mechanism. We propose an alternative module that uses only a single
shared projection matrix and multiple head embeddings (MHE), i.e. one per head.
We empirically demonstrate that our MHE attention is substantially more memory
efficient compared to alternative attention mechanisms while achieving high
predictive performance retention ratio to vanilla MHA on several downstream
tasks. MHE attention only requires a negligible fraction of additional
parameters ($3nd$, where $n$ is the number of attention heads and $d$ the size
of the head embeddings) compared to a single-head attention, while MHA requires
$(3n^2-3n)d^2-3nd$ additional parameters.
</p></li>
</ul>

<h3>Title: The Expresssive Power of Transformers with Chain of Thought. (arXiv:2310.07923v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.07923">http://arxiv.org/abs/2310.07923</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.07923]] The Expresssive Power of Transformers with Chain of Thought(http://arxiv.org/abs/2310.07923)</code></li>
<li>Summary: <p>Recent theoretical work has identified surprisingly simple reasoning
problems, such as checking if two nodes in a graph are connected or simulating
finite-state machines, that are provably unsolvable by standard transformers
that answer immediately after reading their input. However, in practice,
transformers' reasoning can be improved by allowing them to use a "chain of
thought" or "scratchpad", i.e., generate and condition on a sequence of
intermediate tokens before answering. Motivated by this, we ask: Does such
intermediate generation fundamentally extend the computational power of a
decoder-only transformer? We show that the answer is yes, but the amount of
increase depends crucially on the amount of intermediate generation. For
instance, we find that transformer decoders with a logarithmic number of
decoding steps (w.r.t. the input length) push the limits of standard
transformers only slightly, while a linear number of decoding steps adds a
clear new ability (under standard complexity conjectures): recognizing all
regular languages. Our results also imply that linear steps keep transformer
decoders within context-sensitive languages, and polynomial steps make them
recognize exactly the class of polynomial-time solvable problems -- the first
exact characterization of a type of transformers in terms of standard
complexity classes. Together, our results provide a nuanced framework for
understanding how the length of a transformer's chain of thought or scratchpad
impacts its reasoning power.
</p></li>
</ul>

<h3>Title: Context Compression for Auto-regressive Transformers with Sentinel Tokens. (arXiv:2310.08152v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.08152">http://arxiv.org/abs/2310.08152</a></li>
<li>Code URL: https://github.com/DRSY/KV_Compression</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.08152]] Context Compression for Auto-regressive Transformers with Sentinel Tokens(http://arxiv.org/abs/2310.08152)</code></li>
<li>Summary: <p>The quadratic complexity of the attention module makes it gradually become
the bulk of compute in Transformer-based LLMs during generation. Moreover, the
excessive key-value cache that arises when dealing with long inputs also brings
severe issues on memory footprint and inference latency. In this work, we
propose a plug-and-play approach that is able to incrementally compress the
intermediate activation of a specified span of tokens into compact ones,
thereby reducing both memory and computational cost when processing subsequent
context. Experiments on both in-domain language modeling and zero-shot
open-ended document generation demonstrate the advantage of our approach over
sparse attention baselines in terms of fluency, n-gram matching, and semantic
similarity. At last, we comprehensively profile the benefit of context
compression on improving the system throughout. Code is available at
https://github.com/DRSY/KV_Compression.
</p></li>
</ul>

<h3>Title: Ziya-VL: Bilingual Large Vision-Language Model via Multi-Task Instruction Tuning. (arXiv:2310.08166v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.08166">http://arxiv.org/abs/2310.08166</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.08166]] Ziya-VL: Bilingual Large Vision-Language Model via Multi-Task Instruction Tuning(http://arxiv.org/abs/2310.08166)</code></li>
<li>Summary: <p>Recent advancements enlarge the capabilities of large language models (LLMs)
in zero-shot image-to-text generation and understanding by integrating
multi-modal inputs. However, such success is typically limited to English
scenarios due to the lack of large-scale and high-quality non-English
multi-modal resources, making it extremely difficult to establish competitive
counterparts in other languages. In this paper, we introduce the Ziya-VL
series, a set of bilingual large-scale vision-language models (LVLMs) designed
to incorporate visual semantics into LLM for multi-modal dialogue. Composed of
Ziya-VL-Base and Ziya-VL-Chat, our models adopt the Querying Transformer from
BLIP-2, further exploring the assistance of optimization schemes such as
instruction tuning, multi-stage training and low-rank adaptation module for
visual-language alignment. In addition, we stimulate the understanding ability
of GPT-4 in multi-modal scenarios, translating our gathered English image-text
datasets into Chinese and generating instruction-response through the
in-context learning method. The experiment results demonstrate that compared to
the existing LVLMs, Ziya-VL achieves competitive performance across a wide
range of English-only tasks including zero-shot image-text retrieval, image
captioning, and visual question answering. The evaluation leaderboard accessed
by GPT-4 also indicates that our models possess satisfactory image-text
understanding and generation capabilities in Chinese multi-modal scenario
dialogues. Code, demo and models are available at
~\url{https://huggingface.co/IDEA-CCNL/Ziya-BLIP2-14B-Visual-v1}.
</p></li>
</ul>

<h3>Title: Visual Question Generation in Bengali. (arXiv:2310.08187v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.08187">http://arxiv.org/abs/2310.08187</a></li>
<li>Code URL: https://github.com/mahmudhasankhan/vqg-in-bengali</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.08187]] Visual Question Generation in Bengali(http://arxiv.org/abs/2310.08187)</code></li>
<li>Summary: <p>The task of Visual Question Generation (VQG) is to generate human-like
questions relevant to the given image. As VQG is an emerging research field,
existing works tend to focus only on resource-rich language such as English due
to the availability of datasets. In this paper, we propose the first Bengali
Visual Question Generation task and develop a novel transformer-based
encoder-decoder architecture that generates questions in Bengali when given an
image. We propose multiple variants of models - (i) image-only: baseline model
of generating questions from images without additional information, (ii)
image-category and image-answer-category: guided VQG where we condition the
model to generate questions based on the answer and the category of expected
question. These models are trained and evaluated on the translated VQAv2.0
dataset. Our quantitative and qualitative results establish the first state of
the art models for VQG task in Bengali and demonstrate that our models are
capable of generating grammatically correct and relevant questions. Our
quantitative results show that our image-cat model achieves a BLUE-1 score of
33.12 and BLEU-3 score of 7.56 which is the highest of the other two variants.
We also perform a human evaluation to assess the quality of the generation
tasks. Human evaluation suggests that image-cat model is capable of generating
goal-driven and attribute-specific questions and also stays relevant to the
corresponding image.
</p></li>
</ul>

<h3>Title: Language Models are Universal Embedders. (arXiv:2310.08232v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.08232">http://arxiv.org/abs/2310.08232</a></li>
<li>Code URL: https://github.com/izhx/uni-rep</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.08232]] Language Models are Universal Embedders(http://arxiv.org/abs/2310.08232)</code></li>
<li>Summary: <p>In the large language model (LLM) revolution, embedding is a key component of
various systems. For example, it is used to retrieve knowledge or memories for
LLMs, to build content moderation filters, etc. As such cases span from English
to other natural or programming languages, from retrieval to classification and
beyond, it is desirable to build a unified embedding model rather than
dedicated ones for each scenario. In this work, we make an initial step towards
this goal, demonstrating that multiple languages (both natural and programming)
pre-trained transformer decoders can embed universally when finetuned on
limited English data. We provide a comprehensive practice with thorough
evaluations. On English MTEB, our models achieve competitive performance on
different embedding tasks by minimal training data. On other benchmarks, such
as multilingual classification and code search, our models (without any
supervision) perform comparably to, or even surpass heavily supervised
baselines and/or APIs. These results provide evidence of a promising path
towards building powerful unified embedders that can be applied across tasks
and languages.
</p></li>
</ul>

<h3>Title: LEMON: Lossless model expansion. (arXiv:2310.07999v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.07999">http://arxiv.org/abs/2310.07999</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.07999]] LEMON: Lossless model expansion(http://arxiv.org/abs/2310.07999)</code></li>
<li>Summary: <p>Scaling of deep neural networks, especially Transformers, is pivotal for
their surging performance and has further led to the emergence of sophisticated
reasoning capabilities in foundation models. Such scaling generally requires
training large models from scratch with random initialization, failing to
leverage the knowledge acquired by their smaller counterparts, which are
already resource-intensive to obtain. To tackle this inefficiency, we present
$\textbf{L}$ossl$\textbf{E}$ss $\textbf{MO}$del Expansio$\textbf{N}$ (LEMON), a
recipe to initialize scaled models using the weights of their smaller but
pre-trained counterparts. This is followed by model training with an optimized
learning rate scheduler tailored explicitly for the scaled models,
substantially reducing the training time compared to training from scratch.
Notably, LEMON is versatile, ensuring compatibility with various network
structures, including models like Vision Transformers and BERT. Our empirical
results demonstrate that LEMON reduces computational costs by 56.7% for Vision
Transformers and 33.2% for BERT when compared to training from scratch.
</p></li>
</ul>

<h3>Title: Lag-Llama: Towards Foundation Models for Time Series Forecasting. (arXiv:2310.08278v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.08278">http://arxiv.org/abs/2310.08278</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.08278]] Lag-Llama: Towards Foundation Models for Time Series Forecasting(http://arxiv.org/abs/2310.08278)</code></li>
<li>Summary: <p>Aiming to build foundation models for time-series forecasting and study their
scaling behavior, we present here our work-in-progress on Lag-Llama, a
general-purpose univariate probabilistic time-series forecasting model trained
on a large collection of time-series data. The model shows good zero-shot
prediction capabilities on unseen "out-of-distribution" time-series datasets,
outperforming supervised baselines. We use smoothly broken power-laws to fit
and predict model scaling behavior. The open source code is made available at
https://github.com/kashif/pytorch-transformer-ts.
</p></li>
</ul>

<h2>generative</h2>
<h3>Title: CleftGAN: Adapting A Style-Based Generative Adversarial Network To Create Images Depicting Cleft Lip Deformity. (arXiv:2310.07969v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.07969">http://arxiv.org/abs/2310.07969</a></li>
<li>Code URL: https://github.com/abdullah-tamu/CleftGAN</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.07969]] CleftGAN: Adapting A Style-Based Generative Adversarial Network To Create Images Depicting Cleft Lip Deformity(http://arxiv.org/abs/2310.07969)</code></li>
<li>Summary: <p>A major obstacle when attempting to train a machine learning system to
evaluate facial clefts is the scarcity of large datasets of high-quality,
ethics board-approved patient images. In response, we have built a deep
learning-based cleft lip generator designed to produce an almost unlimited
number of artificial images exhibiting high-fidelity facsimiles of cleft lip
with wide variation. We undertook a transfer learning protocol testing
different versions of StyleGAN-ADA (a generative adversarial network image
generator incorporating adaptive data augmentation (ADA)) as the base model.
Training images depicting a variety of cleft deformities were pre-processed to
adjust for rotation, scaling, color adjustment and background blurring. The ADA
modification of the primary algorithm permitted construction of our new
generative model while requiring input of a relatively small number of training
images. Adversarial training was carried out using 514 unique frontal
photographs of cleft-affected faces to adapt a pre-trained model based on
70,000 normal faces. The Frechet Inception Distance (FID) was used to measure
the similarity of the newly generated facial images to the cleft training
dataset, while Perceptual Path Length (PPL) and the novel Divergence Index of
Severity Histograms (DISH) measures were also used to assess the performance of
the image generator that we dub CleftGAN. We found that StyleGAN3 with
translation invariance (StyleGAN3-t) performed optimally as a base model.
Generated images achieved a low FID reflecting a close similarity to our
training input dataset of genuine cleft images. Low PPL and DISH measures
reflected a smooth and semantically valid interpolation of images through the
transfer learning process and a similar distribution of severity in the
training and generated images, respectively.
</p></li>
</ul>

<h3>Title: GePSAn: Generative Procedure Step Anticipation in Cooking Videos. (arXiv:2310.08312v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.08312">http://arxiv.org/abs/2310.08312</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.08312]] GePSAn: Generative Procedure Step Anticipation in Cooking Videos(http://arxiv.org/abs/2310.08312)</code></li>
<li>Summary: <p>We study the problem of future step anticipation in procedural videos. Given
a video of an ongoing procedural activity, we predict a plausible next
procedure step described in rich natural language. While most previous work
focus on the problem of data scarcity in procedural video datasets, another
core challenge of future anticipation is how to account for multiple plausible
future realizations in natural settings. This problem has been largely
overlooked in previous work. To address this challenge, we frame future step
prediction as modelling the distribution of all possible candidates for the
next step. Specifically, we design a generative model that takes a series of
video clips as input, and generates multiple plausible and diverse candidates
(in natural language) for the next step. Following previous work, we side-step
the video annotation scarcity by pretraining our model on a large text-based
corpus of procedural activities, and then transfer the model to the video
domain. Our experiments, both in textual and video domains, show that our model
captures diversity in the next step prediction and generates multiple plausible
future predictions. Moreover, our model establishes new state-of-the-art
results on YouCookII, where it outperforms existing baselines on the next step
anticipation. Finally, we also show that our model can successfully transfer
from text to the video domain zero-shot, ie, without fine-tuning or adaptation,
and produces good-quality future step predictions from video.
</p></li>
</ul>

<h3>Title: GenTKG: Generative Forecasting on Temporal Knowledge Graph. (arXiv:2310.07793v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.07793">http://arxiv.org/abs/2310.07793</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.07793]] GenTKG: Generative Forecasting on Temporal Knowledge Graph(http://arxiv.org/abs/2310.07793)</code></li>
<li>Summary: <p>The rapid advancements in large language models (LLMs) have ignited interest
in the temporal knowledge graph (tKG) domain, where conventional carefully
designed embedding-based and rule-based models dominate. The question remains
open of whether pre-trained LLMs can understand structured temporal relational
data and replace them as the foundation model for temporal relational
forecasting. Therefore, we bring temporal knowledge forecasting into the
generative setting. However, challenges occur in the huge chasms between
complex temporal graph data structure and sequential natural expressions LLMs
can handle, and between the enormous data sizes of tKGs and heavy computation
costs of finetuning LLMs. To address these challenges, we propose a novel
retrieval augmented generation framework that performs generative forecasting
on tKGs named GenTKG, which combines a temporal logical rule-based retrieval
strategy and lightweight parameter-efficient instruction tuning. Extensive
experiments have shown that GenTKG outperforms conventional methods of temporal
relational forecasting under low computation resources. GenTKG also highlights
remarkable transferability with exceeding performance on unseen datasets
without re-training. Our work reveals the huge potential of LLMs in the tKG
domain and opens a new frontier for generative forecasting on tKGs.
</p></li>
</ul>

<h3>Title: Training Generative Question-Answering on Synthetic Data Obtained from an Instruct-tuned Mo. (arXiv:2310.08072v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.08072">http://arxiv.org/abs/2310.08072</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.08072]] Training Generative Question-Answering on Synthetic Data Obtained from an Instruct-tuned Mo(http://arxiv.org/abs/2310.08072)</code></li>
<li>Summary: <p>This paper presents a simple and cost-effective method for synthesizing data
to train question-answering systems. For training, fine-tuning GPT models is a
common practice in resource-rich languages like English, however, it becomes
challenging for non-English languages due to the scarcity of sufficient
question-answer (QA) pairs. Existing approaches use question and answer
generators trained on human-authored QA pairs, which involves substantial human
expenses. In contrast, we use an instruct-tuned model to generate QA pairs in a
zero-shot or few-shot manner. We conduct experiments to compare various
strategies for obtaining QA pairs from the instruct-tuned model. The results
demonstrate that a model trained on our proposed synthetic data achieves
comparable performance to a model trained on manually curated datasets, without
incurring human costs.
</p></li>
</ul>

<h3>Title: Generative Modeling with Phase Stochastic Bridges. (arXiv:2310.07805v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.07805">http://arxiv.org/abs/2310.07805</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.07805]] Generative Modeling with Phase Stochastic Bridges(http://arxiv.org/abs/2310.07805)</code></li>
<li>Summary: <p>Diffusion models (DMs) represent state-of-the-art generative models for
continuous inputs. DMs work by constructing a Stochastic Differential Equation
(SDE) in the input space (ie, position space), and using a neural network to
reverse it. In this work, we introduce a novel generative modeling framework
grounded in \textbf{phase space dynamics}, where a phase space is defined as
{an augmented space encompassing both position and velocity.} Leveraging
insights from Stochastic Optimal Control, we construct a path measure in the
phase space that enables efficient sampling. {In contrast to DMs, our framework
demonstrates the capability to generate realistic data points at an early stage
of dynamics propagation.} This early prediction sets the stage for efficient
data generation by leveraging additional velocity information along the
trajectory. On standard image generation benchmarks, our model yields favorable
performance over baselines in the regime of small Number of Function
Evaluations (NFEs). Furthermore, our approach rivals the performance of
diffusion models equipped with efficient sampling techniques, underscoring its
potential as a new tool generative modeling.
</p></li>
</ul>

<h3>Title: SEE-OoD: Supervised Exploration For Enhanced Out-of-Distribution Detection. (arXiv:2310.08040v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.08040">http://arxiv.org/abs/2310.08040</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.08040]] SEE-OoD: Supervised Exploration For Enhanced Out-of-Distribution Detection(http://arxiv.org/abs/2310.08040)</code></li>
<li>Summary: <p>Current techniques for Out-of-Distribution (OoD) detection predominantly rely
on quantifying predictive uncertainty and incorporating model regularization
during the training phase, using either real or synthetic OoD samples. However,
methods that utilize real OoD samples lack exploration and are prone to overfit
the OoD samples at hand. Whereas synthetic samples are often generated based on
features extracted from training data, rendering them less effective when the
training and OoD data are highly overlapped in the feature space. In this work,
we propose a Wasserstein-score-based generative adversarial training scheme to
enhance OoD detection accuracy, which, for the first time, performs data
augmentation and exploration simultaneously under the supervision of limited
OoD samples. Specifically, the generator explores OoD spaces and generates
synthetic OoD samples using feedback from the discriminator, while the
discriminator exploits both the observed and synthesized samples for OoD
detection using a predefined Wasserstein score. We provide theoretical
guarantees that the optimal solutions of our generative scheme are
statistically achievable through adversarial training in empirical settings. We
then demonstrate that the proposed method outperforms state-of-the-art
techniques on various computer vision datasets and exhibits superior
generalizability to unseen OoD data.
</p></li>
</ul>

<h3>Title: Generative Intrinsic Optimization: Intrisic Control with Model Learning. (arXiv:2310.08100v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.08100">http://arxiv.org/abs/2310.08100</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.08100]] Generative Intrinsic Optimization: Intrisic Control with Model Learning(http://arxiv.org/abs/2310.08100)</code></li>
<li>Summary: <p>Future sequence represents the outcome after executing the action into the
environment. When driven by the information-theoretic concept of mutual
information, it seeks maximally informative consequences. Explicit outcomes may
vary across state, return, or trajectory serving different purposes such as
credit assignment or imitation learning. However, the inherent nature of
incorporating intrinsic motivation with reward maximization is often neglected.
In this work, we propose a variational approach to jointly learn the necessary
quantity for estimating the mutual information and the dynamics model,
providing a general framework for incorporating different forms of outcomes of
interest. Integrated into a policy iteration scheme, our approach guarantees
convergence to the optimal policy. While we mainly focus on theoretical
analysis, our approach opens the possibilities of leveraging intrinsic control
with model learning to enhance sample efficiency and incorporate uncertainty of
the environment into decision-making.
</p></li>
</ul>

<h2>large language model</h2>
<h3>Title: LangNav: Language as a Perceptual Representation for Navigation. (arXiv:2310.07889v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.07889">http://arxiv.org/abs/2310.07889</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.07889]] LangNav: Language as a Perceptual Representation for Navigation(http://arxiv.org/abs/2310.07889)</code></li>
<li>Summary: <p>We explore the use of language as a perceptual representation for
vision-and-language navigation. Our approach uses off-the-shelf vision systems
(for image captioning and object detection) to convert an agent's egocentric
panoramic view at each time step into natural language descriptions. We then
finetune a pretrained language model to select an action, based on the current
view and the trajectory history, that would best fulfill the navigation
instructions. In contrast to the standard setup which adapts a pretrained
language model to work directly with continuous visual features from pretrained
vision models, our approach instead uses (discrete) language as the perceptual
representation. We explore two use cases of our language-based navigation
(LangNav) approach on the R2R vision-and-language navigation benchmark:
generating synthetic trajectories from a prompted large language model (GPT-4)
with which to finetune a smaller language model; and sim-to-real transfer where
we transfer a policy learned on a simulated environment (ALFRED) to a
real-world environment (R2R). Our approach is found to improve upon strong
baselines that rely on visual features in settings where only a few gold
trajectories (10-100) are available, demonstrating the potential of using
language as a perceptual representation for navigation tasks.
</p></li>
</ul>

<h3>Title: Exploring Large Language Models for Multi-Modal Out-of-Distribution Detection. (arXiv:2310.08027v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.08027">http://arxiv.org/abs/2310.08027</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.08027]] Exploring Large Language Models for Multi-Modal Out-of-Distribution Detection(http://arxiv.org/abs/2310.08027)</code></li>
<li>Summary: <p>Out-of-distribution (OOD) detection is essential for reliable and trustworthy
machine learning. Recent multi-modal OOD detection leverages textual
information from in-distribution (ID) class names for visual OOD detection, yet
it currently neglects the rich contextual information of ID classes. Large
language models (LLMs) encode a wealth of world knowledge and can be prompted
to generate descriptive features for each class. Indiscriminately using such
knowledge causes catastrophic damage to OOD detection due to LLMs'
hallucinations, as is observed by our analysis. In this paper, we propose to
apply world knowledge to enhance OOD detection performance through selective
generation from LLMs. Specifically, we introduce a consistency-based
uncertainty calibration method to estimate the confidence score of each
generation. We further extract visual objects from each image to fully
capitalize on the aforementioned world knowledge. Extensive experiments
demonstrate that our method consistently outperforms the state-of-the-art.
</p></li>
</ul>

<h3>Title: Exploring the Relationship between Analogy Identification and Sentence Structure Encoding in Large Language Models. (arXiv:2310.07818v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.07818">http://arxiv.org/abs/2310.07818</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.07818]] Exploring the Relationship between Analogy Identification and Sentence Structure Encoding in Large Language Models(http://arxiv.org/abs/2310.07818)</code></li>
<li>Summary: <p>Identifying analogies plays a pivotal role in human cognition and language
proficiency. In the last decade, there has been extensive research on word
analogies in the form of ``A is to B as C is to D.'' However, there is a
growing interest in analogies that involve longer text, such as sentences and
collections of sentences, which convey analogous meanings. While the current
NLP research community evaluates the ability of Large Language Models (LLMs) to
identify such analogies, the underlying reasons behind these abilities warrant
deeper investigation. Furthermore, the capability of LLMs to encode both
syntactic and semantic structures of language within their embeddings has
garnered significant attention with the surge in their utilization. In this
work, we examine the relationship between the abilities of multiple LLMs to
identify sentence analogies, and their capacity to encode syntactic and
semantic structures. Through our analysis, we find that analogy identification
ability of LLMs is positively correlated with their ability to encode syntactic
and semantic structures of sentences. Specifically, we find that the LLMs which
capture syntactic structures better, also have higher abilities in identifying
sentence analogies.
</p></li>
</ul>

<h3>Title: Does Synthetic Data Make Large Language Models More Efficient?. (arXiv:2310.07830v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.07830">http://arxiv.org/abs/2310.07830</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.07830]] Does Synthetic Data Make Large Language Models More Efficient?(http://arxiv.org/abs/2310.07830)</code></li>
<li>Summary: <p>Natural Language Processing (NLP) has undergone transformative changes with
the advent of deep learning methodologies. One challenge persistently
confronting researchers is the scarcity of high-quality, annotated datasets
that drive these models. This paper explores the nuances of synthetic data
generation in NLP, with a focal point on template-based question generation. By
assessing its advantages, including data augmentation potential and the
introduction of structured variety, we juxtapose these benefits against
inherent limitations, such as the risk of overfitting and the constraints posed
by pre-defined templates. Drawing from empirical evaluations, we demonstrate
the impact of template-based synthetic data on the performance of modern
transformer models. We conclude by emphasizing the delicate balance required
between synthetic and real-world data, and the future trajectories of
integrating synthetic data in model training pipelines. The findings aim to
guide NLP practitioners in harnessing synthetic data's potential, ensuring
optimal model performance in diverse applications.
</p></li>
</ul>

<h3>Title: Synthetic Data Generation with Large Language Models for Text Classification: Potential and Limitations. (arXiv:2310.07849v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.07849">http://arxiv.org/abs/2310.07849</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.07849]] Synthetic Data Generation with Large Language Models for Text Classification: Potential and Limitations(http://arxiv.org/abs/2310.07849)</code></li>
<li>Summary: <p>The collection and curation of high-quality training data is crucial for
developing text classification models with superior performance, but it is
often associated with significant costs and time investment. Researchers have
recently explored using large language models (LLMs) to generate synthetic
datasets as an alternative approach. However, the effectiveness of the
LLM-generated synthetic data in supporting model training is inconsistent
across different classification tasks. To better understand factors that
moderate the effectiveness of the LLM-generated synthetic data, in this study,
we look into how the performance of models trained on these synthetic data may
vary with the subjectivity of classification. Our results indicate that
subjectivity, at both the task level and instance level, is negatively
associated with the performance of the model trained on synthetic data. We
conclude by discussing the implications of our work on the potential and
limitations of leveraging LLM for synthetic data generation.
</p></li>
</ul>

<h3>Title: Harnessing Large Language Models' Empathetic Response Generation Capabilities for Online Mental Health Counselling Support. (arXiv:2310.08017v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.08017">http://arxiv.org/abs/2310.08017</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.08017]] Harnessing Large Language Models' Empathetic Response Generation Capabilities for Online Mental Health Counselling Support(http://arxiv.org/abs/2310.08017)</code></li>
<li>Summary: <p>Large Language Models (LLMs) have demonstrated remarkable performance across
various information-seeking and reasoning tasks. These computational systems
drive state-of-the-art dialogue systems, such as ChatGPT and Bard. They also
carry substantial promise in meeting the growing demands of mental health care,
albeit relatively unexplored. As such, this study sought to examine LLMs'
capability to generate empathetic responses in conversations that emulate those
in a mental health counselling setting. We selected five LLMs: version 3.5 and
version 4 of the Generative Pre-training (GPT), Vicuna FastChat-T5, Pathways
Language Model (PaLM) version 2, and Falcon-7B-Instruct. Based on a simple
instructional prompt, these models responded to utterances derived from the
EmpatheticDialogues (ED) dataset. Using three empathy-related metrics, we
compared their responses to those from traditional response generation dialogue
systems, which were fine-tuned on the ED dataset, along with human-generated
responses. Notably, we discovered that responses from the LLMs were remarkably
more empathetic in most scenarios. We position our findings in light of
catapulting advancements in creating empathetic conversational systems.
</p></li>
</ul>

<h3>Title: QLLM: Accurate and Efficient Low-Bitwidth Quantization for Large Language Models. (arXiv:2310.08041v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.08041">http://arxiv.org/abs/2310.08041</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.08041]] QLLM: Accurate and Efficient Low-Bitwidth Quantization for Large Language Models(http://arxiv.org/abs/2310.08041)</code></li>
<li>Summary: <p>Large Language Models (LLMs) excel in NLP, but their demands hinder their
widespread deployment. While Quantization-Aware Training (QAT) offers a
solution, its extensive training costs make Post-Training Quantization (PTQ) a
more practical approach for LLMs. In existing studies, activation outliers in
particular channels are identified as the bottleneck to PTQ accuracy. They
propose to transform the magnitudes from activations to weights, which however
offers limited alleviation or suffers from unstable gradients, resulting in a
severe performance drop at low-bitwidth. In this paper, we propose QLLM, an
accurate and efficient low-bitwidth PTQ method designed for LLMs. QLLM
introduces an adaptive channel reassembly technique that reallocates the
magnitude of outliers to other channels, thereby mitigating their impact on the
quantization range. This is achieved by channel disassembly and channel
assembly, which first breaks down the outlier channels into several
sub-channels to ensure a more balanced distribution of activation magnitudes.
Then similar channels are merged to maintain the original channel number for
efficiency. Additionally, an adaptive strategy is designed to autonomously
determine the optimal number of sub-channels for channel disassembly. To
further compensate for the performance loss caused by quantization, we propose
an efficient tuning method that only learns a small number of low-rank weights
while freezing the pre-trained quantized model. After training, these low-rank
parameters can be fused into the frozen weights without affecting inference.
Extensive experiments on LLaMA-1 and LLaMA-2 show that QLLM can obtain accurate
quantized models efficiently. For example, QLLM quantizes the 4-bit LLaMA-2-70B
within 10 hours on a single A100-80G GPU, outperforming the previous
state-of-the-art method by 7.89% on the average accuracy across five zero-shot
tasks.
</p></li>
</ul>

<h3>Title: Promptor: A Conversational and Autonomous Prompt Generation Agent for Intelligent Text Entry Techniques. (arXiv:2310.08101v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.08101">http://arxiv.org/abs/2310.08101</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.08101]] Promptor: A Conversational and Autonomous Prompt Generation Agent for Intelligent Text Entry Techniques(http://arxiv.org/abs/2310.08101)</code></li>
<li>Summary: <p>Text entry is an essential task in our day-to-day digital interactions.
Numerous intelligent features have been developed to streamline this process,
making text entry more effective, efficient, and fluid. These improvements
include sentence prediction and user personalization. However, as deep
learning-based language models become the norm for these advanced features, the
necessity for data collection and model fine-tuning increases. These challenges
can be mitigated by harnessing the in-context learning capability of large
language models such as GPT-3.5. This unique feature allows the language model
to acquire new skills through prompts, eliminating the need for data collection
and fine-tuning. Consequently, large language models can learn various text
prediction techniques. We initially showed that, for a sentence prediction
task, merely prompting GPT-3.5 surpassed a GPT-2 backed system and is
comparable with a fine-tuned GPT-3.5 model, with the latter two methods
requiring costly data collection, fine-tuning and post-processing. However, the
task of prompting large language models to specialize in specific text
prediction tasks can be challenging, particularly for designers without
expertise in prompt engineering. To address this, we introduce Promptor, a
conversational prompt generation agent designed to engage proactively with
designers. Promptor can automatically generate complex prompts tailored to meet
specific needs, thus offering a solution to this challenge. We conducted a user
study involving 24 participants creating prompts for three intelligent text
entry tasks, half of the participants used Promptor while the other half
designed prompts themselves. The results show that Promptor-designed prompts
result in a 35% increase in similarity and 22% in coherence over those by
designers.
</p></li>
</ul>

<h3>Title: QASiNa: Religious Domain Question Answering using Sirah Nabawiyah. (arXiv:2310.08102v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.08102">http://arxiv.org/abs/2310.08102</a></li>
<li>Code URL: https://github.com/rizquuula/QASiNa</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.08102]] QASiNa: Religious Domain Question Answering using Sirah Nabawiyah(http://arxiv.org/abs/2310.08102)</code></li>
<li>Summary: <p>Nowadays, Question Answering (QA) tasks receive significant research focus,
particularly with the development of Large Language Model (LLM) such as Chat
GPT [1]. LLM can be applied to various domains, but it contradicts the
principles of information transmission when applied to the Islamic domain. In
Islam we strictly regulates the sources of information and who can give
interpretations or tafseer for that sources [2]. The approach used by LLM to
generate answers based on its own interpretation is similar to the concept of
tafseer, LLM is neither an Islamic expert nor a human which is not permitted in
Islam. Indonesia is the country with the largest Islamic believer population in
the world [3]. With the high influence of LLM, we need to make evaluation of
LLM in religious domain. Currently, there is only few religious QA dataset
available and none of them using Sirah Nabawiyah especially in Indonesian
Language. In this paper, we propose the Question Answering Sirah Nabawiyah
(QASiNa) dataset, a novel dataset compiled from Sirah Nabawiyah literatures in
Indonesian language. We demonstrate our dataset by using mBERT [4], XLM-R [5],
and IndoBERT [6] which fine-tuned with Indonesian translation of SQuAD v2.0
[7]. XLM-R model returned the best performance on QASiNa with EM of 61.20,
F1-Score of 75.94, and Substring Match of 70.00. We compare XLM-R performance
with Chat GPT-3.5 and GPT-4 [1]. Both Chat GPT version returned lower EM and
F1-Score with higher Substring Match, the gap of EM and Substring Match get
wider in GPT-4. The experiment indicate that Chat GPT tends to give excessive
interpretations as evidenced by its higher Substring Match scores compared to
EM and F1-Score, even after providing instruction and context. This concludes
Chat GPT is unsuitable for question answering task in religious domain
especially for Islamic religion.
</p></li>
</ul>

<h3>Title: Multiclass Classification of Policy Documents with Large Language Models. (arXiv:2310.08167v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.08167">http://arxiv.org/abs/2310.08167</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.08167]] Multiclass Classification of Policy Documents with Large Language Models(http://arxiv.org/abs/2310.08167)</code></li>
<li>Summary: <p>Classifying policy documents into policy issue topics has been a long-time
effort in political science and communication disciplines. Efforts to automate
text classification processes for social science research purposes have so far
achieved remarkable results, but there is still a large room for progress. In
this work, we test the prediction performance of an alternative strategy, which
requires human involvement much less than full manual coding. We use the GPT
3.5 and GPT 4 models of the OpenAI, which are pre-trained instruction-tuned
Large Language Models (LLM), to classify congressional bills and congressional
hearings into Comparative Agendas Project's 21 major policy issue topics. We
propose three use-case scenarios and estimate overall accuracies ranging from
%58-83 depending on scenario and GPT model employed. The three scenarios aims
at minimal, moderate, and major human interference, respectively. Overall, our
results point towards the insufficiency of complete reliance on GPT with
minimal human intervention, an increasing accuracy along with the human effort
exerted, and a surprisingly high accuracy achieved in the most humanly
demanding use-case. However, the superior use-case achieved the %83 accuracy on
the %65 of the data in which the two models agreed, suggesting that a similar
approach to ours can be relatively easily implemented and allow for mostly
automated coding of a majority of a given dataset. This could free up resources
allowing manual human coding of the remaining %35 of the data to achieve an
overall higher level of accuracy while reducing costs significantly.
</p></li>
</ul>

<h3>Title: Exploring the Cognitive Knowledge Structure of Large Language Models: An Educational Diagnostic Assessment Approach. (arXiv:2310.08172v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.08172">http://arxiv.org/abs/2310.08172</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.08172]] Exploring the Cognitive Knowledge Structure of Large Language Models: An Educational Diagnostic Assessment Approach(http://arxiv.org/abs/2310.08172)</code></li>
<li>Summary: <p>Large Language Models (LLMs) have not only exhibited exceptional performance
across various tasks, but also demonstrated sparks of intelligence. Recent
studies have focused on assessing their capabilities on human exams and
revealed their impressive competence in different domains. However, cognitive
research on the overall knowledge structure of LLMs is still lacking. In this
paper, based on educational diagnostic assessment method, we conduct an
evaluation using MoocRadar, a meticulously annotated human test dataset based
on Bloom Taxonomy. We aim to reveal the knowledge structures of LLMs and gain
insights of their cognitive capabilities. This research emphasizes the
significance of investigating LLMs' knowledge and understanding the disparate
cognitive patterns of LLMs. By shedding light on models' knowledge, researchers
can advance development and utilization of LLMs in a more informed and
effective manner.
</p></li>
</ul>

<h3>Title: Impact of Co-occurrence on Factual Knowledge of Large Language Models. (arXiv:2310.08256v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.08256">http://arxiv.org/abs/2310.08256</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.08256]] Impact of Co-occurrence on Factual Knowledge of Large Language Models(http://arxiv.org/abs/2310.08256)</code></li>
<li>Summary: <p>Large language models (LLMs) often make factually incorrect responses despite
their success in various applications. In this paper, we hypothesize that
relying heavily on simple co-occurrence statistics of the pre-training corpora
is one of the main factors that cause factual errors. Our results reveal that
LLMs are vulnerable to the co-occurrence bias, defined as preferring frequently
co-occurred words over the correct answer. Consequently, LLMs struggle to
recall facts whose subject and object rarely co-occur in the pre-training
dataset although they are seen during finetuning. We show that co-occurrence
bias remains despite scaling up model sizes or finetuning. Therefore, we
suggest finetuning on a debiased dataset to mitigate the bias by filtering out
biased samples whose subject-object co-occurrence count is high. Although
debiased finetuning allows LLMs to memorize rare facts in the training set, it
is not effective in recalling rare facts unseen during finetuning. Further
research in mitigation will help build reliable language models by preventing
potential errors. The code is available at
\url{https://github.com/CheongWoong/impact_of_cooccurrence}.
</p></li>
</ul>

<h3>Title: CP-KGC: Constrained-Prompt Knowledge Graph Completion with Large Language Models. (arXiv:2310.08279v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.08279">http://arxiv.org/abs/2310.08279</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.08279]] CP-KGC: Constrained-Prompt Knowledge Graph Completion with Large Language Models(http://arxiv.org/abs/2310.08279)</code></li>
<li>Summary: <p>Knowledge graph completion (KGC) aims to utilize existing knowledge to deduce
and infer missing connections within knowledge graphs. Text-based approaches,
like SimKGC, have outperformed graph embedding methods, showcasing the promise
of inductive KGC. However, the efficacy of text-based methods hinges on the
quality of entity textual descriptions. In this paper, we identify the key
issue of whether large language models (LLMs) can generate effective text. To
mitigate hallucination in LLM-generated text in this paper, we introduce a
constraint-based prompt that utilizes the entity and its textual description as
contextual constraints to enhance data quality. Our Constrained-Prompt
Knowledge Graph Completion (CP-KGC) method demonstrates effective inference
under low resource computing conditions and surpasses prior results on the
WN18RR and FB15K237 datasets. This showcases the integration of LLMs in KGC
tasks and provides new directions for future research.
</p></li>
</ul>

<h3>Title: Not All Demonstration Examples are Equally Beneficial: Reweighting Demonstration Examples for In-Context Learning. (arXiv:2310.08309v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.08309">http://arxiv.org/abs/2310.08309</a></li>
<li>Code URL: https://github.com/Zhe-Young/WICL</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.08309]] Not All Demonstration Examples are Equally Beneficial: Reweighting Demonstration Examples for In-Context Learning(http://arxiv.org/abs/2310.08309)</code></li>
<li>Summary: <p>Large Language Models (LLMs) have recently gained the In-Context Learning
(ICL) ability with the models scaling up, allowing them to quickly adapt to
downstream tasks with only a few demonstration examples prepended in the input
sequence. Nonetheless, the current practice of ICL treats all demonstration
examples equally, which still warrants improvement, as the quality of examples
is usually uneven. In this paper, we investigate how to determine approximately
optimal weights for demonstration examples and how to apply them during ICL. To
assess the quality of weights in the absence of additional validation data, we
design a masked self-prediction (MSP) score that exhibits a strong correlation
with the final ICL performance. To expedite the weight-searching process, we
discretize the continuous weight space and adopt beam search. With
approximately optimal weights obtained, we further propose two strategies to
apply them to demonstrations at different model positions. Experimental results
on 8 text classification tasks show that our approach outperforms conventional
ICL by a large margin. Our code are publicly available at
https:github.com/Zhe-Young/WICL.
</p></li>
</ul>

<h3>Title: Large Language Models Are Zero-Shot Time Series Forecasters. (arXiv:2310.07820v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.07820">http://arxiv.org/abs/2310.07820</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.07820]] Large Language Models Are Zero-Shot Time Series Forecasters(http://arxiv.org/abs/2310.07820)</code></li>
<li>Summary: <p>By encoding time series as a string of numerical digits, we can frame time
series forecasting as next-token prediction in text. Developing this approach,
we find that large language models (LLMs) such as GPT-3 and LLaMA-2 can
surprisingly zero-shot extrapolate time series at a level comparable to or
exceeding the performance of purpose-built time series models trained on the
downstream tasks. To facilitate this performance, we propose procedures for
effectively tokenizing time series data and converting discrete distributions
over tokens into highly flexible densities over continuous values. We argue the
success of LLMs for time series stems from their ability to naturally represent
multimodal distributions, in conjunction with biases for simplicity, and
repetition, which align with the salient features in many time series, such as
repeated seasonal trends. We also show how LLMs can naturally handle missing
data without imputation through non-numerical text, accommodate textual side
information, and answer questions to help explain predictions. While we find
that increasing model size generally improves performance on time series, we
show GPT-4 can perform worse than GPT-3 because of how it tokenizes numbers,
and poor uncertainty calibration, which is likely the result of alignment
interventions such as RLHF.
</p></li>
</ul>

<h3>Title: Interpreting Reward Models in RLHF-Tuned Language Models Using Sparse Autoencoders. (arXiv:2310.08164v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.08164">http://arxiv.org/abs/2310.08164</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.08164]] Interpreting Reward Models in RLHF-Tuned Language Models Using Sparse Autoencoders(http://arxiv.org/abs/2310.08164)</code></li>
<li>Summary: <p>Large language models (LLMs) aligned to human preferences via reinforcement
learning from human feedback (RLHF) underpin many commercial applications.
However, how RLHF impacts LLM internals remains opaque. We propose a novel
method to interpret learned reward functions in RLHF-tuned LLMs using sparse
autoencoders. Our approach trains autoencoder sets on activations from a base
LLM and its RLHF-tuned version. By comparing autoencoder hidden spaces, we
identify unique features that reflect the accuracy of the learned reward model.
To quantify this, we construct a scenario where the tuned LLM learns
token-reward mappings to maximize reward. This is the first application of
sparse autoencoders for interpreting learned rewards and broadly inspecting
reward learning in LLMs. Our method provides an abstract approximation of
reward integrity. This presents a promising technique for ensuring alignment
between specified objectives and model behaviors.
</p></li>
</ul>

<h2>segmentation</h2>
<h3>Title: Deep Learning based Systems for Crater Detection: A Review. (arXiv:2310.07727v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.07727">http://arxiv.org/abs/2310.07727</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.07727]] Deep Learning based Systems for Crater Detection: A Review(http://arxiv.org/abs/2310.07727)</code></li>
<li>Summary: <p>Craters are one of the most prominent features on planetary surfaces, used in
applications such as age estimation, hazard detection, and spacecraft
navigation. Crater detection is a challenging problem due to various aspects,
including complex crater characteristics such as varying sizes and shapes, data
resolution, and planetary data types. Similar to other computer vision tasks,
deep learning-based approaches have significantly impacted research on crater
detection in recent years. This survey aims to assist researchers in this field
by examining the development of deep learning-based crater detection algorithms
(CDAs). The review includes over 140 research works covering diverse crater
detection approaches, including planetary data, craters database, and
evaluation metrics. To be specific, we discuss the challenges in crater
detection due to the complex properties of the craters and survey the DL-based
CDAs by categorizing them into three parts: (a) semantic segmentation-based,
(b) object detection-based, and (c) classification-based. Additionally, we have
conducted training and testing of all the semantic segmentation-based CDAs on a
common dataset to evaluate the effectiveness of each architecture for crater
detection and its potential applications. Finally, we have provided
recommendations for potential future works.
</p></li>
</ul>

<h3>Title: PointHR: Exploring High-Resolution Architectures for 3D Point Cloud Segmentation. (arXiv:2310.07743v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.07743">http://arxiv.org/abs/2310.07743</a></li>
<li>Code URL: https://github.com/haibo-qiu/PointHR</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.07743]] PointHR: Exploring High-Resolution Architectures for 3D Point Cloud Segmentation(http://arxiv.org/abs/2310.07743)</code></li>
<li>Summary: <p>Significant progress has been made recently in point cloud segmentation
utilizing an encoder-decoder framework, which initially encodes point clouds
into low-resolution representations and subsequently decodes high-resolution
predictions. Inspired by the success of high-resolution architectures in image
dense prediction, which always maintains a high-resolution representation
throughout the entire learning process, we consider it also highly important
for 3D dense point cloud analysis. Therefore, in this paper, we explore
high-resolution architectures for 3D point cloud segmentation. Specifically, we
generalize high-resolution architectures using a unified pipeline named
PointHR, which includes a knn-based sequence operator for feature extraction
and a differential resampling operator to efficiently communicate different
resolutions. Additionally, we propose to avoid numerous on-the-fly computations
of high-resolution architectures by pre-computing the indices for both sequence
and resampling operators. By doing so, we deliver highly competitive
high-resolution architectures while capitalizing on the benefits of
well-designed point cloud blocks without additional effort. To evaluate these
architectures for dense point cloud analysis, we conduct thorough experiments
using S3DIS and ScanNetV2 datasets, where the proposed PointHR outperforms
recent state-of-the-art methods without any bells and whistles. The source code
is available at \url{https://github.com/haibo-qiu/PointHR}.
</p></li>
</ul>

<h3>Title: CrIBo: Self-Supervised Learning via Cross-Image Object-Level Bootstrapping. (arXiv:2310.07855v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.07855">http://arxiv.org/abs/2310.07855</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.07855]] CrIBo: Self-Supervised Learning via Cross-Image Object-Level Bootstrapping(http://arxiv.org/abs/2310.07855)</code></li>
<li>Summary: <p>Leveraging nearest neighbor retrieval for self-supervised representation
learning has proven beneficial with object-centric images. However, this
approach faces limitations when applied to scene-centric datasets, where
multiple objects within an image are only implicitly captured in the global
representation. Such global bootstrapping can lead to undesirable entanglement
of object representations. Furthermore, even object-centric datasets stand to
benefit from a finer-grained bootstrapping approach. In response to these
challenges, we introduce a novel Cross-Image Object-Level Bootstrapping method
tailored to enhance dense visual representation learning. By employing
object-level nearest neighbor bootstrapping throughout the training, CrIBo
emerges as a notably strong and adequate candidate for in-context learning,
leveraging nearest neighbor retrieval at test time. CrIBo shows
state-of-the-art performance on the latter task while being highly competitive
in more standard downstream segmentation tasks. Our code and pretrained models
will be publicly available upon acceptance.
</p></li>
</ul>

<h3>Title: BaSAL: Size Balanced Warm Start Active Learning for LiDAR Semantic Segmentation. (arXiv:2310.08035v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.08035">http://arxiv.org/abs/2310.08035</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.08035]] BaSAL: Size Balanced Warm Start Active Learning for LiDAR Semantic Segmentation(http://arxiv.org/abs/2310.08035)</code></li>
<li>Summary: <p>Active learning strives to reduce the need for costly data annotation, by
repeatedly querying an annotator to label the most informative samples from a
pool of unlabeled data and retraining a model from these samples. We identify
two problems with existing active learning methods for LiDAR semantic
segmentation. First, they ignore the severe class imbalance inherent in LiDAR
semantic segmentation datasets. Second, to bootstrap the active learning loop,
they train their initial model from randomly selected data samples, which leads
to low performance and is referred to as the cold start problem. To address
these problems we propose BaSAL, a size-balanced warm start active learning
model, based on the observation that each object class has a characteristic
size. By sampling object clusters according to their size, we can thus create a
size-balanced dataset that is also more class-balanced. Furthermore, in
contrast to existing information measures like entropy or CoreSet, size-based
sampling does not require an already trained model and thus can be used to
address the cold start problem. Results show that we are able to improve the
performance of the initial model by a large margin. Combining size-balanced
sampling and warm start with established information measures, our approach
achieves a comparable performance to training on the entire SemanticKITTI
dataset, despite using only 5% of the annotations, which outperforms existing
active learning methods. We also match the existing state-of-the-art in active
learning on nuScenes. Our code will be made available upon paper acceptance.
</p></li>
</ul>

<h3>Title: Volumetric Medical Image Segmentation via Scribble Annotations and Shape Priors. (arXiv:2310.08084v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.08084">http://arxiv.org/abs/2310.08084</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.08084]] Volumetric Medical Image Segmentation via Scribble Annotations and Shape Priors(http://arxiv.org/abs/2310.08084)</code></li>
<li>Summary: <p>Recently, weakly-supervised image segmentation using weak annotations like
scribbles has gained great attention in computer vision and medical image
analysis, since such annotations are much easier to obtain compared to
time-consuming and labor-intensive labeling at the pixel/voxel level. However,
due to a lack of structure supervision on regions of interest (ROIs), existing
scribble-based methods suffer from poor boundary localization. Furthermore,
most current methods are designed for 2D image segmentation, which do not fully
leverage the volumetric information if directly applied to each image slice. In
this paper, we propose a scribble-based volumetric image segmentation,
Scribble2D5, which tackles 3D anisotropic image segmentation and aims to its
improve boundary prediction. To achieve this, we augment a 2.5D attention UNet
with a proposed label propagation module to extend semantic information from
scribbles and use a combination of static and active boundary prediction to
learn ROI's boundary and regularize its shape. Also, we propose an optional
add-on component, which incorporates the shape prior information from unpaired
segmentation masks to further improve model accuracy. Extensive experiments on
three public datasets and one private dataset demonstrate our Scribble2D5
achieves state-of-the-art performance on volumetric image segmentation using
scribbles and shape prior if available.
</p></li>
</ul>

<h3>Title: GraphAlign: Enhancing Accurate Feature Alignment by Graph matching for Multi-Modal 3D Object Detection. (arXiv:2310.08261v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.08261">http://arxiv.org/abs/2310.08261</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.08261]] GraphAlign: Enhancing Accurate Feature Alignment by Graph matching for Multi-Modal 3D Object Detection(http://arxiv.org/abs/2310.08261)</code></li>
<li>Summary: <p>LiDAR and cameras are complementary sensors for 3D object detection in
autonomous driving. However, it is challenging to explore the unnatural
interaction between point clouds and images, and the critical factor is how to
conduct feature alignment of heterogeneous modalities. Currently, many methods
achieve feature alignment by projection calibration only, without considering
the problem of coordinate conversion accuracy errors between sensors, leading
to sub-optimal performance. In this paper, we present GraphAlign, a more
accurate feature alignment strategy for 3D object detection by graph matching.
Specifically, we fuse image features from a semantic segmentation encoder in
the image branch and point cloud features from a 3D Sparse CNN in the LiDAR
branch. To save computation, we construct the nearest neighbor relationship by
calculating Euclidean distance within the subspaces that are divided into the
point cloud features. Through the projection calibration between the image and
point cloud, we project the nearest neighbors of point cloud features onto the
image features. Then by matching the nearest neighbors with a single point
cloud to multiple images, we search for a more appropriate feature alignment.
In addition, we provide a self-attention module to enhance the weights of
significant relations to fine-tune the feature alignment between heterogeneous
modalities. Extensive experiments on nuScenes benchmark demonstrate the
effectiveness and efficiency of our GraphAlign.
</p></li>
</ul>

<h3>Title: Multimodal Variational Auto-encoder based Audio-Visual Segmentation. (arXiv:2310.08303v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.08303">http://arxiv.org/abs/2310.08303</a></li>
<li>Code URL: https://github.com/opennlplab/mmvae-avs</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.08303]] Multimodal Variational Auto-encoder based Audio-Visual Segmentation(http://arxiv.org/abs/2310.08303)</code></li>
<li>Summary: <p>We propose an Explicit Conditional Multimodal Variational Auto-Encoder
(ECMVAE) for audio-visual segmentation (AVS), aiming to segment sound sources
in the video sequence. Existing AVS methods focus on implicit feature fusion
strategies, where models are trained to fit the discrete samples in the
dataset. With a limited and less diverse dataset, the resulting performance is
usually unsatisfactory. In contrast, we address this problem from an effective
representation learning perspective, aiming to model the contribution of each
modality explicitly. Specifically, we find that audio contains critical
category information of the sound producers, and visual data provides candidate
sound producer(s). Their shared information corresponds to the target sound
producer(s) shown in the visual data. In this case, cross-modal shared
representation learning is especially important for AVS. To achieve this, our
ECMVAE factorizes the representations of each modality with a modality-shared
representation and a modality-specific representation. An orthogonality
constraint is applied between the shared and specific representations to
maintain the exclusive attribute of the factorized latent code. Further, a
mutual information maximization regularizer is introduced to achieve extensive
exploration of each modality. Quantitative and qualitative evaluations on the
AVSBench demonstrate the effectiveness of our approach, leading to a new
state-of-the-art for AVS, with a 3.84 mIOU performance leap on the challenging
MS3 subset for multiple sound source segmentation.
</p></li>
</ul>

<h3>Title: To token or not to token: A Comparative Study of Text Representations for Cross-Lingual Transfer. (arXiv:2310.08078v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.08078">http://arxiv.org/abs/2310.08078</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.08078]] To token or not to token: A Comparative Study of Text Representations for Cross-Lingual Transfer(http://arxiv.org/abs/2310.08078)</code></li>
<li>Summary: <p>Choosing an appropriate tokenization scheme is often a bottleneck in
low-resource cross-lingual transfer. To understand the downstream implications
of text representation choices, we perform a comparative analysis on language
models having diverse text representation modalities including 2
segmentation-based models (\texttt{BERT}, \texttt{mBERT}), 1 image-based model
(\texttt{PIXEL}), and 1 character-level model (\texttt{CANINE}). First, we
propose a scoring Language Quotient (LQ) metric capable of providing a weighted
representation of both zero-shot and few-shot evaluation combined. Utilizing
this metric, we perform experiments comprising 19 source languages and 133
target languages on three tasks (POS tagging, Dependency parsing, and NER). Our
analysis reveals that image-based models excel in cross-lingual transfer when
languages are closely related and share visually similar scripts. However, for
tasks biased toward word meaning (POS, NER), segmentation-based models prove to
be superior. Furthermore, in dependency parsing tasks where word relationships
play a crucial role, models with their character-level focus, outperform
others. Finally, we propose a recommendation scheme based on our findings to
guide model selection according to task and language requirements.
</p></li>
</ul>

<button id="copy">Copy All</button>
</article>
<script src="https://cdn.staticfile.org/clipboard.js/2.0.4/clipboard.min.js"></script>
<script src="../../javascript/clipboard.js"></script>
