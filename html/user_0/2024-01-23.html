<link rel="stylesheet" href="../../css/markdown.css" />
<article class="markdown-body">
<h1>2024-01-23</h1>
<h3>Title: AI in Supply Chain Risk Assessment: A Systematic Literature Review and  Bibliometric Analysis</h3>
<ul>
<li><strong>Authors: </strong>Md Abrar Jahin, Saleh Akram Naife, Anik Kumar Saha, M. F. Mridha</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CE</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.10895">https://arxiv.org/abs/2401.10895</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.10895">https://arxiv.org/pdf/2401.10895</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.10895]] AI in Supply Chain Risk Assessment: A Systematic Literature Review and  Bibliometric Analysis(https://arxiv.org/abs/2401.10895)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Supply chain risk assessment (SCRA) has witnessed a profound evolution through the integration of artificial intelligence (AI) and machine learning (ML) techniques, revolutionizing predictive capabilities and risk mitigation strategies. The significance of this evolution stems from the critical role of robust risk management strategies in ensuring operational resilience and continuity within modern supply chains. Previous reviews have outlined established methodologies but have overlooked emerging AI/ML techniques, leaving a notable research gap in understanding their practical implications within SCRA. This paper conducts a systematic literature review combined with a comprehensive bibliometric analysis. We meticulously examined 1,717 papers and derived key insights from a select group of 48 articles published between 2014 and 2023. The review fills this research gap by addressing pivotal research questions, and exploring existing AI/ML techniques, methodologies, findings, and future trajectories, thereby providing a more encompassing view of the evolving landscape of SCRA. Our study unveils the transformative impact of AI/ML models, such as Random Forest, XGBoost, and hybrids, in substantially enhancing precision within SCRA. It underscores adaptable post-COVID strategies, advocating for resilient contingency plans and aligning with evolving risk landscapes. Significantly, this review surpasses previous examinations by accentuating emerging AI/ML techniques and their practical implications within SCRA. Furthermore, it highlights the contributions through a comprehensive bibliometric analysis, revealing publication trends, influential authors, and highly cited articles.</li>
</ul>

<h3>Title: One Step Learning, One Step Review</h3>
<ul>
<li><strong>Authors: </strong>Xiaolong Huang, Qiankun Li, Xueran Li, Xuesong Gao</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.10962">https://arxiv.org/abs/2401.10962</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.10962">https://arxiv.org/pdf/2401.10962</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.10962]] One Step Learning, One Step Review(https://arxiv.org/abs/2401.10962)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>Visual fine-tuning has garnered significant attention with the rise of pre-trained vision models. The current prevailing method, full fine-tuning, suffers from the issue of knowledge forgetting as it focuses solely on fitting the downstream training set. In this paper, we propose a novel weight rollback-based fine-tuning method called OLOR (One step Learning, One step Review). OLOR combines fine-tuning with optimizers, incorporating a weight rollback term into the weight update term at each step. This ensures consistency in the weight range of upstream and downstream models, effectively mitigating knowledge forgetting and enhancing fine-tuning performance. In addition, a layer-wise penalty is presented to employ penalty decay and the diversified decay rate to adjust the weight rollback levels of layers for adapting varying downstream tasks. Through extensive experiments on various tasks such as image classification, object detection, semantic segmentation, and instance segmentation, we demonstrate the general applicability and state-of-the-art performance of our proposed OLOR. Code is available at https://github.com/rainbow-xiao/OLOR-AAAI-2024.</li>
</ul>

<h3>Title: The Radiation Oncology NLP Database</h3>
<ul>
<li><strong>Authors: </strong>Zhengliang Liu, Jason Holmes, Wenxiong Liao, Chenbin Liu, Lian Zhang, Hongying Feng, Peilong Wang, Muhammad Ali Elahi, Hongmin Cai, Lichao Sun, Quanzheng Li, Xiang Li, Tianming Liu, Jiajian Shen, Wei Liu</a></li>
<li><strong>Subjects: </strong>cs.CL, physics.med-ph</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.10995">https://arxiv.org/abs/2401.10995</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.10995">https://arxiv.org/pdf/2401.10995</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.10995]] The Radiation Oncology NLP Database(https://arxiv.org/abs/2401.10995)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>We present the Radiation Oncology NLP Database (ROND), the first dedicated Natural Language Processing (NLP) dataset for radiation oncology, an important medical specialty that has received limited attention from the NLP community in the past. With the advent of Artificial General Intelligence (AGI), there is an increasing need for specialized datasets and benchmarks to facilitate research and development. ROND is specifically designed to address this gap in the domain of radiation oncology, a field that offers many opportunities for NLP exploration. It encompasses various NLP tasks including Logic Reasoning, Text Classification, Named Entity Recognition (NER), Question Answering (QA), Text Summarization, and Patient-Clinician Conversations, each with a distinct focus on radiation oncology concepts and application cases. In addition, we have developed an instruction-tuning dataset consisting of over 20k instruction pairs (based on ROND) and trained a large language model, CancerChat. This serves to demonstrate the potential of instruction-tuning large language models within a highly-specialized medical domain. The evaluation results in this study could serve as baseline results for future research. ROND aims to stimulate advancements in radiation oncology and clinical NLP by offering a platform for testing and improving algorithms and models in a domain-specific context. The ROND dataset is a joint effort of multiple U.S. health institutions. The data is available at https://github.com/zl-liu/Radiation-Oncology-NLP-Database.</li>
</ul>

<h3>Title: Fast Registration of Photorealistic Avatars for VR Facial Animation</h3>
<ul>
<li><strong>Authors: </strong>Chaitanya Patel, Shaojie Bai, Te-Li Wang, Jason Saragih, Shih-En Wei</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.11002">https://arxiv.org/abs/2401.11002</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.11002">https://arxiv.org/pdf/2401.11002</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.11002]] Fast Registration of Photorealistic Avatars for VR Facial Animation(https://arxiv.org/abs/2401.11002)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Virtual Reality (VR) bares promise of social interactions that can feel more immersive than other media. Key to this is the ability to accurately animate a photorealistic avatar of one's likeness while wearing a VR headset. Although high quality registration of person-specific avatars to headset-mounted camera (HMC) images is possible in an offline setting, the performance of generic realtime models are significantly degraded. Online registration is also challenging due to oblique camera views and differences in modality. In this work, we first show that the domain gap between the avatar and headset-camera images is one of the primary sources of difficulty, where a transformer-based architecture achieves high accuracy on domain-consistent data, but degrades when the domain-gap is re-introduced. Building on this finding, we develop a system design that decouples the problem into two parts: 1) an iterative refinement module that takes in-domain inputs, and 2) a generic avatar-guided image-to-image style transfer module that is conditioned on current estimation of expression and head pose. These two modules reinforce each other, as image style transfer becomes easier when close-to-ground-truth examples are shown, and better domain-gap removal helps registration. Our system produces high-quality results efficiently, obviating the need for costly offline registration to generate personalized labels. We validate the accuracy and efficiency of our approach through extensive experiments on a commodity headset, demonstrating significant improvements over direct regression methods as well as offline registration.</li>
</ul>

<h3>Title: Communication Efficient and Provable Federated Unlearning</h3>
<ul>
<li><strong>Authors: </strong>Youming Tao, Cheng-Long Wang, Miao Pan, Dongxiao Yu, Xiuzhen Cheng, Di Wang</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.DC</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.11018">https://arxiv.org/abs/2401.11018</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.11018">https://arxiv.org/pdf/2401.11018</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.11018]] Communication Efficient and Provable Federated Unlearning(https://arxiv.org/abs/2401.11018)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, federate</a></li>
<li><strong>Abstract: </strong>We study federated unlearning, a novel problem to eliminate the impact of specific clients or data points on the global model learned via federated learning (FL). This problem is driven by the right to be forgotten and the privacy challenges in FL. We introduce a new framework for exact federated unlearning that meets two essential criteria: \textit{communication efficiency} and \textit{exact unlearning provability}. To our knowledge, this is the first work to tackle both aspects coherently. We start by giving a rigorous definition of \textit{exact} federated unlearning, which guarantees that the unlearned model is statistically indistinguishable from the one trained without the deleted data. We then pinpoint the key property that enables fast exact federated unlearning: total variation (TV) stability, which measures the sensitivity of the model parameters to slight changes in the dataset. Leveraging this insight, we develop a TV-stable FL algorithm called \texttt{FATS}, which modifies the classical \texttt{\underline{F}ed\underline{A}vg} algorithm for \underline{T}V \underline{S}tability and employs local SGD with periodic averaging to lower the communication round. We also design efficient unlearning algorithms for \texttt{FATS} under two settings: client-level and sample-level unlearning. We provide theoretical guarantees for our learning and unlearning algorithms, proving that they achieve exact federated unlearning with reasonable convergence rates for both the original and unlearned models. We empirically validate our framework on 6 benchmark datasets, and show its superiority over state-of-the-art methods in terms of accuracy, communication cost, computation cost, and unlearning efficacy.</li>
</ul>

<h3>Title: Analysis and Detection of Multilingual Hate Speech Using Transformer  Based Deep Learning</h3>
<ul>
<li><strong>Authors: </strong>Arijit Das, Somashree Nandy, Rupam Saha, Srijan Das, Diganta Saha</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.11021">https://arxiv.org/abs/2401.11021</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.11021">https://arxiv.org/pdf/2401.11021</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.11021]] Analysis and Detection of Multilingual Hate Speech Using Transformer  Based Deep Learning(https://arxiv.org/abs/2401.11021)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack, transformer</a></li>
<li><strong>Abstract: </strong>Hate speech is harmful content that directly attacks or promotes hatred against members of groups or individuals based on actual or perceived aspects of identity, such as racism, religion, or sexual orientation. This can affect social life on social media platforms as hateful content shared through social media can harm both individuals and communities. As the prevalence of hate speech increases online, the demand for automated detection as an NLP task is increasing. In this work, the proposed method is using transformer-based model to detect hate speech in social media, like twitter, Facebook, WhatsApp, Instagram, etc. The proposed model is independent of languages and has been tested on Italian, English, German, Bengali. The Gold standard datasets were collected from renowned researcher Zeerak Talat, Sara Tonelli, Melanie Siegel, and Rezaul Karim. The success rate of the proposed model for hate speech detection is higher than the existing baseline and state-of-the-art models with accuracy in Bengali dataset is 89%, in English: 91%, in German dataset 91% and in Italian dataset it is 77%. The proposed algorithm shows substantial improvement to the benchmark method.</li>
</ul>

<h3>Title: Exploring Highly Quantised Neural Networks for Intrusion Detection in  Automotive CAN</h3>
<ul>
<li><strong>Authors: </strong>Shashwat Khandelwal, Shreejith Shanker</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.AR, cs.LG, eess.SY</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.11030">https://arxiv.org/abs/2401.11030</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.11030">https://arxiv.org/pdf/2401.11030</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.11030]] Exploring Highly Quantised Neural Networks for Intrusion Detection in  Automotive CAN(https://arxiv.org/abs/2401.11030)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack</a></li>
<li><strong>Abstract: </strong>Vehicles today comprise intelligent systems like connected autonomous driving and advanced driving assistance systems (ADAS) to enhance the driving experience, which is enabled through increased connectivity to infrastructure and fusion of information from different sensing modes. However, the rising connectivity coupled with the legacy network architecture within vehicles can be exploited for launching active and passive attacks on critical vehicle systems and directly affecting the safety of passengers. Machine learning-based intrusion detection models have been shown to successfully detect multiple targeted attack vectors in recent literature, whose deployments are enabled through quantised neural networks targeting low-power platforms. Multiple models are often required to simultaneously detect multiple attack vectors, increasing the area, (resource) cost, and energy consumption. In this paper, we present a case for utilising custom-quantised MLP's (CQMLP) as a multi-class classification model, capable of detecting multiple attacks from the benign flow of controller area network (CAN) messages. The specific quantisation and neural architecture are determined through a joint design space exploration, resulting in our choice of the 2-bit precision and the n-layer MLP. Our 2-bit version is trained using Brevitas and optimised as a dataflow hardware model through the FINN toolflow from AMD/Xilinx, targeting an XCZU7EV device. We show that the 2-bit CQMLP model, when integrated as the IDS, can detect malicious attack messages (DoS, fuzzing, and spoofing attack) with a very high accuracy of 99.9%, on par with the state-of-the-art methods in the literature. Furthermore, the dataflow model can perform line rate detection at a latency of 0.11 ms from message reception while consuming 0.23 mJ/inference, making it ideally suited for integration with an ECU in critical CAN networks.</li>
</ul>

<h3>Title: FAIR Enough: How Can We Develop and Assess a FAIR-Compliant Dataset for  Large Language Models' Training?</h3>
<ul>
<li><strong>Authors: </strong>Shaina Raza, Shardul Ghuge, Chen Ding, Deval Pandya</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.11033">https://arxiv.org/abs/2401.11033</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.11033">https://arxiv.org/pdf/2401.11033</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.11033]] FAIR Enough: How Can We Develop and Assess a FAIR-Compliant Dataset for  Large Language Models' Training?(https://arxiv.org/abs/2401.11033)</code><input type="text"></li>
<li><strong>Keywords: </strong>fair, large language model</a></li>
<li><strong>Abstract: </strong>Advancements in Large Language Models (LLMs) highlight the need for ethical practices and data integrity. We introduce a framework that embeds FAIR (Findable, Accessible, Interoperable, Reusable) data principles into LLM training. This approach marks a shift towards practices compliant with FAIR standards. Our framework presents guidelines for integrating FAIR data principles into LLM training. This initiative includes a checklist for researchers and developers. We also demonstrate its practical application through a case study focused on bias identification and mitigation in our FAIR-compliant dataset. This work is a significant contribution to AI ethics and data science, advocating for balanced and ethical training methods in LLMs.</li>
</ul>

<h3>Title: Image Safeguarding: Reasoning with Conditional Vision Language Model and  Obfuscating Unsafe Content Counterfactually</h3>
<ul>
<li><strong>Authors: </strong>Mazal Bethany, Brandon Wherry, Nishant Vishwamitra, Peyman Najafirad</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.11035">https://arxiv.org/abs/2401.11035</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.11035">https://arxiv.org/pdf/2401.11035</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.11035]] Image Safeguarding: Reasoning with Conditional Vision Language Model and  Obfuscating Unsafe Content Counterfactually(https://arxiv.org/abs/2401.11035)</code><input type="text"></li>
<li><strong>Keywords: </strong>secure, segmentation</a></li>
<li><strong>Abstract: </strong>Social media platforms are being increasingly used by malicious actors to share unsafe content, such as images depicting sexual activity, cyberbullying, and self-harm. Consequently, major platforms use artificial intelligence (AI) and human moderation to obfuscate such images to make them safer. Two critical needs for obfuscating unsafe images is that an accurate rationale for obfuscating image regions must be provided, and the sensitive regions should be obfuscated (\textit{e.g.} blurring) for users' safety. This process involves addressing two key problems: (1) the reason for obfuscating unsafe images demands the platform to provide an accurate rationale that must be grounded in unsafe image-specific attributes, and (2) the unsafe regions in the image must be minimally obfuscated while still depicting the safe regions. In this work, we address these key issues by first performing visual reasoning by designing a visual reasoning model (VLM) conditioned on pre-trained unsafe image classifiers to provide an accurate rationale grounded in unsafe image attributes, and then proposing a counterfactual explanation algorithm that minimally identifies and obfuscates unsafe regions for safe viewing, by first utilizing an unsafe image classifier attribution matrix to guide segmentation for a more optimal subregion segmentation followed by an informed greedy search to determine the minimum number of subregions required to modify the classifier's output based on attribution score. Extensive experiments on uncurated data from social networks emphasize the efficacy of our proposed method. We make our code available at: https://github.com/SecureAIAutonomyLab/ConditionalVLM</li>
</ul>

<h3>Title: Mining experimental data from Materials Science literature with Large  Language Models</h3>
<ul>
<li><strong>Authors: </strong>Luca Foppiano, Guillaume Lambard, Toshiyuki Amagasa, Masashi Ishii</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.11052">https://arxiv.org/abs/2401.11052</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.11052">https://arxiv.org/pdf/2401.11052</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.11052]] Mining experimental data from Materials Science literature with Large  Language Models(https://arxiv.org/abs/2401.11052)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction, large language model</a></li>
<li><strong>Abstract: </strong>This study is dedicated to evaluating the capabilities of advanced large language models (LLMs) such as GPT-3.5-Turbo, GPT-4, and GPT-4-Turbo in the extraction of structured information from scientific documents within the field of materials science. We introduce a novel methodology for the comparative analysis of intricate material expressions, emphasising the standardisation of chemical formulas to tackle the complexities inherent in materials science information assessment. To this end, we primarily focus on two critical tasks of information extraction: (i) a named entity recognition (NER) of studied materials and physical properties and (ii) a relation extraction (RE) between these entities. The performance of LLMs in executing these tasks is benchmarked against traditional models based on the BERT architecture and rule-based approaches. For NER, LLMs fail to outperform the baseline with zero-shot prompting and exhibit only limited improvement with few-shot prompting. However, for RE, a GPT-3.5-Turbo fine-tuned with the appropriate strategy outperforms all models, including the baseline. Without any fine-tuning, GPT-4 and GPT-4-Turbo display remarkable reasoning and relationship extraction capabilities after being provided with merely a couple of examples, surpassing the baseline. Overall, the results suggest that although LLMs demonstrate relevant reasoning skills in connecting concepts, for tasks requiring extracting complex domain-specific entities like materials, specialised models are currently a better choice.</li>
</ul>

<h3>Title: PhotoBot: Reference-Guided Interactive Photography via Natural Language</h3>
<ul>
<li><strong>Authors: </strong>Oliver Limoyo, Jimmy Li, Dmitriy Rivkin, Jonathan Kelly, Gregory Dudek</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI, cs.RO</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.11061">https://arxiv.org/abs/2401.11061</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.11061">https://arxiv.org/pdf/2401.11061</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.11061]] PhotoBot: Reference-Guided Interactive Photography via Natural Language(https://arxiv.org/abs/2401.11061)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer, large language model</a></li>
<li><strong>Abstract: </strong>We introduce PhotoBot, a framework for automated photo acquisition based on an interplay between high-level human language guidance and a robot photographer. We propose to communicate photography suggestions to the user via a reference picture that is retrieved from a curated gallery. We exploit a visual language model (VLM) and an object detector to characterize reference pictures via textual descriptions and use a large language model (LLM) to retrieve relevant reference pictures based on a user's language query through text-based reasoning. To correspond the reference picture and the observed scene, we exploit pre-trained features from a vision transformer capable of capturing semantic similarity across significantly varying images. Using these features, we compute pose adjustments for an RGB-D camera by solving a Perspective-n-Point (PnP) problem. We demonstrate our approach on a real-world manipulator equipped with a wrist camera. Our user studies show that photos taken by PhotoBot are often more aesthetically pleasing than those taken by users themselves, as measured by human feedback.</li>
</ul>

<h3>Title: Low-Complexity Integer Divider Architecture for Homomorphic Encryption</h3>
<ul>
<li><strong>Authors: </strong>Sajjad Akherati, Jiaxuan Cai, Xinmiao Zhang</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.AR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.11064">https://arxiv.org/abs/2401.11064</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.11064">https://arxiv.org/pdf/2401.11064</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.11064]] Low-Complexity Integer Divider Architecture for Homomorphic Encryption(https://arxiv.org/abs/2401.11064)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy</a></li>
<li><strong>Abstract: </strong>Homomorphic encryption (HE) allows computations to be directly carried out on ciphertexts and enables privacy-preserving cloud computing. The computations on the coefficients of the polynomials involved in HE are always followed by modular reduction, and the overall complexity of ciphertext multiplication can be reduced by utilizing the quotient. Our previous design considers the cases that the dividend is an integer multiple of the modulus and the modulus is in the format of $2^w-2^u\pm1$, where $u<w/2$. In this paper, the division is generalized for larger $u$ and dividend not an integer multiple of the modulus. An algorithm is proposed to compute the quotient and vigorous mathematical proofs are provided. Moreover, efficient hardware architecture is developed for implementing the proposed algorithm. Compared to alternative division approaches that utilize the inverse of the divisor, for $w=32$, the proposed design achieves at least 9% shorter latency and 79\% area reduction for 75% possible values of $u$.</li>
</ul>

<h3>Title: Make-A-Shape: a Ten-Million-scale 3D Shape Model</h3>
<ul>
<li><strong>Authors: </strong>Ka-Hei Hui, Aditya Sanghi, Arianna Rampini, Kamal Rahimi Malekshan, Zhengzhe Liu, Hooman Shayani, Chi-Wing Fu</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.GR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.11067">https://arxiv.org/abs/2401.11067</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.11067">https://arxiv.org/pdf/2401.11067</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.11067]] Make-A-Shape: a Ten-Million-scale 3D Shape Model(https://arxiv.org/abs/2401.11067)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, generative</a></li>
<li><strong>Abstract: </strong>Significant progress has been made in training large generative models for natural language and images. Yet, the advancement of 3D generative models is hindered by their substantial resource demands for training, along with inefficient, non-compact, and less expressive representations. This paper introduces Make-A-Shape, a new 3D generative model designed for efficient training on a vast scale, capable of utilizing 10 millions publicly-available shapes. Technical-wise, we first innovate a wavelet-tree representation to compactly encode shapes by formulating the subband coefficient filtering scheme to efficiently exploit coefficient relations. We then make the representation generatable by a diffusion model by devising the subband coefficients packing scheme to layout the representation in a low-resolution grid. Further, we derive the subband adaptive training strategy to train our model to effectively learn to generate coarse and detail wavelet coefficients. Last, we extend our framework to be controlled by additional input conditions to enable it to generate shapes from assorted modalities, e.g., single/multi-view images, point clouds, and low-resolution voxels. In our extensive set of experiments, we demonstrate various applications, such as unconditional generation, shape completion, and conditional generation on a wide range of modalities. Our approach not only surpasses the state of the art in delivering high-quality results but also efficiently generates shapes within a few seconds, often achieving this in just 2 seconds for most conditions.</li>
</ul>

<h3>Title: Optimal Control of Malware Propagation in IoT Networks</h3>
<ul>
<li><strong>Authors: </strong>Mousa Tayseer Jafar, Lu-Xing Yang, Gang Li, Xiaofan Yang</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.11076">https://arxiv.org/abs/2401.11076</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.11076">https://arxiv.org/pdf/2401.11076</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.11076]] Optimal Control of Malware Propagation in IoT Networks(https://arxiv.org/abs/2401.11076)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, attack, robust</a></li>
<li><strong>Abstract: </strong>The rapid proliferation of Internet of Things (IoT) devices in recent years has resulted in a significant surge in the number of cyber-attacks targeting these devices. Recent data indicates that the number of such attacks has increased by over 100 percent, highlighting the urgent need for robust cybersecurity measures to mitigate these threats. In addition, a cyber-attack will begin to spread malware across the network once it has successfully compromised an IoT network. However, to mitigate this attack, a new patch must be applied immediately. In reality, the time required to prepare and apply the new patch can vary significantly depending on the nature of the cyber-attack. In this paper, we address the issue of how to mitigate cyber-attacks before the new patch is applied by formulating an optimal control strategy that reduces the impact of malware propagation and minimise the number of infected devices across IoT networks in the smart home. A novel node-based epidemiological model susceptible, infected high, infected low, recover first, and recover complete(SI_HI_LR_FR_C) is established with immediate response state for the restricted environment. After that, the impact of malware on IoT devices using both high and low infected rates will be analyzed. Finally, to illustrate the main results, several numerical analyses are carried out in addition to simulate the real-world scenario of IoT networks in the smart home, we built a dataset to be used in the experiments.</li>
</ul>

<h3>Title: UltrAvatar: A Realistic Animatable 3D Avatar Diffusion Model with  Authenticity Guided Textures</h3>
<ul>
<li><strong>Authors: </strong>Mingyuan Zhou, Rakib Hyder, Ziwei Xuan, Guojun Qi</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.11078">https://arxiv.org/abs/2401.11078</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.11078">https://arxiv.org/pdf/2401.11078</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.11078]] UltrAvatar: A Realistic Animatable 3D Avatar Diffusion Model with  Authenticity Guided Textures(https://arxiv.org/abs/2401.11078)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, extraction, diffusion</a></li>
<li><strong>Abstract: </strong>Recent advances in 3D avatar generation have gained significant attentions. These breakthroughs aim to produce more realistic animatable avatars, narrowing the gap between virtual and real-world experiences. Most of existing works employ Score Distillation Sampling (SDS) loss, combined with a differentiable renderer and text condition, to guide a diffusion model in generating 3D avatars. However, SDS often generates oversmoothed results with few facial details, thereby lacking the diversity compared with ancestral sampling. On the other hand, other works generate 3D avatar from a single image, where the challenges of unwanted lighting effects, perspective views, and inferior image quality make them difficult to reliably reconstruct the 3D face meshes with the aligned complete textures. In this paper, we propose a novel 3D avatar generation approach termed UltrAvatar with enhanced fidelity of geometry, and superior quality of physically based rendering (PBR) textures without unwanted lighting. To this end, the proposed approach presents a diffuse color extraction model and an authenticity guided texture diffusion model. The former removes the unwanted lighting effects to reveal true diffuse colors so that the generated avatars can be rendered under various lighting conditions. The latter follows two gradient-based guidances for generating PBR textures to render diverse face-identity features and details better aligning with 3D mesh geometry. We demonstrate the effectiveness and robustness of the proposed method, outperforming the state-of-the-art methods by a large margin in the experiments.</li>
</ul>

<h3>Title: Learning from Aggregate responses: Instance Level versus Bag Level Loss  Functions</h3>
<ul>
<li><strong>Authors: </strong>Adel Javanmard, Lin Chen, Vahab Mirrokni, Ashwinkumar Badanidiyuru, Gang Fu</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, math.ST, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.11081">https://arxiv.org/abs/2401.11081</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.11081">https://arxiv.org/pdf/2401.11081</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.11081]] Learning from Aggregate responses: Instance Level versus Bag Level Loss  Functions(https://arxiv.org/abs/2401.11081)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, protect</a></li>
<li><strong>Abstract: </strong>Due to the rise of privacy concerns, in many practical applications the training data is aggregated before being shared with the learner, in order to protect privacy of users' sensitive responses. In an aggregate learning framework, the dataset is grouped into bags of samples, where each bag is available only with an aggregate response, providing a summary of individuals' responses in that bag. In this paper, we study two natural loss functions for learning from aggregate responses: bag-level loss and the instance-level loss. In the former, the model is learnt by minimizing a loss between aggregate responses and aggregate model predictions, while in the latter the model aims to fit individual predictions to the aggregate responses. In this work, we show that the instance-level loss can be perceived as a regularized form of the bag-level loss. This observation lets us compare the two approaches with respect to bias and variance of the resulting estimators, and introduce a novel interpolating estimator which combines the two approaches. For linear regression tasks, we provide a precise characterization of the risk of the interpolating estimator in an asymptotic regime where the size of the training set grows in proportion to the features dimension. Our analysis allows us to theoretically understand the effect of different factors, such as bag size on the model prediction risk. In addition, we propose a mechanism for differentially private learning from aggregate responses and derive the optimal bag size in terms of prediction risk-privacy trade-off. We also carry out thorough experiments to corroborate our theory and show the efficacy of the interpolating estimator.</li>
</ul>

<h3>Title: Adaptive Global-Local Representation Learning and Selection for  Cross-Domain Facial Expression Recognition</h3>
<ul>
<li><strong>Authors: </strong>Yuefang Gao, Yuhao Xie, Zeke Zexi Hu, Tianshui Chen, Liang Lin</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.11085">https://arxiv.org/abs/2401.11085</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.11085">https://arxiv.org/pdf/2401.11085</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.11085]] Adaptive Global-Local Representation Learning and Selection for  Cross-Domain Facial Expression Recognition(https://arxiv.org/abs/2401.11085)</code><input type="text"></li>
<li><strong>Keywords: </strong>fair</a></li>
<li><strong>Abstract: </strong>Domain shift poses a significant challenge in Cross-Domain Facial Expression Recognition (CD-FER) due to the distribution variation across different domains. Current works mainly focus on learning domain-invariant features through global feature adaptation, while neglecting the transferability of local features. Additionally, these methods lack discriminative supervision during training on target datasets, resulting in deteriorated feature representation in target domain. To address these limitations, we propose an Adaptive Global-Local Representation Learning and Selection (AGLRLS) framework. The framework incorporates global-local adversarial adaptation and semantic-aware pseudo label generation to enhance the learning of domain-invariant and discriminative feature during training. Meanwhile, a global-local prediction consistency learning is introduced to improve classification results during inference. Specifically, the framework consists of separate global-local adversarial learning modules that learn domain-invariant global and local features independently. We also design a semantic-aware pseudo label generation module, which computes semantic labels based on global and local features. Moreover, a novel dynamic threshold strategy is employed to learn the optimal thresholds by leveraging independent prediction of global and local features, ensuring filtering out the unreliable pseudo labels while retaining reliable ones. These labels are utilized for model optimization through the adversarial learning process in an end-to-end manner. During inference, a global-local prediction consistency module is developed to automatically learn an optimal result from multiple predictions. We conduct comprehensive experiments and analysis based on a fair evaluation benchmark. The results demonstrate that the proposed framework outperforms the current competing methods by a substantial margin.</li>
</ul>

<h3>Title: FedRKG: A Privacy-preserving Federated Recommendation Framework via  Knowledge Graph Enhancement</h3>
<ul>
<li><strong>Authors: </strong>Dezhong Yao, Tongtong Liu, Qi Cao, Hai Jin</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.AI, cs.DC, cs.IR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.11089">https://arxiv.org/abs/2401.11089</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.11089">https://arxiv.org/pdf/2401.11089</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.11089]] FedRKG: A Privacy-preserving Federated Recommendation Framework via  Knowledge Graph Enhancement(https://arxiv.org/abs/2401.11089)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, protect, federate</a></li>
<li><strong>Abstract: </strong>Federated Learning (FL) has emerged as a promising approach for preserving data privacy in recommendation systems by training models locally. Recently, Graph Neural Networks (GNN) have gained popularity in recommendation tasks due to their ability to capture high-order interactions between users and items. However, privacy concerns prevent the global sharing of the entire user-item graph. To address this limitation, some methods create pseudo-interacted items or users in the graph to compensate for missing information for each client. Unfortunately, these methods introduce random noise and raise privacy concerns. In this paper, we propose FedRKG, a novel federated recommendation system, where a global knowledge graph (KG) is constructed and maintained on the server using publicly available item information, enabling higher-order user-item interactions. On the client side, a relation-aware GNN model leverages diverse KG relationships. To protect local interaction items and obscure gradients, we employ pseudo-labeling and Local Differential Privacy (LDP). Extensive experiments conducted on three real-world datasets demonstrate the competitive performance of our approach compared to centralized algorithms while ensuring privacy preservation. Moreover, FedRKG achieves an average accuracy improvement of 4% compared to existing federated learning baselines.</li>
</ul>

<h3>Title: Exploiting Duality in Open Information Extraction with Predicate Prompt</h3>
<ul>
<li><strong>Authors: </strong>Zhen Chen, Jingping Liu, Deqing Yang, Yanghua Xiao, Huimin Xu, Zongyu Wang, Rui Xie, Yunsen Xian</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.IR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.11107">https://arxiv.org/abs/2401.11107</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.11107">https://arxiv.org/pdf/2401.11107</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.11107]] Exploiting Duality in Open Information Extraction with Predicate Prompt(https://arxiv.org/abs/2401.11107)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction, generative</a></li>
<li><strong>Abstract: </strong>Open information extraction (OpenIE) aims to extract the schema-free triplets in the form of (\emph{subject}, \emph{predicate}, \emph{object}) from a given sentence. Compared with general information extraction (IE), OpenIE poses more challenges for the IE models, {especially when multiple complicated triplets exist in a sentence. To extract these complicated triplets more effectively, in this paper we propose a novel generative OpenIE model, namely \emph{DualOIE}, which achieves a dual task at the same time as extracting some triplets from the sentence, i.e., converting the triplets into the sentence.} Such dual task encourages the model to correctly recognize the structure of the given sentence and thus is helpful to extract all potential triplets from the sentence. Specifically, DualOIE extracts the triplets in two steps: 1) first extracting a sequence of all potential predicates, 2) then using the predicate sequence as a prompt to induce the generation of triplets. Our experiments on two benchmarks and our dataset constructed from Meituan demonstrate that DualOIE achieves the best performance among the state-of-the-art baselines. Furthermore, the online A/B test on Meituan platform shows that 0.93\% improvement of QV-CTR and 0.56\% improvement of UV-CTR have been obtained when the triplets extracted by DualOIE were leveraged in Meituan's search system.</li>
</ul>

<h3>Title: LLM4Fuzz: Guided Fuzzing of Smart Contracts with Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Chaofan Shou, Jing Liu, Doudou Lu, Koushik Sen</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.SE</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.11108">https://arxiv.org/abs/2401.11108</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.11108">https://arxiv.org/pdf/2401.11108</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.11108]] LLM4Fuzz: Guided Fuzzing of Smart Contracts with Large Language Models(https://arxiv.org/abs/2401.11108)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, large language model</a></li>
<li><strong>Abstract: </strong>As blockchain platforms grow exponentially, millions of lines of smart contract code are being deployed to manage extensive digital assets. However, vulnerabilities in this mission-critical code have led to significant exploitations and asset losses. Thorough automated security analysis of smart contracts is thus imperative. This paper introduces LLM4Fuzz to optimize automated smart contract security analysis by leveraging large language models (LLMs) to intelligently guide and prioritize fuzzing campaigns. While traditional fuzzing suffers from low efficiency in exploring the vast state space, LLM4Fuzz employs LLMs to direct fuzzers towards high-value code regions and input sequences more likely to trigger vulnerabilities. Additionally, LLM4Fuzz can leverage LLMs to guide fuzzers based on user-defined invariants, reducing blind exploration overhead. Evaluations of LLM4Fuzz on real-world DeFi projects show substantial gains in efficiency, coverage, and vulnerability detection compared to baseline fuzzing. LLM4Fuzz also uncovered five critical vulnerabilities that can lead to a loss of more than $247k.</li>
</ul>

<h3>Title: VONet: Unsupervised Video Object Learning With Parallel U-Net Attention  and Object-wise Sequential VAE</h3>
<ul>
<li><strong>Authors: </strong>Haonan Yu, Wei Xu</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.11110">https://arxiv.org/abs/2401.11110</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.11110">https://arxiv.org/pdf/2401.11110</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.11110]] VONet: Unsupervised Video Object Learning With Parallel U-Net Attention  and Object-wise Sequential VAE(https://arxiv.org/abs/2401.11110)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer, segmentation</a></li>
<li><strong>Abstract: </strong>Unsupervised video object learning seeks to decompose video scenes into structural object representations without any supervision from depth, optical flow, or segmentation. We present VONet, an innovative approach that is inspired by MONet. While utilizing a U-Net architecture, VONet employs an efficient and effective parallel attention inference process, generating attention masks for all slots simultaneously. Additionally, to enhance the temporal consistency of each mask across consecutive video frames, VONet develops an object-wise sequential VAE framework. The integration of these innovative encoder-side techniques, in conjunction with an expressive transformer-based decoder, establishes VONet as the leading unsupervised method for object learning across five MOVI datasets, encompassing videos of diverse complexities. Code is available at https://github.com/hnyu/vonet.</li>
</ul>

<h3>Title: SPAND: Sleep Prediction Architecture using Network Dynamics</h3>
<ul>
<li><strong>Authors: </strong>Maryam Khalid, Elizabeth B. Klerman, Andrew W. Mchill, Andrew J. K. Phillips, Akane Sano</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.SI, eess.SP</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.11113">https://arxiv.org/abs/2401.11113</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.11113">https://arxiv.org/pdf/2401.11113</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.11113]] SPAND: Sleep Prediction Architecture using Network Dynamics(https://arxiv.org/abs/2401.11113)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Sleep behavior significantly impacts health and acts as an indicator of physical and mental well-being. Monitoring and predicting sleep behavior with ubiquitous sensors may therefore assist in both sleep management and tracking of related health conditions. While sleep behavior depends on, and is reflected in the physiology of a person, it is also impacted by external factors such as digital media usage, social network contagion, and the surrounding weather. In this work, we propose SPAND (Sleep Prediction Architecture using Network Dynamics), a system that exploits social contagion in sleep behavior through graph networks and integrates it with physiological and phone data extracted from ubiquitous mobile and wearable devices for predicting next-day sleep labels about sleep duration. Our architecture overcomes the limitations of large-scale graphs containing connections irrelevant to sleep behavior by devising an attention mechanism. The extensive experimental evaluation highlights the improvement provided by incorporating social networks in the model. Additionally, we conduct robustness analysis to demonstrate the system's performance in real-life conditions. The outcomes affirm the stability of SPAND against perturbations in input data. Further analyses emphasize the significance of network topology in prediction performance revealing that users with higher eigenvalue centrality are more vulnerable to data perturbations.</li>
</ul>

<h3>Title: DengueNet: Dengue Prediction using Spatiotemporal Satellite Imagery for  Resource-Limited Countries</h3>
<ul>
<li><strong>Authors: </strong>Kuan-Ting Kuo, Dana Moukheiber, Sebastian Cajas Ordonez, David Restrepo, Atika Rahman Paddo, Tsung-Yu Chen, Lama Moukheiber, Mira Moukheiber, Sulaiman Moukheiber, Saptarshi Purkayastha, Po-Chih Kuo, Leo Anthony Celi</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.11114">https://arxiv.org/abs/2401.11114</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.11114">https://arxiv.org/pdf/2401.11114</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.11114]] DengueNet: Dengue Prediction using Spatiotemporal Satellite Imagery for  Resource-Limited Countries(https://arxiv.org/abs/2401.11114)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction, transformer</a></li>
<li><strong>Abstract: </strong>Dengue fever presents a substantial challenge in developing countries where sanitation infrastructure is inadequate. The absence of comprehensive healthcare systems exacerbates the severity of dengue infections, potentially leading to life-threatening circumstances. Rapid response to dengue outbreaks is also challenging due to limited information exchange and integration. While timely dengue outbreak forecasts have the potential to prevent such outbreaks, the majority of dengue prediction studies have predominantly relied on data that impose significant burdens on individual countries for collection. In this study, our aim is to improve health equity in resource-constrained countries by exploring the effectiveness of high-resolution satellite imagery as a nontraditional and readily accessible data source. By leveraging the wealth of publicly available and easily obtainable satellite imagery, we present a scalable satellite extraction framework based on Sentinel Hub, a cloud-based computing platform. Furthermore, we introduce DengueNet, an innovative architecture that combines Vision Transformer, Radiomics, and Long Short-term Memory to extract and integrate spatiotemporal features from satellite images. This enables dengue predictions on an epi-week basis. To evaluate the effectiveness of our proposed method, we conducted experiments on five municipalities in Colombia. We utilized a dataset comprising 780 high-resolution Sentinel-2 satellite images for training and evaluation. The performance of DengueNet was assessed using the mean absolute error (MAE) metric. Across the five municipalities, DengueNet achieved an average MAE of 43.92. Our findings strongly support the efficacy of satellite imagery as a valuable resource for dengue prediction, particularly in informing public health policies within countries where manually collected data is scarce and dengue virus prevalence is severe.</li>
</ul>

<h3>Title: MotionMix: Weakly-Supervised Diffusion for Controllable Motion  Generation</h3>
<ul>
<li><strong>Authors: </strong>Nhat M. Hoang, Kehong Gong, Chuan Guo, Michael Bi Mi</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.11115">https://arxiv.org/abs/2401.11115</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.11115">https://arxiv.org/pdf/2401.11115</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.11115]] MotionMix: Weakly-Supervised Diffusion for Controllable Motion  Generation(https://arxiv.org/abs/2401.11115)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>Controllable generation of 3D human motions becomes an important topic as the world embraces digital transformation. Existing works, though making promising progress with the advent of diffusion models, heavily rely on meticulously captured and annotated (e.g., text) high-quality motion corpus, a resource-intensive endeavor in the real world. This motivates our proposed MotionMix, a simple yet effective weakly-supervised diffusion model that leverages both noisy and unannotated motion sequences. Specifically, we separate the denoising objectives of a diffusion model into two stages: obtaining conditional rough motion approximations in the initial $T-T^*$ steps by learning the noisy annotated motions, followed by the unconditional refinement of these preliminary motions during the last $T^*$ steps using unannotated motions. Notably, though learning from two sources of imperfect data, our model does not compromise motion generation quality compared to fully supervised approaches that access gold data. Extensive experiments on several benchmarks demonstrate that our MotionMix, as a versatile framework, consistently achieves state-of-the-art performances on text-to-motion, action-to-motion, and music-to-dance tasks.</li>
</ul>

<h3>Title: Enhancing Large Language Models for Clinical Decision Support by  Incorporating Clinical Practice Guidelines</h3>
<ul>
<li><strong>Authors: </strong>David Oniani, Xizhi Wu, Shyam Visweswaran, Sumit Kapoor, Shravan Kooragayalu, Katelyn Polanska, Yanshan Wang</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.11120">https://arxiv.org/abs/2401.11120</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.11120">https://arxiv.org/pdf/2401.11120</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.11120]] Enhancing Large Language Models for Clinical Decision Support by  Incorporating Clinical Practice Guidelines(https://arxiv.org/abs/2401.11120)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Background Large Language Models (LLMs), enhanced with Clinical Practice Guidelines (CPGs), can significantly improve Clinical Decision Support (CDS). However, methods for incorporating CPGs into LLMs are not well studied. Methods We develop three distinct methods for incorporating CPGs into LLMs: Binary Decision Tree (BDT), Program-Aided Graph Construction (PAGC), and Chain-of-Thought-Few-Shot Prompting (CoT-FSP). To evaluate the effectiveness of the proposed methods, we create a set of synthetic patient descriptions and conduct both automatic and human evaluation of the responses generated by four LLMs: GPT-4, GPT-3.5 Turbo, LLaMA, and PaLM 2. Zero-Shot Prompting (ZSP) was used as the baseline method. We focus on CDS for COVID-19 outpatient treatment as the case study. Results All four LLMs exhibit improved performance when enhanced with CPGs compared to the baseline ZSP. BDT outperformed both CoT-FSP and PAGC in automatic evaluation. All of the proposed methods demonstrated high performance in human evaluation. Conclusion LLMs enhanced with CPGs demonstrate superior performance, as compared to plain LLMs with ZSP, in providing accurate recommendations for COVID-19 outpatient treatment, which also highlights the potential for broader applications beyond the case study.</li>
</ul>

<h3>Title: Spatial Structure Constraints for Weakly Supervised Semantic  Segmentation</h3>
<ul>
<li><strong>Authors: </strong>Tao Chen, Yazhou Yao, Xingguo Huang, Zechao Li, Liqiang Nie, Jinhui Tang</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.11122">https://arxiv.org/abs/2401.11122</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.11122">https://arxiv.org/pdf/2401.11122</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.11122]] Spatial Structure Constraints for Weakly Supervised Semantic  Segmentation(https://arxiv.org/abs/2401.11122)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, segmentation</a></li>
<li><strong>Abstract: </strong>The image-level label has prevailed in weakly supervised semantic segmentation tasks due to its easy availability. Since image-level labels can only indicate the existence or absence of specific categories of objects, visualization-based techniques have been widely adopted to provide object location clues. Considering class activation maps (CAMs) can only locate the most discriminative part of objects, recent approaches usually adopt an expansion strategy to enlarge the activation area for more integral object localization. However, without proper constraints, the expanded activation will easily intrude into the background region. In this paper, we propose spatial structure constraints (SSC) for weakly supervised semantic segmentation to alleviate the unwanted object over-activation of attention expansion. Specifically, we propose a CAM-driven reconstruction module to directly reconstruct the input image from deep CAM features, which constrains the diffusion of last-layer object attention by preserving the coarse spatial structure of the image content. Moreover, we propose an activation self-modulation module to refine CAMs with finer spatial structure details by enhancing regional consistency. Without external saliency models to provide background clues, our approach achieves 72.7\% and 47.0\% mIoU on the PASCAL VOC 2012 and COCO datasets, respectively, demonstrating the superiority of our proposed approach.</li>
</ul>

<h3>Title: Uncertainty-aware Bridge based Mobile-Former Network for Event-based  Pattern Recognition</h3>
<ul>
<li><strong>Authors: </strong>Haoxiang Yang, Chengguo Yuan, Yabin Zhu, Lan Chen, Xiao Wang, Jin Tang</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.11123">https://arxiv.org/abs/2401.11123</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.11123">https://arxiv.org/pdf/2401.11123</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.11123]] Uncertainty-aware Bridge based Mobile-Former Network for Event-based  Pattern Recognition(https://arxiv.org/abs/2401.11123)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, protect, transformer</a></li>
<li><strong>Abstract: </strong>The mainstream human activity recognition (HAR) algorithms are developed based on RGB cameras, which are easily influenced by low-quality images (e.g., low illumination, motion blur). Meanwhile, the privacy protection issue caused by ultra-high definition (HD) RGB cameras aroused more and more people's attention. Inspired by the success of event cameras which perform better on high dynamic range, no motion blur, and low energy consumption, we propose to recognize human actions based on the event stream. We propose a lightweight uncertainty-aware information propagation based Mobile-Former network for efficient pattern recognition, which aggregates the MobileNet and Transformer network effectively. Specifically, we first embed the event images using a stem network into feature representations, then, feed them into uncertainty-aware Mobile-Former blocks for local and global feature learning and fusion. Finally, the features from MobileNet and Transformer branches are concatenated for pattern recognition. Extensive experiments on multiple event-based recognition datasets fully validated the effectiveness of our model. The source code of this work will be released at https://github.com/Event-AHU/Uncertainty_aware_MobileFormer.</li>
</ul>

<h3>Title: CARE: Ensemble Adversarial Robustness Evaluation Against Adaptive  Attackers for Security Applications</h3>
<ul>
<li><strong>Authors: </strong>Hangsheng Zhang, Jiqiang Liu, Jinsong Dong</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.11126">https://arxiv.org/abs/2401.11126</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.11126">https://arxiv.org/pdf/2401.11126</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.11126]] CARE: Ensemble Adversarial Robustness Evaluation Against Adaptive  Attackers for Security Applications(https://arxiv.org/abs/2401.11126)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, defense, attack, robust</a></li>
<li><strong>Abstract: </strong>Ensemble defenses, are widely employed in various security-related applications to enhance model performance and robustness. The widespread adoption of these techniques also raises many questions: Are general ensembles defenses guaranteed to be more robust than individuals? Will stronger adaptive attacks defeat existing ensemble defense strategies as the cybersecurity arms race progresses? Can ensemble defenses achieve adversarial robustness to different types of attacks simultaneously and resist the continually adjusted adaptive attacks? Unfortunately, these critical questions remain unresolved as there are no platforms for comprehensive evaluation of ensemble adversarial attacks and defenses in the cybersecurity domain. In this paper, we propose a general Cybersecurity Adversarial Robustness Evaluation (CARE) platform aiming to bridge this gap.</li>
</ul>

<h3>Title: Gaussian Adaptive Attention is All You Need: Robust Contextual  Representations Across Multiple Modalities</h3>
<ul>
<li><strong>Authors: </strong>Georgios Ioannides, Aman Chadha, Aaron Elkins</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CL, cs.CV, cs.SD, eess.AS, eess.SP</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.11143">https://arxiv.org/abs/2401.11143</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.11143">https://arxiv.org/pdf/2401.11143</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.11143]] Gaussian Adaptive Attention is All You Need: Robust Contextual  Representations Across Multiple Modalities(https://arxiv.org/abs/2401.11143)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, explainability, transformer</a></li>
<li><strong>Abstract: </strong>We propose the Multi-Head Gaussian Adaptive Attention Mechanism (GAAM), a novel probabilistic attention framework, and the Gaussian Adaptive Transformer (GAT), designed to enhance information aggregation across multiple modalities, including Speech, Text and Vision. GAAM integrates learnable mean and variance into its attention mechanism, implemented in a Multi-Headed framework enabling it to collectively model any Probability Distribution for dynamic recalibration of feature significance. This method demonstrates significant improvements, especially with highly non-stationary data, surpassing the state-of-the-art attention techniques in model performance (up to approximately +20% in accuracy) by identifying key elements within the feature space. GAAM's compatibility with dot-product-based attention models and relatively low number of parameters showcases its adaptability and potential to boost existing attention frameworks. Empirically, GAAM exhibits superior adaptability and efficacy across a diverse range of tasks, including emotion recognition in speech, image classification, and text classification, thereby establishing its robustness and versatility in handling multi-modal data. Furthermore, we introduce the Importance Factor (IF), a new learning-based metric that enhances the explainability of models trained with GAAM-based methods. Overall, GAAM represents an advancement towards development of better performing and more explainable attention models across multiple modalities.</li>
</ul>

<h3>Title: Generalizing Speaker Verification for Spoof Awareness in the Embedding  Space</h3>
<ul>
<li><strong>Authors: </strong>Xuechen Liu, Md Sahidullah, Kong Aik Lee, Tomi Kinnunen</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.AI, cs.SD, eess.AS</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.11156">https://arxiv.org/abs/2401.11156</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.11156">https://arxiv.org/pdf/2401.11156</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.11156]] Generalizing Speaker Verification for Spoof Awareness in the Embedding  Space(https://arxiv.org/abs/2401.11156)</code><input type="text"></li>
<li><strong>Keywords: </strong>protect, attack</a></li>
<li><strong>Abstract: </strong>It is now well-known that automatic speaker verification (ASV) systems can be spoofed using various types of adversaries. The usual approach to counteract ASV systems against such attacks is to develop a separate spoofing countermeasure (CM) module to classify speech input either as a bonafide, or a spoofed utterance. Nevertheless, such a design requires additional computation and utilization efforts at the authentication stage. An alternative strategy involves a single monolithic ASV system designed to handle both zero-effort imposter (non-targets) and spoofing attacks. Such spoof-aware ASV systems have the potential to provide stronger protections and more economic computations. To this end, we propose to generalize the standalone ASV (G-SASV) against spoofing attacks, where we leverage limited training data from CM to enhance a simple backend in the embedding space, without the involvement of a separate CM module during the test (authentication) phase. We propose a novel yet simple backend classifier based on deep neural networks and conduct the study via domain adaptation and multi-task integration of spoof embeddings at the training stage. Experiments are conducted on the ASVspoof 2019 logical access dataset, where we improve the performance of statistical ASV backends on the joint (bonafide and spoofed) and spoofed conditions by a maximum of 36.2% and 49.8% in terms of equal error rates, respectively.</li>
</ul>

<h3>Title: Inducing High Energy-Latency of Large Vision-Language Models with  Verbose Images</h3>
<ul>
<li><strong>Authors: </strong>Kuofeng Gao, Yang Bai, Jindong Gu, Shu-Tao Xia, Philip Torr, Zhifeng Li, Wei Liu</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.11170">https://arxiv.org/abs/2401.11170</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.11170">https://arxiv.org/pdf/2401.11170</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.11170]] Inducing High Energy-Latency of Large Vision-Language Models with  Verbose Images(https://arxiv.org/abs/2401.11170)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack</a></li>
<li><strong>Abstract: </strong>Large vision-language models (VLMs) such as GPT-4 have achieved exceptional performance across various multi-modal tasks. However, the deployment of VLMs necessitates substantial energy consumption and computational resources. Once attackers maliciously induce high energy consumption and latency time (energy-latency cost) during inference of VLMs, it will exhaust computational resources. In this paper, we explore this attack surface about availability of VLMs and aim to induce high energy-latency cost during inference of VLMs. We find that high energy-latency cost during inference of VLMs can be manipulated by maximizing the length of generated sequences. To this end, we propose verbose images, with the goal of crafting an imperceptible perturbation to induce VLMs to generate long sentences during inference. Concretely, we design three loss objectives. First, a loss is proposed to delay the occurrence of end-of-sequence (EOS) token, where EOS token is a signal for VLMs to stop generating further tokens. Moreover, an uncertainty loss and a token diversity loss are proposed to increase the uncertainty over each generated token and the diversity among all tokens of the whole generated sequence, respectively, which can break output dependency at token-level and sequence-level. Furthermore, a temporal weight adjustment algorithm is proposed, which can effectively balance these losses. Extensive experiments demonstrate that our verbose images can increase the length of generated sequences by 7.87 times and 8.56 times compared to original images on MS-COCO and ImageNet datasets, which presents potential challenges for various applications. Our code is available at https://github.com/KuofengGao/Verbose_Images.</li>
</ul>

<h3>Title: Pixel-Wise Recognition for Holistic Surgical Scene Understanding</h3>
<ul>
<li><strong>Authors: </strong>Nicolás Ayobi, Santiago Rodríguez, Alejandra Pérez, Isabela Hernández, Nicolás Aparicio, Eugénie Dessevres, Sebastián Peña, Jessica Santander, Juan Ignacio Caicedo, Nicolás Fernández, Pablo Arbeláez</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.11174">https://arxiv.org/abs/2401.11174</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.11174">https://arxiv.org/pdf/2401.11174</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.11174]] Pixel-Wise Recognition for Holistic Surgical Scene Understanding(https://arxiv.org/abs/2401.11174)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, transformer, segmentation</a></li>
<li><strong>Abstract: </strong>This paper presents the Holistic and Multi-Granular Surgical Scene Understanding of Prostatectomies (GraSP) dataset, a curated benchmark that models surgical scene understanding as a hierarchy of complementary tasks with varying levels of granularity. Our approach enables a multi-level comprehension of surgical activities, encompassing long-term tasks such as surgical phases and steps recognition and short-term tasks including surgical instrument segmentation and atomic visual actions detection. To exploit our proposed benchmark, we introduce the Transformers for Actions, Phases, Steps, and Instrument Segmentation (TAPIS) model, a general architecture that combines a global video feature extractor with localized region proposals from an instrument segmentation model to tackle the multi-granularity of our benchmark. Through extensive experimentation, we demonstrate the impact of including segmentation annotations in short-term recognition tasks, highlight the varying granularity requirements of each task, and establish TAPIS's superiority over previously proposed baselines and conventional CNN-based models. Additionally, we validate the robustness of our method across multiple public benchmarks, confirming the reliability and applicability of our dataset. This work represents a significant step forward in Endoscopic Vision, offering a novel and comprehensive framework for future research towards a holistic understanding of surgical procedures.</li>
</ul>

<h3>Title: How the Advent of Ubiquitous Large Language Models both Stymie and  Turbocharge Dynamic Adversarial Question Generation</h3>
<ul>
<li><strong>Authors: </strong>Yoo Yeon Sung, Ishani Mondal, Jordan Boyd-Graber</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.HC</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.11185">https://arxiv.org/abs/2401.11185</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.11185">https://arxiv.org/pdf/2401.11185</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.11185]] How the Advent of Ubiquitous Large Language Models both Stymie and  Turbocharge Dynamic Adversarial Question Generation(https://arxiv.org/abs/2401.11185)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Dynamic adversarial question generation, where humans write examples to stump a model, aims to create examples that are realistic and informative. However, the advent of large language models (LLMs) has been a double-edged sword for human authors: more people are interested in seeing and pushing the limits of these models, but because the models are so much stronger an opponent, they are harder to defeat. To understand how these models impact adversarial question writing process, we enrich the writing guidance with LLMs and retrieval models for the authors to reason why their questions are not adversarial. While authors could create interesting, challenging adversarial questions, they sometimes resort to tricks that result in poor questions that are ambiguous, subjective, or confusing not just to a computer but also to humans. To address these issues, we propose new metrics and incentives for eliciting good, challenging questions and present a new dataset of adversarially authored questions.</li>
</ul>

<h3>Title: Projected Belief Networks With Discriminative Alignment for Acoustic  Event Classification: Rivaling State of the Art CNNs</h3>
<ul>
<li><strong>Authors: </strong>Paul M. Baggenstoss, Kevin Wilkinghoff, Felix Govaers, Frank Kurth</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.SD, eess.AS</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.11199">https://arxiv.org/abs/2401.11199</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.11199">https://arxiv.org/pdf/2401.11199</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.11199]] Projected Belief Networks With Discriminative Alignment for Acoustic  Event Classification: Rivaling State of the Art CNNs(https://arxiv.org/abs/2401.11199)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>The projected belief network (PBN) is a generative stochastic network with tractable likelihood function based on a feed-forward neural network (FFNN). The generative function operates by "backing up" through the FFNN. The PBN is two networks in one, a FFNN that operates in the forward direction, and a generative network that operates in the backward direction. Both networks co-exist based on the same parameter set, have their own cost functions, and can be separately or jointly trained. The PBN therefore has the potential to possess the best qualities of both discriminative and generative classifiers. To realize this potential, a separate PBN is trained on each class, maximizing the generative likelihood function for the given class, while minimizing the discriminative cost for the FFNN against "all other classes". This technique, called discriminative alignment (PBN-DA), aligns the contours of the likelihood function to the decision boundaries and attains vastly improved classification performance, rivaling that of state of the art discriminative networks. The method may be further improved using a hidden Markov model (HMM) as a component of the PBN, called PBN-DA-HMM. This paper provides a comprehensive treatment of PBN, PBN-DA, and PBN-DA-HMM. In addition, the results of two new classification experiments are provided. The first experiment uses air-acoustic events, and the second uses underwater acoustic data consisting of marine mammal calls. In both experiments, PBN-DA-HMM attains comparable or better performance as a state of the art CNN, and attain a factor of two error reduction when combined with the CNN.</li>
</ul>

<h3>Title: Towards Category Unification of 3D Single Object Tracking on Point  Clouds</h3>
<ul>
<li><strong>Authors: </strong>Jiahao Nie, Zhiwei He, Xudong Lv, Xueyi Zhou, Dong-Kyu Chae, Fei Xie</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.11204">https://arxiv.org/abs/2401.11204</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.11204">https://arxiv.org/pdf/2401.11204</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.11204]] Towards Category Unification of 3D Single Object Tracking on Point  Clouds(https://arxiv.org/abs/2401.11204)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Category-specific models are provenly valuable methods in 3D single object tracking (SOT) regardless of Siamese or motion-centric paradigms. However, such over-specialized model designs incur redundant parameters, thus limiting the broader applicability of 3D SOT task. This paper first introduces unified models that can simultaneously track objects across all categories using a single network with shared model parameters. Specifically, we propose to explicitly encode distinct attributes associated to different object categories, enabling the model to adapt to cross-category data. We find that the attribute variances of point cloud objects primarily occur from the varying size and shape (e.g., large and square vehicles v.s. small and slender humans). Based on this observation, we design a novel point set representation learning network inheriting transformer architecture, termed AdaFormer, which adaptively encodes the dynamically varying shape and size information from cross-category data in a unified manner. We further incorporate the size and shape prior derived from the known template targets into the model's inputs and learning objective, facilitating the learning of unified representation. Equipped with such designs, we construct two category-unified models SiamCUT and MoCUT.Extensive experiments demonstrate that SiamCUT and MoCUT exhibit strong generalization and training stability. Furthermore, our category-unified models outperform the category-specific counterparts by a significant margin (e.g., on KITTI dataset, 12% and 3% performance gains on the Siamese and motion paradigms). Our code will be available.</li>
</ul>

<h3>Title: InferAligner: Inference-Time Alignment for Harmlessness through  Cross-Model Guidance</h3>
<ul>
<li><strong>Authors: </strong>Pengyu Wang, Dong Zhang, Linyang Li, Chenkun Tan, Xinghao Wang, Ke Ren, Botian Jiang, Xipeng Qiu</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.11206">https://arxiv.org/abs/2401.11206</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.11206">https://arxiv.org/pdf/2401.11206</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.11206]] InferAligner: Inference-Time Alignment for Harmlessness through  Cross-Model Guidance(https://arxiv.org/abs/2401.11206)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack, large language model</a></li>
<li><strong>Abstract: </strong>With the rapid development of large language models (LLMs), they are not only used as general-purpose AI assistants but are also customized through further fine-tuning to meet the requirements of different applications. A pivotal factor in the success of current LLMs is the alignment process. Current alignment methods, such as supervised fine-tuning (SFT) and reinforcement learning from human feedback (RLHF), focus on training-time alignment and are often complex and cumbersome to implement. Therefore, we develop \textbf{InferAligner}, a novel inference-time alignment method that utilizes cross-model guidance for harmlessness alignment. InferAligner utilizes safety steering vectors extracted from safety-aligned model to modify the activations of the target model when responding to harmful inputs, thereby guiding the target model to provide harmless responses. Experimental results show that our method can be very effectively applied to domain-specific models in finance, medicine, and mathematics, as well as to multimodal large language models (MLLMs) such as LLaVA. It significantly diminishes the Attack Success Rate (ASR) of both harmful instructions and jailbreak attacks, while maintaining almost unchanged performance in downstream tasks.</li>
</ul>

<h3>Title: Unfair TOS: An Automated Approach using Customized BERT</h3>
<ul>
<li><strong>Authors: </strong>Bathini Sai Akash, Akshara Kupireddy, Lalita Bhanu Murthy</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.CY</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.11207">https://arxiv.org/abs/2401.11207</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.11207">https://arxiv.org/pdf/2401.11207</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.11207]] Unfair TOS: An Automated Approach using Customized BERT(https://arxiv.org/abs/2401.11207)</code><input type="text"></li>
<li><strong>Keywords: </strong>protect, fair, transformer</a></li>
<li><strong>Abstract: </strong>Terms of Service (ToS) form an integral part of any agreement as it defines the legal relationship between a service provider and an end-user. Not only do they establish and delineate reciprocal rights and responsibilities, but they also provide users with information on essential aspects of contracts that pertain to the use of digital spaces. These aspects include a wide range of topics, including limitation of liability, data protection, etc. Users tend to accept the ToS without going through it before using any application or service. Such ignorance puts them in a potentially weaker situation in case any action is required. Existing methodologies for the detection or classification of unfair clauses are however obsolete and show modest performance. In this research paper, we present SOTA(State of The Art) results on unfair clause detection from ToS documents based on unprecedented Fine-tuning BERT in integration with SVC(Support Vector Classifier). The study shows proficient performance with a macro F1-score of 0.922 at unfair clause detection, and superior performance is also shown in the classification of unfair clauses by each tag. Further, a comparative analysis is performed by answering research questions on the Transformer models utilized. In order to further research and experimentation the code and results are made available on https://github.com/batking24/Unfair-TOS-An-Automated-Approach-based-on-Fine-tuning-BERT-in-conjunction-with-ML.</li>
</ul>

<h3>Title: Protecting Personalized Trajectory with Differential Privacy under  Temporal Correlations</h3>
<ul>
<li><strong>Authors: </strong>Mingge Cao, Haopeng Zhu, Minghui Min, Yulu Li, Shiyin Li, Hongliang Zhang, Zhu Han</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.11225">https://arxiv.org/abs/2401.11225</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.11225">https://arxiv.org/pdf/2401.11225</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.11225]] Protecting Personalized Trajectory with Differential Privacy under  Temporal Correlations(https://arxiv.org/abs/2401.11225)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, protect</a></li>
<li><strong>Abstract: </strong>Location-based services (LBSs) in vehicular ad hoc networks (VANETs) offer users numerous conveniences. However, the extensive use of LBSs raises concerns about the privacy of users' trajectories, as adversaries can exploit temporal correlations between different locations to extract personal information. Additionally, users have varying privacy requirements depending on the time and location. To address these issues, this paper proposes a personalized trajectory privacy protection mechanism (PTPPM). This mechanism first uses the temporal correlation between trajectory locations to determine the possible location set for each time instant. We identify a protection location set (PLS) for each location by employing the Hilbert curve-based minimum distance search algorithm. This approach incorporates the complementary features of geo-indistinguishability and distortion privacy. We put forth a novel Permute-and-Flip mechanism for location perturbation, which maps its initial application in data publishing privacy protection to a location perturbation mechanism. This mechanism generates fake locations with smaller perturbation distances while improving the balance between privacy and quality of service (QoS). Simulation results show that our mechanism outperforms the benchmark by providing enhanced privacy protection while meeting user's QoS requirements.</li>
</ul>

<h3>Title: Unifying Visual and Vision-Language Tracking via Contrastive Learning</h3>
<ul>
<li><strong>Authors: </strong>Yinchao Ma, Yuyang Tang, Wenfei Yang, Tianzhu Zhang, Jinpeng Zhang, Mengxue Kang</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.11228">https://arxiv.org/abs/2401.11228</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.11228">https://arxiv.org/pdf/2401.11228</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.11228]] Unifying Visual and Vision-Language Tracking via Contrastive Learning(https://arxiv.org/abs/2401.11228)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Single object tracking aims to locate the target object in a video sequence according to the state specified by different modal references, including the initial bounding box (BBOX), natural language (NL), or both (NL+BBOX). Due to the gap between different modalities, most existing trackers are designed for single or partial of these reference settings and overspecialize on the specific modality. Differently, we present a unified tracker called UVLTrack, which can simultaneously handle all three reference settings (BBOX, NL, NL+BBOX) with the same parameters. The proposed UVLTrack enjoys several merits. First, we design a modality-unified feature extractor for joint visual and language feature learning and propose a multi-modal contrastive loss to align the visual and language features into a unified semantic space. Second, a modality-adaptive box head is proposed, which makes full use of the target reference to mine ever-changing scenario features dynamically from video contexts and distinguish the target in a contrastive way, enabling robust performance in different reference settings. Extensive experimental results demonstrate that UVLTrack achieves promising performance on seven visual tracking datasets, three vision-language tracking datasets, and three visual grounding datasets. Codes and models will be open-sourced at https://github.com/OpenSpaceAI/UVLTrack.</li>
</ul>

<h3>Title: Can global, extended and repeated ransomware attacks overcome the users  status quo bias and cause a switch of system</h3>
<ul>
<li><strong>Authors: </strong>Alex Zarifis, Xusen Cheng, Uchitha Jayawickrama, Simone Corsi</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.CY</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.11238">https://arxiv.org/abs/2401.11238</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.11238">https://arxiv.org/pdf/2401.11238</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.11238]] Can global, extended and repeated ransomware attacks overcome the users  status quo bias and cause a switch of system(https://arxiv.org/abs/2401.11238)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack</a></li>
<li><strong>Abstract: </strong>Ransomware attack effectiveness has increased causing far reaching consequences that are not fully understood. The ability to disrupt core services, the global reach, extended duration, and the repetition has increased their ability to harm organizations. One aspect that needs to be understood better is the effect on the user. The user in the current environment is exposed to new technologies that might be adopted, but there are also habits of using existing systems. The habits have developed over time with trust increasing in the organization in contact directly and the institutions supporting it. This research explores whether the global, extended, and repeated RW attacks reduce the trust and inertia sufficiently to change long-held habits in using information systems. The model tested measures the effect of the RW attack on the e-commerce status quo to evaluate if it is significant enough to overcome the users resistance to change.</li>
</ul>

<h3>Title: Product-Level Try-on: Characteristics-preserving Try-on with Realistic  Clothes Shading and Wrinkles</h3>
<ul>
<li><strong>Authors: </strong>Yanlong Zang, Han Yang, Jiaxu Miao, Yi Yang</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.11239">https://arxiv.org/abs/2401.11239</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.11239">https://arxiv.org/pdf/2401.11239</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.11239]] Product-Level Try-on: Characteristics-preserving Try-on with Realistic  Clothes Shading and Wrinkles(https://arxiv.org/abs/2401.11239)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, generative</a></li>
<li><strong>Abstract: </strong>Image-based virtual try-on systems,which fit new garments onto human portraits,are gaining research attention.An ideal pipeline should preserve the static features of clothes(like textures and logos)while also generating dynamic elements(e.g.shadows,folds)that adapt to the model's pose and environment.Previous works fail specifically in generating dynamic features,as they preserve the warped in-shop clothes trivially with predicted an alpha mask by composition.To break the dilemma of over-preserving and textures losses,we propose a novel diffusion-based Product-level virtual try-on pipeline,\ie PLTON, which can preserve the fine details of logos and embroideries while producing realistic clothes shading and wrinkles.The main insights are in three folds:1)Adaptive Dynamic Rendering:We take a pre-trained diffusion model as a generative prior and tame it with image features,training a dynamic extractor from scratch to generate dynamic tokens that preserve high-fidelity semantic information. Due to the strong generative power of the diffusion prior,we can generate realistic clothes shadows and wrinkles.2)Static Characteristics Transformation: High-frequency Map(HF-Map)is our fundamental insight for static representation.PLTON first warps in-shop clothes to the target model pose by a traditional warping network,and uses a high-pass filter to extract an HF-Map for preserving static cloth features.The HF-Map is used to generate modulation maps through our static extractor,which are injected into a fixed U-net to synthesize the final result.To enhance retention,a Two-stage Blended Denoising method is proposed to guide the diffusion process for correct spatial layout and color.PLTON is finetuned only with our collected small-size try-on dataset.Extensive quantitative and qualitative experiments on 1024 768 datasets demonstrate the superiority of our framework in mimicking real clothes dynamics.</li>
</ul>

<h3>Title: LRP-QViT: Mixed-Precision Vision Transformer Quantization via Layer-wise  Relevance Propagation</h3>
<ul>
<li><strong>Authors: </strong>Navin Ranjan, Andreas Savakis</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.11243">https://arxiv.org/abs/2401.11243</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.11243">https://arxiv.org/pdf/2401.11243</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.11243]] LRP-QViT: Mixed-Precision Vision Transformer Quantization via Layer-wise  Relevance Propagation(https://arxiv.org/abs/2401.11243)</code><input type="text"></li>
<li><strong>Keywords: </strong>explainability, transformer</a></li>
<li><strong>Abstract: </strong>Vision transformers (ViTs) have demonstrated remarkable performance across various visual tasks. However, ViT models suffer from substantial computational and memory requirements, making it challenging to deploy them on resource-constrained platforms. Quantization is a popular approach for reducing model size, but most studies mainly focus on equal bit-width quantization for the entire network, resulting in sub-optimal solutions. While there are few works on mixed precision quantization (MPQ) for ViTs, they typically rely on search space-based methods or employ mixed precision arbitrarily. In this paper, we introduce LRP-QViT, an explainability-based method for assigning mixed-precision bit allocations to different layers based on their importance during classification. Specifically, to measure the contribution score of each layer in predicting the target class, we employ the Layer-wise Relevance Propagation (LRP) method. LRP assigns local relevance at the output layer and propagates it through all layers, distributing the relevance until it reaches the input layers. These relevance scores serve as indicators for computing the layer contribution score. Additionally, we have introduced a clipped channel-wise quantization aimed at eliminating outliers from post-LayerNorm activations to alleviate severe inter-channel variations. To validate and assess our approach, we employ LRP-QViT across ViT, DeiT, and Swin transformer models on various datasets. Our experimental findings demonstrate that both our fixed-bit and mixed-bit post-training quantization methods surpass existing models in the context of 4-bit and 6-bit quantization.</li>
</ul>

<h3>Title: Prompt-RAG: Pioneering Vector Embedding-Free Retrieval-Augmented  Generation in Niche Domains, Exemplified by Korean Medicine</h3>
<ul>
<li><strong>Authors: </strong>Bongsu Kang, Jundong Kim, Tae-Rim Yun, Chang-Eop Kim</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.IR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.11246">https://arxiv.org/abs/2401.11246</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.11246">https://arxiv.org/pdf/2401.11246</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.11246]] Prompt-RAG: Pioneering Vector Embedding-Free Retrieval-Augmented  Generation in Niche Domains, Exemplified by Korean Medicine(https://arxiv.org/abs/2401.11246)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative, large language model</a></li>
<li><strong>Abstract: </strong>We propose a natural language prompt-based retrieval augmented generation (Prompt-RAG), a novel approach to enhance the performance of generative large language models (LLMs) in niche domains. Conventional RAG methods mostly require vector embeddings, yet the suitability of generic LLM-based embedding representations for specialized domains remains uncertain. To explore and exemplify this point, we compared vector embeddings from Korean Medicine (KM) and Conventional Medicine (CM) documents, finding that KM document embeddings correlated more with token overlaps and less with human-assessed document relatedness, in contrast to CM embeddings. Prompt-RAG, distinct from conventional RAG models, operates without the need for embedding vectors. Its performance was assessed through a Question-Answering (QA) chatbot application, where responses were evaluated for relevance, readability, and informativeness. The results showed that Prompt-RAG outperformed existing models, including ChatGPT and conventional vector embedding-based RAGs, in terms of relevance and informativeness. Despite challenges like content structuring and response latency, the advancements in LLMs are expected to encourage the use of Prompt-RAG, making it a promising tool for other domains in need of RAG methods.</li>
</ul>

<h3>Title: Diffusion Model Conditioning on Gaussian Mixture Model and Negative  Gaussian Mixture Gradient</h3>
<ul>
<li><strong>Authors: </strong>Weiguo Lu, Xuan Wu, Deng Ding, Jinqiao Duan, Jirong Zhuang, Gangnan Yuan</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.11261">https://arxiv.org/abs/2401.11261</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.11261">https://arxiv.org/pdf/2401.11261</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.11261]] Diffusion Model Conditioning on Gaussian Mixture Model and Negative  Gaussian Mixture Gradient(https://arxiv.org/abs/2401.11261)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, generative</a></li>
<li><strong>Abstract: </strong>Diffusion models (DMs) are a type of generative model that has a huge impact on image synthesis and beyond. They achieve state-of-the-art generation results in various generative tasks. A great diversity of conditioning inputs, such as text or bounding boxes, are accessible to control the generation. In this work, we propose a conditioning mechanism utilizing Gaussian mixture models (GMMs) as feature conditioning to guide the denoising process. Based on set theory, we provide a comprehensive theoretical analysis that shows that conditional latent distribution based on features and classes is significantly different, so that conditional latent distribution on features produces fewer defect generations than conditioning on classes. Two diffusion models conditioned on the Gaussian mixture model are trained separately for comparison. Experiments support our findings. A novel gradient function called the negative Gaussian mixture gradient (NGMG) is proposed and applied in diffusion model training with an additional classifier. Training stability has improved. We also theoretically prove that NGMG shares the same benefit as the Earth Mover distance (Wasserstein) as a more sensible cost function when learning distributions supported by low-dimensional manifolds.</li>
</ul>

<h3>Title: DACR: Distribution-Augmented Contrastive Reconstruction for Time-Series  Anomaly Detection</h3>
<ul>
<li><strong>Authors: </strong>Lixu Wang, Shichao Xu, Xinyu Du, Qi Zhu</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.11271">https://arxiv.org/abs/2401.11271</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.11271">https://arxiv.org/pdf/2401.11271</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.11271]] DACR: Distribution-Augmented Contrastive Reconstruction for Time-Series  Anomaly Detection(https://arxiv.org/abs/2401.11271)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Anomaly detection in time-series data is crucial for identifying faults, failures, threats, and outliers across a range of applications. Recently, deep learning techniques have been applied to this topic, but they often struggle in real-world scenarios that are complex and highly dynamic, e.g., the normal data may consist of multiple distributions, and various types of anomalies may differ from the normal data to different degrees. In this work, to tackle these challenges, we propose Distribution-Augmented Contrastive Reconstruction (DACR). DACR generates extra data disjoint from the normal data distribution to compress the normal data's representation space, and enhances the feature extractor through contrastive learning to better capture the intrinsic semantics from time-series data. Furthermore, DACR employs an attention mechanism to model the semantic dependencies among multivariate time-series features, thereby achieving more robust reconstruction for anomaly detection. Extensive experiments conducted on nine benchmark datasets in various anomaly detection scenarios demonstrate the effectiveness of DACR in achieving new state-of-the-art time-series anomaly detection.</li>
</ul>

<h3>Title: Long-Term Fair Decision Making through Deep Generative Models</h3>
<ul>
<li><strong>Authors: </strong>Yaowei Hu, Yongkai Wu, Lu Zhang</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CY</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.11288">https://arxiv.org/abs/2401.11288</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.11288">https://arxiv.org/pdf/2401.11288</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.11288]] Long-Term Fair Decision Making through Deep Generative Models(https://arxiv.org/abs/2401.11288)</code><input type="text"></li>
<li><strong>Keywords: </strong>fair, generative</a></li>
<li><strong>Abstract: </strong>This paper studies long-term fair machine learning which aims to mitigate group disparity over the long term in sequential decision-making systems. To define long-term fairness, we leverage the temporal causal graph and use the 1-Wasserstein distance between the interventional distributions of different demographic groups at a sufficiently large time step as the quantitative metric. Then, we propose a three-phase learning framework where the decision model is trained on high-fidelity data generated by a deep generative model. We formulate the optimization problem as a performative risk minimization and adopt the repeated gradient descent algorithm for learning. The empirical evaluation shows the efficacy of the proposed method using both synthetic and semi-synthetic datasets.</li>
</ul>

<h3>Title: Progress in Privacy Protection: A Review of Privacy Preserving  Techniques in Recommender Systems, Edge Computing, and Cloud Computing</h3>
<ul>
<li><strong>Authors: </strong>Syed Raza Bashir, Shaina Raza, Vojislav Misic</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.11305">https://arxiv.org/abs/2401.11305</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.11305">https://arxiv.org/pdf/2401.11305</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.11305]] Progress in Privacy Protection: A Review of Privacy Preserving  Techniques in Recommender Systems, Edge Computing, and Cloud Computing(https://arxiv.org/abs/2401.11305)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, privacy, protect</a></li>
<li><strong>Abstract: </strong>As digital technology evolves, the increasing use of connected devices brings both challenges and opportunities in the areas of mobile crowdsourcing, edge computing, and recommender systems. This survey focuses on these dynamic fields, emphasizing the critical need for privacy protection in our increasingly data-oriented world. It explores the latest trends in these interconnected areas, with a special emphasis on privacy and data security. Our method involves an in-depth analysis of various academic works, which helps us to gain a comprehensive understanding of these sectors and their shifting focus towards privacy concerns. We present new insights and marks a significant advancement in addressing privacy issues within these technologies. The survey is a valuable resource for researchers, industry practitioners, and policy makers, offering an extensive overview of these fields and their related privacy challenges, catering to a wide audience in the modern digital era.</li>
</ul>

<h3>Title: A Novel Benchmark for Few-Shot Semantic Segmentation in the Era of  Foundation Models</h3>
<ul>
<li><strong>Authors: </strong>Reda Bensaid, Vincent Gripon, François Leduc-Primeau, Lukas Mauch, Ghouthi Boukli Hacene, Fabien Cardinaux</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.11311">https://arxiv.org/abs/2401.11311</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.11311">https://arxiv.org/pdf/2401.11311</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.11311]] A Novel Benchmark for Few-Shot Semantic Segmentation in the Era of  Foundation Models(https://arxiv.org/abs/2401.11311)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, extraction, large language model, segmentation</a></li>
<li><strong>Abstract: </strong>In recent years, the rapid evolution of computer vision has seen the emergence of various vision foundation models, each tailored to specific data types and tasks. While large language models often share a common pretext task, the diversity in vision foundation models arises from their varying training objectives. In this study, we delve into the quest for identifying the most effective vision foundation models for few-shot semantic segmentation, a critical task in computer vision. Specifically, we conduct a comprehensive comparative analysis of four prominent foundation models: DINO V2, Segment Anything, CLIP, Masked AutoEncoders, and a straightforward ResNet50 pre-trained on the COCO dataset. Our investigation focuses on their adaptability to new semantic segmentation tasks, leveraging only a limited number of segmented images. Our experimental findings reveal that DINO V2 consistently outperforms the other considered foundation models across a diverse range of datasets and adaptation methods. This outcome underscores DINO V2's superior capability to adapt to semantic segmentation tasks compared to its counterparts. Furthermore, our observations indicate that various adapter methods exhibit similar performance, emphasizing the paramount importance of selecting a robust feature extractor over the intricacies of the adaptation technique itself. This insight sheds light on the critical role of feature extraction in the context of few-shot semantic segmentation. This research not only contributes valuable insights into the comparative performance of vision foundation models in the realm of few-shot semantic segmentation but also highlights the significance of a robust feature extractor in this domain.</li>
</ul>

<h3>Title: Weakly-Supervised Semantic Segmentation of Circular-Scan,  Synthetic-Aperture-Sonar Imagery</h3>
<ul>
<li><strong>Authors: </strong>Isaac J. Sledge, Dominic M. Byrne, Jonathan L. King, Steven H. Ostertag, Denton L. Woods, James L. Prater, Jermaine L. Kennedy, Timothy M. Marston, Jose C. Principe</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.LG, eess.IV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.11313">https://arxiv.org/abs/2401.11313</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.11313">https://arxiv.org/pdf/2401.11313</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.11313]] Weakly-Supervised Semantic Segmentation of Circular-Scan,  Synthetic-Aperture-Sonar Imagery(https://arxiv.org/abs/2401.11313)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>We propose a weakly-supervised framework for the semantic segmentation of circular-scan synthetic-aperture-sonar (CSAS) imagery. The first part of our framework is trained in a supervised manner, on image-level labels, to uncover a set of semi-sparse, spatially-discriminative regions in each image. The classification uncertainty of each region is then evaluated. Those areas with the lowest uncertainties are then chosen to be weakly labeled segmentation seeds, at the pixel level, for the second part of the framework. Each of the seed extents are progressively resized according to an unsupervised, information-theoretic loss with structured-prediction regularizers. This reshaping process uses multi-scale, adaptively-weighted features to delineate class-specific transitions in local image content. Content-addressable memories are inserted at various parts of our framework so that it can leverage features from previously seen images to improve segmentation performance for related images. We evaluate our weakly-supervised framework using real-world CSAS imagery that contains over ten seafloor classes and ten target classes. We show that our framework performs comparably to nine fully-supervised deep networks. Our framework also outperforms eleven of the best weakly-supervised deep networks. We achieve state-of-the-art performance when pre-training on natural imagery. The average absolute performance gap to the next-best weakly-supervised network is well over ten percent for both natural imagery and sonar imagery. This gap is found to be statistically significant.</li>
</ul>

<h3>Title: Analyzing Task-Encoding Tokens in Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Yu Bai, Heyan Huang, Cesare Spinoso-Di Piano, Marc-Antoine Rondeau, Sanxing Chen, Yang Gao, Jackie Chi Kit Cheung</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.11323">https://arxiv.org/abs/2401.11323</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.11323">https://arxiv.org/pdf/2401.11323</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.11323]] Analyzing Task-Encoding Tokens in Large Language Models(https://arxiv.org/abs/2401.11323)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>In-context learning (ICL) has become an effective solution for few-shot learning in natural language processing. Past work has found that, during this process, representations of the last prompt token are utilized to store task reasoning procedures, thereby explaining the working mechanism of in-context learning. In this paper, we seek to locate and analyze other task-encoding tokens whose representations store task reasoning procedures. Supported by experiments that ablate the representations of different token types, we find that template and stopword tokens are the most prone to be task-encoding tokens. In addition, we demonstrate experimentally that lexical cues, repetition, and text formats are the main distinguishing characteristics of these tokens. Our work provides additional insights into how large language models (LLMs) leverage task reasoning procedures in ICL and suggests that future work may involve using task-encoding tokens to improve the computational efficiency of LLMs at inference time and their ability to handle long sequences.</li>
</ul>

<h3>Title: Navigating Cybersecurity Training: A Comprehensive Review</h3>
<ul>
<li><strong>Authors: </strong>Saif Al-Dean Qawasmeh, Ali Abdullah S. AlQahtani, Muhammad Khurram Khan</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.11326">https://arxiv.org/abs/2401.11326</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.11326">https://arxiv.org/pdf/2401.11326</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.11326]] Navigating Cybersecurity Training: A Comprehensive Review(https://arxiv.org/abs/2401.11326)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, defense</a></li>
<li><strong>Abstract: </strong>In the dynamic realm of cybersecurity, awareness training is crucial for strengthening defenses against cyber threats. This survey examines a spectrum of cybersecurity awareness training methods, analyzing traditional, technology-based, and innovative strategies. It evaluates the principles, efficacy, and constraints of each method, presenting a comparative analysis that highlights their pros and cons. The study also investigates emerging trends like artificial intelligence and extended reality, discussing their prospective influence on the future of cybersecurity training. Additionally, it addresses implementation challenges and proposes solutions, drawing on insights from real-world case studies. The goal is to bolster the understanding of cybersecurity awareness training's current landscape, offering valuable perspectives for both practitioners and scholars.</li>
</ul>

<h3>Title: Prompting Large Vision-Language Models for Compositional Reasoning</h3>
<ul>
<li><strong>Authors: </strong>Timothy Ossowski, Ming Jiang, Junjie Hu</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.11337">https://arxiv.org/abs/2401.11337</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.11337">https://arxiv.org/pdf/2401.11337</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.11337]] Prompting Large Vision-Language Models for Compositional Reasoning(https://arxiv.org/abs/2401.11337)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>Vision-language models such as CLIP have shown impressive capabilities in encoding texts and images into aligned embeddings, enabling the retrieval of multimodal data in a shared embedding space. However, these embedding-based models still face challenges in effectively matching images and texts with similar visio-linguistic compositionality, as evidenced by their performance on the recent Winoground dataset. In this paper, we argue that this limitation stems from two factors: the use of single vector representations for complex multimodal data, and the absence of step-by-step reasoning in these embedding-based methods. To address this issue, we make an exploratory step using a novel generative method that prompts large vision-language models (e.g., GPT-4) to depict images and perform compositional reasoning. Our method outperforms other embedding-based methods on the Winoground dataset, and obtains further improvement of up to 10% accuracy when enhanced with the optimal description.</li>
</ul>

<h3>Title: Distributionally Robust Policy Evaluation under General Covariate Shift  in Contextual Bandits</h3>
<ul>
<li><strong>Authors: </strong>Yihong Guo, Hao Liu, Yisong Yue, Anqi Liu</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.11353">https://arxiv.org/abs/2401.11353</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.11353">https://arxiv.org/pdf/2401.11353</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.11353]] Distributionally Robust Policy Evaluation under General Covariate Shift  in Contextual Bandits(https://arxiv.org/abs/2401.11353)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>We introduce a distributionally robust approach that enhances the reliability of offline policy evaluation in contextual bandits under general covariate shifts. Our method aims to deliver robust policy evaluation results in the presence of discrepancies in both context and policy distribution between logging and target data. Central to our methodology is the application of robust regression, a distributionally robust technique tailored here to improve the estimation of conditional reward distribution from logging data. Utilizing the reward model obtained from robust regression, we develop a comprehensive suite of policy value estimators, by integrating our reward model into established evaluation frameworks, namely direct methods and doubly robust methods. Through theoretical analysis, we further establish that the proposed policy value estimators offer a finite sample upper bound for the bias, providing a clear advantage over traditional methods, especially when the shift is large. Finally, we designed an extensive range of policy evaluation scenarios, covering diverse magnitudes of shifts and a spectrum of logging and target policies. Our empirical results indicate that our approach significantly outperforms baseline methods, most notably in 90% of the cases under the policy shift-only settings and 72% of the scenarios under the general covariate shift settings.</li>
</ul>

<h3>Title: ANNA: A Deep Learning Based Dataset in Heterogeneous Traffic for  Autonomous Vehicles</h3>
<ul>
<li><strong>Authors: </strong>Mahedi Kamal, Tasnim Fariha, Afrina Kabir Zinia, Md. Abu Syed, Fahim Hasan Khan, Md. Mahbubur Rahman</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.11358">https://arxiv.org/abs/2401.11358</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.11358">https://arxiv.org/pdf/2401.11358</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.11358]] ANNA: A Deep Learning Based Dataset in Heterogeneous Traffic for  Autonomous Vehicles(https://arxiv.org/abs/2401.11358)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>Recent breakthroughs in artificial intelligence offer tremendous promise for the development of self-driving applications. Deep Neural Networks, in particular, are being utilized to support the operation of semi-autonomous cars through object identification and semantic segmentation. To assess the inadequacy of the current dataset in the context of autonomous and semi-autonomous cars, we created a new dataset named ANNA. This study discusses a custom-built dataset that includes some unidentified vehicles in the perspective of Bangladesh, which are not included in the existing dataset. A dataset validity check was performed by evaluating models using the Intersection Over Union (IOU) metric. The results demonstrated that the model trained on our custom dataset was more precise and efficient than the models trained on the KITTI or COCO dataset concerning Bangladeshi traffic. The research presented in this paper also emphasizes the importance of developing accurate and efficient object detection algorithms for the advancement of autonomous vehicles.</li>
</ul>

<h3>Title: PepHarmony: A Multi-View Contrastive Learning Framework for Integrated  Sequence and Structure-Based Peptide Encoding</h3>
<ul>
<li><strong>Authors: </strong>Ruochi Zhang, Haoran Wu, Chang Liu, Huaping Li, Yuqian Wu, Kewei Li, Yifan Wang, Yifan Deng, Jiahui Chen, Fengfeng Zhou, Xin Gao</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CE, q-bio.BM</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.11360">https://arxiv.org/abs/2401.11360</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.11360">https://arxiv.org/pdf/2401.11360</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.11360]] PepHarmony: A Multi-View Contrastive Learning Framework for Integrated  Sequence and Structure-Based Peptide Encoding(https://arxiv.org/abs/2401.11360)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Recent advances in protein language models have catalyzed significant progress in peptide sequence representation. Despite extensive exploration in this field, pre-trained models tailored for peptide-specific needs remain largely unaddressed due to the difficulty in capturing the complex and sometimes unstable structures of peptides. This study introduces a novel multi-view contrastive learning framework PepHarmony for the sequence-based peptide encoding task. PepHarmony innovatively combines both sequence- and structure-level information into a sequence-level encoding module through contrastive learning. We carefully select datasets from the Protein Data Bank (PDB) and AlphaFold database to encompass a broad spectrum of peptide sequences and structures. The experimental data highlights PepHarmony's exceptional capability in capturing the intricate relationship between peptide sequences and structures compared with the baseline and fine-tuned models. The robustness of our model is confirmed through extensive ablation studies, which emphasize the crucial roles of contrastive loss and strategic data sorting in enhancing predictive performance. The proposed PepHarmony framework serves as a notable contribution to peptide representations, and offers valuable insights for future applications in peptide drug discovery and peptide engineering. We have made all the source code utilized in this study publicly accessible via GitHub at https://github.com/zhangruochi/PepHarmony or this http URL</li>
</ul>

<h3>Title: Finding a Needle in the Adversarial Haystack: A Targeted Paraphrasing  Approach For Uncovering Edge Cases with Minimal Distribution Distortion</h3>
<ul>
<li><strong>Authors: </strong>Aly M. Kassem, Sherif Saad</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.11373">https://arxiv.org/abs/2401.11373</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.11373">https://arxiv.org/pdf/2401.11373</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.11373]] Finding a Needle in the Adversarial Haystack: A Targeted Paraphrasing  Approach For Uncovering Edge Cases with Minimal Distribution Distortion(https://arxiv.org/abs/2401.11373)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack</a></li>
<li><strong>Abstract: </strong>Adversarial attacks against NLP Deep Learning models are a significant concern. In particular, adversarial samples exploit the model's sensitivity to small input changes. While these changes appear insignificant on the semantics of the input sample, they result in significant decay in model performance. In this paper, we propose Targeted Paraphrasing via RL (TPRL), an approach to automatically learn a policy to generate challenging samples that most likely improve the model's performance. TPRL leverages FLAN T5, a language model, as a generator and employs a self learned policy using a proximal policy gradient to generate the adversarial examples automatically. TPRL's reward is based on the confusion induced in the classifier, preserving the original text meaning through a Mutual Implication score. We demonstrate and evaluate TPRL's effectiveness in discovering natural adversarial attacks and improving model performance through extensive experiments on four diverse NLP classification tasks via Automatic and Human evaluation. TPRL outperforms strong baselines, exhibits generalizability across classifiers and datasets, and combines the strengths of language modeling and reinforcement learning to generate diverse and influential adversarial examples.</li>
</ul>

<h3>Title: Language Models as Hierarchy Encoders</h3>
<ul>
<li><strong>Authors: </strong>Yuan He, Zhangdie Yuan, Jiaoyan Chen, Ian Horrocks</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.11374">https://arxiv.org/abs/2401.11374</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.11374">https://arxiv.org/pdf/2401.11374</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.11374]] Language Models as Hierarchy Encoders(https://arxiv.org/abs/2401.11374)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Interpreting hierarchical structures latent in language is a key limitation of current language models (LMs). While previous research has implicitly leveraged these hierarchies to enhance LMs, approaches for their explicit encoding are yet to be explored. To address this, we introduce a novel approach to re-train transformer encoder-based LMs as Hierarchy Transformer encoders (HiTs), harnessing the expansive nature of hyperbolic space. Our method situates the output embedding space of pre-trained LMs within a Poincar\'e ball with a curvature that adapts to the embedding dimension, followed by re-training on hyperbolic cluster and centripetal losses. These losses are designed to effectively cluster related entities (input as texts) and organise them hierarchically. We evaluate HiTs against pre-trained and fine-tuned LMs, focusing on their capabilities in simulating transitive inference, predicting subsumptions, and transferring knowledge across hierarchies. The results demonstrate that HiTs consistently outperform both pre-trained and fine-tuned LMs in these tasks, underscoring the effectiveness and transferability of our re-trained hierarchy encoders.</li>
</ul>

<h3>Title: Using Large Language Model for End-to-End Chinese ASR and NER</h3>
<ul>
<li><strong>Authors: </strong>Yuang Li, Jiawei Yu, Yanqing Zhao, Min Zhang, Mengxin Ren, Xiaofeng Zhao, Xiaosong Qiao, Chang Su, Miaomiao Ma, Hao Yang</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.11382">https://arxiv.org/abs/2401.11382</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.11382">https://arxiv.org/pdf/2401.11382</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.11382]] Using Large Language Model for End-to-End Chinese ASR and NER(https://arxiv.org/abs/2401.11382)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Mapping speech tokens to the same feature space as text tokens has become the paradigm for the integration of speech modality into decoder-only large language models (LLMs). An alternative approach is to use an encoder-decoder architecture that incorporates speech features through cross-attention. This approach, however, has received less attention in the literature. In this work, we connect the Whisper encoder with ChatGLM3 and provide in-depth comparisons of these two approaches using Chinese automatic speech recognition (ASR) and name entity recognition (NER) tasks. We evaluate them not only by conventional metrics like the F1 score but also by a novel fine-grained taxonomy of ASR-NER errors. Our experiments reveal that encoder-decoder architecture outperforms decoder-only architecture with a short context, while decoder-only architecture benefits from a long context as it fully exploits all layers of the LLM. By using LLM, we significantly reduced the entity omission errors and improved the entity ASR accuracy compared to the Conformer baseline. Additionally, we obtained a state-of-the-art (SOTA) F1 score of 0.805 on the AISHELL-NER test set by using chain-of-thought (CoT) NER which first infers long-form ASR transcriptions and then predicts NER labels.</li>
</ul>

<h3>Title: MedLM: Exploring Language Models for Medical Question Answering Systems</h3>
<ul>
<li><strong>Authors: </strong>Niraj Yagnik, Jay Jhaveri, Vivek Sharma, Gabriel Pila, Asma Ben, Jingbo Shang</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.11389">https://arxiv.org/abs/2401.11389</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.11389">https://arxiv.org/pdf/2401.11389</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.11389]] MedLM: Exploring Language Models for Medical Question Answering Systems(https://arxiv.org/abs/2401.11389)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative, large language model</a></li>
<li><strong>Abstract: </strong>In the face of rapidly expanding online medical literature, automated systems for aggregating and summarizing information are becoming increasingly crucial for healthcare professionals and patients. Large Language Models (LLMs), with their advanced generative capabilities, have shown promise in various NLP tasks, and their potential in the healthcare domain, particularly for Closed-Book Generative QnA, is significant. However, the performance of these models in domain-specific tasks such as medical Q&A remains largely unexplored. This study aims to fill this gap by comparing the performance of general and medical-specific distilled LMs for medical Q&A. We aim to evaluate the effectiveness of fine-tuning domain-specific LMs and compare the performance of different families of Language Models. The study will address critical questions about these models' reliability, comparative performance, and effectiveness in the context of medical Q&A. The findings will provide valuable insights into the suitability of different LMs for specific applications in the medical domain.</li>
</ul>

<h3>Title: Causal Generative Explainers using Counterfactual Inference: A Case  Study on the Morpho-MNIST Dataset</h3>
<ul>
<li><strong>Authors: </strong>Will Taylor-Melanson, Zahra Sadeghi, Stan Matwin</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.11394">https://arxiv.org/abs/2401.11394</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.11394">https://arxiv.org/pdf/2401.11394</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.11394]] Causal Generative Explainers using Counterfactual Inference: A Case  Study on the Morpho-MNIST Dataset(https://arxiv.org/abs/2401.11394)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability, generative</a></li>
<li><strong>Abstract: </strong>In this paper, we propose leveraging causal generative learning as an interpretable tool for explaining image classifiers. Specifically, we present a generative counterfactual inference approach to study the influence of visual features (i.e., pixels) as well as causal factors through generative learning. To this end, we first uncover the most influential pixels on a classifier's decision by varying the value of a causal attribute via counterfactual inference and computing both Shapely and contrastive explanations for counterfactual images with these different attribute values. We then establish a Monte-Carlo mechanism using the generator of a causal generative model in order to adapt Shapley explainers to produce feature importances for the human-interpretable attributes of a causal dataset in the case where a classifier has been trained exclusively on the images of the dataset. Finally, we present optimization methods for creating counterfactual explanations of classifiers by means of counterfactual inference, proposing straightforward approaches for both differentiable and arbitrary classifiers. We exploit the Morpho-MNIST causal dataset as a case study for exploring our proposed methods for generating counterfacutl explantions. We employ visual explanation methods from OmnixAI open source toolkit to compare them with our proposed methods. By employing quantitative metrics to measure the interpretability of counterfactual explanations, we find that our proposed methods of counterfactual explanation offer more interpretable explanations compared to those generated from OmnixAI. This finding suggests that our methods are well-suited for generating highly interpretable counterfactual explanations on causal datasets.</li>
</ul>

<h3>Title: UniM-OV3D: Uni-Modality Open-Vocabulary 3D Scene Understanding with  Fine-Grained Feature Representation</h3>
<ul>
<li><strong>Authors: </strong>Qingdong He, Jinlong Peng, Zhengkai Jiang, Kai Wu, Xiaozhong Ji, Jiangning Zhang, Yabiao Wang, Chengjie Wang, Mingang Chen, Yunsheng Wu</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.11395">https://arxiv.org/abs/2401.11395</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.11395">https://arxiv.org/pdf/2401.11395</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.11395]] UniM-OV3D: Uni-Modality Open-Vocabulary 3D Scene Understanding with  Fine-Grained Feature Representation(https://arxiv.org/abs/2401.11395)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction, segmentation</a></li>
<li><strong>Abstract: </strong>3D open-vocabulary scene understanding aims to recognize arbitrary novel categories beyond the base label space. However, existing works not only fail to fully utilize all the available modal information in the 3D domain but also lack sufficient granularity in representing the features of each modality. In this paper, we propose a unified multimodal 3D open-vocabulary scene understanding network, namely UniM-OV3D, which aligns point clouds with image, language and depth. To better integrate global and local features of the point clouds, we design a hierarchical point cloud feature extraction module that learns comprehensive fine-grained feature representations. Further, to facilitate the learning of coarse-to-fine point-semantic representations from captions, we propose the utilization of hierarchical 3D caption pairs, capitalizing on geometric constraints across various viewpoints of 3D scenes. Extensive experimental results demonstrate the effectiveness and superiority of our method in open-vocabulary semantic and instance segmentation, which achieves state-of-the-art performance on both indoor and outdoor benchmarks such as ScanNet, ScanNet200, S3IDS and nuScenes. Code is available at https://github.com/hithqd/UniM-OV3D.</li>
</ul>

<h3>Title: LLMRA: Multi-modal Large Language Model based Restoration Assistant</h3>
<ul>
<li><strong>Authors: </strong>Xiaoyu Jin, Yuan Shi, Bin Xia, Wenming Yang</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.11401">https://arxiv.org/abs/2401.11401</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.11401">https://arxiv.org/pdf/2401.11401</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.11401]] LLMRA: Multi-modal Large Language Model based Restoration Assistant(https://arxiv.org/abs/2401.11401)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer, large language model</a></li>
<li><strong>Abstract: </strong>Multi-modal Large Language Models (MLLMs) have a significant impact on various tasks, due to their extensive knowledge and powerful perception and generation capabilities. However, it still remains an open research problem on applying MLLMs to low-level vision tasks. In this paper, we present a simple MLLM-based Image Restoration framework to address this gap, namely Multi-modal Large Language Model based Restoration Assistant (LLMRA). We exploit the impressive capabilities of MLLMs to obtain the degradation information for universal image restoration. By employing a pretrained multi-modal large language model and a vision language model, we generate text descriptions and encode them as context embedding with degradation information for the degraded image. Through the proposed Context Enhance Module (CEM) and Degradation Context based Transformer Network (DC-former), we integrate these context embedding into the restoration network, contributing to more accurate and adjustable image restoration. Based on the dialogue with the users, our method leverages image degradation priors from MLLMs, providing low-level attributes descriptions of the input low-quality images and the restored high-quality images simultaneously. Extensive experiments demonstrate the superior performance of our LLMRA in universal image restoration tasks.</li>
</ul>

<h3>Title: Enabling clustering algorithms to detect clusters of varying densities  through scale-invariant data preprocessing</h3>
<ul>
<li><strong>Authors: </strong>Sunil Aryal, Jonathan R. Wells, Arbind Agrahari Baniya, KC Santosh</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.11402">https://arxiv.org/abs/2401.11402</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.11402">https://arxiv.org/pdf/2401.11402</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.11402]] Enabling clustering algorithms to detect clusters of varying densities  through scale-invariant data preprocessing(https://arxiv.org/abs/2401.11402)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>In this paper, we show that preprocessing data using a variant of rank transformation called 'Average Rank over an Ensemble of Sub-samples (ARES)' makes clustering algorithms robust to data representation and enable them to detect varying density clusters. Our empirical results, obtained using three most widely used clustering algorithms-namely KMeans, DBSCAN, and DP (Density Peak)-across a wide range of real-world datasets, show that clustering after ARES transformation produces better and more consistent results.</li>
</ul>

<h3>Title: Adversarial Augmentation Training Makes Action Recognition Models More  Robust to Realistic Video Distribution Shifts</h3>
<ul>
<li><strong>Authors: </strong>Kiyoon Kim, Shreyank N Gowda, Panagiotis Eustratiadis, Antreas Antoniou, Robert B Fisher</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.11406">https://arxiv.org/abs/2401.11406</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.11406">https://arxiv.org/pdf/2401.11406</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.11406]] Adversarial Augmentation Training Makes Action Recognition Models More  Robust to Realistic Video Distribution Shifts(https://arxiv.org/abs/2401.11406)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, transformer</a></li>
<li><strong>Abstract: </strong>Despite recent advances in video action recognition achieving strong performance on existing benchmarks, these models often lack robustness when faced with natural distribution shifts between training and test data. We propose two novel evaluation methods to assess model resilience to such distribution disparity. One method uses two different datasets collected from different sources and uses one for training and validation, and the other for testing. More precisely, we created dataset splits of HMDB-51 or UCF-101 for training, and Kinetics-400 for testing, using the subset of the classes that are overlapping in both train and test datasets. The other proposed method extracts the feature mean of each class from the target evaluation dataset's training data (i.e. class prototype) and estimates test video prediction as a cosine similarity score between each sample to the class prototypes of each target class. This procedure does not alter model weights using the target dataset and it does not require aligning overlapping classes of two different datasets, thus is a very efficient method to test the model robustness to distribution shifts without prior knowledge of the target distribution. We address the robustness problem by adversarial augmentation training - generating augmented views of videos that are "hard" for the classification model by applying gradient ascent on the augmentation parameters - as well as "curriculum" scheduling the strength of the video augmentations. We experimentally demonstrate the superior performance of the proposed adversarial augmentation approach over baselines across three state-of-the-art action recognition models - TSM, Video Swin Transformer, and Uniformer. The presented work provides critical insight into model robustness to distribution shifts and presents effective techniques to enhance video action recognition performance in a real-world deployment.</li>
</ul>

<h3>Title: SEBERTNets: Sequence Enhanced BERT Networks for Event Entity Extraction  Tasks Oriented to the Finance Field</h3>
<ul>
<li><strong>Authors: </strong>Congqing He, Xiangyu Zhu, Yuquan Le, Yuzhong Liu, Jianhong Yin</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.11408">https://arxiv.org/abs/2401.11408</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.11408">https://arxiv.org/pdf/2401.11408</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.11408]] SEBERTNets: Sequence Enhanced BERT Networks for Event Entity Extraction  Tasks Oriented to the Finance Field(https://arxiv.org/abs/2401.11408)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction</a></li>
<li><strong>Abstract: </strong>Event extraction lies at the cores of investment analysis and asset management in the financial field, and thus has received much attention. The 2019 China conference on knowledge graph and semantic computing (CCKS) challenge sets up a evaluation competition for event entity extraction task oriented to the finance field. In this task, we mainly focus on how to extract the event entity accurately, and recall all the corresponding event entity effectively. In this paper, we propose a novel model, Sequence Enhanced BERT Networks (SEBERTNets for short), which can inherit the advantages of the BERT,and while capturing sequence semantic information. In addition, motivated by recommendation system, we propose Hybrid Sequence Enhanced BERT Networks (HSEBERTNets for short), which uses a multi-channel recall method to recall all the corresponding event entity. The experimental results show that, the F1 score of SEBERTNets is 0.905 in the first stage, and the F1 score of HSEBERTNets is 0.934 in the first stage, which demonstarate the effectiveness of our methods.</li>
</ul>

<h3>Title: Agricultural Recommendation System based on Deep Learning: A  Multivariate Weather Forecasting Approach</h3>
<ul>
<li><strong>Authors: </strong>Md Zubair (1), Md. Shahidul Salim (2), Mehrab Mustafy Rahman (3), Mohammad Jahid Ibna Basher (1), Shahin Imran (4), Iqbal H. Sarker (5) ((1) Chittagong University of Engineering & Technology, Chittagong, Bangladesh, (2) Khulna University of Engineering & Technology, Khulna, Bangladesh, (3) Islamic University of Technology, Gazipur, Bangladesh, (4) Khulna Agricultural University, Khulna, Bangladesh, (5) Edith Cowan University, Perth, Australia.)</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.11410">https://arxiv.org/abs/2401.11410</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.11410">https://arxiv.org/pdf/2401.11410</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.11410]] Agricultural Recommendation System based on Deep Learning: A  Multivariate Weather Forecasting Approach(https://arxiv.org/abs/2401.11410)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, protect</a></li>
<li><strong>Abstract: </strong>Bangladesh is predominantly an agricultural country, where the agrarian sector plays an essential role in accelerating economic growth and enabling the food security of the people. The performance of this sector has an overwhelming impact on the primary macroeconomic objectives like food security, employment generation, poverty alleviation, human resources development, and other economic and social forces. Although Bangladesh's labor-intensive agriculture has achieved steady increases in food grain production, it often suffered from unfavorable weather conditions such as heavy rainfall, low temperature, and drought. Consequently, these factors hinder the production of food substantially, putting the country's overall food security in danger. In order to have a profitable, sustainable, and farmer-friendly agricultural practice, this paper proposes a context-based crop recommendation system powered by a weather forecast model. With extensive evaluation, the multivariate Stacked Bi-LSTM Network is employed as the weather forecasting model. The proposed weather model can forecast Rainfall, Temperature, Humidity, and Sunshine for any given location in Bangladesh with higher accuracy. These predictions guide our system to assist the farmers in making feasible decisions about planting, irrigation, harvesting, and so on. Additionally, our full-fledged system is capable of alerting the farmers about extreme weather conditions so that preventive measures can be undertaken to protect the crops. Finally, the system is also adept at making knowledge-based crop suggestions for the flood and drought-prone regions of Bangladesh.</li>
</ul>

<h3>Title: S$^3$M-Net: Joint Learning of Semantic Segmentation and Stereo Matching  for Autonomous Driving</h3>
<ul>
<li><strong>Authors: </strong>Zhiyuan Wu, Yi Feng, Chuang-Wei Liu, Fisher Yu, Qijun Chen, Rui Fan</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI, cs.RO</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.11414">https://arxiv.org/abs/2401.11414</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.11414">https://arxiv.org/pdf/2401.11414</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.11414]] S$^3$M-Net: Joint Learning of Semantic Segmentation and Stereo Matching  for Autonomous Driving(https://arxiv.org/abs/2401.11414)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>Semantic segmentation and stereo matching are two essential components of 3D environmental perception systems for autonomous driving. Nevertheless, conventional approaches often address these two problems independently, employing separate models for each task. This approach poses practical limitations in real-world scenarios, particularly when computational resources are scarce or real-time performance is imperative. Hence, in this article, we introduce S$^3$M-Net, a novel joint learning framework developed to perform semantic segmentation and stereo matching simultaneously. Specifically, S$^3$M-Net shares the features extracted from RGB images between both tasks, resulting in an improved overall scene understanding capability. This feature sharing process is realized using a feature fusion adaption (FFA) module, which effectively transforms the shared features into semantic space and subsequently fuses them with the encoded disparity features. The entire joint learning framework is trained by minimizing a novel semantic consistency-guided (SCG) loss, which places emphasis on the structural consistency in both tasks. Extensive experimental results conducted on the vKITTI2 and KITTI datasets demonstrate the effectiveness of our proposed joint learning framework and its superior performance compared to other state-of-the-art single-task networks. Our project webpage is accessible at mias.group/S3M-Net.</li>
</ul>

<h3>Title: Embedded Hyperspectral Band Selection with Adaptive Optimization for  Image Semantic Segmentation</h3>
<ul>
<li><strong>Authors: </strong>Yaniv Zimmer, Oren Glickman</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.11420">https://arxiv.org/abs/2401.11420</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.11420">https://arxiv.org/pdf/2401.11420</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.11420]] Embedded Hyperspectral Band Selection with Adaptive Optimization for  Image Semantic Segmentation(https://arxiv.org/abs/2401.11420)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>Hyperspectral band selection plays a pivotal role in remote sensing and image analysis, aiming to identify the most informative spectral bands while minimizing computational overhead. In this paper, we introduce a pioneering approach for hyperspectral band selection that offers an embedded solution, making it well-suited for resource-constrained or real-time applications. Our proposed method, embedded Hyperspectral Band Selection (EHBS), excels in selecting the best bands without the need for prior processing, seamlessly integrating with the downstream task model. This is achieved through the adaptation of the Stochastic Gates (STG) algorithm, originally designed for feature selection, for hyperspectral band selection in the context of image semantic segmentation and the integration of a dynamic optimizer, DoG, which removes the need for the required tuning the learning rate. To assess the performance of our method, we introduce a novel metric for evaluating band selection methods across different target numbers of selected bands quantified by the Area Under the Curve (AUC). We conduct experiments on two distinct semantic-segmentation hyperspectral benchmark datasets, demonstrating its superiority in terms of its resulting accuracy and its ease of use compared to many common and state-of-the-art methods. Furthermore, our contributions extend beyond the realm of hyperspectral band selection. The adaptability of our approach to other tasks, especially those involving grouped features, opens up promising avenues for broader applications within the realm of deep learning, such as feature selection for feature groups. The demonstrated success on the tested datasets and the potential for application to a variety of tasks underscore the value of our method as a substantial addition to the field of computer vision.</li>
</ul>

<h3>Title: Enhancing the vision-language foundation model with key semantic  knowledge-emphasized report refinement</h3>
<ul>
<li><strong>Authors: </strong>Cheng Li, Weijian Huang, Hao Yang, Jiarun Liu, Shanshan Wang</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.11421">https://arxiv.org/abs/2401.11421</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.11421">https://arxiv.org/pdf/2401.11421</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.11421]] Enhancing the vision-language foundation model with key semantic  knowledge-emphasized report refinement(https://arxiv.org/abs/2401.11421)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>Recently, vision-language representation learning has made remarkable advancements in building up medical foundation models, holding immense potential for transforming the landscape of clinical research and medical care. The underlying hypothesis is that the rich knowledge embedded in radiology reports can effectively assist and guide the learning process, reducing the need for additional labels. However, these reports tend to be complex and sometimes even consist of redundant descriptions that make the representation learning too challenging to capture the key semantic information. This paper develops a novel iterative vision-language representation learning framework by proposing a key semantic knowledge-emphasized report refinement method. Particularly, raw radiology reports are refined to highlight the key information according to a constructed clinical dictionary and two model-optimized knowledge-enhancement metrics. The iterative framework is designed to progressively learn, starting from gaining a general understanding of the patient's condition based on raw reports and gradually refines and extracts critical information essential to the fine-grained analysis tasks. The effectiveness of the proposed framework is validated on various downstream medical image analysis tasks, including disease classification, region-of-interest segmentation, and phrase grounding. Our framework surpasses seven state-of-the-art methods in both fine-tuning and zero-shot settings, demonstrating its encouraging potential for different clinical applications.</li>
</ul>

<h3>Title: Exploring Diffusion Time-steps for Unsupervised Representation Learning</h3>
<ul>
<li><strong>Authors: </strong>Zhongqi Yue, Jiankun Wang, Qianru Sun, Lei Ji, Eric I-Chao Chang, Hanwang Zhang</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.11430">https://arxiv.org/abs/2401.11430</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.11430">https://arxiv.org/pdf/2401.11430</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.11430]] Exploring Diffusion Time-steps for Unsupervised Representation Learning(https://arxiv.org/abs/2401.11430)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>Representation learning is all about discovering the hidden modular attributes that generate the data faithfully. We explore the potential of Denoising Diffusion Probabilistic Model (DM) in unsupervised learning of the modular attributes. We build a theoretical framework that connects the diffusion time-steps and the hidden attributes, which serves as an effective inductive bias for unsupervised learning. Specifically, the forward diffusion process incrementally adds Gaussian noise to samples at each time-step, which essentially collapses different samples into similar ones by losing attributes, e.g., fine-grained attributes such as texture are lost with less noise added (i.e., early time-steps), while coarse-grained ones such as shape are lost by adding more noise (i.e., late time-steps). To disentangle the modular attributes, at each time-step t, we learn a t-specific feature to compensate for the newly lost attribute, and the set of all 1,...,t-specific features, corresponding to the cumulative set of lost attributes, are trained to make up for the reconstruction error of a pre-trained DM at time-step t. On CelebA, FFHQ, and Bedroom datasets, the learned feature significantly improves attribute classification and enables faithful counterfactual generation, e.g., interpolating only one specified attribute between two images, validating the disentanglement quality. Codes are in https://github.com/yue-zhongqi/diti.</li>
</ul>

<h3>Title: Linear Alignment: A Closed-form Solution for Aligning Human Preferences  without Tuning and Feedback</h3>
<ul>
<li><strong>Authors: </strong>Songyang Gao, Qiming Ge, Wei Shen, Shihan Dou, Junjie Ye, Xiao Wang, Rui Zheng, Yicheng Zou, Zhi Chen, Hang Yan, Qi Zhang, Dahua Lin</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.11458">https://arxiv.org/abs/2401.11458</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.11458">https://arxiv.org/pdf/2401.11458</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.11458]] Linear Alignment: A Closed-form Solution for Aligning Human Preferences  without Tuning and Feedback(https://arxiv.org/abs/2401.11458)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction</a></li>
<li><strong>Abstract: </strong>The success of AI assistants based on Language Models (LLMs) hinges on Reinforcement Learning from Human Feedback (RLHF) to comprehend and align with user intentions. However, traditional alignment algorithms, such as PPO, are hampered by complex annotation and training requirements. This reliance limits the applicability of RLHF and hinders the development of professional assistants tailored to diverse human preferences. In this work, we introduce \textit{Linear Alignment}, a novel algorithm that aligns language models with human preferences in one single inference step, eliminating the reliance on data annotation and model training. Linear alignment incorporates a new parameterization for policy optimization under divergence constraints, which enables the extraction of optimal policy in a closed-form manner and facilitates the direct estimation of the aligned response. Extensive experiments on both general and personalized preference datasets demonstrate that linear alignment significantly enhances the performance and efficiency of LLM alignment across diverse scenarios. Our code and dataset will be published on \url{https://github.com/Wizardcoast/Linear_Alignment.git}.</li>
</ul>

<h3>Title: Over-Reasoning and Redundant Calculation of Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Cheng-Han Chiang, Hung-yi Lee</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.11467">https://arxiv.org/abs/2401.11467</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.11467">https://arxiv.org/pdf/2401.11467</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.11467]] Over-Reasoning and Redundant Calculation of Large Language Models(https://arxiv.org/abs/2401.11467)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large language models (LLMs) can solve problems step-by-step. While this chain-of-thought (CoT) reasoning boosts LLMs' performance, it is unclear if LLMs \textit{know} when to use CoT and whether those CoT are always necessary to answer the question. This paper shows that LLMs tend to generate redundant calculations and reasoning on a manually constructed math QA dataset, GSM8K-Zero. GSM8K-Zero is constructed such that the questions can be answered without any calculations, but LLMs, including Llama-2 models and Claude-2, tend to generate lengthy and unnecessary calculations to answer the questions. We also conduct experiments to explain why LLMs generate redundant calculations and reasonings. GSM8K-Zero is publicly available at https://github.com/d223302/Over-Reasoning-of-LLMs and https://huggingface.co/datasets/dcml0714/GSM8K-Zero.</li>
</ul>

<h3>Title: Exploring Missing Modality in Multimodal Egocentric Datasets</h3>
<ul>
<li><strong>Authors: </strong>Merey Ramazanova, Alejandro Pardo, Humam Alwassel, Bernard Ghanem</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.11470">https://arxiv.org/abs/2401.11470</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.11470">https://arxiv.org/pdf/2401.11470</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.11470]] Exploring Missing Modality in Multimodal Egocentric Datasets(https://arxiv.org/abs/2401.11470)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, transformer</a></li>
<li><strong>Abstract: </strong>Multimodal video understanding is crucial for analyzing egocentric videos, where integrating multiple sensory signals significantly enhances action recognition and moment localization. However, practical applications often grapple with incomplete modalities due to factors like privacy concerns, efficiency demands, or hardware malfunctions. Addressing this, our study delves into the impact of missing modalities on egocentric action recognition, particularly within transformer-based models. We introduce a novel concept -Missing Modality Token (MMT)-to maintain performance even when modalities are absent, a strategy that proves effective in the Ego4D, Epic-Kitchens, and Epic-Sounds datasets. Our method mitigates the performance loss, reducing it from its original $\sim 30\%$ drop to only $\sim 10\%$ when half of the test set is modal-incomplete. Through extensive experimentation, we demonstrate the adaptability of MMT to different training scenarios and its superiority in handling missing modalities compared to current methods. Our research contributes a comprehensive analysis and an innovative approach, opening avenues for more resilient multimodal systems in real-world settings.</li>
</ul>

<h3>Title: Edge-Enabled Real-time Railway Track Segmentation</h3>
<ul>
<li><strong>Authors: </strong>Chen Chenglin, Wang Fei, Yang Min, Qin Yong, Bai Yun</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.11492">https://arxiv.org/abs/2401.11492</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.11492">https://arxiv.org/pdf/2401.11492</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.11492]] Edge-Enabled Real-time Railway Track Segmentation(https://arxiv.org/abs/2401.11492)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction, segmentation</a></li>
<li><strong>Abstract: </strong>Accurate and rapid railway track segmentation can assist automatic train driving and is a key step in early warning to fixed or moving obstacles on the railway track. However, certain existing algorithms tailored for track segmentation often struggle to meet the requirements of real-time and efficiency on resource-constrained edge devices. Considering this challenge, we propose an edge-enabled real-time railway track segmentation algorithm, which is optimized to be suitable for edge applications by optimizing the network structure and quantizing the model after training. Initially, Ghost convolution is introduced to reduce the complexity of the backbone, thereby achieving the extraction of key information of the interested region at a lower cost. To further reduce the model complexity and calculation, a new lightweight detection head is proposed to achieve the best balance between accuracy and efficiency. Subsequently, we introduce quantization techniques to map the model's floating-point weights and activation values into lower bit-width fixed-point representations, reducing computational demands and memory footprint, ultimately accelerating the model's inference. Finally, we draw inspiration from GPU parallel programming principles to expedite the pre-processing and post-processing stages of the algorithm by doing parallel processing. The approach is evaluated with public and challenging dataset RailSem19 and tested on Jetson Nano. Experimental results demonstrate that our enhanced algorithm achieves an accuracy level of 83.3% while achieving a real-time inference rate of 25 frames per second when the input size is 480x480, thereby effectively meeting the requirements for real-time and high-efficiency operation.</li>
</ul>

<h3>Title: CheX-GPT: Harnessing Large Language Models for Enhanced Chest X-ray  Report Labeling</h3>
<ul>
<li><strong>Authors: </strong>Jawook Gu, Han-Cheol Cho, Jiho Kim, Kihyun You, Eun Kyoung Hong, Byungseok Roh</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.IR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.11505">https://arxiv.org/abs/2401.11505</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.11505">https://arxiv.org/pdf/2401.11505</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.11505]] CheX-GPT: Harnessing Large Language Models for Enhanced Chest X-ray  Report Labeling(https://arxiv.org/abs/2401.11505)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, large language model</a></li>
<li><strong>Abstract: </strong>Free-text radiology reports present a rich data source for various medical tasks, but effectively labeling these texts remains challenging. Traditional rule-based labeling methods fall short of capturing the nuances of diverse free-text patterns. Moreover, models using expert-annotated data are limited by data scarcity and pre-defined classes, impacting their performance, flexibility and scalability. To address these issues, our study offers three main contributions: 1) We demonstrate the potential of GPT as an adept labeler using carefully designed prompts. 2) Utilizing only the data labeled by GPT, we trained a BERT-based labeler, CheX-GPT, which operates faster and more efficiently than its GPT counterpart. 3) To benchmark labeler performance, we introduced a publicly available expert-annotated test set, MIMIC-500, comprising 500 cases from the MIMIC validation set. Our findings demonstrate that CheX-GPT not only excels in labeling accuracy over existing models, but also showcases superior efficiency, flexibility, and scalability, supported by our introduction of the MIMIC-500 dataset for robust benchmarking. Code and models are available at https://github.com/kakaobrain/CheXGPT.</li>
</ul>

<h3>Title: MobileARLoc: On-device Robust Absolute Localisation for Pervasive  Markerless Mobile AR</h3>
<ul>
<li><strong>Authors: </strong>Changkun Liu, Yukun Zhao, Tristan Braud</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.11511">https://arxiv.org/abs/2401.11511</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.11511">https://arxiv.org/pdf/2401.11511</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.11511]] MobileARLoc: On-device Robust Absolute Localisation for Pervasive  Markerless Mobile AR(https://arxiv.org/abs/2401.11511)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Recent years have seen significant improvement in absolute camera pose estimation, paving the way for pervasive markerless Augmented Reality (AR). However, accurate absolute pose estimation techniques are computation- and storage-heavy, requiring computation offloading. As such, AR systems rely on visual-inertial odometry (VIO) to track the device's relative pose between requests to the server. However, VIO suffers from drift, requiring frequent absolute repositioning. This paper introduces MobileARLoc, a new framework for on-device large-scale markerless mobile AR that combines an absolute pose regressor (APR) with a local VIO tracking system. Absolute pose regressors (APRs) provide fast on-device pose estimation at the cost of reduced accuracy. To address APR accuracy and reduce VIO drift, MobileARLoc creates a feedback loop where VIO pose estimations refine the APR predictions. The VIO system identifies reliable predictions of APR, which are then used to compensate for the VIO drift. We comprehensively evaluate MobileARLoc through dataset simulations. MobileARLoc halves the error compared to the underlying APR and achieve fast (80\,ms) on-device inference speed.</li>
</ul>

<h3>Title: CaBuAr: California Burned Areas dataset for delineation</h3>
<ul>
<li><strong>Authors: </strong>Daniele Rege Cambrin, Luca Colomba, Paolo Garza</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.LG, eess.IV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.11519">https://arxiv.org/abs/2401.11519</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.11519">https://arxiv.org/pdf/2401.11519</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.11519]] CaBuAr: California Burned Areas dataset for delineation(https://arxiv.org/abs/2401.11519)</code><input type="text"></li>
<li><strong>Keywords: </strong>protect, segmentation</a></li>
<li><strong>Abstract: </strong>Forest wildfires represent one of the catastrophic events that, over the last decades, caused huge environmental and humanitarian damages. In addition to a significant amount of carbon dioxide emission, they are a source of risk to society in both short-term (e.g., temporary city evacuation due to fire) and long-term (e.g., higher risks of landslides) cases. Consequently, the availability of tools to support local authorities in automatically identifying burned areas plays an important role in the continuous monitoring requirement to alleviate the aftereffects of such catastrophic events. The great availability of satellite acquisitions coupled with computer vision techniques represents an important step in developing such tools. This paper introduces a novel open dataset that tackles the burned area delineation problem, a binary segmentation problem applied to satellite imagery. The presented resource consists of pre- and post-fire Sentinel-2 L2A acquisitions of California forest fires that took place starting in 2015. Raster annotations were generated from the data released by California's Department of Forestry and Fire Protection. Moreover, in conjunction with the dataset, we release three different baselines based on spectral indexes analyses, SegFormer, and U-Net models.</li>
</ul>

<h3>Title: Tempo: Confidentiality Preservation in Cloud-Based Neural Network  Training</h3>
<ul>
<li><strong>Authors: </strong>Rongwu Xu, Zhixuan Fang</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.11531">https://arxiv.org/abs/2401.11531</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.11531">https://arxiv.org/pdf/2401.11531</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.11531]] Tempo: Confidentiality Preservation in Cloud-Based Neural Network  Training(https://arxiv.org/abs/2401.11531)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, protect, attack</a></li>
<li><strong>Abstract: </strong>Cloud deep learning platforms provide cost-effective deep neural network (DNN) training for customers who lack computation resources. However, cloud systems are often untrustworthy and vulnerable to attackers, leading to growing concerns about model privacy. Recently, researchers have sought to protect data privacy in deep learning by leveraging CPU trusted execution environments (TEEs), which minimize the use of cryptography, but existing works failed to simultaneously utilize the computational resources of GPUs to assist in training and prevent model leakage. This paper presents Tempo, the first cloud-based deep learning system that cooperates with TEE and distributed GPUs for efficient DNN training with model confidentiality preserved. To tackle the challenge of preserving privacy while offloading linear algebraic operations from TEE to GPUs for efficient batch computation, we introduce a customized permutation-based obfuscation algorithm to blind both inputs and model parameters. An optimization mechanism that reduces encryption operations is proposed for faster weight updates during backpropagation to speed up training. We implement Tempo and evaluate it with both training and inference for two prevalent DNNs. Empirical results indicate that Tempo outperforms baselines and offers sufficient privacy protection.</li>
</ul>

<h3>Title: How Robust Are Energy-Based Models Trained With Equilibrium Propagation?</h3>
<ul>
<li><strong>Authors: </strong>Siddharth Mansingh, Michal Kucer, Garrett Kenyon, Juston Moore, Michael Teti</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.11543">https://arxiv.org/abs/2401.11543</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.11543">https://arxiv.org/pdf/2401.11543</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.11543]] How Robust Are Energy-Based Models Trained With Equilibrium Propagation?(https://arxiv.org/abs/2401.11543)</code><input type="text"></li>
<li><strong>Keywords: </strong>defense, attack, robust, transformer</a></li>
<li><strong>Abstract: </strong>Deep neural networks (DNNs) are easily fooled by adversarial perturbations that are imperceptible to humans. Adversarial training, a process where adversarial examples are added to the training set, is the current state-of-the-art defense against adversarial attacks, but it lowers the model's accuracy on clean inputs, is computationally expensive, and offers less robustness to natural noise. In contrast, energy-based models (EBMs), which were designed for efficient implementation in neuromorphic hardware and physical systems, incorporate feedback connections from each layer to the previous layer, yielding a recurrent, deep-attractor architecture which we hypothesize should make them naturally robust. Our work is the first to explore the robustness of EBMs to both natural corruptions and adversarial attacks, which we do using the CIFAR-10 and CIFAR-100 datasets. We demonstrate that EBMs are more robust than transformers and display comparable robustness to adversarially-trained DNNs on gradient-based (white-box) attacks, query-based (black-box) attacks, and natural perturbations without sacrificing clean accuracy, and without the need for adversarial training or additional training techniques.</li>
</ul>

<h3>Title: Understanding the Security Risks of Decentralized Exchanges by  Uncovering Unfair Trades in the Wild</h3>
<ul>
<li><strong>Authors: </strong>Jiaqi Chen, Yibo Wang, Yuxuan Zhou, Wanning Ding, Yuzhe Tang, XiaoFeng Wang, Kai Li</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.11547">https://arxiv.org/abs/2401.11547</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.11547">https://arxiv.org/pdf/2401.11547</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.11547]] Understanding the Security Risks of Decentralized Exchanges by  Uncovering Unfair Trades in the Wild(https://arxiv.org/abs/2401.11547)</code><input type="text"></li>
<li><strong>Keywords: </strong>secure, security, fair</a></li>
<li><strong>Abstract: </strong>DEX, or decentralized exchange, is a prominent class of decentralized finance (DeFi) applications on blockchains, attracting a total locked value worth tens of billions of USD today. This paper presents the first large-scale empirical study that uncovers unfair trades on popular DEX services on Ethereum and Binance Smart Chain (BSC). By joining and analyzing 60 million transactions, we find 671,400 unfair trades on all six measured DEXes, including Uniswap, Balancer, and Curve. Out of these unfair trades, we attribute 55,000 instances, with high confidence, to token thefts that cause a value loss of more than 3.88 million USD. Furthermore, the measurement study uncovers previously unknown causes of extractable value and real-world adaptive strategies to these causes. Finally, we propose countermeasures to redesign secure DEX protocols and to harden deployed services against the discovered security risks.</li>
</ul>

<h3>Title: Differential Privacy in Hierarchical Federated Learning: A Formal  Analysis and Evaluation</h3>
<ul>
<li><strong>Authors: </strong>Frank Po-Chen Lin, Christopher Brinton</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CR, cs.DC</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.11592">https://arxiv.org/abs/2401.11592</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.11592">https://arxiv.org/pdf/2401.11592</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.11592]] Differential Privacy in Hierarchical Federated Learning: A Formal  Analysis and Evaluation(https://arxiv.org/abs/2401.11592)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, federate</a></li>
<li><strong>Abstract: </strong>While federated learning (FL) eliminates the transmission of raw data over a network, it is still vulnerable to privacy breaches from the communicated model parameters. In this work, we formalize Differentially Private Hierarchical Federated Learning (DP-HFL), a DP-enhanced FL methodology that seeks to improve the privacy-utility tradeoff inherent in FL. Building upon recent proposals for Hierarchical Differential Privacy (HDP), one of the key concepts of DP-HFL is adapting DP noise injection at different layers of an established FL hierarchy -- edge devices, edge servers, and cloud servers -- according to the trust models within particular subnetworks. We conduct a comprehensive analysis of the convergence behavior of DP-HFL, revealing conditions on parameter tuning under which the model training process converges sublinearly to a stationarity gap, with this gap depending on the network hierarchy, trust model, and target privacy level. Subsequent numerical evaluations demonstrate that DP-HFL obtains substantial improvements in convergence speed over baselines for different privacy budgets, and validate the impact of network configuration on training.</li>
</ul>

<h3>Title: TetraLoss: Improving the Robustness of Face Recognition against Morphing  Attacks</h3>
<ul>
<li><strong>Authors: </strong>Mathias Ibsen, Lázaro J. González-Soler, Christian Rathgeb, Christoph Busch</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.11598">https://arxiv.org/abs/2401.11598</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.11598">https://arxiv.org/pdf/2401.11598</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.11598]] TetraLoss: Improving the Robustness of Face Recognition against Morphing  Attacks(https://arxiv.org/abs/2401.11598)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, attack, robust, biometric</a></li>
<li><strong>Abstract: </strong>Face recognition systems are widely deployed in high-security applications such as for biometric verification at border controls. Despite their high accuracy on pristine data, it is well-known that digital manipulations, such as face morphing, pose a security threat to face recognition systems. Malicious actors can exploit the facilities offered by the identity document issuance process to obtain identity documents containing morphed images. Thus, subjects who contributed to the creation of the morphed image can with high probability use the identity document to bypass automated face recognition systems. In recent years, no-reference (i.e., single image) and differential morphing attack detectors have been proposed to tackle this risk. These systems are typically evaluated in isolation from the face recognition system that they have to operate jointly with and do not consider the face recognition process. Contrary to most existing works, we present a novel method for adapting deep learning-based face recognition systems to be more robust against face morphing attacks. To this end, we introduce TetraLoss, a novel loss function that learns to separate morphed face images from its contributing subjects in the embedding space while still preserving high biometric verification performance. In a comprehensive evaluation, we show that the proposed method can significantly enhance the original system while also significantly outperforming other tested baseline methods.</li>
</ul>

<h3>Title: Reducing Usefulness of Stolen Credentials in SSO Contexts</h3>
<ul>
<li><strong>Authors: </strong>Sam Hays, Michael Sandborn, Dr. Jules White</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.11599">https://arxiv.org/abs/2401.11599</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.11599">https://arxiv.org/pdf/2401.11599</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.11599]] Reducing Usefulness of Stolen Credentials in SSO Contexts(https://arxiv.org/abs/2401.11599)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, protect, attack</a></li>
<li><strong>Abstract: </strong>Approximately 61% of cyber attacks involve adversaries in possession of valid credentials. Attackers acquire credentials through various means, including phishing, dark web data drops, password reuse, etc. Multi-factor authentication (MFA) helps to thwart attacks that use valid credentials, but attackers still commonly breach systems by tricking users into accepting MFA step up requests through techniques, such as ``MFA Bombing'', where multiple requests are sent to a user until they accept one. Currently, there are several solutions to this problem, each with varying levels of security and increasing invasiveness on user devices. This paper proposes a token-based enrollment architecture that is less invasive to user devices than mobile device management, but still offers strong protection against use of stolen credentials and MFA attacks.</li>
</ul>

<h3>Title: Robust Evaluation Measures for Evaluating Social Biases in Masked  Language Models</h3>
<ul>
<li><strong>Authors: </strong>Yang Liu</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.11601">https://arxiv.org/abs/2401.11601</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.11601">https://arxiv.org/pdf/2401.11601</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.11601]] Robust Evaluation Measures for Evaluating Social Biases in Masked  Language Models(https://arxiv.org/abs/2401.11601)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Many evaluation measures are used to evaluate social biases in masked language models (MLMs). However, we find that these previously proposed evaluation measures are lacking robustness in scenarios with limited datasets. This is because these measures are obtained by comparing the pseudo-log-likelihood (PLL) scores of the stereotypical and anti-stereotypical samples using an indicator function. The disadvantage is the limited mining of the PLL score sets without capturing its distributional information. In this paper, we represent a PLL score set as a Gaussian distribution and use Kullback Leibler (KL) divergence and Jensen Shannon (JS) divergence to construct evaluation measures for the distributions of stereotypical and anti-stereotypical PLL scores. Experimental results on the publicly available datasets StereoSet (SS) and CrowS-Pairs (CP) show that our proposed measures are significantly more robust and interpretable than those proposed previously.</li>
</ul>

<h3>Title: Scalable High-Resolution Pixel-Space Image Synthesis with Hourglass  Diffusion Transformers</h3>
<ul>
<li><strong>Authors: </strong>Katherine Crowson, Stefan Andreas Baumann, Alex Birch, Tanishq Mathew Abraham, Daniel Z. Kaplan, Enrico Shippole</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.11605">https://arxiv.org/abs/2401.11605</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.11605">https://arxiv.org/pdf/2401.11605</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.11605]] Scalable High-Resolution Pixel-Space Image Synthesis with Hourglass  Diffusion Transformers(https://arxiv.org/abs/2401.11605)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, transformer, generative</a></li>
<li><strong>Abstract: </strong>We present the Hourglass Diffusion Transformer (HDiT), an image generative model that exhibits linear scaling with pixel count, supporting training at high-resolution (e.g. $1024 \times 1024$) directly in pixel-space. Building on the Transformer architecture, which is known to scale to billions of parameters, it bridges the gap between the efficiency of convolutional U-Nets and the scalability of Transformers. HDiT trains successfully without typical high-resolution training techniques such as multiscale architectures, latent autoencoders or self-conditioning. We demonstrate that HDiT performs competitively with existing models on ImageNet $256^2$, and sets a new state-of-the-art for diffusion models on FFHQ-$1024^2$.</li>
</ul>

<h3>Title: Graph Edits for Counterfactual Explanations: A Unified GNN Approach</h3>
<ul>
<li><strong>Authors: </strong>Nikolaos Chaidos, Angeliki Dimitriou, Maria Lymperaiou, Giorgos Stamou</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.11609">https://arxiv.org/abs/2401.11609</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.11609">https://arxiv.org/pdf/2401.11609</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.11609]] Graph Edits for Counterfactual Explanations: A Unified GNN Approach(https://arxiv.org/abs/2401.11609)</code><input type="text"></li>
<li><strong>Keywords: </strong>explainability</a></li>
<li><strong>Abstract: </strong>Counterfactuals have been established as a popular explainability technique which leverages a set of minimal edits to alter the prediction of a classifier. When considering conceptual counterfactuals, the edits requested should correspond to salient concepts present in the input data. At the same time, conceptual distances are defined by knowledge graphs, ensuring the optimality of conceptual edits. In this work, we extend previous endeavors on conceptual counterfactuals by introducing \textit{graph edits as counterfactual explanations}: should we represent input data as graphs, which is the shortest graph edit path that results in an alternative classification label as provided by a black-box classifier?</li>
</ul>

<h3>Title: A Survey on African Computer Vision Datasets, Topics and Researchers</h3>
<ul>
<li><strong>Authors: </strong>Abdul-Hakeem Omotayo, Ashery Mbilinyi, Lukman Ismaila, Houcemeddine Turki, Mahmoud Abdien, Karim Gamal, Idriss Tondji, Yvan Pimi, Naome A. Etori, Marwa M. Matar, Clifford Broni-Bediako, Abigail Oppong, Mai Gamal, Eman Ehab, Gbetondji Dovonon, Zainab Akinjobi, Daniel Ajisafe, Oluwabukola G. Adegboro, Mennatullah Siam</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.11617">https://arxiv.org/abs/2401.11617</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.11617">https://arxiv.org/pdf/2401.11617</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.11617]] A Survey on African Computer Vision Datasets, Topics and Researchers(https://arxiv.org/abs/2401.11617)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model, segmentation</a></li>
<li><strong>Abstract: </strong>Computer vision encompasses a range of tasks such as object detection, semantic segmentation, and 3D reconstruction. Despite its relevance to African communities, research in this field within Africa represents only 0.06% of top-tier publications over the past decade. This study undertakes a thorough analysis of 63,000 Scopus-indexed computer vision publications from Africa, spanning from 2012 to 2022. The aim is to provide a survey of African computer vision topics, datasets and researchers. A key aspect of our study is the identification and categorization of African Computer Vision datasets using large language models that automatically parse abstracts of these publications. We also provide a compilation of unofficial African Computer Vision datasets distributed through challenges or data hosting platforms, and provide a full taxonomy of dataset categories. Our survey also pinpoints computer vision topics trends specific to different African regions, indicating their unique focus areas. Additionally, we carried out an extensive survey to capture the views of African researchers on the current state of computer vision research in the continent and the structural barriers they believe need urgent attention. In conclusion, this study catalogs and categorizes Computer Vision datasets and topics contributed or initiated by African institutions and identifies barriers to publishing in top-tier Computer Vision venues. This survey underscores the importance of encouraging African researchers and institutions in advancing computer vision research in the continent. It also stresses on the need for research topics to be more aligned with the needs of African communities.</li>
</ul>

<h3>Title: In-context Learning with Retrieved Demonstrations for Language Models: A  Survey</h3>
<ul>
<li><strong>Authors: </strong>an Luo, Xin Xu, Yue Liu, Panupong Pasupat, Mehran Kazemi</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.IR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.11624">https://arxiv.org/abs/2401.11624</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.11624">https://arxiv.org/pdf/2401.11624</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.11624]] In-context Learning with Retrieved Demonstrations for Language Models: A  Survey(https://arxiv.org/abs/2401.11624)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Language models, especially pre-trained large language models, have showcased remarkable abilities as few-shot in-context learners (ICL), adept at adapting to new tasks with just a few demonstrations in the input context. However, the model's ability to perform ICL is sensitive to the choice of the few-shot demonstrations. Instead of using a fixed set of demonstrations, one recent development is to retrieve demonstrations tailored to each input query. The implementation of demonstration retrieval is relatively straightforward, leveraging existing databases and retrieval systems. This not only improves the efficiency and scalability of the learning process but also has been shown to reduce biases inherent in manual example selection. In light of the encouraging results and growing research in ICL with retrieved demonstrations, we conduct an extensive review of studies in this area. In this survey, we discuss and compare different design choices for retrieval models, retrieval training procedures, and inference algorithms.</li>
</ul>

<h3>Title: Freely Long-Thinking Transformer (FraiLT)</h3>
<ul>
<li><strong>Authors: </strong>Akbay Tabak</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.11626">https://arxiv.org/abs/2401.11626</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.11626">https://arxiv.org/pdf/2401.11626</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.11626]] Freely Long-Thinking Transformer (FraiLT)(https://arxiv.org/abs/2401.11626)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Freely Long-Thinking Transformer (FraiLT) is an improved transformer model designed to enhance processing capabilities without scaling up size. It utilizes a recursive approach, iterating over a subset of layers multiple times, and introduces iteration encodings to maintain awareness across these cycles. Iteration encoding allows FraiLT to achieve the interpretive depth of larger models in a compact form. When evaluated on a synthetic story dataset, FraiLT outperformed larger models, showcasing its ability to deliver high-quality performance while reducing memory demands. This model represents a step forward towards more efficient and accessible language models.</li>
</ul>

<h3>Title: Tight Verification of Probabilistic Robustness in Bayesian Neural  Networks</h3>
<ul>
<li><strong>Authors: </strong>Ben Batten, Mehran Hosseini, Alessio Lomuscio</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.FL, cs.LO</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.11627">https://arxiv.org/abs/2401.11627</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.11627">https://arxiv.org/pdf/2401.11627</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.11627]] Tight Verification of Probabilistic Robustness in Bayesian Neural  Networks(https://arxiv.org/abs/2401.11627)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>We introduce two algorithms for computing tight guarantees on the probabilistic robustness of Bayesian Neural Networks (BNNs). Computing robustness guarantees for BNNs is a significantly more challenging task than verifying the robustness of standard Neural Networks (NNs) because it requires searching the parameters' space for safe weights. Moreover, tight and complete approaches for the verification of standard NNs, such as those based on Mixed-Integer Linear Programming (MILP), cannot be directly used for the verification of BNNs because of the polynomial terms resulting from the consecutive multiplication of variables encoding the weights. Our algorithms efficiently and effectively search the parameters' space for safe weights by using iterative expansion and the network's gradient and can be used with any verification algorithm of choice for BNNs. In addition to proving that our algorithms compute tighter bounds than the SoA, we also evaluate our algorithms against the SoA on standard benchmarks, such as MNIST and CIFAR10, showing that our algorithms compute bounds up to 40% tighter than the SoA.</li>
</ul>

<h3>Title: Reframing Offline Reinforcement Learning as a Regression Problem</h3>
<ul>
<li><strong>Authors: </strong>Prajwal Koirala, Cody Fleming</a></li>
<li><strong>Subjects: </strong>cs.LG, eess.SY</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.11630">https://arxiv.org/abs/2401.11630</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.11630">https://arxiv.org/pdf/2401.11630</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.11630]] Reframing Offline Reinforcement Learning as a Regression Problem(https://arxiv.org/abs/2401.11630)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>The study proposes the reformulation of offline reinforcement learning as a regression problem that can be solved with decision trees. Aiming to predict actions based on input states, return-to-go (RTG), and timestep information, we observe that with gradient-boosted trees, the agent training and inference are very fast, the former taking less than a minute. Despite the simplification inherent in this reformulated problem, our agent demonstrates performance that is at least on par with established methods. This assertion is validated by testing it across standard datasets associated with D4RL Gym-MuJoCo tasks. We further discuss the agent's ability to generalize by testing it on two extreme cases, how it learns to model the return distributions effectively even with highly skewed expert datasets, and how it exhibits robust performance in scenarios with sparse/delayed rewards.</li>
</ul>

<h3>Title: Revolutionizing Finance with LLMs: An Overview of Applications and  Insights</h3>
<ul>
<li><strong>Authors: </strong>Huaqin Zhao, Zhengliang Liu, Zihao Wu, Yiwei Li, Tianze Yang, Peng Shu, Shaochen Xu, Haixing Dai, Lin Zhao, Gengchen Mai, Ninghao Liu, Tianming Liu</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.11641">https://arxiv.org/abs/2401.11641</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.11641">https://arxiv.org/pdf/2401.11641</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.11641]] Revolutionizing Finance with LLMs: An Overview of Applications and  Insights(https://arxiv.org/abs/2401.11641)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer, large language model</a></li>
<li><strong>Abstract: </strong>In recent years, Large Language Models (LLMs) like ChatGPT have seen considerable advancements and have been applied in diverse fields. Built on the Transformer architecture, these models are trained on extensive datasets, enabling them to understand and generate human language effectively. In the financial domain, the deployment of LLMs is gaining momentum. These models are being utilized for automating financial report generation, forecasting market trends, analyzing investor sentiment, and offering personalized financial advice. Leveraging their natural language processing capabilities, LLMs can distill key insights from vast financial data, aiding institutions in making informed investment choices and enhancing both operational efficiency and customer satisfaction. In this study, we provide a comprehensive overview of the emerging integration of LLMs into various financial tasks. Additionally, we conducted holistic tests on multiple financial tasks through the combination of natural language instructions. Our findings show that GPT-4 effectively follow prompt instructions across various financial tasks. This survey and evaluation of LLMs in the financial domain aim to deepen the understanding of LLMs' current role in finance for both financial practitioners and LLM researchers, identify new research and application prospects, and highlight how these technologies can be leveraged to solve practical challenges in the finance industry.</li>
</ul>

<h3>Title: Friends Across Time: Multi-Scale Action Segmentation Transformer for  Surgical Phase Recognition</h3>
<ul>
<li><strong>Authors: </strong>Bokai Zhang, Jiayuan Meng, Bin Cheng, Dean Biskup, Svetlana Petculescu, Angela Chapman</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.RO</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.11644">https://arxiv.org/abs/2401.11644</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.11644">https://arxiv.org/pdf/2401.11644</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.11644]] Friends Across Time: Multi-Scale Action Segmentation Transformer for  Surgical Phase Recognition(https://arxiv.org/abs/2401.11644)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction, transformer, segmentation</a></li>
<li><strong>Abstract: </strong>Automatic surgical phase recognition is a core technology for modern operating rooms and online surgical video assessment platforms. Current state-of-the-art methods use both spatial and temporal information to tackle the surgical phase recognition task. Building on this idea, we propose the Multi-Scale Action Segmentation Transformer (MS-AST) for offline surgical phase recognition and the Multi-Scale Action Segmentation Causal Transformer (MS-ASCT) for online surgical phase recognition. We use ResNet50 or EfficientNetV2-M for spatial feature extraction. Our MS-AST and MS-ASCT can model temporal information at different scales with multi-scale temporal self-attention and multi-scale temporal cross-attention, which enhances the capture of temporal relationships between frames and segments. We demonstrate that our method can achieve 95.26% and 96.15% accuracy on the Cholec80 dataset for online and offline surgical phase recognition, respectively, which achieves new state-of-the-art results. Our method can also achieve state-of-the-art results on non-medical datasets in the video action segmentation domain.</li>
</ul>

<h3>Title: LW-FedSSL: Resource-efficient Layer-wise Federated Self-supervised  Learning</h3>
<ul>
<li><strong>Authors: </strong>Ye Lin Tun, Chu Myaet Thwal, Le Quang Huy, Minh N. H. Nguyen, Choong Seon Hong</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.11647">https://arxiv.org/abs/2401.11647</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.11647">https://arxiv.org/pdf/2401.11647</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.11647]] LW-FedSSL: Resource-efficient Layer-wise Federated Self-supervised  Learning(https://arxiv.org/abs/2401.11647)</code><input type="text"></li>
<li><strong>Keywords: </strong>federate</a></li>
<li><strong>Abstract: </strong>Many recent studies integrate federated learning (FL) with self-supervised learning (SSL) to take advantage of raw training data distributed across edge devices. However, edge devices often struggle with high computation and communication costs imposed by SSL and FL algorithms. To tackle this hindrance, we propose LW-FedSSL, a layer-wise federated self-supervised learning approach that allows edge devices to incrementally train one layer of the model at a time. LW-FedSSL comprises server-side calibration and representation alignment mechanisms to maintain comparable performance with end-to-end FedSSL while significantly lowering clients' resource requirements. The server-side calibration mechanism takes advantage of the resource-rich server in an FL environment to assist in global model training. Meanwhile, the representation alignment mechanism encourages closeness between representations of FL local models and those of the global model. Our experiments show that LW-FedSSL has a $3.3 \times$ lower memory requirement and a $3.2 \times$ cheaper communication cost than its end-to-end counterpart. We also explore a progressive training strategy called Prog-FedSSL that outperforms end-to-end training with a similar memory requirement and a $1.8 \times$ cheaper communication cost.</li>
</ul>

<h3>Title: M2-CLIP: A Multimodal, Multi-task Adapting Framework for Video Action  Recognition</h3>
<ul>
<li><strong>Authors: </strong>Mengmeng Wang, Jiazheng Xing, Boyuan Jiang, Jun Chen, Jianbiao Mei, Xingxing Zuo, Guang Dai, Jingdong Wang, Yong Liu</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.11649">https://arxiv.org/abs/2401.11649</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.11649">https://arxiv.org/pdf/2401.11649</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.11649]] M2-CLIP: A Multimodal, Multi-task Adapting Framework for Video Action  Recognition(https://arxiv.org/abs/2401.11649)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Recently, the rise of large-scale vision-language pretrained models like CLIP, coupled with the technology of Parameter-Efficient FineTuning (PEFT), has captured substantial attraction in video action recognition. Nevertheless, prevailing approaches tend to prioritize strong supervised performance at the expense of compromising the models' generalization capabilities during transfer. In this paper, we introduce a novel Multimodal, Multi-task CLIP adapting framework named \name to address these challenges, preserving both high supervised performance and robust transferability. Firstly, to enhance the individual modality architectures, we introduce multimodal adapters to both the visual and text branches. Specifically, we design a novel visual TED-Adapter, that performs global Temporal Enhancement and local temporal Difference modeling to improve the temporal representation capabilities of the visual encoder. Moreover, we adopt text encoder adapters to strengthen the learning of semantic label information. Secondly, we design a multi-task decoder with a rich set of supervisory signals to adeptly satisfy the need for strong supervised performance and generalization within a multimodal framework. Experimental results validate the efficacy of our approach, demonstrating exceptional performance in supervised learning while maintaining strong generalization in zero-shot scenarios.</li>
</ul>

<h3>Title: OnDev-LCT: On-Device Lightweight Convolutional Transformers towards  federated learning</h3>
<ul>
<li><strong>Authors: </strong>Chu Myaet Thwal, Minh N.H. Nguyen, Ye Lin Tun, Seong Tae Kim, My T. Thai, Choong Seon Hong</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.11652">https://arxiv.org/abs/2401.11652</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.11652">https://arxiv.org/pdf/2401.11652</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.11652]] OnDev-LCT: On-Device Lightweight Convolutional Transformers towards  federated learning(https://arxiv.org/abs/2401.11652)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, federate, transformer</a></li>
<li><strong>Abstract: </strong>Federated learning (FL) has emerged as a promising approach to collaboratively train machine learning models across multiple edge devices while preserving privacy. The success of FL hinges on the efficiency of participating models and their ability to handle the unique challenges of distributed learning. While several variants of Vision Transformer (ViT) have shown great potential as alternatives to modern convolutional neural networks (CNNs) for centralized training, the unprecedented size and higher computational demands hinder their deployment on resource-constrained edge devices, challenging their widespread application in FL. Since client devices in FL typically have limited computing resources and communication bandwidth, models intended for such devices must strike a balance between model size, computational efficiency, and the ability to adapt to the diverse and non-IID data distributions encountered in FL. To address these challenges, we propose OnDev-LCT: Lightweight Convolutional Transformers for On-Device vision tasks with limited training data and resources. Our models incorporate image-specific inductive biases through the LCT tokenizer by leveraging efficient depthwise separable convolutions in residual linear bottleneck blocks to extract local features, while the multi-head self-attention (MHSA) mechanism in the LCT encoder implicitly facilitates capturing global representations of images. Extensive experiments on benchmark image datasets indicate that our models outperform existing lightweight vision models while having fewer parameters and lower computational demands, making them suitable for FL scenarios with data heterogeneity and communication bottlenecks.</li>
</ul>

<h3>Title: Differentiable Tree Search in Latent State Space</h3>
<ul>
<li><strong>Authors: </strong>Dixant Mittal, Wee Sun Lee</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.11660">https://arxiv.org/abs/2401.11660</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.11660">https://arxiv.org/pdf/2401.11660</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.11660]] Differentiable Tree Search in Latent State Space(https://arxiv.org/abs/2401.11660)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>In decision-making problems with limited training data, policy functions approximated using deep neural networks often exhibit suboptimal performance. An alternative approach involves learning a world model from the limited data and determining actions through online search. However, the performance is adversely affected by compounding errors arising from inaccuracies in the learnt world model. While methods like TreeQN have attempted to address these inaccuracies by incorporating algorithmic structural biases into their architectures, the biases they introduce are often weak and insufficient for complex decision-making tasks. In this work, we introduce Differentiable Tree Search (DTS), a novel neural network architecture that significantly strengthens the inductive bias by embedding the algorithmic structure of a best-first online search algorithm. DTS employs a learnt world model to conduct a fully differentiable online search in latent state space. The world model is jointly optimised with the search algorithm, enabling the learning of a robust world model and mitigating the effect of model inaccuracies. We address potential Q-function discontinuities arising from naive incorporation of best-first search by adopting a stochastic tree expansion policy, formulating search tree expansion as a decision-making task, and introducing an effective variance reduction technique for the gradient computation. We evaluate DTS in an offline-RL setting with a limited training data scenario on Procgen games and grid navigation task, and demonstrate that DTS outperforms popular model-free and model-based baselines.</li>
</ul>

<h3>Title: Zero-Space Cost Fault Tolerance for Transformer-based Language Models on  ReRAM</h3>
<ul>
<li><strong>Authors: </strong>Bingbing Li, Geng Yuan, Zigeng Wang, Shaoyi Huang, Hongwu Peng, Payman Behnam, Wujie Wen, Hang Liu, Caiwen Ding</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.AR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.11664">https://arxiv.org/abs/2401.11664</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.11664">https://arxiv.org/pdf/2401.11664</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.11664]] Zero-Space Cost Fault Tolerance for Transformer-based Language Models on  ReRAM(https://arxiv.org/abs/2401.11664)</code><input type="text"></li>
<li><strong>Keywords: </strong>protect, robust, transformer</a></li>
<li><strong>Abstract: </strong>Resistive Random Access Memory (ReRAM) has emerged as a promising platform for deep neural networks (DNNs) due to its support for parallel in-situ matrix-vector multiplication. However, hardware failures, such as stuck-at-fault defects, can result in significant prediction errors during model inference. While additional crossbars can be used to address these failures, they come with storage overhead and are not efficient in terms of space, energy, and cost. In this paper, we propose a fault protection mechanism that incurs zero space cost. Our approach includes: 1) differentiable structure pruning of rows and columns to reduce model redundancy, 2) weight duplication and voting for robust output, and 3) embedding duplicated most significant bits (MSBs) into the model weight. We evaluate our method on nine tasks of the GLUE benchmark with the BERT model, and experimental results prove its effectiveness.</li>
</ul>

<h3>Title: P2DT: Mitigating Forgetting in task-incremental Learning with  progressive prompt Decision Transformer</h3>
<ul>
<li><strong>Authors: </strong>Zhiyuan Wang, Xiaoyang Qu, Jing Xiao, Bokui Chen, Jianzong Wang</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.11666">https://arxiv.org/abs/2401.11666</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.11666">https://arxiv.org/pdf/2401.11666</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.11666]] P2DT: Mitigating Forgetting in task-incremental Learning with  progressive prompt Decision Transformer(https://arxiv.org/abs/2401.11666)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Catastrophic forgetting poses a substantial challenge for managing intelligent agents controlled by a large model, causing performance degradation when these agents face new tasks. In our work, we propose a novel solution - the Progressive Prompt Decision Transformer (P2DT). This method enhances a transformer-based model by dynamically appending decision tokens during new task training, thus fostering task-specific policies. Our approach mitigates forgetting in continual and offline reinforcement learning scenarios. Moreover, P2DT leverages trajectories collected via traditional reinforcement learning from all tasks and generates new task-specific tokens during training, thereby retaining knowledge from previous studies. Preliminary results demonstrate that our model effectively alleviates catastrophic forgetting and scales well with increasing task environments.</li>
</ul>

<h3>Title: An Improved Grey Wolf Optimization Algorithm for Heart Disease  Prediction</h3>
<ul>
<li><strong>Authors: </strong>Sihan Niu, Yifan Zhou, Zhikai Li, Shuyao Huang, Yujun Zhou</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.NE</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.11669">https://arxiv.org/abs/2401.11669</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.11669">https://arxiv.org/pdf/2401.11669</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.11669]] An Improved Grey Wolf Optimization Algorithm for Heart Disease  Prediction(https://arxiv.org/abs/2401.11669)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, interpretability</a></li>
<li><strong>Abstract: </strong>This paper presents a unique solution to challenges in medical image processing by incorporating an adaptive curve grey wolf optimization (ACGWO) algorithm into neural network backpropagation. Neural networks show potential in medical data but suffer from issues like overfitting and lack of interpretability due to imbalanced and scarce data. Traditional Gray Wolf Optimization (GWO) also has its drawbacks, such as a lack of population diversity and premature convergence. This paper addresses these problems by introducing an adaptive algorithm, enhancing the standard GWO with a sigmoid function. This algorithm was extensively compared to four leading algorithms using six well-known test functions, outperforming them effectively. Moreover, by utilizing the ACGWO, we increase the robustness and generalization of the neural network, resulting in more interpretable predictions. Applied to the publicly accessible Cleveland Heart Disease dataset, our technique surpasses ten other methods, achieving 86.8% accuracy, indicating its potential for efficient heart disease prediction in the clinical setting.</li>
</ul>

<h3>Title: MVSFormer++: Revealing the Devil in Transformer's Details for Multi-View  Stereo</h3>
<ul>
<li><strong>Authors: </strong>Chenjie Cao, Xinlin Ren, Yanwei Fu</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.11673">https://arxiv.org/abs/2401.11673</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.11673">https://arxiv.org/pdf/2401.11673</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.11673]] MVSFormer++: Revealing the Devil in Transformer's Details for Multi-View  Stereo(https://arxiv.org/abs/2401.11673)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Recent advancements in learning-based Multi-View Stereo (MVS) methods have prominently featured transformer-based models with attention mechanisms. However, existing approaches have not thoroughly investigated the profound influence of transformers on different MVS modules, resulting in limited depth estimation capabilities. In this paper, we introduce MVSFormer++, a method that prudently maximizes the inherent characteristics of attention to enhance various components of the MVS pipeline. Formally, our approach involves infusing cross-view information into the pre-trained DINOv2 model to facilitate MVS learning. Furthermore, we employ different attention mechanisms for the feature encoder and cost volume regularization, focusing on feature and spatial aggregations respectively. Additionally, we uncover that some design details would substantially impact the performance of transformer modules in MVS, including normalized 3D positional encoding, adaptive attention scaling, and the position of layer normalization. Comprehensive experiments on DTU, Tanks-and-Temples, BlendedMVS, and ETH3D validate the effectiveness of the proposed method. Notably, MVSFormer++ achieves state-of-the-art performance on the challenging DTU and Tanks-and-Temples benchmarks.</li>
</ul>

<h3>Title: Memory-Efficient Prompt Tuning for Incremental Histopathology  Classification</h3>
<ul>
<li><strong>Authors: </strong>Yu Zhu, Kang Li, Lequan Yu, Pheng-Ann Heng</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.11674">https://arxiv.org/abs/2401.11674</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.11674">https://arxiv.org/pdf/2401.11674</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.11674]] Memory-Efficient Prompt Tuning for Incremental Histopathology  Classification(https://arxiv.org/abs/2401.11674)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Recent studies have made remarkable progress in histopathology classification. Based on current successes, contemporary works proposed to further upgrade the model towards a more generalizable and robust direction through incrementally learning from the sequentially delivered domains. Unlike previous parameter isolation based approaches that usually demand massive computation resources during model updating, we present a memory-efficient prompt tuning framework to cultivate model generalization potential in economical memory cost. For each incoming domain, we reuse the existing parameters of the initial classification model and attach lightweight trainable prompts into it for customized tuning. Considering the domain heterogeneity, we perform decoupled prompt tuning, where we adopt a domain-specific prompt for each domain to independently investigate its distinctive characteristics, and one domain-invariant prompt shared across all domains to continually explore the common content embedding throughout time. All domain-specific prompts will be appended to the prompt bank and isolated from further changes to prevent forgetting the distinctive features of early-seen domains. While the domain-invariant prompt will be passed on and iteratively evolve by style-augmented prompt refining to improve model generalization capability over time. In specific, we construct a graph with existing prompts and build a style-augmented graph attention network to guide the domain-invariant prompt exploring the overlapped latent embedding among all delivered domains for more domain generic representations. We have extensively evaluated our framework with two histopathology tasks, i.e., breast cancer metastasis classification and epithelium-stroma tissue classification, where our approach yielded superior performance and memory efficiency over the competing methods.</li>
</ul>

<h3>Title: Parametric Matrix Models</h3>
<ul>
<li><strong>Authors: </strong>Patrick Cook, Danny Jammooa, Morten Hjorth-Jensen, Daniel D. Lee, Dean Lee</a></li>
<li><strong>Subjects: </strong>cs.LG, cond-mat.dis-nn, nucl-th, physics.comp-ph, quant-ph</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.11694">https://arxiv.org/abs/2401.11694</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.11694">https://arxiv.org/pdf/2401.11694</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.11694]] Parametric Matrix Models(https://arxiv.org/abs/2401.11694)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability</a></li>
<li><strong>Abstract: </strong>We present a general class of machine learning algorithms called parametric matrix models. Parametric matrix models are based on matrix equations, and the design is motivated by the efficiency of reduced basis methods for approximating solutions of parametric equations. The dependent variables can be defined implicitly or explicitly, and the equations may use algebraic, differential, or integral relations. Parametric matrix models can be trained with empirical data only, and no high-fidelity model calculations are needed. While originally designed for scientific computing, parametric matrix models are universal function approximators that can be applied to general machine learning problems. After introducing the underlying theory, we apply parametric matrix models to a series of different challenges that show their performance for a wide range of problems. For all the challenges tested here, parametric matrix models produce accurate results within a computational framework that allows for parameter extrapolation and interpretability.</li>
</ul>

<h3>Title: Admission Prediction in Undergraduate Applications: an Interpretable  Deep Learning Approach</h3>
<ul>
<li><strong>Authors: </strong>Amisha Priyadarshini, Barbara Martinez-Neda, Sergio Gago-Masague</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.11698">https://arxiv.org/abs/2401.11698</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.11698">https://arxiv.org/pdf/2401.11698</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.11698]] Admission Prediction in Undergraduate Applications: an Interpretable  Deep Learning Approach(https://arxiv.org/abs/2401.11698)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability</a></li>
<li><strong>Abstract: </strong>This article addresses the challenge of validating the admission committee's decisions for undergraduate admissions. In recent years, the traditional review process has struggled to handle the overwhelmingly large amount of applicants' data. Moreover, this traditional assessment often leads to human bias, which might result in discrimination among applicants. Although classical machine learning-based approaches exist that aim to verify the quantitative assessment made by the application reviewers, these methods lack scalability and suffer from performance issues when a large volume of data is in place. In this context, we propose deep learning-based classifiers, namely Feed-Forward and Input Convex neural networks, which overcome the challenges faced by the existing methods. Furthermore, we give additional insights into our model by incorporating an interpretability module, namely LIME. Our training and test datasets comprise applicants' data with a wide range of variables and information. Our models achieve higher accuracy compared to the best-performing traditional machine learning-based approach by a considerable margin of 3.03\%. Additionally, we show the sensitivity of different features and their relative impacts on the overall admission decision using the LIME technique.</li>
</ul>

<h3>Title: Mastering Text-to-Image Diffusion: Recaptioning, Planning, and  Generating with Multimodal LLMs</h3>
<ul>
<li><strong>Authors: </strong>Ling Yang, Zhaochen Yu, Chenlin Meng, Minkai Xu, Stefano Ermon, Bin Cui</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.11708">https://arxiv.org/abs/2401.11708</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.11708">https://arxiv.org/pdf/2401.11708</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.11708]] Mastering Text-to-Image Diffusion: Recaptioning, Planning, and  Generating with Multimodal LLMs(https://arxiv.org/abs/2401.11708)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>Diffusion models have exhibit exceptional performance in text-to-image generation and editing. However, existing methods often face challenges when handling complex text prompts that involve multiple objects with multiple attributes and relationships. In this paper, we propose a brand new training-free text-to-image generation/editing framework, namely Recaption, Plan and Generate (RPG), harnessing the powerful chain-of-thought reasoning ability of multimodal LLMs to enhance the compositionality of text-to-image diffusion models. Our approach employs the MLLM as a global planner to decompose the process of generating complex images into multiple simpler generation tasks within subregions. We propose complementary regional diffusion to enable region-wise compositional generation. Furthermore, we integrate text-guided image generation and editing within the proposed RPG in a closed-loop fashion, thereby enhancing generalization ability. Extensive experiments demonstrate our RPG outperforms state-of-the-art text-to-image diffusion models, including DALL-E 3 and SDXL, particularly in multi-category object composition and text-image semantic alignment. Notably, our RPG framework exhibits wide compatibility with various MLLM architectures (e.g., MiniGPT-4) and diffusion backbones (e.g., ControlNet). Our code is available at: https://github.com/YangLing0818/RPG-DiffusionMaster</li>
</ul>

<h3>Title: Medical Image Debiasing by Learning Adaptive Agreement from a Biased  Council</h3>
<ul>
<li><strong>Authors: </strong>Luyang Luo, Xin Huang, Minghao Wang, Zhuoyue Wan, Hao Chen</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.11713">https://arxiv.org/abs/2401.11713</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.11713">https://arxiv.org/pdf/2401.11713</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.11713]] Medical Image Debiasing by Learning Adaptive Agreement from a Biased  Council(https://arxiv.org/abs/2401.11713)</code><input type="text"></li>
<li><strong>Keywords: </strong>fair</a></li>
<li><strong>Abstract: </strong>Deep learning could be prone to learning shortcuts raised by dataset bias and result in inaccurate, unreliable, and unfair models, which impedes its adoption in real-world clinical applications. Despite its significance, there is a dearth of research in the medical image classification domain to address dataset bias. Furthermore, the bias labels are often agnostic, as identifying biases can be laborious and depend on post-hoc interpretation. This paper proposes learning Adaptive Agreement from a Biased Council (Ada-ABC), a debiasing framework that does not rely on explicit bias labels to tackle dataset bias in medical images. Ada-ABC develops a biased council consisting of multiple classifiers optimized with generalized cross entropy loss to learn the dataset bias. A debiasing model is then simultaneously trained under the guidance of the biased council. Specifically, the debiasing model is required to learn adaptive agreement with the biased council by agreeing on the correctly predicted samples and disagreeing on the wrongly predicted samples by the biased council. In this way, the debiasing model could learn the target attribute on the samples without spurious correlations while also avoiding ignoring the rich information in samples with spurious correlations. We theoretically demonstrated that the debiasing model could learn the target features when the biased model successfully captures dataset bias. Moreover, to our best knowledge, we constructed the first medical debiasing benchmark from four datasets containing seven different bias scenarios. Our extensive experiments practically showed that our proposed Ada-ABC outperformed competitive approaches, verifying its effectiveness in mitigating dataset bias for medical image classification. The codes and organized benchmark datasets will be made publicly available.</li>
</ul>

<h3>Title: MsSVT++: Mixed-scale Sparse Voxel Transformer with Center Voting for 3D  Object Detection</h3>
<ul>
<li><strong>Authors: </strong>Jianan Li, Shaocong Dong, Lihe Ding, Tingfa Xu</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.11718">https://arxiv.org/abs/2401.11718</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.11718">https://arxiv.org/pdf/2401.11718</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.11718]] MsSVT++: Mixed-scale Sparse Voxel Transformer with Center Voting for 3D  Object Detection(https://arxiv.org/abs/2401.11718)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Accurate 3D object detection in large-scale outdoor scenes, characterized by considerable variations in object scales, necessitates features rich in both long-range and fine-grained information. While recent detectors have utilized window-based transformers to model long-range dependencies, they tend to overlook fine-grained details. To bridge this gap, we propose MsSVT++, an innovative Mixed-scale Sparse Voxel Transformer that simultaneously captures both types of information through a divide-and-conquer approach. This approach involves explicitly dividing attention heads into multiple groups, each responsible for attending to information within a specific range. The outputs of these groups are subsequently merged to obtain final mixed-scale features. To mitigate the computational complexity associated with applying a window-based transformer in 3D voxel space, we introduce a novel Chessboard Sampling strategy and implement voxel sampling and gathering operations sparsely using a hash map. Moreover, an important challenge stems from the observation that non-empty voxels are primarily located on the surface of objects, which impedes the accurate estimation of bounding boxes. To overcome this challenge, we introduce a Center Voting module that integrates newly voted voxels enriched with mixed-scale contextual information towards the centers of the objects, thereby improving precise object localization. Extensive experiments demonstrate that our single-stage detector, built upon the foundation of MsSVT++, consistently delivers exceptional performance across diverse datasets.</li>
</ul>

<h3>Title: SFC: Shared Feature Calibration in Weakly Supervised Semantic  Segmentation</h3>
<ul>
<li><strong>Authors: </strong>Xinqiao Zhao, Feilong Tang, Xiaoyang Wang, Jimin Xiao</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.11719">https://arxiv.org/abs/2401.11719</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.11719">https://arxiv.org/pdf/2401.11719</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.11719]] SFC: Shared Feature Calibration in Weakly Supervised Semantic  Segmentation(https://arxiv.org/abs/2401.11719)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>Image-level weakly supervised semantic segmentation has received increasing attention due to its low annotation cost. Existing methods mainly rely on Class Activation Mapping (CAM) to obtain pseudo-labels for training semantic segmentation models. In this work, we are the first to demonstrate that long-tailed distribution in training data can cause the CAM calculated through classifier weights over-activated for head classes and under-activated for tail classes due to the shared features among head- and tail- classes. This degrades pseudo-label quality and further influences final semantic segmentation performance. To address this issue, we propose a Shared Feature Calibration (SFC) method for CAM generation. Specifically, we leverage the class prototypes that carry positive shared features and propose a Multi-Scaled Distribution-Weighted (MSDW) consistency loss for narrowing the gap between the CAMs generated through classifier weights and class prototypes during training. The MSDW loss counterbalances over-activation and under-activation by calibrating the shared features in head-/tail-class classifier weights. Experimental results show that our SFC significantly improves CAM boundaries and achieves new state-of-the-art performances. The project is available at https://github.com/Barrett-python/SFC.</li>
</ul>

<h3>Title: Graph Condensation: A Survey</h3>
<ul>
<li><strong>Authors: </strong>Xinyi Gao, Junliang Yu, Wei Jiang, Tong Chen, Wentao Zhang, Hongzhi Yin</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.11720">https://arxiv.org/abs/2401.11720</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.11720">https://arxiv.org/pdf/2401.11720</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.11720]] Graph Condensation: A Survey(https://arxiv.org/abs/2401.11720)</code><input type="text"></li>
<li><strong>Keywords: </strong>fair</a></li>
<li><strong>Abstract: </strong>The burgeoning volume of graph data poses significant challenges in storage, transmission, and particularly the training of graph neural networks (GNNs). To address these challenges, graph condensation (GC) has emerged as an innovative solution. GC focuses on synthesizing a compact yet highly representative graph, on which GNNs can achieve performance comparable to trained on the large original graph. The notable efficacy of GC and its broad prospects have garnered significant attention and spurred extensive research. This survey paper provides an up-to-date and systematic overview of GC, organizing existing research into four categories aligned with critical GC evaluation criteria: effectiveness, generalization, fairness, and efficiency. To facilitate an in-depth and comprehensive understanding of GC, we examine various methods under each category and thoroughly discuss two essential components within GC: optimization strategies and condensed graph generation. Additionally, we introduce the applications of GC in a variety of fields, and highlight the present challenges and novel insights in GC, promoting advancements in future research.</li>
</ul>

<h3>Title: Unraveling Attacks in Machine Learning-based IoT Ecosystems: A Survey  and the Open Libraries Behind Them</h3>
<ul>
<li><strong>Authors: </strong>Chao Liu, Boxi Chen, Wei Shao, Chris Zhang, Kelvin Wong, Yi Zhang</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.11723">https://arxiv.org/abs/2401.11723</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.11723">https://arxiv.org/pdf/2401.11723</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.11723]] Unraveling Attacks in Machine Learning-based IoT Ecosystems: A Survey  and the Open Libraries Behind Them(https://arxiv.org/abs/2401.11723)</code><input type="text"></li>
<li><strong>Keywords: </strong>secure, security, privacy, defense, attack, extraction, membership infer</a></li>
<li><strong>Abstract: </strong>The advent of the Internet of Things (IoT) has brought forth an era of unprecedented connectivity, with an estimated 80 billion smart devices expected to be in operation by the end of 2025. These devices facilitate a multitude of smart applications, enhancing the quality of life and efficiency across various domains. Machine Learning (ML) serves as a crucial technology, not only for analyzing IoT-generated data but also for diverse applications within the IoT ecosystem. For instance, ML finds utility in IoT device recognition, anomaly detection, and even in uncovering malicious activities. This paper embarks on a comprehensive exploration of the security threats arising from ML's integration into various facets of IoT, spanning various attack types including membership inference, adversarial evasion, reconstruction, property inference, model extraction, and poisoning attacks. Unlike previous studies, our work offers a holistic perspective, categorizing threats based on criteria such as adversary models, attack targets, and key security attributes (confidentiality, availability, and integrity). We delve into the underlying techniques of ML attacks in IoT environment, providing a critical evaluation of their mechanisms and impacts. Furthermore, our research thoroughly assesses 65 libraries, both author-contributed and third-party, evaluating their role in safeguarding model and data privacy. We emphasize the availability and usability of these libraries, aiming to arm the community with the necessary tools to bolster their defenses against the evolving threat landscape. Through our comprehensive review and analysis, this paper seeks to contribute to the ongoing discourse on ML-based IoT security, offering valuable insights and practical solutions to secure ML models and data in the rapidly expanding field of artificial intelligence in IoT.</li>
</ul>

<h3>Title: Augmenting Prototype Network with TransMix for Few-shot Hyperspectral  Image Classification</h3>
<ul>
<li><strong>Authors: </strong>Chun Liu, Longwei Yang, Dongmei Dong, Zheng Li, Wei Yang, Zhigang Han, Jiayao Wang</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.11724">https://arxiv.org/abs/2401.11724</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.11724">https://arxiv.org/pdf/2401.11724</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.11724]] Augmenting Prototype Network with TransMix for Few-shot Hyperspectral  Image Classification(https://arxiv.org/abs/2401.11724)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, transformer</a></li>
<li><strong>Abstract: </strong>Few-shot hyperspectral image classification aims to identify the classes of each pixel in the images by only marking few of these pixels. And in order to obtain the spatial-spectral joint features of each pixel, the fixed-size patches centering around each pixel are often used for classification. However, observing the classification results of existing methods, we found that boundary patches corresponding to the pixels which are located at the boundary of the objects in the hyperspectral images, are hard to classify. These boundary patchs are mixed with multi-class spectral information. Inspired by this, we propose to augment the prototype network with TransMix for few-shot hyperspectrial image classification(APNT). While taking the prototype network as the backbone, it adopts the transformer as feature extractor to learn the pixel-to-pixel relation and pay different attentions to different pixels. At the same time, instead of directly using the patches which are cut from the hyperspectral images for training, it randomly mixs up two patches to imitate the boundary patches and uses the synthetic patches to train the model, with the aim to enlarge the number of hard training samples and enhance their diversity. And by following the data agumentation technique TransMix, the attention returned by the transformer is also used to mix up the labels of two patches to generate better labels for synthetic patches. Compared with existing methods, the proposed method has demonstrated sate of the art performance and better robustness for few-shot hyperspectral image classification in our experiments.</li>
</ul>

<h3>Title: Speak It Out: Solving Symbol-Related Problems with Symbol-to-Language  Conversion for Language Models</h3>
<ul>
<li><strong>Authors: </strong>Yile Wang, Sijie Cheng, Zixin Sun, Peng Li, Yang Liu</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.11725">https://arxiv.org/abs/2401.11725</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.11725">https://arxiv.org/pdf/2401.11725</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.11725]] Speak It Out: Solving Symbol-Related Problems with Symbol-to-Language  Conversion for Language Models(https://arxiv.org/abs/2401.11725)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Symbols (or more broadly, non-natural language textual representations) such as numerical sequences, molecular formulas, and table delimiters widely exist, playing important roles in various tasks such as abstract reasoning, chemical property prediction, and table question answering. Despite the impressive natural language comprehension capabilities of large language models (LLMs), their reasoning abilities for symbols remain inadequate, which could attributed to the difference between symbol representations and general natural languages. We propose symbol-to-language (S2L), a tuning-free method that enables large language models to solve symbol-related problems with information expressed in natural language. Specifically, S2L first converts the symbols involved to language-based representations, which can be implemented by prompting LLMs or leveraging external tools, then these language-based representations are integrated into the original problem via direct substitution or concatenation, serving as useful input information for LLMs. We evaluate the S2L method using both API-based (GPT-4, ChatGPT) and open-source (OpenChat) models over eight symbol-related tasks, ranging from symbol-only abstract reasoning to sentiment analysis in social media. Experimental results show that S2L consistently leads to superior performance. For example, by employing S2L for GPT-4, there can be average significant improvements of +21.9% and +9.5% for subtasks in 1D-ARC and Dyck language, respectively. Codes and data are available at https://github.com/THUNLP-MT/symbol2language.</li>
</ul>

<h3>Title: Colorectal Polyp Segmentation in the Deep Learning Era: A Comprehensive  Survey</h3>
<ul>
<li><strong>Authors: </strong>Zhenyu Wu, Fengmao Lv, Chenglizhao Chen, Aimin Hao, Shuo Li</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.11734">https://arxiv.org/abs/2401.11734</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.11734">https://arxiv.org/pdf/2401.11734</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.11734]] Colorectal Polyp Segmentation in the Deep Learning Era: A Comprehensive  Survey(https://arxiv.org/abs/2401.11734)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>Colorectal polyp segmentation (CPS), an essential problem in medical image analysis, has garnered growing research attention. Recently, the deep learning-based model completely overwhelmed traditional methods in the field of CPS, and more and more deep CPS methods have emerged, bringing the CPS into the deep learning era. To help the researchers quickly grasp the main techniques, datasets, evaluation metrics, challenges, and trending of deep CPS, this paper presents a systematic and comprehensive review of deep-learning-based CPS methods from 2014 to 2023, a total of 115 technical papers. In particular, we first provide a comprehensive review of the current deep CPS with a novel taxonomy, including network architectures, level of supervision, and learning paradigm. More specifically, network architectures include eight subcategories, the level of supervision comprises six subcategories, and the learning paradigm encompasses 12 subcategories, totaling 26 subcategories. Then, we provided a comprehensive analysis the characteristics of each dataset, including the number of datasets, annotation types, image resolution, polyp size, contrast values, and polyp location. Following that, we summarized CPS's commonly used evaluation metrics and conducted a detailed analysis of 40 deep SOTA models, including out-of-distribution generalization and attribute-based performance analysis. Finally, we discussed deep learning-based CPS methods' main challenges and opportunities.</li>
</ul>

<h3>Title: zkLogin: Privacy-Preserving Blockchain Authentication with Existing  Credentials</h3>
<ul>
<li><strong>Authors: </strong>Foteini Baldimtsi, Konstantinos Kryptos Chalkias, Yan Ji, Jonas Lindstrøm, Deepak Maram, Ben Riva, Arnab Roy, Mahdi Sedaghat, Joy Wang</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.11735">https://arxiv.org/abs/2401.11735</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.11735">https://arxiv.org/pdf/2401.11735</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.11735]] zkLogin: Privacy-Preserving Blockchain Authentication with Existing  Credentials(https://arxiv.org/abs/2401.11735)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, privacy</a></li>
<li><strong>Abstract: </strong>For many users, a private key based wallet serves as the primary entry point to blockchains. Commonly recommended wallet authentication methods, such as mnemonics or hardware wallets, can be cumbersome. This difficulty in user onboarding has significantly hindered the adoption of blockchain-based applications. We develop zkLogin, a novel technique that leverages identity tokens issued by popular platforms (any OpenID Connect enabled platform e.g. Google, Facebook, etc.) to authenticate transactions. At the heart of zkLogin lies a signature scheme allowing the signer to \textit{sign using their existing OpenID accounts} and nothing else. This improves the user experience significantly as users do not need to remember a new secret and can reuse their existing accounts. zkLogin provides strong security and privacy guarantees. By design, zkLogin builds on top of the underlying platform's authentication mechanisms, and derives its security from there. Unlike prior related works however, zkLogin avoids the use of additional trusted parties (e.g., trusted hardware or oracles) for its security guarantees. zkLogin leverages zero-knowledge proofs (ZKP) to ensure that the link between a user's off-chain and on-chain identities is hidden, even from the platform itself. We have implemented and deployed zkLogin on the Sui blockchain as an alternative to traditional digital signature-based addresses. Due to the ease of web3 on-boarding just with social login, without requiring mnemonics, many hundreds of thousands zkLogin accounts have already been generated in various industries such as gaming, DeFi, direct payments, NFT collections, ride sharing, sports racing and many more.</li>
</ul>

<h3>Title: Attention on Personalized Clinical Decision Support System: Federated  Learning Approach</h3>
<ul>
<li><strong>Authors: </strong>Chu Myaet Thwal, Kyi Thar, Ye Lin Tun, Choong Seon Hong</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.11736">https://arxiv.org/abs/2401.11736</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.11736">https://arxiv.org/pdf/2401.11736</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.11736]] Attention on Personalized Clinical Decision Support System: Federated  Learning Approach(https://arxiv.org/abs/2401.11736)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, attack, federate</a></li>
<li><strong>Abstract: </strong>Health management has become a primary problem as new kinds of diseases and complex symptoms are introduced to a rapidly growing modern society. Building a better and smarter healthcare infrastructure is one of the ultimate goals of a smart city. To the best of our knowledge, neural network models are already employed to assist healthcare professionals in achieving this goal. Typically, training a neural network requires a rich amount of data but heterogeneous and vulnerable properties of clinical data introduce a challenge for the traditional centralized network. Moreover, adding new inputs to a medical database requires re-training an existing model from scratch. To tackle these challenges, we proposed a deep learning-based clinical decision support system trained and managed under a federated learning paradigm. We focused on a novel strategy to guarantee the safety of patient privacy and overcome the risk of cyberattacks while enabling large-scale clinical data mining. As a result, we can leverage rich clinical data for training each local neural network without the need for exchanging the confidential data of patients. Moreover, we implemented the proposed scheme as a sequence-to-sequence model architecture integrating the attention mechanism. Thus, our objective is to provide a personalized clinical decision support system with evolvable characteristics that can deliver accurate solutions and assist healthcare professionals in medical diagnosing.</li>
</ul>

<h3>Title: MetaSeg: Content-Aware Meta-Net for Omni-Supervised Semantic  Segmentation</h3>
<ul>
<li><strong>Authors: </strong>Shenwang Jiang, Jianan Li, Ying Wang, Wenxuan Wu, Jizhou Zhang, Bo Huang, Tingfa Xu</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.11738">https://arxiv.org/abs/2401.11738</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.11738">https://arxiv.org/pdf/2401.11738</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.11738]] MetaSeg: Content-Aware Meta-Net for Omni-Supervised Semantic  Segmentation(https://arxiv.org/abs/2401.11738)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>Noisy labels, inevitably existing in pseudo segmentation labels generated from weak object-level annotations, severely hampers model optimization for semantic segmentation. Previous works often rely on massive hand-crafted losses and carefully-tuned hyper-parameters to resist noise, suffering poor generalization capability and high model complexity. Inspired by recent advances in meta learning, we argue that rather than struggling to tolerate noise hidden behind clean labels passively, a more feasible solution would be to find out the noisy regions actively, so as to simply ignore them during model optimization. With this in mind, this work presents a novel meta learning based semantic segmentation method, MetaSeg, that comprises a primary content-aware meta-net (CAM-Net) to sever as a noise indicator for an arbitrary segmentation model counterpart. Specifically, CAM-Net learns to generate pixel-wise weights to suppress noisy regions with incorrect pseudo labels while highlighting clean ones by exploiting hybrid strengthened features from image content, providing straightforward and reliable guidance for optimizing the segmentation model. Moreover, to break the barrier of time-consuming training when applying meta learning to common large segmentation models, we further present a new decoupled training strategy that optimizes different model layers in a divide-and-conquer manner. Extensive experiments on object, medical, remote sensing and human segmentation shows that our method achieves superior performance, approaching that of fully supervised settings, which paves a new promising way for omni-supervised semantic segmentation.</li>
</ul>

<h3>Title: EmerDiff: Emerging Pixel-level Semantic Knowledge in Diffusion Models</h3>
<ul>
<li><strong>Authors: </strong>Koichi Namekata, Amirmojtaba Sabour, Sanja Fidler, Seung Wook Kim</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.11739">https://arxiv.org/abs/2401.11739</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.11739">https://arxiv.org/pdf/2401.11739</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.11739]] EmerDiff: Emerging Pixel-level Semantic Knowledge in Diffusion Models(https://arxiv.org/abs/2401.11739)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, segmentation</a></li>
<li><strong>Abstract: </strong>Diffusion models have recently received increasing research attention for their remarkable transfer abilities in semantic segmentation tasks. However, generating fine-grained segmentation masks with diffusion models often requires additional training on annotated datasets, leaving it unclear to what extent pre-trained diffusion models alone understand the semantic relations of their generated images. To address this question, we leverage the semantic knowledge extracted from Stable Diffusion (SD) and aim to develop an image segmentor capable of generating fine-grained segmentation maps without any additional training. The primary difficulty stems from the fact that semantically meaningful feature maps typically exist only in the spatially lower-dimensional layers, which poses a challenge in directly extracting pixel-level semantic relations from these feature maps. To overcome this issue, our framework identifies semantic correspondences between image pixels and spatial locations of low-dimensional feature maps by exploiting SD's generation process and utilizes them for constructing image-resolution segmentation maps. In extensive experiments, the produced segmentation maps are demonstrated to be well delineated and capture detailed parts of the images, indicating the existence of highly accurate pixel-level semantic knowledge in diffusion models.</li>
</ul>

<h3>Title: GI-PIP: Do We Require Impractical Auxiliary Dataset for Gradient  Inversion Attacks?</h3>
<ul>
<li><strong>Authors: </strong>Yu sun, Gaojian Xiong, Xianxun Yao, Kailang Ma, Jian Cui</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.11748">https://arxiv.org/abs/2401.11748</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.11748">https://arxiv.org/pdf/2401.11748</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.11748]] GI-PIP: Do We Require Impractical Auxiliary Dataset for Gradient  Inversion Attacks?(https://arxiv.org/abs/2401.11748)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack, federate</a></li>
<li><strong>Abstract: </strong>Deep gradient inversion attacks expose a serious threat to Federated Learning (FL) by accurately recovering private data from shared gradients. However, the state-of-the-art heavily relies on impractical assumptions to access excessive auxiliary data, which violates the basic data partitioning principle of FL. In this paper, a novel method, Gradient Inversion Attack using Practical Image Prior (GI-PIP), is proposed under a revised threat model. GI-PIP exploits anomaly detection models to capture the underlying distribution from fewer data, while GAN-based methods consume significant more data to synthesize images. The extracted distribution is then leveraged to regulate the attack process as Anomaly Score loss. Experimental results show that GI-PIP achieves a 16.12 dB PSNR recovery using only 3.8\% data of ImageNet, while GAN-based methods necessitate over 70\%. Moreover, GI-PIP exhibits superior capability on distribution generalization compared to GAN-based methods. Our approach significantly alleviates the auxiliary data requirement on both amount and distribution in gradient inversion attacks, hence posing more substantial threat to real-world FL.</li>
</ul>

<h3>Title: AdaFGL: A New Paradigm for Federated Node Classification with Topology  Heterogeneity</h3>
<ul>
<li><strong>Authors: </strong>Xunkai Li, Zhengyu Wu, Wentao Zhang, Henan Sun, Rong-Hua Li, Guoren Wang</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.DB, cs.SI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.11750">https://arxiv.org/abs/2401.11750</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.11750">https://arxiv.org/pdf/2401.11750</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.11750]] AdaFGL: A New Paradigm for Federated Node Classification with Topology  Heterogeneity(https://arxiv.org/abs/2401.11750)</code><input type="text"></li>
<li><strong>Keywords: </strong>federate</a></li>
<li><strong>Abstract: </strong>Recently, Federated Graph Learning (FGL) has attracted significant attention as a distributed framework based on graph neural networks, primarily due to its capability to break data silos. Existing FGL studies employ community split on the homophilous global graph by default to simulate federated semi-supervised node classification settings. Such a strategy assumes the consistency of topology between the multi-client subgraphs and the global graph, where connected nodes are highly likely to possess similar feature distributions and the same label. However, in real-world implementations, the varying perspectives of local data engineering result in various subgraph topologies, posing unique heterogeneity challenges in FGL. Unlike the well-known label Non-independent identical distribution (Non-iid) problems in federated learning, FGL heterogeneity essentially reveals the topological divergence among multiple clients, namely homophily or heterophily. To simulate and handle this unique challenge, we introduce the concept of structure Non-iid split and then present a new paradigm called \underline{Ada}ptive \underline{F}ederated \underline{G}raph \underline{L}earning (AdaFGL), a decoupled two-step personalized approach. To begin with, AdaFGL employs standard multi-client federated collaborative training to acquire the federated knowledge extractor by aggregating uploaded models in the final round at the server. Then, each client conducts personalized training based on the local subgraph and the federated knowledge extractor. Extensive experiments on the 12 graph benchmark datasets validate the superior performance of AdaFGL over state-of-the-art baselines. Specifically, in terms of test accuracy, our proposed AdaFGL outperforms baselines by significant margins of 3.24\% and 5.57\% on community split and structure Non-iid split, respectively.</li>
</ul>

<h3>Title: FedGTA: Topology-aware Averaging for Federated Graph Learning</h3>
<ul>
<li><strong>Authors: </strong>Xunkai Li, Zhengyu Wu, Wentao Zhang, Yinlin Zhu, Rong-Hua Li, Guoren Wang</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.DB, cs.SI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.11755">https://arxiv.org/abs/2401.11755</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.11755">https://arxiv.org/pdf/2401.11755</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.11755]] FedGTA: Topology-aware Averaging for Federated Graph Learning(https://arxiv.org/abs/2401.11755)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, federate</a></li>
<li><strong>Abstract: </strong>Federated Graph Learning (FGL) is a distributed machine learning paradigm that enables collaborative training on large-scale subgraphs across multiple local systems. Existing FGL studies fall into two categories: (i) FGL Optimization, which improves multi-client training in existing machine learning models; (ii) FGL Model, which enhances performance with complex local models and multi-client interactions. However, most FGL optimization strategies are designed specifically for the computer vision domain and ignore graph structure, presenting dissatisfied performance and slow convergence. Meanwhile, complex local model architectures in FGL Models studies lack scalability for handling large-scale subgraphs and have deployment limitations. To address these issues, we propose Federated Graph Topology-aware Aggregation (FedGTA), a personalized optimization strategy that optimizes through topology-aware local smoothing confidence and mixed neighbor features. During experiments, we deploy FedGTA in 12 multi-scale real-world datasets with the Louvain and Metis split. This allows us to evaluate the performance and robustness of FedGTA across a range of scenarios. Extensive experiments demonstrate that FedGTA achieves state-of-the-art performance while exhibiting high scalability and efficiency. The experiment includes ogbn-papers100M, the most representative large-scale graph database so that we can verify the applicability of our method to large-scale graph learning. To the best of our knowledge, our study is the first to bridge large-scale graph learning with FGL using this optimization strategy, contributing to the development of efficient and scalable FGL methods.</li>
</ul>

<h3>Title: Towards Effective and General Graph Unlearning via Mutual Evolution</h3>
<ul>
<li><strong>Authors: </strong>Xunkai Li, Yulin Zhao, Zhengyu Wu, Wentao Zhang, Rong-Hua Li, Guoren Wang</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.NE, cs.SI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.11760">https://arxiv.org/abs/2401.11760</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.11760">https://arxiv.org/pdf/2401.11760</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.11760]] Towards Effective and General Graph Unlearning via Mutual Evolution(https://arxiv.org/abs/2401.11760)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, robust</a></li>
<li><strong>Abstract: </strong>With the rapid advancement of AI applications, the growing needs for data privacy and model robustness have highlighted the importance of machine unlearning, especially in thriving graph-based scenarios. However, most existing graph unlearning strategies primarily rely on well-designed architectures or manual process, rendering them less user-friendly and posing challenges in terms of deployment efficiency. Furthermore, striking a balance between unlearning performance and framework generalization is also a pivotal concern. To address the above issues, we propose \underline{\textbf{M}}utual \underline{\textbf{E}}volution \underline{\textbf{G}}raph \underline{\textbf{U}}nlearning (MEGU), a new mutual evolution paradigm that simultaneously evolves the predictive and unlearning capacities of graph unlearning. By incorporating aforementioned two components, MEGU ensures complementary optimization in a unified training framework that aligns with the prediction and unlearning requirements. Extensive experiments on 9 graph benchmark datasets demonstrate the superior performance of MEGU in addressing unlearning requirements at the feature, node, and edge levels. Specifically, MEGU achieves average performance improvements of 2.7\%, 2.5\%, and 3.2\% across these three levels of unlearning tasks when compared to state-of-the-art baselines. Furthermore, MEGU exhibits satisfactory training efficiency, reducing time and space overhead by an average of 159.8x and 9.6x, respectively, in comparison to retraining GNN from scratch.</li>
</ul>

<h3>Title: Concealed Object Segmentation with Hierarchical Coherence Modeling</h3>
<ul>
<li><strong>Authors: </strong>Fengyang Xiao, Pan Zhang, Chunming He, Runze Hu, Yutao Liu</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.11767">https://arxiv.org/abs/2401.11767</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.11767">https://arxiv.org/pdf/2401.11767</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.11767]] Concealed Object Segmentation with Hierarchical Coherence Modeling(https://arxiv.org/abs/2401.11767)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>Concealed object segmentation (COS) is a challenging task that involves localizing and segmenting those concealed objects that are visually blended with their surrounding environments. Despite achieving remarkable success, existing COS segmenters still struggle to achieve complete segmentation results in extremely concealed scenarios. In this paper, we propose a Hierarchical Coherence Modeling (HCM) segmenter for COS, aiming to address this incomplete segmentation limitation. In specific, HCM promotes feature coherence by leveraging the intra-stage coherence and cross-stage coherence modules, exploring feature correlations at both the single-stage and contextual levels. Additionally, we introduce the reversible re-calibration decoder to detect previously undetected parts in low-confidence regions, resulting in further enhancing segmentation performance. Extensive experiments conducted on three COS tasks, including camouflaged object detection, polyp image segmentation, and transparent object detection, demonstrate the promising results achieved by the proposed HCM segmenter.</li>
</ul>

<h3>Title: Collaborative Position Reasoning Network for Referring Image  Segmentation</h3>
<ul>
<li><strong>Authors: </strong>Jianjian Cao, Beiya Dai, Yulin Li, Xiameng Qin, Jingdong Wang</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.11775">https://arxiv.org/abs/2401.11775</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.11775">https://arxiv.org/pdf/2401.11775</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.11775]] Collaborative Position Reasoning Network for Referring Image  Segmentation(https://arxiv.org/abs/2401.11775)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>Given an image and a natural language expression as input, the goal of referring image segmentation is to segment the foreground masks of the entities referred by the expression. Existing methods mainly focus on interactive learning between vision and language to enhance the multi-modal representations for global context reasoning. However, predicting directly in pixel-level space can lead to collapsed positioning and poor segmentation results. Its main challenge lies in how to explicitly model entity localization, especially for non-salient entities. In this paper, we tackle this problem by executing a Collaborative Position Reasoning Network (CPRN) via the proposed novel Row-and-Column interactive (RoCo) and Guided Holistic interactive (Holi) modules. Specifically, RoCo aggregates the visual features into the row- and column-wise features corresponding two directional axes respectively. It offers a fine-grained matching behavior that perceives the associations between the linguistic features and two decoupled visual features to perform position reasoning over a hierarchical space. Holi integrates features of the two modalities by a cross-modal attention mechanism, which suppresses the irrelevant redundancy under the guide of positioning information from RoCo. Thus, with the incorporation of RoCo and Holi modules, CPRN captures the visual details of position reasoning so that the model can achieve more accurate segmentation. To our knowledge, this is the first work that explicitly focuses on position reasoning modeling. We also validate the proposed method on three evaluation datasets. It consistently outperforms existing state-of-the-art methods.</li>
</ul>

<h3>Title: SemPLeS: Semantic Prompt Learning for Weakly-Supervised Semantic  Segmentation</h3>
<ul>
<li><strong>Authors: </strong>Ci-Siang Lin, Chien-Yi Wang, Yu-Chiang Frank Wang, Min-Hung Chen</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.CL, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.11791">https://arxiv.org/abs/2401.11791</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.11791">https://arxiv.org/pdf/2401.11791</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.11791]] SemPLeS: Semantic Prompt Learning for Weakly-Supervised Semantic  Segmentation(https://arxiv.org/abs/2401.11791)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability, segmentation</a></li>
<li><strong>Abstract: </strong>Weakly-Supervised Semantic Segmentation (WSSS) aims to train segmentation models using training image data with only image-level supervision. Since precise pixel-level annotations are not accessible, existing methods typically focus on producing pseudo masks for training segmentation models by refining CAM-like heatmaps. However, the produced heatmaps may only capture discriminative image regions of target object categories or the associated co-occurring backgrounds. To address the issues, we propose a Semantic Prompt Learning for WSSS (SemPLeS) framework, which learns to effectively prompt the CLIP space to enhance the semantic alignment between the segmented regions and the target object categories. More specifically, we propose Contrastive Prompt Learning and Class-associated Semantic Refinement to learn the prompts that adequately describe and suppress the image backgrounds associated with each target object category. In this way, our proposed framework is able to perform better semantic matching between object regions and the associated text labels, resulting in desired pseudo masks for training the segmentation model. The proposed SemPLeS framework achieves SOTA performance on the standard WSSS benchmarks, PASCAL VOC and MS COCO, and demonstrated interpretability with the semantic visualization of our learned prompts. The codes will be released.</li>
</ul>

<h3>Title: Hallucination is Inevitable: An Innate Limitation of Large Language  Models</h3>
<ul>
<li><strong>Authors: </strong>Ziwei Xu, Sanjay Jain, Mohan Kankanhalli</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.11817">https://arxiv.org/abs/2401.11817</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.11817">https://arxiv.org/pdf/2401.11817</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.11817]] Hallucination is Inevitable: An Innate Limitation of Large Language  Models(https://arxiv.org/abs/2401.11817)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Hallucination has been widely recognized to be a significant drawback for large language models (LLMs). There have been many works that attempt to reduce the extent of hallucination. These efforts have mostly been empirical so far, which cannot answer the fundamental question whether it can be completely eliminated. In this paper, we formalize the problem and show that it is impossible to eliminate hallucination in LLMs. Specifically, we define a formal world where hallucination is defined as inconsistencies between a computable LLM and a computable ground truth function. By employing results from learning theory, we show that LLMs cannot learn all of the computable functions and will therefore always hallucinate. Since the formal world is a part of the real world which is much more complicated, hallucinations are also inevitable for real world LLMs. Furthermore, for real world LLMs constrained by provable time complexity, we describe the hallucination-prone tasks and empirically validate our claims. Finally, using the formal world framework, we discuss the possible mechanisms and efficacies of existing hallucination mitigators as well as the practical implications on the safe deployment of LLMs.</li>
</ul>

<h3>Title: A Fair Evaluation of Various Deep Learning-Based Document Image  Binarization Approaches</h3>
<ul>
<li><strong>Authors: </strong>Richin Sukesh, Mathias Seuret, Anguelos Nicolaou, Martin Mayr, Vincent Christlein</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.11831">https://arxiv.org/abs/2401.11831</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.11831">https://arxiv.org/pdf/2401.11831</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.11831]] A Fair Evaluation of Various Deep Learning-Based Document Image  Binarization Approaches(https://arxiv.org/abs/2401.11831)</code><input type="text"></li>
<li><strong>Keywords: </strong>fair</a></li>
<li><strong>Abstract: </strong>Binarization of document images is an important pre-processing step in the field of document analysis. Traditional image binarization techniques usually rely on histograms or local statistics to identify a valid threshold to differentiate between different aspects of the image. Deep learning techniques are able to generate binarized versions of the images by learning context-dependent features that are less error-prone to degradation typically occurring in document images. In recent years, many deep learning-based methods have been developed for document binarization. But which one to choose? There have been no studies that compare these methods rigorously. Therefore, this work focuses on the evaluation of different deep learning-based methods under the same evaluation protocol. We evaluate them on different Document Image Binarization Contest (DIBCO) datasets and obtain very heterogeneous results. We show that the DE-GAN model was able to perform better compared to other models when evaluated on the DIBCO2013 dataset while DP-LinkNet performed best on the DIBCO2017 dataset. The 2-StageGAN performed best on the DIBCO2018 dataset while SauvolaNet outperformed the others on the DIBCO2019 challenge. Finally, we make the code, all models and evaluation publicly available (https://github.com/RichSu95/Document_Binarization_Collection) to ensure reproducibility and simplify future binarization evaluations.</li>
</ul>

<h3>Title: Privacy-Preserving Data Fusion for Traffic State Estimation: A Vertical  Federated Learning Approach</h3>
<ul>
<li><strong>Authors: </strong>Qiqing Wang, Kaidi Yang</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CR, eess.SY</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.11836">https://arxiv.org/abs/2401.11836</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.11836">https://arxiv.org/pdf/2401.11836</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.11836]] Privacy-Preserving Data Fusion for Traffic State Estimation: A Vertical  Federated Learning Approach(https://arxiv.org/abs/2401.11836)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, protect, federate</a></li>
<li><strong>Abstract: </strong>This paper proposes a privacy-preserving data fusion method for traffic state estimation (TSE). Unlike existing works that assume all data sources to be accessible by a single trusted party, we explicitly address data privacy concerns that arise in the collaboration and data sharing between multiple data owners, such as municipal authorities (MAs) and mobility providers (MPs). To this end, we propose a novel vertical federated learning (FL) approach, FedTSE, that enables multiple data owners to collaboratively train and apply a TSE model without having to exchange their private data. To enhance the applicability of the proposed FedTSE in common TSE scenarios with limited availability of ground-truth data, we further propose a privacy-preserving physics-informed FL approach, i.e., FedTSE-PI, that integrates traffic models into FL. Real-world data validation shows that the proposed methods can protect privacy while yielding similar accuracy to the oracle method without privacy considerations.</li>
</ul>

<h3>Title: AI for social science and social science of AI: A Survey</h3>
<ul>
<li><strong>Authors: </strong>Ruoxi Xu, Yingfei Sun, Mengjie Ren, Shiguang Guo, Ruotong Pan, Hongyu Lin, Le Sun, Xianpei Han</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.CY</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.11839">https://arxiv.org/abs/2401.11839</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.11839">https://arxiv.org/pdf/2401.11839</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.11839]] AI for social science and social science of AI: A Survey(https://arxiv.org/abs/2401.11839)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Recent advancements in artificial intelligence, particularly with the emergence of large language models (LLMs), have sparked a rethinking of artificial general intelligence possibilities. The increasing human-like capabilities of AI are also attracting attention in social science research, leading to various studies exploring the combination of these two fields. In this survey, we systematically categorize previous explorations in the combination of AI and social science into two directions that share common technical approaches but differ in their research objectives. The first direction is focused on AI for social science, where AI is utilized as a powerful tool to enhance various stages of social science research. While the second direction is the social science of AI, which examines AI agents as social entities with their human-like cognitive and linguistic capabilities. By conducting a thorough review, particularly on the substantial progress facilitated by recent advancements in large language models, this paper introduces a fresh perspective to reassess the relationship between AI and social science, provides a cohesive framework that allows researchers to understand the distinctions and connections between AI for social science and social science of AI, and also summarized state-of-art experiment simulation platforms to facilitate research in these two directions. We believe that as AI technology continues to advance and intelligent agents find increasing applications in our daily lives, the significance of the combination of AI and social science will become even more prominent.</li>
</ul>

<h3>Title: Learning to Approximate Adaptive Kernel Convolution on Graphs</h3>
<ul>
<li><strong>Authors: </strong>Jaeyoon Sim, Sooyeon Jeon, InJun Choi, Guorong Wu, Won Hwa Kim</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.11840">https://arxiv.org/abs/2401.11840</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.11840">https://arxiv.org/pdf/2401.11840</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.11840]] Learning to Approximate Adaptive Kernel Convolution on Graphs(https://arxiv.org/abs/2401.11840)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>Various Graph Neural Networks (GNNs) have been successful in analyzing data in non-Euclidean spaces, however, they have limitations such as oversmoothing, i.e., information becomes excessively averaged as the number of hidden layers increases. The issue stems from the intrinsic formulation of conventional graph convolution where the nodal features are aggregated from a direct neighborhood per layer across the entire nodes in the graph. As setting different number of hidden layers per node is infeasible, recent works leverage a diffusion kernel to redefine the graph structure and incorporate information from farther nodes. Unfortunately, such approaches suffer from heavy diagonalization of a graph Laplacian or learning a large transform matrix. In this regards, we propose a diffusion learning framework, where the range of feature aggregation is controlled by the scale of a diffusion kernel. For efficient computation, we derive closed-form derivatives of approximations of the graph convolution with respect to the scale, so that node-wise range can be adaptively learned. With a downstream classifier, the entire framework is made trainable in an end-to-end manner. Our model is tested on various standard datasets for node-wise classification for the state-of-the-art performance, and it is also validated on a real-world brain network data for graph classifications to demonstrate its practicality for Alzheimer classification.</li>
</ul>

<h3>Title: SignVTCL: Multi-Modal Continuous Sign Language Recognition Enhanced by  Visual-Textual Contrastive Learning</h3>
<ul>
<li><strong>Authors: </strong>Hao Chen, Jiaze Wang, Ziyu Guo, Jinpeng Li, Donghao Zhou, Bian Wu, Chenyong Guan, Guangyong Chen, Pheng-Ann Heng</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.11847">https://arxiv.org/abs/2401.11847</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.11847">https://arxiv.org/pdf/2401.11847</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.11847]] SignVTCL: Multi-Modal Continuous Sign Language Recognition Enhanced by  Visual-Textual Contrastive Learning(https://arxiv.org/abs/2401.11847)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Sign language recognition (SLR) plays a vital role in facilitating communication for the hearing-impaired community. SLR is a weakly supervised task where entire videos are annotated with glosses, making it challenging to identify the corresponding gloss within a video segment. Recent studies indicate that the main bottleneck in SLR is the insufficient training caused by the limited availability of large-scale datasets. To address this challenge, we present SignVTCL, a multi-modal continuous sign language recognition framework enhanced by visual-textual contrastive learning, which leverages the full potential of multi-modal data and the generalization ability of language model. SignVTCL integrates multi-modal data (video, keypoints, and optical flow) simultaneously to train a unified visual backbone, thereby yielding more robust visual representations. Furthermore, SignVTCL contains a visual-textual alignment approach incorporating gloss-level and sentence-level alignment to ensure precise correspondence between visual features and glosses at the level of individual glosses and sentence. Experimental results conducted on three datasets, Phoenix-2014, Phoenix-2014T, and CSL-Daily, demonstrate that SignVTCL achieves state-of-the-art results compared with previous methods.</li>
</ul>

<h3>Title: Self-Labeling the Job Shop Scheduling Problem</h3>
<ul>
<li><strong>Authors: </strong>Andrea Corsini, Angelo Porrello, Simone Calderara, Mauro Dell'Amico</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, math.CO</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.11849">https://arxiv.org/abs/2401.11849</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.11849">https://arxiv.org/pdf/2401.11849</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.11849]] Self-Labeling the Job Shop Scheduling Problem(https://arxiv.org/abs/2401.11849)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>In this work, we propose a Self-Supervised training strategy specifically designed for combinatorial problems. One of the main obstacles in applying supervised paradigms to such problems is the requirement of expensive target solutions as ground-truth, often produced with costly exact solvers. Inspired by Semi- and Self-Supervised learning, we show that it is possible to easily train generative models by sampling multiple solutions and using the best one according to the problem objective as a pseudo-label. In this way, we iteratively improve the model generation capability by relying only on its self-supervision, completely removing the need for optimality information. We prove the effectiveness of this Self-Labeling strategy on the Job Shop Scheduling (JSP), a complex combinatorial problem that is receiving much attention from the Reinforcement Learning community. We propose a generative model based on the well-known Pointer Network and train it with our strategy. Experiments on two popular benchmarks demonstrate the potential of this approach as the resulting models outperform constructive heuristics and current state-of-the-art Reinforcement Learning proposals.</li>
</ul>

<h3>Title: The Right Model for the Job: An Evaluation of Legal Multi-Label  Classification Baselines</h3>
<ul>
<li><strong>Authors: </strong>Martina Forster, Claudia Schulz, Prudhvi Nokku, Melicaalsadat Mirsafian, Jaykumar Kasundra, Stavroula Skylaki</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.11852">https://arxiv.org/abs/2401.11852</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.11852">https://arxiv.org/pdf/2401.11852</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.11852]] The Right Model for the Job: An Evaluation of Legal Multi-Label  Classification Baselines(https://arxiv.org/abs/2401.11852)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer, generative</a></li>
<li><strong>Abstract: </strong>Multi-Label Classification (MLC) is a common task in the legal domain, where more than one label may be assigned to a legal document. A wide range of methods can be applied, ranging from traditional ML approaches to the latest Transformer-based architectures. In this work, we perform an evaluation of different MLC methods using two public legal datasets, POSTURE50K and EURLEX57K. By varying the amount of training data and the number of labels, we explore the comparative advantage offered by different approaches in relation to the dataset properties. Our findings highlight DistilRoBERTa and LegalBERT as performing consistently well in legal MLC with reasonable computational demands. T5 also demonstrates comparable performance while offering advantages as a generative model in the presence of changing label sets. Finally, we show that the CrossEncoder exhibits potential for notable macro-F1 score improvements, albeit with increased computational costs.</li>
</ul>

<h3>Title: A Review of Physics-Informed Machine Learning Methods with Applications  to Condition Monitoring and Anomaly Detection</h3>
<ul>
<li><strong>Authors: </strong>Yuandi Wu, Brett Sicard, Stephen Andrew Gadsden</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, eess.SY</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.11860">https://arxiv.org/abs/2401.11860</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.11860">https://arxiv.org/pdf/2401.11860</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.11860]] A Review of Physics-Informed Machine Learning Methods with Applications  to Condition Monitoring and Anomaly Detection(https://arxiv.org/abs/2401.11860)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability</a></li>
<li><strong>Abstract: </strong>This study presents a comprehensive overview of PIML techniques in the context of condition monitoring. The central concept driving PIML is the incorporation of known physical laws and constraints into machine learning algorithms, enabling them to learn from available data while remaining consistent with physical principles. Through fusing domain knowledge with data-driven learning, PIML methods offer enhanced accuracy and interpretability in comparison to purely data-driven approaches. In this comprehensive survey, detailed examinations are performed with regard to the methodology by which known physical principles are integrated within machine learning frameworks, as well as their suitability for specific tasks within condition monitoring. Incorporation of physical knowledge into the ML model may be realized in a variety of methods, with each having its unique advantages and drawbacks. The distinct advantages and limitations of each methodology for the integration of physics within data-driven models are detailed, considering factors such as computational efficiency, model interpretability, and generalizability to different systems in condition monitoring and fault detection. Several case studies and works of literature utilizing this emerging concept are presented to demonstrate the efficacy of PIML in condition monitoring applications. From the literature reviewed, the versatility and potential of PIML in condition monitoring may be demonstrated. Novel PIML methods offer an innovative solution for addressing the complexities of condition monitoring and associated challenges. This comprehensive survey helps form the foundation for future work in the field. As the technology continues to advance, PIML is expected to play a crucial role in enhancing maintenance strategies, system reliability, and overall operational efficiency in engineering systems.</li>
</ul>

<h3>Title: Improving Small Language Models' Mathematical Reasoning via Mix Thoughts  Distillation</h3>
<ul>
<li><strong>Authors: </strong>Xunyu Zhu, Jian Li, Yong Liu, Can Ma, Weiping Wang</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.11864">https://arxiv.org/abs/2401.11864</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.11864">https://arxiv.org/pdf/2401.11864</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.11864]] Improving Small Language Models' Mathematical Reasoning via Mix Thoughts  Distillation(https://arxiv.org/abs/2401.11864)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>This work addresses the challenge of democratizing advanced Large Language Models (LLMs) by compressing their mathematical reasoning capabilities into sub-billion parameter Small Language Models (SLMs) without compromising performance. We introduce Equation-of-Thought Distillation (EoTD), a novel technique that encapsulates the reasoning process into equation-based representations to construct an EoTD dataset for fine-tuning SLMs. Additionally, we propose the Mix Thoughts Distillation (MTD) framework to enhance the reasoning performance of SLMs. This involves creating a reasoning dataset with multiple thought processes and using it for fine-tuning. Our experimental findings demonstrate that EoTD significantly boosts the reasoning abilities of SLMs, while MTD enables these models to achieve state-of-the-art reasoning performance.</li>
</ul>

<h3>Title: Detect-Order-Construct: A Tree Construction based Approach for  Hierarchical Document Structure Analysis</h3>
<ul>
<li><strong>Authors: </strong>Jiawei Wang, Kai Hu, Zhuoyao Zhong, Lei Sun, Qiang Huo</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.11874">https://arxiv.org/abs/2401.11874</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.11874">https://arxiv.org/pdf/2401.11874</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.11874]] Detect-Order-Construct: A Tree Construction based Approach for  Hierarchical Document Structure Analysis(https://arxiv.org/abs/2401.11874)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction</a></li>
<li><strong>Abstract: </strong>Document structure analysis (aka document layout analysis) is crucial for understanding the physical layout and logical structure of documents, with applications in information retrieval, document summarization, knowledge extraction, etc. In this paper, we concentrate on Hierarchical Document Structure Analysis (HDSA) to explore hierarchical relationships within structured documents created using authoring software employing hierarchical schemas, such as LaTeX, Microsoft Word, and HTML. To comprehensively analyze hierarchical document structures, we propose a tree construction based approach that addresses multiple subtasks concurrently, including page object detection (Detect), reading order prediction of identified objects (Order), and the construction of intended hierarchical structure (Construct). We present an effective end-to-end solution based on this framework to demonstrate its performance. To assess our approach, we develop a comprehensive benchmark called Comp-HRDoc, which evaluates the above subtasks simultaneously. Our end-to-end system achieves state-of-the-art performance on two large-scale document layout analysis datasets (PubLayNet and DocLayNet), a high-quality hierarchical document structure reconstruction dataset (HRDoc), and our Comp-HRDoc benchmark. The Comp-HRDoc benchmark will be released to facilitate further research in this field.</li>
</ul>

<h3>Title: PsySafe: A Comprehensive Framework for Psychological-based Attack,  Defense, and Evaluation of Multi-agent System Safety</h3>
<ul>
<li><strong>Authors: </strong>Zaibin Zhang, Yongting Zhang, Lijun Li, Hongzhi Gao, Lijun Wang, Huchuan Lu, Feng Zhao, Yu Qiao, Jing Shao</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.CR, cs.MA</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.11880">https://arxiv.org/abs/2401.11880</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.11880">https://arxiv.org/pdf/2401.11880</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.11880]] PsySafe: A Comprehensive Framework for Psychological-based Attack,  Defense, and Evaluation of Multi-agent System Safety(https://arxiv.org/abs/2401.11880)</code><input type="text"></li>
<li><strong>Keywords: </strong>defense, attack, large language model</a></li>
<li><strong>Abstract: </strong>Multi-agent systems, augmented with Large Language Models (LLMs), demonstrate significant capabilities for collective intelligence. However, the potential misuse of this intelligence for malicious purposes presents significant risks. To date, comprehensive research on the safety issues associated with multi-agent systems remains limited. From the perspective of agent psychology, we discover that the dark psychological states of agents can lead to severe safety issues. To address these issues, we propose a comprehensive framework grounded in agent psychology. In our framework, we focus on three aspects: identifying how dark personality traits in agents might lead to risky behaviors, designing defense strategies to mitigate these risks, and evaluating the safety of multi-agent systems from both psychological and behavioral perspectives. Our experiments reveal several intriguing phenomena, such as the collective dangerous behaviors among agents, agents' propensity for self-reflection when engaging in dangerous behavior, and the correlation between agents' psychological assessments and their dangerous behaviors. We anticipate that our framework and observations will provide valuable insights for further research into the safety of multi-agent systems. We will make our data and code publicly accessible at https:/github.com/AI4Good24/PsySafe.</li>
</ul>

<h3>Title: Blinded by Generated Contexts: How Language Models Merge Generated and  Retrieved Contexts for Open-Domain QA?</h3>
<ul>
<li><strong>Authors: </strong>Hexiang Tan, Fei Sun, Wanli Yang, Yuanzhuo Wang, Qi Cao, Xueqi Cheng</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.11911">https://arxiv.org/abs/2401.11911</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.11911">https://arxiv.org/pdf/2401.11911</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.11911]] Blinded by Generated Contexts: How Language Models Merge Generated and  Retrieved Contexts for Open-Domain QA?(https://arxiv.org/abs/2401.11911)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model, segmentation</a></li>
<li><strong>Abstract: </strong>While auxiliary information has become a key to enhance Large Language Models (LLMs), relatively little is known about how well LLMs merge these contexts, specifically generated and retrieved. To study this, we formulate a task specifically designed to identify whether the answers, derived from the integration of generated and retrieved contexts, are attributed to either generated or retrieved contexts. To support this task, we develop a methodology to construct datasets with conflicting contexts, where each question is paired with both generated and retrieved contexts, yet only one of them contains the correct answer. Our experiments reveal a significant bias in LLMs towards generated contexts, as evidenced across state-of-the-art open (Llama2-7b/13b) and closed (GPT 3.5/4) systems. We further identify two key factors contributing to this bias: i) Contexts generated by LLMs typically show greater similarity to the questions, increasing their likelihood of selection; ii) The segmentation process used in retrieved contexts disrupts their completeness, thereby hindering their full utilization in LLMs. Our analysis enhances the understanding of how LLMs merge diverse contexts, offering valuable insights for advancing current augmentation methods for LLMs.</li>
</ul>

<h3>Title: Large receptive field strategy and important feature extraction strategy  in 3D object detection</h3>
<ul>
<li><strong>Authors: </strong>Leichao Cui, Xiuxian Li, Min Meng</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.11913">https://arxiv.org/abs/2401.11913</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.11913">https://arxiv.org/pdf/2401.11913</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.11913]] Large receptive field strategy and important feature extraction strategy  in 3D object detection(https://arxiv.org/abs/2401.11913)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction</a></li>
<li><strong>Abstract: </strong>The enhancement of 3D object detection is pivotal for precise environmental perception and improved task execution capabilities in autonomous driving. LiDAR point clouds, offering accurate depth information, serve as a crucial information for this purpose. Our study focuses on key challenges in 3D target detection. To tackle the challenge of expanding the receptive field of a 3D convolutional kernel, we introduce the Dynamic Feature Fusion Module (DFFM). This module achieves adaptive expansion of the 3D convolutional kernel's receptive field, balancing the expansion with acceptable computational loads. This innovation reduces operations, expands the receptive field, and allows the model to dynamically adjust to different object requirements. Simultaneously, we identify redundant information in 3D features. Employing the Feature Selection Module (FSM) quantitatively evaluates and eliminates non-important features, achieving the separation of output box fitting and feature extraction. This innovation enables the detector to focus on critical features, resulting in model compression, reduced computational burden, and minimized candidate frame interference. Extensive experiments confirm that both DFFM and FSM not only enhance current benchmarks, particularly in small target detection, but also accelerate network performance. Importantly, these modules exhibit effective complementarity.</li>
</ul>

<h3>Title: Secure Multi-hop Telemetry Broadcasts for UAV Swarm Communication</h3>
<ul>
<li><strong>Authors: </strong>Randolf Rotta, Pavlo Mykytyn</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.RO</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.11915">https://arxiv.org/abs/2401.11915</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.11915">https://arxiv.org/pdf/2401.11915</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.11915]] Secure Multi-hop Telemetry Broadcasts for UAV Swarm Communication(https://arxiv.org/abs/2401.11915)</code><input type="text"></li>
<li><strong>Keywords: </strong>secure</a></li>
<li><strong>Abstract: </strong>Unmanned Aerial Vehicles (UAVs) are evolving as adaptable platforms for a wide range of applications such as precise inspections, emergency response, and remote sensing. Autonomous UAV swarms require efficient and stable communication during deployment for a successful mission execution. For instance, the periodic exchange of telemetry data between all swarm members provides the foundation for formation flight and collision avoidance. However, due to the mobility of the vehicles and instability of wireless transmissions, maintaining a secure and reliable all-to-all communication remains challenging. This paper investigates encrypted and authenticated multi-hop broadcast communication based on the transmission of custom IEEE 802.11 Wi-Fi data frames.</li>
</ul>

<h3>Title: The Bigger the Better? Rethinking the Effective Model Scale in Long-term  Time Series Forecasting</h3>
<ul>
<li><strong>Authors: </strong>Jinliang Deng, Xuan Song, Ivor W. Tsang, Hui Xiong</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.11929">https://arxiv.org/abs/2401.11929</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.11929">https://arxiv.org/pdf/2401.11929</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.11929]] The Bigger the Better? Rethinking the Effective Model Scale in Long-term  Time Series Forecasting(https://arxiv.org/abs/2401.11929)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Long-term time series forecasting (LTSF) represents a critical frontier in time series analysis, distinguished by its focus on extensive input sequences, in contrast to the constrained lengths typical of traditional approaches. While longer sequences inherently convey richer information, potentially enhancing predictive precision, prevailing techniques often respond by escalating model complexity. These intricate models can inflate into millions of parameters, incorporating parameter-intensive elements like positional encodings, feed-forward networks and self-attention mechanisms. This complexity, however, leads to prohibitive model scale, particularly given the time series data's semantic simplicity. Motivated by the pursuit of parsimony, our research employs conditional correlation and auto-correlation as investigative tools, revealing significant redundancies within the input data. Leveraging these insights, we introduce the HDformer, a lightweight Transformer variant enhanced with hierarchical decomposition. This novel architecture not only inverts the prevailing trend toward model expansion but also accomplishes precise forecasting with drastically fewer computations and parameters. Remarkably, HDformer outperforms existing state-of-the-art LTSF models, while requiring over 99\% fewer parameters. Through this work, we advocate a paradigm shift in LTSF, emphasizing the importance to tailor the model to the inherent dynamics of time series data-a timely reminder that in the realm of LTSF, bigger is not invariably better.</li>
</ul>

<h3>Title: Low-Tubal-Rank Tensor Recovery via Factorized Gradient Descent</h3>
<ul>
<li><strong>Authors: </strong>Zhiyu Liu, Zhi Han, Yandong Tang, Xi-Le Zhao, Yao Wang</a></li>
<li><strong>Subjects: </strong>cs.LG, math.OC, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.11940">https://arxiv.org/abs/2401.11940</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.11940">https://arxiv.org/pdf/2401.11940</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.11940]] Low-Tubal-Rank Tensor Recovery via Factorized Gradient Descent(https://arxiv.org/abs/2401.11940)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>This paper considers the problem of recovering a tensor with an underlying low-tubal-rank structure from a small number of corrupted linear measurements. Traditional approaches tackling such a problem require the computation of tensor Singular Value Decomposition (t-SVD), that is a computationally intensive process, rendering them impractical for dealing with large-scale tensors. Aim to address this challenge, we propose an efficient and effective low-tubal-rank tensor recovery method based on a factorization procedure akin to the Burer-Monteiro (BM) method. Precisely, our fundamental approach involves decomposing a large tensor into two smaller factor tensors, followed by solving the problem through factorized gradient descent (FGD). This strategy eliminates the need for t-SVD computation, thereby reducing computational costs and storage requirements. We provide rigorous theoretical analysis to ensure the convergence of FGD under both noise-free and noisy situations. Additionally, it is worth noting that our method does not require the precise estimation of the tensor tubal-rank. Even in cases where the tubal-rank is slightly overestimated, our approach continues to demonstrate robust performance. A series of experiments have been carried out to demonstrate that, as compared to other popular ones, our approach exhibits superior performance in multiple scenarios, in terms of the faster computational speed and the smaller convergence error.</li>
</ul>

<h3>Title: A Dynamic YOLO-Based Sequence-Matching Model for Efficient Coverless  Image Steganography</h3>
<ul>
<li><strong>Authors: </strong>Jiajun Liu, Lina Tan, Zhili Zhou, Yi Li, Peng Chen</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.11946">https://arxiv.org/abs/2401.11946</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.11946">https://arxiv.org/pdf/2401.11946</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.11946]] A Dynamic YOLO-Based Sequence-Matching Model for Efficient Coverless  Image Steganography(https://arxiv.org/abs/2401.11946)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, attack</a></li>
<li><strong>Abstract: </strong>Many existing coverless steganography methods establish a mapping relationship between cover images and hidden data. There exists an issue that the number of images stored in the database grows exponentially as the steganographic capacity rises. The need for a high steganographic capacity makes it challenging to build an image database. To improve the image library utilization and anti-attack capability of the steganography system, we present an efficient coverless scheme based on dynamically matched substrings. YOLO is employed for selecting optimal objects, and a mapping dictionary is established between these objects and scrambling factors. With the aid of this dictionary, each image is effectively assigned to a specific scrambling factor, which is used to scramble the receiver's sequence key. To achieve sufficient steganography capability based on a limited image library, all substrings of the scrambled sequences hold the potential to hide data. After completing the secret information matching, the ideal number of stego images will be obtained from the database. According to experimental results, this technology outperforms most previous works on data load, transmission security, and hiding capacity. Under typical geometric attacks, it can recover 79.85\% of secret information on average. Furthermore, only approximately 200 random images are needed to meet a capacity of 19 bits per image.</li>
</ul>

<h3>Title: Feature Denoising Diffusion Model for Blind Image Quality Assessment</h3>
<ul>
<li><strong>Authors: </strong>Xudong Li, Jingyuan Zheng, Runze Hu, Yan Zhang, Ke Li, Yunhang Shen, Xiawu Zheng, Yutao Liu, ShengChuan Zhang, Pingyang Dai, Rongrong Ji</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.11949">https://arxiv.org/abs/2401.11949</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.11949">https://arxiv.org/pdf/2401.11949</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.11949]] Feature Denoising Diffusion Model for Blind Image Quality Assessment(https://arxiv.org/abs/2401.11949)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>Blind Image Quality Assessment (BIQA) aims to evaluate image quality in line with human perception, without reference benchmarks. Currently, deep learning BIQA methods typically depend on using features from high-level tasks for transfer learning. However, the inherent differences between BIQA and these high-level tasks inevitably introduce noise into the quality-aware features. In this paper, we take an initial step towards exploring the diffusion model for feature denoising in BIQA, namely Perceptual Feature Diffusion for IQA (PFD-IQA), which aims to remove noise from quality-aware features. Specifically, (i) We propose a {Perceptual Prior Discovery and Aggregation module to establish two auxiliary tasks to discover potential low-level features in images that are used to aggregate perceptual text conditions for the diffusion model. (ii) We propose a Perceptual Prior-based Feature Refinement strategy, which matches noisy features to predefined denoising trajectories and then performs exact feature denoising based on text conditions. Extensive experiments on eight standard BIQA datasets demonstrate the superior performance to the state-of-the-art BIQA methods, i.e., achieving the PLCC values of 0.935 ( vs. 0.905 in KADID) and 0.922 ( vs. 0.894 in LIVEC).</li>
</ul>

<h3>Title: RUMBoost: Gradient Boosted Random Utility Models</h3>
<ul>
<li><strong>Authors: </strong>Nicolas Salvadé, Tim Hillel</a></li>
<li><strong>Subjects: </strong>cs.LG, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.11954">https://arxiv.org/abs/2401.11954</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.11954">https://arxiv.org/pdf/2401.11954</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.11954]] RUMBoost: Gradient Boosted Random Utility Models(https://arxiv.org/abs/2401.11954)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, interpretability</a></li>
<li><strong>Abstract: </strong>This paper introduces the RUMBoost model, a novel discrete choice modelling approach that combines the interpretability and behavioural robustness of Random Utility Models (RUMs) with the generalisation and predictive ability of deep learning methods. We obtain the full functional form of non-linear utility specifications by replacing each linear parameter in the utility functions of a RUM with an ensemble of gradient boosted regression trees. This enables piece-wise constant utility values to be imputed for all alternatives directly from the data for any possible combination of input variables. We introduce additional constraints on the ensembles to ensure three crucial features of the utility specifications: (i) dependency of the utilities of each alternative on only the attributes of that alternative, (ii) monotonicity of marginal utilities, and (iii) an intrinsically interpretable functional form, where the exact response of the model is known throughout the entire input space. Furthermore, we introduce an optimisation-based smoothing technique that replaces the piece-wise constant utility values of alternative attributes with monotonic piece-wise cubic splines to identify non-linear parameters with defined gradient. We demonstrate the potential of the RUMBoost model compared to various ML and Random Utility benchmark models for revealed preference mode choice data from London. The results highlight the great predictive performance and the direct interpretability of our proposed approach. Furthermore, the smoothed attribute utility functions allow for the calculation of various behavioural indicators and marginal utilities. Finally, we demonstrate the flexibility of our methodology by showing how the RUMBoost model can be extended to complex model specifications, including attribute interactions, correlation within alternative error terms and heterogeneity within the population.</li>
</ul>

<h3>Title: Effective Intrusion Detection in Heterogeneous Internet-of-Things  Networks via Ensemble Knowledge Distillation-based Federated Learning</h3>
<ul>
<li><strong>Authors: </strong>Jiyuan Shen, Wenzhuo Yang, Zhaowei Chu, Jiani Fan, Dusit Niyato, Kwok-Yan Lam</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.11968">https://arxiv.org/abs/2401.11968</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.11968">https://arxiv.org/pdf/2401.11968</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.11968]] Effective Intrusion Detection in Heterogeneous Internet-of-Things  Networks via Ensemble Knowledge Distillation-based Federated Learning(https://arxiv.org/abs/2401.11968)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, privacy, attack, federate</a></li>
<li><strong>Abstract: </strong>With the rapid development of low-cost consumer electronics and cloud computing, Internet-of-Things (IoT) devices are widely adopted for supporting next-generation distributed systems such as smart cities and industrial control systems. IoT devices are often susceptible to cyber attacks due to their open deployment environment and limited computing capabilities for stringent security controls. Hence, Intrusion Detection Systems (IDS) have emerged as one of the effective ways of securing IoT networks by monitoring and detecting abnormal activities. However, existing IDS approaches rely on centralized servers to generate behaviour profiles and detect anomalies, causing high response time and large operational costs due to communication overhead. Besides, sharing of behaviour data in an open and distributed IoT network environment may violate on-device privacy requirements. Additionally, various IoT devices tend to capture heterogeneous data, which complicates the training of behaviour models. In this paper, we introduce Federated Learning (FL) to collaboratively train a decentralized shared model of IDS, without exposing training data to others. Furthermore, we propose an effective method called Federated Learning Ensemble Knowledge Distillation (FLEKD) to mitigate the heterogeneity problems across various clients. FLEKD enables a more flexible aggregation method than conventional model fusion techniques. Experiment results on the public dataset CICIDS2019 demonstrate that the proposed approach outperforms local training and traditional FL in terms of both speed and performance and significantly improves the system's ability to detect unknown attacks. Finally, we evaluate our proposed framework's performance in three potential real-world scenarios and show FLEKD has a clear advantage in experimental results.</li>
</ul>

<h3>Title: Claim Detection for Automated Fact-checking: A Survey on Monolingual,  Multilingual and Cross-Lingual Research</h3>
<ul>
<li><strong>Authors: </strong>Rrubaa Panchendrarajan, Arkaitz Zubiaga</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.11969">https://arxiv.org/abs/2401.11969</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.11969">https://arxiv.org/pdf/2401.11969</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.11969]] Claim Detection for Automated Fact-checking: A Survey on Monolingual,  Multilingual and Cross-Lingual Research(https://arxiv.org/abs/2401.11969)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>Automated fact-checking has drawn considerable attention over the past few decades due to the increase in the diffusion of misinformation on online platforms. This is often carried out as a sequence of tasks comprising (i) the detection of sentences circulating in online platforms which constitute claims needing verification, followed by (ii) the verification process of those claims. This survey focuses on the former, by discussing existing efforts towards detecting claims needing fact-checking, with a particular focus on multilingual data and methods. This is a challenging and fertile direction where existing methods are yet far from matching human performance due to the profoundly challenging nature of the issue. Especially, the dissemination of information across multiple social platforms, articulated in multiple languages and modalities demands more generalized solutions for combating misinformation. Focusing on multilingual misinformation, we present a comprehensive survey of existing multilingual claim detection research. We present state-of-the-art multilingual claim detection research categorized into three key factors of the problem, verifiability, priority, and similarity. Further, we present a detailed overview of the existing multilingual datasets along with the challenges and suggest possible future advancements.</li>
</ul>

<h3>Title: TurboSVM-FL: Boosting Federated Learning through SVM Aggregation for  Lazy Clients</h3>
<ul>
<li><strong>Authors: </strong>Mengdi Wang, Anna Bodonhelyi, Efe Bozkir, Enkelejda Kasneci</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.DC</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.12012">https://arxiv.org/abs/2401.12012</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.12012">https://arxiv.org/pdf/2401.12012</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.12012]] TurboSVM-FL: Boosting Federated Learning through SVM Aggregation for  Lazy Clients(https://arxiv.org/abs/2401.12012)</code><input type="text"></li>
<li><strong>Keywords: </strong>federate</a></li>
<li><strong>Abstract: </strong>Federated learning is a distributed collaborative machine learning paradigm that has gained strong momentum in recent years. In federated learning, a central server periodically coordinates models with clients and aggregates the models trained locally by clients without necessitating access to local data. Despite its potential, the implementation of federated learning continues to encounter several challenges, predominantly the slow convergence that is largely due to data heterogeneity. The slow convergence becomes particularly problematic in cross-device federated learning scenarios where clients may be strongly limited by computing power and storage space, and hence counteracting methods that induce additional computation or memory cost on the client side such as auxiliary objective terms and larger training iterations can be impractical. In this paper, we propose a novel federated aggregation strategy, TurboSVM-FL, that poses no additional computation burden on the client side and can significantly accelerate convergence for federated classification task, especially when clients are "lazy" and train their models solely for few epochs for next global aggregation. TurboSVM-FL extensively utilizes support vector machine to conduct selective aggregation and max-margin spread-out regularization on class embeddings. We evaluate TurboSVM-FL on multiple datasets including FEMNIST, CelebA, and Shakespeare using user-independent validation with non-iid data distribution. Our results show that TurboSVM-FL can significantly outperform existing popular algorithms on convergence rate and reduce communication rounds while delivering better test metrics including accuracy, F1 score, and MCC.</li>
</ul>

<h3>Title: Robustness to distribution shifts of compressed networks for edge  devices</h3>
<ul>
<li><strong>Authors: </strong>Lulan Shen, Ali Edalati, Brett Meyer, Warren Gross, James J. Clark</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.12014">https://arxiv.org/abs/2401.12014</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.12014">https://arxiv.org/pdf/2401.12014</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.12014]] Robustness to distribution shifts of compressed networks for edge  devices(https://arxiv.org/abs/2401.12014)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>It is necessary to develop efficient DNNs deployed on edge devices with limited computation resources. However, the compressed networks often execute new tasks in the target domain, which is different from the source domain where the original network is trained. It is important to investigate the robustness of compressed networks in two types of data distribution shifts: domain shifts and adversarial perturbations. In this study, we discover that compressed models are less robust to distribution shifts than their original networks. Interestingly, larger networks are more vulnerable to losing robustness than smaller ones, even when they are compressed to a similar size as the smaller networks. Furthermore, compact networks obtained by knowledge distillation are much more robust to distribution shifts than pruned networks. Finally, post-training quantization is a reliable method for achieving significant robustness to distribution shifts, and it outperforms both pruned and distilled models in terms of robustness.</li>
</ul>

<h3>Title: CloSe: A 3D Clothing Segmentation Dataset and Model</h3>
<ul>
<li><strong>Authors: </strong>Dimitrije Antić, Garvita Tiwari, Batuhan Ozcomlekci, Riccardo Marin, Gerard Pons-Moll</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.12051">https://arxiv.org/abs/2401.12051</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.12051">https://arxiv.org/pdf/2401.12051</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.12051]] CloSe: A 3D Clothing Segmentation Dataset and Model(https://arxiv.org/abs/2401.12051)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>3D Clothing modeling and datasets play crucial role in the entertainment, animation, and digital fashion industries. Existing work often lacks detailed semantic understanding or uses synthetic datasets, lacking realism and personalization. To address this, we first introduce CloSe-D: a novel large-scale dataset containing 3D clothing segmentation of 3167 scans, covering a range of 18 distinct clothing classes. Additionally, we propose CloSe-Net, the first learning-based 3D clothing segmentation model for fine-grained segmentation from colored point clouds. CloSe-Net uses local point features, body-clothing correlation, and a garment-class and point features-based attention module, improving performance over baselines and prior work. The proposed attention module enables our model to learn appearance and geometry-dependent clothing prior from data. We further validate the efficacy of our approach by successfully segmenting publicly available datasets of people in clothing. We also introduce CloSe-T, a 3D interactive tool for refining segmentation labels. Combining the tool with CloSe-T in a continual learning setup demonstrates improved generalization on real-world data. Dataset, model, and tool can be found at https://virtualhumans.mpi-inf.mpg.de/close3dv24/.</li>
</ul>

<h3>Title: NEUROSEC: FPGA-Based Neuromorphic Audio Security</h3>
<ul>
<li><strong>Authors: </strong>Murat Isik, Hiruna Vishwamith, Yusuf Sur, Kayode Inadagbo, I. Can Dikmen</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.ET, cs.LG, cs.NE, cs.SD, eess.AS</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.12055">https://arxiv.org/abs/2401.12055</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.12055">https://arxiv.org/pdf/2401.12055</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.12055]] NEUROSEC: FPGA-Based Neuromorphic Audio Security(https://arxiv.org/abs/2401.12055)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, privacy, attack, robust</a></li>
<li><strong>Abstract: </strong>Neuromorphic systems, inspired by the complexity and functionality of the human brain, have gained interest in academic and industrial attention due to their unparalleled potential across a wide range of applications. While their capabilities herald innovation, it is imperative to underscore that these computational paradigms, analogous to their traditional counterparts, are not impervious to security threats. Although the exploration of neuromorphic methodologies for image and video processing has been rigorously pursued, the realm of neuromorphic audio processing remains in its early stages. Our results highlight the robustness and precision of our FPGA-based neuromorphic system. Specifically, our system showcases a commendable balance between desired signal and background noise, efficient spike rate encoding, and unparalleled resilience against adversarial attacks such as FGSM and PGD. A standout feature of our framework is its detection rate of 94%, which, when compared to other methodologies, underscores its greater capability in identifying and mitigating threats within 5.39 dB, a commendable SNR ratio. Furthermore, neuromorphic computing and hardware security serve many sensor domains in mission-critical and privacy-preserving applications.</li>
</ul>

<h3>Title: SEDAC: A CVAE-Based Data Augmentation Method for Security Bug Report  Identification</h3>
<ul>
<li><strong>Authors: </strong>Y. Liao, T. Zhang</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.SE</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.12060">https://arxiv.org/abs/2401.12060</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.12060">https://arxiv.org/pdf/2401.12060</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.12060]] SEDAC: A CVAE-Based Data Augmentation Method for Security Bug Report  Identification(https://arxiv.org/abs/2401.12060)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, attack, generative</a></li>
<li><strong>Abstract: </strong>Bug tracking systems store many bug reports, some of which are related to security. Identifying those security bug reports (SBRs) may help us predict some security-related bugs and solve security issues promptly so that the project can avoid threats and attacks. However, in the real world, the ratio of security bug reports is severely low; thus, directly training a prediction model with raw data may result in inaccurate results. Faced with the massive challenge of data imbalance, many researchers in the past have attempted to use text filtering or clustering methods to minimize the proportion of non-security bug reports (NSBRs) or apply oversampling methods to synthesize SBRs to make the dataset as balanced as possible. Nevertheless, there are still two challenges to those methods: 1) They ignore long-distance contextual information. 2) They fail to generate an utterly balanced dataset. To tackle these two challenges, we propose SEDAC, a new SBR identification method that generates similar bug report vectors to solve data imbalance problems and accurately detect security bug reports. Unlike previous studies, it first converts bug reports into individual bug report vectors with distilBERT, which are based on word2vec. Then, it trains a generative model through conditional variational auto-encoder (CVAE) to generate similar vectors with security labels, which makes the number of SBRs equal to NSBRs'. Finally, balanced data are used to train a security bug report classifier. To evaluate the effectiveness of our framework, we conduct it on 45,940 bug reports from Chromium and four Apache projects. The experimental results show that SEDAC outperforms all the baselines in g-measure with improvements of around 14.24%-50.10%.</li>
</ul>

<h3>Title: Spotting LLMs With Binoculars: Zero-Shot Detection of Machine-Generated  Text</h3>
<ul>
<li><strong>Authors: </strong>Abhimanyu Hans, Avi Schwarzschild, Valeriia Cherepanova, Hamid Kazemi, Aniruddha Saha, Micah Goldblum, Jonas Geiping, Tom Goldstein</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.12070">https://arxiv.org/abs/2401.12070</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.12070">https://arxiv.org/pdf/2401.12070</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.12070]] Spotting LLMs With Binoculars: Zero-Shot Detection of Machine-Generated  Text(https://arxiv.org/abs/2401.12070)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Detecting text generated by modern large language models is thought to be hard, as both LLMs and humans can exhibit a wide range of complex behaviors. However, we find that a score based on contrasting two closely related language models is highly accurate at separating human-generated and machine-generated text. Based on this mechanism, we propose a novel LLM detector that only requires simple calculations using a pair of pre-trained LLMs. The method, called Binoculars, achieves state-of-the-art accuracy without any training data. It is capable of spotting machine text from a range of modern LLMs without any model-specific modifications. We comprehensively evaluate Binoculars on a number of text sources and in varied situations. Over a wide range of document types, Binoculars detects over 90% of generated samples from ChatGPT (and other LLMs) at a false positive rate of 0.01%, despite not being trained on any ChatGPT data.</li>
</ul>

<h3>Title: Temporal Blind Spots in Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Jonas Wallat, Adam Jatowt, Avishek Anand</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.12078">https://arxiv.org/abs/2401.12078</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.12078">https://arxiv.org/pdf/2401.12078</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.12078]] Temporal Blind Spots in Large Language Models(https://arxiv.org/abs/2401.12078)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large language models (LLMs) have recently gained significant attention due to their unparalleled ability to perform various natural language processing tasks. These models, benefiting from their advanced natural language understanding capabilities, have demonstrated impressive zero-shot performance. However, the pre-training data utilized in LLMs is often confined to a specific corpus, resulting in inherent freshness and temporal scope limitations. Consequently, this raises concerns regarding the effectiveness of LLMs for tasks involving temporal intents. In this study, we aim to investigate the underlying limitations of general-purpose LLMs when deployed for tasks that require a temporal understanding. We pay particular attention to handling factual temporal knowledge through three popular temporal QA datasets. Specifically, we observe low performance on detailed questions about the past and, surprisingly, for rather new information. In manual and automatic testing, we find multiple temporal errors and characterize the conditions under which QA performance deteriorates. Our analysis contributes to understanding LLM limitations and offers valuable insights into developing future models that can better cater to the demands of temporally-oriented tasks. The code is available\footnote{https://github.com/jwallat/temporalblindspots}.</li>
</ul>

<h3>Title: Revisiting Demonstration Selection Strategies in In-Context Learning</h3>
<ul>
<li><strong>Authors: </strong>Keqin Peng, Liang Ding, Yancheng Yuan, Xuebo Liu, Min Zhang, Yuanxin Ouyang, Dacheng Tao</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.12087">https://arxiv.org/abs/2401.12087</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.12087">https://arxiv.org/pdf/2401.12087</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.12087]] Revisiting Demonstration Selection Strategies in In-Context Learning(https://arxiv.org/abs/2401.12087)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large language models (LLMs) have shown an impressive ability to perform a wide range of tasks using in-context learning (ICL), where a few examples are used to describe a task to the model. However, the performance of ICL varies significantly with the choice of demonstrations, and it is still unclear why this happens or what factors will influence its choice. In this work, we first revisit the factors contributing to this variance from both data and model aspects, and find that the choice of demonstration is both data- and model-dependent. We further proposed a data- and model-dependent demonstration selection method, \textbf{TopK + ConE}, based on the assumption that \textit{the performance of a demonstration positively correlates with its contribution to the model's understanding of the test samples}, resulting in a simple and effective recipe for ICL. Empirically, our method yields consistent improvements in both language understanding and generation tasks with different model scales. Further analyses confirm that, besides the generality and stability under different circumstances, our method provides a unified explanation for the effectiveness of previous methods. Code will be released.</li>
</ul>

<h3>Title: An Empirical Analysis of In-context Learning Abilities of LLMs for MT</h3>
<ul>
<li><strong>Authors: </strong>Pranjal A. Chitale, Jay Gala, Varun Gumma, Mitesh M. Khapra, Raj Dabre</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.12097">https://arxiv.org/abs/2401.12097</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.12097">https://arxiv.org/pdf/2401.12097</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.12097]] An Empirical Analysis of In-context Learning Abilities of LLMs for MT(https://arxiv.org/abs/2401.12097)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, large language model</a></li>
<li><strong>Abstract: </strong>In-context learning (ICL) has consistently demonstrated superior performance over zero-shot performance in large language models (LLMs). However, the understanding of the dynamics of ICL and the aspects that influence downstream performance remains limited, especially for natural language generation (NLG) tasks. This work aims to address this gap by investigating the ICL capabilities of LLMs and studying the impact of different aspects of the in-context demonstrations for the task of machine translation (MT). Our preliminary investigations aim to discern whether in-context learning (ICL) is predominantly influenced by demonstrations or instructions by applying diverse perturbations to in-context demonstrations while preserving the task instruction. We observe varying behavior to perturbed examples across different model families, notably with BLOOM-7B derivatives being severely influenced by noise, whereas Llama 2 derivatives not only exhibit robustness but also tend to show enhancements over the clean baseline when subject to perturbed demonstrations. This suggests that the robustness of ICL may be governed by several factors, including the type of noise, perturbation direction (source or target), the extent of pretraining of the specific model, and fine-tuning for downstream tasks if applicable. Further investigation is warranted to develop a comprehensive understanding of these factors in future research.</li>
</ul>

<h3>Title: The Curious Case of Nonverbal Abstract Reasoning with Multi-Modal Large  Language Models</h3>
<ul>
<li><strong>Authors: </strong>Kian Ahrabian, Zhivar Sourati, Kexuan Sun, Jiarui Zhang, Yifan Jiang, Fred Morstatter, Jay Pujara</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.12117">https://arxiv.org/abs/2401.12117</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.12117">https://arxiv.org/pdf/2401.12117</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.12117]] The Curious Case of Nonverbal Abstract Reasoning with Multi-Modal Large  Language Models(https://arxiv.org/abs/2401.12117)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>While large language models (LLMs) are still being adopted to new domains and utilized in novel applications, we are experiencing an influx of the new generation of foundation models, namely multi-modal large language models (MLLMs). These models integrate verbal and visual information, opening new possibilities to demonstrate more complex reasoning abilities at the intersection of the two modalities. However, despite the revolutionizing prospect of MLLMs, our understanding of their reasoning abilities is limited. In this study, we assess the nonverbal abstract reasoning abilities of open-source and closed-source MLLMs using variations of Raven's Progressive Matrices. Our experiments expose the difficulty of solving such problems while showcasing the immense gap between open-source and closed-source models. We also reveal critical shortcomings with individual visual and textual modules, subjecting the models to low-performance ceilings. Finally, to improve MLLMs' performance, we experiment with various methods, such as Chain-of-Thought prompting, resulting in a significant (up to 100%) boost in performance.</li>
</ul>

<h3>Title: Out-of-Distribution Detection & Applications With Ablated Learned  Temperature Energy</h3>
<ul>
<li><strong>Authors: </strong>Will LeVine, Benjamin Pikus, Jacob Phillips, Berk Norman, Fernando Amat Gil, Sean Hendryx</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.12129">https://arxiv.org/abs/2401.12129</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.12129">https://arxiv.org/pdf/2401.12129</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.12129]] Out-of-Distribution Detection & Applications With Ablated Learned  Temperature Energy(https://arxiv.org/abs/2401.12129)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>As deep neural networks become adopted in high-stakes domains, it is crucial to be able to identify when inference inputs are Out-of-Distribution (OOD) so that users can be alerted of likely drops in performance and calibration despite high confidence. Among many others, existing methods use the following two scores to do so without training on any apriori OOD examples: a learned temperature and an energy score. In this paper we introduce Ablated Learned Temperature Energy (or "AbeT" for short), a method which combines these prior methods in novel ways with effective modifications. Due to these contributions, AbeT lowers the False Positive Rate at $95\%$ True Positive Rate (FPR@95) by $35.39\%$ in classification (averaged across all ID and OOD datasets measured) compared to state of the art without training networks in multiple stages or requiring hyperparameters or test-time backward passes. We additionally provide empirical insights as to how our model learns to distinguish between In-Distribution (ID) and OOD samples while only being explicitly trained on ID samples via exposure to misclassified ID examples at training time. Lastly, we show the efficacy of our method in identifying predicted bounding boxes and pixels corresponding to OOD objects in object detection and semantic segmentation, respectively - with an AUROC increase of $5.15\%$ in object detection and both a decrease in FPR@95 of $41.48\%$ and an increase in AUPRC of $34.20\%$ on average in semantic segmentation compared to previous state of the art.</li>
</ul>

<h3>Title: Evaluation of QCNN-LSTM for Disability Forecasting in Multiple Sclerosis  Using Sequential Multisequence MRI</h3>
<ul>
<li><strong>Authors: </strong>John D. Mayfield, Issam El Naqa</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.ET, eess.IV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.12132">https://arxiv.org/abs/2401.12132</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.12132">https://arxiv.org/pdf/2401.12132</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.12132]] Evaluation of QCNN-LSTM for Disability Forecasting in Multiple Sclerosis  Using Sequential Multisequence MRI(https://arxiv.org/abs/2401.12132)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Introduction Quantum Convolutional Neural Network (QCNN)-Long Short-Term Memory (LSTM) models were studied to provide sequential relationships for each timepoint in MRIs of patients with Multiple Sclerosis (MS). In this pilot study, we compared three QCNN-LSTM models for binary classification of MS disability benchmarked against classical neural network architectures. Our hypothesis is that quantum models will provide competitive performance. Methods Matrix Product State (MPS), reverse Multistate Entanglement Renormalization Ansatz (MERA), and Tree-Tensor Network (TTN) circuits were paired with LSTM layer to process near-annual MRI data of patients diagnosed with MS. These were benchmarked against a Visual Geometry Group (VGG)-LSTM and a Video Vision Transformer (ViViT). Predicted logits were measured against ground truth labels of each patient's Extended Disability Severity Score (EDSS) using binary cross-entropy loss. Training/validation/holdout testing was partitioned using 5-fold cross validation with a total split of 60:20:20. Levene's test of variance was used to measure statistical difference and Student's t-test for paired model differences in mean. Results The MPS-LSTM, reverse MERA-LSTM, and TTN-LSTM had holdout testing ROC-AUC of 0.70, 0.77, and 0.81, respectively (p-value 0.915). VGG16-LSTM and ViViT performed similarly with ROC-AUC of 0.73 and 0.77, respectively (p-value 0.631). Overall variance and mean were not statistically significant (p-value 0.713), however, time to train was significantly faster for the QCNN-LSTMs (39.4 sec per fold vs. 224 and 218, respectively, p-value <0.001). Conclusion QCNN-LSTM models perform competitively to their classical counterparts with greater efficiency in train time. Clinically, these can add value in terms of efficiency to time-dependent deep learning prediction of disease progression based upon medical imaging.</li>
</ul>

<h3>Title: Anisotropy Is Inherent to Self-Attention in Transformers</h3>
<ul>
<li><strong>Authors: </strong>Nathan Godey, Éric de la Clergerie, Benoît Sagot</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.12143">https://arxiv.org/abs/2401.12143</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.12143">https://arxiv.org/pdf/2401.12143</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.12143]] Anisotropy Is Inherent to Self-Attention in Transformers(https://arxiv.org/abs/2401.12143)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>The representation degeneration problem is a phenomenon that is widely observed among self-supervised learning methods based on Transformers. In NLP, it takes the form of anisotropy, a singular property of hidden representations which makes them unexpectedly close to each other in terms of angular distance (cosine-similarity). Some recent works tend to show that anisotropy is a consequence of optimizing the cross-entropy loss on long-tailed distributions of tokens. We show in this paper that anisotropy can also be observed empirically in language models with specific objectives that should not suffer directly from the same consequences. We also show that the anisotropy problem extends to Transformers trained on other modalities. Our observations suggest that anisotropy is actually inherent to Transformers-based models.</li>
</ul>

<h3>Title: Automated facial recognition system using deep learning for pain  assessment in adults with cerebral palsy</h3>
<ul>
<li><strong>Authors: </strong>Álvaro Sabater-Gárriz, F. Xavier Gaya-Morey, José María Buades-Rubio, Cristina Manresa Yee, Pedro Montoya, Inmaculada Riquelme</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.12161">https://arxiv.org/abs/2401.12161</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.12161">https://arxiv.org/pdf/2401.12161</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.12161]] Automated facial recognition system using deep learning for pain  assessment in adults with cerebral palsy(https://arxiv.org/abs/2401.12161)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Background: Pain assessment in individuals with neurological conditions, especially those with limited self-report ability and altered facial expressions, presents challenges. Existing measures, relying on direct observation by caregivers, lack sensitivity and specificity. In cerebral palsy, pain is a common comorbidity and a reliable evaluation protocol is crucial. Thus, having an automatic system that recognizes facial expressions could be of enormous help when diagnosing pain in this type of patient. Objectives: 1) to build a dataset of facial pain expressions in individuals with cerebral palsy, and 2) to develop an automated facial recognition system based on deep learning for pain assessment addressed to this population. Methods: Ten neural networks were trained on three pain image databases, including the UNBC-McMaster Shoulder Pain Expression Archive Database, the Multimodal Intensity Pain Dataset, and the Delaware Pain Database. Additionally, a curated dataset (CPPAIN) was created, consisting of 109 preprocessed facial pain expression images from individuals with cerebral palsy, categorized by two physiotherapists using the Facial Action Coding System observational scale. Results: InceptionV3 exhibited promising performance on the CP-PAIN dataset, achieving an accuracy of 62.67% and an F1 score of 61.12%. Explainable artificial intelligence techniques revealed consistent essential features for pain identification across models. Conclusion: This study demonstrates the potential of deep learning models for robust pain detection in populations with neurological conditions and communication disabilities. The creation of a larger dataset specific to cerebral palsy would further enhance model accuracy, offering a valuable tool for discerning subtle and idiosyncratic pain expressions. The insights gained could extend to other complex neurological conditions.</li>
</ul>

<h3>Title: Semi-supervised segmentation of land cover images using nonlinear  canonical correlation analysis with multiple features and t-SNE</h3>
<ul>
<li><strong>Authors: </strong>Hong Wei, James Xiao, Yichao Zhang, Xia Hong</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.12164">https://arxiv.org/abs/2401.12164</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.12164">https://arxiv.org/pdf/2401.12164</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.12164]] Semi-supervised segmentation of land cover images using nonlinear  canonical correlation analysis with multiple features and t-SNE(https://arxiv.org/abs/2401.12164)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>Image segmentation is a clustering task whereby each pixel is assigned a cluster label. Remote sensing data usually consists of multiple bands of spectral images in which there exist semantically meaningful land cover subregions, co-registered with other source data such as LIDAR (LIght Detection And Ranging) data, where available. This suggests that, in order to account for spatial correlation between pixels, a feature vector associated with each pixel may be a vectorized tensor representing the multiple bands and a local patch as appropriate. Similarly, multiple types of texture features based on a pixel's local patch would also be beneficial for encoding locally statistical information and spatial variations, without necessarily labelling pixel-wise a large amount of ground truth, then training a supervised model, which is sometimes impractical. In this work, by resorting to label only a small quantity of pixels, a new semi-supervised segmentation approach is proposed. Initially, over all pixels, an image data matrix is created in high dimensional feature space. Then, t-SNE projects the high dimensional data onto 3D embedding. By using radial basis functions as input features, which use the labelled data samples as centres, to pair with the output class labels, a modified canonical correlation analysis algorithm, referred to as RBF-CCA, is introduced which learns the associated projection matrix via the small labelled data set. The associated canonical variables, obtained for the full image, are applied by k-means clustering algorithm. The proposed semi-supervised RBF-CCA algorithm has been implemented on several remotely sensed multispectral images, demonstrating excellent segmentation results.</li>
</ul>

<h3>Title: Single-View 3D Human Digitalization with Large Reconstruction Models</h3>
<ul>
<li><strong>Authors: </strong>Zhenzhen Weng, Jingyuan Liu, Hao Tan, Zhan Xu, Yang Zhou, Serena Yeung-Levy, Jimei Yang</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.12175">https://arxiv.org/abs/2401.12175</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.12175">https://arxiv.org/pdf/2401.12175</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.12175]] Single-View 3D Human Digitalization with Large Reconstruction Models(https://arxiv.org/abs/2401.12175)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, generative</a></li>
<li><strong>Abstract: </strong>In this paper, we introduce Human-LRM, a single-stage feed-forward Large Reconstruction Model designed to predict human Neural Radiance Fields (NeRF) from a single image. Our approach demonstrates remarkable adaptability in training using extensive datasets containing 3D scans and multi-view capture. Furthermore, to enhance the model's applicability for in-the-wild scenarios especially with occlusions, we propose a novel strategy that distills multi-view reconstruction into single-view via a conditional triplane diffusion model. This generative extension addresses the inherent variations in human body shapes when observed from a single view, and makes it possible to reconstruct the full body human from an occluded image. Through extensive experiments, we show that Human-LRM surpasses previous methods by a significant margin on several benchmarks.</li>
</ul>

<h3>Title: Universal Neurons in GPT2 Language Models</h3>
<ul>
<li><strong>Authors: </strong>Wes Gurnee, Theo Horsley, Zifan Carl Guo, Tara Rezaei Kheirkhah, Qinyi Sun, Will Hathaway, Neel Nanda, Dimitris Bertsimas</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.12181">https://arxiv.org/abs/2401.12181</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.12181">https://arxiv.org/pdf/2401.12181</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.12181]] Universal Neurons in GPT2 Language Models(https://arxiv.org/abs/2401.12181)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability</a></li>
<li><strong>Abstract: </strong>A basic question within the emerging field of mechanistic interpretability is the degree to which neural networks learn the same underlying mechanisms. In other words, are neural mechanisms universal across different models? In this work, we study the universality of individual neurons across GPT2 models trained from different initial random seeds, motivated by the hypothesis that universal neurons are likely to be interpretable. In particular, we compute pairwise correlations of neuron activations over 100 million tokens for every neuron pair across five different seeds and find that 1-5\% of neurons are universal, that is, pairs of neurons which consistently activate on the same inputs. We then study these universal neurons in detail, finding that they usually have clear interpretations and taxonomize them into a small number of neuron families. We conclude by studying patterns in neuron weights to establish several universal functional roles of neurons in simple circuits: deactivating attention heads, changing the entropy of the next token distribution, and predicting the next token to (not) be within a particular set.</li>
</ul>

<h3>Title: Is Your Kettle Smarter Than a Hacker? A Scalable Tool for Assessing  Replay Attack Vulnerabilities on Consumer IoT Devices</h3>
<ul>
<li><strong>Authors: </strong>Sara Lazzaro, Vincenzo De Angelis, Anna Maria Mandalari, Francesco Buccafurri</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.12184">https://arxiv.org/abs/2401.12184</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.12184">https://arxiv.org/pdf/2401.12184</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.12184]] Is Your Kettle Smarter Than a Hacker? A Scalable Tool for Assessing  Replay Attack Vulnerabilities on Consumer IoT Devices(https://arxiv.org/abs/2401.12184)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, attack</a></li>
<li><strong>Abstract: </strong>Consumer Internet of Things (IoT) devices often leverage the local network to communicate with the corresponding companion app or other devices. This has benefits in terms of efficiency since it offloads the cloud. ENISA and NIST security guidelines underscore the importance of enabling default local communication for safety and reliability. Indeed, an IoT device should continue to function in case the cloud connection is not available. While the security of cloud-device connections is typically strengthened through the usage of standard protocols, local connectivity security is frequently overlooked. Neglecting the security of local communication opens doors to various threats, including replay attacks. In this paper, we investigate this class of attacks by designing a systematic methodology for automatically testing IoT devices vulnerability to replay attacks. Specifically, we propose a tool, named REPLIOT, able to test whether a replay attack is successful or not, without prior knowledge of the target devices. We perform thousands of automated experiments using popular commercial devices spanning various vendors and categories. Notably, our study reveals that among these devices, 51% of them do not support local connectivity, thus they are not compliant with the reliability and safety requirements of the ENISA/NIST guidelines. We find that 75% of the remaining devices are vulnerable to replay attacks with REPLIOT having a detection accuracy of 0.98-1. Finally, we investigate the possible causes of this vulnerability, discussing possible mitigation strategies.</li>
</ul>

<h3>Title: WARM: On the Benefits of Weight Averaged Reward Models</h3>
<ul>
<li><strong>Authors: </strong>Alexandre Ramé, Nino Vieillard, Léonard Hussenot, Robert Dadashi, Geoffrey Cideron, Olivier Bachem, Johan Ferret</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.12187">https://arxiv.org/abs/2401.12187</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.12187">https://arxiv.org/pdf/2401.12187</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.12187]] WARM: On the Benefits of Weight Averaged Reward Models(https://arxiv.org/abs/2401.12187)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, large language model</a></li>
<li><strong>Abstract: </strong>Aligning large language models (LLMs) with human preferences through reinforcement learning (RLHF) can lead to reward hacking, where LLMs exploit failures in the reward model (RM) to achieve seemingly high rewards without meeting the underlying objectives. We identify two primary challenges when designing RMs to mitigate reward hacking: distribution shifts during the RL process and inconsistencies in human preferences. As a solution, we propose Weight Averaged Reward Models (WARM), first fine-tuning multiple RMs, then averaging them in the weight space. This strategy follows the observation that fine-tuned weights remain linearly mode connected when sharing the same pre-training. By averaging weights, WARM improves efficiency compared to the traditional ensembling of predictions, while improving reliability under distribution shifts and robustness to preference inconsistencies. Our experiments on summarization tasks, using best-of-N and RL methods, shows that WARM improves the overall quality and alignment of LLM predictions; for example, a policy RL fine-tuned with WARM has a 79.4% win rate against a policy RL fine-tuned with a single RM.</li>
</ul>

<h3>Title: Text Embedding Inversion Attacks on Multilingual Language Models</h3>
<ul>
<li><strong>Authors: </strong>Yiyi Chen, Heather Lent, Johannes Bjerva</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.12192">https://arxiv.org/abs/2401.12192</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.12192">https://arxiv.org/pdf/2401.12192</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.12192]] Text Embedding Inversion Attacks on Multilingual Language Models(https://arxiv.org/abs/2401.12192)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, defense, attack, large language model</a></li>
<li><strong>Abstract: </strong>Representing textual information as real-numbered embeddings has become the norm in NLP. Moreover, with the rise of public interest in large language models (LLMs), Embeddings as a Service (EaaS) has rapidly gained traction as a business model. This is not without outstanding security risks, as previous research has demonstrated that sensitive data can be reconstructed from embeddings, even without knowledge of the underlying model that generated them. However, such work is limited by its sole focus on English, leaving all other languages vulnerable to attacks by malicious actors. %As many international and multilingual companies leverage EaaS, there is an urgent need for research into multilingual LLM security. To this end, this work investigates LLM security from the perspective of multilingual embedding inversion. Concretely, we define the problem of black-box multilingual and cross-lingual inversion attacks, with special attention to a cross-domain scenario. Our findings reveal that multilingual models are potentially more vulnerable to inversion attacks than their monolingual counterparts. This stems from the reduced data requirements for achieving comparable inversion performance in settings where the underlying language is not known a-priori. To our knowledge, this work is the first to delve into multilinguality within the context of inversion attacks, and our findings highlight the need for further investigation and enhanced defenses in the area of NLP Security.</li>
</ul>

<h3>Title: APT: Adaptive Pruning and Tuning Pretrained Language Models for  Efficient Training and Inference</h3>
<ul>
<li><strong>Authors: </strong>Bowen Zhao, Hannaneh Hajishirzi, Qingqing Cao</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.12200">https://arxiv.org/abs/2401.12200</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.12200">https://arxiv.org/pdf/2401.12200</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.12200]] APT: Adaptive Pruning and Tuning Pretrained Language Models for  Efficient Training and Inference(https://arxiv.org/abs/2401.12200)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Fine-tuning and inference with large Language Models (LM) are generally known to be expensive. Parameter-efficient fine-tuning over pretrained LMs reduces training memory by updating a small number of LM parameters but does not improve inference efficiency. Structured pruning improves LM inference efficiency by removing consistent parameter blocks, yet often increases training memory and time. To improve both training and inference efficiency, we introduce APT that adaptively prunes and tunes parameters for the LMs. At the early stage of fine-tuning, APT dynamically adds salient tuning parameters for fast and accurate convergence while discarding unimportant parameters for efficiency. Compared to baselines, our experiments show that APT maintains up to 98% task performance when pruning RoBERTa and T5 models with 40% parameters left while keeping 86.4% LLaMA models' performance with 70% parameters remained. Furthermore, APT speeds up LMs fine-tuning by up to 8x and reduces large LMs memory training footprint by up to 70%.</li>
</ul>

<h3>Title: CheXagent: Towards a Foundation Model for Chest X-Ray Interpretation</h3>
<ul>
<li><strong>Authors: </strong>Zhihong Chen, Maya Varma, Jean-Benoit Delbrouck, Magdalini Paschali, Louis Blankemeier, Dave Van Veen, Jeya Maria Jose Valanarasu, Alaa Youssef, Joseph Paul Cohen, Eduardo Pontes Reis, Emily B. Tsai, Andrew Johnston, Cameron Olsen, Tanishq Mathew Abraham, Sergios Gatidis, Akshay S. Chaudhari, Curtis Langlotz</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.12208">https://arxiv.org/abs/2401.12208</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.12208">https://arxiv.org/pdf/2401.12208</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.12208]] CheXagent: Towards a Foundation Model for Chest X-Ray Interpretation(https://arxiv.org/abs/2401.12208)</code><input type="text"></li>
<li><strong>Keywords: </strong>fair, large language model</a></li>
<li><strong>Abstract: </strong>Chest X-rays (CXRs) are the most frequently performed imaging test in clinical practice. Recent advances in the development of vision-language foundation models (FMs) give rise to the possibility of performing automated CXR interpretation, which can assist physicians with clinical decision-making and improve patient outcomes. However, developing FMs that can accurately interpret CXRs is challenging due to the (1) limited availability of large-scale vision-language datasets in the medical image domain, (2) lack of vision and language encoders that can capture the complexities of medical data, and (3) absence of evaluation frameworks for benchmarking the abilities of FMs on CXR interpretation. In this work, we address these challenges by first introducing \emph{CheXinstruct} - a large-scale instruction-tuning dataset curated from 28 publicly-available datasets. We then present \emph{CheXagent} - an instruction-tuned FM capable of analyzing and summarizing CXRs. To build CheXagent, we design a clinical large language model (LLM) for parsing radiology reports, a vision encoder for representing CXR images, and a network to bridge the vision and language modalities. Finally, we introduce \emph{CheXbench} - a novel benchmark designed to systematically evaluate FMs across 8 clinically-relevant CXR interpretation tasks. Extensive quantitative evaluations and qualitative reviews with five expert radiologists demonstrate that CheXagent outperforms previously-developed general- and medical-domain FMs on CheXbench tasks. Furthermore, in an effort to improve model transparency, we perform a fairness evaluation across factors of sex, race and age to highlight potential performance disparities. Our project is at \url{https://stanford-aimi.github.io/chexagent.html}.</li>
</ul>

<h3>Title: Less Could Be Better: Parameter-efficient Fine-tuning Advances Medical  Vision Foundation Models</h3>
<ul>
<li><strong>Authors: </strong>Chenyu Lian, Hong-Yu Zhou, Yizhou Yu, Liansheng Wang</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.12215">https://arxiv.org/abs/2401.12215</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.12215">https://arxiv.org/pdf/2401.12215</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.12215]] Less Could Be Better: Parameter-efficient Fine-tuning Advances Medical  Vision Foundation Models(https://arxiv.org/abs/2401.12215)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Parameter-efficient fine-tuning (PEFT) that was initially developed for exploiting pre-trained large language models has recently emerged as an effective approach to perform transfer learning on computer vision tasks. However, the effectiveness of PEFT on medical vision foundation models is still unclear and remains to be explored. As a proof of concept, we conducted a detailed empirical study on applying PEFT to chest radiography foundation models. Specifically, we delved into LoRA, a representative PEFT method, and compared it against full-parameter fine-tuning (FFT) on two self-supervised radiography foundation models across three well-established chest radiograph datasets. Our results showed that LoRA outperformed FFT in 13 out of 18 transfer learning tasks by at most 2.9% using fewer than 1% tunable parameters. Combining LoRA with foundation models, we set up new state-of-the-art on a range of data-efficient learning tasks, such as an AUROC score of 80.6% using 1% labeled data on NIH ChestX-ray14. We hope this study can evoke more attention from the community in the use of PEFT for transfer learning on medical imaging tasks. Code and models are available at https://github.com/RL4M/MED-PEFT.</li>
</ul>

<h3>Title: Exploring Simple Open-Vocabulary Semantic Segmentation</h3>
<ul>
<li><strong>Authors: </strong>Zihang Lai</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.12217">https://arxiv.org/abs/2401.12217</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.12217">https://arxiv.org/pdf/2401.12217</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.12217]] Exploring Simple Open-Vocabulary Semantic Segmentation(https://arxiv.org/abs/2401.12217)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>Open-vocabulary semantic segmentation models aim to accurately assign a semantic label to each pixel in an image from a set of arbitrary open-vocabulary texts. In order to learn such pixel-level alignment, current approaches typically rely on a combination of (i) image-level VL model (e.g. CLIP), (ii) ground truth masks, and (iii) custom grouping encoders. In this paper, we introduce S-Seg, a novel model that can achieve surprisingly strong performance without depending on any of the above elements. S-Seg leverages pseudo-mask and language to train a MaskFormer, and can be easily trained from publicly available image-text datasets. Contrary to prior works, our model directly trains for pixel-level features and language alignment. Once trained, S-Seg generalizes well to multiple testing datasets without requiring fine-tuning. In addition, S-Seg has the extra benefits of scalability with data and consistently improvement when augmented with self-training. We believe that our simple yet effective approach will serve as a solid baseline for future research.</li>
</ul>

<button id="copy">Copy All</button>
</article>
<script src="../../javascript/clipboard.min.js"></script>
<script src="../../javascript/clipboard.js"></script>
