<link rel="stylesheet" href="../../css/markdown.css" />
<article class="markdown-body">
<h1>2024-01-25</h1>
<h3>Title: Identifying Risk Patterns in Brazilian Police Reports Preceding  Femicides: A Long Short Term Memory (LSTM) Based Analysis</h3>
<ul>
<li><strong>Authors: </strong>Vinicius Lima, Jaque Almeida de Oliveira</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.12980">https://arxiv.org/abs/2401.12980</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.12980">https://arxiv.org/pdf/2401.12980</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.12980]] Identifying Risk Patterns in Brazilian Police Reports Preceding  Femicides: A Long Short Term Memory (LSTM) Based Analysis(https://arxiv.org/abs/2401.12980)</code><input type="text"></li>
<li><strong>Keywords: </strong>protect</a></li>
<li><strong>Abstract: </strong>Femicide refers to the killing of a female victim, often perpetrated by an intimate partner or family member, and is also associated with gender-based violence. Studies have shown that there is a pattern of escalating violence leading up to these killings, highlighting the potential for prevention if the level of danger to the victim can be assessed. Machine learning offers a promising approach to address this challenge by predicting risk levels based on textual descriptions of the violence. In this study, we employed the Long Short Term Memory (LSTM) technique to identify patterns of behavior in Brazilian police reports preceding femicides. Our first objective was to classify the content of these reports as indicating either a lower or higher risk of the victim being murdered, achieving an accuracy of 66%. In the second approach, we developed a model to predict the next action a victim might experience within a sequence of patterned events. Both approaches contribute to the understanding and assessment of the risks associated with domestic violence, providing authorities with valuable insights to protect women and prevent situations from escalating.</li>
</ul>

<h3>Title: A General-purpose AI Avatar in Healthcare</h3>
<ul>
<li><strong>Authors: </strong>Nicholas Yan, Gil Alterovitz</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.12981">https://arxiv.org/abs/2401.12981</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.12981">https://arxiv.org/pdf/2401.12981</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.12981]] A General-purpose AI Avatar in Healthcare(https://arxiv.org/abs/2401.12981)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Recent advancements in machine learning and natural language processing have led to the rapid development of artificial intelligence (AI) as a valuable tool in the healthcare industry. Using large language models (LLMs) as conversational agents or chatbots has the potential to assist doctors in diagnosing patients, detecting early symptoms of diseases, and providing health advice to patients. This paper focuses on the role of chatbots in healthcare and explores the use of avatars to make AI interactions more appealing to patients. A framework of a general-purpose AI avatar application is demonstrated by using a three-category prompt dictionary and prompt improvement mechanism. A two-phase approach is suggested to fine-tune a general-purpose AI language model and create different AI avatars to discuss medical issues with users. Prompt engineering enhances the chatbot's conversational abilities and personality traits, fostering a more human-like interaction with patients. Ultimately, the injection of personality into the chatbot could potentially increase patient engagement. Future directions for research include investigating ways to improve chatbots' understanding of context and ensuring the accuracy of their outputs through fine-tuning with specialized medical data sets.</li>
</ul>

<h3>Title: Assessing Large Language Models in Mechanical Engineering Education: A  Study on Mechanics-Focused Conceptual Understanding</h3>
<ul>
<li><strong>Authors: </strong>Jie Tian, Jixin Hou, Zihao Wu, Peng Shu, Zhengliang Liu, Yujie Xiang, Beikang Gu, Nicholas Filla, Yiwei Li, Ning Liu, Xianyan Chen, Keke Tang, Tianming Liu, Xianqiao Wang</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, physics.ed-ph</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.12983">https://arxiv.org/abs/2401.12983</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.12983">https://arxiv.org/pdf/2401.12983</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.12983]] Assessing Large Language Models in Mechanical Engineering Education: A  Study on Mechanics-Focused Conceptual Understanding(https://arxiv.org/abs/2401.12983)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>This study is a pioneering endeavor to investigate the capabilities of Large Language Models (LLMs) in addressing conceptual questions within the domain of mechanical engineering with a focus on mechanics. Our examination involves a manually crafted exam encompassing 126 multiple-choice questions, spanning various aspects of mechanics courses, including Fluid Mechanics, Mechanical Vibration, Engineering Statics and Dynamics, Mechanics of Materials, Theory of Elasticity, and Continuum Mechanics. Three LLMs, including ChatGPT (GPT-3.5), ChatGPT (GPT-4), and Claude (Claude-2.1), were subjected to evaluation against engineering faculties and students with or without mechanical engineering background. The findings reveal GPT-4's superior performance over the other two LLMs and human cohorts in answering questions across various mechanics topics, except for Continuum Mechanics. This signals the potential future improvements for GPT models in handling symbolic calculations and tensor analyses. The performances of LLMs were all significantly improved with explanations prompted prior to direct responses, underscoring the crucial role of prompt engineering. Interestingly, GPT-3.5 demonstrates improved performance with prompts covering a broader domain, while GPT-4 excels with prompts focusing on specific subjects. Finally, GPT-4 exhibits notable advancements in mitigating input bias, as evidenced by guessing preferences for humans. This study unveils the substantial potential of LLMs as highly knowledgeable assistants in both mechanical pedagogy and scientific research.</li>
</ul>

<h3>Title: The Effect of Human v/s Synthetic Test Data and Round-tripping on  Assessment of Sentiment Analysis Systems for Bias</h3>
<ul>
<li><strong>Authors: </strong>Kausik Lakkaraju, Aniket Gupta, Biplav Srivastava, Marco Valtorta, Dezhi Wu</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.12985">https://arxiv.org/abs/2401.12985</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.12985">https://arxiv.org/pdf/2401.12985</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.12985]] The Effect of Human v/s Synthetic Test Data and Round-tripping on  Assessment of Sentiment Analysis Systems for Bias(https://arxiv.org/abs/2401.12985)</code><input type="text"></li>
<li><strong>Keywords: </strong>protect</a></li>
<li><strong>Abstract: </strong>Sentiment Analysis Systems (SASs) are data-driven Artificial Intelligence (AI) systems that output polarity and emotional intensity when given a piece of text as input. Like other AIs, SASs are also known to have unstable behavior when subjected to changes in data which can make it problematic to trust out of concerns like bias when AI works with humans and data has protected attributes like gender, race, and age. Recently, an approach was introduced to assess SASs in a blackbox setting without training data or code, and rating them for bias using synthetic English data. We augment it by introducing two human-generated chatbot datasets and also consider a round-trip setting of translating the data from one language to the same through an intermediate language. We find that these settings show SASs performance in a more realistic light. Specifically, we find that rating SASs on the chatbot data showed more bias compared to the synthetic data, and round-tripping using Spanish and Danish as intermediate languages reduces the bias (up to 68% reduction) in human-generated data while, in synthetic data, it takes a surprising turn by increasing the bias! Our findings will help researchers and practitioners refine their SAS testing strategies and foster trust as SASs are considered part of more mission-critical applications for global use.</li>
</ul>

<h3>Title: Few-Shot Learning for Chronic Disease Management: Leveraging Large  Language Models and Multi-Prompt Engineering with Medical Knowledge Injection</h3>
<ul>
<li><strong>Authors: </strong>Haoxin Liu, Wenli Zhang, Jiaheng Xie, Buomsoo Kim, Zhu Zhang, Yidong Chai</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.12988">https://arxiv.org/abs/2401.12988</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.12988">https://arxiv.org/pdf/2401.12988</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.12988]] Few-Shot Learning for Chronic Disease Management: Leveraging Large  Language Models and Multi-Prompt Engineering with Medical Knowledge Injection(https://arxiv.org/abs/2401.12988)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>This study harnesses state-of-the-art AI technology for chronic disease management, specifically in detecting various mental disorders through user-generated textual content. Existing studies typically rely on fully supervised machine learning, which presents challenges such as the labor-intensive manual process of annotating extensive training data for each disease and the need to design specialized deep learning architectures for each problem. To address such challenges, we propose a novel framework that leverages advanced AI techniques, including large language models and multi-prompt engineering. Specifically, we address two key technical challenges in data-driven chronic disease management: (1) developing personalized prompts to represent each user's uniqueness and (2) incorporating medical knowledge into prompts to provide context for chronic disease detection, instruct learning objectives, and operationalize prediction goals. We evaluate our method using four mental disorders, which are prevalent chronic diseases worldwide, as research cases. On the depression detection task, our method (F1 = 0.975~0.978) significantly outperforms traditional supervised learning paradigms, including feature engineering (F1 = 0.760) and architecture engineering (F1 = 0.756). Meanwhile, our approach demonstrates success in few-shot learning, i.e., requiring only a minimal number of training examples to detect chronic diseases based on user-generated textual content (i.e., only 2, 10, or 100 subjects). Moreover, our method can be generalized to other mental disorder detection tasks, including anorexia, pathological gambling, and self-harm (F1 = 0.919~0.978).</li>
</ul>

<h3>Title: Topic Modelling: Going Beyond Token Outputs</h3>
<ul>
<li><strong>Authors: </strong>Lowri Williams, Eirini Anthi, Laura Arman, Pete Burnap</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.12990">https://arxiv.org/abs/2401.12990</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.12990">https://arxiv.org/pdf/2401.12990</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.12990]] Topic Modelling: Going Beyond Token Outputs(https://arxiv.org/abs/2401.12990)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, interpretability</a></li>
<li><strong>Abstract: </strong>Topic modelling is a text mining technique for identifying salient themes from a number of documents. The output is commonly a set of topics consisting of isolated tokens that often co-occur in such documents. Manual effort is often associated with interpreting a topic's description from such tokens. However, from a human's perspective, such outputs may not adequately provide enough information to infer the meaning of the topics; thus, their interpretability is often inaccurately understood. Although several studies have attempted to automatically extend topic descriptions as a means of enhancing the interpretation of topic models, they rely on external language sources that may become unavailable, must be kept up-to-date to generate relevant results, and present privacy issues when training on or processing data. This paper presents a novel approach towards extending the output of traditional topic modelling methods beyond a list of isolated tokens. This approach removes the dependence on external sources by using the textual data itself by extracting high-scoring keywords and mapping them to the topic model's token outputs. To measure the interpretability of the proposed outputs against those of the traditional topic modelling approach, independent annotators manually scored each output based on their quality and usefulness, as well as the efficiency of the annotation task. The proposed approach demonstrated higher quality and usefulness, as well as higher efficiency in the annotation task, in comparison to the outputs of a traditional topic modelling method, demonstrating an increase in their interpretability.</li>
</ul>

<h3>Title: A Comparison of Veterans with Problematic Opioid Use Identified through  Natural Language Processing of Clinical Notes versus Using Diagnostic Codes</h3>
<ul>
<li><strong>Authors: </strong>Terri Elizabeth Workman, Joel Kupersmith, Phillip Ma, Christopher Spevak, Friedhelm Sandbrink, Yan Cheng Qing Zeng-Treitler</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.12996">https://arxiv.org/abs/2401.12996</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.12996">https://arxiv.org/pdf/2401.12996</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.12996]] A Comparison of Veterans with Problematic Opioid Use Identified through  Natural Language Processing of Clinical Notes versus Using Diagnostic Codes(https://arxiv.org/abs/2401.12996)</code><input type="text"></li>
<li><strong>Keywords: </strong>fair</a></li>
<li><strong>Abstract: </strong>Background: Electronic health records (EHRs) are a data source for opioid research. Opioid use disorder is known to be under-coded as a diagnosis, yet problematic opioid use can be documented in clinical notes. Objectives: Our goals were 1) to identify problematic opioid use from a full range of clinical notes; and 2) to compare the characteristics of patients identified as having problematic opioid use, exclusively documented in clinical notes, to those having documented ICD opioid use disorder diagnostic codes. Materials and Methods: We developed and applied a natural language processing (NLP) tool to the clinical notes of a patient cohort (n=222,371) from two Veteran Affairs service regions to identify patients with problematic opioid use. We also used a set of ICD diagnostic codes to identify patients with opioid use disorder from the same cohort. We compared the demographic and clinical characteristics of patients identified only through NLP, to those of patients identified through ICD codes. Results: NLP exclusively identified 57,331 patients; 6,997 patients had positive ICD code identifications. Patients exclusively identified through NLP were more likely to be women. Those identified through ICD codes were more likely to be male, younger, have concurrent benzodiazepine prescriptions, more comorbidities, more care encounters, and less likely to be married. Patients in the NLP and ICD groups had substantially elevated comorbidity levels compared to patients not documented as experiencing problematic opioid use. Conclusions: NLP is a feasible approach for identifying problematic opioid use not otherwise recorded by ICD codes. Clinicians may be reluctant to code for opioid use disorder. It is therefore incumbent on the healthcare team to search for documentation of opioid concerns within clinical notes.</li>
</ul>

<h3>Title: Evaluating and Enhancing Large Language Models Performance in  Domain-specific Medicine: Osteoarthritis Management with DocOA</h3>
<ul>
<li><strong>Authors: </strong>Xi Chen, MingKe You, Li Wang, WeiZhi Liu, Yu Fu, Jie Xu, Shaoting Zhang, Gang Chen, Jian Li</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.12998">https://arxiv.org/abs/2401.12998</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.12998">https://arxiv.org/pdf/2401.12998</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.12998]] Evaluating and Enhancing Large Language Models Performance in  Domain-specific Medicine: Osteoarthritis Management with DocOA(https://arxiv.org/abs/2401.12998)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>The efficacy of large language models (LLMs) in domain-specific medicine, particularly for managing complex diseases such as osteoarthritis (OA), remains largely unexplored. This study focused on evaluating and enhancing the clinical capabilities of LLMs in specific domains, using osteoarthritis (OA) management as a case study. A domain specific benchmark framework was developed, which evaluate LLMs across a spectrum from domain-specific knowledge to clinical applications in real-world clinical scenarios. DocOA, a specialized LLM tailored for OA management that integrates retrieval-augmented generation (RAG) and instruction prompts, was developed. The study compared the performance of GPT-3.5, GPT-4, and a specialized assistant, DocOA, using objective and human evaluations. Results showed that general LLMs like GPT-3.5 and GPT-4 were less effective in the specialized domain of OA management, particularly in providing personalized treatment recommendations. However, DocOA showed significant improvements. This study introduces a novel benchmark framework which assesses the domain-specific abilities of LLMs in multiple aspects, highlights the limitations of generalized LLMs in clinical contexts, and demonstrates the potential of tailored approaches for developing domain-specific medical LLMs.</li>
</ul>

<h3>Title: CCA: Collaborative Competitive Agents for Image Editing</h3>
<ul>
<li><strong>Authors: </strong>Tiankai Hang, Shuyang Gu, Dong Chen, Xin Geng, Baining Guo</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.13011">https://arxiv.org/abs/2401.13011</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.13011">https://arxiv.org/pdf/2401.13011</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.13011]] CCA: Collaborative Competitive Agents for Image Editing(https://arxiv.org/abs/2401.13011)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, generative, large language model</a></li>
<li><strong>Abstract: </strong>This paper presents a novel generative model, Collaborative Competitive Agents (CCA), which leverages the capabilities of multiple Large Language Models (LLMs) based agents to execute complex tasks. Drawing inspiration from Generative Adversarial Networks (GANs), the CCA system employs two equal-status generator agents and a discriminator agent. The generators independently process user instructions and generate results, while the discriminator evaluates the outputs, and provides feedback for the generator agents to further reflect and improve the generation results. Unlike the previous generative model, our system can obtain the intermediate steps of generation. This allows each generator agent to learn from other successful executions due to its transparency, enabling a collaborative competition that enhances the quality and robustness of the system's results. The primary focus of this study is image editing, demonstrating the CCA's ability to handle intricate instructions robustly. The paper's main contributions include the introduction of a multi-agent-based generative model with controllable intermediate steps and iterative optimization, a detailed examination of agent relationships, and comprehensive experiments on image editing. Code is available at \href{https://github.com/TiankaiHang/CCA}{https://github.com/TiankaiHang/CCA}.</li>
</ul>

<h3>Title: PA-SAM: Prompt Adapter SAM for High-Quality Image Segmentation</h3>
<ul>
<li><strong>Authors: </strong>Zhaozhi Xie, Bochen Guan, Weihao Jiang, Muyang Yi, Yue Ding, Hongtao Lu, Lei Zhang</a></li>
<li><strong>Subjects: </strong>cs.CV, eess.IV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.13051">https://arxiv.org/abs/2401.13051</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.13051">https://arxiv.org/pdf/2401.13051</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.13051]] PA-SAM: Prompt Adapter SAM for High-Quality Image Segmentation(https://arxiv.org/abs/2401.13051)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>The Segment Anything Model (SAM) has exhibited outstanding performance in various image segmentation tasks. Despite being trained with over a billion masks, SAM faces challenges in mask prediction quality in numerous scenarios, especially in real-world contexts. In this paper, we introduce a novel prompt-driven adapter into SAM, namely Prompt Adapter Segment Anything Model (PA-SAM), aiming to enhance the segmentation mask quality of the original SAM. By exclusively training the prompt adapter, PA-SAM extracts detailed information from images and optimizes the mask decoder feature at both sparse and dense prompt levels, improving the segmentation performance of SAM to produce high-quality masks. Experimental results demonstrate that our PA-SAM outperforms other SAM-based methods in high-quality, zero-shot, and open-set segmentation. We're making the source code and models available at https://github.com/xzz2/pa-sam.</li>
</ul>

<h3>Title: TCE at Qur'an QA 2023 Shared Task: Low Resource Enhanced  Transformer-based Ensemble Approach for Qur'anic QA</h3>
<ul>
<li><strong>Authors: </strong>Mohammed Alaa Elkomy, Amany Sarhan</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.13060">https://arxiv.org/abs/2401.13060</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.13060">https://arxiv.org/pdf/2401.13060</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.13060]] TCE at Qur'an QA 2023 Shared Task: Low Resource Enhanced  Transformer-based Ensemble Approach for Qur'anic QA(https://arxiv.org/abs/2401.13060)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>In this paper, we present our approach to tackle Qur'an QA 2023 shared tasks A and B. To address the challenge of low-resourced training data, we rely on transfer learning together with a voting ensemble to improve prediction stability across multiple runs. Additionally, we employ different architectures and learning mechanisms for a range of Arabic pre-trained transformer-based models for both tasks. To identify unanswerable questions, we propose using a thresholding mechanism. Our top-performing systems greatly surpass the baseline performance on the hidden split, achieving a MAP score of 25.05% for task A and a partial Average Precision (pAP) of 57.11% for task B.</li>
</ul>

<h3>Title: Local Background Estimation for Improved Gas Plume Identification in  Hyperspectral Images</h3>
<ul>
<li><strong>Authors: </strong>Scout Jarman, Zigfried Hampel-Arias, Adra Carr, Kevin R. Moon</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.13068">https://arxiv.org/abs/2401.13068</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.13068">https://arxiv.org/pdf/2401.13068</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.13068]] Local Background Estimation for Improved Gas Plume Identification in  Hyperspectral Images(https://arxiv.org/abs/2401.13068)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>Deep learning identification models have shown promise for identifying gas plumes in Longwave IR hyperspectral images of urban scenes, particularly when a large library of gases are being considered. Because many gases have similar spectral signatures, it is important to properly estimate the signal from a detected plume. Typically, a scene's global mean spectrum and covariance matrix are estimated to whiten the plume's signal, which removes the background's signature from the gas signature. However, urban scenes can have many different background materials that are spatially and spectrally heterogeneous. This can lead to poor identification performance when the global background estimate is not representative of a given local background material. We use image segmentation, along with an iterative background estimation algorithm, to create local estimates for the various background materials that reside underneath a gas plume. Our method outperforms global background estimation on a set of simulated and real gas plumes. This method shows promise in increasing deep learning identification confidence, while being simple and easy to tune when considering diverse plumes.</li>
</ul>

<h3>Title: PlaceFormer: Transformer-based Visual Place Recognition using  Multi-Scale Patch Selection and Fusion</h3>
<ul>
<li><strong>Authors: </strong>Shyam Sundar Kannan, Byung-Cheol Min</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.RO</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.13082">https://arxiv.org/abs/2401.13082</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.13082">https://arxiv.org/pdf/2401.13082</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.13082]] PlaceFormer: Transformer-based Visual Place Recognition using  Multi-Scale Patch Selection and Fusion(https://arxiv.org/abs/2401.13082)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Visual place recognition is a challenging task in the field of computer vision, and autonomous robotics and vehicles, which aims to identify a location or a place from visual inputs. Contemporary methods in visual place recognition employ convolutional neural networks and utilize every region within the image for the place recognition task. However, the presence of dynamic and distracting elements in the image may impact the effectiveness of the place recognition process. Therefore, it is meaningful to focus on task-relevant regions of the image for improved recognition. In this paper, we present PlaceFormer, a novel transformer-based approach for visual place recognition. PlaceFormer employs patch tokens from the transformer to create global image descriptors, which are then used for image retrieval. To re-rank the retrieved images, PlaceFormer merges the patch tokens from the transformer to form multi-scale patches. Utilizing the transformer's self-attention mechanism, it selects patches that correspond to task-relevant areas in an image. These selected patches undergo geometric verification, generating similarity scores across different patch sizes. Subsequently, spatial scores from each patch size are fused to produce a final similarity score. This score is then used to re-rank the images initially retrieved using global image descriptors. Extensive experiments on benchmark datasets demonstrate that PlaceFormer outperforms several state-of-the-art methods in terms of accuracy and computational efficiency, requiring less time and memory.</li>
</ul>

<h3>Title: Towards Trustable Language Models: Investigating Information Quality of  Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Rick Rejeleene, Xiaowei Xu, John Talburt</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.13086">https://arxiv.org/abs/2401.13086</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.13086">https://arxiv.org/pdf/2401.13086</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.13086]] Towards Trustable Language Models: Investigating Information Quality of  Large Language Models(https://arxiv.org/abs/2401.13086)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large language models (LLM) are generating information at a rapid pace, requiring users to increasingly rely and trust the data. Despite remarkable advances of LLM, Information generated by LLM is not completely trustworthy, due to challenges in information quality. Specifically, integrity of Information quality decreases due to unreliable, biased, tokenization during pre-training of LLM. Moreover, due to decreased information quality issues, has led towards hallucination, fabricated information. Unreliable information can lead towards flawed decisions in businesses, which impacts economic activity. In this work, we introduce novel mathematical information quality evaluation of LLM, we furthermore analyze and highlight information quality challenges, scaling laws to systematically scale language models.</li>
</ul>

<h3>Title: Digital Divides in Scene Recognition: Uncovering Socioeconomic Biases in  Deep Learning Systems</h3>
<ul>
<li><strong>Authors: </strong>Michelle R. Greene, Mariam Josyula, Wentao Si, Jennifer A. Hart</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.13097">https://arxiv.org/abs/2401.13097</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.13097">https://arxiv.org/pdf/2401.13097</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.13097]] Digital Divides in Scene Recognition: Uncovering Socioeconomic Biases in  Deep Learning Systems(https://arxiv.org/abs/2401.13097)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, fair</a></li>
<li><strong>Abstract: </strong>Computer-based scene understanding has influenced fields ranging from urban planning to autonomous vehicle performance, yet little is known about how well these technologies work across social differences. We investigate the biases of deep convolutional neural networks (dCNNs) in scene classification, using nearly one million images from global and US sources, including user-submitted home photographs and Airbnb listings. We applied statistical models to quantify the impact of socioeconomic indicators such as family income, Human Development Index (HDI), and demographic factors from public data sources (CIA and US Census) on dCNN performance. Our analyses revealed significant socioeconomic bias, where pretrained dCNNs demonstrated lower classification accuracy, lower classification confidence, and a higher tendency to assign labels that could be offensive when applied to homes (e.g., "ruin", "slum"), especially in images from homes with lower socioeconomic status (SES). This trend is consistent across two datasets of international images and within the diverse economic and racial landscapes of the United States. This research contributes to understanding biases in computer vision, emphasizing the need for more inclusive and representative training datasets. By mitigating the bias in the computer vision pipelines, we can ensure fairer and more equitable outcomes for applied computer vision, including home valuation and smart home security systems. There is urgency in addressing these biases, which can significantly impact critical decisions in urban development and resource allocation. Our findings also motivate the development of AI systems that better understand and serve diverse communities, moving towards technology that equitably benefits all sectors of society.</li>
</ul>

<h3>Title: Gravity-Informed Deep Learning Framework for Predicting Ship Traffic  Flow and Invasion Risk of Non-Indigenous Species via Ballast Water Discharge</h3>
<ul>
<li><strong>Authors: </strong>Ruixin Song, Gabriel Spadon, Sarah Bailey, Ronald Pelot, Stan Matwin, Amilcar Soares</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.SI, stat.AP</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.13098">https://arxiv.org/abs/2401.13098</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.13098">https://arxiv.org/pdf/2401.13098</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.13098]] Gravity-Informed Deep Learning Framework for Predicting Ship Traffic  Flow and Invasion Risk of Non-Indigenous Species via Ballast Water Discharge(https://arxiv.org/abs/2401.13098)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer, segmentation</a></li>
<li><strong>Abstract: </strong>Invasive species in water bodies pose a major threat to the environment and biodiversity globally. Due to increased transportation and trade, non-native species have been introduced to new environments, causing damage to ecosystems and leading to economic losses in agriculture, forestry, and fisheries. Therefore, there is a pressing need for risk assessment and management techniques to mitigate the impact of these invasions. This study aims to develop a new physics-inspired model to forecast maritime shipping traffic and thus inform risk assessment of invasive species spread through global transportation networks. Inspired by the gravity model for international trades, our model considers various factors that influence the likelihood and impact of vessel activities, such as shipping flux density, distance between ports, trade flow, and centrality measures of transportation hubs. Additionally, by analyzing the risk network of invasive species, we provide a comprehensive framework for assessing the invasion threat level given a pair of origin and destination. Accordingly, this paper introduces transformers to gravity models to rebuild the short- and long-term dependencies that make the risk analysis feasible. Thus, we introduce a physics-inspired framework that achieves an 89% segmentation accuracy for existing and non-existing trajectories and an 84.8% accuracy for the number of vessels flowing between key port areas, representing more than 10% improvement over the traditional deep-gravity model. Along these lines, this research contributes to a better understanding of invasive species risk assessment. It allows policymakers, conservationists, and stakeholders to prioritize management actions by identifying high-risk invasion pathways. Besides, our model is versatile and can include new data sources, making it suitable for assessing species invasion risks in a changing global landscape.</li>
</ul>

<h3>Title: Sparse identification of nonlinear dynamics in the presence of library  and system uncertainty</h3>
<ul>
<li><strong>Authors: </strong>Andrew O'Brien</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.13099">https://arxiv.org/abs/2401.13099</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.13099">https://arxiv.org/pdf/2401.13099</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.13099]] Sparse identification of nonlinear dynamics in the presence of library  and system uncertainty(https://arxiv.org/abs/2401.13099)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>The SINDy algorithm has been successfully used to identify the governing equations of dynamical systems from time series data. However, SINDy assumes the user has prior knowledge of the variables in the system and of a function library that can act as a basis for the system. In this paper, we demonstrate on real world data how the Augmented SINDy algorithm outperforms SINDy in the presence of system variable uncertainty. We then show SINDy can be further augmented to perform robustly when both kinds of uncertainty are present.</li>
</ul>

<h3>Title: Contractive Diffusion Probabilistic Models</h3>
<ul>
<li><strong>Authors: </strong>Wenpin Tang, Hanyang Zhao</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.13115">https://arxiv.org/abs/2401.13115</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.13115">https://arxiv.org/pdf/2401.13115</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.13115]] Contractive Diffusion Probabilistic Models(https://arxiv.org/abs/2401.13115)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, diffusion, generative</a></li>
<li><strong>Abstract: </strong>Diffusion probabilistic models (DPMs) have emerged as a promising technology in generative modeling. The success of DPMs relies on two ingredients: time reversal of Markov diffusion processes and score matching. Most existing work implicitly assumes that score matching is close to perfect, while this assumption is questionable. In view of possibly unguaranteed score matching, we propose a new criterion -- the contraction of backward sampling in the design of DPMs. This leads to a novel class of contractive DPMs (CDPMs), including contractive Ornstein-Uhlenbeck (OU) processes and contractive sub-variance preserving (sub-VP) stochastic differential equations (SDEs). The key insight is that the contraction in the backward process narrows score matching errors, as well as discretization error. Thus, the proposed CDPMs are robust to both sources of error. Our proposal is supported by theoretical results, and is corroborated by experiments. Notably, contractive sub-VP shows the best performance among all known SDE-based DPMs on the CIFAR-10 dataset.</li>
</ul>

<h3>Title: Seed-Guided Fine-Grained Entity Typing in Science and Engineering  Domains</h3>
<ul>
<li><strong>Authors: </strong>Yu Zhang, Yunyi Zhang, Yanzhen Shen, Yu Deng, Lucian Popa, Larisa Shwartz, ChengXiang Zhai, Jiawei Han</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.SE</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.13129">https://arxiv.org/abs/2401.13129</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.13129">https://arxiv.org/pdf/2401.13129</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.13129]] Seed-Guided Fine-Grained Entity Typing in Science and Engineering  Domains(https://arxiv.org/abs/2401.13129)</code><input type="text"></li>
<li><strong>Keywords: </strong>security</a></li>
<li><strong>Abstract: </strong>Accurately typing entity mentions from text segments is a fundamental task for various natural language processing applications. Many previous approaches rely on massive human-annotated data to perform entity typing. Nevertheless, collecting such data in highly specialized science and engineering domains (e.g., software engineering and security) can be time-consuming and costly, without mentioning the domain gaps between training and inference data if the model needs to be applied to confidential datasets. In this paper, we study the task of seed-guided fine-grained entity typing in science and engineering domains, which takes the name and a few seed entities for each entity type as the only supervision and aims to classify new entity mentions into both seen and unseen types (i.e., those without seed entities). To solve this problem, we propose SEType which first enriches the weak supervision by finding more entities for each seen type from an unlabeled corpus using the contextualized representations of pre-trained language models. It then matches the enriched entities to unlabeled text to get pseudo-labeled samples and trains a textual entailment model that can make inferences for both seen and unseen types. Extensive experiments on two datasets covering four domains demonstrate the effectiveness of SEType in comparison with various baselines.</li>
</ul>

<h3>Title: Analyzing COVID-19 Vaccination Sentiments in Nigerian Cyberspace:  Insights from a Manually Annotated Twitter Dataset</h3>
<ul>
<li><strong>Authors: </strong>Ibrahim Said Ahmad, Lukman Jibril Aliyu, Abubakar Auwal Khalid, Saminu Muhammad Aliyu, Shamsuddeen Hassan Muhammad, Idris Abdulmumin, Bala Mairiga Abduljalil, Bello Shehu Bello, Amina Imam Abubakar</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.SI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.13133">https://arxiv.org/abs/2401.13133</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.13133">https://arxiv.org/pdf/2401.13133</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.13133]] Analyzing COVID-19 Vaccination Sentiments in Nigerian Cyberspace:  Insights from a Manually Annotated Twitter Dataset(https://arxiv.org/abs/2401.13133)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Numerous successes have been achieved in combating the COVID-19 pandemic, initially using various precautionary measures like lockdowns, social distancing, and the use of face masks. More recently, various vaccinations have been developed to aid in the prevention or reduction of the severity of the COVID-19 infection. Despite the effectiveness of the precautionary measures and the vaccines, there are several controversies that are massively shared on social media platforms like Twitter. In this paper, we explore the use of state-of-the-art transformer-based language models to study people's acceptance of vaccines in Nigeria. We developed a novel dataset by crawling multi-lingual tweets using relevant hashtags and keywords. Our analysis and visualizations revealed that most tweets expressed neutral sentiments about COVID-19 vaccines, with some individuals expressing positive views, and there was no strong preference for specific vaccine types, although Moderna received slightly more positive sentiment. We also found out that fine-tuning a pre-trained LLM with an appropriate dataset can yield competitive results, even if the LLM was not initially pre-trained on the specific language of that dataset.</li>
</ul>

<h3>Title: The Language Barrier: Dissecting Safety Challenges of LLMs in  Multilingual Contexts</h3>
<ul>
<li><strong>Authors: </strong>Lingfeng Shen, Weiting Tan, Sihao Chen, Yunmo Chen, Jingyu Zhang, Haoran Xu, Boyuan Zheng, Philipp Koehn, Daniel Khashabi</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.13136">https://arxiv.org/abs/2401.13136</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.13136">https://arxiv.org/pdf/2401.13136</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.13136]] The Language Barrier: Dissecting Safety Challenges of LLMs in  Multilingual Contexts(https://arxiv.org/abs/2401.13136)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>As the influence of large language models (LLMs) spans across global communities, their safety challenges in multilingual settings become paramount for alignment research. This paper examines the variations in safety challenges faced by LLMs across different languages and discusses approaches to alleviating such concerns. By comparing how state-of-the-art LLMs respond to the same set of malicious prompts written in higher- vs. lower-resource languages, we observe that (1) LLMs tend to generate unsafe responses much more often when a malicious prompt is written in a lower-resource language, and (2) LLMs tend to generate more irrelevant responses to malicious prompts in lower-resource languages. To understand where the discrepancy can be attributed, we study the effect of instruction tuning with reinforcement learning from human feedback (RLHF) or supervised finetuning (SFT) on the HH-RLHF dataset. Surprisingly, while training with high-resource languages improves model alignment, training in lower-resource languages yields minimal improvement. This suggests that the bottleneck of cross-lingual alignment is rooted in the pretraining stage. Our findings highlight the challenges in cross-lingual LLM safety, and we hope they inform future research in this direction.</li>
</ul>

<h3>Title: SpacTor-T5: Pre-training T5 Models with Span Corruption and Replaced  Token Detection</h3>
<ul>
<li><strong>Authors: </strong>Ke Ye, Heinrich Jiang, Afshin Rostamizadeh, Ayan Chakrabarti, Giulia DeSalvo, Jean-François Kagy, Lazaros Karydas, Gui Citovsky, Sanjiv Kumar</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.13160">https://arxiv.org/abs/2401.13160</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.13160">https://arxiv.org/pdf/2401.13160</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.13160]] SpacTor-T5: Pre-training T5 Models with Span Corruption and Replaced  Token Detection(https://arxiv.org/abs/2401.13160)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Pre-training large language models is known to be extremely resource intensive and often times inefficient, under-utilizing the information encapsulated in the training text sequences. In this paper, we present SpacTor, a new training procedure consisting of (1) a hybrid objective combining span corruption (SC) and token replacement detection (RTD), and (2) a two-stage curriculum that optimizes the hybrid objective over the initial $\tau$ iterations, then transitions to standard SC loss. We show empirically that the effectiveness of the hybrid objective is tied to the two-stage pre-training schedule, and provide extensive analysis on why this is the case. In our experiments with encoder-decoder architectures (T5) on a variety of NLP tasks, SpacTor-T5 yields the same downstream performance as standard SC pre-training, while enabling a 50% reduction in pre-training iterations and 40% reduction in total FLOPs. Alternatively, given the same amount of computing budget, we find that SpacTor results in significantly improved downstream benchmark performance.</li>
</ul>

<h3>Title: A Generalized Multiscale Bundle-Based Hyperspectral Sparse Unmixing  Algorithm</h3>
<ul>
<li><strong>Authors: </strong>Luciano Carvalho Ayres, Ricardo Augusto Borsoi, José Carlos Moreira Bermudez, Sérgio José Melo de Almeida</a></li>
<li><strong>Subjects: </strong>cs.CV, eess.SP</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.13161">https://arxiv.org/abs/2401.13161</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.13161">https://arxiv.org/pdf/2401.13161</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.13161]] A Generalized Multiscale Bundle-Based Hyperspectral Sparse Unmixing  Algorithm(https://arxiv.org/abs/2401.13161)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>In hyperspectral sparse unmixing, a successful approach employs spectral bundles to address the variability of the endmembers in the spatial domain. However, the regularization penalties usually employed aggregate substantial computational complexity, and the solutions are very noise-sensitive. We generalize a multiscale spatial regularization approach to solve the unmixing problem by incorporating group sparsity-inducing mixed norms. Then, we propose a noise-robust method that can take advantage of the bundle structure to deal with endmember variability while ensuring inter- and intra-class sparsity in abundance estimation with reasonable computational cost. We also present a general heuristic to select the \emph{most representative} abundance estimation over multiple runs of the unmixing process, yielding a solution that is robust and highly reproducible. Experiments illustrate the robustness and consistency of the results when compared to related methods.</li>
</ul>

<h3>Title: A Repository-Level Dataset For Detecting, Classifying and Repairing  Software Vulnerabilities</h3>
<ul>
<li><strong>Authors: </strong>Xinchen Wang, Ruida Hu, Cuiyun Gao, Xin-Cheng Wen, Yujia Chen, Qing Liao</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.SE</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.13169">https://arxiv.org/abs/2401.13169</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.13169">https://arxiv.org/pdf/2401.13169</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.13169]] A Repository-Level Dataset For Detecting, Classifying and Repairing  Software Vulnerabilities(https://arxiv.org/abs/2401.13169)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, extraction, large language model</a></li>
<li><strong>Abstract: </strong>Open-Source Software (OSS) vulnerabilities bring great challenges to the software security and pose potential risks to our society. Enormous efforts have been devoted into automated vulnerability detection, among which deep learning (DL)-based approaches have proven to be the most effective. However, the current labeled data present the following limitations: (1) \textbf{Tangled Patches}: Developers may submit code changes unrelated to vulnerability fixes within patches, leading to tangled patches. (2) \textbf{Lacking Inter-procedural Vulnerabilities}: The existing vulnerability datasets typically contain function-level and file-level vulnerabilities, ignoring the relations between functions, thus rendering the approaches unable to detect the inter-procedural vulnerabilities. (3) \textbf{Outdated Patches}: The existing datasets usually contain outdated patches, which may bias the model during training. To address the above limitations, in this paper, we propose an automated data collection framework and construct the first repository-level high-quality vulnerability dataset named \textbf{ReposVul}. The proposed framework mainly contains three modules: (1) A vulnerability untangling module, aiming at distinguishing vulnerability-fixing related code changes from tangled patches, in which the Large Language Models (LLMs) and static analysis tools are jointly employed. (2) A multi-granularity dependency extraction module, aiming at capturing the inter-procedural call relationships of vulnerabilities, in which we construct multiple-granularity information for each vulnerability patch, including repository-level, file-level, function-level, and line-level. (3) A trace-based filtering module, aiming at filtering the outdated patches, which leverages the file path trace-based filter and commit time trace-based filter to construct an up-to-date dataset.</li>
</ul>

<h3>Title: CFMatch: Aligning Automated Answer Equivalence Evaluation with Expert  Judgments For Open-Domain Question Answering</h3>
<ul>
<li><strong>Authors: </strong>Zongxia Li, Ishani Mondal, Yijun Liang, Huy Nghiem, Jordan Boyd-Graber</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.13170">https://arxiv.org/abs/2401.13170</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.13170">https://arxiv.org/pdf/2401.13170</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.13170]] CFMatch: Aligning Automated Answer Equivalence Evaluation with Expert  Judgments For Open-Domain Question Answering(https://arxiv.org/abs/2401.13170)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, large language model</a></li>
<li><strong>Abstract: </strong>Question answering (QA) can only make progress if we know if an answer is correct, but for many of the most challenging and interesting QA examples, current evaluation metrics to determine answer equivalence (AE) often do not align with human judgments, particularly more verbose, free-form answers from large language models (LLM). There are two challenges: a lack of data and that models are too big: LLM-based scorers can correlate better with human judges, but this task has only been tested on limited QA datasets, and even when available, update of the model is limited because LLMs are large and often expensive. We rectify both of these issues by providing clear and consistent guidelines for evaluating AE in machine QA adopted from professional human QA contests. We also introduce a combination of standard evaluation and a more efficient, robust, and lightweight discriminate AE classifier-based matching method (CFMatch, smaller than 1 MB), trained and validated to more accurately evaluate answer correctness in accordance with adopted expert AE rules that are more aligned with human judgments.</li>
</ul>

<h3>Title: Compositional Generative Inverse Design</h3>
<ul>
<li><strong>Authors: </strong>Tailin Wu, Takashi Maruyama, Long Wei, Tao Zhang, Yilun Du, Gianluca Iaccarino, Jure Leskovec</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CE</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.13171">https://arxiv.org/abs/2401.13171</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.13171">https://arxiv.org/pdf/2401.13171</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.13171]] Compositional Generative Inverse Design(https://arxiv.org/abs/2401.13171)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, generative</a></li>
<li><strong>Abstract: </strong>Inverse design, where we seek to design input variables in order to optimize an underlying objective function, is an important problem that arises across fields such as mechanical engineering to aerospace engineering. Inverse design is typically formulated as an optimization problem, with recent works leveraging optimization across learned dynamics models. However, as models are optimized they tend to fall into adversarial modes, preventing effective sampling. We illustrate that by instead optimizing over the learned energy function captured by the diffusion model, we can avoid such adversarial examples and significantly improve design performance. We further illustrate how such a design system is compositional, enabling us to combine multiple different diffusion models representing subcomponents of our desired system to design systems with every specified component. In an N-body interaction task and a challenging 2D multi-airfoil design task, we demonstrate that by composing the learned diffusion model at test time, our method allows us to design initial states and boundary shapes that are more complex than those in the training data. Our method outperforms state-of-the-art neural inverse design method by an average of 41.5% in prediction MAE and 14.3% in design objective for the N-body dataset and discovers formation flying to minimize drag in the multi-airfoil design task. Project website and code can be found at https://github.com/AI4Science-WestlakeU/cindm.</li>
</ul>

<h3>Title: Boundary and Relation Distillation for Semantic Segmentation</h3>
<ul>
<li><strong>Authors: </strong>Dong Zhang, Pingcheng Dong, Xinting Hu, Long Chen, Kwang-Ting Cheng</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.13174">https://arxiv.org/abs/2401.13174</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.13174">https://arxiv.org/pdf/2401.13174</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.13174]] Boundary and Relation Distillation for Semantic Segmentation(https://arxiv.org/abs/2401.13174)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>Recently, it has been revealed that small semantic segmentation (SS) models exhibit a tendency to make errors in maintaining boundary region completeness and preserving target region connectivity, despite their effective segmentation of the main object regions. To address these errors, we propose a targeted boundary and relation distillation (BRD) strategy using knowledge distillation from large teacher models to small student models. Specifically, the boundary distillation extracts explicit object boundaries from the hierarchical feature maps of the backbone network, subsequently enhancing the student model's mask quality in boundary regions. Concurrently, the relation distillation transfers implicit relations from the teacher model to the student model using pixel-level self-relation as a bridge, ensuring that the student's mask has strong target region connectivity. The proposed BRD is designed concretely for SS and is characterized by simplicity and efficiency. Through experimental evaluations on multiple SS datasets, including Pascal VOC 2012, Cityscapes, ADE20K, and COCO-Stuff 10K, we demonstrated that BRD significantly surpasses the current methods without increasing the inference costs, generating crisp region boundaries and smooth connecting regions that are challenging for small models.</li>
</ul>

<h3>Title: AgentBoard: An Analytical Evaluation Board of Multi-turn LLM Agents</h3>
<ul>
<li><strong>Authors: </strong>Chang Ma, Junlei Zhang, Zhihao Zhu, Cheng Yang, Yujiu Yang, Yaohui Jin, Zhenzhong Lan, Lingpeng Kong, Junxian He</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.13178">https://arxiv.org/abs/2401.13178</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.13178">https://arxiv.org/pdf/2401.13178</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.13178]] AgentBoard: An Analytical Evaluation Board of Multi-turn LLM Agents(https://arxiv.org/abs/2401.13178)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability, large language model</a></li>
<li><strong>Abstract: </strong>Evaluating large language models (LLMs) as general-purpose agents is essential for understanding their capabilities and facilitating their integration into practical applications. However, the evaluation process presents substantial challenges. A primary obstacle is the benchmarking of agent performance across diverse scenarios within a unified framework, especially in maintaining partially-observable environments and ensuring multi-round interactions. Moreover, current evaluation frameworks mostly focus on the final success rate, revealing few insights during the process and failing to provide a deep understanding of the model abilities. To address these challenges, we introduce AgentBoard, a pioneering comprehensive benchmark and accompanied open-source evaluation framework tailored to analytical evaluation of LLM agents. AgentBoard offers a fine-grained progress rate metric that captures incremental advancements as well as a comprehensive evaluation toolkit that features easy assessment of agents for multi-faceted analysis through interactive visualization. This not only sheds light on the capabilities and limitations of LLM agents but also propels the interpretability of their performance to the forefront. Ultimately, AgentBoard serves as a significant step towards demystifying agent behaviors and accelerating the development of stronger LLM agents.</li>
</ul>

<h3>Title: Towards Multi-domain Face Landmark Detection with Synthetic Data from  Diffusion model</h3>
<ul>
<li><strong>Authors: </strong>Yuanming Li, Gwantae Kim, Jeong-gi Kwak, Bon-hwa Ku, Hanseok Ko</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.13191">https://arxiv.org/abs/2401.13191</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.13191">https://arxiv.org/pdf/2401.13191</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.13191]] Towards Multi-domain Face Landmark Detection with Synthetic Data from  Diffusion model(https://arxiv.org/abs/2401.13191)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>Recently, deep learning-based facial landmark detection for in-the-wild faces has achieved significant improvement. However, there are still challenges in face landmark detection in other domains (e.g. cartoon, caricature, etc). This is due to the scarcity of extensively annotated training data. To tackle this concern, we design a two-stage training approach that effectively leverages limited datasets and the pre-trained diffusion model to obtain aligned pairs of landmarks and face in multiple domains. In the first stage, we train a landmark-conditioned face generation model on a large dataset of real faces. In the second stage, we fine-tune the above model on a small dataset of image-landmark pairs with text prompts for controlling the domain. Our new designs enable our method to generate high-quality synthetic paired datasets from multiple domains while preserving the alignment between landmarks and facial features. Finally, we fine-tuned a pre-trained face landmark detection model on the synthetic dataset to achieve multi-domain face landmark detection. Our qualitative and quantitative results demonstrate that our method outperforms existing methods on multi-domain face landmark detection.</li>
</ul>

<h3>Title: Catch-Up Mix: Catch-Up Class for Struggling Filters in CNN</h3>
<ul>
<li><strong>Authors: </strong>Minsoo Kang, Minkoo Kang, Suhyun Kim</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.13193">https://arxiv.org/abs/2401.13193</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.13193">https://arxiv.org/pdf/2401.13193</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.13193]] Catch-Up Mix: Catch-Up Class for Struggling Filters in CNN(https://arxiv.org/abs/2401.13193)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Deep learning has made significant advances in computer vision, particularly in image classification tasks. Despite their high accuracy on training data, deep learning models often face challenges related to complexity and overfitting. One notable concern is that the model often relies heavily on a limited subset of filters for making predictions. This dependency can result in compromised generalization and an increased vulnerability to minor variations. While regularization techniques like weight decay, dropout, and data augmentation are commonly used to address this issue, they may not directly tackle the reliance on specific filters. Our observations reveal that the heavy reliance problem gets severe when slow-learning filters are deprived of learning opportunities due to fast-learning filters. Drawing inspiration from image augmentation research that combats over-reliance on specific image regions by removing and replacing parts of images, our idea is to mitigate the problem of over-reliance on strong filters by substituting highly activated features. To this end, we present a novel method called Catch-up Mix, which provides learning opportunities to a wide range of filters during training, focusing on filters that may lag behind. By mixing activation maps with relatively lower norms, Catch-up Mix promotes the development of more diverse representations and reduces reliance on a small subset of filters. Experimental results demonstrate the superiority of our method in various vision classification datasets, providing enhanced robustness.</li>
</ul>

<h3>Title: MLLMReID: Multimodal Large Language Model-based Person Re-identification</h3>
<ul>
<li><strong>Authors: </strong>Shan Yang, Yongfei Zhang</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.13201">https://arxiv.org/abs/2401.13201</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.13201">https://arxiv.org/pdf/2401.13201</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.13201]] MLLMReID: Multimodal Large Language Model-based Person Re-identification(https://arxiv.org/abs/2401.13201)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Multimodal large language models (MLLM) have achieved satisfactory results in many tasks. However, their performance in the task of person re-identification (ReID) has not been explored to date. This paper will investigate how to adapt them for the task of ReID. An intuitive idea is to fine-tune MLLM with ReID image-text datasets, and then use their visual encoder as a backbone for ReID. However, there still exist two apparent issues: (1) Designing instructions for ReID, MLLMs may overfit specific instructions, and designing a variety of instructions will lead to higher costs. (2) Latent image feature vectors from LLMs are not involved in loss computation. Instructional learning, aligning image-text features, results in indirect optimization and a learning objective that inadequately utilizes features, limiting effectiveness in person feature learning. To address these problems, this paper proposes MLLMReID: Multimodal Large Language Model-based ReID. Firstly, we proposed Common Instruction, a simple approach that leverages the essence ability of LLMs to continue writing, avoiding complex and diverse instruction design. Secondly, we proposed DirectReID, which effectively employs the latent image feature vectors of images outputted by LLMs in ReID tasks. The experimental results demonstrate the superiority of our method. We will open-source the code on GitHub.</li>
</ul>

<h3>Title: Boosting the Transferability of Adversarial Examples via Local Mixup and  Adaptive Step Size</h3>
<ul>
<li><strong>Authors: </strong>Junlin Liu, Xinchen Lyu</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.13205">https://arxiv.org/abs/2401.13205</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.13205">https://arxiv.org/pdf/2401.13205</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.13205]] Boosting the Transferability of Adversarial Examples via Local Mixup and  Adaptive Step Size(https://arxiv.org/abs/2401.13205)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, generative</a></li>
<li><strong>Abstract: </strong>Adversarial examples are one critical security threat to various visual applications, where injected human-imperceptible perturbations can confuse the output.Generating transferable adversarial examples in the black-box setting is crucial but challenging in practice. Existing input-diversity-based methods adopt different image transformations, but may be inefficient due to insufficient input diversity and an identical perturbation step size. Motivated by the fact that different image regions have distinctive weights in classification, this paper proposes a black-box adversarial generative framework by jointly designing enhanced input diversity and adaptive step sizes. We design local mixup to randomly mix a group of transformed adversarial images, strengthening the input diversity. For precise adversarial generation, we project the perturbation into the $tanh$ space to relax the boundary constraint. Moreover, the step sizes of different regions can be dynamically adjusted by integrating a second-order momentum.Extensive experiments on ImageNet validate that our framework can achieve superior transferability compared to state-of-the-art baselines.</li>
</ul>

<h3>Title: Multitask Active Learning for Graph Anomaly Detection</h3>
<ul>
<li><strong>Authors: </strong>Wenjing Chang, Kay Liu, Kaize Ding, Philip S. Yu, Jianjun Yu</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.SI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.13210">https://arxiv.org/abs/2401.13210</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.13210">https://arxiv.org/pdf/2401.13210</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.13210]] Multitask Active Learning for Graph Anomaly Detection(https://arxiv.org/abs/2401.13210)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, robust</a></li>
<li><strong>Abstract: </strong>In the web era, graph machine learning has been widely used on ubiquitous graph-structured data. As a pivotal component for bolstering web security and enhancing the robustness of graph-based applications, the significance of graph anomaly detection is continually increasing. While Graph Neural Networks (GNNs) have demonstrated efficacy in supervised and semi-supervised graph anomaly detection, their performance is contingent upon the availability of sufficient ground truth labels. The labor-intensive nature of identifying anomalies from complex graph structures poses a significant challenge in real-world applications. Despite that, the indirect supervision signals from other tasks (e.g., node classification) are relatively abundant. In this paper, we propose a novel MultItask acTIve Graph Anomaly deTEction framework, namely MITIGATE. Firstly, by coupling node classification tasks, MITIGATE obtains the capability to detect out-of-distribution nodes without known anomalies. Secondly, MITIGATE quantifies the informativeness of nodes by the confidence difference across tasks, allowing samples with conflicting predictions to provide informative yet not excessively challenging information for subsequent training. Finally, to enhance the likelihood of selecting representative nodes that are distant from known patterns, MITIGATE adopts a masked aggregation mechanism for distance measurement, considering both inherent features of nodes and current labeled status. Empirical studies on four datasets demonstrate that MITIGATE significantly outperforms the state-of-the-art methods for anomaly detection. Our code is publicly available at: https://github.com/AhaChang/MITIGATE.</li>
</ul>

<h3>Title: AdCorDA: Classifier Refinement via Adversarial Correction and Domain  Adaptation</h3>
<ul>
<li><strong>Authors: </strong>Lulan Shen, Ali Edalati, Brett Meyer, Warren Gross, James J. Clark</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.13212">https://arxiv.org/abs/2401.13212</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.13212">https://arxiv.org/pdf/2401.13212</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.13212]] AdCorDA: Classifier Refinement via Adversarial Correction and Domain  Adaptation(https://arxiv.org/abs/2401.13212)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack, robust</a></li>
<li><strong>Abstract: </strong>This paper describes a simple yet effective technique for refining a pretrained classifier network. The proposed AdCorDA method is based on modification of the training set and making use of the duality between network weights and layer inputs. We call this input space training. The method consists of two stages - adversarial correction followed by domain adaptation. Adversarial correction uses adversarial attacks to correct incorrect training-set classifications. The incorrectly classified samples of the training set are removed and replaced with the adversarially corrected samples to form a new training set, and then, in the second stage, domain adaptation is performed back to the original training set. Extensive experimental validations show significant accuracy boosts of over 5% on the CIFAR-100 dataset. The technique can be straightforwardly applied to refinement of weight-quantized neural networks, where experiments show substantial enhancement in performance over the baseline. The adversarial correction technique also results in enhanced robustness to adversarial attacks.</li>
</ul>

<h3>Title: On Principled Local Optimization Methods for Federated Learning</h3>
<ul>
<li><strong>Authors: </strong>Honglin Yuan</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.DC, math.OC, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.13216">https://arxiv.org/abs/2401.13216</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.13216">https://arxiv.org/pdf/2401.13216</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.13216]] On Principled Local Optimization Methods for Federated Learning(https://arxiv.org/abs/2401.13216)</code><input type="text"></li>
<li><strong>Keywords: </strong>federate</a></li>
<li><strong>Abstract: </strong>Federated Learning (FL), a distributed learning paradigm that scales on-device learning collaboratively, has emerged as a promising approach for decentralized AI applications. Local optimization methods such as Federated Averaging (FedAvg) are the most prominent methods for FL applications. Despite their simplicity and popularity, the theoretical understanding of local optimization methods is far from clear. This dissertation aims to advance the theoretical foundation of local methods in the following three directions. First, we establish sharp bounds for FedAvg, the most popular algorithm in Federated Learning. We demonstrate how FedAvg may suffer from a notion we call iterate bias, and how an additional third-order smoothness assumption may mitigate this effect and lead to better convergence rates. We explain this phenomenon from a Stochastic Differential Equation (SDE) perspective. Second, we propose Federated Accelerated Stochastic Gradient Descent (FedAc), the first principled acceleration of FedAvg, which provably improves the convergence rate and communication efficiency. Our technique uses on a potential-based perturbed iterate analysis, a novel stability analysis of generalized accelerated SGD, and a strategic tradeoff between acceleration and stability. Third, we study the Federated Composite Optimization problem, which extends the classic smooth setting by incorporating a shared non-smooth regularizer. We show that direct extensions of FedAvg may suffer from the "curse of primal averaging," resulting in slow convergence. As a solution, we propose a new primal-dual algorithm, Federated Dual Averaging, which overcomes the curse of primal averaging by employing a novel inter-client dual averaging procedure.</li>
</ul>

<h3>Title: ULTRA: Unleash LLMs' Potential for Event Argument Extraction through  Hierarchical Modeling and Pair-wise Refinement</h3>
<ul>
<li><strong>Authors: </strong>Xinliang Frederick Zhang, Carter Blum, Temma Choji, Shalin Shah, Alakananda Vempala</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.13218">https://arxiv.org/abs/2401.13218</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.13218">https://arxiv.org/pdf/2401.13218</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.13218]] ULTRA: Unleash LLMs' Potential for Event Argument Extraction through  Hierarchical Modeling and Pair-wise Refinement(https://arxiv.org/abs/2401.13218)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction, large language model</a></li>
<li><strong>Abstract: </strong>Structural extraction of events within discourse is critical since it avails a deeper understanding of communication patterns and behavior trends. Event argument extraction (EAE), at the core of event-centric understanding, is the task of identifying role-specific text spans (i.e., arguments) for a given event. Document-level EAE (DocEAE) focuses on arguments that are scattered across an entire document. In this work, we explore the capabilities of open source Large Language Models (LLMs), i.e., Flan-UL2, for the DocEAE task. To this end, we propose ULTRA, a hierarchical framework that extracts event arguments more cost-effectively -- the method needs as few as 50 annotations and doesn't require hitting costly API endpoints. Further, it alleviates the positional bias issue intrinsic to LLMs. ULTRA first sequentially reads text chunks of a document to generate a candidate argument set, upon which ULTRA learns to drop non-pertinent candidates through self-refinement. We further introduce LEAFER to address the challenge LLMs face in locating the exact boundary of an argument span. ULTRA outperforms strong baselines, which include strong supervised models and ChatGPT, by 9.8% when evaluated by the exact match (EM) metric.</li>
</ul>

<h3>Title: TAT-LLM: A Specialized Language Model for Discrete Reasoning over  Tabular and Textual Data</h3>
<ul>
<li><strong>Authors: </strong>Fengbin Zhu, Ziyang Liu, Fuli Feng, Chao Wang, Moxin Li, Tat-Seng Chua</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.13223">https://arxiv.org/abs/2401.13223</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.13223">https://arxiv.org/pdf/2401.13223</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.13223]] TAT-LLM: A Specialized Language Model for Discrete Reasoning over  Tabular and Textual Data(https://arxiv.org/abs/2401.13223)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, large language model</a></li>
<li><strong>Abstract: </strong>In this work, we address question answering (QA) over a hybrid of tabular and textual data that are very common content on the Web (e.g. SEC filings), where discrete reasoning capabilities are often required. Recently, large language models (LLMs) like GPT-4 have demonstrated strong multi-step reasoning capabilities. We then consider harnessing the amazing power of LLMs to solve our task. We abstract a Step-wise Pipeline for tabular and textual QA, which consists of three key steps, including Extractor, Reasoner and Executor, and initially design an instruction to instantiate the pipeline and validate that GPT-4 outperforms all existing methods. However, utilizing an online LLM like GPT-4 holds various challenges in terms of cost, latency, and data security risk, which motivates us to specialize smaller LLMs in this task. We develop a TAT-LLM language model by fine-tuning LLaMA 2 with the training data generated automatically from existing expert-annotated datasets following the Step-wise Pipeline. The experimental results have verified that our TAT-LLM model can outperform all baseline models, including the previous best fine-tuned models and very large-scale LLMs like GPT-4 on FinQA, TAT-QA and TAT-DQA benchmarks. We hope our work can serve as a pioneering example of specializing smaller language models for specific tasks.</li>
</ul>

<h3>Title: Scalable Link Prediction on Large-Scale Heterogeneous Graphs with Large  Language Models</h3>
<ul>
<li><strong>Authors: </strong>Baolong Bi, Shenghua Liu, Yiwei Wang, Lingrui Mei, Xueqi Chen</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.LG, cs.SI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.13227">https://arxiv.org/abs/2401.13227</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.13227">https://arxiv.org/pdf/2401.13227</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.13227]] Scalable Link Prediction on Large-Scale Heterogeneous Graphs with Large  Language Models(https://arxiv.org/abs/2401.13227)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Exploring the application of large-scale language models to graph learning is a novel endeavor. However, the vast amount of information inherent in large graphs poses significant challenges to this process. This paper focuses on the link prediction task and introduces LPNL (Link Prediction via Natural Language), a framework based on a large language model designed for scalable link prediction on large-scale heterogeneous graphs.We design novel prompts for link prediction that articulate graph details in natural language. We propose a two-stage sampling pipeline to extract crucial information from large-scale heterogeneous graphs, and a divide-and-conquer strategy to control the input token count within predefined limits, addressing the challenge of overwhelming information. We fine-tune a T5 model based on our self-supervised learning designed for for link prediction. Extensive experiments on a large public heterogeneous graphs demonstrate that LPNL outperforms various advanced baselines, highlighting its remarkable performance in link prediction tasks on large-scale graphs.</li>
</ul>

<h3>Title: From Random to Informed Data Selection: A Diversity-Based Approach to  Optimize Human Annotation and Few-Shot Learning</h3>
<ul>
<li><strong>Authors: </strong>Alexandre Alcoforado, Thomas Palmeira Ferraz, Lucas Hideki Okamura, Israel Campos Fama, Arnold Moya Lavado, Bárbara Dias Bueno, Bruno Veloso, Anna Helena Reali Costa</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.13229">https://arxiv.org/abs/2401.13229</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.13229">https://arxiv.org/pdf/2401.13229</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.13229]] From Random to Informed Data Selection: A Diversity-Based Approach to  Optimize Human Annotation and Few-Shot Learning(https://arxiv.org/abs/2401.13229)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>A major challenge in Natural Language Processing is obtaining annotated data for supervised learning. An option is the use of crowdsourcing platforms for data annotation. However, crowdsourcing introduces issues related to the annotator's experience, consistency, and biases. An alternative is to use zero-shot methods, which in turn have limitations compared to their few-shot or fully supervised counterparts. Recent advancements driven by large language models show potential, but struggle to adapt to specialized domains with severely limited data. The most common approaches therefore involve the human itself randomly annotating a set of datapoints to build initial datasets. But randomly sampling data to be annotated is often inefficient as it ignores the characteristics of the data and the specific needs of the model. The situation worsens when working with imbalanced datasets, as random sampling tends to heavily bias towards the majority classes, leading to excessive annotated data. To address these issues, this paper contributes an automatic and informed data selection architecture to build a small dataset for few-shot learning. Our proposal minimizes the quantity and maximizes diversity of data selected for human annotation, while improving model performance.</li>
</ul>

<h3>Title: How to Collaborate: Towards Maximizing the Generalization Performance in  Cross-Silo Federated Learning</h3>
<ul>
<li><strong>Authors: </strong>Yuchang Sun, Marios Kountouris, Jun Zhang</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.DC</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.13236">https://arxiv.org/abs/2401.13236</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.13236">https://arxiv.org/pdf/2401.13236</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.13236]] How to Collaborate: Towards Maximizing the Generalization Performance in  Cross-Silo Federated Learning(https://arxiv.org/abs/2401.13236)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, federate</a></li>
<li><strong>Abstract: </strong>Federated learning (FL) has attracted vivid attention as a privacy-preserving distributed learning framework. In this work, we focus on cross-silo FL, where clients become the model owners after training and are only concerned about the model's generalization performance on their local data. Due to the data heterogeneity issue, asking all the clients to join a single FL training process may result in model performance degradation. To investigate the effectiveness of collaboration, we first derive a generalization bound for each client when collaborating with others or when training independently. We show that the generalization performance of a client can be improved only by collaborating with other clients that have more training data and similar data distribution. Our analysis allows us to formulate a client utility maximization problem by partitioning clients into multiple collaborating groups. A hierarchical clustering-based collaborative training (HCCT) scheme is then proposed, which does not need to fix in advance the number of groups. We further analyze the convergence of HCCT for general non-convex loss functions which unveils the effect of data similarity among clients. Extensive simulations show that HCCT achieves better generalization performance than baseline schemes, whereas it degenerates to independent training and conventional FL in specific scenarios.</li>
</ul>

<h3>Title: SEER: Facilitating Structured Reasoning and Explanation via  Reinforcement Learning</h3>
<ul>
<li><strong>Authors: </strong>Guoxin Chen, Kexin Tang, Chao Yang, Fuying Ye, Yu Qiao, Yiming Qian</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.13246">https://arxiv.org/abs/2401.13246</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.13246">https://arxiv.org/pdf/2401.13246</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.13246]] SEER: Facilitating Structured Reasoning and Explanation via  Reinforcement Learning(https://arxiv.org/abs/2401.13246)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability</a></li>
<li><strong>Abstract: </strong>Elucidating the reasoning process with structured explanations from question to answer is fundamentally crucial, as it significantly enhances the interpretability and trustworthiness of question-answering (QA) systems. However, structured explanations demand models to perform intricate structured reasoning, which poses great challenges. Most existing methods focus on single-step reasoning through supervised learning, ignoring logical dependencies between steps. Meanwhile, existing reinforcement learning (RL)-based methods overlook the structured relationships, impeding RL's potential in structured reasoning. In this paper, we propose SEER, a novel method that maximizes a structure-based return to facilitate structured reasoning and explanation. Our proposed structure-based return precisely describes the hierarchical and branching structure inherent in structured reasoning, effectively capturing the intricate relationships between states. We also introduce a fine-grained reward function to meticulously delineate diverse reasoning steps. Extensive experiments show that SEER significantly outperforms state-of-the-art methods, achieving an absolute improvement of 6.9% over RL-based methods on EntailmentBank, a 4.4% average improvement on STREET benchmark, and exhibiting outstanding efficiency and cross-dataset generalization performance.</li>
</ul>

<h3>Title: UniMS-RAG: A Unified Multi-source Retrieval-Augmented Generation for  Personalized Dialogue Systems</h3>
<ul>
<li><strong>Authors: </strong>Hongru Wang, Wenyu Huang, Yang Deng, Rui Wang, Zezhong Wang, Yufei Wang, Fei Mi, Jeff Z. Pan, Kam-Fai Wong</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.13256">https://arxiv.org/abs/2401.13256</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.13256">https://arxiv.org/pdf/2401.13256</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.13256]] UniMS-RAG: A Unified Multi-source Retrieval-Augmented Generation for  Personalized Dialogue Systems(https://arxiv.org/abs/2401.13256)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large Language Models (LLMs) has shown exceptional capabilities in many natual language understanding and generation tasks. However, the personalization issue still remains a much-coveted property, especially when it comes to the multiple sources involved in the dialogue system. To better plan and incorporate the use of multiple sources in generating personalized response, we firstly decompose it into three sub-tasks: Knowledge Source Selection, Knowledge Retrieval, and Response Generation. We then propose a novel Unified Multi-Source Retrieval-Augmented Generation system (UniMS-RAG) Specifically, we unify these three sub-tasks with different formulations into the same sequence-to-sequence paradigm during the training, to adaptively retrieve evidences and evaluate the relevance on-demand using special tokens, called acting tokens and evaluation tokens. Enabling language models to generate acting tokens facilitates interaction with various knowledge sources, allowing them to adapt their behavior to diverse task requirements. Meanwhile, evaluation tokens gauge the relevance score between the dialogue context and the retrieved evidence. In addition, we carefully design a self-refinement mechanism to iteratively refine the generated response considering 1) the consistency scores between the generated response and retrieved evidence; and 2) the relevance scores. Experiments on two personalized datasets (DuLeMon and KBP) show that UniMS-RAG achieves state-of-the-art performance on the knowledge source selection and response generation task with itself as a retriever in a unified manner. Extensive analyses and discussions are provided for shedding some new perspectives for personalized dialogue systems.</li>
</ul>

<h3>Title: Enhancing cross-domain detection: adaptive class-aware contrastive  transformer</h3>
<ul>
<li><strong>Authors: </strong>Ziru Zeng, Yue Ding, Hongtao Lu</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.13264">https://arxiv.org/abs/2401.13264</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.13264">https://arxiv.org/pdf/2401.13264</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.13264]] Enhancing cross-domain detection: adaptive class-aware contrastive  transformer(https://arxiv.org/abs/2401.13264)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Recently,the detection transformer has gained substantial attention for its inherent minimal post-processing requirement.However,this paradigm relies on abundant training data,yet in the context of the cross-domain adaptation,insufficient labels in the target domain exacerbate issues of class imbalance and model performance degradation.To address these challenges, we propose a novel class-aware cross domain detection transformer based on the adversarial learning and mean-teacher framework.First,considering the inconsistencies between the classification and regression tasks,we introduce an IoU-aware prediction branch and exploit the consistency of classification and location scores to filter and reweight pseudo labels.Second, we devise a dynamic category threshold refinement to adaptively manage model confidence.Third,to alleviate the class imbalance,an instance-level class-aware contrastive learning module is presented to encourage the generation of discriminative features for each class,particularly benefiting minority classes.Experimental results across diverse domain-adaptive scenarios validate our method's effectiveness in improving performance and alleviating class imbalance issues,which outperforms the state-of-the-art transformer based methods.</li>
</ul>

<h3>Title: Dual-modal Dynamic Traceback Learning for Medical Report Generation</h3>
<ul>
<li><strong>Authors: </strong>Shuchang Ye, Mingyuan Meng, Mingjian Li, Dagan Feng, Jinman Kim</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.13267">https://arxiv.org/abs/2401.13267</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.13267">https://arxiv.org/pdf/2401.13267</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.13267]] Dual-modal Dynamic Traceback Learning for Medical Report Generation(https://arxiv.org/abs/2401.13267)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>With increasing reliance on medical imaging in clinical practices, automated report generation from medical images is in great demand. Existing report generation methods typically adopt an encoder-decoder deep learning framework to build a uni-directional image-to-report mapping. However, such a framework ignores the bi-directional mutual associations between images and reports, thus incurring difficulties in associating the intrinsic medical meanings between them. Recent generative representation learning methods have demonstrated the benefits of dual-modal learning from both image and text modalities. However, these methods exhibit two major drawbacks for medical report generation: 1) they tend to capture morphological information and have difficulties in capturing subtle pathological semantic information, and 2) they predict masked text rely on both unmasked images and text, inevitably degrading performance when inference is based solely on images. In this study, we propose a new report generation framework with dual-modal dynamic traceback learning (DTrace) to overcome the two identified drawbacks and enable dual-modal learning for medical report generation. To achieve this, our DTrace introduces a traceback mechanism to control the semantic validity of generated content via self-assessment. Further, our DTrace introduces a dynamic learning strategy to adapt to various proportions of image and text input, enabling report generation without reliance on textual input during inference. Extensive experiments on two well-benchmarked datasets (IU-Xray and MIMIC-CXR) show that our DTrace outperforms state-of-the-art medical report generation methods.</li>
</ul>

<h3>Title: Can AI Assistants Know What They Don't Know?</h3>
<ul>
<li><strong>Authors: </strong>Qinyuan Cheng, Tianxiang Sun, Xiangyang Liu, Wenwei Zhang, Zhangyue Yin, Shimin Li, Linyang Li, Kai Chen, Xipeng Qiu</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.13275">https://arxiv.org/abs/2401.13275</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.13275">https://arxiv.org/pdf/2401.13275</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.13275]] Can AI Assistants Know What They Don't Know?(https://arxiv.org/abs/2401.13275)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Recently, AI assistants based on large language models (LLMs) show surprising performance in many tasks, such as dialogue, solving math problems, writing code, and using tools. Although LLMs possess intensive world knowledge, they still make factual errors when facing some knowledge intensive tasks, like open-domain question answering. These untruthful responses from the AI assistant may cause significant risks in practical applications. We believe that an AI assistant's refusal to answer questions it does not know is a crucial method for reducing hallucinations and making the assistant truthful. Therefore, in this paper, we ask the question "Can AI assistants know what they don't know and express them through natural language?" To answer this question, we construct a model-specific "I don't know" (Idk) dataset for an assistant, which contains its known and unknown questions, based on existing open-domain question answering datasets. Then we align the assistant with its corresponding Idk dataset and observe whether it can refuse to answer its unknown questions after alignment. Experimental results show that after alignment with Idk datasets, the assistant can refuse to answer most its unknown questions. For questions they attempt to answer, the accuracy is significantly higher than before the alignment.</li>
</ul>

<h3>Title: DDI-CoCo: A Dataset For Understanding The Effect Of Color Contrast In  Machine-Assisted Skin Disease Detection</h3>
<ul>
<li><strong>Authors: </strong>Ming-Chang Chiu, Yingfei Wang, Yen-Ju Kuo, Pin-Yu Chen</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.CE</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.13280">https://arxiv.org/abs/2401.13280</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.13280">https://arxiv.org/pdf/2401.13280</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.13280]] DDI-CoCo: A Dataset For Understanding The Effect Of Color Contrast In  Machine-Assisted Skin Disease Detection(https://arxiv.org/abs/2401.13280)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Skin tone as a demographic bias and inconsistent human labeling poses challenges in dermatology AI. We take another angle to investigate color contrast's impact, beyond skin tones, on malignancy detection in skin disease datasets: We hypothesize that in addition to skin tones, the color difference between the lesion area and skin also plays a role in malignancy detection performance of dermatology AI models. To study this, we first propose a robust labeling method to quantify color contrast scores of each image and validate our method by showing small labeling variations. More importantly, applying our method to \textit{the only} diverse-skin tone and pathologically-confirmed skin disease dataset DDI, yields \textbf{DDI-CoCo Dataset}, and we observe a performance gap between the high and low color difference groups. This disparity remains consistent across various state-of-the-art (SoTA) image classification models, which supports our hypothesis. Furthermore, we study the interaction between skin tone and color difference effects and suggest that color difference can be an additional reason behind model performance bias between skin tones. Our work provides a complementary angle to dermatology AI for improving skin disease detection.</li>
</ul>

<h3>Title: RefreshNet: Learning Multiscale Dynamics through Hierarchical Refreshing</h3>
<ul>
<li><strong>Authors: </strong>Junaid Farooq, Danish Rafiq, Pantelis R. Vlachas, Mohammad Abid Bazaz</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.13282">https://arxiv.org/abs/2401.13282</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.13282">https://arxiv.org/pdf/2401.13282</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.13282]] RefreshNet: Learning Multiscale Dynamics through Hierarchical Refreshing(https://arxiv.org/abs/2401.13282)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>Forecasting complex system dynamics, particularly for long-term predictions, is persistently hindered by error accumulation and computational burdens. This study presents RefreshNet, a multiscale framework developed to overcome these challenges, delivering an unprecedented balance between computational efficiency and predictive accuracy. RefreshNet incorporates convolutional autoencoders to identify a reduced order latent space capturing essential features of the dynamics, and strategically employs multiple recurrent neural network (RNN) blocks operating at varying temporal resolutions within the latent space, thus allowing the capture of latent dynamics at multiple temporal scales. The unique "refreshing" mechanism in RefreshNet allows coarser blocks to reset inputs of finer blocks, effectively controlling and alleviating error accumulation. This design demonstrates superiority over existing techniques regarding computational efficiency and predictive accuracy, especially in long-term forecasting. The framework is validated using three benchmark applications: the FitzHugh-Nagumo system, the Reaction-Diffusion equation, and Kuramoto-Sivashinsky dynamics. RefreshNet significantly outperforms state-of-the-art methods in long-term forecasting accuracy and speed, marking a significant advancement in modeling complex systems and opening new avenues in understanding and predicting their behavior.</li>
</ul>

<h3>Title: Small Object Tracking in LiDAR Point Cloud: Learning the  Target-awareness Prototype and Fine-grained Search Region</h3>
<ul>
<li><strong>Authors: </strong>Shengjing Tian, Yinan Han, Xiuping Liu, Xiantong Zhao</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.13285">https://arxiv.org/abs/2401.13285</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.13285">https://arxiv.org/pdf/2401.13285</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.13285]] Small Object Tracking in LiDAR Point Cloud: Learning the  Target-awareness Prototype and Fine-grained Search Region(https://arxiv.org/abs/2401.13285)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Single Object Tracking in LiDAR point cloud is one of the most essential parts of environmental perception, in which small objects are inevitable in real-world scenarios and will bring a significant barrier to the accurate location. However, the existing methods concentrate more on exploring universal architectures for common categories and overlook the challenges that small objects have long been thorny due to the relative deficiency of foreground points and a low tolerance for disturbances. To this end, we propose a Siamese network-based method for small object tracking in the LiDAR point cloud, which is composed of the target-awareness prototype mining (TAPM) module and the regional grid subdivision (RGS) module. The TAPM module adopts the reconstruction mechanism of the masked decoder to learn the prototype in the feature space, aiming to highlight the presence of foreground points that will facilitate the subsequent location of small objects. Through the above prototype is capable of accentuating the small object of interest, the positioning deviation in feature maps still leads to high tracking errors. To alleviate this issue, the RGS module is proposed to recover the fine-grained features of the search region based on ViT and pixel shuffle layers. In addition, apart from the normal settings, we elaborately design a scaling experiment to evaluate the robustness of the different trackers on small objects. Extensive experiments on KITTI and nuScenes demonstrate that our method can effectively improve the tracking performance of small targets without affecting normal-sized objects.</li>
</ul>

<h3>Title: Towards Explainable Harmful Meme Detection through Multimodal Debate  between Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Hongzhan Lin, Ziyang Luo, Wei Gao, Jing Ma, Bo Wang, Ruichao Yang</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.13298">https://arxiv.org/abs/2401.13298</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.13298">https://arxiv.org/pdf/2401.13298</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.13298]] Towards Explainable Harmful Meme Detection through Multimodal Debate  between Large Language Models(https://arxiv.org/abs/2401.13298)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>The age of social media is flooded with Internet memes, necessitating a clear grasp and effective identification of harmful ones. This task presents a significant challenge due to the implicit meaning embedded in memes, which is not explicitly conveyed through the surface text and image. However, existing harmful meme detection methods do not present readable explanations that unveil such implicit meaning to support their detection decisions. In this paper, we propose an explainable approach to detect harmful memes, achieved through reasoning over conflicting rationales from both harmless and harmful positions. Specifically, inspired by the powerful capacity of Large Language Models (LLMs) on text generation and reasoning, we first elicit multimodal debate between LLMs to generate the explanations derived from the contradictory arguments. Then we propose to fine-tune a small language model as the debate judge for harmfulness inference, to facilitate multimodal fusion between the harmfulness rationales and the intrinsic multimodal information within memes. In this way, our model is empowered to perform dialectical reasoning over intricate and implicit harm-indicative patterns, utilizing multimodal explanations originating from both harmless and harmful arguments. Extensive experiments on three public meme datasets demonstrate that our harmful meme detection approach achieves much better performance than state-of-the-art methods and exhibits a superior capacity for explaining the meme harmfulness of the model predictions.</li>
</ul>

<h3>Title: Classification of Radiologically Isolated Syndrome and Clinically  Isolated Syndrome with Machine-Learning Techniques</h3>
<ul>
<li><strong>Authors: </strong>V Mato-Abad, A Labiano-Fontcuberta, S Rodriguez-Yanez, R Garcia-Vazquez, CR Munteanu, J Andrade-Garda, A Domingo-Santos, V Galan Sanchez-Seco, Y Aladro, ML Martinez-Gines, L Ayuso, J Benito-Leon</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.13301">https://arxiv.org/abs/2401.13301</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.13301">https://arxiv.org/pdf/2401.13301</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.13301]] Classification of Radiologically Isolated Syndrome and Clinically  Isolated Syndrome with Machine-Learning Techniques(https://arxiv.org/abs/2401.13301)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>Background and purpose: The unanticipated detection by magnetic resonance imaging (MRI) in the brain of asymptomatic subjects of white matter lesions suggestive of multiple sclerosis (MS) has been named radiologically isolated syndrome (RIS). As the difference between early MS [i.e. clinically isolated syndrome (CIS)] and RIS is the occurrence of a clinical event, it is logical to improve detection of the subclinical form without interfering with MRI as there are radiological diagnostic criteria for that. Our objective was to use machine-learning classification methods to identify morphometric measures that help to discriminate patients with RIS from those with CIS. Methods: We used a multimodal 3-T MRI approach by combining MRI biomarkers (cortical thickness, cortical and subcortical grey matter volume, and white matter integrity) of a cohort of 17 patients with RIS and 17 patients with CIS for single-subject level classification. Results: The best proposed models to predict the diagnosis of CIS and RIS were based on the Naive Bayes, Bagging and Multilayer Perceptron classifiers using only three features: the left rostral middle frontal gyrus volume and the fractional anisotropy values in the right amygdala and right lingual gyrus. The Naive Bayes obtained the highest accuracy [overall classification, 0.765; area under the receiver operating characteristic (AUROC), 0.782]. Conclusions: A machine-learning approach applied to multimodal MRI data may differentiate between the earliest clinical expressions of MS (CIS and RIS) with an accuracy of 78%. Keywords: Bagging; Multilayer Perceptron; Naive Bayes classifier; clinically isolated syndrome; diffusion tensor imaging; machine-learning; magnetic resonance imaging; multiple sclerosis; radiologically isolated syndrome.</li>
</ul>

<h3>Title: MaLA-500: Massive Language Adaptation of Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Peiqin Lin, Shaoxiong Ji, Jörg Tiedemann, André F. T. Martins, Hinrich Schütze</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.13303">https://arxiv.org/abs/2401.13303</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.13303">https://arxiv.org/pdf/2401.13303</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.13303]] MaLA-500: Massive Language Adaptation of Large Language Models(https://arxiv.org/abs/2401.13303)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large language models have advanced the state of the art in natural language processing. However, their predominant design for English or a limited set of languages creates a substantial gap in their effectiveness for low-resource languages. To bridge this gap, we introduce MaLA-500, a novel large language model designed to cover an extensive range of 534 languages. To train MaLA-500, we employ vocabulary extension and continued pretraining on LLaMA 2 with Glot500-c. Our experiments on SIB-200 show that MaLA-500 achieves state-of-the-art in-context learning results. We release MaLA-500 at https://huggingface.co/MaLA-LM</li>
</ul>

<h3>Title: POSTER: Towards Secure 5G Infrastructures for Production Systems</h3>
<ul>
<li><strong>Authors: </strong>Martin Henze, Maximilian Ortmann, Thomas Vogt, Osman Ugus, Kai Hermann, Svenja Nohr, Zeren Lu, Sotiris Michaelides, Angela Massonet, Robert H. Schmitt</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.13306">https://arxiv.org/abs/2401.13306</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.13306">https://arxiv.org/pdf/2401.13306</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.13306]] POSTER: Towards Secure 5G Infrastructures for Production Systems(https://arxiv.org/abs/2401.13306)</code><input type="text"></li>
<li><strong>Keywords: </strong>secure, security, attack</a></li>
<li><strong>Abstract: </strong>To meet the requirements of modern production, industrial communication increasingly shifts from wired fieldbus to wireless 5G communication. Besides tremendous benefits, this shift introduces severe novel risks, ranging from limited reliability over new security vulnerabilities to a lack of accountability. To address these risks, we present approaches to (i) prevent attacks through authentication and redundant communication, (ii) detect anomalies and jamming, and (iii) respond to detected attacks through device exclusion and accountability measures.</li>
</ul>

<h3>Title: ConTextual: Evaluating Context-Sensitive Text-Rich Visual Reasoning in  Large Multimodal Models</h3>
<ul>
<li><strong>Authors: </strong>Rohan Wadhawan, Hritik Bansal, Kai-Wei Chang, Nanyun Peng</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.13311">https://arxiv.org/abs/2401.13311</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.13311">https://arxiv.org/pdf/2401.13311</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.13311]] ConTextual: Evaluating Context-Sensitive Text-Rich Visual Reasoning in  Large Multimodal Models(https://arxiv.org/abs/2401.13311)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Recent advancements in AI have led to the development of large multimodal models (LMMs) capable of processing complex tasks involving joint reasoning over text and visual content in the image (e.g., navigating maps in public places). This paper introduces ConTextual, a novel benchmark comprising instructions designed explicitly to evaluate LMMs' ability to perform context-sensitive text-rich visual reasoning. ConTextual emphasizes diverse real-world scenarios (e.g., time-reading, navigation, shopping and more) demanding a deeper understanding of the interactions between textual and visual elements. Our findings reveal a significant performance gap of 30.8% between the best-performing LMM, GPT-4V(ision), and human capabilities using human evaluation indicating substantial room for improvement in context-sensitive text-rich visual reasoning. Notably, while GPT-4V excelled in abstract categories like meme and quote interpretation, its overall performance still lagged behind humans. In addition to human evaluations, we also employed automatic evaluation metrics using GPT-4, uncovering similar trends in performance disparities. We also perform a fine-grained evaluation across diverse visual contexts and provide qualitative analysis which provides a robust framework for future advancements in the LMM design. https://con-textual.github.io/</li>
</ul>

<h3>Title: InstructDoc: A Dataset for Zero-Shot Generalization of Visual Document  Understanding with Instructions</h3>
<ul>
<li><strong>Authors: </strong>Ryota Tanaka, Taichi Iki, Kyosuke Nishida, Kuniko Saito, Jun Suzuki</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.13313">https://arxiv.org/abs/2401.13313</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.13313">https://arxiv.org/pdf/2401.13313</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.13313]] InstructDoc: A Dataset for Zero-Shot Generalization of Visual Document  Understanding with Instructions(https://arxiv.org/abs/2401.13313)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction, large language model</a></li>
<li><strong>Abstract: </strong>We study the problem of completing various visual document understanding (VDU) tasks, e.g., question answering and information extraction, on real-world documents through human-written instructions. To this end, we propose InstructDoc, the first large-scale collection of 30 publicly available VDU datasets, each with diverse instructions in a unified format, which covers a wide range of 12 tasks and includes open document types/formats. Furthermore, to enhance the generalization performance on VDU tasks, we design a new instruction-based document reading and understanding model, InstructDr, that connects document images, image encoders, and large language models (LLMs) through a trainable bridging module. Experiments demonstrate that InstructDr can effectively adapt to new VDU datasets, tasks, and domains via given instructions and outperforms existing multimodal LLMs and ChatGPT without specific training.</li>
</ul>

<h3>Title: Generating Synthetic Health Sensor Data for Privacy-Preserving Wearable  Stress Detection</h3>
<ul>
<li><strong>Authors: </strong>Lucas Lange, Nils Wenzlitschke, Erhard Rahm</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.13327">https://arxiv.org/abs/2401.13327</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.13327">https://arxiv.org/pdf/2401.13327</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.13327]] Generating Synthetic Health Sensor Data for Privacy-Preserving Wearable  Stress Detection(https://arxiv.org/abs/2401.13327)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, protect, generative</a></li>
<li><strong>Abstract: </strong>Smartwatch health sensor data is increasingly utilized in smart health applications and patient monitoring, including stress detection. However, such medical data often comprises sensitive personal information and is resource-intensive to acquire for research purposes. In response to this challenge, we introduce the privacy-aware synthetization of multi-sensor smartwatch health readings related to moments of stress. Our method involves the generation of synthetic sequence data through Generative Adversarial Networks (GANs), coupled with the implementation of Differential Privacy (DP) safeguards for protecting patient information during model training. To ensure the integrity of our synthetic data, we employ a range of quality assessments and monitor the plausibility between synthetic and original data. To test the usefulness, we create private machine learning models on a commonly used, albeit small, stress detection dataset, exploring strategies for enhancing the existing data foundation with our synthetic data. Through our GAN-based augmentation methods, we observe improvements in model performance, both in non-private (0.45% F1) and private (11.90-15.48% F1) training scenarios. We underline the potential of differentially private synthetic data in optimizing utility-privacy trade-offs, especially with limited availability of real training samples.</li>
</ul>

<h3>Title: Generative Video Diffusion for Unseen Cross-Domain Video Moment  Retrieval</h3>
<ul>
<li><strong>Authors: </strong>Dezhao Luo, Jiabo Huang, Shaogang Gong, Hailin Jin, Yang Liu</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.13329">https://arxiv.org/abs/2401.13329</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.13329">https://arxiv.org/pdf/2401.13329</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.13329]] Generative Video Diffusion for Unseen Cross-Domain Video Moment  Retrieval(https://arxiv.org/abs/2401.13329)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, generative</a></li>
<li><strong>Abstract: </strong>Video Moment Retrieval (VMR) requires precise modelling of fine-grained moment-text associations to capture intricate visual-language relationships. Due to the lack of a diverse and generalisable VMR dataset to facilitate learning scalable moment-text associations, existing methods resort to joint training on both source and target domain videos for cross-domain applications. Meanwhile, recent developments in vision-language multimodal models pre-trained on large-scale image-text and/or video-text pairs are only based on coarse associations (weakly labelled). They are inadequate to provide fine-grained moment-text correlations required for cross-domain VMR. In this work, we solve the problem of unseen cross-domain VMR, where certain visual and textual concepts do not overlap across domains, by only utilising target domain sentences (text prompts) without accessing their videos. To that end, we explore generative video diffusion for fine-grained editing of source videos controlled by the target sentences, enabling us to simulate target domain videos. We address two problems in video editing for optimising unseen domain VMR: (1) generation of high-quality simulation videos of different moments with subtle distinctions, (2) selection of simulation videos that complement existing source training videos without introducing harmful noise or unnecessary repetitions. On the first problem, we formulate a two-stage video diffusion generation controlled simultaneously by (1) the original video structure of a source video, (2) subject specifics, and (3) a target sentence prompt. This ensures fine-grained variations between video moments. On the second problem, we introduce a hybrid selection mechanism that combines two quantitative metrics for noise filtering and one qualitative metric for leveraging VMR prediction on simulation video selection.</li>
</ul>

<h3>Title: Explainable Bayesian Optimization</h3>
<ul>
<li><strong>Authors: </strong>Tanmay Chakraborty, Christin Seifert, Christian Wirth</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.13334">https://arxiv.org/abs/2401.13334</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.13334">https://arxiv.org/pdf/2401.13334</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.13334]] Explainable Bayesian Optimization(https://arxiv.org/abs/2401.13334)</code><input type="text"></li>
<li><strong>Keywords: </strong>explainability</a></li>
<li><strong>Abstract: </strong>In industry, Bayesian optimization (BO) is widely applied in the human-AI collaborative parameter tuning of cyber-physical systems. However, BO's solutions may deviate from human experts' actual goal due to approximation errors and simplified objectives, requiring subsequent tuning. The black-box nature of BO limits the collaborative tuning process because the expert does not trust the BO recommendations. Current explainable AI (XAI) methods are not tailored for optimization and thus fall short of addressing this gap. To bridge this gap, we propose TNTRules (TUNE-NOTUNE Rules), a post-hoc, rule-based explainability method that produces high quality explanations through multiobjective optimization. Our evaluation of benchmark optimization problems and real-world hyperparameter optimization tasks demonstrates TNTRules' superiority over state-of-the-art XAI methods in generating high quality explanations. This work contributes to the intersection of BO and XAI, providing interpretable optimization techniques for real-world applications.</li>
</ul>

<h3>Title: Linear Relative Pose Estimation Founded on Pose-only Imaging Geometry</h3>
<ul>
<li><strong>Authors: </strong>Qi Cai, Xinrui Li, Yuanxin Wu</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.13357">https://arxiv.org/abs/2401.13357</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.13357">https://arxiv.org/pdf/2401.13357</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.13357]] Linear Relative Pose Estimation Founded on Pose-only Imaging Geometry(https://arxiv.org/abs/2401.13357)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>How to efficiently and accurately handle image matching outliers is a critical issue in two-view relative estimation. The prevailing RANSAC method necessitates that the minimal point pairs be inliers. This paper introduces a linear relative pose estimation algorithm for n $( n \geq 6$) point pairs, which is founded on the recent pose-only imaging geometry to filter out outliers by proper reweighting. The proposed algorithm is able to handle planar degenerate scenes, and enhance robustness and accuracy in the presence of a substantial ratio of outliers. Specifically, we embed the linear global translation (LiGT) constraint into the strategies of iteratively reweighted least-squares (IRLS) and RANSAC so as to realize robust outlier removal. Simulations and real tests of the Strecha dataset show that the proposed algorithm achieves relative rotation accuracy improvement of 2 $\sim$ 10 times in face of as large as 80% outliers.</li>
</ul>

<h3>Title: Debiased Sample Selection for Combating Noisy Labels</h3>
<ul>
<li><strong>Authors: </strong>Qi Wei, Lei Feng, Haobo Wang, Bo An</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.13360">https://arxiv.org/abs/2401.13360</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.13360">https://arxiv.org/pdf/2401.13360</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.13360]] Debiased Sample Selection for Combating Noisy Labels(https://arxiv.org/abs/2401.13360)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Learning with noisy labels aims to ensure model generalization given a label-corrupted training set. The sample selection strategy achieves promising performance by selecting a label-reliable subset for model training. In this paper, we empirically reveal that existing sample selection methods suffer from both data and training bias that are represented as imbalanced selected sets and accumulation errors in practice, respectively. However, only the training bias was handled in previous studies. To address this limitation, we propose a noIse-Tolerant Expert Model (ITEM) for debiased learning in sample selection. Specifically, to mitigate the training bias, we design a robust network architecture that integrates with multiple experts. Compared with the prevailing double-branch network, our network exhibits better performance of selection and prediction by ensembling these experts while training with fewer parameters. Meanwhile, to mitigate the data bias, we propose a mixed sampling strategy based on two weight-based data samplers. By training on the mixture of two class-discriminative mini-batches, the model mitigates the effect of the imbalanced training set while avoiding sparse representations that are easily caused by sampling strategies. Extensive experiments and analyses demonstrate the effectiveness of ITEM. Our code is available at this url \href{https://github.com/1998v7/ITEM}{ITEM}.</li>
</ul>

<h3>Title: Mitigating System Bias in Resource Constrained Asynchronous Federated  Learning Systems</h3>
<ul>
<li><strong>Authors: </strong>Jikun Gao, Ioannis Mavromatis, Peizheng Li, Pietro Carnelli, Aftab Khan</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.13366">https://arxiv.org/abs/2401.13366</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.13366">https://arxiv.org/pdf/2401.13366</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.13366]] Mitigating System Bias in Resource Constrained Asynchronous Federated  Learning Systems(https://arxiv.org/abs/2401.13366)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, federate</a></li>
<li><strong>Abstract: </strong>Federated learning (FL) systems face performance challenges in dealing with heterogeneous devices and non-identically distributed data across clients. We propose a dynamic global model aggregation method within Asynchronous Federated Learning (AFL) deployments to address these issues. Our aggregation method scores and adjusts the weighting of client model updates based on their upload frequency to accommodate differences in device capabilities. Additionally, we also immediately provide an updated global model to clients after they upload their local models to reduce idle time and improve training efficiency. We evaluate our approach within an AFL deployment consisting of 10 simulated clients with heterogeneous compute constraints and non-IID data. The simulation results, using the FashionMNIST dataset, demonstrate over 10% and 19% improvement in global model accuracy compared to state-of-the-art methods PAPAYA and FedAsync, respectively. Our dynamic aggregation method allows reliable global model training despite limiting client resources and statistical data heterogeneity. This improves robustness and scalability for real-world FL deployments.</li>
</ul>

<h3>Title: Privacy-Preserving Face Recognition in Hybrid Frequency-Color Domain</h3>
<ul>
<li><strong>Authors: </strong>Dong Han, Yong Li, Joachim Denzler</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.13386">https://arxiv.org/abs/2401.13386</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.13386">https://arxiv.org/pdf/2401.13386</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.13386]] Privacy-Preserving Face Recognition in Hybrid Frequency-Color Domain(https://arxiv.org/abs/2401.13386)</code><input type="text"></li>
<li><strong>Keywords: </strong>secure, privacy, protect, biometric</a></li>
<li><strong>Abstract: </strong>Face recognition technology has been deployed in various real-life applications. The most sophisticated deep learning-based face recognition systems rely on training millions of face images through complex deep neural networks to achieve high accuracy. It is quite common for clients to upload face images to the service provider in order to access the model inference. However, the face image is a type of sensitive biometric attribute tied to the identity information of each user. Directly exposing the raw face image to the service provider poses a threat to the user's privacy. Current privacy-preserving approaches to face recognition focus on either concealing visual information on model input or protecting model output face embedding. The noticeable drop in recognition accuracy is a pitfall for most methods. This paper proposes a hybrid frequency-color fusion approach to reduce the input dimensionality of face recognition in the frequency domain. Moreover, sparse color information is also introduced to alleviate significant accuracy degradation after adding differential privacy noise. Besides, an identity-specific embedding mapping scheme is applied to protect original face embedding by enlarging the distance among identities. Lastly, secure multiparty computation is implemented for safely computing the embedding distance during model inference. The proposed method performs well on multiple widely used verification datasets. Moreover, it has around 2.6% to 4.2% higher accuracy than the state-of-the-art in the 1:N verification scenario.</li>
</ul>

<h3>Title: UNIMO-G: Unified Image Generation through Multimodal Conditional  Diffusion</h3>
<ul>
<li><strong>Authors: </strong>Wei Li, Xue Xu, Jiachen Liu, Xinyan Xiao</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.13388">https://arxiv.org/abs/2401.13388</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.13388">https://arxiv.org/pdf/2401.13388</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.13388]] UNIMO-G: Unified Image Generation through Multimodal Conditional  Diffusion(https://arxiv.org/abs/2401.13388)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, large language model, segmentation</a></li>
<li><strong>Abstract: </strong>Existing text-to-image diffusion models primarily generate images from text prompts. However, the inherent conciseness of textual descriptions poses challenges in faithfully synthesizing images with intricate details, such as specific entities or scenes. This paper presents \textbf{UNIMO-G}, a simple multimodal conditional diffusion framework that operates on multimodal prompts with interleaved textual and visual inputs, which demonstrates a unified ability for both text-driven and subject-driven image generation. UNIMO-G comprises two core components: a Multimodal Large Language Model (MLLM) for encoding multimodal prompts, and a conditional denoising diffusion network for generating images based on the encoded multimodal input. We leverage a two-stage training strategy to effectively train the framework: firstly pre-training on large-scale text-image pairs to develop conditional image generation capabilities, and then instruction tuning with multimodal prompts to achieve unified image generation proficiency. A well-designed data processing pipeline involving language grounding and image segmentation is employed to construct multi-modal prompts. UNIMO-G excels in both text-to-image generation and zero-shot subject-driven synthesis, and is notably effective in generating high-fidelity images from complex multimodal prompts involving multiple image entities.</li>
</ul>

<h3>Title: Beyond Accuracy-Fairness: Stop evaluating bias mitigation methods solely  on between-group metrics</h3>
<ul>
<li><strong>Authors: </strong>Sofie Goethals, Toon Calders, David Martens</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.13391">https://arxiv.org/abs/2401.13391</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.13391">https://arxiv.org/pdf/2401.13391</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.13391]] Beyond Accuracy-Fairness: Stop evaluating bias mitigation methods solely  on between-group metrics(https://arxiv.org/abs/2401.13391)</code><input type="text"></li>
<li><strong>Keywords: </strong>fair</a></li>
<li><strong>Abstract: </strong>Artificial Intelligence (AI) finds widespread applications across various domains, sparking concerns about fairness in its deployment. While fairness in AI remains a central concern, the prevailing discourse often emphasizes outcome-based metrics without a nuanced consideration of the differential impacts within subgroups. Bias mitigation techniques do not only affect the ranking of pairs of instances across sensitive groups, but often also significantly affect the ranking of instances within these groups. Such changes are hard to explain and raise concerns regarding the validity of the intervention. Unfortunately, these effects largely remain under the radar in the accuracy-fairness evaluation framework that is usually applied. This paper challenges the prevailing metrics for assessing bias mitigation techniques, arguing that they do not take into account the changes within-groups and that the resulting prediction labels fall short of reflecting real-world scenarios. We propose a paradigm shift: initially, we should focus on generating the most precise ranking for each subgroup. Following this, individuals should be chosen from these rankings to meet both fairness standards and practical considerations.</li>
</ul>

<h3>Title: Text Categorization Can Enhance Domain-Agnostic Stopword Extraction</h3>
<ul>
<li><strong>Authors: </strong>Houcemeddine Turki, Naome A. Etori, Mohamed Ali Hadj Taieb, Abdul-Hakeem Omotayo, Chris Chinenye Emezue, Mohamed Ben Aouicha, Ayodele Awokoya, Falalu Ibrahim Lawan, Doreen Nixdorf</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.13398">https://arxiv.org/abs/2401.13398</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.13398">https://arxiv.org/pdf/2401.13398</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.13398]] Text Categorization Can Enhance Domain-Agnostic Stopword Extraction(https://arxiv.org/abs/2401.13398)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction</a></li>
<li><strong>Abstract: </strong>This paper investigates the role of text categorization in streamlining stopword extraction in natural language processing (NLP), specifically focusing on nine African languages alongside French. By leveraging the MasakhaNEWS, African Stopwords Project, and MasakhaPOS datasets, our findings emphasize that text categorization effectively identifies domain-agnostic stopwords with over 80% detection success rate for most examined languages. Nevertheless, linguistic variances result in lower detection rates for certain languages. Interestingly, we find that while over 40% of stopwords are common across news categories, less than 15% are unique to a single category. Uncommon stopwords add depth to text but their classification as stopwords depends on context. Therefore combining statistical and linguistic approaches creates comprehensive stopword lists, highlighting the value of our hybrid method. This research enhances NLP for African languages and underscores the importance of text categorization in stopword extraction.</li>
</ul>

<h3>Title: Synthetic data enables faster annotation and robust segmentation for  multi-object grasping in clutter</h3>
<ul>
<li><strong>Authors: </strong>Dongmyoung Lee, Wei Chen, Nicolas Rojas</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.RO</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.13405">https://arxiv.org/abs/2401.13405</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.13405">https://arxiv.org/pdf/2401.13405</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.13405]] Synthetic data enables faster annotation and robust segmentation for  multi-object grasping in clutter(https://arxiv.org/abs/2401.13405)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, segmentation</a></li>
<li><strong>Abstract: </strong>Object recognition and object pose estimation in robotic grasping continue to be significant challenges, since building a labelled dataset can be time consuming and financially costly in terms of data collection and annotation. In this work, we propose a synthetic data generation method that minimizes human intervention and makes downstream image segmentation algorithms more robust by combining a generated synthetic dataset with a smaller real-world dataset (hybrid dataset). Annotation experiments show that the proposed synthetic scene generation can diminish labelling time dramatically. RGB image segmentation is trained with hybrid dataset and combined with depth information to produce pixel-to-point correspondence of individual segmented objects. The object to grasp is then determined by the confidence score of the segmentation algorithm. Pick-and-place experiments demonstrate that segmentation trained on our hybrid dataset (98.9%, 70%) outperforms the real dataset and a publicly available dataset by (6.7%, 18.8%) and (2.8%, 10%) in terms of labelling and grasping success rate, respectively. Supplementary material is available at https://sites.google.com/view/synthetic-dataset-generation.</li>
</ul>

<h3>Title: How to Forget Clients in Federated Online Learning to Rank?</h3>
<ul>
<li><strong>Authors: </strong>Shuyi Wang, Bing Liu, Guido Zuccon</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.IR, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.13410">https://arxiv.org/abs/2401.13410</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.13410">https://arxiv.org/pdf/2401.13410</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.13410]] How to Forget Clients in Federated Online Learning to Rank?(https://arxiv.org/abs/2401.13410)</code><input type="text"></li>
<li><strong>Keywords: </strong>protect, attack, federate</a></li>
<li><strong>Abstract: </strong>Data protection legislation like the European Union's General Data Protection Regulation (GDPR) establishes the \textit{right to be forgotten}: a user (client) can request contributions made using their data to be removed from learned models. In this paper, we study how to remove the contributions made by a client participating in a Federated Online Learning to Rank (FOLTR) system. In a FOLTR system, a ranker is learned by aggregating local updates to the global ranking model. Local updates are learned in an online manner at a client-level using queries and implicit interactions that have occurred within that specific client. By doing so, each client's local data is not shared with other clients or with a centralised search service, while at the same time clients can benefit from an effective global ranking model learned from contributions of each client in the federation. In this paper, we study an effective and efficient unlearning method that can remove a client's contribution without compromising the overall ranker effectiveness and without needing to retrain the global ranker from scratch. A key challenge is how to measure whether the model has unlearned the contributions from the client $c^*$ that has requested removal. For this, we instruct $c^*$ to perform a poisoning attack (add noise to this client updates) and then we measure whether the impact of the attack is lessened when the unlearning process has taken place. Through experiments on four datasets, we demonstrate the effectiveness and efficiency of the unlearning strategy under different combinations of parameter settings.</li>
</ul>

<h3>Title: GTAutoAct: An Automatic Datasets Generation Framework Based on Game  Engine Redevelopment for Action Recognition</h3>
<ul>
<li><strong>Authors: </strong>Xingyu Song, Zhan Li, Shi Chen, Kazuyuki Demachi</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.13414">https://arxiv.org/abs/2401.13414</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.13414">https://arxiv.org/pdf/2401.13414</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.13414]] GTAutoAct: An Automatic Datasets Generation Framework Based on Game  Engine Redevelopment for Action Recognition(https://arxiv.org/abs/2401.13414)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, segmentation</a></li>
<li><strong>Abstract: </strong>Current datasets for action recognition tasks face limitations stemming from traditional collection and generation methods, including the constrained range of action classes, absence of multi-viewpoint recordings, limited diversity, poor video quality, and labor-intensive manually collection. To address these challenges, we introduce GTAutoAct, a innovative dataset generation framework leveraging game engine technology to facilitate advancements in action recognition. GTAutoAct excels in automatically creating large-scale, well-annotated datasets with extensive action classes and superior video quality. Our framework's distinctive contributions encompass: (1) it innovatively transforms readily available coordinate-based 3D human motion into rotation-orientated representation with enhanced suitability in multiple viewpoints; (2) it employs dynamic segmentation and interpolation of rotation sequences to create smooth and realistic animations of action; (3) it offers extensively customizable animation scenes; (4) it implements an autonomous video capture and processing pipeline, featuring a randomly navigating camera, with auto-trimming and labeling functionalities. Experimental results underscore the framework's robustness and highlights its potential to significantly improve action recognition model training.</li>
</ul>

<h3>Title: Serial fusion of multi-modal biometric systems</h3>
<ul>
<li><strong>Authors: </strong>Gian Luca Marcialis, Paolo Mastinu, Fabio Roli</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.13418">https://arxiv.org/abs/2401.13418</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.13418">https://arxiv.org/pdf/2401.13418</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.13418]] Serial fusion of multi-modal biometric systems(https://arxiv.org/abs/2401.13418)</code><input type="text"></li>
<li><strong>Keywords: </strong>biometric</a></li>
<li><strong>Abstract: </strong>Serial, or sequential, fusion of multiple biometric matchers has been not thoroughly investigated so far. However, this approach exhibits some advantages with respect to the widely adopted parallel approaches. In this paper, we propose a novel theoretical framework for the assessment of performance of such systems, based on a previous work of the authors. Benefits in terms of performance are theoretically evaluated, as well as estimation errors in the model parameters computation. Model is analyzed from the viewpoint of its pros and cons, by mean of preliminary experiments performed on NIST Biometric Score Set 1.</li>
</ul>

<h3>Title: Clue-Guided Path Exploration: An Efficient Knowledge Base  Question-Answering Framework with Low Computational Resource Consumption</h3>
<ul>
<li><strong>Authors: </strong>Dehao Tao, Feng Huang, Yongfeng Huang, Minghu Jiang</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.13444">https://arxiv.org/abs/2401.13444</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.13444">https://arxiv.org/pdf/2401.13444</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.13444]] Clue-Guided Path Exploration: An Efficient Knowledge Base  Question-Answering Framework with Low Computational Resource Consumption(https://arxiv.org/abs/2401.13444)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>In recent times, large language models (LLMs) have showcased remarkable capabilities. However, updating their knowledge poses challenges, potentially leading to inaccuracies when confronted with unfamiliar queries. While integrating knowledge graphs with LLMs has been explored, existing approaches treat LLMs as primary decision-makers, imposing high demands on their capabilities. This is particularly unsuitable for LLMs with lower computational costs and relatively poorer performance. In this paper, we introduce a Clue-Guided Path Exploration framework (CGPE) that efficiently merges a knowledge base with an LLM, placing less stringent requirements on the model's capabilities. Inspired by the method humans use to manually retrieve knowledge, CGPE employs information from the question as clues to systematically explore the required knowledge path within the knowledge base. Experiments on open-source datasets reveal that CGPE outperforms previous methods and is highly applicable to LLMs with fewer parameters. In some instances, even ChatGLM3, with its 6 billion parameters, can rival the performance of GPT-4. Furthermore, the results indicate a minimal invocation frequency of CGPE on LLMs, suggesting reduced computational overhead. For organizations and individuals facing constraints in computational resources, our research offers significant practical value.</li>
</ul>

<h3>Title: Multi-Agent Diagnostics for Robustness via Illuminated Diversity</h3>
<ul>
<li><strong>Authors: </strong>Mikayel Samvelyan, Davide Paglieri, Minqi Jiang, Jack Parker-Holder, Tim Rocktäschel</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.MA</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.13460">https://arxiv.org/abs/2401.13460</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.13460">https://arxiv.org/pdf/2401.13460</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.13460]] Multi-Agent Diagnostics for Robustness via Illuminated Diversity(https://arxiv.org/abs/2401.13460)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>In the rapidly advancing field of multi-agent systems, ensuring robustness in unfamiliar and adversarial settings is crucial. Notwithstanding their outstanding performance in familiar environments, these systems often falter in new situations due to overfitting during the training phase. This is especially pronounced in settings where both cooperative and competitive behaviours are present, encapsulating a dual nature of overfitting and generalisation challenges. To address this issue, we present Multi-Agent Diagnostics for Robustness via Illuminated Diversity (MADRID), a novel approach for generating diverse adversarial scenarios that expose strategic vulnerabilities in pre-trained multi-agent policies. Leveraging the concepts from open-ended learning, MADRID navigates the vast space of adversarial settings, employing a target policy's regret to gauge the vulnerabilities of these settings. We evaluate the effectiveness of MADRID on the 11vs11 version of Google Research Football, one of the most complex environments for multi-agent reinforcement learning. Specifically, we employ MADRID for generating a diverse array of adversarial settings for TiZero, the state-of-the-art approach which "masters" the game through 45 days of training on a large-scale distributed infrastructure. We expose key shortcomings in TiZero's tactical decision-making, underlining the crucial importance of rigorous evaluation in multi-agent systems.</li>
</ul>

<h3>Title: SpeechDPR: End-to-End Spoken Passage Retrieval for Open-Domain Spoken  Question Answering</h3>
<ul>
<li><strong>Authors: </strong>Chyi-Jiunn Lin, Guan-Ting Lin, Yung-Sung Chuang, Wei-Lun Wu, Shang-Wen Li, Abdelrahman Mohamed, Hung-yi Lee, Lin-shan Lee</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.IR, cs.SD, eess.AS</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.13463">https://arxiv.org/abs/2401.13463</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.13463">https://arxiv.org/pdf/2401.13463</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.13463]] SpeechDPR: End-to-End Spoken Passage Retrieval for Open-Domain Spoken  Question Answering(https://arxiv.org/abs/2401.13463)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Spoken Question Answering (SQA) is essential for machines to reply to user's question by finding the answer span within a given spoken passage. SQA has been previously achieved without ASR to avoid recognition errors and Out-of-Vocabulary (OOV) problems. However, the real-world problem of Open-domain SQA (openSQA), in which the machine needs to first retrieve passages that possibly contain the answer from a spoken archive in addition, was never considered. This paper proposes the first known end-to-end framework, Speech Dense Passage Retriever (SpeechDPR), for the retrieval component of the openSQA problem. SpeechDPR learns a sentence-level semantic representation by distilling knowledge from the cascading model of unsupervised ASR (UASR) and text dense retriever (TDR). No manually transcribed speech data is needed. Initial experiments showed performance comparable to the cascading model of UASR and TDR, and significantly better when UASR was poor, verifying this approach is more robust to speech recognition errors.</li>
</ul>

<h3>Title: LDCA: Local Descriptors with Contextual Augmentation for Few-Shot  Learning</h3>
<ul>
<li><strong>Authors: </strong>Maofa Wang, Bingchen Yan</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.13499">https://arxiv.org/abs/2401.13499</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.13499">https://arxiv.org/pdf/2401.13499</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.13499]] LDCA: Local Descriptors with Contextual Augmentation for Few-Shot  Learning(https://arxiv.org/abs/2401.13499)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Few-shot image classification has emerged as a key challenge in the field of computer vision, highlighting the capability to rapidly adapt to new tasks with minimal labeled data. Existing methods predominantly rely on image-level features or local descriptors, often overlooking the holistic context surrounding these descriptors. In this work, we introduce a novel approach termed "Local Descriptor with Contextual Augmentation (LDCA)". Specifically, this method bridges the gap between local and global understanding uniquely by leveraging an adaptive global contextual enhancement module. This module incorporates a visual transformer, endowing local descriptors with contextual awareness capabilities, ranging from broad global perspectives to intricate surrounding nuances. By doing so, LDCA transcends traditional descriptor-based approaches, ensuring each local feature is interpreted within its larger visual narrative. Extensive experiments underscore the efficacy of our method, showing a maximal absolute improvement of 20\% over the next-best on fine-grained classification datasets, thus demonstrating significant advancements in few-shot classification tasks.</li>
</ul>

<h3>Title: Learning Representations for Clustering via Partial Information  Discrimination and Cross-Level Interaction</h3>
<ul>
<li><strong>Authors: </strong>Hai-Xin Zhang, Dong Huang, Hua-Bao Ling, Guang-Yu Zhang, Wei-jun Sun, Zi-hao Wen</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.13503">https://arxiv.org/abs/2401.13503</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.13503">https://arxiv.org/pdf/2401.13503</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.13503]] Learning Representations for Clustering via Partial Information  Discrimination and Cross-Level Interaction(https://arxiv.org/abs/2401.13503)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>In this paper, we present a novel deep image clustering approach termed PICI, which enforces the partial information discrimination and the cross-level interaction in a joint learning framework. In particular, we leverage a Transformer encoder as the backbone, through which the masked image modeling with two paralleled augmented views is formulated. After deriving the class tokens from the masked images by the Transformer encoder, three partial information learning modules are further incorporated, including the PISD module for training the auto-encoder via masked image reconstruction, the PICD module for employing two levels of contrastive learning, and the CLI module for mutual interaction between the instance-level and cluster-level subspaces. Extensive experiments have been conducted on six real-world image datasets, which demononstrate the superior clustering performance of the proposed PICI approach over the state-of-the-art deep clustering approaches. The source code is available at https://github.com/Regan-Zhang/PICI.</li>
</ul>

<h3>Title: Research about the Ability of LLM in the Tamper-Detection Area</h3>
<ul>
<li><strong>Authors: </strong>Xinyu Yang, Jizhe Zhou</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.13504">https://arxiv.org/abs/2401.13504</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.13504">https://arxiv.org/pdf/2401.13504</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.13504]] Research about the Ability of LLM in the Tamper-Detection Area(https://arxiv.org/abs/2401.13504)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>In recent years, particularly since the early 2020s, Large Language Models (LLMs) have emerged as the most powerful AI tools in addressing a diverse range of challenges, from natural language processing to complex problem-solving in various domains. In the field of tamper detection, LLMs are capable of identifying basic tampering activities.To assess the capabilities of LLMs in more specialized domains, we have collected five different LLMs developed by various companies: GPT-4, LLaMA, Bard, ERNIE Bot 4.0, and Tongyi Qianwen. This diverse range of models allows for a comprehensive evaluation of their performance in detecting sophisticated tampering instances.We devised two domains of detection: AI-Generated Content (AIGC) detection and manipulation detection. AIGC detection aims to test the ability to distinguish whether an image is real or AI-generated. Manipulation detection, on the other hand, focuses on identifying tampered images. According to our experiments, most LLMs can identify composite pictures that are inconsistent with logic, and only more powerful LLMs can distinguish logical, but visible signs of tampering to the human eye. All of the LLMs can't identify carefully forged images and very realistic images generated by AI. In the area of tamper detection, LLMs still have a long way to go, particularly in reliably identifying highly sophisticated forgeries and AI-generated images that closely mimic reality.</li>
</ul>

<h3>Title: Generative Human Motion Stylization in Latent Space</h3>
<ul>
<li><strong>Authors: </strong>Chuan Guo, Yuxuan Mu, Xinxin Zuo, Peng Dai, Youliang Yan, Juwei Lu, Li Cheng</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.13505">https://arxiv.org/abs/2401.13505</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.13505">https://arxiv.org/pdf/2401.13505</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.13505]] Generative Human Motion Stylization in Latent Space(https://arxiv.org/abs/2401.13505)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, extraction, generative</a></li>
<li><strong>Abstract: </strong>Human motion stylization aims to revise the style of an input motion while keeping its content unaltered. Unlike existing works that operate directly in pose space, we leverage the latent space of pretrained autoencoders as a more expressive and robust representation for motion extraction and infusion. Building upon this, we present a novel generative model that produces diverse stylization results of a single motion (latent) code. During training, a motion code is decomposed into two coding components: a deterministic content code, and a probabilistic style code adhering to a prior distribution; then a generator massages the random combination of content and style codes to reconstruct the corresponding motion codes. Our approach is versatile, allowing the learning of probabilistic style space from either style labeled or unlabeled motions, providing notable flexibility in stylization as well. In inference, users can opt to stylize a motion using style cues from a reference motion or a label. Even in the absence of explicit style input, our model facilitates novel re-stylization by sampling from the unconditional style prior distribution. Experimental results show that our proposed stylization models, despite their lightweight design, outperform the state-of-the-arts in style reeanactment, content preservation, and generalization across various applications and settings. Project Page: https://yxmu.foo/GenMoStyle</li>
</ul>

<h3>Title: SpeechGPT-Gen: Scaling Chain-of-Information Speech Generation</h3>
<ul>
<li><strong>Authors: </strong>Dong Zhang, Xin Zhang, Jun Zhan, Shimin Li, Yaqian Zhou, Xipeng Qiu</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.SD, eess.AS</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.13527">https://arxiv.org/abs/2401.13527</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.13527">https://arxiv.org/pdf/2401.13527</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.13527]] SpeechGPT-Gen: Scaling Chain-of-Information Speech Generation(https://arxiv.org/abs/2401.13527)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Benefiting from effective speech modeling, current Speech Large Language Models (SLLMs) have demonstrated exceptional capabilities in in-context speech generation and efficient generalization to unseen speakers. However, the prevailing information modeling process is encumbered by certain redundancies, leading to inefficiencies in speech generation. We propose Chain-of-Information Generation (CoIG), a method for decoupling semantic and perceptual information in large-scale speech generation. Building on this, we develop SpeechGPT-Gen, an 8-billion-parameter SLLM efficient in semantic and perceptual information modeling. It comprises an autoregressive model based on LLM for semantic information modeling and a non-autoregressive model employing flow matching for perceptual information modeling. Additionally, we introduce the novel approach of infusing semantic information into the prior distribution to enhance the efficiency of flow matching. Extensive experimental results demonstrate that SpeechGPT-Gen markedly excels in zero-shot text-to-speech, zero-shot voice conversion, and speech-to-speech dialogue, underscoring CoIG's remarkable proficiency in capturing and modeling speech's semantic and perceptual dimensions. Code and models are available at https://github.com/0nutation/SpeechGPT.</li>
</ul>

<h3>Title: QAGait: Revisit Gait Recognition from a Quality Perspective</h3>
<ul>
<li><strong>Authors: </strong>Zengbin Wang, Saihui Hou, Man Zhang, Xu Liu, Chunshui Cao, Yongzhen Huang, Peipei Li, Shibiao Xu</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.13531">https://arxiv.org/abs/2401.13531</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.13531">https://arxiv.org/pdf/2401.13531</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.13531]] QAGait: Revisit Gait Recognition from a Quality Perspective(https://arxiv.org/abs/2401.13531)</code><input type="text"></li>
<li><strong>Keywords: </strong>biometric, segmentation</a></li>
<li><strong>Abstract: </strong>Gait recognition is a promising biometric method that aims to identify pedestrians from their unique walking patterns. Silhouette modality, renowned for its easy acquisition, simple structure, sparse representation, and convenient modeling, has been widely employed in controlled in-the-lab research. However, as gait recognition rapidly advances from in-the-lab to in-the-wild scenarios, various conditions raise significant challenges for silhouette modality, including 1) unidentifiable low-quality silhouettes (abnormal segmentation, severe occlusion, or even non-human shape), and 2) identifiable but challenging silhouettes (background noise, non-standard posture, slight occlusion). To address these challenges, we revisit gait recognition pipeline and approach gait recognition from a quality perspective, namely QAGait. Specifically, we propose a series of cost-effective quality assessment strategies, including Maxmial Connect Area and Template Match to eliminate background noises and unidentifiable silhouettes, Alignment strategy to handle non-standard postures. We also propose two quality-aware loss functions to integrate silhouette quality into optimization within the embedding space. Extensive experiments demonstrate our QAGait can guarantee both gait reliability and performance enhancement. Furthermore, our quality assessment strategies can seamlessly integrate with existing gait datasets, showcasing our superiority. Code is available at https://github.com/wzb-bupt/QAGait.</li>
</ul>

<h3>Title: Benchmarking the Fairness of Image Upsampling Methods</h3>
<ul>
<li><strong>Authors: </strong>Mike Laszkiewicz, Imant Daunhawer, Julia E. Vogt, Asja Fischer, Johannes Lederer</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.13555">https://arxiv.org/abs/2401.13555</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.13555">https://arxiv.org/pdf/2401.13555</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.13555]] Benchmarking the Fairness of Image Upsampling Methods(https://arxiv.org/abs/2401.13555)</code><input type="text"></li>
<li><strong>Keywords: </strong>fair, generative</a></li>
<li><strong>Abstract: </strong>Recent years have witnessed a rapid development of deep generative models for creating synthetic media, such as images and videos. While the practical applications of these models in everyday tasks are enticing, it is crucial to assess the inherent risks regarding their fairness. In this work, we introduce a comprehensive framework for benchmarking the performance and fairness of conditional generative models. We develop a set of metrics$\unicode{x2013}$inspired by their supervised fairness counterparts$\unicode{x2013}$to evaluate the models on their fairness and diversity. Focusing on the specific application of image upsampling, we create a benchmark covering a wide variety of modern upsampling methods. As part of the benchmark, we introduce UnfairFace, a subset of FairFace that replicates the racial distribution of common large-scale face datasets. Our empirical study highlights the importance of using an unbiased training set and reveals variations in how the algorithms respond to dataset imbalances. Alarmingly, we find that none of the considered methods produces statistically fair and diverse results.</li>
</ul>

<h3>Title: SegMamba: Long-range Sequential Modeling Mamba For 3D Medical Image  Segmentation</h3>
<ul>
<li><strong>Authors: </strong>Zhaohu Xing, Tian Ye, Yijun Yang, Guang Liu, Lei Zhu</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.13560">https://arxiv.org/abs/2401.13560</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.13560">https://arxiv.org/pdf/2401.13560</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.13560]] SegMamba: Long-range Sequential Modeling Mamba For 3D Medical Image  Segmentation(https://arxiv.org/abs/2401.13560)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer, segmentation</a></li>
<li><strong>Abstract: </strong>The Transformer architecture has shown a remarkable ability in modeling global relationships. However, it poses a significant computational challenge when processing high-dimensional medical images. This hinders its development and widespread adoption in this task. Mamba, as a State Space Model (SSM), recently emerged as a notable manner for long-range dependencies in sequential modeling, excelling in natural language processing filed with its remarkable memory efficiency and computational speed. Inspired by its success, we introduce SegMamba, a novel 3D medical image \textbf{Seg}mentation \textbf{Mamba} model, designed to effectively capture long-range dependencies within whole volume features at every scale. Our SegMamba, in contrast to Transformer-based methods, excels in whole volume feature modeling from a state space model standpoint, maintaining superior processing speed, even with volume features at a resolution of {$64\times 64\times 64$}. Comprehensive experiments on the BraTS2023 dataset demonstrate the effectiveness and efficiency of our SegMamba. The code for SegMamba is available at: https://github.com/ge-xing/SegMamba</li>
</ul>

<h3>Title: CNN architecture extraction on edge GPU</h3>
<ul>
<li><strong>Authors: </strong>Peter Horvath, Lukasz Chmielewski, Leo Weissbart, Lejla Batina, Yuval Yarom</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.13575">https://arxiv.org/abs/2401.13575</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.13575">https://arxiv.org/pdf/2401.13575</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.13575]] CNN architecture extraction on edge GPU(https://arxiv.org/abs/2401.13575)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack, extraction</a></li>
<li><strong>Abstract: </strong>Neural networks have become popular due to their versatility and state-of-the-art results in many applications, such as image classification, natural language processing, speech recognition, forecasting, etc. These applications are also used in resource-constrained environments such as embedded devices. In this work, the susceptibility of neural network implementations to reverse engineering is explored on the NVIDIA Jetson Nano microcomputer via side-channel analysis. To this end, an architecture extraction attack is presented. In the attack, 15 popular convolutional neural network architectures (EfficientNets, MobileNets, NasNet, etc.) are implemented on the GPU of Jetson Nano and the electromagnetic radiation of the GPU is analyzed during the inference operation of the neural networks. The results of the analysis show that neural network architectures are easily distinguishable using deep learning-based side-channel analysis.</li>
</ul>

<h3>Title: WPDA: Frequency-based Backdoor Attack with Wavelet Packet Decomposition</h3>
<ul>
<li><strong>Authors: </strong>Zhengyao Song, Yongqiang Li, Danni Yuan, Li Liu, Shaokui Wei, Baoyuan Wu</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.13578">https://arxiv.org/abs/2401.13578</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.13578">https://arxiv.org/pdf/2401.13578</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.13578]] WPDA: Frequency-based Backdoor Attack with Wavelet Packet Decomposition(https://arxiv.org/abs/2401.13578)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, defense, attack, steal</a></li>
<li><strong>Abstract: </strong>This work explores an emerging security threat against deep neural networks (DNNs) based image classification, i.e., backdoor attack. In this scenario, the attacker aims to inject a backdoor into the model by manipulating training data, such that the backdoor could be activated by a particular trigger and bootstraps the model to make a target prediction at inference. Currently, most existing data poisoning-based attacks struggle to achieve success at low poisoning ratios, increasing the risk of being defended by defense methods. In this paper, we propose a novel frequency-based backdoor attack via Wavelet Packet Decomposition (WPD), WPD decomposes the original image signal to a spectrogram that contains frequency information with different semantic meanings. We leverage WPD to statistically analyze the frequency distribution of the dataset to infer the key frequency regions the DNNs would focus on, and the trigger information is only injected into the key frequency regions. Our method mainly includes three parts: 1) the selection of the poisoning frequency regions in spectrogram; 2) trigger generation; 3) the generation of the poisoned dataset. Our method is stealthy and precise, evidenced by the 98.12% Attack Success Rate (ASR) on CIFAR-10 with the extremely low poisoning ratio 0.004% (i.e., only 2 poisoned samples among 50,000 training samples) and can bypass most existing defense methods. Besides, we also provide visualization analyses to explain why our method works.</li>
</ul>

<h3>Title: Securing the Invisible Thread: A Comprehensive Analysis of BLE Tracker  Security in Apple AirTags and Samsung SmartTags</h3>
<ul>
<li><strong>Authors: </strong>Hosam Alamleh, Michael Gogarty, David Ruddell, Ali Abdullah S. AlQahtani</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.13584">https://arxiv.org/abs/2401.13584</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.13584">https://arxiv.org/pdf/2401.13584</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.13584]] Securing the Invisible Thread: A Comprehensive Analysis of BLE Tracker  Security in Apple AirTags and Samsung SmartTags(https://arxiv.org/abs/2401.13584)</code><input type="text"></li>
<li><strong>Keywords: </strong>secure, security, privacy, attack</a></li>
<li><strong>Abstract: </strong>This study presents an in-depth analysis of the security landscape in Bluetooth Low Energy (BLE) tracking systems, with a particular emphasis on Apple AirTags and Samsung SmartTags, including their cryptographic frameworks. Our investigation traverses a wide spectrum of attack vectors such as physical tampering, firmware exploitation, signal spoofing, eavesdropping, jamming, app security flaws, Bluetooth security weaknesses, location spoofing, threats to owner devices, and cloud-related vulnerabilities. Moreover, we delve into the security implications of the cryptographic methods utilized in these systems. Our findings reveal that while BLE trackers like AirTags and SmartTags offer substantial utility, they also pose significant security risks. Notably, Apple's approach, which prioritizes user privacy by removing intermediaries, inadvertently leads to device authentication challenges, evidenced by successful AirTag spoofing instances. Conversely, Samsung SmartTags, designed to thwart beacon spoofing, raise critical concerns about cloud security and user privacy. Our analysis also highlights the constraints faced by these devices due to their design focus on battery life conservation, particularly the absence of secure boot processes, which leaves them susceptible to OS modification and a range of potential attacks. The paper concludes with insights into the anticipated evolution of these tracking systems. We predict that future enhancements will likely focus on bolstering security features, especially as these devices become increasingly integrated into the broader IoT ecosystem and face evolving privacy regulations. This shift is imperative to address the intricate balance between functionality and security in next-generation BLE tracking systems.</li>
</ul>

<h3>Title: Evaluation of General Large Language Models in Contextually Assessing  Semantic Concepts Extracted from Adult Critical Care Electronic Health Record  Notes</h3>
<ul>
<li><strong>Authors: </strong>Darren Liu, Cheng Ding, Delgersuren Bold, Monique Bouvier, Jiaying Lu, Benjamin Shickel, Craig S. Jabaley, Wenhui Zhang, Soojin Park, Michael J. Young, Mark S. Wainwright, Gilles Clermont, Parisa Rashidi, Eric S. Rosenthal, Laurie Dimisko, Ran Xiao, Joo Heung Yoon, Carl Yang, Xiao Hu</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.SE</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.13588">https://arxiv.org/abs/2401.13588</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.13588">https://arxiv.org/pdf/2401.13588</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.13588]] Evaluation of General Large Language Models in Contextually Assessing  Semantic Concepts Extracted from Adult Critical Care Electronic Health Record  Notes(https://arxiv.org/abs/2401.13588)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>The field of healthcare has increasingly turned its focus towards Large Language Models (LLMs) due to their remarkable performance. However, their performance in actual clinical applications has been underexplored. Traditional evaluations based on question-answering tasks don't fully capture the nuanced contexts. This gap highlights the need for more in-depth and practical assessments of LLMs in real-world healthcare settings. Objective: We sought to evaluate the performance of LLMs in the complex clinical context of adult critical care medicine using systematic and comprehensible analytic methods, including clinician annotation and adjudication. Methods: We investigated the performance of three general LLMs in understanding and processing real-world clinical notes. Concepts from 150 clinical notes were identified by MetaMap and then labeled by 9 clinicians. Each LLM's proficiency was evaluated by identifying the temporality and negation of these concepts using different prompts for an in-depth analysis. Results: GPT-4 showed overall superior performance compared to other LLMs. In contrast, both GPT-3.5 and text-davinci-003 exhibit enhanced performance when the appropriate prompting strategies are employed. The GPT family models have demonstrated considerable efficiency, evidenced by their cost-effectiveness and time-saving capabilities. Conclusion: A comprehensive qualitative performance evaluation framework for LLMs is developed and operationalized. This framework goes beyond singular performance aspects. With expert annotations, this methodology not only validates LLMs' capabilities in processing complex medical data but also establishes a benchmark for future LLM evaluations across specialized domains.</li>
</ul>

<h3>Title: Graph Guided Question Answer Generation for Procedural  Question-Answering</h3>
<ul>
<li><strong>Authors: </strong>Hai X. Pham, Isma Hadji, Xinnuo Xu, Ziedune Degutyte, Jay Rainey, Evangelos Kazakos, Afsaneh Fazly, Georgios Tzimiropoulos, Brais Martinez</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.13594">https://arxiv.org/abs/2401.13594</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.13594">https://arxiv.org/pdf/2401.13594</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.13594]] Graph Guided Question Answer Generation for Procedural  Question-Answering(https://arxiv.org/abs/2401.13594)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>In this paper, we focus on task-specific question answering (QA). To this end, we introduce a method for generating exhaustive and high-quality training data, which allows us to train compact (e.g., run on a mobile device), task-specific QA models that are competitive against GPT variants. The key technological enabler is a novel mechanism for automatic question-answer generation from procedural text which can ingest large amounts of textual instructions and produce exhaustive in-domain QA training data. While current QA data generation methods can produce well-formed and varied data, their non-exhaustive nature is sub-optimal for training a QA model. In contrast, we leverage the highly structured aspect of procedural text and represent each step and the overall flow of the procedure as graphs. We then condition on graph nodes to automatically generate QA pairs in an exhaustive and controllable manner. Comprehensive evaluations of our method show that: 1) small models trained with our data achieve excellent performance on the target QA task, even exceeding that of GPT3 and ChatGPT despite being several orders of magnitude smaller. 2) semantic coverage is the key indicator for downstream QA performance. Crucially, while large language models excel at syntactic diversity, this does not necessarily result in improvements on the end QA model. In contrast, the higher semantic coverage provided by our method is critical for QA performance.</li>
</ul>

<h3>Title: Consistency Guided Knowledge Retrieval and Denoising in LLMs for  Zero-shot Document-level Relation Triplet Extraction</h3>
<ul>
<li><strong>Authors: </strong>Qi Sun, Kun Huang, Xiaocui Yang, Rong Tong, Kun Zhang, Soujanya Poria</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.13598">https://arxiv.org/abs/2401.13598</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.13598">https://arxiv.org/pdf/2401.13598</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.13598]] Consistency Guided Knowledge Retrieval and Denoising in LLMs for  Zero-shot Document-level Relation Triplet Extraction(https://arxiv.org/abs/2401.13598)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction, large language model</a></li>
<li><strong>Abstract: </strong>Document-level Relation Triplet Extraction (DocRTE) is a fundamental task in information systems that aims to simultaneously extract entities with semantic relations from a document. Existing methods heavily rely on a substantial amount of fully labeled data. However, collecting and annotating data for newly emerging relations is time-consuming and labor-intensive. Recent advanced Large Language Models (LLMs), such as ChatGPT and LLaMA, exhibit impressive long-text generation capabilities, inspiring us to explore an alternative approach for obtaining auto-labeled documents with new relations. In this paper, we propose a Zero-shot Document-level Relation Triplet Extraction (ZeroDocRTE) framework, which generates labeled data by retrieval and denoising knowledge from LLMs, called GenRDK. Specifically, we propose a chain-of-retrieval prompt to guide ChatGPT to generate labeled long-text data step by step. To improve the quality of synthetic data, we propose a denoising strategy based on the consistency of cross-document knowledge. Leveraging our denoised synthetic data, we proceed to fine-tune the LLaMA2-13B-Chat for extracting document-level relation triplets. We perform experiments for both zero-shot document-level relation and triplet extraction on two public datasets. The experimental results illustrate that our GenRDK framework outperforms strong baselines.</li>
</ul>

<h3>Title: MM-LLMs: Recent Advances in MultiModal Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Duzhen Zhang, Yahan Yu, Chenxing Li, Jiahua Dong, Dan Su, Chenhui Chu, Dong Yu</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.13601">https://arxiv.org/abs/2401.13601</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.13601">https://arxiv.org/pdf/2401.13601</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.13601]] MM-LLMs: Recent Advances in MultiModal Large Language Models(https://arxiv.org/abs/2401.13601)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>In the past year, MultiModal Large Language Models (MM-LLMs) have undergone substantial advancements, augmenting off-the-shelf LLMs to support MM inputs or outputs via cost-effective training strategies. The resulting models not only preserve the inherent reasoning and decision-making capabilities of LLMs but also empower a diverse range of MM tasks. In this paper, we provide a comprehensive survey aimed at facilitating further research of MM-LLMs. Specifically, we first outline general design formulations for model architecture and training pipeline. Subsequently, we provide brief introductions of $26$ existing MM-LLMs, each characterized by its specific formulations. Additionally, we review the performance of MM-LLMs on mainstream benchmarks and summarize key training recipes to enhance the potency of MM-LLMs. Lastly, we explore promising directions for MM-LLMs while concurrently maintaining a real-time tracking website for the latest developments in the field. We hope that this survey contributes to the ongoing advancement of the MM-LLMs domain.</li>
</ul>

<h3>Title: Scaling Up to Excellence: Practicing Model Scaling for Photo-Realistic  Image Restoration In the Wild</h3>
<ul>
<li><strong>Authors: </strong>Fanghua Yu, Jinjin Gu, Zheyuan Li, Jinfan Hu, Xiangtao Kong, Xintao Wang, Jingwen He, Yu Qiao, Chao Dong</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.13627">https://arxiv.org/abs/2401.13627</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.13627">https://arxiv.org/pdf/2401.13627</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.13627]] Scaling Up to Excellence: Practicing Model Scaling for Photo-Realistic  Image Restoration In the Wild(https://arxiv.org/abs/2401.13627)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>We introduce SUPIR (Scaling-UP Image Restoration), a groundbreaking image restoration method that harnesses generative prior and the power of model scaling up. Leveraging multi-modal techniques and advanced generative prior, SUPIR marks a significant advance in intelligent and realistic image restoration. As a pivotal catalyst within SUPIR, model scaling dramatically enhances its capabilities and demonstrates new potential for image restoration. We collect a dataset comprising 20 million high-resolution, high-quality images for model training, each enriched with descriptive text annotations. SUPIR provides the capability to restore images guided by textual prompts, broadening its application scope and potential. Moreover, we introduce negative-quality prompts to further improve perceptual quality. We also develop a restoration-guided sampling method to suppress the fidelity issue encountered in generative-based restoration. Experiments demonstrate SUPIR's exceptional restoration effects and its novel capacity to manipulate restoration through textual prompts.</li>
</ul>

<h3>Title: How Good is ChatGPT at Face Biometrics? A First Look into Recognition,  Soft Biometrics, and Explainability</h3>
<ul>
<li><strong>Authors: </strong>Ivan DeAndres-Tame, Ruben Tolosana, Ruben Vera-Rodriguez, Aythami Morales, Julian Fierrez, Javier Ortega-Garcia</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI, cs.CY, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.13641">https://arxiv.org/abs/2401.13641</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.13641">https://arxiv.org/pdf/2401.13641</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.13641]] How Good is ChatGPT at Face Biometrics? A First Look into Recognition,  Soft Biometrics, and Explainability(https://arxiv.org/abs/2401.13641)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, biometric, explainability, large language model</a></li>
<li><strong>Abstract: </strong>Large Language Models (LLMs) such as GPT developed by OpenAI, have already shown astonishing results, introducing quick changes in our society. This has been intensified by the release of ChatGPT which allows anyone to interact in a simple conversational way with LLMs, without any experience in the field needed. As a result, ChatGPT has been rapidly applied to many different tasks such as code- and song-writer, education, virtual assistants, etc., showing impressive results for tasks for which it was not trained (zero-shot learning). The present study aims to explore the ability of ChatGPT, based on the recent GPT-4 multimodal LLM, for the task of face biometrics. In particular, we analyze the ability of ChatGPT to perform tasks such as face verification, soft-biometrics estimation, and explainability of the results. ChatGPT could be very valuable to further increase the explainability and transparency of the automatic decisions in human scenarios. Experiments are carried out in order to evaluate the performance and robustness of ChatGPT, using popular public benchmarks and comparing the results with state-of-the-art methods in the field. The results achieved in this study show the potential of LLMs such as ChatGPT for face biometrics, especially to enhance explainability. For reproducibility reasons, we release all the code in GitHub.</li>
</ul>

<h3>Title: Graph-Informed Neural Networks for Sparse Grid-Based Discontinuity  Detectors</h3>
<ul>
<li><strong>Authors: </strong>Francesco Della Santa, Sandra Pieraccini</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, math.NA</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.13652">https://arxiv.org/abs/2401.13652</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.13652">https://arxiv.org/pdf/2401.13652</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.13652]] Graph-Informed Neural Networks for Sparse Grid-Based Discontinuity  Detectors(https://arxiv.org/abs/2401.13652)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>In this paper, we present a novel approach for detecting the discontinuity interfaces of a discontinuous function. This approach leverages Graph-Informed Neural Networks (GINNs) and sparse grids to address discontinuity detection also in domains of dimension larger than 3. GINNs, trained to identify troubled points on sparse grids, exploit graph structures built on the grids to achieve efficient and accurate discontinuity detection performances. We also introduce a recursive algorithm for general sparse grid-based detectors, characterized by convergence properties and easy applicability. Numerical experiments on functions with dimensions n = 2 and n = 4 demonstrate the efficiency and robust generalization of GINNs in detecting discontinuity interfaces. Notably, the trained GINNs offer portability and versatility, allowing integration into various algorithms and sharing among users.</li>
</ul>

<h3>Title: Inadequacy of common stochastic neural networks for reliable clinical  decision support</h3>
<ul>
<li><strong>Authors: </strong>Adrian Lindenmeyer, Malte Blattmann, Stefan Franke, Thomas Neumuth, Daniel Schneider</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.13657">https://arxiv.org/abs/2401.13657</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.13657">https://arxiv.org/pdf/2401.13657</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.13657]] Inadequacy of common stochastic neural networks for reliable clinical  decision support(https://arxiv.org/abs/2401.13657)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Widespread adoption of AI for medical decision making is still hindered due to ethical and safety-related concerns. For AI-based decision support systems in healthcare settings it is paramount to be reliable and trustworthy. Common deep learning approaches, however, have the tendency towards overconfidence under data shift. Such inappropriate extrapolation beyond evidence-based scenarios may have dire consequences. This highlights the importance of reliable estimation of local uncertainty and its communication to the end user. While stochastic neural networks have been heralded as a potential solution to these issues, this study investigates their actual reliability in clinical applications. We centered our analysis on the exemplary use case of mortality prediction for ICU hospitalizations using EHR from MIMIC3 study. For predictions on the EHR time series, Encoder-Only Transformer models were employed. Stochasticity of model functions was achieved by incorporating common methods such as Bayesian neural network layers and model ensembles. Our models achieve state of the art performance in terms of discrimination performance (AUC ROC: 0.868+-0.011, AUC PR: 0.554+-0.034) and calibration on the mortality prediction benchmark. However, epistemic uncertainty is critically underestimated by the selected stochastic deep learning methods. A heuristic proof for the responsible collapse of the posterior distribution is provided. Our findings reveal the inadequacy of commonly used stochastic deep learning approaches to reliably recognize OoD samples. In both methods, unsubstantiated model confidence is not prevented due to strongly biased functional posteriors, rendering them inappropriate for reliable clinical decision support. This highlights the need for approaches with more strictly enforced or inherent distance-awareness to known data points, e.g., using kernel-based techniques.</li>
</ul>

<h3>Title: MambaByte: Token-free Selective State Space Model</h3>
<ul>
<li><strong>Authors: </strong>Junxiong Wang, Tushaar Gangavarapu, Jing Nathan Yan, Alexander M Rush</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.13660">https://arxiv.org/abs/2401.13660</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.13660">https://arxiv.org/pdf/2401.13660</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.13660]] MambaByte: Token-free Selective State Space Model(https://arxiv.org/abs/2401.13660)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Token-free language models learn directly from raw bytes and remove the bias of subword tokenization. Operating on bytes, however, results in significantly longer sequences, and standard autoregressive Transformers scale poorly in such settings. We experiment with MambaByte, a token-free adaptation of the Mamba state space model, trained autoregressively on byte sequences. Our experiments indicate the computational efficiency of MambaByte compared to other byte-level models. We also find MambaByte to be competitive with and even outperform state-of-the-art subword Transformers. Furthermore, owing to linear scaling in length, MambaByte benefits from fast inference compared to Transformers. Our findings establish the viability of MambaByte in enabling token-free language modeling.</li>
</ul>

<button id="copy">Copy All</button>
</article>
<script src="../../javascript/clipboard.min.js"></script>
<script src="../../javascript/clipboard.js"></script>
