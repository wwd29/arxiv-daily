<link rel="stylesheet" href="../../css/markdown.css" />
<article class="markdown-body">
<h2>secure</h2>
<h3>Title: Wink: Deniable Secure Messaging. (arXiv:2207.08891v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2207.08891">http://arxiv.org/abs/2207.08891</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2207.08891] Wink: Deniable Secure Messaging](http://arxiv.org/abs/2207.08891)</code></li>
<li>Summary: <p>End-to-end encrypted (E2EE) messaging is an essential first step towards
combating increasingly privacy-intrusive laws. Unfortunately, it is vulnerable
to compelled key disclosure -- law-mandated, coerced, or simply by device
compromise. This work introduces Wink, the first plausibly-deniable messaging
system protecting message confidentiality even when users are coerced to hand
over keys/passwords. Wink can surreptitiously inject hidden messages in the
standard random coins (e.g., salt, IVs) used by existing E2EE protocols. It
does so as part of legitimate secure cryptographic functionality deployed
inside widely-available trusted execution environments (TEEs) such as
TrustZone. This provides a powerful mechanism for hidden untraceable
communication using virtually unchanged unsuspecting existing E2EE messaging
apps, as well as strong plausible deniability. Wink has been demonstrated with
multiple existing E2EE applications (including Telegram and Signal) with
minimal (external) instrumentation, negligible overheads, and crucially without
changing on-wire message formats.
</p></li>
</ul>

<h3>Title: Blindfold: Keeping Private Keys in PKIs and CDNs out of Sight. (arXiv:2207.09335v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2207.09335">http://arxiv.org/abs/2207.09335</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2207.09335] Blindfold: Keeping Private Keys in PKIs and CDNs out of Sight](http://arxiv.org/abs/2207.09335)</code></li>
<li>Summary: <p>Public key infrastructure (PKI) is a certificate-based technology that helps
in authenticating systems identities. HTTPS/TLS relies mainly on PKI to
minimize fraud over the Internet. Nowadays, websites utilize CDNs to improve
user experience, performance, and resilience against cyber attacks. However,
combining HTTPS/TLS with CDNs has raised new security challenges. In any PKI
system, keeping private keys private is of utmost importance. However, it has
become the norm for CDN-powered websites to violate that fundamental
assumption. Several solutions have been proposed to make HTTPS CDN-friendly.
However, protection of private keys from the very instance of generation; and
how they can be made secure against exposure by malicious (CDN) administrators
and malware remain unexplored. We utilize trusted execution environments to
protect private keys by never exposing them to human operators or untrusted
software. We design Blindfold to protect private keys in HTTPS/TLS
infrastructures, including CAs, website on-premise servers, and CDNs. We
implemented a prototype to assess Blindfold's performance and performed several
experiments on both the micro and macro levels. We found that Blindfold
slightly outperforms SoftHSM in key generation by 1% while lagging by 0.01% for
certificate issuance operations.
</p></li>
</ul>

<h2>security</h2>
<h3>Title: A Security &amp; Privacy Analysis of US-based Contact Tracing Apps. (arXiv:2207.08978v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2207.08978">http://arxiv.org/abs/2207.08978</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2207.08978] A Security &amp; Privacy Analysis of US-based Contact Tracing Apps](http://arxiv.org/abs/2207.08978)</code></li>
<li>Summary: <p>With the onset of COVID-19, governments worldwide planned to develop and
deploy contact tracing apps to help speed up the contact tracing process.
However, experts raised concerns about the long-term privacy and security
implications of using these apps. Consequently, several proposals were made to
design privacy-preserving contact tracing apps. To this end, Google and Apple
developed the Google/Apple Exposure Notification (GAEN) framework to help
public health authorities develop privacy-preserving contact tracing apps. In
the United States, 26 states used the GAEN framework to develop their contact
tracing apps. In this paper, we empirically evaluate the US-based apps to
determine 1) the privileges these apps have, 2) if the apps comply with their
defined privacy policies, and 3) if they contain known vulnerabilities that can
be exploited to compromise privacy. The results show that all apps violate
their privacy policies and contain several known vulnerabilities.
</p></li>
</ul>

<h3>Title: Enhancing Security Patch Identification by Capturing Structures in Commits. (arXiv:2207.09022v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2207.09022">http://arxiv.org/abs/2207.09022</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2207.09022] Enhancing Security Patch Identification by Capturing Structures in Commits](http://arxiv.org/abs/2207.09022)</code></li>
<li>Summary: <p>With the rapid increasing number of open source software (OSS), the majority
of the software vulnerabilities in the open source components are fixed
silently, which leads to the deployed software that integrated them being
unable to get a timely update. Hence, it is critical to design a security patch
identification system to ensure the security of the utilized software. However,
most of the existing works for security patch identification just consider the
changed code and the commit message of a commit as a flat sequence of tokens
with simple neural networks to learn its semantics, while the structure
information is ignored. To address these limitations, in this paper, we propose
our well-designed approach E-SPI, which extracts the structure information
hidden in a commit for effective identification. Specifically, it consists of
the code change encoder to extract the syntactic of the changed code with the
BiLSTM to learn the code representation and the message encoder to construct
the dependency graph for the commit message with the graph neural network (GNN)
to learn the message representation. We further enhance the code change encoder
by embedding contextual information related to the changed code. To demonstrate
the effectiveness of our approach, we conduct the extensive experiments against
six state-of-the-art approaches on the existing dataset and from the real
deployment environment. The experimental results confirm that our approach can
significantly outperform current state-of-the-art baselines.
</p></li>
</ul>

<h3>Title: A Survey on EOSIO Systems Security: Vulnerability, Attack, and Mitigation. (arXiv:2207.09227v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2207.09227">http://arxiv.org/abs/2207.09227</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2207.09227] A Survey on EOSIO Systems Security: Vulnerability, Attack, and Mitigation](http://arxiv.org/abs/2207.09227)</code></li>
<li>Summary: <p>EOSIO, as one of the most representative blockchain 3.0 platforms, involves
lots of new features, e.g., delegated proof of stake consensus algorithm and
updatable smart contracts, enabling a much higher transaction per second and
the prosperous decentralized applications (DApps) ecosystem. According to the
statistics, it has reached nearly 18 billion USD, taking the third place of the
whole cryptocurrency market, following Bitcoin and Ethereum. Loopholes,
however, are hiding in the shadows. EOSBet, a famous gambling DApp, was
attacked twice within a month and lost more than 1 million USD. No existing
work has surveyed the EOSIO from a security researcher perspective. To fill
this gap, in this paper, we collected all occurred attack events against EOSIO,
and systematically studied their root causes, i.e., vulnerabilities lurked in
all relying components for EOSIO, as well as the corresponding attacks and
mitigations. We also summarized some best practices for DApp developers, EOSIO
official team, and security researchers for future directions.
</p></li>
</ul>

<h2>privacy</h2>
<h3>Title: ILASR: Privacy-Preserving Incremental Learning for AutomaticSpeech Recognition at Production Scale. (arXiv:2207.09078v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2207.09078">http://arxiv.org/abs/2207.09078</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2207.09078] ILASR: Privacy-Preserving Incremental Learning for AutomaticSpeech Recognition at Production Scale](http://arxiv.org/abs/2207.09078)</code></li>
<li>Summary: <p>Incremental learning is one paradigm to enable model building and updating at
scale with streaming data. For end-to-end automatic speech recognition (ASR)
tasks, the absence of human annotated labels along with the need for privacy
preserving policies for model building makes it a daunting challenge. Motivated
by these challenges, in this paper we use a cloud based framework for
production systems to demonstrate insights from privacy preserving incremental
learning for automatic speech recognition (ILASR). By privacy preserving, we
mean, usage of ephemeral data which are not human annotated. This system is a
step forward for production levelASR models for incremental/continual learning
that offers near real-time test-bed for experimentation in the cloud for
end-to-end ASR, while adhering to privacy-preserving policies. We show that the
proposed system can improve the production models significantly(3%) over a new
time period of six months even in the absence of human annotated labels with
varying levels of weak supervision and large batch sizes in incremental
learning. This improvement is 20% over test sets with new words and phrases in
the new time period. We demonstrate the effectiveness of model building in a
privacy-preserving incremental fashion for ASR while further exploring the
utility of having an effective teacher model and use of large batch sizes.
</p></li>
</ul>

<h3>Title: MUD-PQFed: Towards Malicious User Detection in Privacy-Preserving Quantized Federated Learning. (arXiv:2207.09080v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2207.09080">http://arxiv.org/abs/2207.09080</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2207.09080] MUD-PQFed: Towards Malicious User Detection in Privacy-Preserving Quantized Federated Learning](http://arxiv.org/abs/2207.09080)</code></li>
<li>Summary: <p>Federated Learning (FL), a distributed machine learning paradigm, has been
adapted to mitigate privacy concerns for customers. Despite their appeal, there
are various inference attacks that can exploit shared-plaintext model updates
to embed traces of customer private information, leading to serious privacy
concerns. To alleviate this privacy issue, cryptographic techniques such as
Secure Multi-Party Computation and Homomorphic Encryption have been used for
privacy-preserving FL. However, such security issues in privacy-preserving FL
are poorly elucidated and underexplored. This work is the first attempt to
elucidate the triviality of performing model corruption attacks on
privacy-preserving FL based on lightweight secret sharing. We consider
scenarios in which model updates are quantized to reduce communication overhead
in this case, where an adversary can simply provide local parameters outside
the legal range to corrupt the model. We then propose the MUD-PQFed protocol,
which can precisely detect malicious clients performing attacks and enforce
fair penalties. By removing the contributions of detected malicious clients,
the global model utility is preserved to be comparable to the baseline global
model without the attack. Extensive experiments validate effectiveness in
maintaining baseline accuracy and detecting malicious clients in a fine-grained
manner
</p></li>
</ul>

<h3>Title: Is Vertical Logistic Regression Privacy-Preserving? A Comprehensive Privacy Analysis and Beyond. (arXiv:2207.09087v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2207.09087">http://arxiv.org/abs/2207.09087</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2207.09087] Is Vertical Logistic Regression Privacy-Preserving? A Comprehensive Privacy Analysis and Beyond](http://arxiv.org/abs/2207.09087)</code></li>
<li>Summary: <p>We consider vertical logistic regression (VLR) trained with mini-batch
gradient descent -- a setting which has attracted growing interest among
industries and proven to be useful in a wide range of applications including
finance and medical research. We provide a comprehensive and rigorous privacy
analysis of VLR in a class of open-source Federated Learning frameworks, where
the protocols might differ between one another, yet a procedure of obtaining
local gradients is implicitly shared. We first consider the honest-but-curious
threat model, in which the detailed implementation of protocol is neglected and
only the shared procedure is assumed, which we abstract as an oracle. We find
that even under this general setting, single-dimension feature and label can
still be recovered from the other party under suitable constraints of batch
size, thus demonstrating the potential vulnerability of all frameworks
following the same philosophy. Then we look into a popular instantiation of the
protocol based on Homomorphic Encryption (HE). We propose an active attack that
significantly weaken the constraints on batch size in the previous analysis via
generating and compressing auxiliary ciphertext. To address the privacy leakage
within the HE-based protocol, we develop a simple-yet-effective countermeasure
based on Differential Privacy (DP), and provide both utility and privacy
guarantees for the updated algorithm. Finally, we empirically verify the
effectiveness of our attack and defense on benchmark datasets. Altogether, our
findings suggest that all vertical federated learning frameworks that solely
depend on HE might contain severe privacy risks, and DP, which has already
demonstrated its power in horizontal federated learning, can also play a
crucial role in the vertical setting, especially when coupled with HE or secure
multi-party computation (MPC) techniques.
</p></li>
</ul>

<h3>Title: Offline-verifiable Data from Distributed Ledger-based Registries. (arXiv:2207.09319v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2207.09319">http://arxiv.org/abs/2207.09319</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2207.09319] Offline-verifiable Data from Distributed Ledger-based Registries](http://arxiv.org/abs/2207.09319)</code></li>
<li>Summary: <p>Trust management systems often use registries to authenticate data, or form
trust decisions. Examples are revocation registries and trust status lists. By
introducing distributed ledgers (DLs), it is also possible to create
decentralized registries. A verifier then queries a node of the respective
ledger, e.g., to retrieve trust status information during the verification of a
credential. While this ensures trustworthy information, the process requires
the verifier to be online and the ledger node available. Additionally, the
connection from the verifier to the registry poses a privacy issue, as it leaks
information about the user's behavior.
</p></li>
</ul>

<p>In this paper, we resolve these issues by extending existing ledger APIs to
support results that are trustworthy even in an offline setting. We do this by
introducing attestations of the ledger's state, issued by ledger nodes,
aggregatable into a collective attestation by all nodes. This attestation
enables a user to prove the provenance of DL-based data to an offline verifier.
Our approach is generic. So once deployed it serves as a basis for any use case
with an offline verifier. We also provide an implementation for the Ethereum
stack and evaluate it, demonstrating the practicability of our approach.
</p>

<h3>Title: Composition Theorems for Interactive Differential Privacy. (arXiv:2207.09397v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2207.09397">http://arxiv.org/abs/2207.09397</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2207.09397] Composition Theorems for Interactive Differential Privacy](http://arxiv.org/abs/2207.09397)</code></li>
<li>Summary: <p>An interactive mechanism is an algorithm that stores a data set and answers
adaptively chosen queries to it. The mechanism is called differentially
private, if any adversary cannot distinguish whether a specific individual is
in the data set by interacting with the mechanism. We study composition
properties of differential privacy in concurrent compositions. In this setting,
an adversary interacts with k interactive mechanisms in parallel and can
interleave its queries to the mechanisms arbitrarily. Previously, [Vadhan and
Wang, TCC 2021] proved an optimal concurrent composition theorem for
pure-differential privacy. We significantly generalize and extend their
results. Namely, we prove optimal parallel composition properties for several
major notions of differential privacy in the literature, including approximate
DP, R\'enyi DP, and zero-concentrated DP. Our results demonstrate that the
adversary gains no advantage by interleaving its queries to independently
running mechanisms. Hence, interactivity is a feature that differential privacy
grants us for free.
</p></li>
</ul>

<h2>protect</h2>
<h2>defense</h2>
<h2>attack</h2>
<h3>Title: Prior-Guided Adversarial Initialization for Fast Adversarial Training. (arXiv:2207.08859v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2207.08859">http://arxiv.org/abs/2207.08859</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2207.08859] Prior-Guided Adversarial Initialization for Fast Adversarial Training](http://arxiv.org/abs/2207.08859)</code></li>
<li>Summary: <p>Fast adversarial training (FAT) effectively improves the efficiency of
standard adversarial training (SAT). However, initial FAT encounters
catastrophic overfitting, i.e.,the robust accuracy against adversarial attacks
suddenly and dramatically decreases. Though several FAT variants spare no
effort to prevent overfitting, they sacrifice much calculation cost. In this
paper, we explore the difference between the training processes of SAT and FAT
and observe that the attack success rate of adversarial examples (AEs) of FAT
gets worse gradually in the late training stage, resulting in overfitting. The
AEs are generated by the fast gradient sign method (FGSM) with a zero or random
initialization. Based on the observation, we propose a prior-guided FGSM
initialization method to avoid overfitting after investigating several
initialization strategies, improving the quality of the AEs during the whole
training process. The initialization is formed by leveraging historically
generated AEs without additional calculation cost. We further provide a
theoretical analysis for the proposed initialization method. We also propose a
simple yet effective regularizer based on the prior-guided initialization,i.e.,
the currently generated perturbation should not deviate too much from the
prior-guided initialization. The regularizer adopts both historical and current
adversarial perturbations to guide the model learning. Evaluations on four
datasets demonstrate that the proposed method can prevent catastrophic
overfitting and outperform state-of-the-art FAT methods. The code is released
at https://github.com/jiaxiaojunQAQ/FGSM-PGI.
</p></li>
</ul>

<h3>Title: Multi-step domain adaptation by adversarial attack to $\mathcal{H} \Delta \mathcal{H}$-divergence. (arXiv:2207.08948v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2207.08948">http://arxiv.org/abs/2207.08948</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2207.08948] Multi-step domain adaptation by adversarial attack to $\mathcal{H} \Delta \mathcal{H}$-divergence](http://arxiv.org/abs/2207.08948)</code></li>
<li>Summary: <p>Adversarial examples are transferable between different models. In our paper,
we propose to use this property for multi-step domain adaptation. In
unsupervised domain adaptation settings, we demonstrate that replacing the
source domain with adversarial examples to $\mathcal{H} \Delta
\mathcal{H}$-divergence can improve source classifier accuracy on the target
domain. Our method can be connected to most domain adaptation techniques. We
conducted a range of experiments and achieved improvement in accuracy on Digits
and Office-Home datasets.
</p></li>
</ul>

<h3>Title: Smart Contract Assisted Blockchain based PKI System. (arXiv:2207.09127v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2207.09127">http://arxiv.org/abs/2207.09127</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2207.09127] Smart Contract Assisted Blockchain based PKI System](http://arxiv.org/abs/2207.09127)</code></li>
<li>Summary: <p>The proposed smart contract can prevent seven cyber attacks, such as Denial
of Service (DoS), Man in the Middle Attack (MITM), Distributed Denial of
Service (DDoS), 51\%, Injection attacks, Routing Attack, and Eclipse attack.
The Delegated Proof of Stake (DPoS) consensus algorithm used in this model
reduces the number of validators for each transaction which makes it suitable
for lightweight applications. The timing complexity of key/certificate
validation and signature/certificate revocation processes do not depend on the
number of transactions. The comparisons of various timing parameters with
existing solutions show that the proposed PKI is competitively better.
</p></li>
</ul>

<h3>Title: FLDetector: Detecting Malicious Clients in Model Poisoning Attacks to Federated Learning. (arXiv:2207.09209v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2207.09209">http://arxiv.org/abs/2207.09209</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2207.09209] FLDetector: Detecting Malicious Clients in Model Poisoning Attacks to Federated Learning](http://arxiv.org/abs/2207.09209)</code></li>
<li>Summary: <p>Federated learning (FL) is vulnerable to model poisoning attacks, in which
malicious clients corrupt the global model via sending manipulated model
updates to the server. Existing defenses mainly rely on Byzantine-robust FL
methods, which aim to learn an accurate global model even if some clients are
malicious. However, they can only resist a small number of malicious clients in
practice. It is still an open challenge how to defend against model poisoning
attacks with a large number of malicious clients. Our FLDetector addresses this
challenge via detecting malicious clients. FLDetector aims to detect and remove
the majority of the malicious clients such that a Byzantine-robust FL method
can learn an accurate global model using the remaining clients. Our key
observation is that, in model poisoning attacks, the model updates from a
client in multiple iterations are inconsistent. Therefore, FLDetector detects
malicious clients via checking their model-updates consistency. Roughly
speaking, the server predicts a client's model update in each iteration based
on its historical model updates using the Cauchy mean value theorem and L-BFGS,
and flags a client as malicious if the received model update from the client
and the predicted model update are inconsistent in multiple iterations. Our
extensive experiments on three benchmark datasets show that FLDetector can
accurately detect malicious clients in multiple state-of-the-art model
poisoning attacks. After removing the detected malicious clients, existing
Byzantine-robust FL methods can learn accurate global models.
</p></li>
</ul>

<h3>Title: Assaying Out-Of-Distribution Generalization in Transfer Learning. (arXiv:2207.09239v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2207.09239">http://arxiv.org/abs/2207.09239</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2207.09239] Assaying Out-Of-Distribution Generalization in Transfer Learning](http://arxiv.org/abs/2207.09239)</code></li>
<li>Summary: <p>Since out-of-distribution generalization is a generally ill-posed problem,
various proxy targets (e.g., calibration, adversarial robustness, algorithmic
corruptions, invariance across shifts) were studied across different research
programs resulting in different recommendations. While sharing the same
aspirational goal, these approaches have never been tested under the same
experimental conditions on real data. In this paper, we take a unified view of
previous work, highlighting message discrepancies that we address empirically,
and providing recommendations on how to measure the robustness of a model and
how to improve it. To this end, we collect 172 publicly available dataset pairs
for training and out-of-distribution evaluation of accuracy, calibration error,
adversarial attacks, environment invariance, and synthetic corruptions. We
fine-tune over 31k networks, from nine different architectures in the many- and
few-shot setting. Our findings confirm that in- and out-of-distribution
accuracies tend to increase jointly, but show that their relation is largely
dataset-dependent, and in general more nuanced and more complex than posited by
previous, smaller scale studies.
</p></li>
</ul>

<h2>robust</h2>
<h3>Title: Easy Batch Normalization. (arXiv:2207.08940v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2207.08940">http://arxiv.org/abs/2207.08940</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2207.08940] Easy Batch Normalization](http://arxiv.org/abs/2207.08940)</code></li>
<li>Summary: <p>It was shown that adversarial examples improve object recognition. But what
about their opposite side, easy examples? Easy examples are samples that the
machine learning model classifies correctly with high confidence. In our paper,
we are making the first step toward exploring the potential benefits of using
easy examples in the training procedure of neural networks. We propose to use
an auxiliary batch normalization for easy examples for the standard and robust
accuracy improvement.
</p></li>
</ul>

<h3>Title: Robustar: Interactive Toolbox Supporting Precise Data Annotation for Robust Vision Learning. (arXiv:2207.08944v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2207.08944">http://arxiv.org/abs/2207.08944</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2207.08944] Robustar: Interactive Toolbox Supporting Precise Data Annotation for Robust Vision Learning](http://arxiv.org/abs/2207.08944)</code></li>
<li>Summary: <p>We introduce the initial release of our software Robustar, which aims to
improve the robustness of vision classification machine learning models through
a data-driven perspective. Building upon the recent understanding that the lack
of machine learning model's robustness is the tendency of the model's learning
of spurious features, we aim to solve this problem from its root at the data
perspective by removing the spurious features from the data before training. In
particular, we introduce a software that helps the users to better prepare the
data for training image classification models by allowing the users to annotate
the spurious features at the pixel level of images. To facilitate this process,
our software also leverages recent advances to help identify potential images
and pixels worthy of attention and to continue the training with newly
annotated data. Our software is hosted at the GitHub Repository
https://github.com/HaohanWang/Robustar.
</p></li>
</ul>

<h3>Title: Exploiting Unlabeled Data with Vision and Language Models for Object Detection. (arXiv:2207.08954v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2207.08954">http://arxiv.org/abs/2207.08954</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2207.08954] Exploiting Unlabeled Data with Vision and Language Models for Object Detection](http://arxiv.org/abs/2207.08954)</code></li>
<li>Summary: <p>Building robust and generic object detection frameworks requires scaling to
larger label spaces and bigger training datasets. However, it is prohibitively
costly to acquire annotations for thousands of categories at a large scale. We
propose a novel method that leverages the rich semantics available in recent
vision and language models to localize and classify objects in unlabeled
images, effectively generating pseudo labels for object detection. Starting
with a generic and class-agnostic region proposal mechanism, we use vision and
language models to categorize each region of an image into any object category
that is required for downstream tasks. We demonstrate the value of the
generated pseudo labels in two specific tasks, open-vocabulary detection, where
a model needs to generalize to unseen object categories, and semi-supervised
object detection, where additional unlabeled images can be used to improve the
model. Our empirical evaluation shows the effectiveness of the pseudo labels in
both tasks, where we outperform competitive baselines and achieve a novel
state-of-the-art for open-vocabulary object detection. Our code is available at
https://github.com/xiaofeng94/VL-PLM.
</p></li>
</ul>

<h3>Title: Box-supervised Instance Segmentation with Level Set Evolution. (arXiv:2207.09055v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2207.09055">http://arxiv.org/abs/2207.09055</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2207.09055] Box-supervised Instance Segmentation with Level Set Evolution](http://arxiv.org/abs/2207.09055)</code></li>
<li>Summary: <p>In contrast to the fully supervised methods using pixel-wise mask labels,
box-supervised instance segmentation takes advantage of the simple box
annotations, which has recently attracted a lot of research attentions. In this
paper, we propose a novel single-shot box-supervised instance segmentation
approach, which integrates the classical level set model with deep neural
network delicately. Specifically, our proposed method iteratively learns a
series of level sets through a continuous Chan-Vese energy-based function in an
end-to-end fashion. A simple mask supervised SOLOv2 model is adapted to predict
the instance-aware mask map as the level set for each instance. Both the input
image and its deep features are employed as the input data to evolve the level
set curves, where a box projection function is employed to obtain the initial
boundary. By minimizing the fully differentiable energy function, the level set
for each instance is iteratively optimized within its corresponding bounding
box annotation. The experimental results on four challenging benchmarks
demonstrate the leading performance of our proposed approach to robust instance
segmentation in various scenarios. The code is available at:
https://github.com/LiWentomng/boxlevelset.
</p></li>
</ul>

<h3>Title: Shrinking the Semantic Gap: Spatial Pooling of Local Moment Invariants for Copy-Move Forgery Detection. (arXiv:2207.09135v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2207.09135">http://arxiv.org/abs/2207.09135</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2207.09135] Shrinking the Semantic Gap: Spatial Pooling of Local Moment Invariants for Copy-Move Forgery Detection](http://arxiv.org/abs/2207.09135)</code></li>
<li>Summary: <p>Copy-move forgery is a manipulation of copying and pasting specific patches
from and to an image, with potentially illegal or unethical uses. Recent
advances in the forensic methods for copy-move forgery have shown increasing
success in detection accuracy and robustness. However, for images with high
self-similarity or strong signal corruption, the existing algorithms often
exhibit inefficient processes and unreliable results. This is mainly due to the
inherent semantic gap between low-level visual representation and high-level
semantic concept. In this paper, we present a very first study of trying to
mitigate the semantic gap problem in copy-move forgery detection, with spatial
pooling of local moment invariants for midlevel image representation. Our
detection method expands the traditional works on two aspects: 1) we introduce
the bag-of-visual-words model into this field for the first time, may meaning a
new perspective of forensic study; 2) we propose a word-to-phrase feature
description and matching pipeline, covering the spatial structure and visual
saliency information of digital images. Extensive experimental results show the
superior performance of our framework over state-of-the-art algorithms in
overcoming the related problems caused by the semantic gap.
</p></li>
</ul>

<h3>Title: ParticleSfM: Exploiting Dense Point Trajectories for Localizing Moving Cameras in the Wild. (arXiv:2207.09137v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2207.09137">http://arxiv.org/abs/2207.09137</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2207.09137] ParticleSfM: Exploiting Dense Point Trajectories for Localizing Moving Cameras in the Wild](http://arxiv.org/abs/2207.09137)</code></li>
<li>Summary: <p>Estimating the pose of a moving camera from monocular video is a challenging
problem, especially due to the presence of moving objects in dynamic
environments, where the performance of existing camera pose estimation methods
are susceptible to pixels that are not geometrically consistent. To tackle this
challenge, we present a robust dense indirect structure-from-motion method for
videos that is based on dense correspondence initialized from pairwise optical
flow. Our key idea is to optimize long-range video correspondence as dense
point trajectories and use it to learn robust estimation of motion
segmentation. A novel neural network architecture is proposed for processing
irregular point trajectory data. Camera poses are then estimated and optimized
with global bundle adjustment over the portion of long-range point trajectories
that are classified as static. Experiments on MPI Sintel dataset show that our
system produces significantly more accurate camera trajectories compared to
existing state-of-the-art methods. In addition, our method is able to retain
reasonable accuracy of camera poses on fully static scenes, which consistently
outperforms strong state-of-the-art dense correspondence based methods with
end-to-end deep learning, demonstrating the potential of dense indirect methods
based on optical flow and point trajectories. As the point trajectory
representation is general, we further present results and comparisons on
in-the-wild monocular videos with complex motion of dynamic objects. Code is
available at https://github.com/bytedance/particle-sfm.
</p></li>
</ul>

<h3>Title: Image Super-Resolution with Deep Dictionary. (arXiv:2207.09228v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2207.09228">http://arxiv.org/abs/2207.09228</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2207.09228] Image Super-Resolution with Deep Dictionary](http://arxiv.org/abs/2207.09228)</code></li>
<li>Summary: <p>Since the first success of Dong et al., the deep-learning-based approach has
become dominant in the field of single-image super-resolution. This replaces
all the handcrafted image processing steps of traditional sparse-coding-based
methods with a deep neural network. In contrast to sparse-coding-based methods,
which explicitly create high/low-resolution dictionaries, the dictionaries in
deep-learning-based methods are implicitly acquired as a nonlinear combination
of multiple convolutions. One disadvantage of deep-learning-based methods is
that their performance is degraded for images created differently from the
training dataset (out-of-domain images). We propose an end-to-end
super-resolution network with a deep dictionary (SRDD), where a high-resolution
dictionary is explicitly learned without sacrificing the advantages of deep
learning. Extensive experiments show that explicit learning of high-resolution
dictionary makes the network more robust for out-of-domain test images while
maintaining the performance of the in-domain test images.
</p></li>
</ul>

<h3>Title: Content-aware Scalable Deep Compressed Sensing. (arXiv:2207.09313v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2207.09313">http://arxiv.org/abs/2207.09313</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2207.09313] Content-aware Scalable Deep Compressed Sensing](http://arxiv.org/abs/2207.09313)</code></li>
<li>Summary: <p>To more efficiently address image compressed sensing (CS) problems, we
present a novel content-aware scalable network dubbed CASNet which collectively
achieves adaptive sampling rate allocation, fine granular scalability and
high-quality reconstruction. We first adopt a data-driven saliency detector to
evaluate the importances of different image regions and propose a
saliency-based block ratio aggregation (BRA) strategy for sampling rate
allocation. A unified learnable generating matrix is then developed to produce
sampling matrix of any CS ratio with an ordered structure. Being equipped with
the optimization-inspired recovery subnet guided by saliency information and a
multi-block training scheme preventing blocking artifacts, CASNet jointly
reconstructs the image blocks sampled at various sampling rates with one single
model. To accelerate training convergence and improve network robustness, we
propose an SVD-based initialization scheme and a random transformation
enhancement (RTE) strategy, which are extensible without introducing extra
parameters. All the CASNet components can be combined and learned end-to-end.
We further provide a four-stage implementation for evaluation and practical
deployments. Experiments demonstrate that CASNet outperforms other CS networks
by a large margin, validating the collaboration and mutual supports among its
components and strategies. Codes are available at
https://github.com/Guaishou74851/CASNet.
</p></li>
</ul>

<h3>Title: Det6D: A Ground-Aware Full-Pose 3D Object Detector for Improving Terrain Robustness. (arXiv:2207.09412v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2207.09412">http://arxiv.org/abs/2207.09412</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2207.09412] Det6D: A Ground-Aware Full-Pose 3D Object Detector for Improving Terrain Robustness](http://arxiv.org/abs/2207.09412)</code></li>
<li>Summary: <p>Accurate 3D object detection with LiDAR is critical for autonomous driving.
Existing research is all based on the flat-world assumption. However, the
actual road can be complex with steep sections, which breaks the premise.
Current methods suffer from performance degradation in this case due to
difficulty correctly detecting objects on sloped terrain. In this work, we
propose Det6D, the first full-degree-of-freedom 3D object detector without
spatial and postural limitations, to improve terrain robustness. We choose the
point-based framework by founding their capability of detecting objects in the
entire spatial range. To predict full-degree poses, including pitch and roll,
we design a ground-aware orientation branch that leverages the local ground
constraints. Given the difficulty of long-tail non-flat scene data collection
and 6D pose annotation, we present Slope-Aug, a data augmentation method for
synthesizing non-flat terrain from existing datasets recorded in flat scenes.
Experiments on various datasets demonstrate the effectiveness and robustness of
our method in different terrains. We further conducted an extended experiment
to explore how the network predicts the two extra poses. The proposed modules
are plug-and-play for existing point-based frameworks. The code is available at
https://github.com/HITSZ-NRSL/De6D.
</p></li>
</ul>

<h3>Title: A Study of Deep CNN Model with Labeling Noise Based on Granular-ball Computing. (arXiv:2207.08810v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2207.08810">http://arxiv.org/abs/2207.08810</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2207.08810] A Study of Deep CNN Model with Labeling Noise Based on Granular-ball Computing](http://arxiv.org/abs/2207.08810)</code></li>
<li>Summary: <p>In supervised learning, the presence of noise can have a significant impact
on decision making. Since many classifiers do not take label noise into account
in the derivation of the loss function, including the loss functions of
logistic regression, SVM, and AdaBoost, especially the AdaBoost iterative
algorithm, whose core idea is to continuously increase the weight value of the
misclassified samples, the weight of samples in many presence of label noise
will be increased, leading to a decrease in model accuracy. In addition, the
learning process of BP neural network and decision tree will also be affected
by label noise. Therefore, solving the label noise problem is an important
element of maintaining the robustness of the network model, which is of great
practical significance. Granular ball computing is an important modeling method
developed in the field of granular computing in recent years, which is an
efficient, robust and scalable learning method. In this paper, we pioneered a
granular ball neural network algorithm model, which adopts the idea of
multi-granular to filter label noise samples during model training, solving the
current problem of model instability caused by label noise in the field of deep
learning, greatly reducing the proportion of label noise in training samples
and improving the robustness of neural network models.
</p></li>
</ul>

<h3>Title: Why do tree-based models still outperform deep learning on tabular data?. (arXiv:2207.08815v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2207.08815">http://arxiv.org/abs/2207.08815</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2207.08815] Why do tree-based models still outperform deep learning on tabular data?](http://arxiv.org/abs/2207.08815)</code></li>
<li>Summary: <p>While deep learning has enabled tremendous progress on text and image
datasets, its superiority on tabular data is not clear. We contribute extensive
benchmarks of standard and novel deep learning methods as well as tree-based
models such as XGBoost and Random Forests, across a large number of datasets
and hyperparameter combinations. We define a standard set of 45 datasets from
varied domains with clear characteristics of tabular data and a benchmarking
methodology accounting for both fitting models and finding good
hyperparameters. Results show that tree-based models remain state-of-the-art on
medium-sized data ($\sim$10K samples) even without accounting for their
superior speed. To understand this gap, we conduct an empirical investigation
into the differing inductive biases of tree-based models and Neural Networks
(NNs). This leads to a series of challenges which should guide researchers
aiming to build tabular-specific NNs: 1. be robust to uninformative features,</li>
<li>preserve the orientation of the data, and 3. be able to easily learn
irregular functions. To stimulate research on tabular architectures, we
contribute a standard benchmark and raw data for baselines: every point of a 20
000 compute hours hyperparameter search for each learner.
</p></li>
</ul>

<h3>Title: A Deep Reinforcement Learning Approach for Finding Non-Exploitable Strategies in Two-Player Atari Games. (arXiv:2207.08894v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2207.08894">http://arxiv.org/abs/2207.08894</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2207.08894] A Deep Reinforcement Learning Approach for Finding Non-Exploitable Strategies in Two-Player Atari Games](http://arxiv.org/abs/2207.08894)</code></li>
<li>Summary: <p>This paper proposes novel, end-to-end deep reinforcement learning algorithms
for learning two-player zero-sum Markov games. Our objective is to find the
Nash Equilibrium policies, which are free from exploitation by adversarial
opponents. Distinct from prior efforts on finding Nash equilibria in
extensive-form games such as Poker, which feature tree-structured transition
dynamics and discrete state space, this paper focuses on Markov games with
general transition dynamics and continuous state space. We propose (1) Nash DQN
algorithm, which integrates DQN with a Nash finding subroutine for the joint
value functions; and (2) Nash DQN Exploiter algorithm, which additionally
adopts an exploiter for guiding agent's exploration. Our algorithms are the
practical variants of theoretical algorithms which are guaranteed to converge
to Nash equilibria in the basic tabular setting. Experimental evaluation on
both tabular examples and two-player Atari games demonstrates the robustness of
the proposed algorithms against adversarial opponents, as well as their
advantageous performance over existing methods.
</p></li>
</ul>

<h3>Title: Decorrelative Network Architecture for Robust Electrocardiogram Classification. (arXiv:2207.09031v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2207.09031">http://arxiv.org/abs/2207.09031</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2207.09031] Decorrelative Network Architecture for Robust Electrocardiogram Classification](http://arxiv.org/abs/2207.09031)</code></li>
<li>Summary: <p>Artificial intelligence has made great progresses in medical data analysis,
but the lack of robustness and interpretability has kept these methods from
being widely deployed. In particular, data-driven models are vulnerable to
adversarial attacks, which are small, targeted perturbations that dramatically
degrade model performance. As a recent example, while deep learning has shown
impressive performance in electrocardiogram (ECG) classification, Han et al.
crafted realistic perturbations that fooled the network 74% of the time [2020].
Current adversarial defense paradigms are computationally intensive and
impractical for many high dimensional problems. Previous research indicates
that a network vulnerability is related to the features learned during
training. We propose a novel approach based on ensemble decorrelation and
Fourier partitioning for training parallel network arms into a decorrelated
architecture to learn complementary features, significantly reducing the chance
of a perturbation fooling all arms of the deep learning model. We test our
approach in ECG classification, demonstrating a much-improved 77.2% chance of
at least one correct network arm on the strongest adversarial attack tested, in
contrast to a 21.7% chance from a comparable ensemble. Our approach does not
require expensive optimization with adversarial samples, and thus can be scaled
to large problems. These methods can easily be applied to other tasks for
improved network robustness.
</p></li>
</ul>

<h3>Title: A-SFS: Semi-supervised Feature Selection based on Multi-task Self-supervision. (arXiv:2207.09061v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2207.09061">http://arxiv.org/abs/2207.09061</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2207.09061] A-SFS: Semi-supervised Feature Selection based on Multi-task Self-supervision](http://arxiv.org/abs/2207.09061)</code></li>
<li>Summary: <p>Feature selection is an important process in machine learning. It builds an
interpretable and robust model by selecting the features that contribute the
most to the prediction target. However, most mature feature selection
algorithms, including supervised and semi-supervised, fail to fully exploit the
complex potential structure between features. We believe that these structures
are very important for the feature selection process, especially when labels
are lacking and data is noisy.
</p></li>
</ul>

<p>To this end, we innovatively introduce a deep learning-based self-supervised
mechanism into feature selection problems, namely batch-Attention-based
Self-supervision Feature Selection(A-SFS). Firstly, a multi-task
self-supervised autoencoder is designed to uncover the hidden structure among
features with the support of two pretext tasks. Guided by the integrated
information from the multi-self-supervised learning model, a batch-attention
mechanism is designed to generate feature weights according to batch-based
feature selection patterns to alleviate the impacts introduced by a handful of
noisy data. This method is compared to 14 major strong benchmarks, including
LightGBM and XGBoost. Experimental results show that A-SFS achieves the highest
accuracy in most datasets. Furthermore, this design significantly reduces the
reliance on labels, with only 1/10 labeled data needed to achieve the same
performance as those state of art baselines. Results show that A-SFS is also
most robust to the noisy and missing data.
</p>

<h3>Title: Bounding generalization error with input compression: An empirical study with infinite-width networks. (arXiv:2207.09408v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2207.09408">http://arxiv.org/abs/2207.09408</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2207.09408] Bounding generalization error with input compression: An empirical study with infinite-width networks](http://arxiv.org/abs/2207.09408)</code></li>
<li>Summary: <p>Estimating the Generalization Error (GE) of Deep Neural Networks (DNNs) is an
important task that often relies on availability of held-out data. The ability
to better predict GE based on a single training set may yield overarching DNN
design principles to reduce a reliance on trial-and-error, along with other
performance assessment advantages. In search of a quantity relevant to GE, we
investigate the Mutual Information (MI) between the input and final layer
representations, using the infinite-width DNN limit to bound MI. An existing
input compression-based GE bound is used to link MI and GE. To the best of our
knowledge, this represents the first empirical study of this bound. In our
attempt to empirically falsify the theoretical bound, we find that it is often
tight for best-performing models. Furthermore, it detects randomization of
training labels in many cases, reflects test-time perturbation robustness, and
works well given only few training samples. These results are promising given
that input compression is broadly applicable where MI can be estimated with
confidence.
</p></li>
</ul>

<h3>Title: Research Trends and Applications of Data Augmentation Algorithms. (arXiv:2207.08817v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2207.08817">http://arxiv.org/abs/2207.08817</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2207.08817] Research Trends and Applications of Data Augmentation Algorithms](http://arxiv.org/abs/2207.08817)</code></li>
<li>Summary: <p>In the Machine Learning research community, there is a consensus regarding
the relationship between model complexity and the required amount of data and
computation power. In real world applications, these computational requirements
are not always available, motivating research on regularization methods. In
addition, current and past research have shown that simpler classification
algorithms can reach state-of-the-art performance on computer vision tasks
given a robust method to artificially augment the training dataset. Because of
this, data augmentation techniques became a popular research topic in recent
years. However, existing data augmentation methods are generally less
transferable than other regularization methods. In this paper we identify the
main areas of application of data augmentation algorithms, the types of
algorithms used, significant research trends, their progression over time and
research gaps in data augmentation literature. To do this, the related
literature was collected through the Scopus database. Its analysis was done
following network science, text mining and exploratory analysis approaches. We
expect readers to understand the potential of data augmentation, as well as
identify future research directions and open questions within data augmentation
research.
</p></li>
</ul>

<h3>Title: Adversarial Training Improves Joint Energy-Based Generative Modelling. (arXiv:2207.08950v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2207.08950">http://arxiv.org/abs/2207.08950</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2207.08950] Adversarial Training Improves Joint Energy-Based Generative Modelling](http://arxiv.org/abs/2207.08950)</code></li>
<li>Summary: <p>We propose the novel framework for generative modelling using hybrid
energy-based models. In our method we combine the interpretable input gradients
of the robust classifier and Langevin Dynamics for sampling. Using the
adversarial training we improve not only the training stability, but robustness
and generative modelling of the joint energy-based models.
</p></li>
</ul>

<h3>Title: Calibrated ensembles can mitigate accuracy tradeoffs under distribution shift. (arXiv:2207.08977v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2207.08977">http://arxiv.org/abs/2207.08977</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2207.08977] Calibrated ensembles can mitigate accuracy tradeoffs under distribution shift](http://arxiv.org/abs/2207.08977)</code></li>
<li>Summary: <p>We often see undesirable tradeoffs in robust machine learning where
out-of-distribution (OOD) accuracy is at odds with in-distribution (ID)
accuracy: a robust classifier obtained via specialized techniques such as
removing spurious features often has better OOD but worse ID accuracy compared
to a standard classifier trained via ERM. In this paper, we find that
ID-calibrated ensembles -- where we simply ensemble the standard and robust
models after calibrating on only ID data -- outperforms prior state-of-the-art
(based on self-training) on both ID and OOD accuracy. On eleven natural
distribution shift datasets, ID-calibrated ensembles obtain the best of both
worlds: strong ID accuracy and OOD accuracy. We analyze this method in stylized
settings, and identify two important conditions for ensembles to perform well
both ID and OOD: (1) we need to calibrate the standard and robust models (on ID
data, because OOD data is unavailable), (2) OOD has no anticorrelated spurious
features.
</p></li>
</ul>

<h2>biometric</h2>
<h2>steal</h2>
<h2>extraction</h2>
<h3>Title: Deep Sequence Models for Text Classification Tasks. (arXiv:2207.08880v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2207.08880">http://arxiv.org/abs/2207.08880</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2207.08880] Deep Sequence Models for Text Classification Tasks](http://arxiv.org/abs/2207.08880)</code></li>
<li>Summary: <p>The exponential growth of data generated on the Internet in the current
information age is a driving force for the digital economy. Extraction of
information is the major value in an accumulated big data. Big data dependency
on statistical analysis and hand-engineered rules machine learning algorithms
are overwhelmed with vast complexities inherent in human languages. Natural
Language Processing (NLP) is equipping machines to understand these human
diverse and complicated languages. Text Classification is an NLP task which
automatically identifies patterns based on predefined or undefined labeled
sets. Common text classification application includes information retrieval,
modeling news topic, theme extraction, sentiment analysis, and spam detection.
In texts, some sequences of words depend on the previous or next word sequences
to make full meaning; this is a challenging dependency task that requires the
machine to be able to store some previous important information to impact
future meaning. Sequence models such as RNN, GRU, and LSTM is a breakthrough
for tasks with long-range dependencies. As such, we applied these models to
Binary and Multi-class classification. Results generated were excellent with
most of the models performing within the range of 80% and 94%. However, this
result is not exhaustive as we believe there is room for improvement if
machines are to compete with humans.
</p></li>
</ul>

<h3>Title: PBRE: A Rule Extraction Method from Trained Neural Networks Designed for Smart Home Services. (arXiv:2207.08814v1 [cs.AI])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2207.08814">http://arxiv.org/abs/2207.08814</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2207.08814] PBRE: A Rule Extraction Method from Trained Neural Networks Designed for Smart Home Services](http://arxiv.org/abs/2207.08814)</code></li>
<li>Summary: <p>Designing smart home services is a complex task when multiple services with a
large number of sensors and actuators are deployed simultaneously. It may rely
on knowledge-based or data-driven approaches. The former can use rule-based
methods to design services statically, and the latter can use learning methods
to discover inhabitants' preferences dynamically. However, neither of these
approaches is entirely satisfactory because rules cannot cover all possible
situations that may change, and learning methods may make decisions that are
sometimes incomprehensible to the inhabitant. In this paper, PBRE (Pedagogic
Based Rule Extractor) is proposed to extract rules from learning methods to
realize dynamic rule generation for smart home systems. The expected advantage
is that both the explainability of rule-based methods and the dynamicity of
learning methods are adopted. We compare PBRE with an existing rule extraction
method, and the results show better performance of PBRE. We also apply PBRE to
extract rules from a smart home service represented by an NRL (Neural
Network-based Reinforcement Learning). The results show that PBRE can help the
NRL-simulated service to make understandable suggestions to the inhabitant.
</p></li>
</ul>

<h3>Title: EVE: Environmental Adaptive Neural Network Models for Low-power Energy Harvesting System. (arXiv:2207.09258v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2207.09258">http://arxiv.org/abs/2207.09258</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2207.09258] EVE: Environmental Adaptive Neural Network Models for Low-power Energy Harvesting System](http://arxiv.org/abs/2207.09258)</code></li>
<li>Summary: <p>IoT devices are increasingly being implemented with neural network models to
enable smart applications. Energy harvesting (EH) technology that harvests
energy from ambient environment is a promising alternative to batteries for
powering those devices due to the low maintenance cost and wide availability of
the energy sources. However, the power provided by the energy harvester is low
and has an intrinsic drawback of instability since it varies with the ambient
environment. This paper proposes EVE, an automated machine learning (autoML)
co-exploration framework to search for desired multi-models with shared weights
for energy harvesting IoT devices. Those shared models incur significantly
reduced memory footprint with different levels of model sparsity, latency, and
accuracy to adapt to the environmental changes. An efficient on-device
implementation architecture is further developed to efficiently execute each
model on device. A run-time model extraction algorithm is proposed that
retrieves individual model with negligible overhead when a specific model mode
is triggered. Experimental results show that the neural networks models
generated by EVE is on average 2.5X times faster than the baseline models
without pruning and shared weights.
</p></li>
</ul>

<h2>membership infer</h2>
<h2>federate</h2>
<h3>Title: FLAIR: Federated Learning Annotated Image Repository. (arXiv:2207.08869v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2207.08869">http://arxiv.org/abs/2207.08869</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2207.08869] FLAIR: Federated Learning Annotated Image Repository](http://arxiv.org/abs/2207.08869)</code></li>
<li>Summary: <p>Cross-device federated learning is an emerging machine learning (ML) paradigm
where a large population of devices collectively train an ML model while the
data remains on the devices. This research field has a unique set of practical
challenges, and to systematically make advances, new datasets curated to be
compatible with this paradigm are needed. Existing federated learning
benchmarks in the image domain do not accurately capture the scale and
heterogeneity of many real-world use cases. We introduce FLAIR, a challenging
large-scale annotated image dataset for multi-label classification suitable for
federated learning. FLAIR has 429,078 images from 51,414 Flickr users and
captures many of the intricacies typically encountered in federated learning,
such as heterogeneous user data and a long-tailed label distribution. We
implement multiple baselines in different learning setups for different tasks
on this dataset. We believe FLAIR can serve as a challenging benchmark for
advancing the state-of-the art in federated learning. Dataset access and the
code for the benchmark are available at
\url{https://github.com/apple/ml-flair}.
</p></li>
</ul>

<h3>Title: FedX: Unsupervised Federated Learning with Cross Knowledge Distillation. (arXiv:2207.09158v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2207.09158">http://arxiv.org/abs/2207.09158</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2207.09158] FedX: Unsupervised Federated Learning with Cross Knowledge Distillation](http://arxiv.org/abs/2207.09158)</code></li>
<li>Summary: <p>This paper presents FedX, an unsupervised federated learning framework. Our
model learns unbiased representation from decentralized and heterogeneous local
data. It employs a two-sided knowledge distillation with contrastive learning
as a core component, allowing the federated system to function without
requiring clients to share any data features. Furthermore, its adaptable
architecture can be used as an add-on module for existing unsupervised
algorithms in federated settings. Experiments show that our model improves
performance significantly (1.58--5.52pp) on five unsupervised algorithms.
</p></li>
</ul>

<h3>Title: SphereFed: Hyperspherical Federated Learning. (arXiv:2207.09413v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2207.09413">http://arxiv.org/abs/2207.09413</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2207.09413] SphereFed: Hyperspherical Federated Learning](http://arxiv.org/abs/2207.09413)</code></li>
<li>Summary: <p>Federated Learning aims at training a global model from multiple
decentralized devices (i.e. clients) without exchanging their private local
data. A key challenge is the handling of non-i.i.d. (independent identically
distributed) data across multiple clients that may induce disparities of their
local features. We introduce the Hyperspherical Federated Learning (SphereFed)
framework to address the non-i.i.d. issue by constraining learned
representations of data points to be on a unit hypersphere shared by clients.
Specifically, all clients learn their local representations by minimizing the
loss with respect to a fixed classifier whose weights span the unit
hypersphere. After federated training in improving the global model, this
classifier is further calibrated with a closed-form solution by minimizing a
mean squared loss. We show that the calibration solution can be computed
efficiently and distributedly without direct access of local data. Extensive
experiments indicate that our SphereFed approach is able to improve the
accuracy of multiple existing federated learning algorithms by a considerable
margin (up to 6% on challenging datasets) with enhanced computation and
communication efficiency across datasets and model architectures.
</p></li>
</ul>

<h3>Title: Training Large-Vocabulary Neural Language Models by Private Federated Learning for Resource-Constrained Devices. (arXiv:2207.08988v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2207.08988">http://arxiv.org/abs/2207.08988</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2207.08988] Training Large-Vocabulary Neural Language Models by Private Federated Learning for Resource-Constrained Devices](http://arxiv.org/abs/2207.08988)</code></li>
<li>Summary: <p>Federated Learning (FL) is a technique to train models using data distributed
across devices. Differential Privacy (DP) provides a formal privacy guarantee
for sensitive data. Our goal is to train a large neural network language model
(NNLM) on compute-constrained devices while preserving privacy using FL and DP.
However, the DP-noise introduced to the model increases as the model size
grows, which often prevents convergence. We propose Partial Embedding Updates
(PEU), a novel technique to decrease noise by decreasing payload size.
Furthermore, we adopt Low Rank Adaptation (LoRA) and Noise Contrastive
Estimation (NCE) to reduce the memory demands of large models on
compute-constrained devices. This combination of techniques makes it possible
to train large-vocabulary language models while preserving accuracy and
privacy.
</p></li>
</ul>

<h3>Title: Over-the-Air Federated Edge Learning with Hierarchical Clustering. (arXiv:2207.09232v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2207.09232">http://arxiv.org/abs/2207.09232</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2207.09232] Over-the-Air Federated Edge Learning with Hierarchical Clustering](http://arxiv.org/abs/2207.09232)</code></li>
<li>Summary: <p>We examine federated learning (FL) with over-the-air (OTA) aggregation, where
mobile users (MUs) aim to reach a consensus on a global model with the help of
a parameter server (PS) that aggregates the local gradients. In OTA FL, MUs
train their models using local data at every training round and transmit their
gradients simultaneously using the same frequency band in an uncoded fashion.
Based on the received signal of the superposed gradients, the PS performs a
global model update. While the OTA FL has a significantly decreased
communication cost, it is susceptible to adverse channel effects and noise.
Employing multiple antennas at the receiver side can reduce these effects, yet
the path-loss is still a limiting factor for users located far away from the
PS. To ameliorate this issue, in this paper, we propose a wireless-based
hierarchical FL scheme that uses intermediate servers (ISs) to form clusters at
the areas where the MUs are more densely located. Our scheme utilizes OTA
cluster aggregations for the communication of the MUs with their corresponding
IS, and OTA global aggregations from the ISs to the PS. We present a
convergence analysis for the proposed algorithm, and show through numerical
evaluations of the derived analytical expressions and experimental results that
utilizing ISs results in a faster convergence and a better performance than the
OTA FL alone while using less transmit power. We also validate the results on
the performance using different number of cluster iterations with different
datasets and data distributions. We conclude that the best choice of cluster
aggregations depends on the data distribution among the MUs and the clusters.
</p></li>
</ul>

<h3>Title: Green, Quantized Federated Learning over Wireless Networks: An Energy-Efficient Design. (arXiv:2207.09387v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2207.09387">http://arxiv.org/abs/2207.09387</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2207.09387] Green, Quantized Federated Learning over Wireless Networks: An Energy-Efficient Design](http://arxiv.org/abs/2207.09387)</code></li>
<li>Summary: <p>In this paper, a green, quantized FL framework, which represents data with a
finite precision level in both local training and uplink transmission, is
proposed. Here, the finite precision level is captured through the use of
quantized neural networks (QNNs) that quantize weights and activations in
fixed-precision format. In the considered FL model, each device trains its QNN
and transmits a quantized training result to the base station. Energy models
for the local training and the transmission with quantization are rigorously
derived. To minimize the energy consumption and the number of communication
rounds simultaneously, a multi-objective optimization problem is formulated
with respect to the number of local iterations, the number of selected devices,
and the precision levels for both local training and transmission while
ensuring convergence under a target accuracy constraint. To solve this problem,
the convergence rate of the proposed FL system is analytically derived with
respect to the system control variables. Then, the Pareto boundary of the
problem is characterized to provide efficient solutions using the normal
boundary inspection method. Design insights on balancing the tradeoff between
the two objectives are drawn from using the Nash bargaining solution and
analyzing the derived convergence rate. Simulation results show that the
proposed FL framework can reduce energy consumption until convergence by up to
52% compared to a baseline FL algorithm that represents data with full
precision.
</p></li>
</ul>

<h2>fair</h2>
<h2>interpretability</h2>
<h3>Title: Multi-view hierarchical Variational AutoEncoders with Factor Analysis latent space. (arXiv:2207.09185v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2207.09185">http://arxiv.org/abs/2207.09185</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2207.09185] Multi-view hierarchical Variational AutoEncoders with Factor Analysis latent space](http://arxiv.org/abs/2207.09185)</code></li>
<li>Summary: <p>Real-world databases are complex, they usually present redundancy and shared
correlations between heterogeneous and multiple representations of the same
data. Thus, exploiting and disentangling shared information between views is
critical. For this purpose, recent studies often fuse all views into a shared
nonlinear complex latent space but they lose the interpretability. To overcome
this limitation, here we propose a novel method to combine multiple Variational
AutoEncoders (VAE) architectures with a Factor Analysis latent space (FA-VAE).
Concretely, we use a VAE to learn a private representation of each
heterogeneous view in a continuous latent space. Then, we model the shared
latent space by projecting every private variable to a low-dimensional latent
space using a linear projection matrix. Thus, we create an interpretable
hierarchical dependency between private and shared information. This way, the
novel model is able to simultaneously: (i) learn from multiple heterogeneous
views, (ii) obtain an interpretable hierarchical shared space, and, (iii)
perform transfer learning between generative models.
</p></li>
</ul>

<h3>Title: Semi-supervised Predictive Clustering Trees for (Hierarchical) Multi-label Classification. (arXiv:2207.09237v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2207.09237">http://arxiv.org/abs/2207.09237</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2207.09237] Semi-supervised Predictive Clustering Trees for (Hierarchical) Multi-label Classification](http://arxiv.org/abs/2207.09237)</code></li>
<li>Summary: <p>Semi-supervised learning (SSL) is a common approach to learning predictive
models using not only labeled examples, but also unlabeled examples. While SSL
for the simple tasks of classification and regression has received a lot of
attention from the research community, this is not properly investigated for
complex prediction tasks with structurally dependent variables. This is the
case of multi-label classification and hierarchical multi-label classification
tasks, which may require additional information, possibly coming from the
underlying distribution in the descriptive space provided by unlabeled
examples, to better face the challenging task of predicting simultaneously
multiple class labels.
</p></li>
</ul>

<p>In this paper, we investigate this aspect and propose a (hierarchical)
multi-label classification method based on semi-supervised learning of
predictive clustering trees. We also extend the method towards ensemble
learning and propose a method based on the random forest approach. Extensive
experimental evaluation conducted on 23 datasets shows significant advantages
of the proposed method and its extension with respect to their supervised
counterparts. Moreover, the method preserves interpretability and reduces the
time complexity of classical tree-based models.
</p>

<h3>Title: Metadata Representations for Queryable ML Model Zoos. (arXiv:2207.09315v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2207.09315">http://arxiv.org/abs/2207.09315</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2207.09315] Metadata Representations for Queryable ML Model Zoos](http://arxiv.org/abs/2207.09315)</code></li>
<li>Summary: <p>Machine learning (ML) practitioners and organizations are building model zoos
of pre-trained models, containing metadata describing properties of the ML
models and datasets that are useful for reporting, auditing, reproducibility,
and interpretability purposes. The metatada is currently not standardised; its
expressivity is limited; and there is no interoperable way to store and query
it. Consequently, model search, reuse, comparison, and composition are
hindered. In this paper, we advocate for standardized ML model meta-data
representation and management, proposing a toolkit supported to help
practitioners manage and query that metadata.
</p></li>
</ul>

<h2>exlainability</h2>
<h2>watermark</h2>
<button id="copy">Copy All</button>
</article>
<script src="../../javascript/clipboard.min.js"></script>
<script src="../../javascript/clipboard.js"></script>
