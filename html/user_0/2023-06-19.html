<link rel="stylesheet" href="../../css/markdown.css" />
<article class="markdown-body">
<h2>secure</h2>
<h3>Title: Fuzzy Feature Selection with Key-based Cryptographic Transformations. (arXiv:2306.09583v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.09583">http://arxiv.org/abs/2306.09583</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.09583] Fuzzy Feature Selection with Key-based Cryptographic Transformations](http://arxiv.org/abs/2306.09583) #secure</code></li>
<li>Summary: <p>In the field of cryptography, the selection of relevant features plays a
crucial role in enhancing the security and efficiency of cryptographic
algorithms. This paper presents a novel approach of applying fuzzy feature
selection to key-based cryptographic transformations. The proposed fuzzy
feature selection leverages the power of fuzzy logic to identify and select
optimal subsets of features that contribute most effectively to the
cryptographic transformation process. By incorporating fuzzy feature selection
into key-based cryptographic transformations, this research aims to improve the
resistance against attacks and enhance the overall performance of cryptographic
systems. Experimental evaluations may demonstrate the effectiveness of the
proposed approach in selecting secure key features with minimal computational
overhead. This paper highlights the potential of fuzzy feature selection as a
valuable tool in the design and optimization of key-based cryptographic
algorithms, contributing to the advancement of secure information exchange and
communication in various domains.
</p></li>
</ul>

<h3>Title: Lost and not Found: An Investigation of Recovery Methods for Multi-Factor Authentication. (arXiv:2306.09708v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.09708">http://arxiv.org/abs/2306.09708</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.09708] Lost and not Found: An Investigation of Recovery Methods for Multi-Factor Authentication](http://arxiv.org/abs/2306.09708) #secure</code></li>
<li>Summary: <p>Multi-Factor Authentication is intended to strengthen the security of
password-based authentication by adding another factor, such as hardware tokens
or one-time passwords using mobile apps. However, this increased authentication
security comes with potential drawbacks that can lead to account and asset
loss. If users lose access to their additional authentication factors for any
reason, they will be locked out of their accounts. Consequently, services that
provide Multi-Factor Authentication should deploy procedures to allow their
users to recover from losing access to their additional factor that are both
secure and easy-to-use. To the best of our knowledge, we are the first to
first-hand investigate the security and user experience of deployed
Multi-Factor Authentication recovery procedures. We first evaluate the official
help and support pages of 1,303 websites that provide Multi-Factor
Authentication and collect documented information about their recovery
procedures. Second, we select a subset of 71 websites, create accounts, set up
Multi-Factor Authentication, and perform an in-depth investigation of their
recovery procedure security and user experience. We find that many websites
deploy insecure Multi-Factor Authentication recovery procedures and allowed us
to circumvent and disable Multi-Factor Authentication when having access to the
accounts' associated email addresses. Furthermore, we commonly observed
discrepancies between our in-depth analysis and the official help and support
pages, implying that information meant to aid users is often either incorrect
or outdated.
</p></li>
</ul>

<h3>Title: Employing Multimodal Machine Learning for Stress Detection. (arXiv:2306.09385v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.09385">http://arxiv.org/abs/2306.09385</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.09385] Employing Multimodal Machine Learning for Stress Detection](http://arxiv.org/abs/2306.09385) #secure</code></li>
<li>Summary: <p>In the current age, human lifestyle has become more knowledge oriented
leading to generation of sedentary employment. This has given rise to a number
of health and mental disorders. Mental wellness is one of the most neglected
but crucial aspects of today's world. Mental health issues can, both directly
and indirectly, affect other sections of human physiology and impede an
individual's day-to-day activities and performance. However, identifying the
stress and finding the stress trend for an individual leading to serious mental
ailments is challenging and involves multiple factors. Such identification can
be achieved accurately by fusing these multiple modalities (due to various
factors) arising from behavioral patterns. Certain techniques are identified in
the literature for this purpose; however, very few machine learning-based
methods are proposed for such multimodal fusion tasks. In this work, a
multimodal AI-based framework is proposed to monitor a person's working
behavior and stress levels. We propose a methodology for efficiently detecting
stress due to workload by concatenating heterogeneous raw sensor data streams
(e.g., face expressions, posture, heart rate, computer interaction). This data
can be securely stored and analyzed to understand and discover personalized
unique behavioral patterns leading to mental strain and fatigue. The
contribution of this work is twofold; proposing a multimodal AI-based strategy
for fusion to detect stress and its level and secondly identify a stress
pattern over a period of time. We were able to achieve 96.09% accuracy on the
test set in stress detection and classification. Further, we reduce the stress
scale prediction model loss to 0.036 using these modalities. This work can
prove important for the community at large, specifically those working
sedentary jobs to monitor and identify stress levels, especially in current
times of COVID-19.
</p></li>
</ul>

<h2>security</h2>
<h3>Title: SAFER: Situation Aware Facial Emotion Recognition. (arXiv:2306.09372v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.09372">http://arxiv.org/abs/2306.09372</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.09372] SAFER: Situation Aware Facial Emotion Recognition](http://arxiv.org/abs/2306.09372) #security</code></li>
<li>Summary: <p>In this paper, we present SAFER, a novel system for emotion recognition from
facial expressions. It employs state-of-the-art deep learning techniques to
extract various features from facial images and incorporates contextual
information, such as background and location type, to enhance its performance.
The system has been designed to operate in an open-world setting, meaning it
can adapt to unseen and varied facial expressions, making it suitable for
real-world applications. An extensive evaluation of SAFER against existing
works in the field demonstrates improved performance, achieving an accuracy of
91.4% on the CAER-S dataset. Additionally, the study investigates the effect of
novelty such as face masks during the Covid-19 pandemic on facial emotion
recognition and critically examines the limitations of mainstream facial
expressions datasets. To address these limitations, a novel dataset for facial
emotion recognition is proposed. The proposed dataset and the system are
expected to be useful for various applications such as human-computer
interaction, security, and surveillance.
</p></li>
</ul>

<h2>privacy</h2>
<h3>Title: CLIP2Protect: Protecting Facial Privacy using Text-Guided Makeup via Adversarial Latent Search. (arXiv:2306.10008v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.10008">http://arxiv.org/abs/2306.10008</a></li>
<li>Code URL: <a href="https://github.com/fahadshamshad/clip2protect">https://github.com/fahadshamshad/clip2protect</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2306.10008] CLIP2Protect: Protecting Facial Privacy using Text-Guided Makeup via Adversarial Latent Search](http://arxiv.org/abs/2306.10008) #privacy</code></li>
<li>Summary: <p>The success of deep learning based face recognition systems has given rise to
serious privacy concerns due to their ability to enable unauthorized tracking
of users in the digital world. Existing methods for enhancing privacy fail to
generate naturalistic images that can protect facial privacy without
compromising user experience. We propose a novel two-step approach for facial
privacy protection that relies on finding adversarial latent codes in the
low-dimensional manifold of a pretrained generative model. The first step
inverts the given face image into the latent space and finetunes the generative
model to achieve an accurate reconstruction of the given image from its latent
code. This step produces a good initialization, aiding the generation of
high-quality faces that resemble the given identity. Subsequently, user-defined
makeup text prompts and identity-preserving regularization are used to guide
the search for adversarial codes in the latent space. Extensive experiments
demonstrate that faces generated by our approach have stronger black-box
transferability with an absolute gain of 12.06% over the state-of-the-art
facial privacy protection approach under the face verification task. Finally,
we demonstrate the effectiveness of the proposed approach for commercial face
recognition systems. Our code is available at
https://github.com/fahadshamshad/Clip2Protect.
</p></li>
</ul>

<h3>Title: Just One Byte (per gradient): A Note on Low-Bandwidth Decentralized Language Model Finetuning Using Shared Randomness. (arXiv:2306.10015v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.10015">http://arxiv.org/abs/2306.10015</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.10015] Just One Byte (per gradient): A Note on Low-Bandwidth Decentralized Language Model Finetuning Using Shared Randomness](http://arxiv.org/abs/2306.10015) #privacy</code></li>
<li>Summary: <p>Language model training in distributed settings is limited by the
communication cost of gradient exchanges. In this short note, we extend recent
work from Malladi et al. (2023), using shared randomness to perform distributed
fine-tuning with low bandwidth. The method is a natural decentralized extension
of memory-efficient Simultaneous Perturbation Stochastic Approximation (SPSA).
Each iteration, each machine seeds a Random Number Generator (RNG) to perform
local reproducible perturbations on model weights and calculate and exchange
scalar projected gradients, which are then used to update each model. By using
a (machine, sample) identifier as the random seed, each model can regenerate
one another's perturbations. As machines only exchange single-byte projected
gradients, this is highly communication efficient. There are also potential
privacy benefits, as projected gradients may be calculated on different
training data, and models never access the other's data. Our approach not only
drastically reduces communication bandwidth requirements but also accommodates
dynamic addition or removal of machines during the training process and retains
the memory-efficient and inference-only advantages of recent work. We perform
proof-of-concept experiments to demonstrate the potential usefulness of this
method, building off of rich literature on distributed optimization and
memory-efficient training.
</p></li>
</ul>

<h3>Title: Privacy Guarantees for Personal Mobility Data in Humanitarian Response. (arXiv:2306.09471v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.09471">http://arxiv.org/abs/2306.09471</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.09471] Privacy Guarantees for Personal Mobility Data in Humanitarian Response](http://arxiv.org/abs/2306.09471) #privacy</code></li>
<li>Summary: <p>Personal mobility data from mobile phones and other sensors are increasingly
used to inform policymaking during pandemics, natural disasters, and other
humanitarian crises. However, even aggregated mobility traces can reveal
private information about individual movements to potentially malicious actors.
This paper develops and tests an approach for releasing private mobility data,
which provides formal guarantees over the privacy of the underlying subjects.
Specifically, we (1) introduce an algorithm for constructing differentially
private mobility matrices, and derive privacy and accuracy bounds on this
algorithm; (2) use real-world data from mobile phone operators in Afghanistan
and Rwanda to show how this algorithm can enable the use of private mobility
data in two high-stakes policy decisions: pandemic response and the
distribution of humanitarian aid; and (3) discuss practical decisions that need
to be made when implementing this approach, such as how to optimally balance
privacy and accuracy. Taken together, these results can help enable the
responsible use of private mobility data in humanitarian response.
</p></li>
</ul>

<h3>Title: A Smooth Binary Mechanism for Efficient Private Continual Observation. (arXiv:2306.09666v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.09666">http://arxiv.org/abs/2306.09666</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.09666] A Smooth Binary Mechanism for Efficient Private Continual Observation](http://arxiv.org/abs/2306.09666) #privacy</code></li>
<li>Summary: <p>In privacy under continual observation we study how to release differentially
private estimates based on a dataset that evolves over time. The problem of
releasing private prefix sums of $x_1,x_2,x_3,\dots \in{0,1}$ (where the
value of each $x_i$ is to be private) is particularly well-studied, and a
generalized form is used in state-of-the-art methods for private stochastic
gradient descent (SGD). The seminal binary mechanism privately releases the
first $t$ prefix sums with noise of variance polylogarithmic in $t$. Recently,
Henzinger et al. and Denisov et al. showed that it is possible to improve on
the binary mechanism in two ways: The variance of the noise can be reduced by a
(large) constant factor, and also made more even across time steps. However,
their algorithms for generating the noise distribution are not as efficient as
one would like in terms of computation time and (in particular) space. We
address the efficiency problem by presenting a simple alternative to the binary
mechanism in which 1) generating the noise takes constant average time per
value, 2) the variance is reduced by a factor about 4 compared to the binary
mechanism, and 3) the noise distribution at each step is identical.
Empirically, a simple Python implementation of our approach outperforms the
running time of the approach of Henzinger et al., as well as an attempt to
improve their algorithm using high-performance algorithms for multiplication
with Toeplitz matrices.
</p></li>
</ul>

<h3>Title: Data Protection for Data Privacy-A South African Problem?. (arXiv:2306.09934v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.09934">http://arxiv.org/abs/2306.09934</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.09934] Data Protection for Data Privacy-A South African Problem?](http://arxiv.org/abs/2306.09934) #privacy</code></li>
<li>Summary: <p>This study proposes a comprehensive framework for enhancing data security and
privacy within organizations through data protection awareness. It employs a
quantitative method and survey research strategy to assess the level of data
protection awareness among employees of a public organization.
</p></li>
</ul>

<h2>protect</h2>
<h3>Title: FETNet: Feature Erasing and Transferring Network for Scene Text Removal. (arXiv:2306.09593v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.09593">http://arxiv.org/abs/2306.09593</a></li>
<li>Code URL: <a href="https://github.com/guangtaolyu/fetnet">https://github.com/guangtaolyu/fetnet</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2306.09593] FETNet: Feature Erasing and Transferring Network for Scene Text Removal](http://arxiv.org/abs/2306.09593) #protect</code></li>
<li>Summary: <p>The scene text removal (STR) task aims to remove text regions and recover the
background smoothly in images for private information protection. Most existing
STR methods adopt encoder-decoder-based CNNs, with direct copies of the
features in the skip connections. However, the encoded features contain both
text texture and structure information. The insufficient utilization of text
features hampers the performance of background reconstruction in text removal
regions. To tackle these problems, we propose a novel Feature Erasing and
Transferring (FET) mechanism to reconfigure the encoded features for STR in
this paper. In FET, a Feature Erasing Module (FEM) is designed to erase text
features. An attention module is responsible for generating the feature
similarity guidance. The Feature Transferring Module (FTM) is introduced to
transfer the corresponding features in different layers based on the attention
guidance. With this mechanism, a one-stage, end-to-end trainable network called
FETNet is constructed for scene text removal. In addition, to facilitate
research on both scene text removal and segmentation tasks, we introduce a
novel dataset, Flickr-ST, with multi-category annotations. A sufficient number
of experiments and ablation studies are conducted on the public datasets and
Flickr-ST. Our proposed method achieves state-of-the-art performance using most
metrics, with remarkably higher quality scene text removal results. The source
code of our work is available at:
\href{https://github.com/GuangtaoLyu/FETNet}{https://github.com/GuangtaoLyu/FETNet.
</p></li>
</ul>

<h2>defense</h2>
<h2>attack</h2>
<h3>Title: Politeness Stereotypes and Attack Vectors: Gender Stereotypes in Japanese and Korean Language Models. (arXiv:2306.09752v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.09752">http://arxiv.org/abs/2306.09752</a></li>
<li>Code URL: <a href="https://github.com/vsteinborn/politeness-attacks">https://github.com/vsteinborn/politeness-attacks</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2306.09752] Politeness Stereotypes and Attack Vectors: Gender Stereotypes in Japanese and Korean Language Models](http://arxiv.org/abs/2306.09752) #attack</code></li>
<li>Summary: <p>In efforts to keep up with the rapid progress and use of large language
models, gender bias research is becoming more prevalent in NLP. Non-English
bias research, however, is still in its infancy with most work focusing on
English. In our work, we study how grammatical gender bias relating to
politeness levels manifests in Japanese and Korean language models. Linguistic
studies in these languages have identified a connection between gender bias and
politeness levels, however it is not yet known if language models reproduce
these biases. We analyze relative prediction probabilities of the male and
female grammatical genders using templates and find that informal polite speech
is most indicative of the female grammatical gender, while rude and formal
speech is most indicative of the male grammatical gender. Further, we find
politeness levels to be an attack vector for allocational gender bias in
cyberbullying detection models. Cyberbullies can evade detection through simple
techniques abusing politeness levels. We introduce an attack dataset to (i)
identify representational gender bias across politeness levels, (ii)
demonstrate how gender biases can be abused to bypass cyberbullying detection
models and (iii) show that allocational biases can be mitigated via training on
our proposed dataset. Through our findings we highlight the importance of bias
research moving beyond its current English-centrism.
</p></li>
</ul>

<h3>Title: Prevention of cyberattacks in WSN and packet drop by CI framework and information processing protocol using AI and Big Data. (arXiv:2306.09448v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.09448">http://arxiv.org/abs/2306.09448</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.09448] Prevention of cyberattacks in WSN and packet drop by CI framework and information processing protocol using AI and Big Data](http://arxiv.org/abs/2306.09448) #attack</code></li>
<li>Summary: <p>As the reliance on wireless sensor networks (WSNs) rises in numerous sectors,
cyberattack prevention and data transmission integrity become essential
problems. This study provides a complete framework to handle these difficulties
by integrating a cognitive intelligence (CI) framework, an information
processing protocol, and sophisticated artificial intelligence (AI) and big
data analytics approaches. The CI architecture is intended to improve WSN
security by dynamically reacting to an evolving threat scenario. It employs
artificial intelligence algorithms to continuously monitor and analyze network
behavior, identifying and mitigating any intrusions in real time. Anomaly
detection algorithms are also included in the framework to identify packet drop
instances caused by attacks or network congestion. To support the CI
architecture, an information processing protocol focusing on efficient and
secure data transfer within the WSN is introduced. To protect data integrity
and prevent unwanted access, this protocol includes encryption and
authentication techniques. Furthermore, it enhances the routing process with
the use of AI and big data approaches, providing reliable and timely packet
delivery. Extensive simulations and tests are carried out to assess the
efficiency of the suggested framework. The findings show that it is capable of
detecting and preventing several forms of assaults, including as
denial-of-service (DoS) attacks, node compromise, and data tampering.
Furthermore, the framework is highly resilient to packet drop occurrences,
which improves the WSN's overall reliability and performance
</p></li>
</ul>

<h3>Title: Host-Based Network Intrusion Detection via Feature Flattening and Two-stage Collaborative Classifier. (arXiv:2306.09451v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.09451">http://arxiv.org/abs/2306.09451</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.09451] Host-Based Network Intrusion Detection via Feature Flattening and Two-stage Collaborative Classifier](http://arxiv.org/abs/2306.09451) #attack</code></li>
<li>Summary: <p>Network Intrusion Detection Systems (NIDS) have been extensively investigated
by monitoring real network traffic and analyzing suspicious activities.
However, there are limitations in detecting specific types of attacks with
NIDS, such as Advanced Persistent Threats (APT). Additionally, NIDS is
restricted in observing complete traffic information due to encrypted traffic
or a lack of authority. To address these limitations, a Host-based Intrusion
Detection system (HIDS) evaluates resources in the host, including logs, files,
and folders, to identify APT attacks that routinely inject malicious files into
victimized nodes. In this study, a hybrid network intrusion detection system
that combines NIDS and HIDS is proposed to improve intrusion detection
performance. The feature flattening technique is applied to flatten
two-dimensional host-based features into one-dimensional vectors, which can be
directly used by traditional Machine Learning (ML) models. A two-stage
collaborative classifier is introduced that deploys two levels of ML algorithms
to identify network intrusions. In the first stage, a binary classifier is used
to detect benign samples. All detected attack types undergo a multi-class
classifier to reduce the complexity of the original problem and improve the
overall detection performance. The proposed method is shown to generalize
across two well-known datasets, CICIDS 2018 and NDSec-1. Performance of
XGBoost, which represents conventional ML, is evaluated. Combining host and
network features enhances attack detection performance (macro average F1 score)
by 8.1% under the CICIDS 2018 dataset and 3.7% under the NDSec-1 dataset.
Meanwhile, the two-stage collaborative classifier improves detection
performance for most single classes, especially for DoS-LOIC-UDP and
DoS-SlowHTTPTest, with improvements of 30.7% and 84.3%, respectively, when
compared with the traditional ML XGBoost.
</p></li>
</ul>

<h3>Title: Query-Free Evasion Attacks Against Machine Learning-Based Malware Detectors with Generative Adversarial Networks. (arXiv:2306.09925v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.09925">http://arxiv.org/abs/2306.09925</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.09925] Query-Free Evasion Attacks Against Machine Learning-Based Malware Detectors with Generative Adversarial Networks](http://arxiv.org/abs/2306.09925) #attack</code></li>
<li>Summary: <p>Malware detectors based on machine learning (ML) have been shown to be
susceptible to adversarial malware examples. However, current methods to
generate adversarial malware examples still have their limits. They either rely
on detailed model information (gradient-based attacks), or on detailed outputs
of the model - such as class probabilities (score-based attacks), neither of
which are available in real-world scenarios. Alternatively, adversarial
examples might be crafted using only the label assigned by the detector
(label-based attack) to train a substitute network or an agent using
reinforcement learning. Nonetheless, label-based attacks might require querying
a black-box system from a small number to thousands of times, depending on the
approach, which might not be feasible against malware detectors. This work
presents a novel query-free approach to craft adversarial malware examples to
evade ML-based malware detectors. To this end, we have devised a GAN-based
framework to generate adversarial malware examples that look similar to benign
executables in the feature space. To demonstrate the suitability of our
approach we have applied the GAN-based attack to three common types of features
usually employed by static ML-based malware detectors: (1) Byte histogram
features, (2) API-based features, and (3) String-based features. Results show
that our model-agnostic approach performs on par with MalGAN, while generating
more realistic adversarial malware examples without requiring any query to the
malware detectors. Furthermore, we have tested the generated adversarial
examples against state-of-the-art multimodal and deep learning malware
detectors, showing a decrease in detection performance, as well as a decrease
in the average number of detections by the anti-malware engines in VirusTotal.
</p></li>
</ul>

<h3>Title: You Don't Need Robust Machine Learning to Manage Adversarial Attack Risks. (arXiv:2306.09951v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.09951">http://arxiv.org/abs/2306.09951</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.09951] You Don't Need Robust Machine Learning to Manage Adversarial Attack Risks](http://arxiv.org/abs/2306.09951) #attack</code></li>
<li>Summary: <p>The robustness of modern machine learning (ML) models has become an
increasing concern within the community. The ability to subvert a model into
making errant predictions using seemingly inconsequential changes to input is
startling, as is our lack of success in building models robust to this concern.
Existing research shows progress, but current mitigations come with a high cost
and simultaneously reduce the model's accuracy. However, such trade-offs may
not be necessary when other design choices could subvert the risk. In this
survey we review the current literature on attacks and their real-world
occurrences, or limited evidence thereof, to critically evaluate the real-world
risks of adversarial machine learning (AML) for the average entity. This is
done with an eye toward how one would then mitigate these attacks in practice,
the risks for production deployment, and how those risks could be managed. In
doing so we elucidate that many AML threats do not warrant the cost and
trade-offs of robustness due to a low likelihood of attack or availability of
superior non-ML mitigations. Our analysis also recommends cases where an actor
should be concerned about AML to the degree where robust ML models are
necessary for a complete deployment.
</p></li>
</ul>

<h2>robust</h2>
<h3>Title: A New Low-Rank Learning Robust Quaternion Tensor Completion Method for Color Video Inpainting Problem and Fast Algorithms. (arXiv:2306.09652v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.09652">http://arxiv.org/abs/2306.09652</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.09652] A New Low-Rank Learning Robust Quaternion Tensor Completion Method for Color Video Inpainting Problem and Fast Algorithms](http://arxiv.org/abs/2306.09652) #robust</code></li>
<li>Summary: <p>The color video inpainting problem is one of the most challenging problem in
the modern imaging science. It aims to recover a color video from a small part
of pixels that may contain noise. However, there are less of robust models that
can simultaneously preserve the coupling of color channels and the evolution of
color video frames. In this paper, we present a new robust quaternion tensor
completion (RQTC) model to solve this challenging problem and derive the exact
recovery theory. The main idea is to build a quaternion tensor optimization
model to recover a low-rank quaternion tensor that represents the targeted
color video and a sparse quaternion tensor that represents noise. This new
model is very efficient to recover high dimensional data that satisfies the
prior low-rank assumption. To solve the case without low-rank property, we
introduce a new low-rank learning RQTC model, which rearranges similar patches
classified by a quaternion learning method into smaller tensors satisfying the
prior low-rank assumption. We also propose fast algorithms with global
convergence guarantees. In numerical experiments, the proposed methods
successfully recover color videos with eliminating color contamination and
keeping the continuity of video scenery, and their solutions are of higher
quality in terms of PSNR and SSIM values than the state-of-the-art algorithms.
</p></li>
</ul>

<h3>Title: End-to-End Vectorized HD-map Construction with Piecewise Bezier Curve. (arXiv:2306.09700v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.09700">http://arxiv.org/abs/2306.09700</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.09700] End-to-End Vectorized HD-map Construction with Piecewise Bezier Curve](http://arxiv.org/abs/2306.09700) #robust</code></li>
<li>Summary: <p>Vectorized high-definition map (HD-map) construction, which focuses on the
perception of centimeter-level environmental information, has attracted
significant research interest in the autonomous driving community. Most
existing approaches first obtain rasterized map with the segmentation-based
pipeline and then conduct heavy post-processing for downstream-friendly
vectorization. In this paper, by delving into parameterization-based methods,
we pioneer a concise and elegant scheme that adopts unified piecewise Bezier
curve. In order to vectorize changeful map elements end-to-end, we elaborate a
simple yet effective architecture, named Piecewise Bezier HD-map Network
(BeMapNet), which is formulated as a direct set prediction paradigm and
postprocessing-free. Concretely, we first introduce a novel IPM-PE Align module
to inject 3D geometry prior into BEV features through common position encoding
in Transformer. Then a well-designed Piecewise Bezier Head is proposed to
output the details of each map element, including the coordinate of control
points and the segment number of curves. In addition, based on the
progressively restoration of Bezier curve, we also present an efficient
Point-Curve-Region Loss for supervising more robust and precise HD-map
modeling. Extensive comparisons show that our method is remarkably superior to
other existing SOTAs by 18.0 mAP at least.
</p></li>
</ul>

<h3>Title: Label-noise-tolerant medical image classification via self-attention and self-supervised learning. (arXiv:2306.09718v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.09718">http://arxiv.org/abs/2306.09718</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.09718] Label-noise-tolerant medical image classification via self-attention and self-supervised learning](http://arxiv.org/abs/2306.09718) #robust</code></li>
<li>Summary: <p>Deep neural networks (DNNs) have been widely applied in medical image
classification and achieve remarkable classification performance. These
achievements heavily depend on large-scale accurately annotated training data.
However, label noise is inevitably introduced in the medical image annotation,
as the labeling process heavily relies on the expertise and experience of
annotators. Meanwhile, DNNs suffer from overfitting noisy labels, degrading the
performance of models. Therefore, in this work, we innovatively devise
noise-robust training approach to mitigate the adverse effects of noisy labels
in medical image classification. Specifically, we incorporate contrastive
learning and intra-group attention mixup strategies into the vanilla supervised
learning. The contrastive learning for feature extractor helps to enhance
visual representation of DNNs. The intra-group attention mixup module
constructs groups and assigns self-attention weights for group-wise samples,
and subsequently interpolates massive noisy-suppressed samples through weighted
mixup operation. We conduct comparative experiments on both synthetic and
real-world noisy medical datasets under various noise levels. Rigorous
experiments validate that our noise-robust method with contrastive learning and
attention mixup can effectively handle with label noise, and is superior to
state-of-the-art methods. An ablation study also shows that both components
contribute to boost model performance. The proposed method demonstrates its
capability of curb label noise and has certain potential toward real-world
clinic applications.
</p></li>
</ul>

<h3>Title: Wasserstein distributional robustness of neural networks. (arXiv:2306.09844v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.09844">http://arxiv.org/abs/2306.09844</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.09844] Wasserstein distributional robustness of neural networks](http://arxiv.org/abs/2306.09844) #robust</code></li>
<li>Summary: <p>Deep neural networks are known to be vulnerable to adversarial attacks (AA).
For an image recognition task, this means that a small perturbation of the
original can result in the image being misclassified. Design of such attacks as
well as methods of adversarial training against them are subject of intense
research. We re-cast the problem using techniques of Wasserstein
distributionally robust optimization (DRO) and obtain novel contributions
leveraging recent insights from DRO sensitivity analysis. We consider a set of
distributional threat models. Unlike the traditional pointwise attacks, which
assume a uniform bound on perturbation of each input data point, distributional
threat models allow attackers to perturb inputs in a non-uniform way. We link
these more general attacks with questions of out-of-sample performance and
Knightian uncertainty. To evaluate the distributional robustness of neural
networks, we propose a first-order AA algorithm and its multi-step version. Our
attack algorithms include Fast Gradient Sign Method (FGSM) and Projected
Gradient Descent (PGD) as special cases. Furthermore, we provide a new
asymptotic estimate of the adversarial accuracy against distributional threat
models. The bound is fast to compute and first-order accurate, offering new
insights even for the pointwise AA. It also naturally yields out-of-sample
performance guarantees. We conduct numerical experiments on the CIFAR-10
dataset using DNNs on RobustBench to illustrate our theoretical results. Our
code is available at https://github.com/JanObloj/W-DRO-Adversarial-Methods.
</p></li>
</ul>

<h3>Title: Towards Better Orthogonality Regularization with Disentangled Norm in Training Deep CNNs. (arXiv:2306.09939v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.09939">http://arxiv.org/abs/2306.09939</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.09939] Towards Better Orthogonality Regularization with Disentangled Norm in Training Deep CNNs](http://arxiv.org/abs/2306.09939) #robust</code></li>
<li>Summary: <p>Orthogonality regularization has been developed to prevent deep CNNs from
training instability and feature redundancy. Among existing proposals, kernel
orthogonality regularization enforces orthogonality by minimizing the residual
between the Gram matrix formed by convolutional filters and the orthogonality
matrix.
</p></li>
</ul>

<p>We propose a novel measure for achieving better orthogonality among filters,
which disentangles diagonal and correlation information from the residual. The
model equipped with the measure under the principle of imposing strict
orthogonality between filters surpasses previous regularization methods in
near-orthogonality. Moreover, we observe the benefits of improved strict filter
orthogonality in relatively shallow models, but as model depth increases, the
performance gains in models employing strict kernel orthogonality decrease
sharply.
</p>
<p>Furthermore, based on the observation of the potential conflict between
strict kernel orthogonality and growing model capacity, we propose a relaxation
theory on kernel orthogonality regularization. The relaxed kernel orthogonality
achieves enhanced performance on models with increased capacity, shedding light
on the burden of strict kernel orthogonality on deep model performance.
</p>
<p>We conduct extensive experiments with our kernel orthogonality regularization
toolkit on ResNet and WideResNet in CIFAR-10 and CIFAR-100. We observe
state-of-the-art gains in model performance from the toolkit, which includes
both strict orthogonality and relaxed orthogonality regularization, and obtain
more robust models with expressive features. These experiments demonstrate the
efficacy of our toolkit and subtly provide insights into the often overlooked
challenges posed by strict orthogonality, addressing the burden of strict
orthogonality on capacity-rich models.
</p>

<h3>Title: Group Orthogonalization Regularization For Vision Models Adaptation and Robustness. (arXiv:2306.10001v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.10001">http://arxiv.org/abs/2306.10001</a></li>
<li>Code URL: <a href="https://github.com/yoavkurtz/gor">https://github.com/yoavkurtz/gor</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2306.10001] Group Orthogonalization Regularization For Vision Models Adaptation and Robustness](http://arxiv.org/abs/2306.10001) #robust</code></li>
<li>Summary: <p>As neural networks become deeper, the redundancy within their parameters
increases. This phenomenon has led to several methods that attempt to reduce
the correlation between convolutional filters. We propose a computationally
efficient regularization technique that encourages orthonormality between
groups of filters within the same layer. Our experiments show that when
incorporated into recent adaptation methods for diffusion models and vision
transformers (ViTs), this regularization improves performance on downstream
tasks. We further show improved robustness when group orthogonality is enforced
during adversarial training. Our code is available at
https://github.com/YoavKurtz/GOR.
</p></li>
</ul>

<h3>Title: C2F2NeUS: Cascade Cost Frustum Fusion for High Fidelity and Generalizable Neural Surface Reconstruction. (arXiv:2306.10003v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.10003">http://arxiv.org/abs/2306.10003</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.10003] C2F2NeUS: Cascade Cost Frustum Fusion for High Fidelity and Generalizable Neural Surface Reconstruction](http://arxiv.org/abs/2306.10003) #robust</code></li>
<li>Summary: <p>There is an emerging effort to combine the two popular technical paths, i.e.,
the multi-view stereo (MVS) and neural implicit surface (NIS), in scene
reconstruction from sparse views. In this paper, we introduce a novel
integration scheme that combines the multi-view stereo with neural signed
distance function representations, which potentially overcomes the limitations
of both methods. MVS uses per-view depth estimation and cross-view fusion to
generate accurate surface, while NIS relies on a common coordinate volume.
Based on this, we propose to construct per-view cost frustum for finer geometry
estimation, and then fuse cross-view frustums and estimate the implicit signed
distance functions to tackle noise and hole issues. We further apply a cascade
frustum fusion strategy to effectively captures global-local information and
structural consistency. Finally, we apply cascade sampling and a
pseudo-geometric loss to foster stronger integration between the two
architectures. Extensive experiments demonstrate that our method reconstructs
robust surfaces and outperforms existing state-of-the-art methods.
</p></li>
</ul>

<h3>Title: Coaching a Teachable Student. (arXiv:2306.10014v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.10014">http://arxiv.org/abs/2306.10014</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.10014] Coaching a Teachable Student](http://arxiv.org/abs/2306.10014) #robust</code></li>
<li>Summary: <p>We propose a novel knowledge distillation framework for effectively teaching
a sensorimotor student agent to drive from the supervision of a privileged
teacher agent. Current distillation for sensorimotor agents methods tend to
result in suboptimal learned driving behavior by the student, which we
hypothesize is due to inherent differences between the input, modeling
capacity, and optimization processes of the two agents. We develop a novel
distillation scheme that can address these limitations and close the gap
between the sensorimotor agent and its privileged teacher. Our key insight is
to design a student which learns to align their input features with the
teacher's privileged Bird's Eye View (BEV) space. The student then can benefit
from direct supervision by the teacher over the internal representation
learning. To scaffold the difficult sensorimotor learning task, the student
model is optimized via a student-paced coaching mechanism with various
auxiliary supervision. We further propose a high-capacity imitation learned
privileged agent that surpasses prior privileged agents in CARLA and ensures
the student learns safe driving behavior. Our proposed sensorimotor agent
results in a robust image-based behavior cloning agent in CARLA, improving over
current models by over 20.6% in driving score without requiring LiDAR,
historical observations, ensemble of models, on-policy data aggregation or
reinforcement learning.
</p></li>
</ul>

<h3>Title: Building blocks for complex tasks: Robust generative event extraction for radiology reports under domain shifts. (arXiv:2306.09544v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.09544">http://arxiv.org/abs/2306.09544</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.09544] Building blocks for complex tasks: Robust generative event extraction for radiology reports under domain shifts](http://arxiv.org/abs/2306.09544) #robust</code></li>
<li>Summary: <p>This paper explores methods for extracting information from radiology reports
that generalize across exam modalities to reduce requirements for annotated
data. We demonstrate that multi-pass T5-based text-to-text generative models
exhibit better generalization across exam modalities compared to approaches
that employ BERT-based task-specific classification layers. We then develop
methods that reduce the inference cost of the model, making large-scale corpus
processing more feasible for clinical applications. Specifically, we introduce
a generative technique that decomposes complex tasks into smaller subtask
blocks, which improves a single-pass model when combined with multitask
training. In addition, we leverage target-domain contexts during inference to
enhance domain adaptation, enabling use of smaller models. Analyses offer
insights into the benefits of different cost reduction strategies.
</p></li>
</ul>

<h3>Title: Cross-corpus Readability Compatibility Assessment for English Texts. (arXiv:2306.09704v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.09704">http://arxiv.org/abs/2306.09704</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.09704] Cross-corpus Readability Compatibility Assessment for English Texts](http://arxiv.org/abs/2306.09704) #robust</code></li>
<li>Summary: <p>Text readability assessment has gained significant attention from researchers
in various domains. However, the lack of exploration into corpus compatibility
poses a challenge as different research groups utilize different corpora. In
this study, we propose a novel evaluation framework, Cross-corpus text
Readability Compatibility Assessment (CRCA), to address this issue. The
framework encompasses three key components: (1) Corpus: CEFR, CLEC, CLOTH, NES,
OSP, and RACE. Linguistic features, GloVe word vector representations, and
their fusion features were extracted. (2) Classification models: Machine
learning methods (XGBoost, SVM) and deep learning methods (BiLSTM,
Attention-BiLSTM) were employed. (3) Compatibility metrics: RJSD, RRNSS, and
NDCG metrics. Our findings revealed: (1) Validated corpus compatibility, with
OSP standing out as significantly different from other datasets. (2) An
adaptation effect among corpora, feature representations, and classification
methods. (3) Consistent outcomes across the three metrics, validating the
robustness of the compatibility assessment framework. The outcomes of this
study offer valuable insights into corpus selection, feature representation,
and classification methods, and it can also serve as a beginning effort for
cross-corpus transfer learning.
</p></li>
</ul>

<h3>Title: Pushing the Limits of ChatGPT on NLP Tasks. (arXiv:2306.09719v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.09719">http://arxiv.org/abs/2306.09719</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.09719] Pushing the Limits of ChatGPT on NLP Tasks](http://arxiv.org/abs/2306.09719) #robust</code></li>
<li>Summary: <p>Despite the success of ChatGPT, its performances on most NLP tasks are still
well below the supervised baselines. In this work, we looked into the causes,
and discovered that its subpar performance was caused by the following factors:
(1) token limit in the prompt does not allow for the full utilization of the
supervised datasets; (2) mismatch between the generation nature of ChatGPT and
NLP tasks; (3) intrinsic pitfalls of LLMs models, e.g., hallucination, overly
focus on certain keywords, etc.
</p></li>
</ul>

<p>In this work, we propose a collection of general modules to address these
issues, in an attempt to push the limits of ChatGPT on NLP tasks. Our proposed
modules include (1) a one-input-multiple-prompts strategy that employs multiple
prompts for one input to accommodate more demonstrations; (2) using fine-tuned
models for better demonstration retrieval; (3) transforming tasks to formats
that are more tailored to the generation nature; (4) employing reasoning
strategies that are tailored to addressing the task-specific complexity; (5)
the self-verification strategy to address the hallucination issue of LLMs; (6)
the paraphrase strategy to improve the robustness of model predictions.
</p>
<p>We conduct experiments on 21 datasets of 10 representative NLP tasks,
including question answering, commonsense reasoning, natural language
inference, sentiment analysis, named entity recognition, entity-relation
extraction, event extraction, dependency parsing, semantic role labeling, and
part-of-speech tagging. Using the proposed assemble of techniques, we are able
to significantly boost the performance of ChatGPT on the selected NLP tasks,
achieving performances comparable to or better than supervised baselines, or
even existing SOTA performances.
</p>

<h2>biometric</h2>
<h3>Title: Lightweight Attribute Localizing Models for Pedestrian Attribute Recognition. (arXiv:2306.09822v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.09822">http://arxiv.org/abs/2306.09822</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.09822] Lightweight Attribute Localizing Models for Pedestrian Attribute Recognition](http://arxiv.org/abs/2306.09822) #biometric</code></li>
<li>Summary: <p>Pedestrian Attribute Recognition (PAR) deals with the problem of identifying
features in a pedestrian image. It has found interesting applications in person
retrieval, suspect re-identification and soft biometrics. In the past few
years, several Deep Neural Networks (DNNs) have been designed to solve the
task; however, the developed DNNs predominantly suffer from
over-parameterization and high computational complexity. These problems hinder
them from being exploited in resource-constrained embedded devices with limited
memory and computational capacity. By reducing a network's layers using
effective compression techniques, such as tensor decomposition, neural network
compression is an effective method to tackle these problems. We propose novel
Lightweight Attribute Localizing Models (LWALM) for Pedestrian Attribute
Recognition (PAR). LWALM is a compressed neural network obtained after
effective layer-wise compression of the Attribute Localization Model (ALM)
using the Canonical Polyadic Decomposition with Error Preserving Correction
(CPD-EPC) algorithm.
</p></li>
</ul>

<h2>steal</h2>
<h2>extraction</h2>
<h3>Title: PAtt-Lite: Lightweight Patch and Attention MobileNet for Challenging Facial Expression Recognition. (arXiv:2306.09626v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.09626">http://arxiv.org/abs/2306.09626</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.09626] PAtt-Lite: Lightweight Patch and Attention MobileNet for Challenging Facial Expression Recognition](http://arxiv.org/abs/2306.09626) #extraction</code></li>
<li>Summary: <p>Facial Expression Recognition (FER) is a machine learning problem that deals
with recognizing human facial expressions. While existing work has achieved
performance improvements in recent years, FER in the wild and under challenging
conditions remains a challenge. In this paper, a lightweight patch and
attention network based on MobileNetV1, referred to as PAtt-Lite, is proposed
to improve FER performance under challenging conditions. A truncated
ImageNet-pre-trained MobileNetV1 is utilized as the backbone feature extractor
of the proposed method. In place of the truncated layers is a patch extraction
block that is proposed for extracting significant local facial features to
enhance the representation from MobileNetV1, especially under challenging
conditions. An attention classifier is also proposed to improve the learning of
these patched feature maps from the extremely lightweight feature extractor.
The experimental results on public benchmark databases proved the effectiveness
of the proposed method. PAtt-Lite achieved state-of-the-art results on CK+,
RAF-DB, FER2013, FERPlus, and the challenging conditions subsets for RAF-DB and
FERPlus. The source code for the proposed method will be available at
https://github.com/JLREx/PAtt-Lite.
</p></li>
</ul>

<h3>Title: Multi-View Class Incremental Learning. (arXiv:2306.09675v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.09675">http://arxiv.org/abs/2306.09675</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.09675] Multi-View Class Incremental Learning](http://arxiv.org/abs/2306.09675) #extraction</code></li>
<li>Summary: <p>Multi-view learning (MVL) has gained great success in integrating information
from multiple perspectives of a dataset to improve downstream task performance.
To make MVL methods more practical in an open-ended environment, this paper
investigates a novel paradigm called multi-view class incremental learning
(MVCIL), where a single model incrementally classifies new classes from a
continual stream of views, requiring no access to earlier views of data.
However, MVCIL is challenged by the catastrophic forgetting of old information
and the interference with learning new concepts. To address this, we first
develop a randomization-based representation learning technique serving for
feature extraction to guarantee their separate view-optimal working states,
during which multiple views belonging to a class are presented sequentially;
Then, we integrate them one by one in the orthogonality fusion subspace spanned
by the extracted features; Finally, we introduce selective weight consolidation
for learning-without-forgetting decision-making while encountering new classes.
Extensive experiments on synthetic and real-world datasets validate the
effectiveness of our approach.
</p></li>
</ul>

<h3>Title: MixedTeacher : Knowledge Distillation for fast inference textural anomaly detection. (arXiv:2306.09859v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.09859">http://arxiv.org/abs/2306.09859</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.09859] MixedTeacher : Knowledge Distillation for fast inference textural anomaly detection](http://arxiv.org/abs/2306.09859) #extraction</code></li>
<li>Summary: <p>For a very long time, unsupervised learning for anomaly detection has been at
the heart of image processing research and a stepping stone for high
performance industrial automation process. With the emergence of CNN, several
methods have been proposed such as Autoencoders, GAN, deep feature extraction,
etc. In this paper, we propose a new method based on the promising concept of
knowledge distillation which consists of training a network (the student) on
normal samples while considering the output of a larger pretrained network (the
teacher). The main contributions of this paper are twofold: First, a reduced
student architecture with optimal layer selection is proposed, then a new
Student-Teacher architecture with network bias reduction combining two teachers
is proposed in order to jointly enhance the performance of anomaly detection
and its localization accuracy. The proposed texture anomaly detector has an
outstanding capability to detect defects in any texture and a fast inference
time compared to the SOTA methods.
</p></li>
</ul>

<h3>Title: Listener Model for the PhotoBook Referential Game with CLIPScores as Implicit Reference Chain. (arXiv:2306.09607v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.09607">http://arxiv.org/abs/2306.09607</a></li>
<li>Code URL: <a href="https://github.com/slseanwu/photobook-full-listener">https://github.com/slseanwu/photobook-full-listener</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2306.09607] Listener Model for the PhotoBook Referential Game with CLIPScores as Implicit Reference Chain](http://arxiv.org/abs/2306.09607) #extraction</code></li>
<li>Summary: <p>PhotoBook is a collaborative dialogue game where two players receive private,
partially-overlapping sets of images and resolve which images they have in
common. It presents machines with a great challenge to learn how people build
common ground around multimodal context to communicate effectively. Methods
developed in the literature, however, cannot be deployed to real gameplay since
they only tackle some subtasks of the game, and they require additional
reference chains inputs, whose extraction process is imperfect. Therefore, we
propose a reference chain-free listener model that directly addresses the
game's predictive task, i.e., deciding whether an image is shared with partner.
Our DeBERTa-based listener model reads the full dialogue, and utilizes
CLIPScore features to assess utterance-image relevance. We achieve >77%
accuracy on unseen sets of images/game themes, outperforming baseline by >17
points.
</p></li>
</ul>

<h3>Title: Cross-Domain Toxic Spans Detection. (arXiv:2306.09642v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.09642">http://arxiv.org/abs/2306.09642</a></li>
<li>Code URL: <a href="https://github.com/sfschouten/toxic-cross-domain">https://github.com/sfschouten/toxic-cross-domain</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2306.09642] Cross-Domain Toxic Spans Detection](http://arxiv.org/abs/2306.09642) #extraction</code></li>
<li>Summary: <p>Given the dynamic nature of toxic language use, automated methods for
detecting toxic spans are likely to encounter distributional shift. To explore
this phenomenon, we evaluate three approaches for detecting toxic spans under
cross-domain conditions: lexicon-based, rationale extraction, and fine-tuned
language models. Our findings indicate that a simple method using off-the-shelf
lexicons performs best in the cross-domain setup. The cross-domain error
analysis suggests that (1) rationale extraction methods are prone to false
negatives, while (2) language models, despite performing best for the in-domain
case, recall fewer explicitly toxic words than lexicons and are prone to
certain types of false positives. Our code is publicly available at:
https://github.com/sfschouten/toxic-cross-domain.
</p></li>
</ul>

<h3>Title: Class-Adaptive Self-Training for Relation Extraction with Incompletely Annotated Training Data. (arXiv:2306.09697v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.09697">http://arxiv.org/abs/2306.09697</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.09697] Class-Adaptive Self-Training for Relation Extraction with Incompletely Annotated Training Data](http://arxiv.org/abs/2306.09697) #extraction</code></li>
<li>Summary: <p>Relation extraction (RE) aims to extract relations from sentences and
documents. Existing relation extraction models typically rely on supervised
machine learning. However, recent studies showed that many RE datasets are
incompletely annotated. This is known as the false negative problem in which
valid relations are falsely annotated as 'no_relation'. Models trained with
such data inevitably make similar mistakes during the inference stage.
Self-training has been proven effective in alleviating the false negative
problem. However, traditional self-training is vulnerable to confirmation bias
and exhibits poor performance in minority classes. To overcome this limitation,
we proposed a novel class-adaptive re-sampling self-training framework.
Specifically, we re-sampled the pseudo-labels for each class by precision and
recall scores. Our re-sampling strategy favored the pseudo-labels of classes
with high precision and low recall, which improved the overall recall without
significantly compromising precision. We conducted experiments on
document-level and biomedical relation extraction datasets, and the results
showed that our proposed self-training framework consistently outperforms
existing competitive methods on the Re-DocRED and ChemDisgene datasets when the
training data are incompletely annotated. Our code is released at
https://github.com/DAMO-NLP-SG/CAST.
</p></li>
</ul>

<h3>Title: RED$^{\rm FM}$: a Filtered and Multilingual Relation Extraction Dataset. (arXiv:2306.09802v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.09802">http://arxiv.org/abs/2306.09802</a></li>
<li>Code URL: <a href="https://github.com/Babelscape/rebel">https://github.com/Babelscape/rebel</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2306.09802] RED$^{\rm FM}$: a Filtered and Multilingual Relation Extraction Dataset](http://arxiv.org/abs/2306.09802) #extraction</code></li>
<li>Summary: <p>Relation Extraction (RE) is a task that identifies relationships between
entities in a text, enabling the acquisition of relational facts and bridging
the gap between natural language and structured knowledge. However, current RE
models often rely on small datasets with low coverage of relation types,
particularly when working with languages other than English. In this paper, we
address the above issue and provide two new resources that enable the training
and evaluation of multilingual RE systems. First, we present SRED$^{\rm FM}$,
an automatically annotated dataset covering 18 languages, 400 relation types,
13 entity types, totaling more than 40 million triplet instances. Second, we
propose RED$^{\rm FM}$, a smaller, human-revised dataset for seven languages
that allows for the evaluation of multilingual RE systems. To demonstrate the
utility of these novel datasets, we experiment with the first end-to-end
multilingual RE model, mREBEL, that extracts triplets, including entity types,
in multiple languages. We release our resources and model checkpoints at
https://www.github.com/babelscape/rebel
</p></li>
</ul>

<h2>membership infer</h2>
<h2>federate</h2>
<h3>Title: HePCo: Data-Free Heterogeneous Prompt Consolidation for Continual Federated Learning. (arXiv:2306.09970v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.09970">http://arxiv.org/abs/2306.09970</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.09970] HePCo: Data-Free Heterogeneous Prompt Consolidation for Continual Federated Learning](http://arxiv.org/abs/2306.09970) #federate</code></li>
<li>Summary: <p>In this paper, we focus on the important yet understudied problem of
Continual Federated Learning (CFL), where a server communicates with a set of
clients to incrementally learn new concepts over time without sharing or
storing any data. The complexity of this problem is compounded by challenges
from both the Continual and Federated Learning perspectives. Specifically,
models trained in a CFL setup suffer from catastrophic forgetting which is
exacerbated by data heterogeneity across clients. Existing attempts at this
problem tend to impose large overheads on clients and communication channels or
require access to stored data which renders them unsuitable for real-world use
due to privacy. In this paper, we attempt to tackle forgetting and
heterogeneity while minimizing overhead costs and without requiring access to
any stored data. We achieve this by leveraging a prompting based approach (such
that only prompts and classifier heads have to be communicated) and proposing a
novel and lightweight generation and distillation scheme to consolidate client
models at the server. We formulate this problem for image classification and
establish strong baselines for comparison, conduct experiments on CIFAR-100 as
well as challenging, large-scale datasets like ImageNet-R and DomainNet. Our
approach outperforms both existing methods and our own baselines by as much as
7% while significantly reducing communication and client-level computation
costs.
</p></li>
</ul>

<h3>Title: A Simple Data Augmentation for Feature Distribution Skewed Federated Learning. (arXiv:2306.09363v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.09363">http://arxiv.org/abs/2306.09363</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.09363] A Simple Data Augmentation for Feature Distribution Skewed Federated Learning](http://arxiv.org/abs/2306.09363) #federate</code></li>
<li>Summary: <p>Federated learning (FL) facilitates collaborative learning among multiple
clients in a distributed manner, while ensuring privacy protection. However,
its performance is inevitably degraded as suffering data heterogeneity, i.e.,
non-IID data. In this paper, we focus on the feature distribution skewed FL
scenario, which is widespread in real-world applications. The main challenge
lies in the feature shift caused by the different underlying distributions of
local datasets. While the previous attempts achieved progress, few studies pay
attention to the data itself, the root of this issue. Therefore, the primary
goal of this paper is to develop a general data augmentation technique at the
input level, to mitigate the feature shift. To achieve this goal, we propose
FedRDN, a simple yet remarkably effective data augmentation method for feature
distribution skewed FL, which randomly injects the statistics of the dataset
from the entire federation into the client's data. By this, our method can
effectively improve the generalization of features, thereby mitigating the
feature shift. Moreover, FedRDN is a plug-and-play component, which can be
seamlessly integrated into the data augmentation flow with only a few lines of
code. Extensive experiments on several datasets show that the performance of
various representative FL works can be further improved by combining them with
FedRDN, which demonstrates the strong scalability and generalizability of
FedRDN. The source code will be released.
</p></li>
</ul>

<h3>Title: Towards Practical Federated Causal Structure Learning. (arXiv:2306.09433v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.09433">http://arxiv.org/abs/2306.09433</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.09433] Towards Practical Federated Causal Structure Learning](http://arxiv.org/abs/2306.09433) #federate</code></li>
<li>Summary: <p>Understanding causal relations is vital in scientific discovery. The process
of causal structure learning involves identifying causal graphs from
observational data to understand such relations. Usually, a central server
performs this task, but sharing data with the server poses privacy risks.
Federated learning can solve this problem, but existing solutions for federated
causal structure learning make unrealistic assumptions about data and lack
convergence guarantees. FedC2SL is a federated constraint-based causal
structure learning scheme that learns causal graphs using a federated
conditional independence test, which examines conditional independence between
two variables under a condition set without collecting raw data from clients.
FedC2SL requires weaker and more realistic assumptions about data and offers
stronger resistance to data variability among clients. FedPC and FedFCI are the
two variants of FedC2SL for causal structure learning in causal sufficiency and
causal insufficiency, respectively. The study evaluates FedC2SL using both
synthetic datasets and real-world data against existing solutions and finds it
demonstrates encouraging performance and strong resilience to data
heterogeneity among clients.
</p></li>
</ul>

<h3>Title: Fedstellar: A Platform for Decentralized Federated Learning. (arXiv:2306.09750v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.09750">http://arxiv.org/abs/2306.09750</a></li>
<li>Code URL: <a href="https://github.com/enriquetomasmb/fedstellar">https://github.com/enriquetomasmb/fedstellar</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2306.09750] Fedstellar: A Platform for Decentralized Federated Learning](http://arxiv.org/abs/2306.09750) #federate</code></li>
<li>Summary: <p>In 2016, Google proposed Federated Learning (FL) as a novel paradigm to train
Machine Learning (ML) models across the participants of a federation while
preserving data privacy. Since its birth, Centralized FL (CFL) has been the
most used approach, where a central entity aggregates participants' models to
create a global one. However, CFL presents limitations such as communication
bottlenecks, single point of failure, and reliance on a central server.
Decentralized Federated Learning (DFL) addresses these issues by enabling
decentralized model aggregation and minimizing dependency on a central entity.
Despite these advances, current platforms training DFL models struggle with key
issues such as managing heterogeneous federation network topologies. To
overcome these challenges, this paper presents Fedstellar, a novel platform
designed to train FL models in a decentralized, semi-decentralized, and
centralized fashion across diverse federations of physical or virtualized
devices. The Fedstellar implementation encompasses a web application with an
interactive graphical interface, a controller for deploying federations of
nodes using physical or virtual devices, and a core deployed on each device
which provides the logic needed to train, aggregate, and communicate in the
network. The effectiveness of the platform has been demonstrated in two
scenarios: a physical deployment involving single-board devices such as
Raspberry Pis for detecting cyberattacks, and a virtualized deployment
comparing various FL approaches in a controlled environment using MNIST and
CIFAR-10 datasets. In both scenarios, Fedstellar demonstrated consistent
performance and adaptability, achieving F1 scores of 91%, 98%, and 91.2% using
DFL for detecting cyberattacks and classifying MNIST and CIFAR-10,
respectively, reducing training time by 32% compared to centralized approaches.
</p></li>
</ul>

<h3>Title: Towards Quantum Federated Learning. (arXiv:2306.09912v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.09912">http://arxiv.org/abs/2306.09912</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.09912] Towards Quantum Federated Learning](http://arxiv.org/abs/2306.09912) #federate</code></li>
<li>Summary: <p>Quantum Federated Learning (QFL) is an emerging interdisciplinary field that
merges the principles of Quantum Computing (QC) and Federated Learning (FL),
with the goal of leveraging quantum technologies to enhance privacy, security,
and efficiency in the learning process. Currently, there is no comprehensive
survey for this interdisciplinary field. This review offers a thorough,
holistic examination of QFL. We aim to provide a comprehensive understanding of
the principles, techniques, and emerging applications of QFL. We discuss the
current state of research in this rapidly evolving field, identify challenges
and opportunities associated with integrating these technologies, and outline
future directions and open research questions. We propose a unique taxonomy of
QFL techniques, categorized according to their characteristics and the quantum
techniques employed. As the field of QFL continues to progress, we can
anticipate further breakthroughs and applications across various industries,
driving innovation and addressing challenges related to data privacy, security,
and resource optimization. This review serves as a first-of-its-kind
comprehensive guide for researchers and practitioners interested in
understanding and advancing the field of QFL.
</p></li>
</ul>

<h2>fair</h2>
<h3>Title: Demystifying GPT Self-Repair for Code Generation. (arXiv:2306.09896v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.09896">http://arxiv.org/abs/2306.09896</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.09896] Demystifying GPT Self-Repair for Code Generation](http://arxiv.org/abs/2306.09896) #fair</code></li>
<li>Summary: <p>Large Language Models (LLMs) have shown remarkable aptitude in code
generation but still struggle on challenging programming tasks. Self-repair --
in which the model debugs and fixes mistakes in its own code -- has recently
become a popular way to boost performance in these settings. However, only very
limited studies on how and when self-repair works effectively exist in the
literature, and one might wonder to what extent a model is really capable of
providing accurate feedback on why the code is wrong when that code was
generated by the same model. In this paper, we analyze GPT-3.5 and GPT-4's
ability to perform self-repair on APPS, a challenging dataset consisting of
diverse coding challenges. To do so, we first establish a new evaluation
strategy dubbed pass@t that measures the pass rate of the tasks against the
total number of tokens sampled from the model, enabling a fair comparison to
purely sampling-based approaches. With this evaluation strategy, we find that
the effectiveness of self-repair is only seen in GPT-4. We also observe that
self-repair is bottlenecked by the feedback stage; using GPT-4 to give feedback
on the programs generated by GPT-3.5 and using expert human programmers to give
feedback on the programs generated by GPT-4, we unlock significant performance
gains.
</p></li>
</ul>

<h3>Title: Arbitrariness Lies Beyond the Fairness-Accuracy Frontier. (arXiv:2306.09425v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.09425">http://arxiv.org/abs/2306.09425</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.09425] Arbitrariness Lies Beyond the Fairness-Accuracy Frontier](http://arxiv.org/abs/2306.09425) #fair</code></li>
<li>Summary: <p>Machine learning tasks may admit multiple competing models that achieve
similar performance yet produce conflicting outputs for individual samples -- a
phenomenon known as predictive multiplicity. We demonstrate that fairness
interventions in machine learning optimized solely for group fairness and
accuracy can exacerbate predictive multiplicity. Consequently, state-of-the-art
fairness interventions can mask high predictive multiplicity behind favorable
group fairness and accuracy metrics. We argue that a third axis of
``arbitrariness'' should be considered when deploying models to aid
decision-making in applications of individual-level impact. To address this
challenge, we propose an ensemble algorithm applicable to any fairness
intervention that provably ensures more consistent predictions.
</p></li>
</ul>

<h3>Title: FFB: A Fair Fairness Benchmark for In-Processing Group Fairness Methods. (arXiv:2306.09468v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.09468">http://arxiv.org/abs/2306.09468</a></li>
<li>Code URL: <a href="https://github.com/ahxt/fair_fairness_benchmark">https://github.com/ahxt/fair_fairness_benchmark</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2306.09468] FFB: A Fair Fairness Benchmark for In-Processing Group Fairness Methods](http://arxiv.org/abs/2306.09468) #fair</code></li>
<li>Summary: <p>This paper introduces the Fair Fairness Benchmark (\textsf{FFB}), a
benchmarking framework for in-processing group fairness methods. Ensuring
fairness in machine learning is critical for ethical and legal compliance.
However, there exist challenges in comparing and developing of fairness methods
due to inconsistencies in experimental settings, lack of accessible algorithmic
implementations, and limited extensibility of current fairness packages and
tools. To address these issues, we introduce an open-source, standardized
benchmark for evaluating in-processing group fairness methods and provide a
comprehensive analysis of state-of-the-art methods to ensure different notions
of group fairness. This work offers the following key contributions: the
provision of flexible, extensible, minimalistic, and research-oriented
open-source code; the establishment of unified fairness method benchmarking
pipelines; and extensive benchmarking, which yields key insights from
$\mathbf{45,079}$ experiments. We believe our work will significantly
facilitate the growth and development of the fairness research community. The
benchmark, including code and running logs, is available at
https://github.com/ahxt/fair_fairness_benchmark
</p></li>
</ul>

<h3>Title: Fairness in Preference-based Reinforcement Learning. (arXiv:2306.09995v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.09995">http://arxiv.org/abs/2306.09995</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.09995] Fairness in Preference-based Reinforcement Learning](http://arxiv.org/abs/2306.09995) #fair</code></li>
<li>Summary: <p>In this paper, we address the issue of fairness in preference-based
reinforcement learning (PbRL) in the presence of multiple objectives. The main
objective is to design control policies that can optimize multiple objectives
while treating each objective fairly. Toward this objective, we design a new
fairness-induced preference-based reinforcement learning or FPbRL. The main
idea of FPbRL is to learn vector reward functions associated with multiple
objectives via new welfare-based preferences rather than reward-based
preference in PbRL, coupled with policy learning via maximizing a generalized
Gini welfare function. Finally, we provide experiment studies on three
different environments to show that the proposed FPbRL approach can achieve
both efficiency and equity for learning effective and fair policies.
</p></li>
</ul>

<h2>interpretability</h2>
<h3>Title: Sample-Efficient Learning of Novel Visual Concepts. (arXiv:2306.09482v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.09482">http://arxiv.org/abs/2306.09482</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.09482] Sample-Efficient Learning of Novel Visual Concepts](http://arxiv.org/abs/2306.09482) #interpretability</code></li>
<li>Summary: <p>Despite the advances made in visual object recognition, state-of-the-art deep
learning models struggle to effectively recognize novel objects in a few-shot
setting where only a limited number of examples are provided. Unlike humans who
excel at such tasks, these models often fail to leverage known relationships
between entities in order to draw conclusions about such objects. In this work,
we show that incorporating a symbolic knowledge graph into a state-of-the-art
recognition model enables a new approach for effective few-shot classification.
In our proposed neuro-symbolic architecture and training methodology, the
knowledge graph is augmented with additional relationships extracted from a
small set of examples, improving its ability to recognize novel objects by
considering the presence of interconnected entities. Unlike existing few-shot
classifiers, we show that this enables our model to incorporate not only
objects but also abstract concepts and affordances. The existence of the
knowledge graph also makes this approach amenable to interpretability through
analysis of the relationships contained within it. We empirically show that our
approach outperforms current state-of-the-art few-shot multi-label
classification methods on the COCO dataset and evaluate the addition of
abstract concepts and affordances on the Visual Genome dataset.
</p></li>
</ul>

<h2>explainability</h2>
<h3>Title: Prototype Learning for Explainable Regression. (arXiv:2306.09858v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.09858">http://arxiv.org/abs/2306.09858</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.09858] Prototype Learning for Explainable Regression](http://arxiv.org/abs/2306.09858) #explainability</code></li>
<li>Summary: <p>The lack of explainability limits the adoption of deep learning models in
clinical practice. While methods exist to improve the understanding of such
models, these are mainly saliency-based and developed for classification,
despite many important tasks in medical imaging being continuous regression
problems. Therefore, in this work, we present ExPeRT: an explainable
prototype-based model specifically designed for regression tasks. Our proposed
model makes a sample prediction from the distances to a set of learned
prototypes in latent space, using a weighted mean of prototype labels. The
distances in latent space are regularized to be relative to label differences,
and each of the prototypes can be visualized as a sample from the training set.
The image-level distances are further constructed from patch-level distances,
in which the patches of both images are structurally matched using optimal
transport. We demonstrate our proposed model on the task of brain age
prediction on two image datasets: adult MR and fetal ultrasound. Our approach
achieved state-of-the-art prediction performance while providing insight in the
model's reasoning process.
</p></li>
</ul>

<h2>watermark</h2>
<h2>diffusion</h2>
<h3>Title: R2-Diff: Denoising by diffusion as a refinement of retrieved motion for image-based motion prediction. (arXiv:2306.09483v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.09483">http://arxiv.org/abs/2306.09483</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.09483] R2-Diff: Denoising by diffusion as a refinement of retrieved motion for image-based motion prediction](http://arxiv.org/abs/2306.09483) #diffusion</code></li>
<li>Summary: <p>Image-based motion prediction is one of the essential techniques for robot
manipulation. Among the various prediction models, we focus on diffusion models
because they have achieved state-of-the-art performance in various
applications. In image-based motion prediction, diffusion models stochastically
predict contextually appropriate motion by gradually denoising random Gaussian
noise based on the image context. While diffusion models are able to predict
various motions by changing the random noise, they sometimes fail to predict a
contextually appropriate motion based on the image because the random noise is
sampled independently of the image context. To solve this problem, we propose
R2-Diff. In R2-Diff, a motion retrieved from a dataset based on image
similarity is fed into a diffusion model instead of random noise. Then, the
retrieved motion is refined through the denoising process of the diffusion
model. Since the retrieved motion is almost appropriate to the context, it
becomes easier to predict contextually appropriate motion. However, traditional
diffusion models are not optimized to refine the retrieved motion. Therefore,
we propose the method of tuning the hyperparameters based on the distance of
the nearest neighbor motion among the dataset to optimize the diffusion model
for refinement. Furthermore, we propose an image-based retrieval method to
retrieve the nearest neighbor motion in inference. Our proposed retrieval
efficiently computes the similarity based on the image features along the
motion trajectory. We demonstrate that R2-Diff accurately predicts appropriate
motions and achieves high task success rates compared to recent
state-of-the-art models in robot manipulation.
</p></li>
</ul>

<h3>Title: Edit-DiffNeRF: Editing 3D Neural Radiance Fields using 2D Diffusion Model. (arXiv:2306.09551v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.09551">http://arxiv.org/abs/2306.09551</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.09551] Edit-DiffNeRF: Editing 3D Neural Radiance Fields using 2D Diffusion Model](http://arxiv.org/abs/2306.09551) #diffusion</code></li>
<li>Summary: <p>Recent research has demonstrated that the combination of pretrained diffusion
models with neural radiance fields (NeRFs) has emerged as a promising approach
for text-to-3D generation. Simply coupling NeRF with diffusion models will
result in cross-view inconsistency and degradation of stylized view syntheses.
To address this challenge, we propose the Edit-DiffNeRF framework, which is
composed of a frozen diffusion model, a proposed delta module to edit the
latent semantic space of the diffusion model, and a NeRF. Instead of training
the entire diffusion for each scene, our method focuses on editing the latent
semantic space in frozen pretrained diffusion models by the delta module. This
fundamental change to the standard diffusion framework enables us to make
fine-grained modifications to the rendered views and effectively consolidate
these instructions in a 3D scene via NeRF training. As a result, we are able to
produce an edited 3D scene that faithfully aligns to input text instructions.
Furthermore, to ensure semantic consistency across different viewpoints, we
propose a novel multi-view semantic consistency loss that extracts a latent
semantic embedding from the input view as a prior, and aim to reconstruct it in
different views. Our proposed method has been shown to effectively edit
real-world 3D scenes, resulting in 25% improvement in the alignment of the
performed 3D edits with text instructions compared to prior work.
</p></li>
</ul>

<h3>Title: The Big Data Myth: Using Diffusion Models for Dataset Generation to Train Deep Detection Models. (arXiv:2306.09762v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.09762">http://arxiv.org/abs/2306.09762</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.09762] The Big Data Myth: Using Diffusion Models for Dataset Generation to Train Deep Detection Models](http://arxiv.org/abs/2306.09762) #diffusion</code></li>
<li>Summary: <p>Despite the notable accomplishments of deep object detection models, a major
challenge that persists is the requirement for extensive amounts of training
data. The process of procuring such real-world data is a laborious undertaking,
which has prompted researchers to explore new avenues of research, such as
synthetic data generation techniques. This study presents a framework for the
generation of synthetic datasets by fine-tuning pretrained stable diffusion
models. The synthetic datasets are then manually annotated and employed for
training various object detection models. These detectors are evaluated on a
real-world test set of 331 images and compared against a baseline model that
was trained on real-world images. The results of this study reveal that the
object detection models trained on synthetic data perform similarly to the
baseline model. In the context of apple detection in orchards, the average
precision deviation with the baseline ranges from 0.09 to 0.12. This study
illustrates the potential of synthetic data generation techniques as a viable
alternative to the collection of extensive training data for the training of
deep models.
</p></li>
</ul>

<h3>Title: AvatarBooth: High-Quality and Customizable 3D Human Avatar Generation. (arXiv:2306.09864v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.09864">http://arxiv.org/abs/2306.09864</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.09864] AvatarBooth: High-Quality and Customizable 3D Human Avatar Generation](http://arxiv.org/abs/2306.09864) #diffusion</code></li>
<li>Summary: <p>We introduce AvatarBooth, a novel method for generating high-quality 3D
avatars using text prompts or specific images. Unlike previous approaches that
can only synthesize avatars based on simple text descriptions, our method
enables the creation of personalized avatars from casually captured face or
body images, while still supporting text-based model generation and editing.
Our key contribution is the precise avatar generation control by using dual
fine-tuned diffusion models separately for the human face and body. This
enables us to capture intricate details of facial appearance, clothing, and
accessories, resulting in highly realistic avatar generations. Furthermore, we
introduce pose-consistent constraint to the optimization process to enhance the
multi-view consistency of synthesized head images from the diffusion model and
thus eliminate interference from uncontrolled human poses. In addition, we
present a multi-resolution rendering strategy that facilitates coarse-to-fine
supervision of 3D avatar generation, thereby enhancing the performance of the
proposed system. The resulting avatar model can be further edited using
additional text descriptions and driven by motion sequences. Experiments show
that AvatarBooth outperforms previous text-to-3D methods in terms of rendering
and geometric quality from either text prompts or specific images. Please check
our project website at https://zeng-yifei.github.io/avatarbooth_page/.
</p></li>
</ul>

<h3>Title: Energy-Based Cross Attention for Bayesian Context Update in Text-to-Image Diffusion Models. (arXiv:2306.09869v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.09869">http://arxiv.org/abs/2306.09869</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.09869] Energy-Based Cross Attention for Bayesian Context Update in Text-to-Image Diffusion Models](http://arxiv.org/abs/2306.09869) #diffusion</code></li>
<li>Summary: <p>Despite the remarkable performance of text-to-image diffusion models in image
generation tasks, recent studies have raised the issue that generated images
sometimes cannot capture the intended semantic contents of the text prompts,
which phenomenon is often called semantic misalignment. To address this, here
we present a novel energy-based model (EBM) framework. Specifically, we first
formulate EBMs of latent image representations and text embeddings in each
cross-attention layer of the denoising autoencoder. Then, we obtain the
gradient of the log posterior of context vectors, which can be updated and
transferred to the subsequent cross-attention layer, thereby implicitly
minimizing a nested hierarchy of energy functions. Our latent EBMs further
allow zero-shot compositional generation as a linear combination of
cross-attention outputs from different contexts. Using extensive experiments,
we demonstrate that the proposed method is highly effective in handling various
image generation tasks, including multi-concept generation, text-guided image
inpainting, and real and synthetic image editing.
</p></li>
</ul>

<h3>Title: Drag-guided diffusion models for vehicle image generation. (arXiv:2306.09935v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.09935">http://arxiv.org/abs/2306.09935</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.09935] Drag-guided diffusion models for vehicle image generation](http://arxiv.org/abs/2306.09935) #diffusion</code></li>
<li>Summary: <p>Denoising diffusion models trained at web-scale have revolutionized image
generation. The application of these tools to engineering design is an
intriguing possibility, but is currently limited by their inability to parse
and enforce concrete engineering constraints. In this paper, we take a step
towards this goal by proposing physics-based guidance, which enables
optimization of a performance metric (as predicted by a surrogate model) during
the generation process. As a proof-of-concept, we add drag guidance to Stable
Diffusion, which allows this tool to generate images of novel vehicles while
simultaneously minimizing their predicted drag coefficients.
</p></li>
</ul>

<h3>Title: Towards Better Certified Segmentation via Diffusion Models. (arXiv:2306.09949v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.09949">http://arxiv.org/abs/2306.09949</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.09949] Towards Better Certified Segmentation via Diffusion Models](http://arxiv.org/abs/2306.09949) #diffusion</code></li>
<li>Summary: <p>The robustness of image segmentation has been an important research topic in
the past few years as segmentation models have reached production-level
accuracy. However, like classification models, segmentation models can be
vulnerable to adversarial perturbations, which hinders their use in
critical-decision systems like healthcare or autonomous driving. Recently,
randomized smoothing has been proposed to certify segmentation predictions by
adding Gaussian noise to the input to obtain theoretical guarantees. However,
this method exhibits a trade-off between the amount of added noise and the
level of certification achieved. In this paper, we address the problem of
certifying segmentation prediction using a combination of randomized smoothing
and diffusion models. Our experiments show that combining randomized smoothing
and diffusion models significantly improves certified robustness, with results
indicating a mean improvement of 21 points in accuracy compared to previous
state-of-the-art methods on Pascal-Context and Cityscapes public datasets. Our
method is independent of the selected segmentation model and does not need any
additional specialized training procedure.
</p></li>
</ul>

<h2>noise learning</h2>
<h2>data-free</h2>
<h2>transformer</h2>
<h3>Title: EVOPOSE: A Recursive Transformer For 3D Human Pose Estimation With Kinematic Structure Priors. (arXiv:2306.09615v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.09615">http://arxiv.org/abs/2306.09615</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.09615] EVOPOSE: A Recursive Transformer For 3D Human Pose Estimation With Kinematic Structure Priors](http://arxiv.org/abs/2306.09615) #transformer</code></li>
<li>Summary: <p>Transformer is popular in recent 3D human pose estimation, which utilizes
long-term modeling to lift 2D keypoints into the 3D space. However, current
transformer-based methods do not fully exploit the prior knowledge of the human
skeleton provided by the kinematic structure. In this paper, we propose a novel
transformer-based model EvoPose to introduce the human body prior knowledge for
3D human pose estimation effectively. Specifically, a Structural Priors
Representation (SPR) module represents human priors as structural features
carrying rich body patterns, e.g. joint relationships. The structural features
are interacted with 2D pose sequences and help the model to achieve more
informative spatiotemporal features. Moreover, a Recursive Refinement (RR)
module is applied to refine the 3D pose outputs by utilizing estimated results
and further injects human priors simultaneously. Extensive experiments
demonstrate the effectiveness of EvoPose which achieves a new state of the art
on two most popular benchmarks, Human3.6M and MPI-INF-3DHP.
</p></li>
</ul>

<h3>Title: Building Blocks for a Complex-Valued Transformer Architecture. (arXiv:2306.09827v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.09827">http://arxiv.org/abs/2306.09827</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.09827] Building Blocks for a Complex-Valued Transformer Architecture](http://arxiv.org/abs/2306.09827) #transformer</code></li>
<li>Summary: <p>Most deep learning pipelines are built on real-valued operations to deal with
real-valued inputs such as images, speech or music signals. However, a lot of
applications naturally make use of complex-valued signals or images, such as
MRI or remote sensing. Additionally the Fourier transform of signals is
complex-valued and has numerous applications. We aim to make deep learning
directly applicable to these complex-valued signals without using projections
into $\mathbb{R}^2$. Thus we add to the recent developments of complex-valued
neural networks by presenting building blocks to transfer the transformer
architecture to the complex domain. We present multiple versions of a
complex-valued Scaled Dot-Product Attention mechanism as well as a
complex-valued layer normalization. We test on a classification and a sequence
generation task on the MusicNet dataset and show improved robustness to
overfitting while maintaining on-par performance when compared to the
real-valued transformer architecture.
</p></li>
</ul>

<h3>Title: ChatGPT for Suicide Risk Assessment on Social Media: Quantitative Evaluation of Model Performance, Potentials and Limitations. (arXiv:2306.09390v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.09390">http://arxiv.org/abs/2306.09390</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.09390] ChatGPT for Suicide Risk Assessment on Social Media: Quantitative Evaluation of Model Performance, Potentials and Limitations](http://arxiv.org/abs/2306.09390) #transformer</code></li>
<li>Summary: <p>This paper presents a novel framework for quantitatively evaluating the
interactive ChatGPT model in the context of suicidality assessment from social
media posts, utilizing the University of Maryland Reddit suicidality dataset.
We conduct a technical evaluation of ChatGPT's performance on this task using
Zero-Shot and Few-Shot experiments and compare its results with those of two
fine-tuned transformer-based models. Additionally, we investigate the impact of
different temperature parameters on ChatGPT's response generation and discuss
the optimal temperature based on the inconclusiveness rate of ChatGPT. Our
results indicate that while ChatGPT attains considerable accuracy in this task,
transformer-based models fine-tuned on human-annotated datasets exhibit
superior performance. Moreover, our analysis sheds light on how adjusting the
ChatGPT's hyperparameters can improve its ability to assist mental health
professionals in this critical task.
</p></li>
</ul>

<h3>Title: Block-State Transformer. (arXiv:2306.09539v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.09539">http://arxiv.org/abs/2306.09539</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.09539] Block-State Transformer](http://arxiv.org/abs/2306.09539) #transformer</code></li>
<li>Summary: <p>State space models (SSMs) have shown impressive results on tasks that require
modeling long-range dependencies and efficiently scale to long sequences owing
to their subquadratic runtime complexity. Originally designed for continuous
signals, SSMs have shown superior performance on a plethora of tasks, in vision
and audio; however, SSMs still lag Transformer performance in Language Modeling
tasks. In this work, we propose a hybrid layer named Block-State Transformer
(BST), that internally combines an SSM sublayer for long-range
contextualization, and a Block Transformer sublayer for short-term
representation of sequences. We study three different, and completely
parallelizable, variants that integrate SSMs and block-wise attention. We show
that our model outperforms similar Transformer-based architectures on language
modeling perplexity and generalizes to longer sequences. In addition, the
Block-State Transformer demonstrates more than tenfold increase in speed at the
layer level compared to the Block-Recurrent Transformer when model
parallelization is employed.
</p></li>
</ul>

<h3>Title: Revealing the impact of social circumstances on the selection of cancer therapy through natural language processing of social work notes. (arXiv:2306.09877v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.09877">http://arxiv.org/abs/2306.09877</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.09877] Revealing the impact of social circumstances on the selection of cancer therapy through natural language processing of social work notes](http://arxiv.org/abs/2306.09877) #transformer</code></li>
<li>Summary: <p>We aimed to investigate the impact of social circumstances on cancer therapy
selection using natural language processing to derive insights from social
worker documentation. We developed and employed a Bidirectional Encoder
Representations from Transformers (BERT) based approach, using a hierarchical
multi-step BERT model (BERT-MS) to predict the prescription of targeted cancer
therapy to patients based solely on documentation by clinical social workers.
Our corpus included free-text clinical social work notes, combined with
medication prescription information, for all patients treated for breast
cancer. We conducted a feature importance analysis to pinpoint the specific
social circumstances that impact cancer therapy selection. Using only social
work notes, we consistently predicted the administration of targeted therapies,
suggesting systematic differences in treatment selection exist due to
non-clinical factors. The UCSF-BERT model, pretrained on clinical text at UCSF,
outperformed other publicly available language models with an AUROC of 0.675
and a Macro F1 score of 0.599. The UCSF BERT-MS model, capable of leveraging
multiple pieces of notes, surpassed the UCSF-BERT model in both AUROC and
Macro-F1. Our feature importance analysis identified several clinically
intuitive social determinants of health (SDOH) that potentially contribute to
disparities in treatment. Our findings indicate that significant disparities
exist among breast cancer patients receiving different types of therapies based
on social determinants of health. Social work reports play a crucial role in
understanding these disparities in clinical decision-making.
</p></li>
</ul>

<h3>Title: TSMixer: Lightweight MLP-Mixer Model for Multivariate Time Series Forecasting. (arXiv:2306.09364v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.09364">http://arxiv.org/abs/2306.09364</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.09364] TSMixer: Lightweight MLP-Mixer Model for Multivariate Time Series Forecasting](http://arxiv.org/abs/2306.09364) #transformer</code></li>
<li>Summary: <p>Transformers have gained popularity in time series forecasting for their
ability to capture long-sequence interactions. However, their high memory and
computing requirements pose a critical bottleneck for long-term forecasting. To
address this, we propose TSMixer, a lightweight neural architecture exclusively
composed of multi-layer perceptron (MLP) modules. TSMixer is designed for
multivariate forecasting and representation learning on patched time series,
providing an efficient alternative to Transformers. Our model draws inspiration
from the success of MLP-Mixer models in computer vision. We demonstrate the
challenges involved in adapting Vision MLP-Mixer for time series and introduce
empirically validated components to enhance accuracy. This includes a novel
design paradigm of attaching online reconciliation heads to the MLP-Mixer
backbone, for explicitly modeling the time-series properties such as hierarchy
and channel-correlations. We also propose a Hybrid channel modeling approach to
effectively handle noisy channel interactions and generalization across diverse
datasets, a common challenge in existing patch channel-mixing methods.
Additionally, a simple gated attention mechanism is introduced in the backbone
to prioritize important features. By incorporating these lightweight
components, we significantly enhance the learning capability of simple MLP
structures, outperforming complex Transformer models with minimal computing
usage. Moreover, TSMixer's modular design enables compatibility with both
supervised and masked self-supervised learning methods, making it a promising
building block for time-series Foundation Models. TSMixer outperforms
state-of-the-art MLP and Transformer models in forecasting by a considerable
margin of 8-60%. It also outperforms the latest strong benchmarks of
Patch-Transformer models (by 1-2%) with a significant reduction in memory and
runtime (2-3X).
</p></li>
</ul>

<h3>Title: Understanding Parameter Sharing in Transformers. (arXiv:2306.09380v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.09380">http://arxiv.org/abs/2306.09380</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.09380] Understanding Parameter Sharing in Transformers](http://arxiv.org/abs/2306.09380) #transformer</code></li>
<li>Summary: <p>Parameter sharing has proven to be a parameter-efficient approach. Previous
work on Transformers has focused on sharing parameters in different layers,
which can improve the performance of models with limited parameters by
increasing model depth. In this paper, we study why this approach works from
two perspectives. First, increasing model depth makes the model more complex,
and we hypothesize that the reason is related to model complexity (referring to
FLOPs). Secondly, since each shared parameter will participate in the network
computation several times in forward propagation, its corresponding gradient
will have a different range of values from the original model, which will
affect the model convergence. Based on this, we hypothesize that training
convergence may also be one of the reasons. Through further analysis, we show
that the success of this approach can be largely attributed to better
convergence, with only a small part due to the increased model complexity.
Inspired by this, we tune the training hyperparameters related to model
convergence in a targeted manner. Experiments on 8 machine translation tasks
show that our model achieves competitive performance with only half the model
complexity of parameter sharing models.
</p></li>
</ul>

<h3>Title: Recurrent Memory Decision Transformer. (arXiv:2306.09459v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.09459">http://arxiv.org/abs/2306.09459</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.09459] Recurrent Memory Decision Transformer](http://arxiv.org/abs/2306.09459) #transformer</code></li>
<li>Summary: <p>Transformative models, originally developed for natural language problems,
have recently been widely used in offline reinforcement learning tasks. This is
due to the fact that the agent's history can be represented as a sequence, and
the whole task can be reduced to the sequence modeling task. However, the
quadratic complexity of the transformer operation limits the potential increase
in context. Therefore, to work with long sequences in a natural language,
different versions of the memory mechanism are used. In this paper, we propose
the Recurrent Memory Decision Transformer (RMDT), a model that uses a recurrent
memory mechanism for reinforcement learning problems. We conduct thorough
experiments on Atari games and MoJoCo control problems, and show that our
proposed model is significantly superior to its counterparts without the
recurrent memory mechanism on Atari games. We also carefully study the effect
of memory on the performance of the proposed model. These findings shed light
on the potential of incorporating recurrent memory mechanisms to improve the
performance of large-scale transformer models in offline reinforcement learning
tasks. The Recurrent Memory Decision Transformer code is publicly available in
repository \url{https://anonymous.4open.science/r/RMDT-4FE4}.
</p></li>
</ul>

<h3>Title: LabelBench: A Comprehensive Framework for Benchmarking Label-Efficient Learning. (arXiv:2306.09910v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.09910">http://arxiv.org/abs/2306.09910</a></li>
<li>Code URL: <a href="https://github.com/efficienttraining/labelbench">https://github.com/efficienttraining/labelbench</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2306.09910] LabelBench: A Comprehensive Framework for Benchmarking Label-Efficient Learning](http://arxiv.org/abs/2306.09910) #transformer</code></li>
<li>Summary: <p>Labeled data are critical to modern machine learning applications, but
obtaining labels can be expensive. To mitigate this cost, machine learning
methods, such as transfer learning, semi-supervised learning and active
learning, aim to be label-efficient: achieving high predictive performance from
relatively few labeled examples. While obtaining the best label-efficiency in
practice often requires combinations of these techniques, existing benchmark
and evaluation frameworks do not capture a concerted combination of all such
techniques. This paper addresses this deficiency by introducing LabelBench, a
new computationally-efficient framework for joint evaluation of multiple
label-efficient learning techniques. As an application of LabelBench, we
introduce a novel benchmark of state-of-the-art active learning methods in
combination with semi-supervised learning for fine-tuning pretrained vision
transformers. Our benchmark demonstrates better label-efficiencies than
previously reported in active learning. LabelBench's modular codebase is
open-sourced for the broader community to contribute label-efficient learning
methods and benchmarks. The repository can be found at:
https://github.com/EfficientTraining/LabelBench.
</p></li>
</ul>

<h2>generative</h2>
<h3>Title: Emergent Asymmetry of Precision and Recall for Measuring Fidelity and Diversity of Generative Models in High Dimensions. (arXiv:2306.09618v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.09618">http://arxiv.org/abs/2306.09618</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.09618] Emergent Asymmetry of Precision and Recall for Measuring Fidelity and Diversity of Generative Models in High Dimensions](http://arxiv.org/abs/2306.09618) #generative</code></li>
<li>Summary: <p>Precision and Recall are two prominent metrics of generative performance,
which were proposed to separately measure the fidelity and diversity of
generative models. Given their central role in comparing and improving
generative models, understanding their limitations are crucially important. To
that end, in this work, we identify a critical flaw in the common approximation
of these metrics using k-nearest-neighbors, namely, that the very
interpretations of fidelity and diversity that are assigned to Precision and
Recall can fail in high dimensions, resulting in very misleading conclusions.
Specifically, we empirically and theoretically show that as the number of
dimensions grows, two model distributions with supports at equal point-wise
distance from the support of the real distribution, can have vastly different
Precision and Recall regardless of their respective distributions, hence an
emergent asymmetry in high dimensions. Based on our theoretical insights, we
then provide simple yet effective modifications to these metrics to construct
symmetric metrics regardless of the number of dimensions. Finally, we provide
experiments on real-world datasets to illustrate that the identified flaw is
not merely a pathological case, and that our proposed metrics are effective in
alleviating its impact.
</p></li>
</ul>

<h3>Title: Structural Restricted Boltzmann Machine for image denoising and classification. (arXiv:2306.09628v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.09628">http://arxiv.org/abs/2306.09628</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.09628] Structural Restricted Boltzmann Machine for image denoising and classification](http://arxiv.org/abs/2306.09628) #generative</code></li>
<li>Summary: <p>Restricted Boltzmann Machines are generative models that consist of a layer
of hidden variables connected to another layer of visible units, and they are
used to model the distribution over visible variables. In order to gain a
higher representability power, many hidden units are commonly used, which, in
combination with a large number of visible units, leads to a high number of
trainable parameters. In this work we introduce the Structural Restricted
Boltzmann Machine model, which taking advantage of the structure of the data in
hand, constrains connections of hidden units to subsets of visible units in
order to reduce significantly the number of trainable parameters, without
compromising performance. As a possible area of application, we focus on image
modelling. Based on the nature of the images, the structure of the connections
is given in terms of spatial neighbourhoods over the pixels of the image that
constitute the visible variables of the model. We conduct extensive experiments
on various image domains. Image denoising is evaluated with corrupted images
from the MNIST dataset. The generative power of our models is compared to
vanilla RBMs, as well as their classification performance, which is assessed
with five different image domains. Results show that our proposed model has a
faster and more stable training, while also obtaining better results compared
to an RBM with no constrained connections between its visible and hidden units.
</p></li>
</ul>

<h3>Title: Understanding Deep Generative Models with Generalized Empirical Likelihoods. (arXiv:2306.09780v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.09780">http://arxiv.org/abs/2306.09780</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.09780] Understanding Deep Generative Models with Generalized Empirical Likelihoods](http://arxiv.org/abs/2306.09780) #generative</code></li>
<li>Summary: <p>Understanding how well a deep generative model captures a distribution of
high-dimensional data remains an important open challenge. It is especially
difficult for certain model classes, such as Generative Adversarial Networks
and Diffusion Models, whose models do not admit exact likelihoods. In this
work, we demonstrate that generalized empirical likelihood (GEL) methods offer
a family of diagnostic tools that can identify many deficiencies of deep
generative models (DGMs). We show, with appropriate specification of moment
conditions, that the proposed method can identify which modes have been
dropped, the degree to which DGMs are mode imbalanced, and whether DGMs
sufficiently capture intra-class diversity. We show how to combine techniques
from Maximum Mean Discrepancy and Generalized Empirical Likelihood to create
not only distribution tests that retain per-sample interpretability, but also
metrics that include label information. We find that such tests predict the
degree of mode dropping and mode imbalance up to 60% better than metrics such
as improved precision/recall.
</p></li>
</ul>

<h3>Title: Training generative models from privatized data. (arXiv:2306.09547v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.09547">http://arxiv.org/abs/2306.09547</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.09547] Training generative models from privatized data](http://arxiv.org/abs/2306.09547) #generative</code></li>
<li>Summary: <p>Local differential privacy (LDP) is a powerful method for privacy-preserving
data collection. In this paper, we develop a framework for training Generative
Adversarial Networks (GAN) on differentially privatized data. We show that
entropic regularization of the Wasserstein distance -- a popular regularization
method in the literature that has been often leveraged for its computational
benefits -- can be used to denoise the data distribution when data is
privatized by common additive noise mechanisms, such as Laplace and Gaussian.
This combination uniquely enables the mitigation of both the regularization
bias and the effects of privatization noise, thereby enhancing the overall
efficacy of the model. We analyse the proposed method, provide sample
complexity results and experimental evidence to support its efficacy.
</p></li>
</ul>

<h3>Title: A Hierarchical Bayesian Model for Deep Few-Shot Meta Learning. (arXiv:2306.09702v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.09702">http://arxiv.org/abs/2306.09702</a></li>
<li>Code URL: <a href="https://github.com/minyoungkim21/niwmeta">https://github.com/minyoungkim21/niwmeta</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2306.09702] A Hierarchical Bayesian Model for Deep Few-Shot Meta Learning](http://arxiv.org/abs/2306.09702) #generative</code></li>
<li>Summary: <p>We propose a novel hierarchical Bayesian model for learning with a large
(possibly infinite) number of tasks/episodes, which suits well the few-shot
meta learning problem. We consider episode-wise random variables to model
episode-specific target generative processes, where these local random
variables are governed by a higher-level global random variate. The global
variable helps memorize the important information from historic episodes while
controlling how much the model needs to be adapted to new episodes in a
principled Bayesian manner. Within our model framework, the prediction on a
novel episode/task can be seen as a Bayesian inference problem. However, a main
obstacle in learning with a large/infinite number of local random variables in
online nature, is that one is not allowed to store the posterior distribution
of the current local random variable for frequent future updates, typical in
conventional variational inference. We need to be able to treat each local
variable as a one-time iterate in the optimization. We propose a
Normal-Inverse-Wishart model, for which we show that this one-time iterate
optimization becomes feasible due to the approximate closed-form solutions for
the local posterior distributions. The resulting algorithm is more attractive
than the MAML in that it is not required to maintain computational graphs for
the whole gradient optimization steps per episode. Our approach is also
different from existing Bayesian meta learning methods in that unlike dealing
with a single random variable for the whole episodes, our approach has a
hierarchical structure that allows one-time episodic optimization, desirable
for principled Bayesian learning with many/infinite tasks. The code is
available at \url{https://github.com/minyoungkim21/niwmeta}.
</p></li>
</ul>

<h3>Title: Meta Generative Flow Networks with Personalization for Task-Specific Adaptation. (arXiv:2306.09742v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.09742">http://arxiv.org/abs/2306.09742</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.09742] Meta Generative Flow Networks with Personalization for Task-Specific Adaptation](http://arxiv.org/abs/2306.09742) #generative</code></li>
<li>Summary: <p>Multi-task reinforcement learning and meta-reinforcement learning have been
developed to quickly adapt to new tasks, but they tend to focus on tasks with
higher rewards and more frequent occurrences, leading to poor performance on
tasks with sparse rewards. To address this issue, GFlowNets can be integrated
into meta-learning algorithms (GFlowMeta) by leveraging the advantages of
GFlowNets on tasks with sparse rewards. However, GFlowMeta suffers from
performance degradation when encountering heterogeneous transitions from
distinct tasks. To overcome this challenge, this paper proposes a personalized
approach named pGFlowMeta, which combines task-specific personalized policies
with a meta policy. Each personalized policy balances the loss on its
personalized task and the difference from the meta policy, while the meta
policy aims to minimize the average loss of all tasks. The theoretical analysis
shows that the algorithm converges at a sublinear rate. Extensive experiments
demonstrate that the proposed algorithm outperforms state-of-the-art
reinforcement learning algorithms in discrete environments.
</p></li>
</ul>

<h2>large language model</h2>
<h3>Title: Explore, Establish, Exploit: Red Teaming Language Models from Scratch. (arXiv:2306.09442v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.09442">http://arxiv.org/abs/2306.09442</a></li>
<li>Code URL: <a href="https://github.com/thestephencasper/common_claim">https://github.com/thestephencasper/common_claim</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2306.09442] Explore, Establish, Exploit: Red Teaming Language Models from Scratch](http://arxiv.org/abs/2306.09442) #large language model</code></li>
<li>Summary: <p>Deploying Large language models (LLMs) can pose hazards from harmful outputs
such as toxic or dishonest speech. Prior work has introduced tools that elicit
harmful outputs in order to identify and mitigate these risks. While this is a
valuable step toward securing language models, these approaches typically rely
on a pre-existing classifier for undesired outputs. This limits their
application to situations where the type of harmful behavior is known with
precision beforehand. However, this skips a central challenge of red teaming:
developing a contextual understanding of the behaviors that a model can
exhibit. Furthermore, when such a classifier already exists, red teaming has
limited marginal value because the classifier could simply be used to filter
training data or model outputs. In this work, we consider red teaming under the
assumption that the adversary is working from a high-level, abstract
specification of undesired behavior. The red team is expected to refine/extend
this specification and identify methods to elicit this behavior from the model.
Our red teaming framework consists of three steps: 1) Exploring the model's
behavior in the desired context; 2) Establishing a measurement of undesired
behavior (e.g., a classifier trained to reflect human evaluations); and 3)
Exploiting the model's flaws using this measure and an established red teaming
methodology. We apply this approach to red team GPT-2 and GPT-3 models to
systematically discover classes of prompts that elicit toxic and dishonest
statements. In doing so, we also construct and release the CommonClaim dataset
of 20,000 statements that have been labeled by human subjects as
common-knowledge-true, common-knowledge-false, or neither. Code is available at
https://github.com/thestephencasper/explore_establish_exploit_llms. CommonClaim
is available at https://github.com/thestephencasper/common_claim.
</p></li>
</ul>

<h3>Title: Inverse Scaling: When Bigger Isn't Better. (arXiv:2306.09479v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.09479">http://arxiv.org/abs/2306.09479</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.09479] Inverse Scaling: When Bigger Isn't Better](http://arxiv.org/abs/2306.09479) #large language model</code></li>
<li>Summary: <p>Work on scaling laws has found that large language models (LMs) show
predictable improvements to overall loss with increased scale (model size,
training data, and compute). Here, we present evidence for the claim that LMs
may show inverse scaling, or worse task performance with increased scale, e.g.,
due to flaws in the training objective and data. We present empirical evidence
of inverse scaling on 11 datasets collected by running a public contest, the
Inverse Scaling Prize, with a substantial prize pool. Through analysis of the
datasets, along with other examples found in the literature, we identify four
potential causes of inverse scaling: (i) preference to repeat memorized
sequences over following in-context instructions, (ii) imitation of undesirable
patterns in the training data, (iii) tasks containing an easy distractor task
which LMs could focus on, rather than the harder real task, and (iv) correct
but misleading few-shot demonstrations of the task. We release the winning
datasets at https://inversescaling.com/data to allow for further investigation
of inverse scaling. Our tasks have helped drive the discovery of U-shaped and
inverted-U scaling trends, where an initial trend reverses, suggesting that
scaling trends are less reliable at predicting the behavior of larger-scale
models than previously understood. Overall, our results suggest that there are
tasks for which increased model scale alone may not lead to progress, and that
more careful thought needs to go into the data and objectives for training
language models.
</p></li>
</ul>

<h3>Title: Explaining Legal Concepts with Augmented Large Language Models (GPT-4). (arXiv:2306.09525v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.09525">http://arxiv.org/abs/2306.09525</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.09525] Explaining Legal Concepts with Augmented Large Language Models (GPT-4)](http://arxiv.org/abs/2306.09525) #large language model</code></li>
<li>Summary: <p>Interpreting the meaning of legal open-textured terms is a key task of legal
professionals. An important source for this interpretation is how the term was
applied in previous court cases. In this paper, we evaluate the performance of
GPT-4 in generating factually accurate, clear and relevant explanations of
terms in legislation. We compare the performance of a baseline setup, where
GPT-4 is directly asked to explain a legal term, to an augmented approach,
where a legal information retrieval module is used to provide relevant context
to the model, in the form of sentences from case law. We found that the direct
application of GPT-4 yields explanations that appear to be of very high quality
on their surface. However, detailed analysis uncovered limitations in terms of
the factual accuracy of the explanations. Further, we found that the
augmentation leads to improved quality, and appears to eliminate the issue of
hallucination, where models invent incorrect statements. These findings open
the door to the building of systems that can autonomously retrieve relevant
sentences from case law and condense them into a useful explanation for legal
scholars, educators or practicing lawyers alike.
</p></li>
</ul>

<h3>Title: Clickbait Detection via Large Language Models. (arXiv:2306.09597v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.09597">http://arxiv.org/abs/2306.09597</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.09597] Clickbait Detection via Large Language Models](http://arxiv.org/abs/2306.09597) #large language model</code></li>
<li>Summary: <p>Clickbait, which aims to induce users with some surprising and even thrilling
headlines for increasing click-through rates, permeates almost all online
content publishers, such as news portals and social media. Recently, Large
Language Models (LLMs) have emerged as a powerful instrument and achieved
tremendous success in a serious of NLP downstream tasks. However, it is not yet
known whether LLMs can be served as a high-quality clickbait detection system.
In this paper, we analyze the performance of LLMs in the few-shot scenarios on
a number of English and Chinese benchmark datasets. Experimental results show
that LLMs cannot achieve the best results compared to the state-of-the-art deep
and fine-tuning PLMs methods. Different from the human intuition, the
experiments demonstrated that LLMs cannot make satisfied clickbait detection
just by the headlines.
</p></li>
</ul>

<h3>Title: Full Parameter Fine-tuning for Large Language Models with Limited Resources. (arXiv:2306.09782v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.09782">http://arxiv.org/abs/2306.09782</a></li>
<li>Code URL: <a href="https://github.com/openlmlab/lomo">https://github.com/openlmlab/lomo</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2306.09782] Full Parameter Fine-tuning for Large Language Models with Limited Resources](http://arxiv.org/abs/2306.09782) #large language model</code></li>
<li>Summary: <p>Large Language Models (LLMs) have revolutionized Natural Language Processing
(NLP) but demand massive GPU resources for training. Lowering the threshold for
LLMs training would encourage greater participation from researchers,
benefiting both academia and society. While existing approaches have focused on
parameter-efficient fine-tuning, which tunes or adds a small number of
parameters, few have addressed the challenge of tuning the full parameters of
LLMs with limited resources. In this work, we propose a new optimizer,
LOw-Memory Optimization (LOMO), which fuses the gradient computation and the
parameter update in one step to reduce memory usage. By integrating LOMO with
existing memory saving techniques, we reduce memory usage to 10.8% compared to
the standard approach (DeepSpeed solution). Consequently, our approach enables
the full parameter fine-tuning of a 65B model on a single machine with 8 RTX
3090, each with 24GB memory.
</p></li>
</ul>

<h3>Title: Unlocking the Potential of User Feedback: Leveraging Large Language Model as User Simulator to Enhance Dialogue System. (arXiv:2306.09821v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.09821">http://arxiv.org/abs/2306.09821</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.09821] Unlocking the Potential of User Feedback: Leveraging Large Language Model as User Simulator to Enhance Dialogue System](http://arxiv.org/abs/2306.09821) #large language model</code></li>
<li>Summary: <p>Dialogue systems and large language models (LLMs) have gained considerable
attention. However, the direct utilization of LLMs as task-oriented dialogue
(TOD) models has been found to underperform compared to smaller task-specific
models. Nonetheless, it is crucial to acknowledge the significant potential of
LLMs and explore improved approaches for leveraging their impressive abilities.
Motivated by the goal of leveraging LLMs, we propose an alternative approach
called User-Guided Response Optimization (UGRO) to combine it with a smaller
TOD model. This approach uses LLM as annotation-free user simulator to assess
dialogue responses, combining them with smaller fine-tuned end-to-end TOD
models. By utilizing the satisfaction feedback generated by LLMs, UGRO further
optimizes the supervised fine-tuned TOD model. Specifically, the TOD model
takes the dialogue history as input and, with the assistance of the user
simulator's feedback, generates high-satisfaction responses that meet the
user's requirements. Through empirical experiments on two TOD benchmarks, we
validate the effectiveness of our method. The results demonstrate that our
approach outperforms previous state-of-the-art (SOTA) results.
</p></li>
</ul>

<h3>Title: Are Large Language Models Really Good Logical Reasoners? A Comprehensive Evaluation From Deductive, Inductive and Abductive Views. (arXiv:2306.09841v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.09841">http://arxiv.org/abs/2306.09841</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.09841] Are Large Language Models Really Good Logical Reasoners? A Comprehensive Evaluation From Deductive, Inductive and Abductive Views](http://arxiv.org/abs/2306.09841) #large language model</code></li>
<li>Summary: <p>Large Language Models (LLMs) have achieved great success in various natural
language tasks. It has aroused much interest in evaluating the specific
reasoning capability of LLMs, such as multilingual reasoning and mathematical
reasoning. However, as one of the key reasoning perspectives, logical reasoning
capability has not yet been thoroughly evaluated. In this work, we aim to
bridge those gaps and provide comprehensive evaluations. Firstly, to offer
systematic evaluations, this paper selects fifteen typical logical reasoning
datasets and organizes them into deductive, inductive, abductive and mixed-form
reasoning settings. Considering the comprehensiveness of evaluations, we
include three representative LLMs (i.e., text-davinci-003, ChatGPT and BARD)
and evaluate them on all selected datasets under zero-shot, one-shot and
three-shot settings. Secondly, different from previous evaluations relying only
on simple metrics (e.g., accuracy), we propose fine-level evaluations from
objective and subjective manners, covering both answers and explanations. Also,
to uncover the logical flaws of LLMs, bad cases will be attributed to five
error types from two dimensions. Thirdly, to avoid the influences of knowledge
bias and purely focus on benchmarking the logical reasoning capability of LLMs,
we propose a new dataset with neutral content. It contains 3K samples and
covers deductive, inductive and abductive reasoning settings. Based on the
in-depth evaluations, this paper finally concludes the ability maps of logical
reasoning capability from six dimensions (i.e., correct, rigorous, self-aware,
active, oriented and no hallucination). It reflects the pros and cons of LLMs
and gives guiding directions for future works.
</p></li>
</ul>

<h3>Title: ClinicalGPT: Large Language Models Finetuned with Diverse Medical Data and Comprehensive Evaluation. (arXiv:2306.09968v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.09968">http://arxiv.org/abs/2306.09968</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.09968] ClinicalGPT: Large Language Models Finetuned with Diverse Medical Data and Comprehensive Evaluation](http://arxiv.org/abs/2306.09968) #large language model</code></li>
<li>Summary: <p>Large language models have exhibited exceptional performance on various
Natural Language Processing (NLP) tasks, leveraging techniques such as the
pre-training, and instruction fine-tuning. Despite these advances, their
effectiveness in medical applications is limited, due to challenges such as
factual inaccuracies, reasoning abilities, and lack grounding in real-world
experience. In this study, we present ClinicalGPT, a language model explicitly
designed and optimized for clinical scenarios. By incorporating extensive and
diverse real-world data, such as medical records, domain-specific knowledge,
and multi-round dialogue consultations in the training process, ClinicalGPT is
better prepared to handle multiple clinical task. Furthermore, we introduce a
comprehensive evaluation framework that includes medical knowledge
question-answering, medical exams, patient consultations, and diagnostic
analysis of medical records. Our results demonstrate that ClinicalGPT
significantly outperforms other models in these tasks, highlighting the
effectiveness of our approach in adapting large language models to the critical
domain of healthcare.
</p></li>
</ul>

<h2>segmentation</h2>
<h3>Title: BN-DRISHTI: Bangla Document Recognition through Instance-level Segmentation of Handwritten Text Images. (arXiv:2306.09351v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.09351">http://arxiv.org/abs/2306.09351</a></li>
<li>Code URL: <a href="https://github.com/crusnic-corp/BN-DRISHTI">https://github.com/crusnic-corp/BN-DRISHTI</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2306.09351] BN-DRISHTI: Bangla Document Recognition through Instance-level Segmentation of Handwritten Text Images](http://arxiv.org/abs/2306.09351) #segmentation</code></li>
<li>Summary: <p>Handwriting recognition remains challenging for some of the most spoken
languages, like Bangla, due to the complexity of line and word segmentation
brought by the curvilinear nature of writing and lack of quality datasets. This
paper solves the segmentation problem by introducing a state-of-the-art method
(BN-DRISHTI) that combines a deep learning-based object detection framework
(YOLO) with Hough and Affine transformation for skew correction. However,
training deep learning models requires a massive amount of data. Thus, we also
present an extended version of the BN-HTRd dataset comprising 786 full-page
handwritten Bangla document images, line and word-level annotation for
segmentation, and corresponding ground truths for word recognition. Evaluation
on the test portion of our dataset resulted in an F-score of 99.97% for line
and 98% for word segmentation. For comparative analysis, we used three external
Bangla handwritten datasets, namely BanglaWriting, WBSUBNdb_text, and ICDAR
2013, where our system outperformed by a significant margin, further justifying
the performance of our approach on completely unseen samples.
</p></li>
</ul>

<h3>Title: SSL4EO-L: Datasets and Foundation Models for Landsat Imagery. (arXiv:2306.09424v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.09424">http://arxiv.org/abs/2306.09424</a></li>
<li>Code URL: <a href="https://github.com/microsoft/torchgeo">https://github.com/microsoft/torchgeo</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2306.09424] SSL4EO-L: Datasets and Foundation Models for Landsat Imagery](http://arxiv.org/abs/2306.09424) #segmentation</code></li>
<li>Summary: <p>The Landsat program is the longest-running Earth observation program in
history, with 50+ years of data acquisition by 8 satellites. The multispectral
imagery captured by sensors onboard these satellites is critical for a wide
range of scientific fields. Despite the increasing popularity of deep learning
and remote sensing, the majority of researchers still use decision trees and
random forests for Landsat image analysis due to the prevalence of small
labeled datasets and lack of foundation models. In this paper, we introduce
SSL4EO-L, the first ever dataset designed for Self-Supervised Learning for
Earth Observation for the Landsat family of satellites (including 3 sensors and
2 product levels) and the largest Landsat dataset in history (5M image
patches). Additionally, we modernize and re-release the L7 Irish and L8 Biome
cloud detection datasets, and introduce the first ML benchmark datasets for
Landsats 4-5 TM and Landsat 7 ETM+ SR. Finally, we pre-train the first
foundation models for Landsat imagery using SSL4EO-L and evaluate their
performance on multiple semantic segmentation tasks. All datasets and model
weights are available via the TorchGeo (https://github.com/microsoft/torchgeo)
library, making reproducibility and experimentation easy, and enabling
scientific advancements in the burgeoning field of remote sensing for a myriad
of downstream applications.
</p></li>
</ul>

<h3>Title: Echocardiography Segmentation Using Neural ODE-based Diffeomorphic Registration Field. (arXiv:2306.09687v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.09687">http://arxiv.org/abs/2306.09687</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.09687] Echocardiography Segmentation Using Neural ODE-based Diffeomorphic Registration Field](http://arxiv.org/abs/2306.09687) #segmentation</code></li>
<li>Summary: <p>Convolutional neural networks (CNNs) have recently proven their excellent
ability to segment 2D cardiac ultrasound images. However, the majority of
attempts to perform full-sequence segmentation of cardiac ultrasound videos
either rely on models trained only on keyframe images or fail to maintain the
topology over time. To address these issues, in this work, we consider
segmentation of ultrasound video as a registration estimation problem and
present a novel method for diffeomorphic image registration using neural
ordinary differential equations (Neural ODE). In particular, we consider the
registration field vector field between frames as a continuous trajectory ODE.
The estimated registration field is then applied to the segmentation mask of
the first frame to obtain a segment for the whole cardiac cycle. The proposed
method, Echo-ODE, introduces several key improvements compared to the previous
state-of-the-art. Firstly, by solving a continuous ODE, the proposed method
achieves smoother segmentation, preserving the topology of segmentation maps
over the whole sequence (Hausdorff distance: 3.7-4.4). Secondly, it maintains
temporal consistency between frames without explicitly optimizing for temporal
consistency attributes, achieving temporal consistency in 91% of the videos in
the dataset. Lastly, the proposed method is able to maintain the clinical
accuracy of the segmentation maps (MAE of the LVEF: 2.7-3.1). The results show
that our method surpasses the previous state-of-the-art in multiple aspects,
demonstrating the importance of spatial-temporal data processing for the
implementation of Neural ODEs in medical imaging applications. These findings
open up new research directions for solving echocardiography segmentation
tasks.
</p></li>
</ul>

<h3>Title: Squeezing nnU-Nets with Knowledge Distillation for On-Board Cloud Detection. (arXiv:2306.09886v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.09886">http://arxiv.org/abs/2306.09886</a></li>
<li>Code URL: <a href="https://gitlab.com/jnalepa/nnunets_for_clouds">https://gitlab.com/jnalepa/nnunets_for_clouds</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2306.09886] Squeezing nnU-Nets with Knowledge Distillation for On-Board Cloud Detection](http://arxiv.org/abs/2306.09886) #segmentation</code></li>
<li>Summary: <p>Cloud detection is a pivotal satellite image pre-processing step that can be
performed both on the ground and on board a satellite to tag useful images. In
the latter case, it can reduce the amount of data to downlink by pruning the
cloudy areas, or to make a satellite more autonomous through data-driven
acquisition re-scheduling. We approach this task with nnU-Nets, a
self-reconfigurable framework able to perform meta-learning of a segmentation
network over various datasets. Unfortunately, such models are commonly
memory-inefficient due to their (very) large architectures. To benefit from
them in on-board processing, we compress nnU-Nets with knowledge distillation
into much smaller and compact U-Nets. Our experiments, performed over
Sentinel-2 and Landsat-8 images revealed that nnU-Nets deliver state-of-the-art
performance without any manual design. Our approach was ranked within the top
7% best solutions (across 847 teams) in the On Cloud N: Cloud Cover Detection
Challenge, where we reached the Jaccard index of 0.882 over more than 10k
unseen Sentinel-2 images (the winners obtained 0.897, the baseline U-Net with
the ResNet-34 backbone: 0.817, and the classic Sentinel-2 image thresholding:
0.652). Finally, we showed that knowledge distillation enables to elaborate
dramatically smaller (almost 280x) U-Nets when compared to nnU-Nets while still
maintaining their segmentation capabilities.
</p></li>
</ul>

<h3>Title: Vehicle Occurrence-based Parking Space Detection. (arXiv:2306.09940v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.09940">http://arxiv.org/abs/2306.09940</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.09940] Vehicle Occurrence-based Parking Space Detection](http://arxiv.org/abs/2306.09940) #segmentation</code></li>
<li>Summary: <p>Smart-parking solutions use sensors, cameras, and data analysis to improve
parking efficiency and reduce traffic congestion. Computer vision-based methods
have been used extensively in recent years to tackle the problem of parking lot
management, but most of the works assume that the parking spots are manually
labeled, impacting the cost and feasibility of deployment. To fill this gap,
this work presents an automatic parking space detection method, which receives
a sequence of images of a parking lot and returns a list of coordinates
identifying the detected parking spaces. The proposed method employs instance
segmentation to identify cars and, using vehicle occurrence, generate a heat
map of parking spaces. The results using twelve different subsets from the
PKLot and CNRPark-EXT parking lot datasets show that the method achieved an
AP25 score up to 95.60\% and AP50 score up to 79.90\%.
</p></li>
</ul>

<h3>Title: PanoOcc: Unified Occupancy Representation for Camera-based 3D Panoptic Segmentation. (arXiv:2306.10013v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.10013">http://arxiv.org/abs/2306.10013</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.10013] PanoOcc: Unified Occupancy Representation for Camera-based 3D Panoptic Segmentation](http://arxiv.org/abs/2306.10013) #segmentation</code></li>
<li>Summary: <p>Comprehensive modeling of the surrounding 3D world is key to the success of
autonomous driving. However, existing perception tasks like object detection,
road structure segmentation, depth &amp; elevation estimation, and open-set object
localization each only focus on a small facet of the holistic 3D scene
understanding task. This divide-and-conquer strategy simplifies the algorithm
development procedure at the cost of losing an end-to-end unified solution to
the problem. In this work, we address this limitation by studying camera-based
3D panoptic segmentation, aiming to achieve a unified occupancy representation
for camera-only 3D scene understanding. To achieve this, we introduce a novel
method called PanoOcc, which utilizes voxel queries to aggregate spatiotemporal
information from multi-frame and multi-view images in a coarse-to-fine scheme,
integrating feature learning and scene representation into a unified occupancy
representation. We have conducted extensive ablation studies to verify the
effectiveness and efficiency of the proposed method. Our approach achieves new
state-of-the-art results for camera-based semantic segmentation and panoptic
segmentation on the nuScenes dataset. Furthermore, our method can be easily
extended to dense occupancy prediction and has shown promising performance on
the Occ3D benchmark. The code will be released at
https://github.com/Robertwyq/PanoOcc.
</p></li>
</ul>

<button id="copy">Copy All</button>
</article>
<script src="https://cdn.staticfile.org/clipboard.js/2.0.4/clipboard.min.js"></script>
<script src="../../javascript/clipboard.js"></script>
