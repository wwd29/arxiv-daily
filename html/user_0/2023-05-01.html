<link rel="stylesheet" href="../../css/markdown.css" />
<article class="markdown-body">
<h2>secure</h2>
<h3>Title: Greybox Penetration Testing on Cloud Access Control with IAM Modeling and Deep Reinforcement Learning. (arXiv:2304.14540v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2304.14540">http://arxiv.org/abs/2304.14540</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2304.14540] Greybox Penetration Testing on Cloud Access Control with IAM Modeling and Deep Reinforcement Learning](http://arxiv.org/abs/2304.14540) #secure</code></li>
<li>Summary: <p>Identity and Access Management (IAM) is an access control service in cloud
platforms. To securely manage cloud resources, customers are required to
configure IAM to specify the access control rules for their cloud
organizations. However, IAM misconfiguration may be exploited to perform
privilege escalation attacks, which can cause severe economic loss. To detect
privilege escalations due to IAM misconfigurations, existing third-party cloud
security services apply whitebox penetration testing techniques, which require
the access of complete IAM configurations. This requirement might cause
problems such as information disclosure and anonymization.
</p></li>
</ul>

<p>To mitigate the limitation, we propose a greybox penetration testing approach
called TAC for third-party services to detect IAM privilege escalations,
without requiring the access of complete IAM configurations. The idea is to
intelligently query a limited amount of information that is only related to IAM
privilege escalation detection. Cloud customers are allowed to specify which
entities such as users and services (automatically anonymized by TAC) in their
IAM configurations can be queried, and also limit the maximum number of
queries. To realize the idea, we 1) propose abstract IAM modeling to detect IAM
privilege escalations based on the collected partial information; 2) apply
Reinforcement Learning (RL) with Graph Neural Networks (GNNs) to learn to make
as few queries as possible. To pretrain and evaluate TAC with enough diverse
tasks, we propose an IAM privilege escalation task generator called IAMVulGen.
Experimental results show that TAC detects IAM privilege escalations with
significantly lower false negative rates than baselines with high query
efficiency, on both our task set and the only publicly available privilege
escalation task set called IAM Vulnerable.
</p>

<h3>Title: LNMesh: Who Said You need Internet to send Bitcoin? Offline Lightning Network Payments using Community Wireless Mesh Networks. (arXiv:2304.14559v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2304.14559">http://arxiv.org/abs/2304.14559</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2304.14559] LNMesh: Who Said You need Internet to send Bitcoin? Offline Lightning Network Payments using Community Wireless Mesh Networks](http://arxiv.org/abs/2304.14559) #secure</code></li>
<li>Summary: <p>Bitcoin is undoubtedly a great alternative to today's existing digital
payment systems. Even though Bitcoin's scalability has been debated for a long
time, we see that it is no longer a concern thanks to its layer-2 solution
Lightning Network (LN). LN has been growing non-stop since its creation and
enabled fast, cheap, anonymous, censorship-resistant Bitcoin transactions.
However, as known, LN nodes need an active Internet connection to operate
securely which may not be always possible. For example, in the aftermath of
natural disasters or power outages, users may not have Internet access for a
while. Thus, in this paper, we propose LNMesh which enables offline LN payments
on top of wireless mesh networks. Users of a neighborhood or a community can
establish a wireless mesh network to use it as an infrastructure to enable
offline LN payments when they do not have any Internet connection. As such, we
first present proof-of-concept implementations where we successfully perform
offline LN payments utilizing Bluetooth Low Energy and WiFi. For larger
networks with more users where users can also move around, channel assignments
in the network need to be made strategically and thus, we propose 1) minimum
connected dominating set; and 2) uniform spanning tree based channel assignment
approaches. Finally, to test these approaches, we implemented a simulator in
Python along with the support of BonnMotion mobility tool. We then extensively
tested the performance metrics of large-scale realistic offline LN payments on
mobile wireless mesh networks. Our simulation results show that, success rates
up to %95 are achievable with the proposed channel assignment approaches when
channels have enough liquidity.
</p></li>
</ul>

<h3>Title: Secure and Private Vickrey Auction Protocols: A Secure Multiparty Computation Approach. (arXiv:2304.14626v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2304.14626">http://arxiv.org/abs/2304.14626</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2304.14626] Secure and Private Vickrey Auction Protocols: A Secure Multiparty Computation Approach](http://arxiv.org/abs/2304.14626) #secure</code></li>
<li>Summary: <p>Recent attention on secure multiparty computation and blockchain technology
has garnered new interest in developing auction protocols in a decentralized
setting. In this paper, we propose a secure and private Vickrey auction
protocol that addresses the challenge of maintaining auction correctness while
preserving the confidentiality of bidders' information. Our protocol leverages
secure multiparty computation (SMPC) techniques that enable decentralized
computation of the final payment price without disclosing additional
information. The total computational complexity of our proposed protocol,
including preparation, is $O(n^2 k)$, and the complexity for the main auction
is $O(n k)$. Furthermore, we show that our protocol is resistant to collusion
and the auction outcome is publicly verifiable, which prevents dishonest
bidders from altering this outcome.
</p></li>
</ul>

<h3>Title: faulTPM: Exposing AMD fTPMs' Deepest Secrets. (arXiv:2304.14717v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2304.14717">http://arxiv.org/abs/2304.14717</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2304.14717] faulTPM: Exposing AMD fTPMs' Deepest Secrets](http://arxiv.org/abs/2304.14717) #secure</code></li>
<li>Summary: <p>Trusted Platform Modules constitute an integral building block of modern
security features. Moreover, as Windows 11 made a TPM 2.0 mandatory, they are
subject to an ever-increasing academic challenge. While discrete TPMs - as
found in higher-end systems - have been susceptible to attacks on their exposed
communication interface, more common firmware TPMs (fTPMs) are immune to this
attack vector as they do not communicate with the CPU via an exposed bus. In
this paper, we analyze a new class of attacks against fTPMs: Attacking their
Trusted Execution Environment can lead to a full TPM state compromise. We
experimentally verify this attack by compromising the AMD Secure Processor,
which constitutes the TEE for AMD's fTPMs. In contrast to previous dTPM
sniffing attacks, this vulnerability exposes the complete internal TPM state of
the fTPM. It allows us to extract any cryptographic material stored or sealed
by the fTPM regardless of authentication mechanisms such as Platform
Configuration Register validation or passphrases with anti-hammering
protection. First, we demonstrate the impact of our findings by - to the best
of our knowledge - enabling the first attack against Full Disk Encryption
solutions backed by an fTPM. Furthermore, we lay out how any application
relying solely on the security properties of the TPM - like Bitlocker's TPM-
only protector - can be defeated by an attacker with 2-3 hours of physical
access to the target device. Lastly, we analyze the impact of our attack on FDE
solutions protected by a TPM and PIN strategy. While a naive implementation
also leaves the disk completely unprotected, we find that BitLocker's FDE
implementation withholds some protection depending on the complexity of the
used PIN. Our results show that when an fTPM's internal state is compromised, a
TPM and PIN strategy for FDE is less secure than TPM-less protection with a
reasonable passphrase.
</p></li>
</ul>

<h3>Title: Sensitive Tuning of Large Scale CNNs for E2E Secure Prediction using Homomorphic Encryption. (arXiv:2304.14836v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2304.14836">http://arxiv.org/abs/2304.14836</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2304.14836] Sensitive Tuning of Large Scale CNNs for E2E Secure Prediction using Homomorphic Encryption](http://arxiv.org/abs/2304.14836) #secure</code></li>
<li>Summary: <p>Privacy-preserving machine learning solutions have recently gained
significant attention. One promising research trend is using Homomorphic
Encryption (HE), a method for performing computation over encrypted data. One
major challenge in this approach is training HE-friendly, encrypted or
unencrypted, deep CNNs with decent accuracy. We propose a novel training method
for HE-friendly models, and demonstrate it on fundamental and modern CNNs, such
as ResNet and ConvNeXt. After training, we evaluate our models by running
encrypted samples using HELayers SDK and proving that they yield the desired
results. When running on a GPU over the ImageNet dataset, our ResNet-18/50/101
implementations take only 7, 31 and 57 minutes, respectively, which shows that
this solution is practical. Furthermore, we present several insights on
handling the activation functions and skip-connections under HE. Finally, we
demonstrate in an unprecedented way how to perform secure zero-shot prediction
using a CLIP model that we adapted to be HE-friendly.
</p></li>
</ul>

<h2>security</h2>
<h3>Title: Human activity recognition using deep learning approaches and single frame cnn and convolutional lstm. (arXiv:2304.14499v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2304.14499">http://arxiv.org/abs/2304.14499</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2304.14499] Human activity recognition using deep learning approaches and single frame cnn and convolutional lstm](http://arxiv.org/abs/2304.14499) #security</code></li>
<li>Summary: <p>Human activity recognition is one of the most important tasks in computer
vision and has proved useful in different fields such as healthcare, sports
training and security. There are a number of approaches that have been explored
to solve this task, some of them involving sensor data, and some involving
video data. In this paper, we aim to explore two deep learning-based
approaches, namely single frame Convolutional Neural Networks (CNNs) and
convolutional Long Short-Term Memory to recognise human actions from videos.
Using a convolutional neural networks-based method is advantageous as CNNs can
extract features automatically and Long Short-Term Memory networks are great
when it comes to working on sequence data such as video. The two models were
trained and evaluated on a benchmark action recognition dataset, UCF50, and
another dataset that was created for the experimentation. Though both models
exhibit good accuracies, the single frame CNN model outperforms the
Convolutional LSTM model by having an accuracy of 99.8% with the UCF50 dataset.
</p></li>
</ul>

<h3>Title: An Efficient Ensemble Explainable AI (XAI) Approach for Morphed Face Detection. (arXiv:2304.14509v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2304.14509">http://arxiv.org/abs/2304.14509</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2304.14509] An Efficient Ensemble Explainable AI (XAI) Approach for Morphed Face Detection](http://arxiv.org/abs/2304.14509) #security</code></li>
<li>Summary: <p>The extensive utilization of biometric authentication systems have emanated
attackers / imposters to forge user identity based on morphed images. In this
attack, a synthetic image is produced and merged with genuine. Next, the
resultant image is user for authentication. Numerous deep neural convolutional
architectures have been proposed in literature for face Morphing Attack
Detection (MADs) to prevent such attacks and lessen the risks associated with
them. Although, deep learning models achieved optimal results in terms of
performance, it is difficult to understand and analyse these networks since
they are black box/opaque in nature. As a consequence, incorrect judgments may
be made. There is, however, a dearth of literature that explains
decision-making methods of black box deep learning models for biometric
Presentation Attack Detection (PADs) or MADs that can aid the biometric
community to have trust in deep learning-based biometric systems for
identification and authentication in various security applications such as
border control, criminal database establishment etc. In this work, we present a
novel visual explanation approach named Ensemble XAI integrating Saliency maps,
Class Activation Maps (CAM) and Gradient-CAM (Grad-CAM) to provide a more
comprehensive visual explanation for a deep learning prognostic model
(EfficientNet-B1) that we have employed to predict whether the input presented
to a biometric authentication system is morphed or genuine. The
experimentations have been performed on three publicly available datasets
namely Face Research Lab London Set, Wide Multi-Channel Presentation Attack
(WMCA), and Makeup Induced Face Spoofing (MIFS). The experimental evaluations
affirms that the resultant visual explanations highlight more fine-grained
details of image features/areas focused by EfficientNet-B1 to reach decisions
along with appropriate reasoning.
</p></li>
</ul>

<h3>Title: Preserving Data Confidentiality in Association Rule Mining Using Data Share Allocator Algorithm. (arXiv:2304.14605v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2304.14605">http://arxiv.org/abs/2304.14605</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2304.14605] Preserving Data Confidentiality in Association Rule Mining Using Data Share Allocator Algorithm](http://arxiv.org/abs/2304.14605) #security</code></li>
<li>Summary: <p>These days, investigations of information are becoming essential for various
associations all over the globe. By and large, different associations need to
perform information examinations on their joined data sets. Privacy and
security have become a relentless concern wherein business experts do not
desire to contribute their classified transaction data. Therefore, there is a
requirement to build a proficient methodology that can process the broad
mixture of data and convert those data into meaningful knowledge for the user
without forfeiting the security and privacy of individuals crude information.
We devised two unique protocols for frequent mining itemsets in horizontally
partitioned datasets while maintaining privacy. In such a scenario, data
possessors outwork mining tasks on their multiparty data by preserving privacy.
The proposed framework model encompasses two or more data possessors who
encrypt their information and dispense their encrypted data to two or more
clouds by a data share allocator algorithm. This methodology protects the data
possessor raw data from other data possessors and the other clouds. To
guarantee data privacy, we plan a proficient enhanced homomorphic encryption
conspire. Our approach ensures privacy during communication and accumulation of
data and guarantees no information or data adversity and no incidental
consequences for data utility.
</p></li>
</ul>

<h3>Title: Effective Data Aggregation in WSN for Enhanced Security and Data Privacy. (arXiv:2304.14654v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2304.14654">http://arxiv.org/abs/2304.14654</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2304.14654] Effective Data Aggregation in WSN for Enhanced Security and Data Privacy](http://arxiv.org/abs/2304.14654) #security</code></li>
<li>Summary: <p>The two biggest problems with wireless sensor networks are security and
energy usage. In sensing devices, malicious nodes could be found in large
numbers. The researchers have proposed several methods to find these rogue
nodes. To prevent assaults on these networks and data transmission, the data
must be secured. Data aggregation aids in reducing the number of messages
transmitted within the network, which in turn lowers total network energy
consumption. Additionally, when decrypting the aggregated data, the base
station can distinguish between encrypted and consolidated analysis based on
top of the cryptographic keys. By examining the effectiveness of the data
aggregation in this research. To solve the above problem, the system provides a
method in which an efficient cluster agent is preferred pedestal on its
location at the access point and energy availability. The sensor network's
energy consumption is reduced by selecting an effective cluster agent,
extending the network's lifespan. The cluster's agent is in indict of compiling
data for each member node. The clustering agent validates the data and tosses
any errors before aggregation. The clustering agent only aggregates confirmed
data. To provide end-to-end anonymity, ElGamal elliptic curve (ECE) encryption
is used to secure the client data and reassign the encrypted information en
route for the cluster agent. Only the base station (BS) can decrypt the data.
Furthermore, an ID-based signature system is utilized to enable authenticity.
This research presents a technique for recuperating lost data. The access point
employs a cache-based backup system to search for lost data.
</p></li>
</ul>

<h3>Title: Zero Trust Chain A Design Pattern for Improved Interoperability and Security in Polkadot. (arXiv:2304.14730v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2304.14730">http://arxiv.org/abs/2304.14730</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2304.14730] Zero Trust Chain A Design Pattern for Improved Interoperability and Security in Polkadot](http://arxiv.org/abs/2304.14730) #security</code></li>
<li>Summary: <p>This research article presents various design patterns for improving
interoperability in Polkadot, a blockchain platform. These patterns include
chain bridges, interoperability standards, common asset identifiers, governance
agreements, oracle chains, and a hypothetical design pattern called Zero Trust
Chain. Implementation of these design patterns can help improve security and
confidence in transactions between different chains on the Polkadot network,
allowing for faster and more efficient communication. The article also
emphasizes the importance of interoperability in blockchain technology and
highlights Polkadot's flexibility in creating customized specialized chains
that can further improve interoperability on the network. Overall, this article
highlights how design patterns can improve interoperability in Polkadot, which
could lead to greater adoption of blockchain technology in various industries.
</p></li>
</ul>

<h3>Title: A Systematization of Cybersecurity Regulations, Standards and Guidelines for the Healthcare Sector. (arXiv:2304.14955v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2304.14955">http://arxiv.org/abs/2304.14955</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2304.14955] A Systematization of Cybersecurity Regulations, Standards and Guidelines for the Healthcare Sector](http://arxiv.org/abs/2304.14955) #security</code></li>
<li>Summary: <p>The growing adoption of IT solutions in the healthcare sector is leading to a
steady increase in the number of cybersecurity incidents. As a result,
organizations worldwide have introduced regulations, standards, and best
practices to address cybersecurity and data protection issues in this sector.
However, the application of this large corpus of documents presents operational
difficulties, and operators continue to lag behind in resilience to cyber
attacks. This paper contributes a systematization of the significant
cybersecurity documents relevant to the healthcare sector. We collected the 49
most significant documents and used the NIST cybersecurity framework to
categorize key information and support the implementation of cybersecurity
measures.
</p></li>
</ul>

<h2>privacy</h2>
<h3>Title: Non-Contact Heart Rate Measurement from Deteriorated Videos. (arXiv:2304.14789v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2304.14789">http://arxiv.org/abs/2304.14789</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2304.14789] Non-Contact Heart Rate Measurement from Deteriorated Videos](http://arxiv.org/abs/2304.14789) #privacy</code></li>
<li>Summary: <p>Remote photoplethysmography (rPPG) offers a state-of-the-art, non-contact
methodology for estimating human pulse by analyzing facial videos. Despite its
potential, rPPG methods can be susceptible to various artifacts, such as noise,
occlusions, and other obstructions caused by sunglasses, masks, or even
involuntary facial contact, such as individuals inadvertently touching their
faces. In this study, we apply image processing transformations to
intentionally degrade video quality, mimicking these challenging conditions,
and subsequently evaluate the performance of both non-learning and
learning-based rPPG methods on the deteriorated data. Our results reveal a
significant decrease in accuracy in the presence of these artifacts, prompting
us to propose the application of restoration techniques, such as denoising and
inpainting, to improve heart-rate estimation outcomes. By addressing these
challenging conditions and occlusion artifacts, our approach aims to make rPPG
methods more robust and adaptable to real-world situations. To assess the
effectiveness of our proposed methods, we undertake comprehensive experiments
on three publicly available datasets, encompassing a wide range of scenarios
and artifact types. Our findings underscore the potential to construct a robust
rPPG system by employing an optimal combination of restoration algorithms and
rPPG techniques. Moreover, our study contributes to the advancement of
privacy-conscious rPPG methodologies, thereby bolstering the overall utility
and impact of this innovative technology in the field of remote heart-rate
estimation under realistic and diverse conditions.
</p></li>
</ul>

<h3>Title: A Brief Study of Privacy-Preserving Practices (PPP) in Data Mining. (arXiv:2304.14607v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2304.14607">http://arxiv.org/abs/2304.14607</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2304.14607] A Brief Study of Privacy-Preserving Practices (PPP) in Data Mining](http://arxiv.org/abs/2304.14607) #privacy</code></li>
<li>Summary: <p>Data mining is the way toward mining fascinating patterns or information from
an enormous level of the database. Data mining additionally opens another risk
to privacy and data security.One of the maximum significant themes in the
research fieldis privacy-preserving DM (PPDM). Along these lines, the
investigation of ensuring delicate information and securing sensitive mined
snippets of data without yielding the utility of the information in a dispersed
domain.Extracted information from the analysis can be rules, clusters,
meaningful patterns, trends or classification models. Privacy breach occur at
some stage in the communication of data and aggregation of data. So far, many
effective methods and techniques have been developed for privacy-preserving
data mining, but yields into information loss and side effects on data utility
and data mining effectiveness downgraded. In the f ocal point of consideration
on the viability of Data Mining, Privacy and rightness should be improved and
to lessen the expense.
</p></li>
</ul>

<h3>Title: Hybrid Key Authentication Scheme for Privacy over Adhoc Communication. (arXiv:2304.14652v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2304.14652">http://arxiv.org/abs/2304.14652</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2304.14652] Hybrid Key Authentication Scheme for Privacy over Adhoc Communication](http://arxiv.org/abs/2304.14652) #privacy</code></li>
<li>Summary: <p>Since communication signals are publicly exposed while they transmit across
space, Ad Hoc Networks (MANETs) are where secured communication is most
crucial. Unfortunately, these systems are more open to intrusions that range
from passive listening to aggressive spying. A Hybrid Team centric Re-Key
Control Framework (HT-RCF) suggests that this research examines private group
communication in Adhoc environments. Each group selects a Group Manager to
oversee the group's members choose the group manager, and the suggested HT-RCF
uses the Improved Hybrid Power-Aware Decentralized (I-HPAD) mechanism. The Key
Distribution Center (KDC) generates the keys and distributes them to the group
managers (GMs) using the base algorithm Rivest Shamir Adleman (RSA). The key
agreement technique is investigated for safe user-user communication. Threats
that aim to exploit a node are recognized and stopped using regular
transmissions. The rekeying procedure is started every time a node enters and
exits the network. The research findings demonstrate that the suggested
approach outperforms the currently used Cluster-based Group Key Management in
terms of power use, privacy level, storage use, and processing time.
</p></li>
</ul>

<h3>Title: Trust Aware Privacy Preserving Routing Protocol for Wireless Adhoc Network. (arXiv:2304.14653v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2304.14653">http://arxiv.org/abs/2304.14653</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2304.14653] Trust Aware Privacy Preserving Routing Protocol for Wireless Adhoc Network](http://arxiv.org/abs/2304.14653) #privacy</code></li>
<li>Summary: <p>Wireless Ad-Hoc Networks are especially helpful and quite well for essential
circumstances such as defense, public safety, and disaster recovery. MANETs
require communication privacy and security, notably in core routing protocols,
when functioning in hostile or suspicious environments. The Trust Aware
Privacy-Preserving Protocol (TAP3) is a mechanism for supporting the origin in
proactively selecting a trust-able target and doing privacy-preserving route
verification. We suggest TAP3 using the fellow recommendation model for MANETs
in this work. Nodes use their features to discover their fellow node and use
the trust to create strong connections with the random node via a multi-hop
trusting chain by identifying the secure location. The verification duties are
then spread among the nodes and validate the log updates without exposing the
nodes' details. Unlike previous models that uncover node vulnerabilities or
misconduct after an attack, TAP3 may guarantee the origin node to prevent data
from being transferred through malicious nodes from the beginning and do
verification without needing a third party. Our results show that this approach
can locate problematic nodes with minimal overhead than the conventional
routing protocol.
</p></li>
</ul>

<h2>protect</h2>
<h2>defense</h2>
<h2>attack</h2>
<h3>Title: Fusion is Not Enough: Single-Modal Attacks to Compromise Fusion Models in Autonomous Driving. (arXiv:2304.14614v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2304.14614">http://arxiv.org/abs/2304.14614</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2304.14614] Fusion is Not Enough: Single-Modal Attacks to Compromise Fusion Models in Autonomous Driving](http://arxiv.org/abs/2304.14614) #attack</code></li>
<li>Summary: <p>Multi-sensor fusion (MSF) is widely adopted for perception in autonomous
vehicles (AVs), particularly for the task of 3D object detection with camera
and LiDAR sensors. The rationale behind fusion is to capitalize on the
strengths of each modality while mitigating their limitations. The exceptional
and leading performance of fusion models has been demonstrated by advanced deep
neural network (DNN)-based fusion techniques. Fusion models are also perceived
as more robust to attacks compared to single-modal ones due to the redundant
information in multiple modalities. In this work, we challenge this perspective
with single-modal attacks that targets the camera modality, which is considered
less significant in fusion but more affordable for attackers. We argue that the
weakest link of fusion models depends on their most vulnerable modality, and
propose an attack framework that targets advanced camera-LiDAR fusion models
with adversarial patches. Our approach employs a two-stage optimization-based
strategy that first comprehensively assesses vulnerable image areas under
adversarial attacks, and then applies customized attack strategies to different
fusion models, generating deployable patches. Evaluations with five
state-of-the-art camera-LiDAR fusion models on a real-world dataset show that
our attacks successfully compromise all models. Our approach can either reduce
the mean average precision (mAP) of detection performance from 0.824 to 0.353
or degrade the detection score of the target object from 0.727 to 0.151 on
average, demonstrating the effectiveness and practicality of our proposed
attack framework.
</p></li>
</ul>

<h3>Title: Machine Learning for Detection and Mitigation of Web Vulnerabilities and Web Attacks. (arXiv:2304.14451v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2304.14451">http://arxiv.org/abs/2304.14451</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2304.14451] Machine Learning for Detection and Mitigation of Web Vulnerabilities and Web Attacks](http://arxiv.org/abs/2304.14451) #attack</code></li>
<li>Summary: <p>Detection and mitigation of critical web vulnerabilities and attacks like
cross-site scripting (XSS), and cross-site request forgery (CSRF) have been a
great concern in the field of web security. Such web attacks are evolving and
becoming more challenging to detect. Several ideas from different perspectives
have been put forth that can be used to improve the performance of detecting
these web vulnerabilities and preventing the attacks from happening. Machine
learning techniques have lately been used by researchers to defend against XSS
and CSRF, and given the positive findings, it can be concluded that it is a
promising research direction. The objective of this paper is to briefly report
on the research works that have been published in this direction of applying
classical and advanced machine learning to identify and prevent XSS and CSRF.
The purpose of providing this survey is to address different machine learning
approaches that have been implemented, understand the key takeaway of every
research, discuss their positive impact and the downsides that persists, so
that it can help the researchers to determine the best direction to develop new
approaches for their own research and to encourage researchers to focus towards
the intersection between web security and machine learning.
</p></li>
</ul>

<h3>Title: ChatGPT as an Attack Tool: Stealthy Textual Backdoor Attack via Blackbox Generative Model Trigger. (arXiv:2304.14475v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2304.14475">http://arxiv.org/abs/2304.14475</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2304.14475] ChatGPT as an Attack Tool: Stealthy Textual Backdoor Attack via Blackbox Generative Model Trigger](http://arxiv.org/abs/2304.14475) #attack</code></li>
<li>Summary: <p>Textual backdoor attacks pose a practical threat to existing systems, as they
can compromise the model by inserting imperceptible triggers into inputs and
manipulating labels in the training dataset. With cutting-edge generative
models such as GPT-4 pushing rewriting to extraordinary levels, such attacks
are becoming even harder to detect. We conduct a comprehensive investigation of
the role of black-box generative models as a backdoor attack tool, highlighting
the importance of researching relative defense strategies. In this paper, we
reveal that the proposed generative model-based attack, BGMAttack, could
effectively deceive textual classifiers. Compared with the traditional attack
methods, BGMAttack makes the backdoor trigger less conspicuous by leveraging
state-of-the-art generative models. Our extensive evaluation of attack
effectiveness across five datasets, complemented by three distinct human
cognition assessments, reveals that Figure 4 achieves comparable attack
performance while maintaining superior stealthiness relative to baseline
methods.
</p></li>
</ul>

<h3>Title: Adversary Aware Continual Learning. (arXiv:2304.14483v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2304.14483">http://arxiv.org/abs/2304.14483</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2304.14483] Adversary Aware Continual Learning](http://arxiv.org/abs/2304.14483) #attack</code></li>
<li>Summary: <p>Class incremental learning approaches are useful as they help the model to
learn new information (classes) sequentially, while also retaining the
previously acquired information (classes). However, it has been shown that such
approaches are extremely vulnerable to the adversarial backdoor attacks, where
an intelligent adversary can introduce small amount of misinformation to the
model in the form of imperceptible backdoor pattern during training to cause
deliberate forgetting of a specific task or class at test time. In this work,
we propose a novel defensive framework to counter such an insidious attack
where, we use the attacker's primary strength-hiding the backdoor pattern by
making it imperceptible to humans-against it, and propose to learn a
perceptible (stronger) pattern (also during the training) that can overpower
the attacker's imperceptible (weaker) pattern. We demonstrate the effectiveness
of the proposed defensive mechanism through various commonly used Replay-based
(both generative and exact replay-based) class incremental learning algorithms
using continual learning benchmark variants of CIFAR-10, CIFAR-100, and MNIST
datasets. Most noteworthy, our proposed defensive framework does not assume
that the attacker's target task and target class is known to the defender. The
defender is also unaware of the shape, size, and location of the attacker's
pattern. We show that our proposed defensive framework considerably improves
the performance of class incremental learning algorithms with no knowledge of
the attacker's target task, attacker's target class, and attacker's
imperceptible pattern. We term our defensive framework as Adversary Aware
Continual Learning (AACL).
</p></li>
</ul>

<h3>Title: The Power of Typed Affine Decision Structures: A Case Study. (arXiv:2304.14888v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2304.14888">http://arxiv.org/abs/2304.14888</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2304.14888] The Power of Typed Affine Decision Structures: A Case Study](http://arxiv.org/abs/2304.14888) #attack</code></li>
<li>Summary: <p>TADS are a novel, concise white-box representation of neural networks. In
this paper, we apply TADS to the problem of neural network verification, using
them to generate either proofs or concise error characterizations for desirable
neural network properties. In a case study, we consider the robustness of
neural networks to adversarial attacks, i.e., small changes to an input that
drastically change a neural networks perception, and show that TADS can be used
to provide precise diagnostics on how and where robustness errors a occur. We
achieve these results by introducing Precondition Projection, a technique that
yields a TADS describing network behavior precisely on a given subset of its
input space, and combining it with PCA, a traditional, well-understood
dimensionality reduction technique. We show that PCA is easily compatible with
TADS. All analyses can be implemented in a straightforward fashion using the
rich algebraic properties of TADS, demonstrating the utility of the TADS
framework for neural network explainability and verification. While TADS do not
yet scale as efficiently as state-of-the-art neural network verifiers, we show
that, using PCA-based simplifications, they can still scale to mediumsized
problems and yield concise explanations for potential errors that can be used
for other purposes such as debugging a network or generating new training
samples.
</p></li>
</ul>

<h2>robust</h2>
<h3>Title: Unsupervised Learning of Robust Spectral Shape Matching. (arXiv:2304.14419v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2304.14419">http://arxiv.org/abs/2304.14419</a></li>
<li>Code URL: <a href="https://github.com/dongliangcao/unsupervised-learning-of-robust-spectral-shape-matching">https://github.com/dongliangcao/unsupervised-learning-of-robust-spectral-shape-matching</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2304.14419] Unsupervised Learning of Robust Spectral Shape Matching](http://arxiv.org/abs/2304.14419) #robust</code></li>
<li>Summary: <p>We propose a novel learning-based approach for robust 3D shape matching. Our
method builds upon deep functional maps and can be trained in a fully
unsupervised manner. Previous deep functional map methods mainly focus on
predicting optimised functional maps alone, and then rely on off-the-shelf
post-processing to obtain accurate point-wise maps during inference. However,
this two-stage procedure for obtaining point-wise maps often yields sub-optimal
performance. In contrast, building upon recent insights about the relation
between functional maps and point-wise maps, we propose a novel unsupervised
loss to couple the functional maps and point-wise maps, and thereby directly
obtain point-wise maps without any post-processing. Our approach obtains
accurate correspondences not only for near-isometric shapes, but also for more
challenging non-isometric shapes and partial shapes, as well as shapes with
different discretisation or topological noise. Using a total of nine diverse
datasets, we extensively evaluate the performance and demonstrate that our
method substantially outperforms previous state-of-the-art methods, even
compared to recent supervised methods. Our code is available at
https://github.com/dongliangcao/Unsupervised-Learning-of-Robust-Spectral-Shape-Matching.
</p></li>
</ul>

<h3>Title: Robust and Fast Vehicle Detection using Augmented Confidence Map. (arXiv:2304.14462v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2304.14462">http://arxiv.org/abs/2304.14462</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2304.14462] Robust and Fast Vehicle Detection using Augmented Confidence Map](http://arxiv.org/abs/2304.14462) #robust</code></li>
<li>Summary: <p>Vehicle detection in real-time scenarios is challenging because of the time
constraints and the presence of multiple types of vehicles with different
speeds, shapes, structures, etc. This paper presents a new method relied on
generating a confidence map-for robust and faster vehicle detection. To reduce
the adverse effect of different speeds, shapes, structures, and the presence of
several vehicles in a single image, we introduce the concept of augmentation
which highlights the region of interest containing the vehicles. The augmented
map is generated by exploring the combination of multiresolution analysis and
maximally stable extremal regions (MR-MSER). The output of MR-MSER is supplied
to fast CNN to generate a confidence map, which results in candidate regions.
Furthermore, unlike existing models that implement complicated models for
vehicle detection, we explore the combination of a rough set and fuzzy-based
models for robust vehicle detection. To show the effectiveness of the proposed
method, we conduct experiments on our dataset captured by drones and on several
vehicle detection benchmark datasets, namely, KITTI and UA-DETRAC. The results
on our dataset and the benchmark datasets show that the proposed method
outperforms the existing methods in terms of time efficiency and achieves a
good detection rate.
</p></li>
</ul>

<h3>Title: Enhancing Electrical Impedance Tomography reconstruction using Learned Half-Quadratic Splitting Networks with Anderson Acceleration. (arXiv:2304.14491v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2304.14491">http://arxiv.org/abs/2304.14491</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2304.14491] Enhancing Electrical Impedance Tomography reconstruction using Learned Half-Quadratic Splitting Networks with Anderson Acceleration](http://arxiv.org/abs/2304.14491) #robust</code></li>
<li>Summary: <p>Electrical Impedance Tomography (EIT) is widely applied in medical diagnosis,
industrial inspection, and environmental monitoring. Combining the physical
principles of the imaging system with the advantages of data-driven deep
learning networks, physics-embedded deep unrolling networks have recently
emerged as a promising solution in computational imaging. However, the inherent
nonlinear and ill-posed properties of EIT image reconstruction still present
challenges to existing methods in terms of accuracy and stability. To tackle
this challenge, we propose the learned half-quadratic splitting (HQSNet)
algorithm for incorporating physics into learning-based EIT imaging. We then
apply Anderson acceleration (AA) to the HQSNet algorithm, denoted as AA-HQSNet,
which can be interpreted as AA applied to the Gauss-Newton step and the learned
proximal gradient descent step of the HQSNet, respectively. AA is a widely-used
technique for accelerating the convergence of fixed-point iterative algorithms
and has gained significant interest in numerical optimization and machine
learning. However, the technique has received little attention in the inverse
problems community thus far. Employing AA enhances the convergence rate
compared to the standard HQSNet while simultaneously avoiding artifacts in the
reconstructions. Lastly, we conduct rigorous numerical and visual experiments
to show that the AA module strengthens the HQSNet, leading to robust, accurate,
and considerably superior reconstructions compared to state-of-the-art methods.
Our Anderson acceleration scheme to enhance HQSNet is generic and can be
applied to improve the performance of various physics-embedded deep learning
methods.
</p></li>
</ul>

<h3>Title: UHRNet: A Deep Learning-Based Method for Accurate 3D Reconstruction from a Single Fringe-Pattern. (arXiv:2304.14503v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2304.14503">http://arxiv.org/abs/2304.14503</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2304.14503] UHRNet: A Deep Learning-Based Method for Accurate 3D Reconstruction from a Single Fringe-Pattern](http://arxiv.org/abs/2304.14503) #robust</code></li>
<li>Summary: <p>The quick and accurate retrieval of an object height from a single fringe
pattern in Fringe Projection Profilometry has been a topic of ongoing research.
While a single shot fringe to depth CNN based method can restore height map
directly from a single pattern, its accuracy is currently inferior to the
traditional phase shifting technique. To improve this method's accuracy, we
propose using a U shaped High resolution Network (UHRNet). The network uses
UNet encoding and decoding structure as backbone, with Multi-Level convolution
Block and High resolution Fusion Block applied to extract local features and
global features. We also designed a compound loss function by combining
Structural Similarity Index Measure Loss (SSIMLoss) function and chunked L2
loss function to improve 3D reconstruction details.We conducted several
experiments to demonstrate the validity and robustness of our proposed method.
A few experiments have been conducted to demonstrate the validity and
robustness of the proposed method, The average RMSE of 3D reconstruction by our
method is only 0.443(mm). which is 41.13% of the UNet method and 33.31% of Wang
et al hNet method. Our experimental results show that our proposed method can
increase the accuracy of 3D reconstruction from a single fringe pattern.
</p></li>
</ul>

<h3>Title: Neural Implicit Dense Semantic SLAM. (arXiv:2304.14560v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2304.14560">http://arxiv.org/abs/2304.14560</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2304.14560] Neural Implicit Dense Semantic SLAM](http://arxiv.org/abs/2304.14560) #robust</code></li>
<li>Summary: <p>This paper presents an efficient online framework to solve the well-known
semantic Visual Simultaneous Localization and Mapping (V-SLAM) problem for
indoor scenes leveraging the advantages of neural implicit scene
representation. Existing methods on similar lines, such as NICE-SLAM, has some
critical practical limitations to put to use for such an important indoor scene
understanding problem. To this end, we contend for the following proposition
for modern semantic V-SLAM contrary to existing methods assuming RGB-D frames
as input (i) For a rigid scene, robust and accurate camera motion could be
computed with disentangled tracking and 3D mapping pipeline. (ii) Using neural
fields, a dense and multifaceted scene representation of SDF, semantics, RGB,
and depth is provided memory efficiently. (iii) Rather than using every frame,
we demonstrate that the set of keyframes is sufficient to learn excellent scene
representation, thereby improving the pipeline's train time. (iv) Multiple
local mapping networks could be used to extend the pipeline for large-scale
scenes. We show via extensive experiments on several popular benchmark datasets
that our approach offers accurate tracking, mapping, and semantic labeling at
test time even with noisy and highly sparse depth measurements. Later in the
paper, we show that our pipeline can easily extend to RGB image input. Overall,
the proposed pipeline offers a favorable solution to an important scene
understanding task that can assist in diverse robot visual perception and
related problems.
</p></li>
</ul>

<h3>Title: Improve Video Representation with Temporal Adversarial Augmentation. (arXiv:2304.14601v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2304.14601">http://arxiv.org/abs/2304.14601</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2304.14601] Improve Video Representation with Temporal Adversarial Augmentation](http://arxiv.org/abs/2304.14601) #robust</code></li>
<li>Summary: <p>Recent works reveal that adversarial augmentation benefits the generalization
of neural networks (NNs) if used in an appropriate manner. In this paper, we
introduce Temporal Adversarial Augmentation (TA), a novel video augmentation
technique that utilizes temporal attention. Unlike conventional adversarial
augmentation, TA is specifically designed to shift the attention distributions
of neural networks with respect to video clips by maximizing a temporal-related
loss function. We demonstrate that TA will obtain diverse temporal views, which
significantly affect the focus of neural networks. Training with these examples
remedies the flaw of unbalanced temporal information perception and enhances
the ability to defend against temporal shifts, ultimately leading to better
generalization. To leverage TA, we propose Temporal Video Adversarial
Fine-tuning (TAF) framework for improving video representations. TAF is a
model-agnostic, generic, and interpretability-friendly training strategy. We
evaluate TAF with four powerful models (TSM, GST, TAM, and TPN) over three
challenging temporal-related benchmarks (Something-something V1&amp;V2 and
diving48). Experimental results demonstrate that TAF effectively improves the
test accuracy of these models with notable margins without introducing
additional parameters or computational costs. As a byproduct, TAF also improves
the robustness under out-of-distribution (OOD) settings. Code is available at
https://github.com/jinhaoduan/TAF.
</p></li>
</ul>

<h3>Title: A positive feedback method based on F-measure value for Salient Object Detection. (arXiv:2304.14619v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2304.14619">http://arxiv.org/abs/2304.14619</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2304.14619] A positive feedback method based on F-measure value for Salient Object Detection](http://arxiv.org/abs/2304.14619) #robust</code></li>
<li>Summary: <p>The majority of current salient object detection (SOD) models are focused on
designing a series of decoders based on fully convolutional networks (FCNs) or
Transformer architectures and integrating them in a skillful manner. These
models have achieved remarkable high performance and made significant
contributions to the development of SOD. Their primary research objective is to
develop novel algorithms that can outperform state-of-the-art models, a task
that is extremely difficult and time-consuming. In contrast, this paper
proposes a positive feedback method based on F-measure value for SOD, aiming to
improve the accuracy of saliency prediction using existing methods.
Specifically, our proposed method takes an image to be detected and inputs it
into several existing models to obtain their respective prediction maps. These
prediction maps are then fed into our positive feedback method to generate the
final prediction result, without the need for careful decoder design or model
training. Moreover, our method is adaptive and can be implemented based on
existing models without any restrictions. Experimental results on five publicly
available datasets show that our proposed positive feedback method outperforms
the latest 12 methods in five evaluation metrics for saliency map prediction.
Additionally, we conducted a robustness experiment, which shows that when at
least one good prediction result exists in the selected existing model, our
proposed approach can ensure that the prediction result is not worse. Our
approach achieves a prediction speed of 20 frames per second (FPS) when
evaluated on a low configuration host and after removing the prediction time
overhead of inserted models. These results highlight the effectiveness,
efficiency, and robustness of our proposed approach for salient object
detection.
</p></li>
</ul>

<h3>Title: Quality-agnostic Image Captioning to Safely Assist People with Vision Impairment. (arXiv:2304.14623v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2304.14623">http://arxiv.org/abs/2304.14623</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2304.14623] Quality-agnostic Image Captioning to Safely Assist People with Vision Impairment](http://arxiv.org/abs/2304.14623) #robust</code></li>
<li>Summary: <p>Automated image captioning has the potential to be a useful tool for people
with vision impairments. Images taken by this user group are often noisy, which
leads to incorrect and even unsafe model predictions. In this paper, we propose
a quality-agnostic framework to improve the performance and robustness of image
captioning models for visually impaired people. We address this problem from
three angles: data, model, and evaluation. First, we show how data augmentation
techniques for generating synthetic noise can address data sparsity in this
domain. Second, we enhance the robustness of the model by expanding a
state-of-the-art model to a dual network architecture, using the augmented data
and leveraging different consistency losses. Our results demonstrate increased
performance, e.g. an absolute improvement of 2.15 on CIDEr, compared to
state-of-the-art image captioning networks, as well as increased robustness to
noise with up to 3 points improvement on CIDEr in more noisy settings. Finally,
we evaluate the prediction reliability using confidence calibration on images
with different difficulty/noise levels, showing that our models perform more
reliably in safety-critical situations. The improved model is part of an
assisted living application, which we develop in partnership with the Royal
National Institute of Blind People.
</p></li>
</ul>

<h3>Title: CVRecon: Rethinking 3D Geometric Feature Learning For Neural Reconstruction. (arXiv:2304.14633v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2304.14633">http://arxiv.org/abs/2304.14633</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2304.14633] CVRecon: Rethinking 3D Geometric Feature Learning For Neural Reconstruction](http://arxiv.org/abs/2304.14633) #robust</code></li>
<li>Summary: <p>Recent advances in neural reconstruction using posed image sequences have
made remarkable progress. However, due to the lack of depth information,
existing volumetric-based techniques simply duplicate 2D image features of the
object surface along the entire camera ray. We contend this duplication
introduces noise in empty and occluded spaces, posing challenges for producing
high-quality 3D geometry. Drawing inspiration from traditional multi-view
stereo methods, we propose an end-to-end 3D neural reconstruction framework
CVRecon, designed to exploit the rich geometric embedding in the cost volumes
to facilitate 3D geometric feature learning. Furthermore, we present
Ray-contextual Compensated Cost Volume (RCCV), a novel 3D geometric feature
representation that encodes view-dependent information with improved integrity
and robustness. Through comprehensive experiments, we demonstrate that our
approach significantly improves the reconstruction quality in various metrics
and recovers clear fine details of the 3D geometries. Our extensive ablation
studies provide insights into the development of effective 3D geometric feature
learning schemes. Project page: https://cvrecon.ziyue.cool/
</p></li>
</ul>

<h3>Title: Towards Robust Text-Prompted Semantic Criterion for In-the-Wild Video Quality Assessment. (arXiv:2304.14672v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2304.14672">http://arxiv.org/abs/2304.14672</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2304.14672] Towards Robust Text-Prompted Semantic Criterion for In-the-Wild Video Quality Assessment](http://arxiv.org/abs/2304.14672) #robust</code></li>
<li>Summary: <p>The proliferation of videos collected during in-the-wild natural settings has
pushed the development of effective Video Quality Assessment (VQA)
methodologies. Contemporary supervised opinion-driven VQA strategies
predominantly hinge on training from expensive human annotations for quality
scores, which limited the scale and distribution of VQA datasets and
consequently led to unsatisfactory generalization capacity of methods driven by
these data. On the other hand, although several handcrafted zero-shot quality
indices do not require training from human opinions, they are unable to account
for the semantics of videos, rendering them ineffective in comprehending
complex authentic distortions (e.g., white balance, exposure) and assessing the
quality of semantic content within videos. To address these challenges, we
introduce the text-prompted Semantic Affinity Quality Index (SAQI) and its
localized version (SAQI-Local) using Contrastive Language-Image Pre-training
(CLIP) to ascertain the affinity between textual prompts and visual features,
facilitating a comprehensive examination of semantic quality concerns without
the reliance on human quality annotations. By amalgamating SAQI with existing
low-level metrics, we propose the unified Blind Video Quality Index (BVQI) and
its improved version, BVQI-Local, which demonstrates unprecedented performance,
surpassing existing zero-shot indices by at least 24\% on all datasets.
Moreover, we devise an efficient fine-tuning scheme for BVQI-Local that jointly
optimizes text prompts and final fusion weights, resulting in state-of-the-art
performance and superior generalization ability in comparison to prevalent
opinion-driven VQA methods. We conduct comprehensive analyses to investigate
different quality concerns of distinct indices, demonstrating the effectiveness
and rationality of our design.
</p></li>
</ul>

<h3>Title: 3D shape reconstruction of semi-transparent worms. (arXiv:2304.14841v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2304.14841">http://arxiv.org/abs/2304.14841</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2304.14841] 3D shape reconstruction of semi-transparent worms](http://arxiv.org/abs/2304.14841) #robust</code></li>
<li>Summary: <p>3D shape reconstruction typically requires identifying object features or
textures in multiple images of a subject. This approach is not viable when the
subject is semi-transparent and moving in and out of focus. Here we overcome
these challenges by rendering a candidate shape with adaptive blurring and
transparency for comparison with the images. We use the microscopic nematode
Caenorhabditis elegans as a case study as it freely explores a 3D complex fluid
with constantly changing optical properties. We model the slender worm as a 3D
curve using an intrinsic parametrisation that naturally admits
biologically-informed constraints and regularisation. To account for the
changing optics we develop a novel differentiable renderer to construct images
from 2D projections and compare against raw images to generate a pixel-wise
error to jointly update the curve, camera and renderer parameters using
gradient descent. The method is robust to interference such as bubbles and dirt
trapped in the fluid, stays consistent through complex sequences of postures,
recovers reliable estimates from blurry images and provides a significant
improvement on previous attempts to track C. elegans in 3D. Our results
demonstrate the potential of direct approaches to shape estimation in complex
physical environments in the absence of ground-truth data.
</p></li>
</ul>

<h3>Title: SGAligner : 3D Scene Alignment with Scene Graphs. (arXiv:2304.14880v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2304.14880">http://arxiv.org/abs/2304.14880</a></li>
<li>Code URL: <a href="https://github.com/sayands/sgaligner">https://github.com/sayands/sgaligner</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2304.14880] SGAligner : 3D Scene Alignment with Scene Graphs](http://arxiv.org/abs/2304.14880) #robust</code></li>
<li>Summary: <p>Building 3D scene graphs has recently emerged as a topic in scene
representation for several embodied AI applications to represent the world in a
structured and rich manner. With their increased use in solving downstream
tasks (eg, navigation and room rearrangement), can we leverage and recycle them
for creating 3D maps of environments, a pivotal step in agent operation? We
focus on the fundamental problem of aligning pairs of 3D scene graphs whose
overlap can range from zero to partial and can contain arbitrary changes. We
propose SGAligner, the first method for aligning pairs of 3D scene graphs that
is robust to in-the-wild scenarios (ie, unknown overlap -- if any -- and
changes in the environment). We get inspired by multi-modality knowledge graphs
and use contrastive learning to learn a joint, multi-modal embedding space. We
evaluate on the 3RScan dataset and further showcase that our method can be used
for estimating the transformation between pairs of 3D scenes. Since benchmarks
for these tasks are missing, we create them on this dataset. The code,
benchmark, and trained models are available on the project website.
</p></li>
</ul>

<h3>Title: An Edge Assisted Robust Smart Traffic Management and Signalling System for Guiding Emergency Vehicles During Peak Hours. (arXiv:2304.14924v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2304.14924">http://arxiv.org/abs/2304.14924</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2304.14924] An Edge Assisted Robust Smart Traffic Management and Signalling System for Guiding Emergency Vehicles During Peak Hours](http://arxiv.org/abs/2304.14924) #robust</code></li>
<li>Summary: <p>Congestion in traffic is an unavoidable circumstance in many cities in India
and other countries. It is an issue of major concern. The steep rise in the
number of automobiles on the roads followed by old infrastructure, accidents,
pedestrian traffic, and traffic rule violations all add to challenging traffic
conditions. Given these poor conditions of traffic, there is a critical need
for automatically detecting and signaling systems. There are already various
technologies that are used for traffic management and signaling systems like
video analysis, infrared sensors, and wireless sensors. The main issue with
these methods is they are very costly and high maintenance is required. In this
paper, we have proposed a three-phase system that can guide emergency vehicles
and manage traffic based on the degree of congestion. In the first phase, the
system processes the captured images and calculates the Index value which is
used to discover the degree of congestion. The Index value of a particular road
depends on its width and the length up to which the camera captures images of
that road. We have to take input for the parameters (length and width) while
setting up the system. In the second phase, the system checks whether there are
any emergency vehicles present or not in any lane. In the third phase, the
whole processing and decision-making part is performed at the edge server. The
proposed model is robust and it takes into consideration adverse weather
conditions such as hazy, foggy, and windy. It works very efficiently in low
light conditions also. The edge server is a strategically placed server that
provides us with low latency and better connectivity. Using Edge technology in
this traffic management system reduces the strain on cloud servers and the
system becomes more reliable in real-time because the latency and bandwidth get
reduced due to processing at the intermediate edge server.
</p></li>
</ul>

<h3>Title: Contactless hand tremor amplitude measurement using smartphones: development and pilot evaluation. (arXiv:2304.14937v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2304.14937">http://arxiv.org/abs/2304.14937</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2304.14937] Contactless hand tremor amplitude measurement using smartphones: development and pilot evaluation](http://arxiv.org/abs/2304.14937) #robust</code></li>
<li>Summary: <p>Background: Physiological tremor is defined as an involuntary and rhythmic
shaking. Tremor of the hand is a key symptom of multiple neurological diseases,
and its frequency and amplitude differs according to both disease type and
disease progression. In routine clinical practice, tremor frequency and
amplitude are assessed by expert rating using a 0 to 4 integer scale. Such
ratings are subjective and have poor inter-rater reliability. There is thus a
clinical need for a practical and accurate method for objectively assessing
hand tremor.
</p></li>
</ul>

<p>Objective: to develop a proof of principle method to measure hand tremor
amplitude from smartphone videos.
</p>
<p>Methods: We created a computer vision pipeline that automatically extracts
salient points on the hand and produces a 1-D time series of movement due to
tremor, in pixels. Using the smartphones' depth measurement, we convert this
measure into real distance units. We assessed the accuracy of the method using
60 videos of simulated tremor of different amplitudes from two healthy adults.
Videos were taken at distances of 50, 75 and 100 cm between hand and camera.
The participants had skin tone II and VI on the Fitzpatrick scale. We compared
our method to a gold-standard measurement from a slide rule. Bland-Altman
methods agreement analysis indicated a bias of 0.04 cm and 95% limits of
agreement from -1.27 to 1.20 cm. Furthermore, we qualitatively observed that
the method was robust to differences in skin tone and limited occlusion, such
as a band-aid affixed to the participant's hand.
</p>
<p>Clinical relevance: We have demonstrated how tremor amplitude can be measured
from smartphone videos. In conjunction with tremor frequency, this approach
could be used to help diagnose and monitor neurological diseases
</p>

<h3>Title: Graph Neural Networks on Factor Graphs for Robust, Fast, and Scalable Linear State Estimation with PMUs. (arXiv:2304.14680v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2304.14680">http://arxiv.org/abs/2304.14680</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2304.14680] Graph Neural Networks on Factor Graphs for Robust, Fast, and Scalable Linear State Estimation with PMUs](http://arxiv.org/abs/2304.14680) #robust</code></li>
<li>Summary: <p>As phasor measurement units (PMUs) become more widely used in transmission
power systems, a fast state estimation (SE) algorithm that can take advantage
of their high sample rates is needed. To accomplish this, we present a method
that uses graph neural networks (GNNs) to learn complex bus voltage estimates
from PMU voltage and current measurements. We propose an original
implementation of GNNs over the power system's factor graph to simplify the
integration of various types and quantities of measurements on power system
buses and branches. Furthermore, we augment the factor graph to improve the
robustness of GNN predictions. This model is highly efficient and scalable, as
its computational complexity is linear with respect to the number of nodes in
the power system. Training and test examples were generated by randomly
sampling sets of power system measurements and annotated with the exact
solutions of linear SE with PMUs. The numerical results demonstrate that the
GNN model provides an accurate approximation of the SE solutions. Furthermore,
errors caused by PMU malfunctions or communication failures that would normally
make the SE problem unobservable have a local effect and do not deteriorate the
results in the rest of the power system.
</p></li>
</ul>

<h3>Title: A noise-robust acoustic method for recognition of foraging activities of grazing cattle. (arXiv:2304.14824v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2304.14824">http://arxiv.org/abs/2304.14824</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2304.14824] A noise-robust acoustic method for recognition of foraging activities of grazing cattle](http://arxiv.org/abs/2304.14824) #robust</code></li>
<li>Summary: <p>To stay competitive in the growing dairy market, farmers must continuously
improve their livestock production systems. Precision livestock farming
technologies provide individualised monitoring of animals on commercial farms,
optimising livestock production. Continuous acoustic monitoring is a widely
accepted sensing technique used to estimate the daily rumination and grazing
time budget of free-ranging cattle. However, typical environmental and natural
noises on pasture noticeably affect the performance and generalisation of
current acoustic methods. In this study, we present an acoustic method called
Noise-Robust Foraging Activity Recognizer (NRFAR). The proposed method
determines foraging activity bouts by analysing fixed-length segments of
identified jaw movement events associated with grazing and rumination. The
additive noise robustness of NRFAR was evaluated for several signal-to-noise
ratios, using stationary Gaussian white noise and four different non-stationary
natural noise sources. In noiseless conditions, NRFAR reaches an average
balanced accuracy of 89%, outperforming two previous acoustic methods by more
than 7%. Additionally, NRFAR presents better performance than previous acoustic
methods in 66 out of 80 evaluated noisy scenarios (p<0.01). NRFAR operates
online with a similar computational cost to previous acoustic methods. The
combination of these properties and the high performance in harsh free-ranging
environments render NRFAR an excellent choice for real-time implementation in a
low-power embedded device. The instrumentation and computational algorithms
presented within this publication are protected by a pending patent
application: AR P20220100910. Web demo available at:
https://sinc.unl.edu.ar/web-demo/nrfar
</p></li>
</ul>

<h2>biometric</h2>
<h2>steal</h2>
<h2>extraction</h2>
<h3>Title: CED: Catalog Extraction from Documents. (arXiv:2304.14662v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2304.14662">http://arxiv.org/abs/2304.14662</a></li>
<li>Code URL: <a href="https://github.com/spico197/catalogextraction">https://github.com/spico197/catalogextraction</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2304.14662] CED: Catalog Extraction from Documents](http://arxiv.org/abs/2304.14662) #extraction</code></li>
<li>Summary: <p>Sentence-by-sentence information extraction from long documents is an
exhausting and error-prone task. As the indicator of document skeleton,
catalogs naturally chunk documents into segments and provide informative
cascade semantics, which can help to reduce the search space. Despite their
usefulness, catalogs are hard to be extracted without the assist from external
knowledge. For documents that adhere to a specific template, regular
expressions are practical to extract catalogs. However, handcrafted heuristics
are not applicable when processing documents from different sources with
diverse formats. To address this problem, we build a large manually annotated
corpus, which is the first dataset for the Catalog Extraction from Documents
(CED) task. Based on this corpus, we propose a transition-based framework for
parsing documents into catalog trees. The experimental results demonstrate that
our proposed method outperforms baseline systems and shows a good ability to
transfer. We believe the CED task could fill the gap between raw text segments
and information extraction tasks on extremely long documents. Data and code are
available at \url{https://github.com/Spico197/CatalogExtraction}
</p></li>
</ul>

<h3>Title: Dissecting Recall of Factual Associations in Auto-Regressive Language Models. (arXiv:2304.14767v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2304.14767">http://arxiv.org/abs/2304.14767</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2304.14767] Dissecting Recall of Factual Associations in Auto-Regressive Language Models](http://arxiv.org/abs/2304.14767) #extraction</code></li>
<li>Summary: <p>Transformer-based language models (LMs) are known to capture factual
knowledge in their parameters. While previous work looked into where factual
associations are stored, only little is known about how they are retrieved
internally during inference. We investigate this question through the lens of
information flow. Given a subject-relation query, we study how the model
aggregates information about the subject and relation to predict the correct
attribute. With interventions on attention edges, we first identify two
critical points where information propagates to the prediction: one from the
relation positions followed by another from the subject positions. Next, by
analyzing the information at these points, we unveil a three-step internal
mechanism for attribute extraction. First, the representation at the
last-subject position goes through an enrichment process, driven by the early
MLP sublayers, to encode many subject-related attributes. Second, information
from the relation propagates to the prediction. Third, the prediction
representation "queries" the enriched subject to extract the attribute. Perhaps
surprisingly, this extraction is typically done via attention heads, which
often encode subject-attribute mappings in their parameters. Overall, our
findings introduce a comprehensive view of how factual associations are stored
and extracted internally in LMs, facilitating future research on knowledge
localization and editing.
</p></li>
</ul>

<h3>Title: RexUIE: A Recursive Method with Explicit Schema Instructor for Universal Information Extraction. (arXiv:2304.14770v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2304.14770">http://arxiv.org/abs/2304.14770</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2304.14770] RexUIE: A Recursive Method with Explicit Schema Instructor for Universal Information Extraction](http://arxiv.org/abs/2304.14770) #extraction</code></li>
<li>Summary: <p>Universal Information Extraction (UIE) is an area of interest due to the
challenges posed by varying targets, heterogeneous structures, and
demand-specific schemas. However, previous works have only achieved limited
success by unifying a few tasks, such as Named Entity Recognition (NER) and
Relation Extraction (RE), which fall short of being authentic UIE models
particularly when extracting other general schemas such as quadruples and
quintuples. Additionally, these models used an implicit structural schema
instructor, which could lead to incorrect links between types, hindering the
model's generalization and performance in low-resource scenarios. In this
paper, we redefine the authentic UIE with a formal formulation that encompasses
almost all extraction schemas. To the best of our knowledge, we are the first
to introduce UIE for any kind of schemas. In addition, we propose RexUIE, which
is a Recursive Method with Explicit Schema Instructor for UIE. To avoid
interference between different types, we reset the position ids and attention
mask matrices. RexUIE shows strong performance under both full-shot and
few-shot settings and achieves State-of-the-Art results on the tasks of
extracting complex schemas.
</p></li>
</ul>

<h3>Title: Information Redundancy and Biases in Public Document Information Extraction Benchmarks. (arXiv:2304.14936v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2304.14936">http://arxiv.org/abs/2304.14936</a></li>
<li>Code URL: <a href="https://github.com/seif-lat/bias-study-funsd-sroie">https://github.com/seif-lat/bias-study-funsd-sroie</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2304.14936] Information Redundancy and Biases in Public Document Information Extraction Benchmarks](http://arxiv.org/abs/2304.14936) #extraction</code></li>
<li>Summary: <p>Advances in the Visually-rich Document Understanding (VrDU) field and
particularly the Key-Information Extraction (KIE) task are marked with the
emergence of efficient Transformer-based approaches such as the LayoutLM
models. Despite the good performance of KIE models when fine-tuned on public
benchmarks, they still struggle to generalize on complex real-life use-cases
lacking sufficient document annotations. Our research highlighted that KIE
standard benchmarks such as SROIE and FUNSD contain significant similarity
between training and testing documents and can be adjusted to better evaluate
the generalization of models. In this work, we designed experiments to quantify
the information redundancy in public benchmarks, revealing a 75% template
replication in SROIE official test set and 16% in FUNSD. We also proposed
resampling strategies to provide benchmarks more representative of the
generalization ability of models. We showed that models not suited for document
analysis struggle on the adjusted splits dropping on average 10,5% F1 score on
SROIE and 3.5% on FUNSD compared to multi-modal models dropping only 7,5% F1 on
SROIE and 0.5% F1 on FUNSD.
</p></li>
</ul>

<h2>membership infer</h2>
<h2>federate</h2>
<h3>Title: Quality-Adaptive Split-Federated Learning for Segmenting Medical Images with Inaccurate Annotations. (arXiv:2304.14976v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2304.14976">http://arxiv.org/abs/2304.14976</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2304.14976] Quality-Adaptive Split-Federated Learning for Segmenting Medical Images with Inaccurate Annotations](http://arxiv.org/abs/2304.14976) #federate</code></li>
<li>Summary: <p>SplitFed Learning, a combination of Federated and Split Learning (FL and SL),
is one of the most recent developments in the decentralized machine learning
domain. In SplitFed learning, a model is trained by clients and a server
collaboratively. For image segmentation, labels are created at each client
independently and, therefore, are subject to clients' bias, inaccuracies, and
inconsistencies. In this paper, we propose a data quality-based adaptive
averaging strategy for SplitFed learning, called QA-SplitFed, to cope with the
variation of annotated ground truth (GT) quality over multiple clients. The
proposed method is compared against five state-of-the-art model averaging
methods on the task of learning human embryo image segmentation. Our
experiments show that all five baseline methods fail to maintain accuracy as
the number of corrupted clients increases. QA-SplitFed, however, copes
effectively with corruption as long as there is at least one uncorrupted
client.
</p></li>
</ul>

<h3>Title: Client Recruitment for Federated Learning in ICU Length of Stay Prediction. (arXiv:2304.14663v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2304.14663">http://arxiv.org/abs/2304.14663</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2304.14663] Client Recruitment for Federated Learning in ICU Length of Stay Prediction](http://arxiv.org/abs/2304.14663) #federate</code></li>
<li>Summary: <p>Machine and deep learning methods for medical and healthcare applications
have shown significant progress and performance improvement in recent years.
These methods require vast amounts of training data which are available in the
medical sector, albeit decentralized. Medical institutions generate vast
amounts of data for which sharing and centralizing remains a challenge as the
result of data and privacy regulations. The federated learning technique is
well-suited to tackle these challenges. However, federated learning comes with
a new set of open problems related to communication overhead, efficient
parameter aggregation, client selection strategies and more. In this work, we
address the step prior to the initiation of a federated network for model
training, client recruitment. By intelligently recruiting clients,
communication overhead and overall cost of training can be reduced without
sacrificing predictive performance. Client recruitment aims at pre-excluding
potential clients from partaking in the federation based on a set of criteria
indicative of their eventual contributions to the federation. In this work, we
propose a client recruitment approach using only the output distribution and
sample size at the client site. We show how a subset of clients can be
recruited without sacrificing model performance whilst, at the same time,
significantly improving computation time. By applying the recruitment approach
to the training of federated models for accurate patient Length of Stay
prediction using data from 189 Intensive Care Units, we show how the models
trained in federations made up from recruited clients significantly outperform
federated models trained with the standard procedure in terms of predictive
power and training time.
</p></li>
</ul>

<h3>Title: Hyperparameter Optimization through Neural Network Partitioning. (arXiv:2304.14766v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2304.14766">http://arxiv.org/abs/2304.14766</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2304.14766] Hyperparameter Optimization through Neural Network Partitioning](http://arxiv.org/abs/2304.14766) #federate</code></li>
<li>Summary: <p>Well-tuned hyperparameters are crucial for obtaining good generalization
behavior in neural networks. They can enforce appropriate inductive biases,
regularize the model and improve performance -- especially in the presence of
limited data. In this work, we propose a simple and efficient way for
optimizing hyperparameters inspired by the marginal likelihood, an optimization
objective that requires no validation data. Our method partitions the training
data and a neural network model into $K$ data shards and parameter partitions,
respectively. Each partition is associated with and optimized only on specific
data shards. Combining these partitions into subnetworks allows us to define
the ``out-of-training-sample" loss of a subnetwork, i.e., the loss on data
shards unseen by the subnetwork, as the objective for hyperparameter
optimization. We demonstrate that we can apply this objective to optimize a
variety of different hyperparameters in a single training run while being
significantly computationally cheaper than alternative methods aiming to
optimize the marginal likelihood for neural networks. Lastly, we also focus on
optimizing hyperparameters in federated learning, where retraining and
cross-validation are particularly challenging.
</p></li>
</ul>

<h3>Title: Hierarchical and Decentralised Federated Learning. (arXiv:2304.14982v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2304.14982">http://arxiv.org/abs/2304.14982</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2304.14982] Hierarchical and Decentralised Federated Learning](http://arxiv.org/abs/2304.14982) #federate</code></li>
<li>Summary: <p>Federated learning has shown enormous promise as a way of training ML models
in distributed environments while reducing communication costs and protecting
data privacy. However, the rise of complex cyber-physical systems, such as the
Internet-of-Things, presents new challenges that are not met with traditional
FL methods. Hierarchical Federated Learning extends the traditional FL process
to enable more efficient model aggregation based on application needs or
characteristics of the deployment environment (e.g., resource capabilities
and/or network connectivity). It illustrates the benefits of balancing
processing across the cloud-edge continuum. Hierarchical Federated Learning is
likely to be a key enabler for a wide range of applications, such as smart
farming and smart energy management, as it can improve performance and reduce
costs, whilst also enabling FL workflows to be deployed in environments that
are not well-suited to traditional FL. Model aggregation algorithms, software
frameworks, and infrastructures will need to be designed and implemented to
make such solutions accessible to researchers and engineers across a growing
set of domains.
</p></li>
</ul>

<p>H-FL also introduces a number of new challenges. For instance, there are
implicit infrastructural challenges. There is also a trade-off between having
generalised models and personalised models. If there exist geographical
patterns for data (e.g., soil conditions in a smart farm likely are related to
the geography of the region itself), then it is crucial that models used
locally can consider their own locality in addition to a globally-learned
model. H-FL will be crucial to future FL solutions as it can aggregate and
distribute models at multiple levels to optimally serve the trade-off between
locality dependence and global anomaly robustness.
</p>

<h2>fair</h2>
<h2>interpretability</h2>
<h3>Title: MINN: Learning the dynamics of differential-algebraic equations and application to battery modeling. (arXiv:2304.14422v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2304.14422">http://arxiv.org/abs/2304.14422</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2304.14422] MINN: Learning the dynamics of differential-algebraic equations and application to battery modeling](http://arxiv.org/abs/2304.14422) #interpretability</code></li>
<li>Summary: <p>The concept of integrating physics-based and data-driven approaches has
become popular for modeling sustainable energy systems. However, the existing
literature mainly focuses on the data-driven surrogates generated to replace
physics-based models. These models often trade accuracy for speed but lack the
generalisability, adaptability, and interpretability inherent in physics-based
models, which are often indispensable in the modeling of real-world dynamic
systems for optimization and control purposes. In this work, we propose a novel
architecture for generating model-integrated neural networks (MINN) to allow
integration on the level of learning physics-based dynamics of the system. The
obtained hybrid model solves an unsettled research problem in control-oriented
modeling, i.e., how to obtain an optimally simplified model that is physically
insightful, numerically accurate, and computationally tractable simultaneously.
We apply the proposed neural network architecture to model the electrochemical
dynamics of lithium-ion batteries and show that MINN is extremely
data-efficient to train while being sufficiently generalizable to previously
unseen input data, owing to its underlying physical invariants. The MINN
battery model has an accuracy comparable to the first principle-based model in
predicting both the system outputs and any locally distributed electrochemical
behaviors but achieves two orders of magnitude reduction in the solution time.
</p></li>
</ul>

<h3>Title: Towards Automated Circuit Discovery for Mechanistic Interpretability. (arXiv:2304.14997v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2304.14997">http://arxiv.org/abs/2304.14997</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2304.14997] Towards Automated Circuit Discovery for Mechanistic Interpretability](http://arxiv.org/abs/2304.14997) #interpretability</code></li>
<li>Summary: <p>Recent work in mechanistic interpretability has reverse-engineered nontrivial
behaviors of transformer models. These contributions required considerable
effort and researcher intuition, which makes it difficult to apply the same
methods to understand the complex behavior that current models display. At
their core however, the workflow for these discoveries is surprisingly similar.
Researchers create a data set and metric that elicit the desired model
behavior, subdivide the network into appropriate abstract units, replace
activations of those units to identify which are involved in the behavior, and
then interpret the functions that these units implement. By varying the data
set, metric, and units under investigation, researchers can understand the
functionality of each neural network region and the circuits they compose. This
work proposes a novel algorithm, Automatic Circuit DisCovery (ACDC), to
automate the identification of the important units in the network. Given a
model's computational graph, ACDC finds subgraphs that explain a behavior of
the model. ACDC was able to reproduce a previously identified circuit for
Python docstrings in a small transformer, identifying 6/7 important attention
heads that compose up to 3 layers deep, while including 91% fewer the
connections.
</p></li>
</ul>

<h2>explainability</h2>
<h3>Title: Model Explainability in Physiological and Healthcare-based Neural Networks. (arXiv:2304.14495v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2304.14495">http://arxiv.org/abs/2304.14495</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2304.14495] Model Explainability in Physiological and Healthcare-based Neural Networks](http://arxiv.org/abs/2304.14495) #explainability</code></li>
<li>Summary: <p>The estimation and monitoring of SpO2 are crucial for assessing lung function
and treating chronic pulmonary diseases. The COVID-19 pandemic has highlighted
the importance of early detection of changes in SpO2, particularly in
asymptomatic patients with clinical deterioration. However, conventional SpO2
measurement methods rely on contact-based sensing, presenting the risk of
cross-contamination and complications in patients with impaired limb perfusion.
Additionally, pulse oximeters may not be available in marginalized communities
and undeveloped countries. To address these limitations and provide a more
comfortable and unobtrusive way to monitor SpO2, recent studies have
investigated SpO2 measurement using videos. However, measuring SpO2 using
cameras in a contactless way, particularly from smartphones, is challenging due
to weaker physiological signals and lower optical selectivity of smartphone
camera sensors. The system includes three main steps: 1) extraction of the
region of interest (ROI), which includes the palm and back of the hand, from
the smartphone-captured videos; 2) spatial averaging of the ROI to produce R,
G, and B time series; and 3) feeding the time series into an
optophysiology-inspired CNN for SpO2 estimation. Our proposed method can
provide a more efficient and accurate way to monitor SpO2 using videos captured
from consumer-grade smartphones, which can be especially useful in telehealth
and health screening settings.
</p></li>
</ul>

<h3>Title: Deep state-space modeling for explainable representation, analysis, and generation of professional human poses. (arXiv:2304.14502v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2304.14502">http://arxiv.org/abs/2304.14502</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2304.14502] Deep state-space modeling for explainable representation, analysis, and generation of professional human poses](http://arxiv.org/abs/2304.14502) #explainability</code></li>
<li>Summary: <p>The analysis of human movements has been extensively studied due to its wide
variety of practical applications. Nevertheless, the state-of-the-art still
faces scientific challenges while modeling human movements. Firstly, new models
that account for the stochasticity of human movement and the physical structure
of the human body are required to accurately predict the evolution of full-body
motion descriptors over time. Secondly, the explainability of existing deep
learning algorithms regarding their body posture predictions while generating
human movements still needs to be improved as they lack comprehensible
representations of human movement. This paper addresses these challenges by
introducing three novel approaches for creating explainable representations of
human movement. In this work, full-body movement is formulated as a state-space
model of a dynamic system whose parameters are estimated using deep learning
and statistical algorithms. The representations adhere to the structure of the
Gesture Operational Model (GOM), which describes movement through its spatial
and temporal assumptions. Two approaches correspond to deep state-space models
that apply nonlinear network parameterization to provide interpretable posture
predictions. The third method trains GOM representations using one-shot
training with Kalman Filters. This training strategy enables users to model
single movements and estimate their mathematical representation using
procedures that require less computational power than deep learning algorithms.
Ultimately, two applications of the generated representations are presented.
The first is for the accurate generation of human movements, and the second is
for body dexterity analysis of professional movements, where dynamic
associations between body joints and meaningful motion descriptors are
identified.
</p></li>
</ul>

<h2>watermark</h2>
<h2>diffusion</h2>
<h3>Title: Learning a Diffusion Prior for NeRFs. (arXiv:2304.14473v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2304.14473">http://arxiv.org/abs/2304.14473</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2304.14473] Learning a Diffusion Prior for NeRFs](http://arxiv.org/abs/2304.14473) #diffusion</code></li>
<li>Summary: <p>Neural Radiance Fields (NeRFs) have emerged as a powerful neural 3D
representation for objects and scenes derived from 2D data. Generating NeRFs,
however, remains difficult in many scenarios. For instance, training a NeRF
with only a small number of views as supervision remains challenging since it
is an under-constrained problem. In such settings, it calls for some inductive
prior to filter out bad local minima. One way to introduce such inductive
priors is to learn a generative model for NeRFs modeling a certain class of
scenes. In this paper, we propose to use a diffusion model to generate NeRFs
encoded on a regularized grid. We show that our model can sample realistic
NeRFs, while at the same time allowing conditional generations, given a certain
observation as guidance.
</p></li>
</ul>

<h3>Title: It is all about where you start: Text-to-image generation with seed selection. (arXiv:2304.14530v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2304.14530">http://arxiv.org/abs/2304.14530</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2304.14530] It is all about where you start: Text-to-image generation with seed selection](http://arxiv.org/abs/2304.14530) #diffusion</code></li>
<li>Summary: <p>Text-to-image diffusion models can synthesize a large variety of concepts in
new compositions and scenarios. However, they still struggle with generating
uncommon concepts, rare unusual combinations, or structured concepts like hand
palms. Their limitation is partly due to the long-tail nature of their training
data: web-crawled data sets are strongly unbalanced, causing models to
under-represent concepts from the tail of the distribution. Here we
characterize the effect of unbalanced training data on text-to-image models and
offer a remedy. We show that rare concepts can be correctly generated by
carefully selecting suitable generation seeds in the noise space, a technique
that we call SeedSelect. SeedSelect is efficient and does not require
retraining the diffusion model. We evaluate the benefit of SeedSelect on a
series of problems. First, in few-shot semantic data augmentation, where we
generate semantically correct images for few-shot and long-tail benchmarks. We
show classification improvement on all classes, both from the head and tail of
the training data of diffusion models. We further evaluate SeedSelect on
correcting images of hands, a well-known pitfall of current diffusion models,
and show that it improves hand generation substantially.
</p></li>
</ul>

<h3>Title: SceneGenie: Scene Graph Guided Diffusion Models for Image Synthesis. (arXiv:2304.14573v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2304.14573">http://arxiv.org/abs/2304.14573</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2304.14573] SceneGenie: Scene Graph Guided Diffusion Models for Image Synthesis](http://arxiv.org/abs/2304.14573) #diffusion</code></li>
<li>Summary: <p>Text-conditioned image generation has made significant progress in recent
years with generative adversarial networks and more recently, diffusion models.
While diffusion models conditioned on text prompts have produced impressive and
high-quality images, accurately representing complex text prompts such as the
number of instances of a specific object remains challenging.
</p></li>
</ul>

<p>To address this limitation, we propose a novel guidance approach for the
sampling process in the diffusion model that leverages bounding box and
segmentation map information at inference time without additional training
data. Through a novel loss in the sampling process, our approach guides the
model with semantic features from CLIP embeddings and enforces geometric
constraints, leading to high-resolution images that accurately represent the
scene. To obtain bounding box and segmentation map information, we structure
the text prompt as a scene graph and enrich the nodes with CLIP embeddings. Our
proposed model achieves state-of-the-art performance on two public benchmarks
for image generation from scene graphs, surpassing both scene graph to image
and text-based diffusion models in various metrics. Our results demonstrate the
effectiveness of incorporating bounding box and segmentation map guidance in
the diffusion model sampling process for more accurate text-to-image
generation.
</p>

<h3>Title: MUDiff: Unified Diffusion for Complete Molecule Generation. (arXiv:2304.14621v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2304.14621">http://arxiv.org/abs/2304.14621</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2304.14621] MUDiff: Unified Diffusion for Complete Molecule Generation](http://arxiv.org/abs/2304.14621) #diffusion</code></li>
<li>Summary: <p>We present a new model for generating molecular data by combining discrete
and continuous diffusion processes. Our model generates a comprehensive
representation of molecules, including atom features, 2D discrete molecule
structures, and 3D continuous molecule coordinates. The use of diffusion
processes allows for capturing the probabilistic nature of molecular processes
and the ability to explore the effect of different factors on molecular
structures and properties. Additionally, we propose a novel graph transformer
architecture to denoise the diffusion process. The transformer is equivariant
to Euclidean transformations, allowing it to learn invariant atom and edge
representations while preserving the equivariance of atom coordinates. This
transformer can be used to learn molecular representations robust to geometric
transformations. We evaluate the performance of our model through experiments
and comparisons with existing methods, showing its ability to generate more
stable and valid molecules with good properties. Our model is a promising
approach for designing molecules with desired properties and can be applied to
a wide range of tasks in molecular modeling.
</p></li>
</ul>

<h2>noise learning</h2>
<h2>data-free</h2>
<h2>transformer</h2>
<h3>Title: SSTM: Spatiotemporal Recurrent Transformers for Multi-frame Optical Flow Estimation. (arXiv:2304.14418v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2304.14418">http://arxiv.org/abs/2304.14418</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2304.14418] SSTM: Spatiotemporal Recurrent Transformers for Multi-frame Optical Flow Estimation](http://arxiv.org/abs/2304.14418) #transformer</code></li>
<li>Summary: <p>Inaccurate optical flow estimates in and near occluded regions, and
out-of-boundary regions are two of the current significant limitations of
optical flow estimation algorithms. Recent state-of-the-art optical flow
estimation algorithms are two-frame based methods where optical flow is
estimated sequentially for each consecutive image pair in a sequence. While
this approach gives good flow estimates, it fails to generalize optical flows
in occluded regions mainly due to limited local evidence regarding moving
elements in a scene. In this work, we propose a learning-based multi-frame
optical flow estimation method that estimates two or more consecutive optical
flows in parallel from multi-frame image sequences. Our underlying hypothesis
is that by understanding temporal scene dynamics from longer sequences with
more than two frames, we can characterize pixel-wise dependencies in a larger
spatiotemporal domain, generalize complex motion patterns and thereby improve
the accuracy of optical flow estimates in occluded regions. We present
learning-based spatiotemporal recurrent transformers for multi-frame based
optical flow estimation (SSTMs). Our method utilizes 3D Convolutional Gated
Recurrent Units (3D-ConvGRUs) and spatiotemporal transformers to learn
recurrent space-time motion dynamics and global dependencies in the scene and
provide a generalized optical flow estimation. When compared with recent
state-of-the-art two-frame and multi-frame methods on real world and synthetic
datasets, performance of the SSTMs were significantly higher in occluded and
out-of-boundary regions. Among all published state-of-the-art multi-frame
methods, SSTM achieved state-of the-art results on the Sintel Final and
KITTI2015 benchmark datasets.
</p></li>
</ul>

<h3>Title: Local-Global Transformer Enhanced Unfolding Network for Pan-sharpening. (arXiv:2304.14612v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2304.14612">http://arxiv.org/abs/2304.14612</a></li>
<li>Code URL: <a href="https://github.com/lms-07/lgteun">https://github.com/lms-07/lgteun</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2304.14612] Local-Global Transformer Enhanced Unfolding Network for Pan-sharpening](http://arxiv.org/abs/2304.14612) #transformer</code></li>
<li>Summary: <p>Pan-sharpening aims to increase the spatial resolution of the low-resolution
multispectral (LrMS) image with the guidance of the corresponding panchromatic
(PAN) image. Although deep learning (DL)-based pan-sharpening methods have
achieved promising performance, most of them have a two-fold deficiency. For
one thing, the universally adopted black box principle limits the model
interpretability. For another thing, existing DL-based methods fail to
efficiently capture local and global dependencies at the same time, inevitably
limiting the overall performance. To address these mentioned issues, we first
formulate the degradation process of the high-resolution multispectral (HrMS)
image as a unified variational optimization problem, and alternately solve its
data and prior subproblems by the designed iterative proximal gradient descent
(PGD) algorithm. Moreover, we customize a Local-Global Transformer (LGT) to
simultaneously model local and global dependencies, and further formulate an
LGT-based prior module for image denoising. Besides the prior module, we also
design a lightweight data module. Finally, by serially integrating the data and
prior modules in each iterative stage, we unfold the iterative algorithm into a
stage-wise unfolding network, Local-Global Transformer Enhanced Unfolding
Network (LGTEUN), for the interpretable MS pan-sharpening. Comprehensive
experimental results on three satellite data sets demonstrate the effectiveness
and efficiency of LGTEUN compared with state-of-the-art (SOTA) methods. The
source code is available at https://github.com/lms-07/LGTEUN.
</p></li>
</ul>

<h3>Title: LostPaw: Finding Lost Pets using a Contrastive Learning-based Transformer with Visual Input. (arXiv:2304.14765v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2304.14765">http://arxiv.org/abs/2304.14765</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2304.14765] LostPaw: Finding Lost Pets using a Contrastive Learning-based Transformer with Visual Input](http://arxiv.org/abs/2304.14765) #transformer</code></li>
<li>Summary: <p>Losing pets can be highly distressing for pet owners, and finding a lost pet
is often challenging and time-consuming. An artificial intelligence-based
application can significantly improve the speed and accuracy of finding lost
pets. In order to facilitate such an application, this study introduces a
contrastive neural network model capable of accurately distinguishing between
images of pets. The model was trained on a large dataset of dog images and
evaluated through 3-fold cross-validation. Following 350 epochs of training,
the model achieved a test accuracy of 90%. Furthermore, overfitting was
avoided, as the test accuracy closely matched the training accuracy. Our
findings suggest that contrastive neural network models hold promise as a tool
for locating lost pets. This paper provides the foundation for a potential web
application that allows users to upload images of their missing pets, receiving
notifications when matching images are found in the application's image
database. This would enable pet owners to quickly and accurately locate lost
pets and reunite them with their families.
</p></li>
</ul>

<h3>Title: IMP: Iterative Matching and Pose Estimation with Adaptive Pooling. (arXiv:2304.14837v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2304.14837">http://arxiv.org/abs/2304.14837</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2304.14837] IMP: Iterative Matching and Pose Estimation with Adaptive Pooling](http://arxiv.org/abs/2304.14837) #transformer</code></li>
<li>Summary: <p>Previous methods solve feature matching and pose estimation using a two-stage
process by first finding matches and then estimating the pose. As they ignore
the geometric relationships between the two tasks, they focus on either
improving the quality of matches or filtering potential outliers, leading to
limited efficiency or accuracy. In contrast, we propose an iterative matching
and pose estimation framework (IMP) leveraging the geometric connections
between the two tasks: a few good matches are enough for a roughly accurate
pose estimation; a roughly accurate pose can be used to guide the matching by
providing geometric constraints. To this end, we implement a geometry-aware
recurrent attention-based module which jointly outputs sparse matches and
camera poses. Specifically, for each iteration, we first implicitly embed
geometric information into the module via a pose-consistency loss, allowing it
to predict geometry-aware matches progressively. Second, we introduce an
\textbf{e}fficient IMP, called EIMP, to dynamically discard keypoints without
potential matches, avoiding redundant updating and significantly reducing the
quadratic time complexity of attention computation in transformers. Experiments
on YFCC100m, Scannet, and Aachen Day-Night datasets demonstrate that the
proposed method outperforms previous approaches in terms of accuracy and
efficiency.
</p></li>
</ul>

<h3>Title: MASK-CNN-Transformer For Real-Time Multi-Label Weather Recognition. (arXiv:2304.14857v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2304.14857">http://arxiv.org/abs/2304.14857</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2304.14857] MASK-CNN-Transformer For Real-Time Multi-Label Weather Recognition](http://arxiv.org/abs/2304.14857) #transformer</code></li>
<li>Summary: <p>Weather recognition is an essential support for many practical life
applications, including traffic safety, environment, and meteorology. However,
many existing related works cannot comprehensively describe weather conditions
due to their complex co-occurrence dependencies. This paper proposes a novel
multi-label weather recognition model considering these dependencies. The
proposed model called MASK-Convolutional Neural Network-Transformer (MASK-CT)
is based on the Transformer, the convolutional process, and the MASK mechanism.
The model employs multiple convolutional layers to extract features from
weather images and a Transformer encoder to calculate the probability of each
weather condition based on the extracted features. To improve the
generalization ability of MASK-CT, a MASK mechanism is used during the training
phase. The effect of the MASK mechanism is explored and discussed. The Mask
mechanism randomly withholds some information from one-pair training instances
(one image and its corresponding label). There are two types of MASK methods.
Specifically, MASK-I is designed and deployed on the image before feeding it
into the weather feature extractor and MASK-II is applied to the image label.
The Transformer encoder is then utilized on the randomly masked image features
and labels. The experimental results from various real-world weather
recognition datasets demonstrate that the proposed MASK-CT model outperforms
state-of-the-art methods. Furthermore, the high-speed dynamic real-time weather
recognition capability of the MASK-CT is evaluated.
</p></li>
</ul>

<h3>Title: An Empirical Study of Multimodal Model Merging. (arXiv:2304.14933v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2304.14933">http://arxiv.org/abs/2304.14933</a></li>
<li>Code URL: <a href="https://github.com/ylsung/vl-merging">https://github.com/ylsung/vl-merging</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2304.14933] An Empirical Study of Multimodal Model Merging](http://arxiv.org/abs/2304.14933) #transformer</code></li>
<li>Summary: <p>Model merging (e.g., via interpolation or task arithmetic) fuses multiple
models trained on different tasks to generate a multi-task solution. The
technique has been proven successful in previous studies, where the models are
trained on similar tasks and with the same initialization. In this paper, we
expand on this concept to a multimodal setup by merging transformers trained on
different modalities. Furthermore, we conduct our study for a novel goal where
we can merge vision, language, and cross-modal transformers of a
modality-specific architecture to create a parameter-efficient
modality-agnostic architecture. Through comprehensive experiments, we
systematically investigate the key factors impacting model performance after
merging, including initialization, merging mechanisms, and model architectures.
Our analysis leads to an effective training recipe for matching the performance
of the modality-agnostic baseline (i.e. pre-trained from scratch) via model
merging. Our code is available at: https://github.com/ylsung/vl-merging
</p></li>
</ul>

<h3>Title: FlowTransformer: A Transformer Framework for Flow-based Network Intrusion Detection Systems. (arXiv:2304.14746v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2304.14746">http://arxiv.org/abs/2304.14746</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2304.14746] FlowTransformer: A Transformer Framework for Flow-based Network Intrusion Detection Systems](http://arxiv.org/abs/2304.14746) #transformer</code></li>
<li>Summary: <p>This paper presents the FlowTransformer framework, a novel approach for
implementing transformer-based Network Intrusion Detection Systems (NIDSs).
FlowTransformer leverages the strengths of transformer models in identifying
the long-term behaviour and characteristics of networks, which are often
overlooked by most existing NIDSs. By capturing these complex patterns in
network traffic, FlowTransformer offers a flexible and efficient tool for
researchers and practitioners in the cybersecurity community who are seeking to
implement NIDSs using transformer-based models. FlowTransformer allows the
direct substitution of various transformer components, including the input
encoding, transformer, classification head, and the evaluation of these across
any flow-based network dataset. To demonstrate the effectiveness and efficiency
of the FlowTransformer framework, we utilise it to provide an extensive
evaluation of various common transformer architectures, such as GPT 2.0 and
BERT, on three commonly used public NIDS benchmark datasets. We provide results
for accuracy, model size and speed. A key finding of our evaluation is that the
choice of classification head has the most significant impact on the model
performance. Surprisingly, Global Average Pooling, which is commonly used in
text classification, performs very poorly in the context of NIDS. In addition,
we show that model size can be reduced by over 50\%, and inference and training
times improved, with no loss of accuracy, by making specific choices of input
encoding and classification head instead of other commonly used alternatives.
</p></li>
</ul>

<h3>Title: ResiDual: Transformer with Dual Residual Connections. (arXiv:2304.14802v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2304.14802">http://arxiv.org/abs/2304.14802</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2304.14802] ResiDual: Transformer with Dual Residual Connections](http://arxiv.org/abs/2304.14802) #transformer</code></li>
<li>Summary: <p>Transformer networks have become the preferred architecture for many tasks
due to their state-of-the-art performance. However, the optimal way to
implement residual connections in Transformer, which are essential for
effective training, is still debated. Two widely used variants are the
Post-Layer-Normalization (Post-LN) and Pre-Layer-Normalization (Pre-LN)
Transformers, which apply layer normalization after each residual block's
output or before each residual block's input, respectively. While both variants
enjoy their advantages, they also suffer from severe limitations: Post-LN
causes gradient vanishing issue that hinders training deep Transformers, and
Pre-LN causes representation collapse issue that limits model capacity. In this
paper, we propose ResiDual, a novel Transformer architecture with Pre-Post-LN
(PPLN), which fuses the connections in Post-LN and Pre-LN together and inherits
their advantages while avoids their limitations. We conduct both theoretical
analyses and empirical experiments to verify the effectiveness of ResiDual.
Theoretically, we prove that ResiDual has a lower bound on the gradient to
avoid the vanishing issue due to the residual connection from Pre-LN. Moreover,
ResiDual also has diverse model representations to avoid the collapse issue due
to the residual connection from Post-LN. Empirically, ResiDual outperforms both
Post-LN and Pre-LN on several machine translation benchmarks across different
network depths and data sizes. Thanks to the good theoretical and empirical
performance, ResiDual Transformer can serve as a foundation architecture for
different AI models (e.g., large language models). Our code is available at
https://github.com/microsoft/ResiDual.
</p></li>
</ul>

<h3>Title: X-RLflow: Graph Reinforcement Learning for Neural Network Subgraphs Transformation. (arXiv:2304.14698v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2304.14698">http://arxiv.org/abs/2304.14698</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2304.14698] X-RLflow: Graph Reinforcement Learning for Neural Network Subgraphs Transformation](http://arxiv.org/abs/2304.14698) #transformer</code></li>
<li>Summary: <p>Tensor graph superoptimisation systems perform a sequence of subgraph
substitution to neural networks, to find the optimal computation graph
structure. Such a graph transformation process naturally falls into the
framework of sequential decision-making, and existing systems typically employ
a greedy search approach, which cannot explore the whole search space as it
cannot tolerate a temporary loss of performance. In this paper, we address the
tensor graph superoptimisation problem by exploring an alternative search
approach, reinforcement learning (RL). Our proposed approach, X-RLflow, can
learn to perform neural network dataflow graph rewriting, which substitutes a
subgraph one at a time. X-RLflow is based on a model-free RL agent that uses a
graph neural network (GNN) to encode the target computation graph and outputs a
transformed computation graph iteratively. We show that our approach can
outperform state-of-the-art superoptimisation systems over a range of deep
learning models and achieve by up to 40% on those that are based on
transformer-style architectures.
</p></li>
</ul>

<h2>generative</h2>
<h3>Title: Symmetry and Complexity in Object-Centric Deep Active Inference Models. (arXiv:2304.14493v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2304.14493">http://arxiv.org/abs/2304.14493</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2304.14493] Symmetry and Complexity in Object-Centric Deep Active Inference Models](http://arxiv.org/abs/2304.14493) #generative</code></li>
<li>Summary: <p>Humans perceive and interact with hundreds of objects every day. In doing so,
they need to employ mental models of these objects and often exploit symmetries
in the object's shape and appearance in order to learn generalizable and
transferable skills. Active inference is a first principles approach to
understanding and modeling sentient agents. It states that agents entertain a
generative model of their environment, and learn and act by minimizing an upper
bound on their surprisal, i.e. their Free Energy. The Free Energy decomposes
into an accuracy and complexity term, meaning that agents favor the least
complex model, that can accurately explain their sensory observations. In this
paper, we investigate how inherent symmetries of particular objects also emerge
as symmetries in the latent state space of the generative model learnt under
deep active inference. In particular, we focus on object-centric
representations, which are trained from pixels to predict novel object views as
the agent moves its viewpoint. First, we investigate the relation between model
complexity and symmetry exploitation in the state space. Second, we do a
principal component analysis to demonstrate how the model encodes the principal
axis of symmetry of the object in the latent space. Finally, we also
demonstrate how more symmetrical representations can be exploited for better
generalization in the context of manipulation.
</p></li>
</ul>

<h3>Title: Interpreting Vision and Language Generative Models with Semantic Visual Priors. (arXiv:2304.14986v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2304.14986">http://arxiv.org/abs/2304.14986</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2304.14986] Interpreting Vision and Language Generative Models with Semantic Visual Priors](http://arxiv.org/abs/2304.14986) #generative</code></li>
<li>Summary: <p>When applied to Image-to-text models, interpretability methods often provide
token-by-token explanations namely, they compute a visual explanation for each
token of the generated sequence. Those explanations are expensive to compute
and unable to comprehensively explain the model's output. Therefore, these
models often require some sort of approximation that eventually leads to
misleading explanations. We develop a framework based on SHAP, that allows for
generating comprehensive, meaningful explanations leveraging the meaning
representation of the output sequence as a whole. Moreover, by exploiting
semantic priors in the visual backbone, we extract an arbitrary number of
features that allows the efficient computation of Shapley values on large-scale
models, generating at the same time highly meaningful visual explanations. We
demonstrate that our method generates semantically more expressive explanations
than traditional methods at a lower compute cost and that it can be generalized
over other explainability methods.
</p></li>
</ul>

<h3>Title: Multisample Flow Matching: Straightening Flows with Minibatch Couplings. (arXiv:2304.14772v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2304.14772">http://arxiv.org/abs/2304.14772</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2304.14772] Multisample Flow Matching: Straightening Flows with Minibatch Couplings](http://arxiv.org/abs/2304.14772) #generative</code></li>
<li>Summary: <p>Simulation-free methods for training continuous-time generative models
construct probability paths that go between noise distributions and individual
data samples. Recent works, such as Flow Matching, derived paths that are
optimal for each data sample. However, these algorithms rely on independent
data and noise samples, and do not exploit underlying structure in the data
distribution for constructing probability paths. We propose Multisample Flow
Matching, a more general framework that uses non-trivial couplings between data
and noise samples while satisfying the correct marginal constraints. At very
small overhead costs, this generalization allows us to (i) reduce gradient
variance during training, (ii) obtain straighter flows for the learned vector
field, which allows us to generate high-quality samples using fewer function
evaluations, and (iii) obtain transport maps with lower cost in high
dimensions, which has applications beyond generative modeling. Importantly, we
do so in a completely simulation-free manner with a simple minimization
objective. We show that our proposed methods improve sample consistency on
downsampled ImageNet data sets, and lead to better low-cost sample generation.
</p></li>
</ul>

<h2>large language model</h2>
<h3>Title: LLaMA-Adapter V2: Parameter-Efficient Visual Instruction Model. (arXiv:2304.15010v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2304.15010">http://arxiv.org/abs/2304.15010</a></li>
<li>Code URL: <a href="https://github.com/zrrskywalker/llama-adapter">https://github.com/zrrskywalker/llama-adapter</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2304.15010] LLaMA-Adapter V2: Parameter-Efficient Visual Instruction Model](http://arxiv.org/abs/2304.15010) #large language model</code></li>
<li>Summary: <p>How to efficiently transform large language models (LLMs) into instruction
followers is recently a popular research direction, while training LLM for
multi-modal reasoning remains less explored. Although the recent LLaMA-Adapter
demonstrates the potential to handle visual inputs with LLMs, it still cannot
generalize well to open-ended visual instructions and lags behind GPT-4. In
this paper, we present LLaMA-Adapter V2, a parameter-efficient visual
instruction model. Specifically, we first augment LLaMA-Adapter by unlocking
more learnable parameters (e.g., norm, bias and scale), which distribute the
instruction-following ability across the entire LLaMA model besides adapters.
Secondly, we propose an early fusion strategy to feed visual tokens only into
the early LLM layers, contributing to better visual knowledge incorporation.
Thirdly, a joint training paradigm of image-text pairs and
instruction-following data is introduced by optimizing disjoint groups of
learnable parameters. This strategy effectively alleviates the interference
between the two tasks of image-text alignment and instruction following and
achieves strong multi-modal reasoning with only a small-scale image-text and
instruction dataset. During inference, we incorporate additional expert models
(e.g. captioning/OCR systems) into LLaMA-Adapter to further enhance its image
understanding capability without incurring training costs. Compared to the
original LLaMA-Adapter, our LLaMA-Adapter V2 can perform open-ended multi-modal
instructions by merely introducing 14M parameters over LLaMA. The newly
designed framework also exhibits stronger language-only instruction-following
capabilities and even excels in chat interactions. Our code and models are
available at https://github.com/ZrrSkywalker/LLaMA-Adapter.
</p></li>
</ul>

<h3>Title: PMC-LLaMA: Further Finetuning LLaMA on Medical Papers. (arXiv:2304.14454v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2304.14454">http://arxiv.org/abs/2304.14454</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2304.14454] PMC-LLaMA: Further Finetuning LLaMA on Medical Papers](http://arxiv.org/abs/2304.14454) #large language model</code></li>
<li>Summary: <p>Large Language Models (LLMs) have showcased remarkable capabilities in
natural language understanding in various domains. These models can usually
behave well on daily dialog, or question answering scenarios, however, in areas
that value precision, for example, in medical applications, they often exhibit
unsatisfactory performance due to a lack of domain-specific knowledge. In this
report, we introduce PMC-LLaMA, an open-source language model that is acquired
by fine-tuning an open-source language model on a total of 4.8 million
biomedical academic papers for further injecting medical knowledge, enhancing
its capability in medical domain. Our preliminary evaluations are conducted on
three biomedical QA datasets, including PubMedQA, MedMCQA, and USMLE, showing
that the our model after finetuning, i.e., PMC-LLaMA, demonstrates better
understanding of biomedical domain-specific concepts, thus achieving high
performance on QA benchmarks. The model and codes, along with an online demo,
are publicly available.
</p></li>
</ul>

<h3>Title: Framing the News:From Human Perception to Large Language Model Inferences. (arXiv:2304.14456v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2304.14456">http://arxiv.org/abs/2304.14456</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2304.14456] Framing the News:From Human Perception to Large Language Model Inferences](http://arxiv.org/abs/2304.14456) #large language model</code></li>
<li>Summary: <p>Identifying the frames of news is important to understand the articles'
vision, intention, message to be conveyed, and which aspects of the news are
emphasized. Framing is a widely studied concept in journalism, and has emerged
as a new topic in computing, with the potential to automate processes and
facilitate the work of journalism professionals. In this paper, we study this
issue with articles related to the Covid-19 anti-vaccine movement. First, to
understand the perspectives used to treat this theme, we developed a protocol
for human labeling of frames for 1786 headlines of No-Vax movement articles of
European newspapers from 5 countries. Headlines are key units in the written
press, and worth of analysis as many people only read headlines (or use them to
guide their decision for further reading.) Second, considering advances in
Natural Language Processing (NLP) with large language models, we investigated
two approaches for frame inference of news headlines: first with a GPT-3.5
fine-tuning approach, and second with GPT-3.5 prompt-engineering. Our work
contributes to the study and analysis of the performance that these models have
to facilitate journalistic tasks like classification of frames, while
understanding whether the models are able to replicate human perception in the
identification of these frames.
</p></li>
</ul>

<h3>Title: Search-in-the-Chain: Towards the Accurate, Credible and Traceable Content Generation for Complex Knowledge-intensive Tasks. (arXiv:2304.14732v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2304.14732">http://arxiv.org/abs/2304.14732</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2304.14732] Search-in-the-Chain: Towards the Accurate, Credible and Traceable Content Generation for Complex Knowledge-intensive Tasks](http://arxiv.org/abs/2304.14732) #large language model</code></li>
<li>Summary: <p>With the wide application of Large Language Models (LLMs) such as ChatGPT,
how to make the contents generated by LLM accurate and credible becomes very
important, especially in complex knowledge-intensive tasks. In this paper, we
propose a novel framework called Search-in-the-Chain (SearChain) to improve the
accuracy, credibility and traceability of LLM-generated content for multi-hop
question answering, which is a typical complex knowledge-intensive task.
SearChain is a framework that deeply integrates LLM and information retrieval
(IR). In SearChain, LLM constructs a chain-of-query, which is the decomposition
of the multi-hop question. Each node of the chain is a query-answer pair
consisting of an IR-oriented query and the answer generated by LLM for this
query. IR verifies, completes, and traces the information of each node of the
chain, so as to guide LLM to construct the correct chain-of-query, and finally
answer the multi-hop question. SearChain makes LLM change from trying to give a
answer to trying to construct the chain-of-query when faced with the multi-hop
question, which can stimulate the knowledge-reasoning ability and provides the
interface for IR to be deeply involved in reasoning process of LLM. IR
interacts with each node of chain-of-query of LLM. It verifies the information
of the node and provides the unknown knowledge to LLM, which ensures the
accuracy of the whole chain in the process of LLM generating the answer.
Besides, the contents returned by LLM to the user include not only the final
answer but also the reasoning process for the question, that is, the
chain-of-query and the supporting documents retrieved by IR for each node of
the chain, which improves the credibility and traceability of the contents
generated by LLM. Experimental results show SearChain outperforms related
baselines on four multi-hop question-answering datasets.
</p></li>
</ul>

<h3>Title: ChatGPT Evaluation on Sentence Level Relations: A Focus on Temporal, Causal, and Discourse Relations. (arXiv:2304.14827v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2304.14827">http://arxiv.org/abs/2304.14827</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2304.14827] ChatGPT Evaluation on Sentence Level Relations: A Focus on Temporal, Causal, and Discourse Relations](http://arxiv.org/abs/2304.14827) #large language model</code></li>
<li>Summary: <p>This paper aims to quantitatively evaluate the performance of ChatGPT, an
interactive large language model, on inter-sentential relations such as
temporal relations, causal relations, and discourse relations. Given ChatGPT's
promising performance across various tasks, we conduct extensive evaluations on
the whole test sets of 13 datasets, including temporal and causal relations,
PDTB2.0-based and dialogue-based discourse relations, and downstream
applications on discourse understanding. To achieve reliable results, we adopt
three tailored prompt templates for each task, including the zero-shot prompt
template, zero-shot prompt engineering (PE) template, and in-context learning
(ICL) prompt template, to establish the initial baseline scores for all popular
sentence-pair relation classification tasks for the first time. We find that
ChatGPT exhibits strong performance in detecting and reasoning about causal
relations, while it may not be proficient in identifying the temporal order
between two events. It can recognize most discourse relations with existing
explicit discourse connectives, but the implicit discourse relation still
remains a challenging task. Meanwhile, ChatGPT performs poorly in the dialogue
discourse parsing task that requires structural understanding in a dialogue
before being aware of the discourse relation.
</p></li>
</ul>

<h3>Title: Empirical Analysis of the Strengths and Weaknesses of PEFT Techniques for LLMs. (arXiv:2304.14999v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2304.14999">http://arxiv.org/abs/2304.14999</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2304.14999] Empirical Analysis of the Strengths and Weaknesses of PEFT Techniques for LLMs](http://arxiv.org/abs/2304.14999) #large language model</code></li>
<li>Summary: <p>As foundation models continue to exponentially scale in size, efficient
methods of adaptation become increasingly critical. Parameter-efficient
fine-tuning (PEFT), a recent class of techniques that require only modifying a
small percentage of the model parameters, is currently the most popular method
for adapting large language models (LLMs). Several PEFT techniques have
recently been proposed with varying tradeoffs. We provide a comprehensive and
uniform benchmark of various PEFT techniques across a representative LLM, the
FLAN-T5 model, and evaluate model performance across different data scales of
classification and generation datasets. Based on this, we provide a framework
for choosing the optimal fine-tuning techniques given the task type and data
availability. Contrary to popular belief, we also empirically prove that PEFT
techniques converge slower than full tuning in low data scenarios, and posit
the amount of data required for PEFT methods to both perform well and converge
efficiently. Lastly, we further optimize these PEFT techniques by selectively
choosing which parts of the model to train, and find that these techniques can
be applied with significantly fewer parameters while maintaining and even
improving performance.
</p></li>
</ul>

<h3>Title: MLCopilot: Unleashing the Power of Large Language Models in Solving Machine Learning Tasks. (arXiv:2304.14979v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2304.14979">http://arxiv.org/abs/2304.14979</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2304.14979] MLCopilot: Unleashing the Power of Large Language Models in Solving Machine Learning Tasks](http://arxiv.org/abs/2304.14979) #large language model</code></li>
<li>Summary: <p>The field of machine learning (ML) has gained widespread adoption, leading to
a significant demand for adapting ML to specific scenarios, which is yet
expensive and non-trivial. The predominant approaches towards the automation of
solving ML tasks (e.g., AutoML) are often time consuming and hard to understand
for human developers. In contrast, though human engineers have the incredible
ability to understand tasks and reason about solutions, their experience and
knowledge are often sparse and difficult to utilize by quantitative approaches.
In this paper, we aim to bridge the gap between machine intelligence and human
knowledge by introducing a novel framework MLCopilot, which leverages the
state-of-the-art LLMs to develop ML solutions for novel tasks. We showcase the
possibility of extending the capability of LLMs to comprehend structured inputs
and perform thorough reasoning for solving novel ML tasks. And we find that,
after some dedicated design, the LLM can (i) observe from the existing
experiences of ML tasks and (ii) reason effectively to deliver promising
results for new tasks. The solution generated can be used directly to achieve
high levels of competitiveness.
</p></li>
</ul>

<h2>segmentation</h2>
<h3>Title: SRCNet: Seminal Representation Collaborative Network for Marine Oil Spill Segmentation. (arXiv:2304.14500v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2304.14500">http://arxiv.org/abs/2304.14500</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2304.14500] SRCNet: Seminal Representation Collaborative Network for Marine Oil Spill Segmentation](http://arxiv.org/abs/2304.14500) #segmentation</code></li>
<li>Summary: <p>Effective oil spill segmentation in Synthetic Aperture Radar (SAR) images is
critical for marine oil pollution cleanup, and proper image representation is
helpful for accurate image segmentation. In this paper, we propose an effective
oil spill image segmentation network named SRCNet by leveraging SAR image
representation and the training for oil spill segmentation simultaneously.
Specifically, our proposed segmentation network is constructed with a pair of
deep neural nets with the collaboration of the seminal representation that
describes SAR images, where one deep neural net is the generative net which
strives to produce oil spill segmentation maps, and the other is the
discriminative net which trys its best to distinguish between the produced and
the true segmentations, and they thus built a two-player game. Particularly,
the seminal representation exploited in our proposed SRCNet originates from SAR
imagery, modelling with the internal characteristics of SAR images. Thus, in
the training process, the collaborated seminal representation empowers the
mapped generative net to produce accurate oil spill segmentation maps
efficiently with small amount of training data, promoting the discriminative
net reaching its optimal solution at a fast speed. Therefore, our proposed
SRCNet operates effective oil spill segmentation in an economical and efficient
manner. Additionally, to increase the segmentation capability of the proposed
segmentation network in terms of accurately delineating oil spill details in
SAR images, a regularisation term that penalises the segmentation loss is
devised. This encourages our proposed SRCNet for accurately segmenting oil
spill areas from SAR images. Empirical experimental evaluations from different
metrics validate the effectiveness of our proposed SRCNet for oil spill image
segmentation.
</p></li>
</ul>

<h3>Title: DIAMANT: Dual Image-Attention Map Encoders For Medical Image Segmentation. (arXiv:2304.14571v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2304.14571">http://arxiv.org/abs/2304.14571</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2304.14571] DIAMANT: Dual Image-Attention Map Encoders For Medical Image Segmentation](http://arxiv.org/abs/2304.14571) #segmentation</code></li>
<li>Summary: <p>Although purely transformer-based architectures showed promising performance
in many computer vision tasks, many hybrid models consisting of CNN and
transformer blocks are introduced to fit more specialized tasks. Nevertheless,
despite the performance gain of both pure and hybrid transformer-based
architectures compared to CNNs in medical imaging segmentation, their high
training cost and complexity make it challenging to use them in real scenarios.
In this work, we propose simple architectures based on purely convolutional
layers, and show that by just taking advantage of the attention map
visualizations obtained from a self-supervised pretrained vision transformer
network (e.g., DINO) one can outperform complex transformer-based networks with
much less computation costs. The proposed architecture is composed of two
encoder branches with the original image as input in one branch and the
attention map visualizations of the same image from multiple self-attention
heads from a pre-trained DINO model (as multiple channels) in the other branch.
The results of our experiments on two publicly available medical imaging
datasets show that the proposed pipeline outperforms U-Net and the
state-of-the-art medical image segmentation models.
</p></li>
</ul>

<h3>Title: SCOPE: Structural Continuity Preservation for Medical Image Segmentation. (arXiv:2304.14572v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2304.14572">http://arxiv.org/abs/2304.14572</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2304.14572] SCOPE: Structural Continuity Preservation for Medical Image Segmentation](http://arxiv.org/abs/2304.14572) #segmentation</code></li>
<li>Summary: <p>Although the preservation of shape continuity and physiological anatomy is a
natural assumption in the segmentation of medical images, it is often neglected
by deep learning methods that mostly aim for the statistical modeling of input
data as pixels rather than interconnected structures. In biological structures,
however, organs are not separate entities; for example, in reality, a severed
vessel is an indication of an underlying problem, but traditional segmentation
models are not designed to strictly enforce the continuity of anatomy,
potentially leading to inaccurate medical diagnoses. To address this issue, we
propose a graph-based approach that enforces the continuity and connectivity of
anatomical topology in medical images. Our method encodes the continuity of
shapes as a graph constraint, ensuring that the network's predictions maintain
this continuity. We evaluate our method on two public benchmarks on retinal
vessel segmentation, showing significant improvements in connectivity metrics
compared to traditional methods while getting better or on-par performance on
segmentation metrics.
</p></li>
</ul>

<h3>Title: Pre-processing training data improves accuracy and generalisability of convolutional neural network based landscape semantic segmentation. (arXiv:2304.14625v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2304.14625">http://arxiv.org/abs/2304.14625</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2304.14625] Pre-processing training data improves accuracy and generalisability of convolutional neural network based landscape semantic segmentation](http://arxiv.org/abs/2304.14625) #segmentation</code></li>
<li>Summary: <p>In this paper, we trialled different methods of data preparation for
Convolutional Neural Network (CNN) training and semantic segmentation of land
use land cover (LULC) features within aerial photography over the Wet Tropics
and Atherton Tablelands, Queensland, Australia. This was conducted through
trialling and ranking various training patch selection sampling strategies,
patch and batch sizes and data augmentations and scaling. We also compared
model accuracy through producing the LULC classification using a single pass of
a grid of patches and averaging multiple grid passes and three rotated version
of each patch. Our results showed: a stratified random sampling approach for
producing training patches improved the accuracy of classes with a smaller area
while having minimal effect on larger classes; a smaller number of larger
patches compared to a larger number of smaller patches improves model accuracy;
applying data augmentations and scaling are imperative in creating a
generalised model able to accurately classify LULC features in imagery from a
different date and sensor; and producing the output classification by averaging
multiple grids of patches and three rotated versions of each patch produced and
more accurate and aesthetic result. Combining the findings from the trials, we
fully trained five models on the 2018 training image and applied the model to
the 2015 test image with the output LULC classifications achieving an average
kappa of 0.84 user accuracy of 0.81 and producer accuracy of 0.87. This study
has demonstrated the importance of data pre-processing for developing a
generalised deep-learning model for LULC classification which can be applied to
a different date and sensor. Future research using CNN and earth observation
data should implement the findings of this study to increase LULC model
accuracy and transferability.
</p></li>
</ul>

<h3>Title: Differentiable Sensor Layouts for End-to-End Learning of Task-Specific Camera Parameters. (arXiv:2304.14736v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2304.14736">http://arxiv.org/abs/2304.14736</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2304.14736] Differentiable Sensor Layouts for End-to-End Learning of Task-Specific Camera Parameters](http://arxiv.org/abs/2304.14736) #segmentation</code></li>
<li>Summary: <p>The success of deep learning is frequently described as the ability to train
all parameters of a network on a specific application in an end-to-end fashion.
Yet, several design choices on the camera level, including the pixel layout of
the sensor, are considered as pre-defined and fixed, and high resolution,
regular pixel layouts are considered to be the most generic ones in computer
vision and graphics, treating all regions of an image as equally important.
While several works have considered non-uniform, \eg, hexagonal or foveated,
pixel layouts in hardware and image processing, the layout has not been
integrated into the end-to-end learning paradigm so far. In this work, we
present the first truly end-to-end trained imaging pipeline that optimizes the
size and distribution of pixels on the imaging sensor jointly with the
parameters of a given neural network on a specific task. We derive an analytic,
differentiable approach for the sensor layout parameterization that allows for
task-specific, local varying pixel resolutions. We present two pixel layout
parameterization functions: rectangular and curvilinear grid shapes that retain
a regular topology. We provide a drop-in module that approximates sensor
simulation given existing high-resolution images to directly connect our method
with existing deep learning models. We show that network predictions benefit
from learnable pixel layouts for two different downstream tasks, classification
and semantic segmentation.
</p></li>
</ul>

<h3>Title: Multi-to-Single Knowledge Distillation for Point Cloud Semantic Segmentation. (arXiv:2304.14800v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2304.14800">http://arxiv.org/abs/2304.14800</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2304.14800] Multi-to-Single Knowledge Distillation for Point Cloud Semantic Segmentation](http://arxiv.org/abs/2304.14800) #segmentation</code></li>
<li>Summary: <p>3D point cloud semantic segmentation is one of the fundamental tasks for
environmental understanding. Although significant progress has been made in
recent years, the performance of classes with few examples or few points is
still far from satisfactory. In this paper, we propose a novel multi-to-single
knowledge distillation framework for the 3D point cloud semantic segmentation
task to boost the performance of those hard classes. Instead of fusing all the
points of multi-scans directly, only the instances that belong to the
previously defined hard classes are fused. To effectively and sufficiently
distill valuable knowledge from multi-scans, we leverage a multilevel
distillation framework, i.e., feature representation distillation, logit
distillation, and affinity distillation. We further develop a novel
instance-aware affinity distillation algorithm for capturing high-level
structural knowledge to enhance the distillation efficacy for hard classes.
Finally, we conduct experiments on the SemanticKITTI dataset, and the results
on both the validation and test sets demonstrate that our method yields
substantial improvements compared with the baseline method. The code is
available at \Url{https://github.com/skyshoumeng/M2SKD}.
</p></li>
</ul>

<h3>Title: NeRF-LiDAR: Generating Realistic LiDAR Point Clouds with Neural Radiance Fields. (arXiv:2304.14811v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2304.14811">http://arxiv.org/abs/2304.14811</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2304.14811] NeRF-LiDAR: Generating Realistic LiDAR Point Clouds with Neural Radiance Fields](http://arxiv.org/abs/2304.14811) #segmentation</code></li>
<li>Summary: <p>Labeling LiDAR point clouds for training autonomous driving is extremely
expensive and difficult. LiDAR simulation aims at generating realistic LiDAR
data with labels for training and verifying self-driving algorithms more
efficiently. Recently, Neural Radiance Fields (NeRF) have been proposed for
novel view synthesis using implicit reconstruction of 3D scenes. Inspired by
this, we present NeRF-LIDAR, a novel LiDAR simulation method that leverages
real-world information to generate realistic LIDAR point clouds. Different from
existing LiDAR simulators, we use real images and point cloud data collected by
self-driving cars to learn the 3D scene representation, point cloud generation
and label rendering. We verify the effectiveness of our NeRF-LiDAR by training
different 3D segmentation models on the generated LiDAR point clouds. It
reveals that the trained models are able to achieve similar accuracy when
compared with the same model trained on the real LiDAR data. Besides, the
generated data is capable of boosting the accuracy through pre-training which
helps reduce the requirements of the real labeled data.
</p></li>
</ul>

<h3>Title: SFD2: Semantic-guided Feature Detection and Description. (arXiv:2304.14845v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2304.14845">http://arxiv.org/abs/2304.14845</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2304.14845] SFD2: Semantic-guided Feature Detection and Description](http://arxiv.org/abs/2304.14845) #segmentation</code></li>
<li>Summary: <p>Visual localization is a fundamental task for various applications including
autonomous driving and robotics. Prior methods focus on extracting large
amounts of often redundant locally reliable features, resulting in limited
efficiency and accuracy, especially in large-scale environments under
challenging conditions. Instead, we propose to extract globally reliable
features by implicitly embedding high-level semantics into both the detection
and description processes. Specifically, our semantic-aware detector is able to
detect keypoints from reliable regions (e.g. building, traffic lane) and
suppress unreliable areas (e.g. sky, car) implicitly instead of relying on
explicit semantic labels. This boosts the accuracy of keypoint matching by
reducing the number of features sensitive to appearance changes and avoiding
the need of additional segmentation networks at test time. Moreover, our
descriptors are augmented with semantics and have stronger discriminative
ability, providing more inliers at test time. Particularly, experiments on
long-term large-scale visual localization Aachen Day-Night and RobotCar-Seasons
datasets demonstrate that our model outperforms previous local features and
gives competitive accuracy to advanced matchers but is about 2 and 3 times
faster when using 2k and 4k keypoints, respectively.
</p></li>
</ul>

<button id="copy">Copy All</button>
</article>
<script src="../../javascript/clipboard.min.js"></script>
<script src="../../javascript/clipboard.js"></script>
