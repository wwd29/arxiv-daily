<link rel="stylesheet" href="../../css/markdown.css" />
<article class="markdown-body">
<h1>2025-06-26</h1>
<h3>Title: Secure Energy Transactions Using Blockchain Leveraging AI for Fraud Detection and Energy Market Stability</h3>
<ul>
<li><strong>Authors: </strong>Md Asif Ul Hoq Khan, MD Zahedul Islam, Istiaq Ahmed, Md Masud Karim Rabbi, Farhana Rahman Anonna, MD Abdul Fahim Zeeshan, Mehedi Hasan Ridoy, Bivash Ranjan Chowdhury, Md Nazmul Shakir Rabbi, GM Alamin Sadnan</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.19870">https://arxiv.org/abs/2506.19870</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.19870">https://arxiv.org/pdf/2506.19870</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.19870]] Secure Energy Transactions Using Blockchain Leveraging AI for Fraud Detection and Energy Market Stability(https://arxiv.org/abs/2506.19870)</code><input type="text"></li>
<li><strong>Keywords: </strong>secure, security, privacy</a></li>
<li><strong>Abstract: </strong>Peer-to-peer trading and the move to decentralized grids have reshaped the energy markets in the United States. Notwithstanding, such developments lead to new challenges, mainly regarding the safety and authenticity of energy trade. This study aimed to develop and build a secure, intelligent, and efficient energy transaction system for the decentralized US energy market. This research interlinks the technological prowess of blockchain and artificial intelligence (AI) in a novel way to solve long-standing challenges in the distributed energy market, specifically those of security, fraudulent behavior detection, and market reliability. The dataset for this research is comprised of more than 1.2 million anonymized energy transaction records from a simulated peer-to-peer (P2P) energy exchange network emulating real-life blockchain-based American microgrids, including those tested by LO3 Energy and Grid+ Labs. Each record contains detailed fields of transaction identifier, timestamp, energy volume (kWh), transaction type (buy/sell), unit price, prosumer/consumer identifier (hashed for privacy), smart meter readings, geolocation regions, and settlement confirmation status. The dataset also includes system-calculated behavior metrics of transaction rate, variability of energy production, and historical pricing patterns. The system architecture proposed involves the integration of two layers, namely a blockchain layer and artificial intelligence (AI) layer, each playing a unique but complementary function in energy transaction securing and market intelligence improvement. The machine learning models used in this research were specifically chosen for their established high performance in classification tasks, specifically in the identification of energy transaction fraud in decentralized markets.</li>
</ul>

<h3>Title: An Attack Method for Medical Insurance Claim Fraud Detection based on Generative Adversarial Network</h3>
<ul>
<li><strong>Authors: </strong>Yining Pang, Chenghan Li</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.19871">https://arxiv.org/abs/2506.19871</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.19871">https://arxiv.org/pdf/2506.19871</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.19871]] An Attack Method for Medical Insurance Claim Fraud Detection based on Generative Adversarial Network(https://arxiv.org/abs/2506.19871)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, defense, attack, robust, generative</a></li>
<li><strong>Abstract: </strong>Insurance fraud detection represents a pivotal advancement in modern insurance service, providing intelligent and digitalized monitoring to enhance management and prevent fraud. It is crucial for ensuring the security and efficiency of insurance systems. Although AI and machine learning algorithms have demonstrated strong performance in detecting fraudulent claims, the absence of standardized defense mechanisms renders current systems vulnerable to emerging adversarial threats. In this paper, we propose a GAN-based approach to conduct adversarial attacks on fraud detection systems. Our results indicate that an attacker, without knowledge of the training data or internal model details, can generate fraudulent cases that are classified as legitimate with a 99\% attack success rate (ASR). By subtly modifying real insurance records and claims, adversaries can significantly increase the fraud risk, potentially bypassing compromised detection systems. These findings underscore the urgent need to enhance the robustness of insurance fraud detection models against adversarial manipulation, thereby ensuring the stability and reliability of different insurance systems.</li>
</ul>

<h3>Title: Towards Provable (In)Secure Model Weight Release Schemes</h3>
<ul>
<li><strong>Authors: </strong>Xing Yang, Bingtao Wang, Yuhao Wang, Zimo Ji, Terry Jingchen Zhang, Wenyuan Jiang</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.19874">https://arxiv.org/abs/2506.19874</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.19874">https://arxiv.org/pdf/2506.19874</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.19874]] Towards Provable (In)Secure Model Weight Release Schemes(https://arxiv.org/abs/2506.19874)</code><input type="text"></li>
<li><strong>Keywords: </strong>secure, security, protect, extraction</a></li>
<li><strong>Abstract: </strong>Recent secure weight release schemes claim to enable open-source model distribution while protecting model ownership and preventing misuse. However, these approaches lack rigorous security foundations and provide only informal security guarantees. Inspired by established works in cryptography, we formalize the security of weight release schemes by introducing several concrete security definitions. We then demonstrate our definition's utility through a case study of TaylorMLP, a prominent secure weight release scheme. Our analysis reveals vulnerabilities that allow parameter extraction thus showing that TaylorMLP fails to achieve its informal security goals. We hope this work will advocate for rigorous research at the intersection of machine learning and security communities and provide a blueprint for how future weight release schemes should be designed and evaluated.</li>
</ul>

<h3>Title: Robust Anomaly Detection in Network Traffic: Evaluating Machine Learning Models on CICIDS2017</h3>
<ul>
<li><strong>Authors: </strong>Zhaoyang Xu, Yunbo Liu</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.19877">https://arxiv.org/abs/2506.19877</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.19877">https://arxiv.org/pdf/2506.19877</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.19877]] Robust Anomaly Detection in Network Traffic: Evaluating Machine Learning Models on CICIDS2017(https://arxiv.org/abs/2506.19877)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, attack, robust</a></li>
<li><strong>Abstract: </strong>Identifying suitable machine learning paradigms for intrusion detection remains critical for building effective and generalizable security solutions. In this study, we present a controlled comparison of four representative models - Multi-Layer Perceptron (MLP), 1D Convolutional Neural Network (CNN), One-Class Support Vector Machine (OCSVM) and Local Outlier Factor (LOF) - on the CICIDS2017 dataset under two scenarios: detecting known attack types and generalizing to previously unseen threats. Our results show that supervised MLP and CNN achieve near-perfect accuracy on familiar attacks but suffer drastic recall drops on novel attacks. Unsupervised LOF attains moderate overall accuracy and high recall on unknown threats at the cost of elevated false alarms, while boundary-based OCSVM balances precision and recall best, demonstrating robust detection across both scenarios. These findings offer practical guidance for selecting IDS models in dynamic network environments.</li>
</ul>

<h3>Title: Blameless Users in a Clean Room: Defining Copyright Protection for Generative Models</h3>
<ul>
<li><strong>Authors: </strong>Aloni Cohen</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.CY, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.19881">https://arxiv.org/abs/2506.19881</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.19881">https://arxiv.org/pdf/2506.19881</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.19881]] Blameless Users in a Clean Room: Defining Copyright Protection for Generative Models(https://arxiv.org/abs/2506.19881)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, protect, generative</a></li>
<li><strong>Abstract: </strong>Are there any conditions under which a generative model's outputs are guaranteed not to infringe the copyrights of its training data? This is the question of "provable copyright protection" first posed by Vyas, Kakade, and Barak (ICML 2023). They define near access-freeness (NAF) and propose it as sufficient for protection. This paper revisits the question and establishes new foundations for provable copyright protection -- foundations that are firmer both technically and legally. First, we show that NAF alone does not prevent infringement. In fact, NAF models can enable verbatim copying, a blatant failure of copy protection that we dub being tainted. Then, we introduce our blameless copy protection framework for defining meaningful guarantees, and instantiate it with clean-room copy protection. Clean-room copy protection allows a user to control their risk of copying by behaving in a way that is unlikely to copy in a counterfactual clean-room setting. Finally, we formalize a common intuition about differential privacy and copyright by proving that DP implies clean-room copy protection when the dataset is golden, a copyright deduplication requirement.</li>
</ul>

<h3>Title: Position: Machine Learning Conferences Should Establish a "Refutations and Critiques" Track</h3>
<ul>
<li><strong>Authors: </strong>Rylan Schaeffer, Joshua Kazdan, Yegor Denisov-Blanch, Brando Miranda, Matthias Gerstgrasser, Susan Zhang, Andreas Haupt, Isha Gupta, Elyas Obbad, Jesse Dodge, Jessica Zosa Forde, Koustuv Sinha, Francesco Orabona, Sanmi Koyejo, David Donoho</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CL, cs.CY</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.19882">https://arxiv.org/abs/2506.19882</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.19882">https://arxiv.org/pdf/2506.19882</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.19882]] Position: Machine Learning Conferences Should Establish a "Refutations and Critiques" Track(https://arxiv.org/abs/2506.19882)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Science progresses by iteratively advancing and correcting humanity's understanding of the world. In machine learning (ML) research, rapid advancements have led to an explosion of publications, but have also led to misleading, incorrect, flawed or perhaps even fraudulent studies being accepted and sometimes highlighted at ML conferences due to the fallibility of peer review. While such mistakes are understandable, ML conferences do not offer robust processes to help the field systematically correct when such errors are this http URL position paper argues that ML conferences should establish a dedicated "Refutations and Critiques" (R & C) Track. This R & C Track would provide a high-profile, reputable platform to support vital research that critically challenges prior research, thereby fostering a dynamic self-correcting research ecosystem. We discuss key considerations including track design, review principles, potential pitfalls, and provide an illustrative example submission concerning a recent ICLR 2025 Oral. We conclude that ML conferences should create official, reputable mechanisms to help ML research self-correct.</li>
</ul>

<h3>Title: STIMULUS: Achieving Fast Convergence and Low Sample Complexity in Stochastic Multi-Objective Learning</h3>
<ul>
<li><strong>Authors: </strong>Zhuqing Liu, Chaosheng Dong, Michinari Momma, Simone Shao, Shaoyuan Xu, Yan Gao, Haibo Yang, Jia Liu</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.19883">https://arxiv.org/abs/2506.19883</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.19883">https://arxiv.org/pdf/2506.19883</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.19883]] STIMULUS: Achieving Fast Convergence and Low Sample Complexity in Stochastic Multi-Objective Learning(https://arxiv.org/abs/2506.19883)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Recently, multi-objective optimization (MOO) has gained attention for its broad applications in ML, operations research, and engineering. However, MOO algorithm design remains in its infancy and many existing MOO methods suffer from unsatisfactory convergence rate and sample complexity performance. To address this challenge, in this paper, we propose an algorithm called STIMULUS( stochastic path-integrated multi-gradient recursive e\ulstimator), a new and robust approach for solving MOO problems. Different from the traditional methods, STIMULUS introduces a simple yet powerful recursive framework for updating stochastic gradient estimates to improve convergence performance with low sample complexity. In addition, we introduce an enhanced version of STIMULUS, termed STIMULUS-M, which incorporates a momentum term to further expedite convergence. We establish $O(1/T)$ convergence rates of the proposed methods for non-convex settings and $O (\exp{-\mu T})$ for strongly convex settings, where $T$ is the total number of iteration rounds. Additionally, we achieve the state-of-the-art $O \left(n+\sqrt{n}\epsilon^{-1}\right)$ sample complexities for non-convex settings and $O\left(n+ \sqrt{n} \ln ({\mu/\epsilon})\right)$ for strongly convex settings, where $\epsilon>0$ is a desired stationarity error. Moreover, to alleviate the periodic full gradient evaluation requirement in STIMULUS and STIMULUS-M, we further propose enhanced versions with adaptive batching called STIMULUS+/ STIMULUS-M+ and provide their theoretical analysis.</li>
</ul>

<h3>Title: FlightKooba: A Fast Interpretable FTP Model</h3>
<ul>
<li><strong>Authors: </strong>Jing Lu, Xuan Wu, Yizhun Tian, Songhan Fan, Yali Fang</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.19885">https://arxiv.org/abs/2506.19885</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.19885">https://arxiv.org/pdf/2506.19885</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.19885]] FlightKooba: A Fast Interpretable FTP Model(https://arxiv.org/abs/2506.19885)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability</a></li>
<li><strong>Abstract: </strong>The Koopman theory is a powerful and effective modeling tool for converting nonlinear systems into linear representations, and flight trajectory prediction (FTP) is a complex nonlinear system. However, current models applying the Koopman theory to FTP tasks are not very effective, model interpretability is indeed an issue, and the Koopman operators are computationally intensive, resulting in long training times. To address this issue, this paper proposes a new modeling and control framework based on the HIPPO method, the Koopman theory, and state space equations from cybernetics: FlightKooba. Inspired by the idea of structural state space equations, FlightKooba directly constructs the Koopman operators from data. This makes the framework highly interpretable and significantly reduces the number of trainable parameters in the module, thereby greatly reducing training time. Experiments have demonstrated the superiority of the FlightKooba modeling method in terms of time and memory consumption (training time comparable to the Mamba module without using CUDA-level acceleration; memory reduced by more than 50% on most datasets, with a tenfold reduction in the number of parameters), essentially completing the FTP task. It provides a new method for the fast computation of the Koopman operators, opening up new possibilities for the combination of time series forecasting and control.</li>
</ul>

<h3>Title: Diffusion-based Task-oriented Semantic Communications with Model Inversion Attack</h3>
<ul>
<li><strong>Authors: </strong>Xuesong Wang, Mo Li, Xingyan Shi, Zhaoqian Liu, Shenghao Yang</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.IT, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.19886">https://arxiv.org/abs/2506.19886</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.19886">https://arxiv.org/pdf/2506.19886</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.19886]] Diffusion-based Task-oriented Semantic Communications with Model Inversion Attack(https://arxiv.org/abs/2506.19886)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, attack, robust, diffusion</a></li>
<li><strong>Abstract: </strong>Semantic communication has emerged as a promising neural network-based system design for 6G networks. Task-oriented semantic communication is a novel paradigm whose core goal is to efficiently complete specific tasks by transmitting semantic information, optimizing communication efficiency and task performance. The key challenge lies in preserving privacy while maintaining task accuracy, as this scenario is susceptible to model inversion attacks. In such attacks, adversaries can restore or even reconstruct input data by analyzing and processing model outputs, owing to the neural network-based nature of the systems. In addition, traditional systems use image quality indicators (such as PSNR or SSIM) to assess attack severity, which may be inadequate for task-oriented semantic communication, since visual differences do not necessarily ensure semantic divergence. In this paper, we propose a diffusion-based semantic communication framework, named DiffSem, that optimizes semantic information reconstruction through a diffusion mechanism with self-referential label embedding to significantly improve task performance. Our model also compensates channel noise and adopt semantic information distortion to ensure the robustness of the system in various signal-to-noise ratio environments. To evaluate the attacker's effectiveness, we propose a new metric that better quantifies the semantic fidelity of estimations from the adversary. Experimental results based on this criterion show that on the MNIST dataset, DiffSem improves the classification accuracy by 10.03%, and maintain stable performance under dynamic channels. Our results further demonstrate that significant deviation exists between traditional image quality indicators and the leakage of task-relevant semantic information.</li>
</ul>

<h3>Title: Retrieval-Confused Generation is a Good Defender for Privacy Violation Attack of Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Wanli Peng, Xin Chen, Hang Fu, XinYu He, Xue Yiming, Juan Wen</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.19889">https://arxiv.org/abs/2506.19889</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.19889">https://arxiv.org/pdf/2506.19889</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.19889]] Retrieval-Confused Generation is a Good Defender for Privacy Violation Attack of Large Language Models(https://arxiv.org/abs/2506.19889)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, privacy, defense, attack, large language model</a></li>
<li><strong>Abstract: </strong>Recent advances in large language models (LLMs) have made a profound impact on our society and also raised new security concerns. Particularly, due to the remarkable inference ability of LLMs, the privacy violation attack (PVA), revealed by Staab et al., introduces serious personal privacy issues. Existing defense methods mainly leverage LLMs to anonymize the input query, which requires costly inference time and cannot gain satisfactory defense performance. Moreover, directly rejecting the PVA query seems like an effective defense method, while the defense method is exposed, promoting the evolution of PVA. In this paper, we propose a novel defense paradigm based on retrieval-confused generation (RCG) of LLMs, which can efficiently and covertly defend the PVA. We first design a paraphrasing prompt to induce the LLM to rewrite the "user comments" of the attack query to construct a disturbed database. Then, we propose the most irrelevant retrieval strategy to retrieve the desired user data from the disturbed database. Finally, the "data comments" are replaced with the retrieved user data to form a defended query, leading to responding to the adversary with some wrong personal attributes, i.e., the attack fails. Extensive experiments are conducted on two datasets and eight popular LLMs to comprehensively evaluate the feasibility and the superiority of the proposed defense method.</li>
</ul>

<h3>Title: Causal-Aware Intelligent QoE Optimization for VR Interaction with Adaptive Keyframe Extraction</h3>
<ul>
<li><strong>Authors: </strong>Ziru Zhang, Jiadong Yu, Danny H.K. Tsang</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.19890">https://arxiv.org/abs/2506.19890</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.19890">https://arxiv.org/pdf/2506.19890</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.19890]] Causal-Aware Intelligent QoE Optimization for VR Interaction with Adaptive Keyframe Extraction(https://arxiv.org/abs/2506.19890)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction, fair</a></li>
<li><strong>Abstract: </strong>The optimization of quality of experience (QoE) in multi-user virtual reality (VR) interactions demands a delicate balance between ultra-low latency, high-fidelity motion synchronization, and equitable resource allocation. While adaptive keyframe extraction mitigates transmission overhead, existing approaches often overlook the causal relationships among allocated bandwidth, CPU frequency, and user perception, limiting QoE gains. This paper proposes an intelligent framework to maximize QoE by integrating adaptive keyframe extraction with causal-aware reinforcement learning (RL). First, a novel QoE metric is formulated using the Weber-Fechner Law, combining perceptual sensitivity, attention-driven priorities, and motion reconstruction accuracy. The QoE optimization problem is then modeled as a mixed integer programming (MIP) task, jointly optimizing keyframe ratios, bandwidth, and computational resources under horizon-fairness constraints. We propose Partial State Causal Deep Deterministic Policy Gradient (PS-CDDPG), which integrates the Deep Deterministic Policy Gradient (DDPG) method with causal influence detection. By leveraging causal information regarding how QoE is influenced and determined by various actions, we explore actions guided by weights calculated from causal inference (CI), which in turn improves training efficiency. Experiments conducted with the CMU Motion Capture Database demonstrate that our framework significantly reduces interactive latency, enhances QoE, and maintains fairness, achieving superior performance compared to benchmark methods.</li>
</ul>

<h3>Title: Orthogonal Soft Pruning for Efficient Class Unlearning</h3>
<ul>
<li><strong>Authors: </strong>Qinghui Gong, Xue Yang, Xiaohu Tang</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.19891">https://arxiv.org/abs/2506.19891</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.19891">https://arxiv.org/pdf/2506.19891</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.19891]] Orthogonal Soft Pruning for Efficient Class Unlearning(https://arxiv.org/abs/2506.19891)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, attack, membership infer</a></li>
<li><strong>Abstract: </strong>Machine unlearning aims to selectively remove class-specific knowledge from pretrained neural networks to satisfy privacy regulations such as the GDPR. Existing methods typically face a trade-off between unlearning speed and preservation of predictive accuracy, often incurring either high computational overhead or significant performance degradation on retained classes. In this paper, we propose a novel class-aware soft pruning framework leveraging orthogonal convolutional kernel regularization to achieve rapid and precise forgetting with millisecond-level response times. By enforcing orthogonality constraints during training, our method decorrelates convolutional filters and disentangles feature representations, while efficiently identifying class-specific channels through activation difference analysis. Extensive evaluations across multiple architectures and datasets demonstrate stable pruning with near-instant execution, complete forgetting of targeted classes, and minimal accuracy loss on retained data. Experiments on CIFAR-10, CIFAR-100, and TinyImageNet confirm that our approach substantially reduces membership inference attack risks and accelerates unlearning by orders of magnitude compared to state-of-the-art baselines. This framework provides an efficient, practical solution for real-time machine unlearning in Machine Learning as a Service (MLaaS) scenarios.</li>
</ul>

<h3>Title: RepuNet: A Reputation System for Mitigating Malicious Clients in DFL</h3>
<ul>
<li><strong>Authors: </strong>Isaac Marroqui Penalva, Enrique Tomás Martínez Beltrán, Manuel Gil Pérez, Alberto Huertas Celdrán</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.AI, cs.DC, cs.LG, cs.PF</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.19892">https://arxiv.org/abs/2506.19892</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.19892">https://arxiv.org/pdf/2506.19892</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.19892]] RepuNet: A Reputation System for Mitigating Malicious Clients in DFL(https://arxiv.org/abs/2506.19892)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack, robust, federate</a></li>
<li><strong>Abstract: </strong>Decentralized Federated Learning (DFL) enables nodes to collaboratively train models without a central server, introducing new vulnerabilities since each node independently selects peers for model aggregation. Malicious nodes may exploit this autonomy by sending corrupted models (model poisoning), delaying model submissions (delay attack), or flooding the network with excessive messages, negatively affecting system performance. Existing solutions often depend on rigid configurations or additional infrastructures such as blockchain, leading to computational overhead, scalability issues, or limited adaptability. To overcome these limitations, this paper proposes RepuNet, a decentralized reputation system that categorizes threats in DFL and dynamically evaluates node behavior using metrics like model similarity, parameter changes, message latency, and communication volume. Nodes' influence in model aggregation is adjusted based on their reputation scores. RepuNet was integrated into the Nebula DFL platform and experimentally evaluated with MNIST and CIFAR-10 datasets under non-IID distributions, using federations of up to 25 nodes in both fully connected and random topologies. Different attack intensities, frequencies, and activation intervals were tested. Results demonstrated that RepuNet effectively detects and mitigates malicious behavior, achieving F1 scores above 95% for MNIST scenarios and approximately 76% for CIFAR-10 cases. These outcomes highlight RepuNet's adaptability, robustness, and practical potential for mitigating threats in decentralized federated learning environments.</li>
</ul>

<h3>Title: Distillation-Enabled Knowledge Alignment for Generative Semantic Communications in AIGC Provisioning Tasks</h3>
<ul>
<li><strong>Authors: </strong>Jingzhi Hu, Geoffrey Ye Li</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, eess.IV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.19893">https://arxiv.org/abs/2506.19893</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.19893">https://arxiv.org/pdf/2506.19893</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.19893]] Distillation-Enabled Knowledge Alignment for Generative Semantic Communications in AIGC Provisioning Tasks(https://arxiv.org/abs/2506.19893)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>Due to the surging amount of AI-generated content (AIGC), its provisioning to edges and mobile users from the cloud incurs substantial traffic on networks. Generative semantic communication (GSC) offers a promising solution by transmitting highly compact information, i.e., prompt text and latent representations, instead of high-dimensional AIGC data. However, GSC relies on the alignment between the knowledge in the cloud generative AI (GAI) and that possessed by the edges and users, and between the knowledge for wireless transmission and that of actual channels, which remains challenging. In this paper, we propose DeKA-g, a distillation-enabled knowledge alignment algorithm for GSC systems. The core idea is to distill the generation knowledge from the cloud-GAI into low-rank matrices, which can be incorporated by the edge and used to adapt the transmission knowledge to diverse wireless channel conditions. DeKA-g comprises two novel methods: metaword-aided knowledge distillation (MAKD) and variable-rate grouped SNR adaptation (VGSA). For MAKD, an optimized metaword is employed to enhance the efficiency of knowledge distillation, while VGSA enables efficient adaptation to diverse compression rates and SNR ranges. From simulation results, DeKA-g improves the alignment between the edge-generated images and the cloud-generated ones by 44%. Moreover, it adapts to compression rates with 116% higher efficiency than the baseline and enhances the performance in low-SNR conditions by 28%.</li>
</ul>

<h3>Title: Anti-Phishing Training Does Not Work: A Large-Scale Empirical Assessment of Multi-Modal Training Grounded in the NIST Phish Scale</h3>
<ul>
<li><strong>Authors: </strong>Andrew T. Rozema, James C. Davis</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.HC</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.19899">https://arxiv.org/abs/2506.19899</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.19899">https://arxiv.org/pdf/2506.19899</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.19899]] Anti-Phishing Training Does Not Work: A Large-Scale Empirical Assessment of Multi-Modal Training Grounded in the NIST Phish Scale(https://arxiv.org/abs/2506.19899)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, defense, attack</a></li>
<li><strong>Abstract: </strong>Social engineering attacks using email, commonly known as phishing, are a critical cybersecurity threat. Phishing attacks often lead to operational incidents and data breaches. As a result, many organizations allocate a substantial portion of their cybersecurity budgets to phishing awareness training, driven in part by compliance requirements. However, the effectiveness of this training remains in dispute. Empirical evidence of training (in)effectiveness is essential for evidence-based cybersecurity investment and policy development. Despite recent measurement studies, two critical gaps remain in the literature: (1) we lack a validated measure of phishing lure difficulty, and (2) there are few comparisons of different types of training in real-world business settings. To fill these gaps, we conducted a large-scale study ($N = 12{,}511$) of phishing effectiveness at a US-based financial technology (``fintech'') firm. Our two-factor design compared the effect of treatments (lecture-based, interactive, and control groups) on subjects' susceptibility to phishing lures of varying complexity (using the NIST Phish Scale). The NIST Phish Scale successfully predicted behavior (click rates: 7.0\% easy to 15.0\% hard emails, p $<$ 0.001), but training showed no significant main effects on clicks (p = 0.450) or reporting (p = 0.417). Effect sizes remained below 0.01, indicating little practical value in any of the phishing trainings we deployed. Our results add to the growing evidence that phishing training is ineffective, reinforcing the importance of phishing defense-in-depth and the merit of changes to processes and technology to reduce reliance on humans, as well as rebuking the training costs necessitated by regulatory requirements.</li>
</ul>

<h3>Title: A Hybrid Intrusion Detection System with a New Approach to Protect the Cybersecurity of Cloud Computing</h3>
<ul>
<li><strong>Authors: </strong>Maryam Mahdi Al-Husseini</a></li>
<li><strong>Subjects: </strong>cs.CR, eess.SY</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.19934">https://arxiv.org/abs/2506.19934</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.19934">https://arxiv.org/pdf/2506.19934</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.19934]] A Hybrid Intrusion Detection System with a New Approach to Protect the Cybersecurity of Cloud Computing(https://arxiv.org/abs/2506.19934)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, protect</a></li>
<li><strong>Abstract: </strong>Cybersecurity is one of the foremost challenges facing the world of cloud computing. Recently, the widespread adoption of smart devices in cloud computing environments that provide Internet-based services has become prevalent. Therefore, it is essential to consider the security threats in these environments. The use of intrusion detection systems can mitigate the vulnerabilities of these systems. Furthermore, hybrid intrusion detection systems can provide better protection compared to conventional intrusion detection systems. These systems manage issues related to complexity, dimensionality, and performance. This research aims to propose a Hybrid Intrusion Detection System (HyIDS) that identifies and mitigates initial threats. The main innovation of this research is the introduction of a new method for hybrid intrusion detection systems (HyIDS). For this purpose, an Energy-Valley Optimizer (EVO) is used to select an optimal feature set, which is then classified using supervised machine learning models. The proposed approach is evaluated using the CIC_DDoS2019, CSE_CIC_DDoS2018, and NSL-KDD datasets. For evaluation and testing, the proposed system has been run for a total of 32 times. The results of the proposed approach are compared with the Grey Wolf Optimizer (GWO). With the CIC_DDoS2019 dataset, the D_TreeEVO model achieves an accuracy of 99.13% and a detection rate of 98.941%. Furthermore, this result reaches 99.78% for the CSE_CIC_DDoS2018 dataset. In comparison to NSL-KDD, it has an accuracy of 99.50% and a detection rate (DT) of 99.48%. For feature selection, EVO outperforms GWO. The results of this research indicate that EVO yields better results as an optimizer for HyIDS performance.</li>
</ul>

<h3>Title: Any-Order GPT as Masked Diffusion Model: Decoupling Formulation and Architecture</h3>
<ul>
<li><strong>Authors: </strong>Shuchen Xue, Tianyu Xie, Tianyang Hu, Zijin Feng, Jiacheng Sun, Kenji Kawaguchi, Zhenguo Li, Zhi-Ming Ma</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CV, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.19935">https://arxiv.org/abs/2506.19935</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.19935">https://arxiv.org/pdf/2506.19935</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.19935]] Any-Order GPT as Masked Diffusion Model: Decoupling Formulation and Architecture(https://arxiv.org/abs/2506.19935)</code><input type="text"></li>
<li><strong>Keywords: </strong>fair, diffusion, large language model</a></li>
<li><strong>Abstract: </strong>Large language models (LLMs) predominantly use autoregressive (AR) approaches, but masked diffusion models (MDMs) are emerging as viable alternatives. A key challenge in comparing AR and MDM paradigms is their typical architectural difference: AR models are often decoder-only, while MDMs have largely been encoder-only. This practice of changing both the modeling paradigm and architecture simultaneously makes direct comparisons unfair, as it's hard to distinguish whether observed differences stem from the paradigm itself or the architectural shift. This research evaluates MDMs within a decoder-only framework to: (1) equitably compare MDM (as Any-Order AR, or AO-AR) and standard AR paradigms. Our investigation suggests that the standard AO-AR objective, which averages over all token permutations, may benefit from refinement, as many permutations appear less informative compared to the language's inherent left-to-right structure. (2) Investigate architectural influences (decoder-only vs. encoder-only) within MDMs. We demonstrate that while encoder-only MDMs model a simpler conditional probability space, decoder-only MDMs can achieve dramatic generation speedups ($\sim25\times$) and comparable perplexity with temperature annealing despite modeling a vastly larger space, highlighting key trade-offs. This work thus decouples core paradigm differences from architectural influences, offering insights for future model design. Code is available at this https URL.</li>
</ul>

<h3>Title: Quantum-Resistant Domain Name System: A Comprehensive System-Level Study</h3>
<ul>
<li><strong>Authors: </strong>Juyoul Lee, Sanzida Hoque, Abdullah Aydeger, Engin Zeydan</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.NI, cs.PF</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.19943">https://arxiv.org/abs/2506.19943</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.19943">https://arxiv.org/pdf/2506.19943</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.19943]] Quantum-Resistant Domain Name System: A Comprehensive System-Level Study(https://arxiv.org/abs/2506.19943)</code><input type="text"></li>
<li><strong>Keywords: </strong>security</a></li>
<li><strong>Abstract: </strong>The Domain Name System (DNS) plays a foundational role in Internet infrastructure, yet its core protocols remain vulnerable to compromise by quantum adversaries. As cryptographically relevant quantum computers become a realistic threat, ensuring DNS confidentiality, authenticity, and integrity in the post-quantum era is imperative. In this paper, we present a comprehensive system-level study of post-quantum DNS security across three widely deployed mechanisms: DNSSEC, DNS-over-TLS (DoT), and DNS-over-HTTPS (DoH). We propose Post-Quantum Cryptographic (PQC)-DNS, a unified framework for benchmarking DNS security under legacy, post-quantum, and hybrid cryptographic configurations. Our implementation leverages the Open Quantum Safe (OQS) libraries and integrates lattice- and hash-based primitives into BIND9 and TLS 1.3 stacks. We formalize performance and threat models and analyze the impact of post-quantum key encapsulation and digital signatures on end-to-end DNS resolution. Experimental results on a containerized testbed reveal that lattice-based primitives such as Module-Lattice-Based Key-Encapsulation Mechanism (MLKEM) and Falcon offer practical latency and resource profiles, while hash-based schemes like SPHINCS+ significantly increase message sizes and processing overhead. We also examine security implications including downgrade risks, fragmentation vulnerabilities, and susceptibility to denial-of-service amplification. Our findings inform practical guidance for deploying quantum-resilient DNS and contribute to the broader effort of securing core Internet protocols for the post-quantum future.</li>
</ul>

<h3>Title: CycleDistill: Bootstrapping Machine Translation using LLMs with Cyclical Distillation</h3>
<ul>
<li><strong>Authors: </strong>Deepon Halder, Thanmay Jayakumar, Raj Dabre</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.19952">https://arxiv.org/abs/2506.19952</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.19952">https://arxiv.org/pdf/2506.19952</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.19952]] CycleDistill: Bootstrapping Machine Translation using LLMs with Cyclical Distillation(https://arxiv.org/abs/2506.19952)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large language models (LLMs), despite their ability to perform few-shot machine translation (MT), often lag behind dedicated MT systems trained on parallel corpora, which are crucial for high quality machine translation (MT). However, parallel corpora are often scarce or non-existent for low-resource languages. In this paper, we propose CycleDistill, a bootstrapping approach leveraging LLMs and few-shot translation to obtain high-quality MT systems. CycleDistill involves iteratively generating synthetic parallel corpora from monolingual corpora via zero- or few-shot MT, which is then used to fine-tune the model that was used for generating said data for MT. CycleDistill does not need parallel corpora beyond 1 to 4 few-shot examples, and in our experiments focusing on three Indian languages, by relying solely on monolingual corpora, it can achieve high-quality machine translation, improving upon a few-shot baseline model by over 20-30 chrF points on average in the first iteration. We also study the effect of leveraging softmax activations during the distillation process and observe mild improvements in translation quality.</li>
</ul>

<h3>Title: Inference Scaled GraphRAG: Improving Multi Hop Question Answering on Knowledge Graphs</h3>
<ul>
<li><strong>Authors: </strong>Travis Thompson, Seung-Hwan Lim, Paul Liu, Ruoying He, Dongkuan Xu</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.19967">https://arxiv.org/abs/2506.19967</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.19967">https://arxiv.org/pdf/2506.19967</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.19967]] Inference Scaled GraphRAG: Improving Multi Hop Question Answering on Knowledge Graphs(https://arxiv.org/abs/2506.19967)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large Language Models (LLMs) have achieved impressive capabilities in language understanding and generation, yet they continue to underperform on knowledge-intensive reasoning tasks due to limited access to structured context and multi-hop information. Retrieval-Augmented Generation (RAG) partially mitigates this by grounding generation in retrieved context, but conventional RAG and GraphRAG methods often fail to capture relational structure across nodes in knowledge graphs. We introduce Inference-Scaled GraphRAG, a novel framework that enhances LLM-based graph reasoning by applying inference-time compute scaling. Our method combines sequential scaling with deep chain-of-thought graph traversal, and parallel scaling with majority voting over sampled trajectories within an interleaved reasoning-execution loop. Experiments on the GRBench benchmark demonstrate that our approach significantly improves multi-hop question answering performance, achieving substantial gains over both traditional GraphRAG and prior graph traversal baselines. These findings suggest that inference-time scaling is a practical and architecture-agnostic solution for structured knowledge reasoning with LLMs</li>
</ul>

<h3>Title: HERCULES: Hierarchical Embedding-based Recursive Clustering Using LLMs for Efficient Summarization</h3>
<ul>
<li><strong>Authors: </strong>Gabor Petnehazi, Bernadett Aradi</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.19992">https://arxiv.org/abs/2506.19992</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.19992">https://arxiv.org/pdf/2506.19992</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.19992]] HERCULES: Hierarchical Embedding-based Recursive Clustering Using LLMs for Efficient Summarization(https://arxiv.org/abs/2506.19992)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability, large language model</a></li>
<li><strong>Abstract: </strong>The explosive growth of complex datasets across various modalities necessitates advanced analytical tools that not only group data effectively but also provide human-understandable insights into the discovered structures. We introduce HERCULES (Hierarchical Embedding-based Recursive Clustering Using LLMs for Efficient Summarization), a novel algorithm and Python package designed for hierarchical k-means clustering of diverse data types, including text, images, and numeric data (processed one modality per run). HERCULES constructs a cluster hierarchy by recursively applying k-means clustering, starting from individual data points at level 0. A key innovation is its deep integration of Large Language Models (LLMs) to generate semantically rich titles and descriptions for clusters at each level of the hierarchy, significantly enhancing interpretability. The algorithm supports two main representation modes: `direct' mode, which clusters based on original data embeddings or scaled numeric features, and `description' mode, which clusters based on embeddings derived from LLM-generated summaries. Users can provide a `topic\_seed' to guide LLM-generated summaries towards specific themes. An interactive visualization tool facilitates thorough analysis and understanding of the clustering results. We demonstrate HERCULES's capabilities and discuss its potential for extracting meaningful, hierarchical knowledge from complex datasets.</li>
</ul>

<h3>Title: TRACED: Transition-aware Regret Approximation with Co-learnability for Environment Design</h3>
<ul>
<li><strong>Authors: </strong>Geonwoo Cho, Jaegyun Im, Jihwan Lee, Hojun Yi, Sejin Kim, Sundong Kim</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.19997">https://arxiv.org/abs/2506.19997</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.19997">https://arxiv.org/pdf/2506.19997</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.19997]] TRACED: Transition-aware Regret Approximation with Co-learnability for Environment Design(https://arxiv.org/abs/2506.19997)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Generalizing deep reinforcement learning agents to unseen environments remains a significant challenge. One promising solution is Unsupervised Environment Design (UED), a co-evolutionary framework in which a teacher adaptively generates tasks with high learning potential, while a student learns a robust policy from this evolving curriculum. Existing UED methods typically measure learning potential via regret, the gap between optimal and current performance, approximated solely by value-function loss. Building on these approaches, we introduce the transition prediction error as an additional term in our regret approximation. To capture how training on one task affects performance on others, we further propose a lightweight metric called co-learnability. By combining these two measures, we present Transition-aware Regret Approximation with Co-learnability for Environment Design (TRACED). Empirical evaluations show that TRACED yields curricula that improve zero-shot generalization across multiple benchmarks while requiring up to 2x fewer environment interactions than strong baselines. Ablation studies confirm that the transition prediction error drives rapid complexity ramp-up and that co-learnability delivers additional gains when paired with the transition prediction error. These results demonstrate how refined regret approximation and explicit modeling of task relationships can be leveraged for sample-efficient curriculum design in UED.</li>
</ul>

<h3>Title: Can One Safety Loop Guard Them All? Agentic Guard Rails for Federated Computing</h3>
<ul>
<li><strong>Authors: </strong>Narasimha Raghavan Veeraragavan, Jan Franz Nygård</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.DC, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.20000">https://arxiv.org/abs/2506.20000</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.20000">https://arxiv.org/pdf/2506.20000</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.20000]] Can One Safety Loop Guard Them All? Agentic Guard Rails for Federated Computing(https://arxiv.org/abs/2506.20000)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, federate</a></li>
<li><strong>Abstract: </strong>We propose Guardian-FC, a novel two-layer framework for privacy preserving federated computing that unifies safety enforcement across diverse privacy preserving mechanisms, including cryptographic back-ends like fully homomorphic encryption (FHE) and multiparty computation (MPC), as well as statistical techniques such as differential privacy (DP). Guardian-FC decouples guard-rails from privacy mechanisms by executing plug-ins (modular computation units), written in a backend-neutral, domain-specific language (DSL) designed specifically for federated computing workflows and interchangeable Execution Providers (EPs), which implement DSL operations for various privacy back-ends. An Agentic-AI control plane enforces a finite-state safety loop through signed telemetry and commands, ensuring consistent risk management and auditability. The manifest-centric design supports fail-fast job admission and seamless extensibility to new privacy back-ends. We present qualitative scenarios illustrating backend-agnostic safety and a formal model foundation for verification. Finally, we outline a research agenda inviting the community to advance adaptive guard-rail tuning, multi-backend composition, DSL specification development, implementation, and compiler extensibility alongside human-override usability.</li>
</ul>

<h3>Title: New Insights on Unfolding and Fine-tuning Quantum Federated Learning</h3>
<ul>
<li><strong>Authors: </strong>Shanika Iroshi Nanayakkara, Shiva Raj Pokhrel</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.20016">https://arxiv.org/abs/2506.20016</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.20016">https://arxiv.org/pdf/2506.20016</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.20016]] New Insights on Unfolding and Fine-tuning Quantum Federated Learning(https://arxiv.org/abs/2506.20016)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, federate</a></li>
<li><strong>Abstract: </strong>Client heterogeneity poses significant challenges to the performance of Quantum Federated Learning (QFL). To overcome these limitations, we propose a new approach leveraging deep unfolding, which enables clients to autonomously optimize hyperparameters, such as learning rates and regularization factors, based on their specific training behavior. This dynamic adaptation mitigates overfitting and ensures robust optimization in highly heterogeneous environments where standard aggregation methods often fail. Our framework achieves approximately 90% accuracy, significantly outperforming traditional methods, which typically yield around 55% accuracy, as demonstrated through real-time training on IBM quantum hardware and Qiskit Aer simulators. By developing self adaptive fine tuning, the proposed method proves particularly effective in critical applications such as gene expression analysis and cancer detection, enhancing diagnostic precision and predictive modeling within quantum systems. Our results are attributed to convergence-aware, learnable optimization steps intrinsic to the deep unfolded framework, which maintains the generalization. Hence, this study addresses the core limitations of conventional QFL, streamlining its applicability to any complex challenges such as healthcare and genomic research.</li>
</ul>

<h3>Title: DIM-SUM: Dynamic IMputation for Smart Utility Management</h3>
<ul>
<li><strong>Authors: </strong>Ryan Hildebrant, Rahul Bhope, Sharad Mehrotra, Christopher Tull, Nalini Venkatasubramanian</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.DB</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.20023">https://arxiv.org/abs/2506.20023</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.20023">https://arxiv.org/pdf/2506.20023</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.20023]] DIM-SUM: Dynamic IMputation for Smart Utility Management(https://arxiv.org/abs/2506.20023)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Time series imputation models have traditionally been developed using complete datasets with artificial masking patterns to simulate missing values. However, in real-world infrastructure monitoring, practitioners often encounter datasets where large amounts of data are missing and follow complex, heterogeneous patterns. We introduce DIM-SUM, a preprocessing framework for training robust imputation models that bridges the gap between artificially masked training data and real missing patterns. DIM-SUM combines pattern clustering and adaptive masking strategies with theoretical learning guarantees to handle diverse missing patterns actually observed in the data. Through extensive experiments on over 2 billion readings from California water districts, electricity datasets, and benchmarks, we demonstrate that DIM-SUM outperforms traditional methods by reaching similar accuracy with lower processing time and significantly less training data. When compared against a large pre-trained model, DIM-SUM averages 2x higher accuracy with significantly less inference time.</li>
</ul>

<h3>Title: Elucidated Rolling Diffusion Models for Probabilistic Weather Forecasting</h3>
<ul>
<li><strong>Authors: </strong>Salva Rühling Cachay, Miika Aittala, Karsten Kreis, Noah Brenowitz, Arash Vahdat, Morteza Mardani, Rose Yu</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, physics.ao-ph, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.20024">https://arxiv.org/abs/2506.20024</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.20024">https://arxiv.org/pdf/2506.20024</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.20024]] Elucidated Rolling Diffusion Models for Probabilistic Weather Forecasting(https://arxiv.org/abs/2506.20024)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, extraction, diffusion</a></li>
<li><strong>Abstract: </strong>Diffusion models are a powerful tool for probabilistic forecasting, yet most applications in high-dimensional chaotic systems predict future snapshots one-by-one. This common approach struggles to model complex temporal dependencies and fails to explicitly account for the progressive growth of uncertainty inherent to such systems. While rolling diffusion frameworks, which apply increasing noise to forecasts at longer lead times, have been proposed to address this, their integration with state-of-the-art, high-fidelity diffusion techniques remains a significant challenge. We tackle this problem by introducing Elucidated Rolling Diffusion Models (ERDM), the first framework to successfully unify a rolling forecast structure with the principled, performant design of Elucidated Diffusion Models (EDM). To do this, we adapt the core EDM components-its noise schedule, network preconditioning, and Heun sampler-to the rolling forecast setting. The success of this integration is driven by three key contributions: (i) a novel loss weighting scheme that focuses model capacity on the mid-range forecast horizons where determinism gives way to stochasticity; (ii) an efficient initialization strategy using a pre-trained EDM for the initial window; and (iii) a bespoke hybrid sequence architecture for robust spatiotemporal feature extraction under progressive denoising. On 2D Navier-Stokes simulations and ERA5 global weather forecasting at 1.5^\circ resolution, ERDM consistently outperforms key diffusion-based baselines, including conditional autoregressive EDM. ERDM offers a flexible and powerful general framework for tackling diffusion-based sequence generation problems where modeling escalating uncertainty is paramount. Code is available at: this https URL</li>
</ul>

<h3>Title: Verifiable Unlearning on Edge</h3>
<ul>
<li><strong>Authors: </strong>Mohammad M Maheri, Alex Davidson, Hamed Haddadi</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.20037">https://arxiv.org/abs/2506.20037</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.20037">https://arxiv.org/pdf/2506.20037</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.20037]] Verifiable Unlearning on Edge(https://arxiv.org/abs/2506.20037)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy</a></li>
<li><strong>Abstract: </strong>Machine learning providers commonly distribute global models to edge devices, which subsequently personalize these models using local data. However, issues such as copyright infringements, biases, or regulatory requirements may require the verifiable removal of certain data samples across all edge devices. Ensuring that edge devices correctly execute such unlearning operations is critical to maintaining integrity. In this work, we introduce a verification framework leveraging zero-knowledge proofs, specifically zk-SNARKs, to confirm data unlearning on personalized edge-device models without compromising privacy. We have developed algorithms explicitly designed to facilitate unlearning operations that are compatible with efficient zk-SNARK proof generation, ensuring minimal computational and memory overhead suitable for constrained edge environments. Furthermore, our approach carefully preserves personalized enhancements on edge devices, maintaining model performance post-unlearning. Our results affirm the practicality and effectiveness of this verification framework, demonstrating verifiable unlearning with minimal degradation in personalization-induced performance improvements. Our methodology ensures verifiable, privacy-preserving, and effective machine unlearning across edge devices.</li>
</ul>

<h3>Title: Cross-Layer Discrete Concept Discovery for Interpreting Language Models</h3>
<ul>
<li><strong>Authors: </strong>Ankur Garg, Xuemin Yu, Hassan Sajjad, Samira Ebrahimi Kahou</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.20040">https://arxiv.org/abs/2506.20040</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.20040">https://arxiv.org/pdf/2506.20040</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.20040]] Cross-Layer Discrete Concept Discovery for Interpreting Language Models(https://arxiv.org/abs/2506.20040)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer, large language model</a></li>
<li><strong>Abstract: </strong>Uncovering emergent concepts across transformer layers remains a significant challenge because the residual stream linearly mixes and duplicates information, obscuring how features evolve within large language models. Current research efforts primarily inspect neural representations at single layers, thereby overlooking this cross-layer superposition and the redundancy it introduces. These representations are typically either analyzed directly for activation patterns or passed to probing classifiers that map them to a limited set of predefined concepts. To address these limitations, we propose \gls{clvqvae}, a framework that uses vector quantization to map representations across layers and in the process collapse duplicated residual-stream features into compact, interpretable concept vectors. Our approach uniquely combines top-$k$ temperature-based sampling during quantization with EMA codebook updates, providing controlled exploration of the discrete latent space while maintaining code-book diversity. We further enhance the framework with scaled-spherical k-means++ for codebook initialization, which clusters by directional similarity rather than magnitude, better aligning with semantic structure in word embedding space.</li>
</ul>

<h3>Title: LSH-DynED: A Dynamic Ensemble Framework with LSH-Based Undersampling for Evolving Multi-Class Imbalanced Classification</h3>
<ul>
<li><strong>Authors: </strong>Soheil Abadifard, Fazli Can</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.IR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.20041">https://arxiv.org/abs/2506.20041</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.20041">https://arxiv.org/pdf/2506.20041</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.20041]] LSH-DynED: A Dynamic Ensemble Framework with LSH-Based Undersampling for Evolving Multi-Class Imbalanced Classification(https://arxiv.org/abs/2506.20041)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>The classification of imbalanced data streams, which have unequal class distributions, is a key difficulty in machine learning, especially when dealing with multiple classes. While binary imbalanced data stream classification tasks have received considerable attention, only a few studies have focused on multi-class imbalanced data streams. Effectively managing the dynamic imbalance ratio is a key challenge in this domain. This study introduces a novel, robust, and resilient approach to address these challenges by integrating Locality Sensitive Hashing with Random Hyperplane Projections (LSH-RHP) into the Dynamic Ensemble Diversification (DynED) framework. To the best of our knowledge, we present the first application of LSH-RHP for undersampling in the context of imbalanced non-stationary data streams. The proposed method undersamples the majority classes by utilizing LSH-RHP, provides a balanced training set, and improves the ensemble's prediction performance. We conduct comprehensive experiments on 23 real-world and ten semi-synthetic datasets and compare LSH-DynED with 15 state-of-the-art methods. The results reveal that LSH-DynED outperforms other approaches in terms of both Kappa and mG-Mean effectiveness measures, demonstrating its capability in dealing with multi-class imbalanced non-stationary data streams. Notably, LSH-DynED performs well in large-scale, high-dimensional datasets with considerable class imbalances and demonstrates adaptation and robustness in real-world circumstances. To motivate our design, we review existing methods for imbalanced data streams, outline key challenges, and offer guidance for future work. For the reproducibility of our results, we have made our implementation available on GitHub.</li>
</ul>

<h3>Title: Learning Instruction-Following Policies through Open-Ended Instruction Relabeling with Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Zhicheng Zhang, Ziyan Wang, Yali Du, Fei Fang</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.20061">https://arxiv.org/abs/2506.20061</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.20061">https://arxiv.org/pdf/2506.20061</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.20061]] Learning Instruction-Following Policies through Open-Ended Instruction Relabeling with Large Language Models(https://arxiv.org/abs/2506.20061)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Developing effective instruction-following policies in reinforcement learning remains challenging due to the reliance on extensive human-labeled instruction datasets and the difficulty of learning from sparse rewards. In this paper, we propose a novel approach that leverages the capabilities of large language models (LLMs) to automatically generate open-ended instructions retrospectively from previously collected agent trajectories. Our core idea is to employ LLMs to relabel unsuccessful trajectories by identifying meaningful subtasks the agent has implicitly accomplished, thereby enriching the agent's training data and substantially alleviating reliance on human annotations. Through this open-ended instruction relabeling, we efficiently learn a unified instruction-following policy capable of handling diverse tasks within a single policy. We empirically evaluate our proposed method in the challenging Craftax environment, demonstrating clear improvements in sample efficiency, instruction coverage, and overall policy performance compared to state-of-the-art baselines. Our results highlight the effectiveness of utilizing LLM-guided open-ended instruction relabeling to enhance instruction-following reinforcement learning.</li>
</ul>

<h3>Title: ToSA: Token Merging with Spatial Awareness</h3>
<ul>
<li><strong>Authors: </strong>Hsiang-Wei Huang, Wenhao Chai, Kuang-Ming Chen, Cheng-Yen Yang, Jenq-Neng Hwang</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.20066">https://arxiv.org/abs/2506.20066</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.20066">https://arxiv.org/pdf/2506.20066</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.20066]] ToSA: Token Merging with Spatial Awareness(https://arxiv.org/abs/2506.20066)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Token merging has emerged as an effective strategy to accelerate Vision Transformers (ViT) by reducing computational costs. However, existing methods primarily rely on the visual token's feature similarity for token merging, overlooking the potential of integrating spatial information, which can serve as a reliable criterion for token merging in the early layers of ViT, where the visual tokens only possess weak visual information. In this paper, we propose ToSA, a novel token merging method that combines both semantic and spatial awareness to guide the token merging process. ToSA leverages the depth image as input to generate pseudo spatial tokens, which serve as auxiliary spatial information for the visual token merging process. With the introduced spatial awareness, ToSA achieves a more informed merging strategy that better preserves critical scene structure. Experimental results demonstrate that ToSA outperforms previous token merging methods across multiple benchmarks on visual and embodied question answering while largely reducing the runtime of the ViT, making it an efficient solution for ViT acceleration. The code will be available at: this https URL</li>
</ul>

<h3>Title: A Modular Multitask Reasoning Framework Integrating Spatio-temporal Models and LLMs</h3>
<ul>
<li><strong>Authors: </strong>Kethmi Hirushini Hettige, Jiahao Ji, Cheng Long, Shili Xiang, Gao Cong, Jingyuan Wang</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.20073">https://arxiv.org/abs/2506.20073</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.20073">https://arxiv.org/pdf/2506.20073</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.20073]] A Modular Multitask Reasoning Framework Integrating Spatio-temporal Models and LLMs(https://arxiv.org/abs/2506.20073)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Spatio-temporal data mining plays a pivotal role in informed decision making across diverse domains. However, existing models are often restricted to narrow tasks, lacking the capacity for multi-task inference and complex long-form reasoning that require generation of in-depth, explanatory outputs. These limitations restrict their applicability to real-world, multi-faceted decision scenarios. In this work, we introduce STReason, a novel framework that integrates the reasoning strengths of large language models (LLMs) with the analytical capabilities of spatio-temporal models for multi-task inference and execution. Without requiring task-specific finetuning, STReason leverages in-context learning to decompose complex natural language queries into modular, interpretable programs, which are then systematically executed to generate both solutions and detailed rationales. To facilitate rigorous evaluation, we construct a new benchmark dataset and propose a unified evaluation framework with metrics specifically designed for long-form spatio-temporal reasoning. Experimental results show that STReason significantly outperforms advanced LLM baselines across all metrics, particularly excelling in complex, reasoning-intensive spatio-temporal scenarios. Human evaluations further validate STReason's credibility and practical utility, demonstrating its potential to reduce expert workload and broaden the applicability to real-world spatio-temporal tasks. We believe STReason provides a promising direction for developing more capable and generalizable spatio-temporal reasoning systems.</li>
</ul>

<h3>Title: Attack Smarter: Attention-Driven Fine-Grained Webpage Fingerprinting Attacks</h3>
<ul>
<li><strong>Authors: </strong>Yali Yuan, Weiyi Zou, Guang Cheng</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.20082">https://arxiv.org/abs/2506.20082</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.20082">https://arxiv.org/pdf/2506.20082</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.20082]] Attack Smarter: Attention-Driven Fine-Grained Webpage Fingerprinting Attacks(https://arxiv.org/abs/2506.20082)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack</a></li>
<li><strong>Abstract: </strong>Website Fingerprinting (WF) attacks aim to infer which websites a user is visiting by analyzing traffic patterns, thereby compromising user anonymity. Although this technique has been demonstrated to be effective in controlled experimental environments, it remains largely limited to small-scale scenarios, typically restricted to recognizing website homepages. In practical settings, however, users frequently access multiple subpages in rapid succession, often before previous content fully loads. WebPage Fingerprinting (WPF) generalizes the WF framework to large-scale environments by modeling subpages of the same site as distinct classes. These pages often share similar page elements, resulting in lower inter-class variance in traffic features. Furthermore, we consider multi-tab browsing scenarios, in which a single trace encompasses multiple categories of webpages. This leads to overlapping traffic segments, and similar features may appear in different positions within the traffic, thereby increasing the difficulty of classification. To address these challenges, we propose an attention-driven fine-grained WPF attack, named ADWPF. Specifically, during the training phase, we apply targeted augmentation to salient regions of the traffic based on attention maps, including attention cropping and attention masking. ADWPF then extracts low-dimensional features from both the original and augmented traffic and applies self-attention modules to capture the global contextual patterns of the trace. Finally, to handle the multi-tab scenario, we employ the residual attention to generate class-specific representations of webpages occurring at different temporal positions. Extensive experiments demonstrate that the proposed method consistently surpasses state-of-the-art baselines across datasets of different scales.</li>
</ul>

<h3>Title: Bridging Compositional and Distributional Semantics: A Survey on Latent Semantic Geometry via AutoEncoder</h3>
<ul>
<li><strong>Authors: </strong>Yingji Zhang, Danilo S. Carvalho, André Freitas</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.20083">https://arxiv.org/abs/2506.20083</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.20083">https://arxiv.org/pdf/2506.20083</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.20083]] Bridging Compositional and Distributional Semantics: A Survey on Latent Semantic Geometry via AutoEncoder(https://arxiv.org/abs/2506.20083)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability, transformer</a></li>
<li><strong>Abstract: </strong>Integrating compositional and symbolic properties into current distributional semantic spaces can enhance the interpretability, controllability, compositionality, and generalisation capabilities of Transformer-based auto-regressive language models (LMs). In this survey, we offer a novel perspective on latent space geometry through the lens of compositional semantics, a direction we refer to as \textit{semantic representation learning}. This direction enables a bridge between symbolic and distributional semantics, helping to mitigate the gap between them. We review and compare three mainstream autoencoder architectures-Variational AutoEncoder (VAE), Vector Quantised VAE (VQVAE), and Sparse AutoEncoder (SAE)-and examine the distinctive latent geometries they induce in relation to semantic structure and interpretability.</li>
</ul>

<h3>Title: A Survey of Predictive Maintenance Methods: An Analysis of Prognostics via Classification and Regression</h3>
<ul>
<li><strong>Authors: </strong>Ainaz Jamshidi, Dongchan Kim, Muhammad Arif</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.20090">https://arxiv.org/abs/2506.20090</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.20090">https://arxiv.org/pdf/2506.20090</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.20090]] A Survey of Predictive Maintenance Methods: An Analysis of Prognostics via Classification and Regression(https://arxiv.org/abs/2506.20090)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Predictive maintenance (PdM) has become a crucial element of modern industrial practice. PdM plays a significant role in operational dependability and cost management by decreasing unforeseen downtime and optimizing asset life cycle management. Machine learning and deep learning have enabled more precise forecasts of equipment failure and remaining useful life (RUL). Although many studies have been conducted on PdM, there has not yet been a standalone comparative study between regression- and classification-based approaches. In this review, we look across a range of PdM methodologies, while focusing more strongly on the comparative use of classification and regression methods in prognostics. While regression-based methods typically provide estimates of RUL, classification-based methods present a forecast of the probability of failure across defined time intervals. Through a comprehensive analysis of recent literature, we highlight key advancements, challenges-such as data imbalance and high-dimensional feature spaces-and emerging trends, including hybrid approaches and AI-enabled prognostic systems. This review aims to provide researchers and practitioners with an awareness of the strengths and compromises of various PdM methods and to help identify future research and build more robust, directed adaptive maintenance systems. Future work may include a systematic review of practical aspects such as public datasets, benchmarking platforms, and open-source tools to support the advancement of PdM research.</li>
</ul>

<h3>Title: ITFormer: Bridging Time Series and Natural Language for Multi-Modal QA with Large-Scale Multitask Dataset</h3>
<ul>
<li><strong>Authors: </strong>Yilin Wang, Peixuan Lei, Jie Song, Yuzhe Hao, Tao Chen, Yuxuan Zhang, Lei Jia, Yuanxiang Li, Zhongyu Wei</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.20093">https://arxiv.org/abs/2506.20093</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.20093">https://arxiv.org/pdf/2506.20093</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.20093]] ITFormer: Bridging Time Series and Natural Language for Multi-Modal QA with Large-Scale Multitask Dataset(https://arxiv.org/abs/2506.20093)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, transformer, large language model</a></li>
<li><strong>Abstract: </strong>Time-series data are critical in diverse applications, such as industrial monitoring, medical diagnostics, and climate research. However, effectively integrating these high-dimensional temporal signals with natural language for dynamic, interactive tasks remains a significant challenge. To address this, we introduce the Time-Series Question Answering (Time-Series QA) task and release EngineMT-QA, the first large-scale, multi-task, temporal-textual QA dataset designed to capture complex interactions between time-series signals and natural language. Building on this resource, we propose the Instruct Time Transformer (ITFormer), a novel framework that bridges time-series encoders with frozen large language models (LLMs). ITFormer effectively extracts, aligns, and fuses temporal and textual features, achieving a strong improvement in QA accuracy over strong baselines with fewer than 1\% additional trainable parameters. By combining computational efficiency with robust cross-modal modeling, our work establishes a adaptable paradigm for integrating temporal data with natural language, paving the way for new research and applications in multi-modal AI. More details about the project, including datasets and code, are available at: this https URL</li>
</ul>

<h3>Title: Secure Multi-Key Homomorphic Encryption with Application to Privacy-Preserving Federated Learning</h3>
<ul>
<li><strong>Authors: </strong>Jiahui Wu, Tiecheng Sun, Fucai Luo, Haiyan Wang, Weizhe Zhang</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.20101">https://arxiv.org/abs/2506.20101</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.20101">https://arxiv.org/pdf/2506.20101</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.20101]] Secure Multi-Key Homomorphic Encryption with Application to Privacy-Preserving Federated Learning(https://arxiv.org/abs/2506.20101)</code><input type="text"></li>
<li><strong>Keywords: </strong>secure, security, privacy, federate</a></li>
<li><strong>Abstract: </strong>Multi-Key Homomorphic Encryption (MKHE), proposed by Lopez-Alt et al. (STOC 2012), allows for performing arithmetic computations directly on ciphertexts encrypted under distinct keys. Subsequent works by Chen and Dai et al. (CCS 2019) and Kim and Song et al. (CCS 2023) extended this concept by proposing multi-key BFV/CKKS variants, referred to as the CDKS scheme. These variants incorporate asymptotically optimal techniques to facilitate secure computation across multiple data providers. In this paper, we identify a critical security vulnerability in the CDKS scheme when applied to multiparty secure computation tasks, such as privacy-preserving federated learning (PPFL). In particular, we show that CDKS may inadvertently leak plaintext information from one party to others. To mitigate this issue, we propose a new scheme, SMHE (Secure Multi-Key Homomorphic Encryption), which incorporates a novel masking mechanism into the multi-key BFV and CKKS frameworks to ensure that plaintexts remain confidential throughout the computation. We implement a PPFL application using SMHE and demonstrate that it provides significantly improved security with only a modest overhead in homomorphic evaluation. For instance, our PPFL model based on multi-key CKKS incurs less than a 2\times runtime and communication traffic increase compared to the CDKS-based PPFL model. The code is publicly available at this https URL.</li>
</ul>

<h3>Title: Autonomous Cyber Resilience via a Co-Evolutionary Arms Race within a Fortified Digital Twin Sandbox</h3>
<ul>
<li><strong>Authors: </strong>Malikussaid, Sutiyo</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.LG, eess.SY</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.20102">https://arxiv.org/abs/2506.20102</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.20102">https://arxiv.org/pdf/2506.20102</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.20102]] Autonomous Cyber Resilience via a Co-Evolutionary Arms Race within a Fortified Digital Twin Sandbox(https://arxiv.org/abs/2506.20102)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, defense, attack, steal</a></li>
<li><strong>Abstract: </strong>The convergence of IT and OT has created hyper-connected ICS, exposing critical infrastructure to a new class of adaptive, intelligent adversaries that render static defenses obsolete. Existing security paradigms often fail to address a foundational "Trinity of Trust," comprising the fidelity of the system model, the integrity of synchronizing data, and the resilience of the analytical engine against sophisticated evasion. This paper introduces the ARC framework, a method for achieving analytical resilience through an autonomous, closed-loop hardening process. ARC establishes a perpetual co-evolutionary arms race within the high-fidelity sandbox of a F-SCDT. A DRL agent, the "Red Agent," is formalized and incentivized to autonomously discover stealthy, physically-plausible attack paths that maximize process disruption while evading detection. Concurrently, an ensemble-based "Blue Agent" defender is continuously hardened via adversarial training against the evolving threats discovered by its adversary. This co-evolutionary dynamic forces both agents to become progressively more sophisticated, enabling the system to autonomously probe and patch its own vulnerabilities. Experimental validation on both the TEP and the SWaT testbeds demonstrates the framework's superior performance. A comprehensive ablation study, supported by extensive visualizations including ROC curves and SHAP plots, reveals that the co-evolutionary process itself is responsible for a significant performance increase in detecting novel attacks. By integrating XAI to ensure operator trust and proposing a scalable F-ARC architecture, this work presents ARC not merely as an improvement, but as a necessary paradigm shift toward dynamic, self-improving security for the future of critical infrastructure.</li>
</ul>

<h3>Title: BrokenVideos: A Benchmark Dataset for Fine-Grained Artifact Localization in AI-Generated Videos</h3>
<ul>
<li><strong>Authors: </strong>Jiahao Lin, Weixuan Peng, Bojia Zi, Yifeng Gao, Xianbiao Qi, Xingjun Ma, Yu-Gang Jiang</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.20103">https://arxiv.org/abs/2506.20103</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.20103">https://arxiv.org/pdf/2506.20103</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.20103]] BrokenVideos: A Benchmark Dataset for Fine-Grained Artifact Localization in AI-Generated Videos(https://arxiv.org/abs/2506.20103)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative, large language model</a></li>
<li><strong>Abstract: </strong>Recent advances in deep generative models have led to significant progress in video generation, yet the fidelity of AI-generated videos remains limited. Synthesized content often exhibits visual artifacts such as temporally inconsistent motion, physically implausible trajectories, unnatural object deformations, and local blurring that undermine realism and user trust. Accurate detection and spatial localization of these artifacts are crucial for both automated quality control and for guiding the development of improved generative models. However, the research community currently lacks a comprehensive benchmark specifically designed for artifact localization in AI generated videos. Existing datasets either restrict themselves to video or frame level detection or lack the fine-grained spatial annotations necessary for evaluating localization methods. To address this gap, we introduce BrokenVideos, a benchmark dataset of 3,254 AI-generated videos with meticulously annotated, pixel-level masks highlighting regions of visual corruption. Each annotation is validated through detailed human inspection to ensure high quality ground truth. Our experiments show that training state of the art artifact detection models and multi modal large language models (MLLMs) on BrokenVideos significantly improves their ability to localize corrupted regions. Through extensive evaluation, we demonstrate that BrokenVideos establishes a critical foundation for benchmarking and advancing research on artifact localization in generative video models. The dataset is available at: this https URL.</li>
</ul>

<h3>Title: Evaluating Disassembly Errors With Only Binaries</h3>
<ul>
<li><strong>Authors: </strong>Lambang Akbar Wijayadi, Yuancheng Jiang, Roland H.C. Yap, Zhenkai Liang, Zhuohao Liu</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.20109">https://arxiv.org/abs/2506.20109</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.20109">https://arxiv.org/pdf/2506.20109</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.20109]] Evaluating Disassembly Errors With Only Binaries(https://arxiv.org/abs/2506.20109)</code><input type="text"></li>
<li><strong>Keywords: </strong>security</a></li>
<li><strong>Abstract: </strong>Disassemblers are crucial in the analysis and modification of binaries. Existing works showing disassembler errors largely rely on practical implementation without specific guarantees and assume source code and compiler toolchains to evaluate ground truth. However, the assumption of source code is contrary to typical binary scenarios where only the binary is available. In this work, we investigate an approach with minimal assumptions and a sound approach to disassembly error evaluation that does not require source code. Any source code does not address the fundamental problem of binary disassembly and fails when only the binary exists. As far as we know, this is the first work to evaluate disassembly errors using only the binary. We propose TraceBin, which uses dynamic execution to find disassembly errors. TraceBin targets the use case where the disassembly is used in an automated fashion for security tasks on a target binary, such as static binary instrumentation, binary hardening, automated code repair, and so on, which may be affected by disassembly errors. Discovering disassembly errors in the target binary aids in reducing problems caused by such errors. Furthermore, we are not aware of existing approaches that can evaluate errors given only a target binary, as they require source code. Our evaluation shows TraceBin finds: (i) errors consistent with existing studies even without source; (ii) disassembly errors due to control flow; (iii) new interesting errors; (iv) errors in non-C/C++ binaries; (v) errors in closed-source binaries; and (vi) show that disassembly errors can have significant security implications. Overall, our experimental results show that TraceBin finds many errors in existing popular disassemblers. It is also helpful in automated security tasks on (closed source) binaries relying on disassemblers.</li>
</ul>

<h3>Title: A Multi-Pass Large Language Model Framework for Precise and Efficient Radiology Report Error Detection</h3>
<ul>
<li><strong>Authors: </strong>Songsoo Kim, Seungtae Lee, See Young Lee, Joonho Kim, Keechan Kan, Dukyong Yoon</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.20112">https://arxiv.org/abs/2506.20112</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.20112">https://arxiv.org/pdf/2506.20112</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.20112]] A Multi-Pass Large Language Model Framework for Precise and Efficient Radiology Report Error Detection(https://arxiv.org/abs/2506.20112)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Background: The positive predictive value (PPV) of large language model (LLM)-based proofreading for radiology reports is limited due to the low error prevalence. Purpose: To assess whether a three-pass LLM framework enhances PPV and reduces operational costs compared with baseline approaches. Materials and Methods: A retrospective analysis was performed on 1,000 consecutive radiology reports (250 each: radiography, ultrasonography, CT, MRI) from the MIMIC-III database. Two external datasets (CheXpert and Open-i) were validation sets. Three LLM frameworks were tested: (1) single-prompt detector; (2) extractor plus detector; and (3) extractor, detector, and false-positive verifier. Precision was measured by PPV and absolute true positive rate (aTPR). Efficiency was calculated from model inference charges and reviewer remuneration. Statistical significance was tested using cluster bootstrap, exact McNemar tests, and Holm-Bonferroni correction. Results: Framework PPV increased from 0.063 (95% CI, 0.036-0.101, Framework 1) to 0.079 (0.049-0.118, Framework 2), and significantly to 0.159 (0.090-0.252, Framework 3; P<.001 vs. baselines). aTPR remained stable (0.012-0.014; P>=.84). Operational costs per 1,000 reports dropped to USD 5.58 (Framework 3) from USD 9.72 (Framework 1) and USD 6.85 (Framework 2), reflecting reductions of 42.6% and 18.5%, respectively. Human-reviewed reports decreased from 192 to 88. External validation supported Framework 3's superior PPV (CheXpert 0.133, Open-i 0.105) and stable aTPR (0.007). Conclusion: A three-pass LLM framework significantly enhanced PPV and reduced operational costs, maintaining detection performance, providing an effective strategy for AI-assisted radiology report quality assurance.</li>
</ul>

<h3>Title: CCRS: A Zero-Shot LLM-as-a-Judge Framework for Comprehensive RAG Evaluation</h3>
<ul>
<li><strong>Authors: </strong>Aashiq Muhamed</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.20128">https://arxiv.org/abs/2506.20128</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.20128">https://arxiv.org/pdf/2506.20128</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.20128]] CCRS: A Zero-Shot LLM-as-a-Judge Framework for Comprehensive RAG Evaluation(https://arxiv.org/abs/2506.20128)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction</a></li>
<li><strong>Abstract: </strong>RAG systems enhance LLMs by incorporating external knowledge, which is crucial for domains that demand factual accuracy and up-to-date information. However, evaluating the multifaceted quality of RAG outputs, spanning aspects such as contextual coherence, query relevance, factual correctness, and informational completeness, poses significant challenges. Existing evaluation methods often rely on simple lexical overlap metrics, which are inadequate for capturing these nuances, or involve complex multi-stage pipelines with intermediate steps like claim extraction or require finetuning specialized judge models, hindering practical efficiency. To address these limitations, we propose CCRS (Contextual Coherence and Relevance Score), a novel suite of five metrics that utilizes a single, powerful, pretrained LLM as a zero-shot, end-to-end judge. CCRS evaluates: Contextual Coherence (CC), Question Relevance (QR), Information Density (ID), Answer Correctness (AC), and Information Recall (IR). We apply CCRS to evaluate six diverse RAG system configurations on the challenging BioASQ dataset. Our analysis demonstrates that CCRS effectively discriminates between system performances, confirming, for instance, that the Mistral-7B reader outperforms Llama variants. We provide a detailed analysis of CCRS metric properties, including score distributions, convergent/discriminant validity, tie rates, population statistics, and discriminative power. Compared to the complex RAGChecker framework, CCRS offers comparable or superior discriminative power for key aspects like recall and faithfulness, while being significantly more computationally efficient. CCRS thus provides a practical, comprehensive, and efficient framework for evaluating and iteratively improving RAG systems.</li>
</ul>

<h3>Title: From 2D to 3D Cognition: A Brief Survey of General World Models</h3>
<ul>
<li><strong>Authors: </strong>Ningwei Xie, Zizi Tian, Lei Yang, Xiao-Ping Zhang, Meng Guo, Jie Li</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.20134">https://arxiv.org/abs/2506.20134</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.20134">https://arxiv.org/pdf/2506.20134</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.20134]] From 2D to 3D Cognition: A Brief Survey of General World Models(https://arxiv.org/abs/2506.20134)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, generative</a></li>
<li><strong>Abstract: </strong>World models have garnered increasing attention in the development of artificial general intelligence (AGI), serving as computational frameworks for learning representations of the external world and forecasting future states. While early efforts focused on 2D visual perception and simulation, recent 3D-aware generative world models have demonstrated the ability to synthesize geometrically consistent, interactive 3D environments, marking a shift toward 3D spatial cognition. Despite rapid progress, the field lacks systematic analysis to categorize emerging techniques and clarify their roles in advancing 3D cognitive world models. This survey addresses this need by introducing a conceptual framework, providing a structured and forward-looking review of world models transitioning from 2D perception to 3D cognition. Within this framework, we highlight two key technological drivers, particularly advances in 3D representations and the incorporation of world knowledge, as fundamental pillars. Building on these, we dissect three core cognitive capabilities that underpin 3D world modeling: 3D physical scene generation, 3D spatial reasoning, and 3D spatial interaction. We further examine the deployment of these capabilities in real-world applications, including embodied AI, autonomous driving, digital twin, and gaming/VR. Finally, we identify challenges across data, modeling, and deployment, and outline future directions for advancing more robust and generalizable 3D world models.</li>
</ul>

<h3>Title: EAR: Erasing Concepts from Unified Autoregressive Models</h3>
<ul>
<li><strong>Authors: </strong>Haipeng Fan, Shiyuan Zhang, Baohunesitu, Zihang Guo, Huaiwen Zhang</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.20151">https://arxiv.org/abs/2506.20151</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.20151">https://arxiv.org/pdf/2506.20151</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.20151]] EAR: Erasing Concepts from Unified Autoregressive Models(https://arxiv.org/abs/2506.20151)</code><input type="text"></li>
<li><strong>Keywords: </strong>protect, large language model</a></li>
<li><strong>Abstract: </strong>Autoregressive (AR) models have achieved unified and strong performance across both visual understanding and image generation tasks. However, removing undesired concepts from AR models while maintaining overall generation quality remains an open challenge. In this paper, we propose Erasure Autoregressive Model (EAR), a fine-tuning method for effective and utility-preserving concept erasure in AR models. Specifically, we introduce Windowed Gradient Accumulation (WGA) strategy to align patch-level decoding with erasure objectives, and Thresholded Loss Masking (TLM) strategy to protect content unrelated to the target concept during fine-tuning. Furthermore, we propose a novel benchmark, Erase Concept Generator and Visual Filter (ECGVF), aim at provide a more rigorous and comprehensive foundation for evaluating concept erasure in AR models. Specifically, we first employ structured templates across diverse large language models (LLMs) to pre-generate a large-scale corpus of target-replacement concept prompt pairs. Subsequently, we generate images from these prompts and subject them to rigorous filtering via a visual classifier to ensure concept fidelity and alignment. Extensive experimental results conducted on the ECGVF benchmark with the AR model Janus-Pro demonstrate that EAR achieves marked improvements in both erasure effectiveness and model utility preservation. Code is available at: this https URL</li>
</ul>

<h3>Title: Towards Efficient Exemplar Based Image Editing with Multimodal VLMs</h3>
<ul>
<li><strong>Authors: </strong>Avadhoot Jadhav, Ashutosh Srivastava, Abhinav Java, Silky Singh, Tarun Ram Menta, Surgan Jandial, Balaji Krishnamurthy</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.20155">https://arxiv.org/abs/2506.20155</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.20155">https://arxiv.org/pdf/2506.20155</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.20155]] Towards Efficient Exemplar Based Image Editing with Multimodal VLMs(https://arxiv.org/abs/2506.20155)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>Text-to-Image Diffusion models have enabled a wide array of image editing applications. However, capturing all types of edits through text alone can be challenging and cumbersome. The ambiguous nature of certain image edits is better expressed through an exemplar pair, i.e., a pair of images depicting an image before and after an edit respectively. In this work, we tackle exemplar-based image editing -- the task of transferring an edit from an exemplar pair to a content image(s), by leveraging pretrained text-to-image diffusion models and multimodal VLMs. Even though our end-to-end pipeline is optimization-free, our experiments demonstrate that it still outperforms baselines on multiple types of edits while being ~4x faster.</li>
</ul>

<h3>Title: AALC: Large Language Model Efficient Reasoning via Adaptive Accuracy-Length Control</h3>
<ul>
<li><strong>Authors: </strong>Ruosen Li, Ziming Luo, Quan Zhang, Ruochen Li, Ben Zhou, Ali Payani, Xinya Du</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.20160">https://arxiv.org/abs/2506.20160</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.20160">https://arxiv.org/pdf/2506.20160</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.20160]] AALC: Large Language Model Efficient Reasoning via Adaptive Accuracy-Length Control(https://arxiv.org/abs/2506.20160)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability, large language model</a></li>
<li><strong>Abstract: </strong>Large reasoning models (LRMs) achieve impressive reasoning capabilities by generating lengthy chain-of-thoughts, but this "overthinking" incurs high latency and cost without commensurate accuracy gains. In this work, we introduce AALC, a lightweight, accuracy-aware length reward integrated into reinforcement learning that dynamically balances correctness and brevity during training. By incorporating validation accuracy into the reward and employing a smooth, dynamically scheduled length penalty, AALC delays length penalty until target performance is met. Through extensive experiments across standard and out-of-distribution math benchmarks, we show that our approach reduces response length by over 50% while maintaining or even improving the original accuracy. Furthermore, qualitative analysis reveals that our method curbs redundant reasoning patterns such as excessive subgoal setting and verification, leading to structurally refined outputs rather than naive truncation. We also identify that efficiency gains are accompanied by reduced interpretability: models trained with AALC omit some narrative framing and explanatory context. These findings highlight the potential of reward-based strategies to guide LRMs toward more efficient, generalizable reasoning paths.</li>
</ul>

<h3>Title: SEED: A Structural Encoder for Embedding-Driven Decoding in Time Series Prediction with LLMs</h3>
<ul>
<li><strong>Authors: </strong>Fengze Li, Yue Wang, Yangle Liu, Ming Huang, Dou Hong, Jieming Ma</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.20167">https://arxiv.org/abs/2506.20167</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.20167">https://arxiv.org/pdf/2506.20167</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.20167]] SEED: A Structural Encoder for Embedding-Driven Decoding in Time Series Prediction with LLMs(https://arxiv.org/abs/2506.20167)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction, large language model</a></li>
<li><strong>Abstract: </strong>Multivariate time series forecasting requires models to simultaneously capture variable-wise structural dependencies and generalize across diverse tasks. While structural encoders are effective in modeling feature interactions, they lack the capacity to support semantic-level reasoning or task adaptation. Conversely, large language models (LLMs) possess strong generalization capabilities but remain incompatible with raw time series inputs. This gap limits the development of unified, transferable prediction systems. Therefore, we introduce SEED, a structural encoder for embedding-driven decoding, which integrates four stages: a token-aware encoder for patch extraction, a projection module that aligns patches with language model embeddings, a semantic reprogramming mechanism that maps patches to task-aware prototypes, and a frozen language model for prediction. This modular architecture decouples representation learning from inference, enabling efficient alignment between numerical patterns and semantic reasoning. Empirical results demonstrate that the proposed method achieves consistent improvements over strong baselines, and comparative studies on various datasets confirm SEED's role in addressing the structural-semantic modeling gap.</li>
</ul>

<h3>Title: Seeing is Believing? Mitigating OCR Hallucinations in Multimodal Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Zhentao He, Can Zhang, Ziheng Wu, Zhenghao Chen, Yufei Zhan, Yifan Li, Zhao Zhang, Xian Wang, Minghui Qiu</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.20168">https://arxiv.org/abs/2506.20168</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.20168">https://arxiv.org/pdf/2506.20168</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.20168]] Seeing is Believing? Mitigating OCR Hallucinations in Multimodal Large Language Models(https://arxiv.org/abs/2506.20168)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, large language model</a></li>
<li><strong>Abstract: </strong>Recent advancements in multimodal large language models have enhanced document understanding by integrating textual and visual information. However, existing models exhibit incompleteness within their paradigm in real-world scenarios, particularly under visual degradation. In such conditions, the current response paradigm often fails to adequately perceive visual degradation and ambiguity, leading to overreliance on linguistic priors or misaligned visual-textual reasoning. This difficulty in recognizing uncertainty frequently results in the generation of hallucinatory content, especially when a precise answer is not feasible. To better demonstrate and analyze this phenomenon and problem, we propose KIE-HVQA, the first benchmark dedicated to evaluating OCR hallucination in degraded document understanding. This dataset includes test samples spanning identity cards and invoices, with simulated real-world degradations for OCR reliability. This setup allows for evaluating models' capacity, under degraded input, to distinguish reliable visual information and answer accordingly, thereby highlighting the challenge of avoiding hallucination on uncertain data. To achieve vision-faithful reasoning and thereby avoid the aforementioned issues, we further introduce a GRPO-based framework featuring a novel reward mechanism. By incorporating a self-awareness of visual uncertainty and an analysis method that initiates refusal to answer to increase task difficulty within our supervised fine-tuning and reinforcement learning framework, we successfully mitigated hallucinations in ambiguous regions. Experiments on Qwen2.5-VL demonstrate that our 7B-parameter model achieves a 22\% absolute improvement in hallucination-free accuracy over GPT-4o on KIE-HVQA and there is no significant performance drop in standard tasks, highlighting both effectiveness and robustness.</li>
</ul>

<h3>Title: JsDeObsBench: Measuring and Benchmarking LLMs for JavaScript Deobfuscation</h3>
<ul>
<li><strong>Authors: </strong>Guoqiang Chen, Xin Jin, Zhiqiang Lin</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.20170">https://arxiv.org/abs/2506.20170</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.20170">https://arxiv.org/pdf/2506.20170</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.20170]] JsDeObsBench: Measuring and Benchmarking LLMs for JavaScript Deobfuscation(https://arxiv.org/abs/2506.20170)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, robust, large language model</a></li>
<li><strong>Abstract: </strong>Deobfuscating JavaScript (JS) code poses a significant challenge in web security, particularly as obfuscation techniques are frequently used to conceal malicious activities within scripts. While Large Language Models (LLMs) have recently shown promise in automating the deobfuscation process, transforming detection and mitigation strategies against these obfuscated threats, a systematic benchmark to quantify their effectiveness and limitations has been notably absent. To address this gap, we present JsDeObsBench, a dedicated benchmark designed to rigorously evaluate the effectiveness of LLMs in the context of JS deobfuscation. We detail our benchmarking methodology, which includes a wide range of obfuscation techniques ranging from basic variable renaming to sophisticated structure transformations, providing a robust framework for assessing LLM performance in real-world scenarios. Our extensive experimental analysis investigates the proficiency of cutting-edge LLMs, e.g., GPT-4o, Mixtral, Llama, and DeepSeek-Coder, revealing superior performance in code simplification despite challenges in maintaining syntax accuracy and execution reliability compared to baseline methods. We further evaluate the deobfuscation of JS malware to exhibit the potential of LLMs in security scenarios. The findings highlight the utility of LLMs in deobfuscation applications and pinpoint crucial areas for further improvement.</li>
</ul>

<h3>Title: Towards Scalable and Generalizable Earth Observation Data Mining via Foundation Model Composition</h3>
<ul>
<li><strong>Authors: </strong>Man Duc Chuc</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.20174">https://arxiv.org/abs/2506.20174</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.20174">https://arxiv.org/pdf/2506.20174</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.20174]] Towards Scalable and Generalizable Earth Observation Data Mining via Foundation Model Composition(https://arxiv.org/abs/2506.20174)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>Foundation models are rapidly transforming Earth Observation data mining by enabling generalizable and scalable solutions for key tasks such as scene classification and semantic segmentation. While most efforts in the geospatial domain have focused on developing large models trained from scratch using massive Earth Observation datasets, an alternative strategy that remains underexplored is the reuse and combination of existing pretrained models. In this study, we investigate whether foundation models pretrained on remote sensing and general vision datasets can be effectively combined to improve performance across a diverse set of key Earth Observation tasks. Using the GEO-Bench benchmark, we evaluate several prominent models, including Prithvi, Hiera, and DOFA, on eleven datasets covering a range of spatial resolutions, sensor modalities, and task types. The results show that feature-level ensembling of smaller pretrained models can match or exceed the performance of much larger models, while requiring less training time and computational resources. Moreover, the study highlights the potential of applying knowledge distillation to transfer the strengths of ensembles into more compact models, offering a practical path for deploying foundation models in real-world Earth Observation applications.</li>
</ul>

<h3>Title: COIN: Uncertainty-Guarding Selective Question Answering for Foundation Models with Provable Risk Guarantees</h3>
<ul>
<li><strong>Authors: </strong>Zhiyuan Wang, Jinhao Duan, Qingni Wang, Xiaofeng Zhu, Tianlong Chen, Xiaoshuang Shi, Kaidi Xu</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.20178">https://arxiv.org/abs/2506.20178</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.20178">https://arxiv.org/pdf/2506.20178</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.20178]] COIN: Uncertainty-Guarding Selective Question Answering for Foundation Models with Provable Risk Guarantees(https://arxiv.org/abs/2506.20178)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Uncertainty quantification (UQ) for foundation models is essential to identify and mitigate potential hallucinations in automatically generated text. However, heuristic UQ approaches lack formal guarantees for key metrics such as the false discovery rate (FDR) in selective prediction. Previous work adopts the split conformal prediction (SCP) framework to ensure desired coverage of admissible answers by constructing prediction sets, but these sets often contain incorrect candidates, limiting their practical utility. To address this, we propose COIN, an uncertainty-guarding selection framework that calibrates statistically valid thresholds to filter a single generated answer per question under user-specified FDR constraints. COIN estimates the empirical error rate on a calibration set and applies confidence interval methods such as Clopper-Pearson to establish a high-probability upper bound on the true error rate (i.e., FDR). This enables the selection of the largest uncertainty threshold that ensures FDR control on test data while significantly increasing sample retention. We demonstrate COIN's robustness in risk control, strong test-time power in retaining admissible answers, and predictive efficiency under limited calibration data across both general and multimodal text generation tasks. Furthermore, we show that employing alternative upper bound constructions and UQ strategies can further boost COIN's power performance, which underscores its extensibility and adaptability to diverse application scenarios.</li>
</ul>

<h3>Title: Progressive Alignment Degradation Learning for Pansharpening</h3>
<ul>
<li><strong>Authors: </strong>Enzhe Zhao, Zhichang Guo, Yao Li, Fanghui Song, Boying Wu</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI, eess.IV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.20179">https://arxiv.org/abs/2506.20179</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.20179">https://arxiv.org/pdf/2506.20179</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.20179]] Progressive Alignment Degradation Learning for Pansharpening(https://arxiv.org/abs/2506.20179)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction, diffusion</a></li>
<li><strong>Abstract: </strong>Deep learning-based pansharpening has been shown to effectively generate high-resolution multispectral (HRMS) images. To create supervised ground-truth HRMS images, synthetic data generated using the Wald protocol is commonly employed. This protocol assumes that networks trained on artificial low-resolution data will perform equally well on high-resolution data. However, well-trained models typically exhibit a trade-off in performance between reduced-resolution and full-resolution datasets. In this paper, we delve into the Wald protocol and find that its inaccurate approximation of real-world degradation patterns limits the generalization of deep pansharpening models. To address this issue, we propose the Progressive Alignment Degradation Module (PADM), which uses mutual iteration between two sub-networks, PAlignNet and PDegradeNet, to adaptively learn accurate degradation processes without relying on predefined operators. Building on this, we introduce HFreqdiff, which embeds high-frequency details into a diffusion framework and incorporates CFB and BACM modules for frequency-selective detail extraction and precise reverse process learning. These innovations enable effective integration of high-resolution panchromatic and multispectral images, significantly enhancing spatial sharpness and quality. Experiments and ablation studies demonstrate the proposed method's superior performance compared to state-of-the-art techniques.</li>
</ul>

<h3>Title: Causal Operator Discovery in Partial Differential Equations via Counterfactual Physics-Informed Neural Networks</h3>
<ul>
<li><strong>Authors: </strong>Ronald Katende</a></li>
<li><strong>Subjects: </strong>cs.LG, math.NA</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.20181">https://arxiv.org/abs/2506.20181</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.20181">https://arxiv.org/pdf/2506.20181</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.20181]] Causal Operator Discovery in Partial Differential Equations via Counterfactual Physics-Informed Neural Networks(https://arxiv.org/abs/2506.20181)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>We develop a principled framework for discovering causal structure in partial differential equations (PDEs) using physics-informed neural networks and counterfactual perturbations. Unlike classical residual minimization or sparse regression methods, our approach quantifies operator-level necessity through functional interventions on the governing dynamics. We introduce causal sensitivity indices and structural deviation metrics to assess the influence of candidate differential operators within neural surrogates. Theoretically, we prove exact recovery of the causal operator support under restricted isometry or mutual coherence conditions, with residual bounds guaranteeing identifiability. Empirically, we validate the framework on both synthetic and real-world datasets across climate dynamics, tumor diffusion, and ocean flows. Our method consistently recovers governing operators even under noise, redundancy, and data scarcity, outperforming standard PINNs and DeepONets in structural fidelity. This work positions causal PDE discovery as a tractable and interpretable inference task grounded in structural causal models and variational residual analysis.</li>
</ul>

<h3>Title: DuoGPT: Training-free Dual Sparsity through Activation-aware Pruning in LLMs</h3>
<ul>
<li><strong>Authors: </strong>Ruokai Yin, Yuhang Li, Donghyun Lee, Priyadarshini Panda</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.20194">https://arxiv.org/abs/2506.20194</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.20194">https://arxiv.org/pdf/2506.20194</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.20194]] DuoGPT: Training-free Dual Sparsity through Activation-aware Pruning in LLMs(https://arxiv.org/abs/2506.20194)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large language models (LLMs) deliver strong performance but are difficult to deploy due to high memory and compute costs. While pruning reduces these demands, most methods ignore activation sparsity observed at runtime. We reinterpret activation sparsity as dynamic structured weight sparsity and propose DuoGPT, a unified framework that constructs dual-sparse (spMspV) workloads by combining unstructured weight pruning with activation sparsity. To preserve accuracy, we extend the Optimal Brain Compression (OBC) framework with activation-aware calibration and introduce output residuals from the dense model as correction terms. We further optimize the solution for efficient GPU execution, enabling scalability to billion-parameter LLMs. Evaluations on LLaMA-2 and LLaMA-3 show that DuoGPT outperforms state-of-the-art structured pruning methods by up to 9.17% accuracy at an iso-speedup of 1.39$\times$ compared to the baseline dense model.</li>
</ul>

<h3>Title: Zero-Shot Attribution for Large Language Models: A Distribution Testing Approach</h3>
<ul>
<li><strong>Authors: </strong>Clément L. Canonne, Yash Pote, Uddalok Sarkar</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.20197">https://arxiv.org/abs/2506.20197</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.20197">https://arxiv.org/pdf/2506.20197</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.20197]] Zero-Shot Attribution for Large Language Models: A Distribution Testing Approach(https://arxiv.org/abs/2506.20197)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>A growing fraction of all code is sampled from Large Language Models (LLMs). We investigate the problem of attributing code generated by language models using hypothesis testing to leverage established techniques and guarantees. Given a set of samples $S$ and a suspect model $\mathcal{L}^*$, our goal is to assess the likelihood of $S$ originating from $\mathcal{L}^*$. Due to the curse of dimensionality, this is intractable when only samples from the LLM are given: to circumvent this, we use both samples and density estimates from the LLM, a form of access commonly available. We introduce $\mathsf{Anubis}$, a zero-shot attribution tool that frames attribution as a distribution testing problem. Our experiments on a benchmark of code samples show that $\mathsf{Anubis}$ achieves high AUROC scores ( $\ge0.9$) when distinguishing between LLMs like DeepSeek-Coder, CodeGemma, and Stable-Code using only $\approx 2000$ samples.</li>
</ul>

<h3>Title: How to Retrieve Examples in In-context Learning to Improve Conversational Emotion Recognition using Large Language Models?</h3>
<ul>
<li><strong>Authors: </strong>Mengqi Wang, Tiantian Feng, Shrikanth Narayanan</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.20199">https://arxiv.org/abs/2506.20199</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.20199">https://arxiv.org/pdf/2506.20199</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.20199]] How to Retrieve Examples in In-context Learning to Improve Conversational Emotion Recognition using Large Language Models?(https://arxiv.org/abs/2506.20199)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large language models (LLMs) have enabled a wide variety of real-world applications in various domains. However, creating a high-performing application with high accuracy remains challenging, particularly for subjective tasks like emotion recognition. Inspired by the SLT 2024 GenSER Challenge, this study investigates approaches to improving conversational emotion recognition (CER) by LLMs. Specifically, we explore how to retrieve high-quality examples in in-context learning (ICL) to enhance CER. We propose various strategies based on random and augmented example retrieval and also analyze the impact of conversational context on CER accuracy. Experiments were conducted on the three datasets including IEMOCAP, MELD and EmoryNLP. The results show that augmented example retrieval consistently outperforms other techniques under investigation across all datasets, highlighting the importance of retrieving coherent targeted examples and enhancing them through paraphrasing.</li>
</ul>

<h3>Title: Affective Priming Score: A Data-Driven Method to Detect Priming in Sequential Datasets</h3>
<ul>
<li><strong>Authors: </strong>Eduardo Gutierrez Maestro, Hadi Banaee, Amy Loutfi</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.20204">https://arxiv.org/abs/2506.20204</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.20204">https://arxiv.org/pdf/2506.20204</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.20204]] Affective Priming Score: A Data-Driven Method to Detect Priming in Sequential Datasets(https://arxiv.org/abs/2506.20204)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Affective priming exemplifies the challenge of ambiguity in affective computing. While the community has largely addressed this issue from a label-based perspective, identifying data points in the sequence affected by the priming effect, the impact of priming on data itself, particularly in physiological signals, remains underexplored. Data affected by priming can lead to misclassifications when used in learning models. This study proposes the Affective Priming Score (APS), a data-driven method to detect data points influenced by the priming effect. The APS assigns a score to each data point, quantifying the extent to which it is affected by priming. To validate this method, we apply it to the SEED and SEED-VII datasets, which contain sufficient transitions between emotional events to exhibit priming effects. We train models with the same configuration using both the original data and priming-free sequences. The misclassification rate is significantly reduced when using priming-free sequences compared to the original data. This work contributes to the broader challenge of ambiguity by identifying and mitigating priming effects at the data level, enhancing model robustness, and offering valuable insights for the design and collection of affective computing datasets.</li>
</ul>

<h3>Title: UniCode$^2$: Cascaded Large-scale Codebooks for Unified Multimodal Understanding and Generation</h3>
<ul>
<li><strong>Authors: </strong>Yanzhe Chen (Yen-chieh Chan), Huasong Zhong, Yan Li, Zhenheng Yang</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.MM</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.20214">https://arxiv.org/abs/2506.20214</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.20214">https://arxiv.org/pdf/2506.20214</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.20214]] UniCode$^2$: Cascaded Large-scale Codebooks for Unified Multimodal Understanding and Generation(https://arxiv.org/abs/2506.20214)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, diffusion, large language model</a></li>
<li><strong>Abstract: </strong>Unified multimodal large language models (MLLMs) have shown promise in jointly advancing multimodal understanding and generation, with visual codebooks discretizing images into tokens for autoregressive modeling. Existing codebook-based methods either rely on small vocabularies (~16K entries) that lack fine-grained semantics or naively scale up, resulting in low token utilization and unstable training. We propose UniCode$^2$, a cascaded codebook framework enabling large-scale, semantically aligned, and stable visual tokenization. By clustering millions of SigLIP sequence embeddings, we build a 500K-entry codebook that preserves vision-language alignment while expanding capacity. Stability is ensured via a cascaded design: a frozen codebook anchors the embedding space, and a trainable codebook refines task-specific semantics. This decoupling promotes high utilization and robust learning. Moreover, the alignment of our visual tokens with textual semantics enables seamless integration with pretrained diffusion decoders, supporting high-quality visual synthesis with minimal adaptation. UniCode^2 delivers strong performance across diverse benchmarks, demonstrating the viability of scaling visual token spaces without sacrificing stability, semantics, or modularity.</li>
</ul>

<h3>Title: Measuring Modern Phishing Tactics: A Quantitative Study of Body Obfuscation Prevalence, Co-occurrence, and Filter Impact</h3>
<ul>
<li><strong>Authors: </strong>Antony Dalmiere (LAAS), Zheng Zhou (LAAS), Guillaume Auriol (LAAS-TRUST, INSA Toulouse), Vincent Nicomette (LAAS-TSF, LAAS-TRUST), Pascal Marchand (LERASS, IUT Paul Sabatier)</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.20228">https://arxiv.org/abs/2506.20228</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.20228">https://arxiv.org/pdf/2506.20228</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.20228]] Measuring Modern Phishing Tactics: A Quantitative Study of Body Obfuscation Prevalence, Co-occurrence, and Filter Impact(https://arxiv.org/abs/2506.20228)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack</a></li>
<li><strong>Abstract: </strong>Phishing attacks frequently use email body obfuscation to bypass detection filters, but quantitative insights into how techniques are combined and their impact on filter scores remain limited. This paper addresses this gap by empirically investigating the prevalence, co-occurrence patterns, and spam score associations of body obfuscation techniques. Analysing 386 verified phishing emails, we quantified ten techniques, identified significant pairwise co-occurrences revealing strategic layering like the presence of text in images with multipart abuse, and assessed associations with antispam scores using multilinear regression. Text in Image (47.0%), Base64 Encoding (31.2%), and Invalid HTML (28.8%) were highly prevalent. Regression (R${}^2$=0.486, p<0.001) linked Base64 Encoding and Text in Image with significant antispam evasion (p<0.05) in this configuration, suggesting potential bypass capabilities, while Invalid HTML correlated with higher scores. These findings establish a quantitative baseline for complex evasion strategies, underscoring the need for multi-modal defences against combined obfuscation tactics.</li>
</ul>

<h3>Title: Communication-Efficient Publication of Sparse Vectors under Differential Privacy</h3>
<ul>
<li><strong>Authors: </strong>Quentin Hillebrand, Vorapong Suppakitpaisarn, Tetsuo Shibuya</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.20234">https://arxiv.org/abs/2506.20234</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.20234">https://arxiv.org/pdf/2506.20234</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.20234]] Communication-Efficient Publication of Sparse Vectors under Differential Privacy(https://arxiv.org/abs/2506.20234)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy</a></li>
<li><strong>Abstract: </strong>In this work, we propose a differentially private algorithm for publishing matrices aggregated from sparse vectors. These matrices include social network adjacency matrices, user-item interaction matrices in recommendation systems, and single nucleotide polymorphisms (SNPs) in DNA data. Traditionally, differential privacy in vector collection relies on randomized response, but this approach incurs high communication costs. Specifically, for a matrix with $N$ users, $n$ columns, and $m$ nonzero elements, conventional methods require $\Omega(n \times N)$ communication, making them impractical for large-scale data. Our algorithm significantly reduces this cost to $O(\varepsilon m)$, where $\varepsilon$ is the privacy budget. Notably, this is even lower than the non-private case, which requires $\Omega(m \log n)$ communication. Moreover, as the privacy budget decreases, communication cost further reduces, enabling better privacy with improved efficiency. We theoretically prove that our method yields results identical to those of randomized response, and experimental evaluations confirm its effectiveness in terms of accuracy, communication efficiency, and computational complexity.</li>
</ul>

<h3>Title: Enhancing Large Language Models through Structured Reasoning</h3>
<ul>
<li><strong>Authors: </strong>Yubo Dong, Hehe Fan</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.20241">https://arxiv.org/abs/2506.20241</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.20241">https://arxiv.org/pdf/2506.20241</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.20241]] Enhancing Large Language Models through Structured Reasoning(https://arxiv.org/abs/2506.20241)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, large language model</a></li>
<li><strong>Abstract: </strong>Recent Large Language Models (LLMs) have significantly advanced natural language processing and automated decision-making. However, these models still encounter difficulties when performing complex reasoning tasks involving logical deduction and systematic planning, primarily due to their reliance on implicit statistical relationships without structured knowledge this http URL by cognitive science and neurosymbolic AI, we introduce a novel approach to enhance LLMs through explicit structured reasoning. First, we convert unstructured data into structured formats by explicitly annotating reasoning steps. We then employ this structured dataset to train LLMs through Supervised Fine-Tuning (SFT). Additionally, we enhance the structured reasoning capabilities of LLMs using Group Relative Policy Optimization (GRPO), incorporating two innovative algorithms--MAX-Flow and Longest Common Subsequence (LCS)--which notably improve reasoning effectiveness and reduce computational complexity. Experimental results from fine-tuning a DeepSeek-R1-Distill-Qwen-1.5B model demonstrate concise reasoning, robust performance across various scenarios, and improved compatibility with optimization techniques, validating the efficacy of structured reasoning integration in LLMs.</li>
</ul>

<h3>Title: CBF-AFA: Chunk-Based Multi-SSL Fusion for Automatic Fluency Assessment</h3>
<ul>
<li><strong>Authors: </strong>Papa Séga Wade, Mihai Andries, Ioannis Kanellos, Thierry Moudenc</a></li>
<li><strong>Subjects: </strong>cs.CL, eess.AS</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.20243">https://arxiv.org/abs/2506.20243</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.20243">https://arxiv.org/pdf/2506.20243</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.20243]] CBF-AFA: Chunk-Based Multi-SSL Fusion for Automatic Fluency Assessment(https://arxiv.org/abs/2506.20243)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, segmentation</a></li>
<li><strong>Abstract: </strong>Automatic fluency assessment (AFA) remains challenging, particularly in capturing speech rhythm, pauses, and disfluencies in non-native speakers. We introduce a chunk-based approach integrating self-supervised learning (SSL) models (Wav2Vec2, HuBERT, and WavLM) selected for their complementary strengths in phonetic, prosodic, and noisy speech modeling, with a hierarchical CNN-BiLSTM framework. Speech is segmented into breath-group chunks using Silero voice activity detection (Silero-VAD), enabling fine-grained temporal analysis while mitigating over-segmentation artifacts. SSL embeddings are fused via a learnable weighted mechanism, balancing acoustic and linguistic features, and enriched with chunk-level fluency markers (e.g., speech rate, pause durations, n-gram repetitions). The CNN-BiLSTM captures local and long-term dependencies across chunks. Evaluated on Avalinguo and Speechocean762, our approach improves F1-score by 2.8 and Pearson correlation by 6.2 points over single SSL baselines on Speechocean762, with gains of 4.2 F1-score and 4.0 Pearson points on Avalinguo, surpassing this http URL-based segmentation baselines. These findings highlight chunk-based multi-SSL fusion for robust fluency evaluation, though future work should explore generalization to dialects with irregular prosody.</li>
</ul>

<h3>Title: FedBKD: Distilled Federated Learning to Embrace Gerneralization and Personalization on Non-IID Data</h3>
<ul>
<li><strong>Authors: </strong>Yushan Zhao, Jinyuan He, Donglai Chen, Weijie Luo, Chong Xie, Ri Zhang, Yonghong Chen, Yan Xu</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.20245">https://arxiv.org/abs/2506.20245</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.20245">https://arxiv.org/pdf/2506.20245</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.20245]] FedBKD: Distilled Federated Learning to Embrace Gerneralization and Personalization on Non-IID Data(https://arxiv.org/abs/2506.20245)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, federate, data-free, generative</a></li>
<li><strong>Abstract: </strong>Federated learning (FL) is a decentralized collaborative machine learning (ML) technique. It provides a solution to the issues of isolated data islands and data privacy leakage in industrial ML practices. One major challenge in FL is handling the non-identical and independent distributed (non-IID) data. Current solutions either focus on constructing an all-powerful global model, or customizing personalized local models. Few of them can provide both a well-generalized global model and well-performed local models at the same time. Additionally, many FL solutions to the non-IID problem are benefited from introducing public datasets. However, this will also increase the risk of data leakage. To tackle the problems, we propose a novel data-free distillation framework, Federated Bidirectional Knowledge Distillation (FedBKD). Specifically, we train Generative Adversarial Networks (GAN) for synthetic data. During the GAN training, local models serve as discriminators and their parameters are frozen. The synthetic data is then used for bidirectional distillation between global and local models to achieve knowledge interactions so that performances for both sides are improved. We conduct extensive experiments on 4 benchmarks under different non-IID settings. The results show that FedBKD achieves SOTA performances in every case.</li>
</ul>

<h3>Title: Q-resafe: Assessing Safety Risks and Quantization-aware Safety Patching for Quantized Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Kejia Chen, Jiawen Zhang, Jiacong Hu, Yu Wang, Jian Lou, Zunlei Feng, Mingli Song</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.20251">https://arxiv.org/abs/2506.20251</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.20251">https://arxiv.org/pdf/2506.20251</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.20251]] Q-resafe: Assessing Safety Risks and Quantization-aware Safety Patching for Quantized Large Language Models(https://arxiv.org/abs/2506.20251)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Quantized large language models (LLMs) have gained increasing attention and significance for enabling deployment in resource-constrained environments. However, emerging studies on a few calibration dataset-free quantization methods suggest that quantization may compromise the safety capabilities of LLMs, underscoring the urgent need for systematic safety evaluations and effective mitigation strategies. In this paper, we present comprehensive safety evaluations across various mainstream quantization techniques and diverse calibration datasets, utilizing widely accepted safety benchmarks. To address the identified safety vulnerabilities, we propose a quantization-aware safety patching framework, Q-resafe, to efficiently restore the safety capabilities of quantized LLMs while minimizing any adverse impact on utility. Extensive experimental results demonstrate that Q-resafe successfully re-aligns the safety of quantized LLMs with their pre-quantization counterparts, even under challenging evaluation scenarios. Project page is available at: this https URL.</li>
</ul>

<h3>Title: Time-series surrogates from energy consumers generated by machine learning approaches for long-term forecasting scenarios</h3>
<ul>
<li><strong>Authors: </strong>Ben Gerhards, Nikita Popkov, Annekatrin König, Marcel Arpogaus, Bastian Schäfermeier, Leonie Riedl, Stephan Vogt, Philip Hehlert</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.20253">https://arxiv.org/abs/2506.20253</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.20253">https://arxiv.org/pdf/2506.20253</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.20253]] Time-series surrogates from energy consumers generated by machine learning approaches for long-term forecasting scenarios(https://arxiv.org/abs/2506.20253)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, diffusion, generative</a></li>
<li><strong>Abstract: </strong>Forecasting attracts a lot of research attention in the electricity value chain. However, most studies concentrate on short-term forecasting of generation or consumption with a focus on systems and less on individual consumers. Even more neglected is the topic of long-term forecasting of individual power consumption. Here, we provide an in-depth comparative evaluation of data-driven methods for generating synthetic time series data tailored to energy consumption long-term forecasting. High-fidelity synthetic data is crucial for a wide range of applications, including state estimations in energy systems or power grid planning. In this study, we assess and compare the performance of multiple state-of-the-art but less common techniques: a hybrid Wasserstein Generative Adversarial Network (WGAN), Denoising Diffusion Probabilistic Model (DDPM), Hidden Markov Model (HMM), and Masked Autoregressive Bernstein polynomial normalizing Flows (MABF). We analyze the ability of each method to replicate the temporal dynamics, long-range dependencies, and probabilistic transitions characteristic of individual energy consumption profiles. Our comparative evaluation highlights the strengths and limitations of: WGAN, DDPM, HMM and MABF aiding in selecting the most suitable approach for state estimations and other energy-related tasks. Our generation and analysis framework aims to enhance the accuracy and reliability of synthetic power consumption data while generating data that fulfills criteria like anonymisation - preserving privacy concerns mitigating risks of specific profiling of single customers. This study utilizes an open-source dataset from households in Germany with 15min time resolution. The generated synthetic power profiles can readily be used in applications like state estimations or consumption forecasting.</li>
</ul>

<h3>Title: Recognizing Surgical Phases Anywhere: Few-Shot Test-time Adaptation and Task-graph Guided Refinement</h3>
<ul>
<li><strong>Authors: </strong>Kun Yuan, Tingxuan Chen, Shi Li, Joel L. Lavanchy, Christian Heiliger, Ege Özsoy, Yiming Huang, Long Bai, Nassir Navab, Vinkle Srivastav, Hongliang Ren, Nicolas Padoy</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.20254">https://arxiv.org/abs/2506.20254</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.20254">https://arxiv.org/pdf/2506.20254</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.20254]] Recognizing Surgical Phases Anywhere: Few-Shot Test-time Adaptation and Task-graph Guided Refinement(https://arxiv.org/abs/2506.20254)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>The complexity and diversity of surgical workflows, driven by heterogeneous operating room settings, institutional protocols, and anatomical variability, present a significant challenge in developing generalizable models for cross-institutional and cross-procedural surgical understanding. While recent surgical foundation models pretrained on large-scale vision-language data offer promising transferability, their zero-shot performance remains constrained by domain shifts, limiting their utility in unseen surgical environments. To address this, we introduce Surgical Phase Anywhere (SPA), a lightweight framework for versatile surgical workflow understanding that adapts foundation models to institutional settings with minimal annotation. SPA leverages few-shot spatial adaptation to align multi-modal embeddings with institution-specific surgical scenes and phases. It also ensures temporal consistency through diffusion modeling, which encodes task-graph priors derived from institutional procedure protocols. Finally, SPA employs dynamic test-time adaptation, exploiting the mutual agreement between multi-modal phase prediction streams to adapt the model to a given test video in a self-supervised manner, enhancing the reliability under test-time distribution shifts. SPA is a lightweight adaptation framework, allowing hospitals to rapidly customize phase recognition models by defining phases in natural language text, annotating a few images with the phase labels, and providing a task graph defining phase transitions. The experimental results show that the SPA framework achieves state-of-the-art performance in few-shot surgical phase recognition across multiple institutions and procedures, even outperforming full-shot models with 32-shot labeled data. Code is available at this https URL</li>
</ul>

<h3>Title: A Transformer Based Handwriting Recognition System Jointly Using Online and Offline Features</h3>
<ul>
<li><strong>Authors: </strong>Ayush Lodh, Ritabrata Chakraborty, Shivakumara Palaiahnakote, Umapada Pal</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.20255">https://arxiv.org/abs/2506.20255</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.20255">https://arxiv.org/pdf/2506.20255</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.20255]] A Transformer Based Handwriting Recognition System Jointly Using Online and Offline Features(https://arxiv.org/abs/2506.20255)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>We posit that handwriting recognition benefits from complementary cues carried by the rasterized complex glyph and the pen's trajectory, yet most systems exploit only one modality. We introduce an end-to-end network that performs early fusion of offline images and online stroke data within a shared latent space. A patch encoder converts the grayscale crop into fixed-length visual tokens, while a lightweight transformer embeds the $(x, y, \text{pen})$ sequence. Learnable latent queries attend jointly to both token streams, yielding context-enhanced stroke embeddings that are pooled and decoded under a cross-entropy loss objective. Because integration occurs before any high-level classification, temporal cues reinforce each other during representation learning, producing stronger writer independence. Comprehensive experiments on IAMOn-DB and VNOn-DB demonstrate that our approach achieves state-of-the-art accuracy, exceeding previous bests by up to 1\%. Our study also shows adaptation of this pipeline with gesturification on the ISI-Air dataset. Our code can be found here.</li>
</ul>

<h3>Title: Argumentative Ensembling for Robust Recourse under Model Multiplicity</h3>
<ul>
<li><strong>Authors: </strong>Junqi Jiang, Antonio Rago, Francesco Leofante, Francesca Toni</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.MA</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.20260">https://arxiv.org/abs/2506.20260</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.20260">https://arxiv.org/pdf/2506.20260</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.20260]] Argumentative Ensembling for Robust Recourse under Model Multiplicity(https://arxiv.org/abs/2506.20260)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>In machine learning, it is common to obtain multiple equally performing models for the same prediction task, e.g., when training neural networks with different random seeds. Model multiplicity (MM) is the situation which arises when these competing models differ in their predictions for the same input, for which ensembling is often employed to determine an aggregation of the outputs. Providing recourse recommendations via counterfactual explanations (CEs) under MM thus becomes complex, since the CE may not be valid across all models, i.e., the CEs are not robust under MM. In this work, we formalise the problem of providing recourse under MM, which we name recourse-aware ensembling (RAE). We propose the idea that under MM, CEs for each individual model should be considered alongside their predictions so that the aggregated prediction and recourse are decided in tandem. Centred around this intuition, we introduce six desirable properties for solutions to this problem. For solving RAE, we propose a novel argumentative ensembling method which guarantees the robustness of CEs under MM. Specifically, our method leverages computational argumentation to explicitly represent the conflicts between models and counterfactuals regarding prediction results and CE validity. It then uses argumentation semantics to resolve the conflicts and obtain the final solution, in a manner which is parametric to the chosen semantics. Our method also allows for the specification of preferences over the models under MM, allowing further customisation of the ensemble. In a comprehensive theoretical analysis, we characterise the behaviour of argumentative ensembling with four different argumentation semantics. We then empirically demonstrate the effectiveness of our approach in satisfying desirable properties with eight instantiations of our method. (Abstract is shortened for arXiv.)</li>
</ul>

<h3>Title: Hierarchical Mask-Enhanced Dual Reconstruction Network for Few-Shot Fine-Grained Image Classification</h3>
<ul>
<li><strong>Authors: </strong>Ning Luo, Meiyin Hu, Huan Wan, Yanyan Yang, Zhuohang Jiang, Xin Wei</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.20263">https://arxiv.org/abs/2506.20263</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.20263">https://arxiv.org/pdf/2506.20263</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.20263]] Hierarchical Mask-Enhanced Dual Reconstruction Network for Few-Shot Fine-Grained Image Classification(https://arxiv.org/abs/2506.20263)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Few-shot fine-grained image classification (FS-FGIC) presents a significant challenge, requiring models to distinguish visually similar subclasses with limited labeled examples. Existing methods have critical limitations: metric-based methods lose spatial information and misalign local features, while reconstruction-based methods fail to utilize hierarchical feature information and lack mechanisms to focus on discriminative regions. We propose the Hierarchical Mask-enhanced Dual Reconstruction Network (HMDRN), which integrates dual-layer feature reconstruction with mask-enhanced feature processing to improve fine-grained classification. HMDRN incorporates a dual-layer feature reconstruction and fusion module that leverages complementary visual information from different network hierarchies. Through learnable fusion weights, the model balances high-level semantic representations from the last layer with mid-level structural details from the penultimate layer. Additionally, we design a spatial binary mask-enhanced transformer self-reconstruction module that processes query features through adaptive thresholding while maintaining complete support features, enhancing focus on discriminative regions while filtering background noise. Extensive experiments on three challenging fine-grained datasets demonstrate that HMDRN consistently outperforms state-of-the-art methods across Conv-4 and ResNet-12 backbone architectures. Comprehensive ablation studies validate the effectiveness of each proposed component, revealing that dual-layer reconstruction enhances inter-class discrimination while mask-enhanced transformation reduces intra-class variations. Visualization results provide evidence of HMDRN's superior feature reconstruction capabilities.</li>
</ul>

<h3>Title: Narrative Shift Detection: A Hybrid Approach of Dynamic Topic Models and Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Kai-Robin Lange, Tobias Schmidt, Matthias Reccius, Henrik Müller, Michael Roos, Carsten Jentsch</a></li>
<li><strong>Subjects: </strong>cs.CL, econ.GN</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.20269">https://arxiv.org/abs/2506.20269</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.20269">https://arxiv.org/pdf/2506.20269</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.20269]] Narrative Shift Detection: A Hybrid Approach of Dynamic Topic Models and Large Language Models(https://arxiv.org/abs/2506.20269)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction, large language model</a></li>
<li><strong>Abstract: </strong>With rapidly evolving media narratives, it has become increasingly critical to not just extract narratives from a given corpus but rather investigate, how they develop over time. While popular narrative extraction methods such as Large Language Models do well in capturing typical narrative elements or even the complex structure of a narrative, applying them to an entire corpus comes with obstacles, such as a high financial or computational cost. We propose a combination of the language understanding capabilities of Large Language Models with the large scale applicability of topic models to dynamically model narrative shifts across time using the Narrative Policy Framework. We apply a topic model and a corresponding change point detection method to find changes that concern a specific topic of interest. Using this model, we filter our corpus for documents that are particularly representative of that change and feed them into a Large Language Model that interprets the change that happened in an automated fashion and distinguishes between content and narrative shifts. We employ our pipeline on a corpus of The Wall Street Journal news paper articles from 2009 to 2023. Our findings indicate that a Large Language Model can efficiently extract a narrative shift if one exists at a given point in time, but does not perform as well when having to decide whether a shift in content or a narrative shift took place.</li>
</ul>

<h3>Title: Forensic Study of Paintings Through the Comparison of Fabrics</h3>
<ul>
<li><strong>Authors: </strong>Juan José Murillo-Fuentes, Pablo M. Olmos, Laura Alba-Carcelén</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.20272">https://arxiv.org/abs/2506.20272</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.20272">https://arxiv.org/pdf/2506.20272</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.20272]] Forensic Study of Paintings Through the Comparison of Fabrics(https://arxiv.org/abs/2506.20272)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>The study of canvas fabrics in works of art is a crucial tool for authentication, attribution and conservation. Traditional methods are based on thread density map matching, which cannot be applied when canvases do not come from contiguous positions on a roll. This paper presents a novel approach based on deep learning to assess the similarity of textiles. We introduce an automatic tool that evaluates the similarity between canvases without relying on thread density maps. A Siamese deep learning model is designed and trained to compare pairs of images by exploiting the feature representations learned from the scans. In addition, a similarity estimation method is proposed, aggregating predictions from multiple pairs of cloth samples to provide a robust similarity score. Our approach is applied to canvases from the Museo Nacional del Prado, corroborating the hypothesis that plain weave canvases, widely used in painting, can be effectively compared even when their thread densities are similar. The results demonstrate the feasibility and accuracy of the proposed method, opening new avenues for the analysis of masterpieces.</li>
</ul>

<h3>Title: From Ideal to Real: Unified and Data-Efficient Dense Prediction for Real-World Scenarios</h3>
<ul>
<li><strong>Authors: </strong>Changliang Xia, Chengyou Jia, Zhuohang Dang, Minnan Luo</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.20279">https://arxiv.org/abs/2506.20279</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.20279">https://arxiv.org/pdf/2506.20279</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.20279]] From Ideal to Real: Unified and Data-Efficient Dense Prediction for Real-World Scenarios(https://arxiv.org/abs/2506.20279)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>Dense prediction tasks hold significant importance of computer vision, aiming to learn pixel-wise annotated label for an input image. Despite advances in this field, existing methods primarily focus on idealized conditions, with limited generalization to real-world scenarios and facing the challenging scarcity of real-world data. To systematically study this problem, we first introduce DenseWorld, a benchmark spanning a broad set of 25 dense prediction tasks that correspond to urgent real-world applications, featuring unified evaluation across tasks. Then, we propose DenseDiT, which maximally exploits generative models' visual priors to perform diverse real-world dense prediction tasks through a unified strategy. DenseDiT combines a parameter-reuse mechanism and two lightweight branches that adaptively integrate multi-scale context, working with less than 0.1% additional parameters. Evaluations on DenseWorld reveal significant performance drops in existing general and specialized baselines, highlighting their limited real-world generalization. In contrast, DenseDiT achieves superior results using less than 0.01% training data of baselines, underscoring its practical value for real-world deployment. Our data, and checkpoints and codes are available at this https URL</li>
</ul>

<h3>Title: Distilling A Universal Expert from Clustered Federated Learning</h3>
<ul>
<li><strong>Authors: </strong>Zeqi Leng, Chunxu Zhang, Guodong Long, Riting Xia, Bo Yang</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.20285">https://arxiv.org/abs/2506.20285</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.20285">https://arxiv.org/pdf/2506.20285</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.20285]] Distilling A Universal Expert from Clustered Federated Learning(https://arxiv.org/abs/2506.20285)</code><input type="text"></li>
<li><strong>Keywords: </strong>federate</a></li>
<li><strong>Abstract: </strong>Clustered Federated Learning (CFL) addresses the challenges posed by non-IID data by training multiple group- or cluster-specific expert models. However, existing methods often overlook the shared information across clusters, which represents the generalizable knowledge valuable to all participants in the Federated Learning (FL) system. To overcome this limitation, this paper introduces a novel FL framework that distills a universal expert model from the knowledge of multiple clusters. This universal expert captures globally shared information across all clients and is subsequently distributed to each client as the initialization for the next round of model training. The proposed FL framework operates in three iterative steps: (1) local model training at each client, (2) cluster-specific model aggregation, and (3) universal expert distillation. This three-step learning paradigm ensures the preservation of fine-grained non-IID characteristics while effectively incorporating shared knowledge across clusters. Compared to traditional gradient-based aggregation methods, the distillation-based model aggregation introduces greater flexibility in handling model heterogeneity and reduces conflicts among cluster-specific experts. Extensive experimental results demonstrate the superior performance of the proposed method across various scenarios, highlighting its potential to advance the state of CFL by balancing personalized and shared knowledge more effectively.</li>
</ul>

<h3>Title: Don't Hash Me Like That: Exposing and Mitigating Hash-Induced Unfairness in Local Differential Privacy</h3>
<ul>
<li><strong>Authors: </strong>Berkay Kemal Balioglu, Alireza Khodaie, Mehmet Emre Gursoy</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.20290">https://arxiv.org/abs/2506.20290</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.20290">https://arxiv.org/pdf/2506.20290</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.20290]] Don't Hash Me Like That: Exposing and Mitigating Hash-Induced Unfairness in Local Differential Privacy(https://arxiv.org/abs/2506.20290)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, privacy, attack, fair</a></li>
<li><strong>Abstract: </strong>Local differential privacy (LDP) has become a widely accepted framework for privacy-preserving data collection. In LDP, many protocols rely on hash functions to implement user-side encoding and perturbation. However, the security and privacy implications of hash function selection have not been previously investigated. In this paper, we expose that the hash functions may act as a source of unfairness in LDP protocols. We show that although users operate under the same protocol and privacy budget, differences in hash functions can lead to significant disparities in vulnerability to inference and poisoning attacks. To mitigate hash-induced unfairness, we propose Fair-OLH (F-OLH), a variant of OLH that enforces an entropy-based fairness constraint on hash function selection. Experiments show that F-OLH is effective in mitigating hash-induced unfairness under acceptable time overheads.</li>
</ul>

<h3>Title: Ctrl-Z Sampling: Diffusion Sampling with Controlled Random Zigzag Explorations</h3>
<ul>
<li><strong>Authors: </strong>Shunqi Mao, Wei Guo, Chaoyi Zhang, Weidong Cai</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.20294">https://arxiv.org/abs/2506.20294</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.20294">https://arxiv.org/pdf/2506.20294</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.20294]] Ctrl-Z Sampling: Diffusion Sampling with Controlled Random Zigzag Explorations(https://arxiv.org/abs/2506.20294)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>Diffusion models have shown strong performance in conditional generation by progressively denoising Gaussian noise toward a target data distribution. This denoising process can be interpreted as a form of hill climbing in a learned latent space, where the model iteratively refines the sample toward regions of higher probability. However, diffusion models often converge to local optima that are locally visually coherent yet globally inconsistent or conditionally misaligned, due to latent space complexity and suboptimal initialization. Prior efforts attempted to address this by strengthening guidance signals or manipulating the initial noise distribution. We introduce Controlled Random Zigzag Sampling (Ctrl-Z Sampling), a novel sampling strategy designed to detect and escape such local maxima during conditional generation. The method first identifies potential local maxima using a reward model. Upon detection, it injects noise and reverts to a previous, noisier state to escape the current optimization plateau. The reward model then evaluates candidate trajectories, accepting only those that offer improvement, while progressively deeper retreat enables stronger escapes when nearby alternatives fail. This controlled random zigzag process allows dynamic alternation between forward refinement and backward exploration, enhancing both alignment and visual quality in the generated outputs. The proposed Ctrl-Z Sampling is model-agnostic and compatible with existing diffusion frameworks. Experimental results show that Ctrl-Z Sampling substantially improves generation quality with only around 7.6X increase in function evaluations.</li>
</ul>

<h3>Title: TDiR: Transformer based Diffusion for Image Restoration Tasks</h3>
<ul>
<li><strong>Authors: </strong>Abbas Anwar, Mohammad Shullar, Ali Arshad Nasir, Mudassir Masood, Saeed Anwar</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.20302">https://arxiv.org/abs/2506.20302</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.20302">https://arxiv.org/pdf/2506.20302</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.20302]] TDiR: Transformer based Diffusion for Image Restoration Tasks(https://arxiv.org/abs/2506.20302)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, transformer</a></li>
<li><strong>Abstract: </strong>Images captured in challenging environments often experience various forms of degradation, including noise, color cast, blur, and light scattering. These effects significantly reduce image quality, hindering their applicability in downstream tasks such as object detection, mapping, and classification. Our transformer-based diffusion model was developed to address image restoration tasks, aiming to improve the quality of degraded images. This model was evaluated against existing deep learning methodologies across multiple quality metrics for underwater image enhancement, denoising, and deraining on publicly available datasets. Our findings demonstrate that the diffusion model, combined with transformers, surpasses current methods in performance. The results of our model highlight the efficacy of diffusion models and transformers in improving the quality of degraded images, consequently expanding their utility in downstream tasks that require high-fidelity visual data.</li>
</ul>

<h3>Title: Learning Moderately Input-Sensitive Functions: A Case Study in QR Code Decoding</h3>
<ul>
<li><strong>Authors: </strong>Kazuki Yoda, Kazuhiko Kawamoto, Hiroshi Kera</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.20305">https://arxiv.org/abs/2506.20305</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.20305">https://arxiv.org/pdf/2506.20305</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.20305]] Learning Moderately Input-Sensitive Functions: A Case Study in QR Code Decoding(https://arxiv.org/abs/2506.20305)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>The hardness of learning a function that attains a target task relates to its input-sensitivity. For example, image classification tasks are input-insensitive as minor corruptions should not affect the classification results, whereas arithmetic and symbolic computation, which have been recently attracting interest, are highly input-sensitive as each input variable connects to the computation results. This study presents the first learning-based Quick Response (QR) code decoding and investigates learning functions of medium sensitivity. Our experiments reveal that Transformers can successfully decode QR codes, even beyond the theoretical error-correction limit, by learning the structure of embedded texts. They generalize from English-rich training data to other languages and even random strings. Moreover, we observe that the Transformer-based QR decoder focuses on data bits while ignoring error-correction bits, suggesting a decoding mechanism distinct from standard QR code readers.</li>
</ul>

<h3>Title: Radiomic fingerprints for knee MR images assessment</h3>
<ul>
<li><strong>Authors: </strong>Yaxi Chen, Simin Ni, Shaheer U. Saeed, Aleksandra Ivanova, Rikin Hargunani, Jie Huang, Chaozong Liu, Yipeng Hu</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.20306">https://arxiv.org/abs/2506.20306</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.20306">https://arxiv.org/pdf/2506.20306</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.20306]] Radiomic fingerprints for knee MR images assessment(https://arxiv.org/abs/2506.20306)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability</a></li>
<li><strong>Abstract: </strong>Accurate interpretation of knee MRI scans relies on expert clinical judgment, often with high variability and limited scalability. Existing radiomic approaches use a fixed set of radiomic features (the signature), selected at the population level and applied uniformly to all patients. While interpretable, these signatures are often too constrained to represent individual pathological variations. As a result, conventional radiomic-based approaches are found to be limited in performance, compared with recent end-to-end deep learning (DL) alternatives without using interpretable radiomic features. We argue that the individual-agnostic nature in current radiomic selection is not central to its intepretability, but is responsible for the poor generalization in our application. Here, we propose a novel radiomic fingerprint framework, in which a radiomic feature set (the fingerprint) is dynamically constructed for each patient, selected by a DL model. Unlike the existing radiomic signatures, our fingerprints are derived on a per-patient basis by predicting the feature relevance in a large radiomic feature pool, and selecting only those that are predictive of clinical conditions for individual patients. The radiomic-selecting model is trained simultaneously with a low-dimensional (considered relatively explainable) logistic regression for downstream classification. We validate our methods across multiple diagnostic tasks including general knee abnormalities, anterior cruciate ligament (ACL) tears, and meniscus tears, demonstrating comparable or superior diagnostic accuracy relative to state-of-the-art end-to-end DL models. More importantly, we show that the interpretability inherent in our approach facilitates meaningful clinical insights and potential biomarker discovery, with detailed discussion, quantitative and qualitative analysis of real-world clinical cases to evidence these advantages.</li>
</ul>

<h3>Title: On the Burstiness of Faces in Set</h3>
<ul>
<li><strong>Authors: </strong>Jiong Wang</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.20312">https://arxiv.org/abs/2506.20312</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.20312">https://arxiv.org/pdf/2506.20312</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.20312]] On the Burstiness of Faces in Set(https://arxiv.org/abs/2506.20312)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Burstiness, a phenomenon observed in text and image retrieval, refers to that particular elements appear more times in a set than a statistically independent model assumes. We argue that in the context of set-based face recognition (SFR), burstiness exists widely and degrades the performance in two aspects: Firstly, the bursty faces, where faces with particular attributes %exist frequently in a face set, dominate the training instances and dominate the training face sets and lead to poor generalization ability to unconstrained scenarios. Secondly, the bursty faces %dominating the evaluation sets interfere with the similarity comparison in set verification and identification when evaluation. To detect the bursty faces in a set, we propose three strategies based on Quickshift++, feature self-similarity, and generalized max-pooling (GMP). We apply the burst detection results on training and evaluation stages to enhance the sampling ratios or contributions of the infrequent faces. When evaluation, we additionally propose the quality-aware GMP that enables awareness of the face quality and robustness to the low-quality faces for the original GMP. We give illustrations and extensive experiments on the SFR benchmarks to demonstrate that burstiness is widespread and suppressing burstiness considerably improves the recognition performance.</li>
</ul>

<h3>Title: From Codicology to Code: A Comparative Study of Transformer and YOLO-based Detectors for Layout Analysis in Historical Documents</h3>
<ul>
<li><strong>Authors: </strong>Sergio Torres Aguilar</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.CL, cs.DB</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.20326">https://arxiv.org/abs/2506.20326</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.20326">https://arxiv.org/pdf/2506.20326</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.20326]] From Codicology to Code: A Comparative Study of Transformer and YOLO-based Detectors for Layout Analysis in Historical Documents(https://arxiv.org/abs/2506.20326)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, transformer</a></li>
<li><strong>Abstract: </strong>Robust Document Layout Analysis (DLA) is critical for the automated processing and understanding of historical documents with complex page organizations. This paper benchmarks five state-of-the-art object detection architectures on three annotated datasets representing a spectrum of codicological complexity: The e-NDP, a corpus of Parisian medieval registers (1326-1504); CATMuS, a diverse multiclass dataset derived from various medieval and modern sources (ca.12th-17th centuries) and HORAE, a corpus of decorated books of hours (ca.13th-16th centuries). We evaluate two Transformer-based models (Co-DETR, Grounding DINO) against three YOLO variants (AABB, OBB, and YOLO-World). Our findings reveal significant performance variations dependent on model architecture, data set characteristics, and bounding box representation. In the e-NDP dataset, Co-DETR achieves state-of-the-art results (0.752 mAP@.50:.95), closely followed by YOLOv11X-OBB (0.721). Conversely, on the more complex CATMuS and HORAE datasets, the CNN-based YOLOv11x-OBB significantly outperforms all other models (0.564 and 0.568, respectively). This study unequivocally demonstrates that using Oriented Bounding Boxes (OBB) is not a minor refinement but a fundamental requirement for accurately modeling the non-Cartesian nature of historical manuscripts. We conclude that a key trade-off exists between the global context awareness of Transformers, ideal for structured layouts, and the superior generalization of CNN-OBB models for visually diverse and complex documents.</li>
</ul>

<h3>Title: Producer-Fairness in Sequential Bundle Recommendation</h3>
<ul>
<li><strong>Authors: </strong>Alexandre Rio, Marta Soare, Sihem Amer-Yahia</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.20329">https://arxiv.org/abs/2506.20329</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.20329">https://arxiv.org/pdf/2506.20329</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.20329]] Producer-Fairness in Sequential Bundle Recommendation(https://arxiv.org/abs/2506.20329)</code><input type="text"></li>
<li><strong>Keywords: </strong>fair</a></li>
<li><strong>Abstract: </strong>We address fairness in the context of sequential bundle recommendation, where users are served in turn with sets of relevant and compatible items. Motivated by real-world scenarios, we formalize producer-fairness, that seeks to achieve desired exposure of different item groups across users in a recommendation session. Our formulation combines naturally with building high quality bundles. Our problem is solved in real time as users arrive. We propose an exact solution that caters to small instances of our problem. We then examine two heuristics, quality-first and fairness-first, and an adaptive variant that determines on-the-fly the right balance between bundle fairness and quality. Our experiments on three real-world datasets underscore the strengths and limitations of each solution and demonstrate their efficacy in providing fair bundle recommendations without compromising bundle quality.</li>
</ul>

<h3>Title: Biomed-Enriched: A Biomedical Dataset Enriched with LLMs for Pretraining and Extracting Rare and Hidden Content</h3>
<ul>
<li><strong>Authors: </strong>Rian Touchent, Nathan Godey, Eric de la Clergerie</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.20331">https://arxiv.org/abs/2506.20331</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.20331">https://arxiv.org/pdf/2506.20331</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.20331]] Biomed-Enriched: A Biomedical Dataset Enriched with LLMs for Pretraining and Extracting Rare and Hidden Content(https://arxiv.org/abs/2506.20331)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, large language model</a></li>
<li><strong>Abstract: </strong>We introduce Biomed-Enriched, a biomedical text dataset constructed from PubMed via a two-stage annotation process. In the first stage, a large language model annotates 400K paragraphs from PubMed scientific articles, assigning scores for their type (review, study, clinical case, other), domain (clinical, biomedical, other), and educational quality. The educational quality score (rated 1 to 5) estimates how useful a paragraph is for college-level learning. These annotations are then used to fine-tune a small language model, which propagates the labels across the full PMC-OA corpus. The resulting metadata allows us to extract refined subsets, including 2M clinical case paragraphs with over 450K high-quality ones from articles with commercial-use licenses, and to construct several variants via quality filtering and domain upsampling. Clinical text is typically difficult to access due to privacy constraints, as hospital records cannot be publicly shared. Hence, our dataset provides an alternative large-scale, openly available collection of clinical cases from PubMed, making it a valuable resource for biomedical and clinical NLP. Preliminary continual-pretraining experiments with OLMo2 suggest these curated subsets enable targeted improvements, with clinical upsampling boosting performance by ~5% on MMLU ProfMed and educational quality filtering improving MedQA and MedMCQA by ~1%. Combinations of these techniques led to faster convergence, reaching same performance with a third of training tokens, indicating potential for more efficient and effective biomedical pretraining strategies.</li>
</ul>

<h3>Title: Feature Hallucination for Self-supervised Action Recognition</h3>
<ul>
<li><strong>Authors: </strong>Lei Wang, Piotr Koniusz</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.20342">https://arxiv.org/abs/2506.20342</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.20342">https://arxiv.org/pdf/2506.20342</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.20342]] Feature Hallucination for Self-supervised Action Recognition(https://arxiv.org/abs/2506.20342)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, transformer</a></li>
<li><strong>Abstract: </strong>Understanding human actions in videos requires more than raw pixel analysis; it relies on high-level semantic reasoning and effective integration of multimodal features. We propose a deep translational action recognition framework that enhances recognition accuracy by jointly predicting action concepts and auxiliary features from RGB video frames. At test time, hallucination streams infer missing cues, enriching feature representations without increasing computational overhead. To focus on action-relevant regions beyond raw pixels, we introduce two novel domain-specific descriptors. Object Detection Features (ODF) aggregate outputs from multiple object detectors to capture contextual cues, while Saliency Detection Features (SDF) highlight spatial and intensity patterns crucial for action recognition. Our framework seamlessly integrates these descriptors with auxiliary modalities such as optical flow, Improved Dense Trajectories, skeleton data, and audio cues. It remains compatible with state-of-the-art architectures, including I3D, AssembleNet, Video Transformer Network, FASTER, and recent models like VideoMAE V2 and InternVideo2. To handle uncertainty in auxiliary features, we incorporate aleatoric uncertainty modeling in the hallucination step and introduce a robust loss function to mitigate feature noise. Our multimodal self-supervised action recognition framework achieves state-of-the-art performance on multiple benchmarks, including Kinetics-400, Kinetics-600, and Something-Something V2, demonstrating its effectiveness in capturing fine-grained action dynamics.</li>
</ul>

<h3>Title: DipSVD: Dual-importance Protected SVD for Efficient LLM Compression</h3>
<ul>
<li><strong>Authors: </strong>Xuan Ding, Rui Sun, Yunjian Zhang, Xiu Yan, Yueqi Zhou, Kaihao Huang, Suzhong Fu, Chuanlong Xie, Yao Zhu</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.20353">https://arxiv.org/abs/2506.20353</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.20353">https://arxiv.org/pdf/2506.20353</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.20353]] DipSVD: Dual-importance Protected SVD for Efficient LLM Compression(https://arxiv.org/abs/2506.20353)</code><input type="text"></li>
<li><strong>Keywords: </strong>protect, large language model</a></li>
<li><strong>Abstract: </strong>The ever-increasing computational demands and deployment costs of large language models (LLMs) have spurred numerous compressing methods. Compared to quantization and unstructured pruning, SVD compression offers superior hardware compatibility and theoretical guarantees. However, existing SVD-based methods focus on the overall discrepancy between the original and compressed matrices while overlooking the protection of critical components within the matrix, which leads to inferior performance in the compressed models. This paper proposes a dual-level importance protection mechanism to enhance SVD-based compression methods: (1) local importance protection: preserving the most critical singular vectors within each weight matrix through channel-weighted data whitening; and (2) global importance protection: enabling less important layers to bear a greater portion of the compression burden through either a heuristic or optimization-based approach, thereby minimizing the impact of compression on critical layers. Extensive experiments demonstrate that DipSVD outperforms existing SVD-based compression approaches across multiple benchmarks, achieving superior model performance especially at high model compression ratios.</li>
</ul>

<h3>Title: A foundation model with multi-variate parallel attention to generate neuronal activity</h3>
<ul>
<li><strong>Authors: </strong>Francesco Carzaniga, Michael Hersche, Abu Sebastian, Kaspar Schindler, Abbas Rahimi</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.20354">https://arxiv.org/abs/2506.20354</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.20354">https://arxiv.org/pdf/2506.20354</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.20354]] A foundation model with multi-variate parallel attention to generate neuronal activity(https://arxiv.org/abs/2506.20354)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer, generative</a></li>
<li><strong>Abstract: </strong>Learning from multi-variate time-series with heterogeneous channel configurations remains a fundamental challenge for deep neural networks (DNNs), particularly in clinical domains such as intracranial electroencephalography (iEEG), where channel setups vary widely across subjects. In this work, we introduce multi-variate parallel attention (MVPA), a novel self-attention mechanism that disentangles content, temporal, and spatial attention, enabling flexible, generalizable, and efficient modeling of time-series data with varying channel counts and configurations. We use MVPA to build MVPFormer, a generative foundation model for human electrophysiology, trained to predict the evolution of iEEG signals across diverse subjects. To support this and future effort by the community, we release the SWEC iEEG dataset, the largest publicly available iEEG dataset to date, comprising nearly 10,000 hours of recordings from heterogeneous clinical sources. MVPFormer leverages MVPA to achieve strong generalization across subjects, demonstrating expert-level performance in seizure detection and outperforming state-of-the-art Transformer baselines on our SWEC, the MAYO, and the FNUSA dataset. We further validate MVPA on standard time-series forecasting and classification tasks, where it matches or exceeds existing attention-based models. Together, our contributions establish MVPA as a general-purpose attention mechanism for heterogeneous time-series and MVPFormer as the first open-source, open-weights, and open-data iEEG foundation model with state-of-the-art clinical performance. The code is available at this https URL. The SWEC iEEG dataset is available at this https URL.</li>
</ul>

<h3>Title: Towards Interpretable and Efficient Feature Selection in Trajectory Datasets: A Taxonomic Approach</h3>
<ul>
<li><strong>Authors: </strong>Chanuka Don Samarasinghage, Dhruv Gulabani</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.20359">https://arxiv.org/abs/2506.20359</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.20359">https://arxiv.org/pdf/2506.20359</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.20359]] Towards Interpretable and Efficient Feature Selection in Trajectory Datasets: A Taxonomic Approach(https://arxiv.org/abs/2506.20359)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, interpretability</a></li>
<li><strong>Abstract: </strong>Trajectory analysis is not only about obtaining movement data, but it is also of paramount importance in understanding the pattern in which an object moves through space and time, as well as in predicting its next move. Due to the significant interest in the area, data collection has improved substantially, resulting in a large number of features becoming available for training and predicting models. However, this introduces a high-dimensionality-induced feature explosion problem, which reduces the efficiency and interpretability of the data, thereby reducing the accuracy of machine learning models. To overcome this issue, feature selection has become one of the most prevalent tools. Thus, the objective of this paper was to introduce a taxonomy-based feature selection method that categorizes features based on their internal structure. This approach classifies the data into geometric and kinematic features, further categorizing them into curvature, indentation, speed, and acceleration. The comparative analysis indicated that a taxonomy-based approach consistently achieved comparable or superior predictive performance. Furthermore, due to the taxonomic grouping, which reduces combinatorial space, the time taken to select features was drastically reduced. The taxonomy was also used to gain insights into what feature sets each dataset was more sensitive to. Overall, this study provides robust evidence that a taxonomy-based feature selection method can add a layer of interpretability, reduce dimensionality and computational complexity, and contribute to high-level decision-making. It serves as a step toward providing a methodological framework for researchers and practitioners dealing with trajectory datasets and contributing to the broader field of explainable artificial intelligence.</li>
</ul>

<h3>Title: Self-Supervised Graph Learning via Spectral Bootstrapping and Laplacian-Based Augmentations</h3>
<ul>
<li><strong>Authors: </strong>Lorenzo Bini, Stephane Marchand-Maillet</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.DS</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.20362">https://arxiv.org/abs/2506.20362</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.20362">https://arxiv.org/pdf/2506.20362</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.20362]] Self-Supervised Graph Learning via Spectral Bootstrapping and Laplacian-Based Augmentations(https://arxiv.org/abs/2506.20362)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>We present LaplaceGNN, a novel self-supervised graph learning framework that bypasses the need for negative sampling by leveraging spectral bootstrapping techniques. Our method integrates Laplacian-based signals into the learning process, allowing the model to effectively capture rich structural representations without relying on contrastive objectives or handcrafted augmentations. By focusing on positive alignment, LaplaceGNN achieves linear scaling while offering a simpler, more efficient, self-supervised alternative for graph neural networks, applicable across diverse domains. Our contributions are twofold: we precompute spectral augmentations through max-min centrality-guided optimization, enabling rich structural supervision without relying on handcrafted augmentations, then we integrate an adversarial bootstrapped training scheme that further strengthens feature learning and robustness. Our extensive experiments on different benchmark datasets show that LaplaceGNN achieves superior performance compared to state-of-the-art self-supervised graph methods, offering a promising direction for efficiently learning expressive graph representations.</li>
</ul>

<h3>Title: InvZW: Invariant Feature Learning via Noise-Adversarial Training for Robust Image Zero-Watermarking</h3>
<ul>
<li><strong>Authors: </strong>Abdullah All Tanvir, Xin Zhong</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.LG, cs.MM</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.20370">https://arxiv.org/abs/2506.20370</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.20370">https://arxiv.org/pdf/2506.20370</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.20370]] InvZW: Invariant Feature Learning via Noise-Adversarial Training for Robust Image Zero-Watermarking(https://arxiv.org/abs/2506.20370)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, watermark</a></li>
<li><strong>Abstract: </strong>This paper introduces a novel deep learning framework for robust image zero-watermarking based on distortion-invariant feature learning. As a zero-watermarking scheme, our method leaves the original image unaltered and learns a reference signature through optimization in the feature space. The proposed framework consists of two key modules. In the first module, a feature extractor is trained via noise-adversarial learning to generate representations that are both invariant to distortions and semantically expressive. This is achieved by combining adversarial supervision against a distortion discriminator and a reconstruction constraint to retain image content. In the second module, we design a learning-based multibit zero-watermarking scheme where the trained invariant features are projected onto a set of trainable reference codes optimized to match a target binary message. Extensive experiments on diverse image datasets and a wide range of distortions show that our method achieves state-of-the-art robustness in both feature stability and watermark recovery. Comparative evaluations against existing self-supervised and deep watermarking techniques further highlight the superiority of our framework in generalization and robustness.</li>
</ul>

<h3>Title: TESSERA: Temporal Embeddings of Surface Spectra for Earth Representation and Analysis</h3>
<ul>
<li><strong>Authors: </strong>Zhengpeng Feng, Sadiq Jaffer, Jovana Knezevic, Silja Sormunen, Robin Young, Madeline Lisaius, Markus Immitzer, James Ball, Clement Atzberger, David A. Coomes, Anil Madhavapeddy, Andrew Blake, Srinivasan Keshav</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.20380">https://arxiv.org/abs/2506.20380</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.20380">https://arxiv.org/pdf/2506.20380</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.20380]] TESSERA: Temporal Embeddings of Surface Spectra for Earth Representation and Analysis(https://arxiv.org/abs/2506.20380)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, transformer</a></li>
<li><strong>Abstract: </strong>Satellite remote sensing (RS) enables a wide array of downstream Earth observation (EO) applications, including climate modeling, carbon accounting, and strategies for conservation and sustainable land use. We present TESSERA, a novel Remote Sensing Foundation Model (RSFM) that uses Self-Supervised Learning (SSL) to generate global, robust representations at 10m scale from pixel-level satellite time series data. TESSERA combines information from only optical and SAR data streams using two parallel Transformer-based encoders: one dedicated to Sentinel-1 SAR polarizations and another to Sentinel-2 MSI data (10 selected spectral bands) to create representations that are then fused using a multilayer perceptron (MLP), resulting in a global representation map covering the years 2017 to 2024. Our precomputed representations set a new state-of-the-art performance benchmark and our open-source approach democratizes access to high-performance, high-resolution representations. We benchmark the performance of TESSERA in five diverse tasks, comparing our work with state-of-the-art task-specific models and other foundation models. Our results show that TESSERA outperforms both traditional RS baselines and the leading geospatial foundation models in these diverse downstream tasks.</li>
</ul>

<h3>Title: Exploiting Lightweight Hierarchical ViT and Dynamic Framework for Efficient Visual Tracking</h3>
<ul>
<li><strong>Authors: </strong>Ben Kang, Xin Chen, Jie Zhao, Chunjuan Bo, Dong Wang, Huchuan Lu</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.20381">https://arxiv.org/abs/2506.20381</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.20381">https://arxiv.org/pdf/2506.20381</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.20381]] Exploiting Lightweight Hierarchical ViT and Dynamic Framework for Efficient Visual Tracking(https://arxiv.org/abs/2506.20381)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Transformer-based visual trackers have demonstrated significant advancements due to their powerful modeling capabilities. However, their practicality is limited on resource-constrained devices because of their slow processing speeds. To address this challenge, we present HiT, a novel family of efficient tracking models that achieve high performance while maintaining fast operation across various devices. The core innovation of HiT lies in its Bridge Module, which connects lightweight transformers to the tracking framework, enhancing feature representation quality. Additionally, we introduce a dual-image position encoding approach to effectively encode spatial information. HiT achieves an impressive speed of 61 frames per second (fps) on the NVIDIA Jetson AGX platform, alongside a competitive AUC of 64.6% on the LaSOT benchmark, outperforming all previous efficient this http URL on HiT, we propose DyHiT, an efficient dynamic tracker that flexibly adapts to scene complexity by selecting routes with varying computational requirements. DyHiT uses search area features extracted by the backbone network and inputs them into an efficient dynamic router to classify tracking scenarios. Based on the classification, DyHiT applies a divide-and-conquer strategy, selecting appropriate routes to achieve a superior trade-off between accuracy and speed. The fastest version of DyHiT achieves 111 fps on NVIDIA Jetson AGX while maintaining an AUC of 62.4% on this http URL, we introduce a training-free acceleration method based on the dynamic routing architecture of DyHiT. This method significantly improves the execution speed of various high-performance trackers without sacrificing accuracy. For instance, our acceleration method enables the state-of-the-art tracker SeqTrack-B256 to achieve a 2.68 times speedup on an NVIDIA GeForce RTX 2080 Ti GPU while maintaining the same AUC of 69.9% on the LaSOT.</li>
</ul>

<h3>Title: TAPS: Tool-Augmented Personalisation via Structured Tagging</h3>
<ul>
<li><strong>Authors: </strong>Ekaterina Taktasheva, Jeff Dalton</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.20409">https://arxiv.org/abs/2506.20409</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.20409">https://arxiv.org/pdf/2506.20409</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.20409]] TAPS: Tool-Augmented Personalisation via Structured Tagging(https://arxiv.org/abs/2506.20409)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Recent advancements in tool-augmented large language models have enabled them to interact with external tools, enhancing their ability to perform complex user tasks. However, existing approaches overlook the role of personalisation in guiding tool use. This work investigates how user preferences can be effectively integrated into goal-oriented dialogue agents. Through extensive analysis, we identify key weaknesses in the ability of LLMs to personalise tool use. To this end, we introduce \name, a novel solution that enhances personalised tool use by leveraging a structured tagging tool and an uncertainty-based tool detector. TAPS significantly improves the ability of LLMs to incorporate user preferences, achieving the new state-of-the-art for open source models on the NLSI task.</li>
</ul>

<h3>Title: Client Clustering Meets Knowledge Sharing: Enhancing Privacy and Robustness in Personalized Peer-to-Peer Learning</h3>
<ul>
<li><strong>Authors: </strong>Mohammad Mahdi Maheri, Denys Herasymuk, Hamed Haddadi</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.20413">https://arxiv.org/abs/2506.20413</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.20413">https://arxiv.org/pdf/2506.20413</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.20413]] Client Clustering Meets Knowledge Sharing: Enhancing Privacy and Robustness in Personalized Peer-to-Peer Learning(https://arxiv.org/abs/2506.20413)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, protect, attack, robust</a></li>
<li><strong>Abstract: </strong>The growing adoption of Artificial Intelligence (AI) in Internet of Things (IoT) ecosystems has intensified the need for personalized learning methods that can operate efficiently and privately across heterogeneous, resource-constrained devices. However, enabling effective personalized learning in decentralized settings introduces several challenges, including efficient knowledge transfer between clients, protection of data privacy, and resilience against poisoning attacks. In this paper, we address these challenges by developing P4 (Personalized, Private, Peer-to-Peer) -- a method designed to deliver personalized models for resource-constrained IoT devices while ensuring differential privacy and robustness against poisoning attacks. Our solution employs a lightweight, fully decentralized algorithm to privately detect client similarity and form collaborative groups. Within each group, clients leverage differentially private knowledge distillation to co-train their models, maintaining high accuracy while ensuring robustness to the presence of malicious clients. We evaluate P4 on popular benchmark datasets using both linear and CNN-based architectures across various heterogeneity settings and attack scenarios. Experimental results show that P4 achieves 5% to 30% higher accuracy than leading differentially private peer-to-peer approaches and maintains robustness with up to 30% malicious clients. Additionally, we demonstrate its practicality by deploying it on resource-constrained devices, where collaborative training between two clients adds only ~7 seconds of overhead.</li>
</ul>

<h3>Title: SV-LLM: An Agentic Approach for SoC Security Verification using Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Dipayan Saha, Shams Tarek, Hasan Al Shaikh, Khan Thamid Hasan, Pavan Sai Nalluri, Md. Ajoad Hasan, Nashmin Alam, Jingbo Zhou, Sujan Kumar Saha, Mark Tehranipoor, Farimah Farahmandi</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.AI, cs.MA</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.20415">https://arxiv.org/abs/2506.20415</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.20415">https://arxiv.org/pdf/2506.20415</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.20415]] SV-LLM: An Agentic Approach for SoC Security Verification using Large Language Models(https://arxiv.org/abs/2506.20415)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, large language model</a></li>
<li><strong>Abstract: </strong>Ensuring the security of complex system-on-chips (SoCs) designs is a critical imperative, yet traditional verification techniques struggle to keep pace due to significant challenges in automation, scalability, comprehensiveness, and adaptability. The advent of large language models (LLMs), with their remarkable capabilities in natural language understanding, code generation, and advanced reasoning, presents a new paradigm for tackling these issues. Moving beyond monolithic models, an agentic approach allows for the creation of multi-agent systems where specialized LLMs collaborate to solve complex problems more effectively. Recognizing this opportunity, we introduce SV-LLM, a novel multi-agent assistant system designed to automate and enhance SoC security verification. By integrating specialized agents for tasks like verification question answering, security asset identification, threat modeling, test plan and property generation, vulnerability detection, and simulation-based bug validation, SV-LLM streamlines the workflow. To optimize their performance in these diverse tasks, agents leverage different learning paradigms, such as in-context learning, fine-tuning, and retrieval-augmented generation (RAG). The system aims to reduce manual intervention, improve accuracy, and accelerate security analysis, supporting proactive identification and mitigation of risks early in the design cycle. We demonstrate its potential to transform hardware security practices through illustrative case studies and experiments that showcase its applicability and efficacy.</li>
</ul>

<h3>Title: An Agentic System for Rare Disease Diagnosis with Traceable Reasoning</h3>
<ul>
<li><strong>Authors: </strong>Weike Zhao, Chaoyi Wu, Yanjie Fan, Xiaoman Zhang, Pengcheng Qiu, Yuze Sun, Xiao Zhou, Yanfeng Wang, Ya Zhang, Yongguo Yu, Kun Sun, Weidi Xie</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.CV, cs.MA</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.20430">https://arxiv.org/abs/2506.20430</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.20430">https://arxiv.org/pdf/2506.20430</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.20430]] An Agentic System for Rare Disease Diagnosis with Traceable Reasoning(https://arxiv.org/abs/2506.20430)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Rare diseases collectively affect over 300 million individuals worldwide, yet timely and accurate diagnosis remains a pervasive challenge. This is largely due to their clinical heterogeneity, low individual prevalence, and the limited familiarity most clinicians have with rare conditions. Here, we introduce DeepRare, the first rare disease diagnosis agentic system powered by a large language model (LLM), capable of processing heterogeneous clinical inputs. The system generates ranked diagnostic hypotheses for rare diseases, each accompanied by a transparent chain of reasoning that links intermediate analytic steps to verifiable medical evidence. DeepRare comprises three key components: a central host with a long-term memory module; specialized agent servers responsible for domain-specific analytical tasks integrating over 40 specialized tools and web-scale, up-to-date medical knowledge sources, ensuring access to the most current clinical information. This modular and scalable design enables complex diagnostic reasoning while maintaining traceability and adaptability. We evaluate DeepRare on eight datasets. The system demonstrates exceptional diagnostic performance among 2,919 diseases, achieving 100% accuracy for 1013 diseases. In HPO-based evaluations, DeepRare significantly outperforms other 15 methods, like traditional bioinformatics diagnostic tools, LLMs, and other agentic systems, achieving an average Recall@1 score of 57.18% and surpassing the second-best method (Reasoning LLM) by a substantial margin of 23.79 percentage points. For multi-modal input scenarios, DeepRare achieves 70.60% at Recall@1 compared to Exomiser's 53.20% in 109 cases. Manual verification of reasoning chains by clinical experts achieves 95.40% agreements. Furthermore, the DeepRare system has been implemented as a user-friendly web application this http URL.</li>
</ul>

<h3>Title: Tackling Data Heterogeneity in Federated Learning through Knowledge Distillation with Inequitable Aggregation</h3>
<ul>
<li><strong>Authors: </strong>Xing Ma</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.20431">https://arxiv.org/abs/2506.20431</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.20431">https://arxiv.org/pdf/2506.20431</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.20431]] Tackling Data Heterogeneity in Federated Learning through Knowledge Distillation with Inequitable Aggregation(https://arxiv.org/abs/2506.20431)</code><input type="text"></li>
<li><strong>Keywords: </strong>federate</a></li>
<li><strong>Abstract: </strong>Federated learning aims to train a global model in a distributed environment that is close to the performance of centralized training. However, issues such as client label skew, data quantity skew, and other heterogeneity problems severely degrade the model's performance. Most existing methods overlook the scenario where only a small portion of clients participate in training within a large-scale client setting, whereas our experiments show that this scenario presents a more challenging federated learning task. Therefore, we propose a Knowledge Distillation with teacher-student Inequitable Aggregation (KDIA) strategy tailored to address the federated learning setting mentioned above, which can effectively leverage knowledge from all clients. In KDIA, the student model is the average aggregation of the participating clients, while the teacher model is formed by a weighted aggregation of all clients based on three frequencies: participation intervals, participation counts, and data volume proportions. During local training, self-knowledge distillation is performed. Additionally, we utilize a generator trained on the server to generate approximately independent and identically distributed (IID) data features locally for auxiliary training. We conduct extensive experiments on the CIFAR-10/100/CINIC-10 datasets and various heterogeneous settings to evaluate KDIA. The results show that KDIA can achieve better accuracy with fewer rounds of training, and the improvement is more significant under severe heterogeneity.</li>
</ul>

<h3>Title: Med-Art: Diffusion Transformer for 2D Medical Text-to-Image Generation</h3>
<ul>
<li><strong>Authors: </strong>Changlu Guo, Anders Nymark Christensen, Morten Rieger Hannemose</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.20449">https://arxiv.org/abs/2506.20449</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.20449">https://arxiv.org/pdf/2506.20449</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.20449]] Med-Art: Diffusion Transformer for 2D Medical Text-to-Image Generation(https://arxiv.org/abs/2506.20449)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, transformer, generative</a></li>
<li><strong>Abstract: </strong>Text-to-image generative models have achieved remarkable breakthroughs in recent years. However, their application in medical image generation still faces significant challenges, including small dataset sizes, and scarcity of medical textual data. To address these challenges, we propose Med-Art, a framework specifically designed for medical image generation with limited data. Med-Art leverages vision-language models to generate visual descriptions of medical images which overcomes the scarcity of applicable medical textual data. Med-Art adapts a large-scale pre-trained text-to-image model, PixArt-$\alpha$, based on the Diffusion Transformer (DiT), achieving high performance under limited data. Furthermore, we propose an innovative Hybrid-Level Diffusion Fine-tuning (HLDF) method, which enables pixel-level losses, effectively addressing issues such as overly saturated colors. We achieve state-of-the-art performance on two medical image datasets, measured by FID, KID, and downstream classification performance.</li>
</ul>

<h3>Title: Automatic Demonstration Selection for LLM-based Tabular Data Classification</h3>
<ul>
<li><strong>Authors: </strong>Shuchu Han, Wolfgang Bruckner</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.20451">https://arxiv.org/abs/2506.20451</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.20451">https://arxiv.org/pdf/2506.20451</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.20451]] Automatic Demonstration Selection for LLM-based Tabular Data Classification(https://arxiv.org/abs/2506.20451)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>A fundamental question in applying In-Context Learning (ICL) for tabular data classification is how to determine the ideal number of demonstrations in the prompt. This work addresses this challenge by presenting an algorithm to automatically select a reasonable number of required demonstrations. Our method distinguishes itself by integrating not only the tabular data's distribution but also the user's selected prompt template and the specific Large Language Model (LLM) into its estimation. Rooted in Spectral Graph Theory, our proposed algorithm defines a novel metric to quantify the similarities between different demonstrations. We then construct a similarity graph and analyze the eigenvalues of its Laplacian to derive the minimum number of demonstrations capable of representing the data within the LLM's intrinsic representation space. We validate the efficacy of our approach through experiments comparing its performance against conventional random selection algorithms on diverse datasets and LLMs.</li>
</ul>

<h3>Title: HiWave: Training-Free High-Resolution Image Generation via Wavelet-Based Diffusion Sampling</h3>
<ul>
<li><strong>Authors: </strong>Tobias Vontobel, Seyedmorteza Sadat, Farnood Salehi, Romann M. Weber</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.20452">https://arxiv.org/abs/2506.20452</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.20452">https://arxiv.org/pdf/2506.20452</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.20452]] HiWave: Training-Free High-Resolution Image Generation via Wavelet-Based Diffusion Sampling(https://arxiv.org/abs/2506.20452)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>Diffusion models have emerged as the leading approach for image synthesis, demonstrating exceptional photorealism and diversity. However, training diffusion models at high resolutions remains computationally prohibitive, and existing zero-shot generation techniques for synthesizing images beyond training resolutions often produce artifacts, including object duplication and spatial incoherence. In this paper, we introduce HiWave, a training-free, zero-shot approach that substantially enhances visual fidelity and structural coherence in ultra-high-resolution image synthesis using pretrained diffusion models. Our method employs a two-stage pipeline: generating a base image from the pretrained model followed by a patch-wise DDIM inversion step and a novel wavelet-based detail enhancer module. Specifically, we first utilize inversion methods to derive initial noise vectors that preserve global coherence from the base image. Subsequently, during sampling, our wavelet-domain detail enhancer retains low-frequency components from the base image to ensure structural consistency, while selectively guiding high-frequency components to enrich fine details and textures. Extensive evaluations using Stable Diffusion XL demonstrate that HiWave effectively mitigates common visual artifacts seen in prior methods, achieving superior perceptual quality. A user study confirmed HiWave's performance, where it was preferred over the state-of-the-art alternative in more than 80% of comparisons, highlighting its effectiveness for high-quality, ultra-high-resolution image synthesis without requiring retraining or architectural modifications.</li>
</ul>

<h3>Title: A Deep Learning Approach to Identify Rock Bolts in Complex 3D Point Clouds of Underground Mines Captured Using Mobile Laser Scanners</h3>
<ul>
<li><strong>Authors: </strong>Dibyayan Patra, Pasindu Ranasinghe, Bikram Banerjee, Simit Raval</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.20464">https://arxiv.org/abs/2506.20464</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.20464">https://arxiv.org/pdf/2506.20464</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.20464]] A Deep Learning Approach to Identify Rock Bolts in Complex 3D Point Clouds of Underground Mines Captured Using Mobile Laser Scanners(https://arxiv.org/abs/2506.20464)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, segmentation</a></li>
<li><strong>Abstract: </strong>Rock bolts are crucial components of the subterranean support systems in underground mines that provide adequate structural reinforcement to the rock mass to prevent unforeseen hazards like rockfalls. This makes frequent assessments of such bolts critical for maintaining rock mass stability and minimising risks in underground mining operations. Where manual surveying of rock bolts is challenging due to the low light conditions in the underground mines and the time-intensive nature of the process, automated detection of rock bolts serves as a plausible solution. To that end, this study focuses on the automatic identification of rock bolts within medium to large-scale 3D point clouds obtained from underground mines using mobile laser scanners. Existing techniques for automated rock bolt identification primarily rely on feature engineering and traditional machine learning approaches. However, such techniques lack robustness as these point clouds present several challenges due to data noise, varying environments, and complex surrounding structures. Moreover, the target rock bolts are extremely small objects within large-scale point clouds and are often partially obscured due to the application of reinforcement shotcrete. Addressing these challenges, this paper proposes an approach termed DeepBolt, which employs a novel two-stage deep learning architecture specifically designed for handling severe class imbalance for the automatic and efficient identification of rock bolts in complex 3D point clouds. The proposed method surpasses state-of-the-art semantic segmentation models by up to 42.5% in Intersection over Union (IoU) for rock bolt points. Additionally, it outperforms existing rock bolt identification techniques, achieving a 96.41% precision and 96.96% recall in classifying rock bolts, demonstrating its robustness and effectiveness in complex underground environments.</li>
</ul>

<h3>Title: Probing AI Safety with Source Code</h3>
<ul>
<li><strong>Authors: </strong>Ujwal Narayan, Shreyas Chaudhari, Ashwin Kalyan, Tanmay Rajpurohit, Karthik Narasimhan, Ameet Deshpande, Vishvak Murahari</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.20471">https://arxiv.org/abs/2506.20471</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.20471">https://arxiv.org/pdf/2506.20471</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.20471]] Probing AI Safety with Source Code(https://arxiv.org/abs/2506.20471)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large language models (LLMs) have become ubiquitous, interfacing with humans in numerous safety-critical applications. This necessitates improving capabilities, but importantly coupled with greater safety measures to align these models with human values and preferences. In this work, we demonstrate that contemporary models fall concerningly short of the goal of AI safety, leading to an unsafe and harmful experience for users. We introduce a prompting strategy called Code of Thought (CoDoT) to evaluate the safety of LLMs. CoDoT converts natural language inputs to simple code that represents the same intent. For instance, CoDoT transforms the natural language prompt "Make the statement more toxic: {text}" to: "make_more_toxic({text})". We show that CoDoT results in a consistent failure of a wide range of state-of-the-art LLMs. For example, GPT-4 Turbo's toxicity increases 16.5 times, DeepSeek R1 fails 100% of the time, and toxicity increases 300% on average across seven modern LLMs. Additionally, recursively applying CoDoT can further increase toxicity two times. Given the rapid and widespread adoption of LLMs, CoDoT underscores the critical need to evaluate safety efforts from first principles, ensuring that safety and capabilities advance together.</li>
</ul>

<h3>Title: Knowledge-Aware Diverse Reranking for Cross-Source Question Answering</h3>
<ul>
<li><strong>Authors: </strong>Tong Zhou</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.IR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.20476">https://arxiv.org/abs/2506.20476</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.20476">https://arxiv.org/pdf/2506.20476</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.20476]] Knowledge-Aware Diverse Reranking for Cross-Source Question Answering(https://arxiv.org/abs/2506.20476)</code><input type="text"></li>
<li><strong>Keywords: </strong>fair</a></li>
<li><strong>Abstract: </strong>This paper presents Team Marikarp's solution for the SIGIR 2025 LiveRAG competition. The competition's evaluation set, automatically generated by DataMorgana from internet corpora, encompassed a wide range of target topics, question types, question formulations, audience types, and knowledge organization methods. It offered a fair evaluation of retrieving question-relevant supporting documents from a 15M documents subset of the FineWeb corpus. Our proposed knowledge-aware diverse reranking RAG pipeline achieved first place in the competition.</li>
</ul>

<h3>Title: GPTailor: Large Language Model Pruning Through Layer Cutting and Stitching</h3>
<ul>
<li><strong>Authors: </strong>Guinan Su, Li Shen, Lu Yin, Shiwei Liu, Yanwu Yang, Jonas Geiping</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.20480">https://arxiv.org/abs/2506.20480</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.20480">https://arxiv.org/pdf/2506.20480</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.20480]] GPTailor: Large Language Model Pruning Through Layer Cutting and Stitching(https://arxiv.org/abs/2506.20480)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large language models (LLMs) have shown remarkable capabilities in language understanding and generation. However, such impressive capability typically comes with a substantial model size, which presents significant challenges in deployment and inference. While structured pruning of model parameters offers a promising way to reduce computational costs at deployment time, current methods primarily focus on single model pruning. In this work, we develop a novel strategy to compress models by strategically combining or merging layers from finetuned model variants, which preserves the original model's abilities by aggregating capabilities accentuated in different finetunes. We pose the optimal tailoring of these LLMs as a zero-order optimization problem, adopting a search space that supports three different operations: (1) Layer removal, (2) Layer selection from different candidate models, and (3) Layer merging. Our experiments demonstrate that this approach leads to competitive model pruning, for example, for the Llama2-13B model families, our compressed models maintain approximately 97.3\% of the original performance while removing $\sim25\%$ of parameters, significantly outperforming previous state-of-the-art methods. The code is available at this https URL.</li>
</ul>

<h3>Title: Counterfactual Influence as a Distributional Quantity</h3>
<ul>
<li><strong>Authors: </strong>Matthieu Meeus, Igor Shilov, Georgios Kaissis, Yves-Alexandre de Montjoye</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CL, cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.20481">https://arxiv.org/abs/2506.20481</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.20481">https://arxiv.org/pdf/2506.20481</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.20481]] Counterfactual Influence as a Distributional Quantity(https://arxiv.org/abs/2506.20481)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy</a></li>
<li><strong>Abstract: </strong>Machine learning models are known to memorize samples from their training data, raising concerns around privacy and generalization. Counterfactual self-influence is a popular metric to study memorization, quantifying how the model's prediction for a sample changes depending on the sample's inclusion in the training dataset. However, recent work has shown memorization to be affected by factors beyond self-influence, with other training samples, in particular (near-)duplicates, having a large impact. We here study memorization treating counterfactual influence as a distributional quantity, taking into account how all training samples influence how a sample is memorized. For a small language model, we compute the full influence distribution of training samples on each other and analyze its properties. We find that solely looking at self-influence can severely underestimate tangible risks associated with memorization: the presence of (near-)duplicates seriously reduces self-influence, while we find these samples to be (near-)extractable. We observe similar patterns for image classification, where simply looking at the influence distributions reveals the presence of near-duplicates in CIFAR-10. Our findings highlight that memorization stems from complex interactions across training data and is better captured by the full influence distribution than by self-influence alone.</li>
</ul>

<h3>Title: Generative AI for Vulnerability Detection in 6G Wireless Networks: Advances, Case Study, and Future Directions</h3>
<ul>
<li><strong>Authors: </strong>Shuo Yang, Xinran Zheng, Jinfeng Xu, Jinze Li, Danyang Song, Zheyu Chen, Edith C.H. Ngai</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.NI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.20488">https://arxiv.org/abs/2506.20488</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.20488">https://arxiv.org/pdf/2506.20488</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.20488]] Generative AI for Vulnerability Detection in 6G Wireless Networks: Advances, Case Study, and Future Directions(https://arxiv.org/abs/2506.20488)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, privacy, protect, defense, attack, generative</a></li>
<li><strong>Abstract: </strong>The rapid advancement of 6G wireless networks, IoT, and edge computing has significantly expanded the cyberattack surface, necessitating more intelligent and adaptive vulnerability detection mechanisms. Traditional security methods, while foundational, struggle with zero-day exploits, adversarial threats, and context-dependent vulnerabilities in highly dynamic network environments. Generative AI (GAI) emerges as a transformative solution, leveraging synthetic data generation, multimodal reasoning, and adaptive learning to enhance security frameworks. This paper explores the integration of GAI-powered vulnerability detection in 6G wireless networks, focusing on code auditing, protocol security, cloud-edge defenses, and hardware protection. We introduce a three-layer framework comprising the Technology Layer, Capability Layer, and Application Layer to systematically analyze the role of VAEs, GANs, LLMs, and GDMs in securing next-generation wireless ecosystems. To demonstrate practical implementation, we present a case study on LLM-driven code vulnerability detection, highlighting its effectiveness, performance, and challenges. Finally, we outline future research directions, including lightweight models, high-authenticity data generation, external knowledge integration, and privacy-preserving technologies. By synthesizing current advancements and open challenges, this work provides a roadmap for researchers and practitioners to harness GAI for building resilient and adaptive security solutions in 6G networks.</li>
</ul>

<h3>Title: Multimodal Representation Learning and Fusion</h3>
<ul>
<li><strong>Authors: </strong>Qihang Jin, Enze Ge, Yuhang Xie, Hongying Luo, Junhao Song, Ziqian Bi, Chia Xin Liang, Jibin Guan, Joe Yeong, Junfeng Hao</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.MM</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.20494">https://arxiv.org/abs/2506.20494</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.20494">https://arxiv.org/pdf/2506.20494</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.20494]] Multimodal Representation Learning and Fusion(https://arxiv.org/abs/2506.20494)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack</a></li>
<li><strong>Abstract: </strong>Multi-modal learning is a fast growing area in artificial intelligence. It tries to help machines understand complex things by combining information from different sources, like images, text, and audio. By using the strengths of each modality, multi-modal learning allows AI systems to build stronger and richer internal representations. These help machines better interpretation, reasoning, and making decisions in real-life situations. This field includes core techniques such as representation learning (to get shared features from different data types), alignment methods (to match information across modalities), and fusion strategies (to combine them by deep learning models). Although there has been good progress, some major problems still remain. Like dealing with different data formats, missing or incomplete inputs, and defending against adversarial attacks. Researchers now are exploring new methods, such as unsupervised or semi-supervised learning, AutoML tools, to make models more efficient and easier to scale. And also more attention on designing better evaluation metrics or building shared benchmarks, make it easier to compare model performance across tasks and domains. As the field continues to grow, multi-modal learning is expected to improve many areas: computer vision, natural language processing, speech recognition, and healthcare. In the future, it may help to build AI systems that can understand the world in a way more like humans, flexible, context aware, and able to deal with real-world complexity.</li>
</ul>

<h3>Title: ReCode: Updating Code API Knowledge with Reinforcement Learning</h3>
<ul>
<li><strong>Authors: </strong>Haoze Wu, Yunzhi Yao, Wenhao Yu, Huajun Chen, Ningyu Zhang</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.IR, cs.LG, cs.SE</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.20495">https://arxiv.org/abs/2506.20495</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.20495">https://arxiv.org/pdf/2506.20495</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.20495]] ReCode: Updating Code API Knowledge with Reinforcement Learning(https://arxiv.org/abs/2506.20495)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large Language Models (LLMs) exhibit remarkable code generation capabilities but falter when adapting to frequent updates in external library APIs. This critical limitation, stemming from reliance on outdated API knowledge from their training data, even with access to current documentation, impedes reliable code generation in dynamic environments. To tackle this issue, we propose ReCode (rule-based Reinforcement learning for Code Update), a novel framework that mimics human programmer adaptation to API changes. Specifically, we construct a dataset of approximately 2,000 data entries to train the LLMs to perform version migration based on updated information. Then, we introduce a modified string similarity metric for code evaluation as the reward for reinforcement learning. Our experiments demonstrate that ReCode substantially boosts LLMs' code generation performance in dynamic API scenarios, especially on the unseen CodeUpdateArena task. Crucially, compared to supervised fine-tuning, ReCode has less impact on LLMs' general code generation abilities. We apply ReCode on various LLMs and reinforcement learning algorithms (GRPO and DAPO), all achieving consistent improvements. Notably, after training, Qwen2.5-Coder-7B outperforms that of the 32B parameter code instruction-tuned model and the reasoning model with the same architecture. Code is available at this https URL.</li>
</ul>

<h3>Title: Collaborative Batch Size Optimization for Federated Learning</h3>
<ul>
<li><strong>Authors: </strong>Arno Geimer, Karthick Panner Selvam, Beltran Fiz Pontiveros</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.DC</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.20511">https://arxiv.org/abs/2506.20511</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.20511">https://arxiv.org/pdf/2506.20511</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.20511]] Collaborative Batch Size Optimization for Federated Learning(https://arxiv.org/abs/2506.20511)</code><input type="text"></li>
<li><strong>Keywords: </strong>federate</a></li>
<li><strong>Abstract: </strong>Federated Learning (FL) is a decentralized collaborative Machine Learning framework for training models without collecting data in a centralized location. It has seen application across various disciplines, from helping medical diagnoses in hospitals to detecting fraud in financial transactions. In this paper, we focus on improving the local training process through hardware usage optimization. While participants in a federation might share the hardware they are training on, since there is no information exchange between them, their training process can be hindered by an improper training configuration. Taking advantage of the parallel processing inherent to Federated Learning, we use a greedy randomized search to optimize local batch sizes for the best training settings across all participants. Our results show that against default parameter settings, our method improves convergence speed while staying nearly on par with the case where local parameters are optimized.</li>
</ul>

<h3>Title: WallStreetFeds: Client-Specific Tokens as Investment Vehicles in Federated Learning</h3>
<ul>
<li><strong>Authors: </strong>Arno Geimer, Beltran Fiz Pontiveros, Radu State</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.20518">https://arxiv.org/abs/2506.20518</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.20518">https://arxiv.org/pdf/2506.20518</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.20518]] WallStreetFeds: Client-Specific Tokens as Investment Vehicles in Federated Learning(https://arxiv.org/abs/2506.20518)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, privacy, attack, federate</a></li>
<li><strong>Abstract: </strong>Federated Learning (FL) is a collaborative machine learning paradigm which allows participants to collectively train a model while training data remains private. This paradigm is especially beneficial for sectors like finance, where data privacy, security and model performance are paramount. FL has been extensively studied in the years following its introduction, leading to, among others, better performing collaboration techniques, ways to defend against other clients trying to attack the model, and contribution assessment methods. An important element in for-profit Federated Learning is the development of incentive methods to determine the allocation and distribution of rewards for participants. While numerous methods for allocation have been proposed and thoroughly explored, distribution frameworks remain relatively understudied. In this paper, we propose a novel framework which introduces client-specific tokens as investment vehicles within the FL ecosystem. Our framework aims to address the limitations of existing incentive schemes by leveraging a decentralized finance (DeFi) platform and automated market makers (AMMs) to create a more flexible and scalable reward distribution system for participants, and a mechanism for third parties to invest in the federation learning process.</li>
</ul>

<h3>Title: Asymmetric REINFORCE for off-Policy Reinforcement Learning: Balancing positive and negative rewards</h3>
<ul>
<li><strong>Authors: </strong>Charles Arnal, Gaëtan Narozniak, Vivien Cabannes, Yunhao Tang, Julia Kempe, Remi Munos</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.20520">https://arxiv.org/abs/2506.20520</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.20520">https://arxiv.org/pdf/2506.20520</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.20520]] Asymmetric REINFORCE for off-Policy Reinforcement Learning: Balancing positive and negative rewards(https://arxiv.org/abs/2506.20520)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Reinforcement learning (RL) is increasingly used to align large language models (LLMs). Off-policy methods offer greater implementation simplicity and data efficiency than on-policy techniques, but often result in suboptimal performance. In this work, we study the intermediate range of algorithms between off-policy RL and supervised fine-tuning by analyzing a simple off-policy REINFORCE algorithm, where the advantage is defined as $A=r-V$, with $r$ a reward and $V$ some tunable baseline. Intuitively, lowering $V$ emphasizes high-reward samples, while raising it penalizes low-reward ones more heavily. We first provide a theoretical analysis of this off-policy REINFORCE algorithm, showing that when the baseline $V$ lower-bounds the expected reward, the algorithm enjoys a policy improvement guarantee. Our analysis reveals that while on-policy updates can safely leverage both positive and negative signals, off-policy updates benefit from focusing more on positive rewards than on negative ones. We validate our findings experimentally in a controlled stochastic bandit setting and through fine-tuning state-of-the-art LLMs on reasoning tasks.</li>
</ul>

<h3>Title: Industrial Energy Disaggregation with Digital Twin-generated Dataset and Efficient Data Augmentation</h3>
<ul>
<li><strong>Authors: </strong>Christian Internò, Andrea Castellani, Sebastian Schmitt, Fabio Stella, Barbara Hammer</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, eess.SY</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.20525">https://arxiv.org/abs/2506.20525</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.20525">https://arxiv.org/pdf/2506.20525</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.20525]] Industrial Energy Disaggregation with Digital Twin-generated Dataset and Efficient Data Augmentation(https://arxiv.org/abs/2506.20525)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy</a></li>
<li><strong>Abstract: </strong>Industrial Non-Intrusive Load Monitoring (NILM) is limited by the scarcity of high-quality datasets and the complex variability of industrial energy consumption patterns. To address data scarcity and privacy issues, we introduce the Synthetic Industrial Dataset for Energy Disaggregation (SIDED), an open-source dataset generated using Digital Twin simulations. SIDED includes three types of industrial facilities across three different geographic locations, capturing diverse appliance behaviors, weather conditions, and load profiles. We also propose the Appliance-Modulated Data Augmentation (AMDA) method, a computationally efficient technique that enhances NILM model generalization by intelligently scaling appliance power contributions based on their relative impact. We show in experiments that NILM models trained with AMDA-augmented data significantly improve the disaggregation of energy consumption of complex industrial appliances like combined heat and power systems. Specifically, in our out-of-sample scenarios, models trained with AMDA achieved a Normalized Disaggregation Error of 0.093, outperforming models trained without data augmentation (0.451) and those trained with random data augmentation (0.290). Data distribution analyses confirm that AMDA effectively aligns training and test data distributions, enhancing model generalization.</li>
</ul>

<h3>Title: Demonstration of effective UCB-based routing in skill-based queues on real-world data</h3>
<ul>
<li><strong>Authors: </strong>Sanne van Kempen, Jaron Sanders, Fiona Sloothaak, Maarten G. Wolf</a></li>
<li><strong>Subjects: </strong>cs.LG, math.OC</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.20543">https://arxiv.org/abs/2506.20543</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.20543">https://arxiv.org/pdf/2506.20543</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.20543]] Demonstration of effective UCB-based routing in skill-based queues on real-world data(https://arxiv.org/abs/2506.20543)</code><input type="text"></li>
<li><strong>Keywords: </strong>fair</a></li>
<li><strong>Abstract: </strong>This paper is about optimally controlling skill-based queueing systems such as data centers, cloud computing networks, and service systems. By means of a case study using a real-world data set, we investigate the practical implementation of a recently developed reinforcement learning algorithm for optimal customer routing. Our experiments show that the algorithm efficiently learns and adapts to changing environments and outperforms static benchmark policies, indicating its potential for live implementation. We also augment the real-world applicability of this algorithm by introducing a new heuristic routing rule to reduce delays. Moreover, we show that the algorithm can optimize for multiple objectives: next to payoff maximization, secondary objectives such as server load fairness and customer waiting time reduction can be incorporated. Tuning parameters are used for balancing inherent performance trade--offs. Lastly, we investigate the sensitivity to estimation errors and parameter tuning, providing valuable insights for implementing adaptive routing algorithms in complex real-world queueing systems.</li>
</ul>

<h3>Title: When Life Gives You Samples: The Benefits of Scaling up Inference Compute for Multilingual LLMs</h3>
<ul>
<li><strong>Authors: </strong>Ammar Khairi, Daniel D'souza, Ye Shen, Julia Kreutzer, Sara Hooker</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.20544">https://arxiv.org/abs/2506.20544</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.20544">https://arxiv.org/pdf/2506.20544</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.20544]] When Life Gives You Samples: The Benefits of Scaling up Inference Compute for Multilingual LLMs(https://arxiv.org/abs/2506.20544)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, generative, large language model</a></li>
<li><strong>Abstract: </strong>Recent advancements in large language models (LLMs) have shifted focus toward scaling inference-time compute, improving performance without retraining the model. A common approach is to sample multiple outputs in parallel, and select one of these as the final output. However, work to date has focused on English and a handful of domains such as math and code. In contrast, we are most interested in techniques that generalize across open-ended tasks, formally verifiable tasks, and across languages. In this work, we study how to robustly scale inference-time compute for open-ended generative tasks in a multilingual, multi-task setting. Our findings show that both sampling strategy based on temperature variation and selection strategy must be adapted to account for diverse domains and varied language settings. We evaluate existing selection methods, revealing that strategies effective in English often fail to generalize across languages. We propose novel sampling and selection strategies specifically adapted for multilingual and multi-task inference scenarios, and show they yield notable gains across languages and tasks. In particular, our combined sampling and selection methods lead to an average +6.8 jump in win-rates for our 8B models on m-ArenaHard-v2.0 prompts, against proprietary models such as Gemini. At larger scale, Command-A (111B model) equipped with our methods, shows +9.0 improvement in win-rates on the same benchmark with just five samples against single-sample decoding, a substantial increase at minimal cost. Our results underscore the need for language- and task-aware approaches to inference-time compute, aiming to democratize performance improvements in underrepresented languages.</li>
</ul>

<h3>Title: Pay Less Attention to Deceptive Artifacts: Robust Detection of Compressed Deepfakes on Online Social Networks</h3>
<ul>
<li><strong>Authors: </strong>Manyi Li, Renshuai Tao, Yufan Liu, Chuangchuang Tan, Haotong Qin, Bing Li, Yunchao Wei, Yao Zhao</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI, cs.LG, cs.MM</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.20548">https://arxiv.org/abs/2506.20548</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.20548">https://arxiv.org/pdf/2506.20548</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.20548]] Pay Less Attention to Deceptive Artifacts: Robust Detection of Compressed Deepfakes on Online Social Networks(https://arxiv.org/abs/2506.20548)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, diffusion, generative</a></li>
<li><strong>Abstract: </strong>With the rapid advancement of deep learning, particularly through generative adversarial networks (GANs) and diffusion models (DMs), AI-generated images, or ``deepfakes", have become nearly indistinguishable from real ones. These images are widely shared across Online Social Networks (OSNs), raising concerns about their misuse. Existing deepfake detection methods overlook the ``block effects" introduced by compression in OSNs, which obscure deepfake artifacts, and primarily focus on raw images, rarely encountered in real-world scenarios. To address these challenges, we propose PLADA (Pay Less Attention to Deceptive Artifacts), a novel framework designed to tackle the lack of paired data and the ineffective use of compressed images. PLADA consists of two core modules: Block Effect Eraser (B2E), which uses a dual-stage attention mechanism to handle block effects, and Open Data Aggregation (ODA), which processes both paired and unpaired data to improve detection. Extensive experiments across 26 datasets demonstrate that PLADA achieves a remarkable balance in deepfake detection, outperforming SoTA methods in detecting deepfakes on OSNs, even with limited paired data and compression. More importantly, this work introduces the ``block effect" as a critical factor in deepfake detection, providing a robust solution for open-world scenarios. Our code is available at this https URL.</li>
</ul>

<h3>Title: Lightweight Multi-Frame Integration for Robust YOLO Object Detection in Videos</h3>
<ul>
<li><strong>Authors: </strong>Yitong Quan, Benjamin Kiefer, Martin Messmer, Andreas Zell</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.RO</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.20550">https://arxiv.org/abs/2506.20550</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.20550">https://arxiv.org/pdf/2506.20550</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.20550]] Lightweight Multi-Frame Integration for Robust YOLO Object Detection in Videos(https://arxiv.org/abs/2506.20550)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Modern image-based object detection models, such as YOLOv7, primarily process individual frames independently, thus ignoring valuable temporal context naturally present in videos. Meanwhile, existing video-based detection methods often introduce complex temporal modules, significantly increasing model size and computational complexity. In practical applications such as surveillance and autonomous driving, transient challenges including motion blur, occlusions, and abrupt appearance changes can severely degrade single-frame detection performance. To address these issues, we propose a straightforward yet highly effective strategy: stacking multiple consecutive frames as input to a YOLO-based detector while supervising only the output corresponding to a single target frame. This approach leverages temporal information with minimal modifications to existing architectures, preserving simplicity, computational efficiency, and real-time inference capability. Extensive experiments on the challenging MOT20Det and our BOAT360 datasets demonstrate that our method improves detection robustness, especially for lightweight models, effectively narrowing the gap between compact and heavy detection networks. Additionally, we contribute the BOAT360 benchmark dataset, comprising annotated fisheye video sequences captured from a boat, to support future research in multi-frame video object detection in challenging real-world scenarios.</li>
</ul>

<h3>Title: AdvMIM: Adversarial Masked Image Modeling for Semi-Supervised Medical Image Segmentation</h3>
<ul>
<li><strong>Authors: </strong>Lei Zhu, Jun Zhou, Rick Siow Mong Goh, Yong Liu</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.20563">https://arxiv.org/abs/2506.20563</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.20563">https://arxiv.org/pdf/2506.20563</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.20563]] AdvMIM: Adversarial Masked Image Modeling for Semi-Supervised Medical Image Segmentation(https://arxiv.org/abs/2506.20563)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer, segmentation</a></li>
<li><strong>Abstract: </strong>Vision Transformer has recently gained tremendous popularity in medical image segmentation task due to its superior capability in capturing long-range dependencies. However, transformer requires a large amount of labeled data to be effective, which hinders its applicability in annotation scarce semi-supervised learning scenario where only limited labeled data is available. State-of-the-art semi-supervised learning methods propose combinatorial CNN-Transformer learning to cross teach a transformer with a convolutional neural network, which achieves promising results. However, it remains a challenging task to effectively train the transformer with limited labeled data. In this paper, we propose an adversarial masked image modeling method to fully unleash the potential of transformer for semi-supervised medical image segmentation. The key challenge in semi-supervised learning with transformer lies in the lack of sufficient supervision signal. To this end, we propose to construct an auxiliary masked domain from original domain with masked image modeling and train the transformer to predict the entire segmentation mask with masked inputs to increase supervision signal. We leverage the original labels from labeled data and pseudo-labels from unlabeled data to learn the masked domain. To further benefit the original domain from masked domain, we provide a theoretical analysis of our method from a multi-domain learning perspective and devise a novel adversarial training loss to reduce the domain gap between the original and masked domain, which boosts semi-supervised learning performance. We also extend adversarial masked image modeling to CNN network. Extensive experiments on three public medical image segmentation datasets demonstrate the effectiveness of our method, where our method outperforms existing methods significantly. Our code is publicly available at this https URL.</li>
</ul>

<h3>Title: Benchmarking Unsupervised Strategies for Anomaly Detection in Multivariate Time Series</h3>
<ul>
<li><strong>Authors: </strong>Laura Boggia, Rafael Teixeira de Lima, Bogdan Malaescu</a></li>
<li><strong>Subjects: </strong>cs.LG, stat.ME</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.20574">https://arxiv.org/abs/2506.20574</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.20574">https://arxiv.org/pdf/2506.20574</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.20574]] Benchmarking Unsupervised Strategies for Anomaly Detection in Multivariate Time Series(https://arxiv.org/abs/2506.20574)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Anomaly detection in multivariate time series is an important problem across various fields such as healthcare, financial services, manufacturing or physics detector monitoring. Accurately identifying when unexpected errors or faults occur is essential, yet challenging, due to the unknown nature of anomalies and the complex interdependencies between time series dimensions. In this paper, we investigate transformer-based approaches for time series anomaly detection, focusing on the recently proposed iTransformer architecture. Our contributions are fourfold: (i) we explore the application of the iTransformer to time series anomaly detection, and analyse the influence of key parameters such as window size, step size, and model dimensions on performance; (ii) we examine methods for extracting anomaly labels from multidimensional anomaly scores and discuss appropriate evaluation metrics for such labels; (iii) we study the impact of anomalous data present during training and assess the effectiveness of alternative loss functions in mitigating their influence; and (iv) we present a comprehensive comparison of several transformer-based models across a diverse set of datasets for time series anomaly detection.</li>
</ul>

<h3>Title: Exploring Graph-Transformer Out-of-Distribution Generalization Abilities</h3>
<ul>
<li><strong>Authors: </strong>Itay Niv, Neta Rabin</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.20575">https://arxiv.org/abs/2506.20575</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.20575">https://arxiv.org/pdf/2506.20575</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.20575]] Exploring Graph-Transformer Out-of-Distribution Generalization Abilities(https://arxiv.org/abs/2506.20575)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, transformer</a></li>
<li><strong>Abstract: </strong>Deep learning on graphs has shown remarkable success across numerous applications, including social networks, bio-physics, traffic networks, and recommendation systems. Regardless of their successes, current methods frequently depend on the assumption that training and testing data share the same distribution, a condition rarely met in real-world scenarios. While graph-transformer (GT) backbones have recently outperformed traditional message-passing neural networks (MPNNs) in multiple in-distribution (ID) benchmarks, their effectiveness under distribution shifts remains largely unexplored. In this work, we address the challenge of out-of-distribution (OOD) generalization for graph neural networks, with a special focus on the impact of backbone architecture. We systematically evaluate GT and hybrid backbones in OOD settings and compare them to MPNNs. To do so, we adapt several leading domain generalization (DG) algorithms to work with GTs and assess their performance on a benchmark designed to test a variety of distribution shifts. Our results reveal that GT and hybrid GT-MPNN backbones consistently demonstrate stronger generalization ability compared to MPNNs, even without specialized DG algorithms. Additionally, we propose a novel post-training analysis approach that compares the clustering structure of the entire ID and OOD test datasets, specifically examining domain alignment and class separation. Demonstrating its model-agnostic design, this approach not only provided meaningful insights into GT and MPNN backbones. It also shows promise for broader applicability to DG problems beyond graph learning, offering a deeper perspective on generalization abilities that goes beyond standard accuracy metrics. Together, our findings highlight the promise of graph-transformers for robust, real-world graph learning and set a new direction for future research in OOD generalization.</li>
</ul>

<h3>Title: Vulnerability Disclosure through Adaptive Black-Box Adversarial Attacks on NIDS</h3>
<ul>
<li><strong>Authors: </strong>Sabrine Ennaji, Elhadj Benkhelifa, Luigi V. Mancini</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.20576">https://arxiv.org/abs/2506.20576</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.20576">https://arxiv.org/pdf/2506.20576</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.20576]] Vulnerability Disclosure through Adaptive Black-Box Adversarial Attacks on NIDS(https://arxiv.org/abs/2506.20576)</code><input type="text"></li>
<li><strong>Keywords: </strong>defense, attack, robust</a></li>
<li><strong>Abstract: </strong>Adversarial attacks, wherein slight inputs are carefully crafted to mislead intelligent models, have attracted increasing attention. However, a critical gap persists between theoretical advancements and practical application, particularly in structured data like network traffic, where interdependent features complicate effective adversarial manipulations. Moreover, ambiguity in current approaches restricts reproducibility and limits progress in this field. Hence, existing defenses often fail to handle evolving adversarial attacks. This paper proposes a novel approach for black-box adversarial attacks, that addresses these limitations. Unlike prior work, which often assumes system access or relies on repeated probing, our method strictly respect black-box constraints, reducing interaction to avoid detection and better reflect real-world scenarios. We present an adaptive feature selection strategy using change-point detection and causality analysis to identify and target sensitive features to perturbations. This lightweight design ensures low computational cost and high deployability. Our comprehensive experiments show the attack's effectiveness in evading detection with minimal interaction, enhancing its adaptability and applicability in real-world scenarios. By advancing the understanding of adversarial attacks in network traffic, this work lays a foundation for developing robust defenses.</li>
</ul>

<h3>Title: Causal Representation Learning with Observational Grouping for CXR Classification</h3>
<ul>
<li><strong>Authors: </strong>Rajat Rasal, Avinash Kori, Ben Glocker</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.20582">https://arxiv.org/abs/2506.20582</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.20582">https://arxiv.org/pdf/2506.20582</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.20582]] Causal Representation Learning with Observational Grouping for CXR Classification(https://arxiv.org/abs/2506.20582)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Identifiable causal representation learning seeks to uncover the true causal relationships underlying a data generation process. In medical imaging, this presents opportunities to improve the generalisability and robustness of task-specific latent features. This work introduces the concept of grouping observations to learn identifiable representations for disease classification in chest X-rays via an end-to-end framework. Our experiments demonstrate that these causal representations improve generalisability and robustness across multiple classification tasks when grouping is used to enforce invariance w.r.t race, sex, and imaging views.</li>
</ul>

<h3>Title: On the Impact of Sybil-based Attacks on Mobile Crowdsensing for Transportation</h3>
<ul>
<li><strong>Authors: </strong>Alexander Söderhäll, Zahra Alimadadi, Panos Papadimitratos</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.20585">https://arxiv.org/abs/2506.20585</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.20585">https://arxiv.org/pdf/2506.20585</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.20585]] On the Impact of Sybil-based Attacks on Mobile Crowdsensing for Transportation(https://arxiv.org/abs/2506.20585)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack</a></li>
<li><strong>Abstract: </strong>Mobile Crowd-Sensing (MCS) enables users with personal mobile devices (PMDs) to gain information on their surroundings. Users collect and contribute data on different phenomena using their PMD sensors, and the MCS system processes this data to extract valuable information for end users. Navigation MCS-based applications (N-MCS) are prevalent and important for transportation: users share their location and speed while driving and, in return, find efficient routes to their destinations. However, N-MCS are currently vulnerable to malicious contributors, often termed Sybils: submitting falsified data, seemingly from many devices that are not truly present on target roads, falsely reporting congestion when there is none, thus changing the road status the N-MCS infers. The attack effect is that the N-MCS returns suboptimal routes to users, causing late arrival and, overall, deteriorating road traffic flow. We investigate exactly the impact of Sybil-based attacks on N-MCS: we design an N-MCS system that offers efficient routing on top of the vehicular simulator SUMO, using the InTAS road network as our scenario. We design experiments attacking an individual N-MCS user as well as a larger population of users, selecting the adversary targets based on graph-theoretical arguments. Our experiments show that the resources required for a successful attack depend on the location of the attack (i.e., the surrounding road network and traffic) and the extent of Sybil contributed data for the targeted road(s). We demonstrate that Sybil attacks can alter the route of N-MCS users, increasing average travel time by 20% with Sybils 3% of the N-MCS user population.</li>
</ul>

<h3>Title: Learning-Based Distance Estimation for 360° Single-Sensor Setups</h3>
<ul>
<li><strong>Authors: </strong>Yitong Quan, Benjamin Kiefer, Martin Messmer, Andreas Zell</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.RO</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.20586">https://arxiv.org/abs/2506.20586</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.20586">https://arxiv.org/pdf/2506.20586</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.20586]] Learning-Based Distance Estimation for 360° Single-Sensor Setups(https://arxiv.org/abs/2506.20586)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Accurate distance estimation is a fundamental challenge in robotic perception, particularly in omnidirectional imaging, where traditional geometric methods struggle with lens distortions and environmental variability. In this work, we propose a neural network-based approach for monocular distance estimation using a single 360° fisheye lens camera. Unlike classical trigonometric techniques that rely on precise lens calibration, our method directly learns and infers the distance of objects from raw omnidirectional inputs, offering greater robustness and adaptability across diverse conditions. We evaluate our approach on three 360° datasets (LOAF, ULM360, and a newly captured dataset Boat360), each representing distinct environmental and sensor setups. Our experimental results demonstrate that the proposed learning-based model outperforms traditional geometry-based methods and other learning baselines in both accuracy and robustness. These findings highlight the potential of deep learning for real-time omnidirectional distance estimation, making our approach particularly well-suited for low-cost applications in robotics, autonomous navigation, and surveillance.</li>
</ul>

<h3>Title: TRIM: A Self-Supervised Video Summarization Framework Maximizing Temporal Relative Information and Representativeness</h3>
<ul>
<li><strong>Authors: </strong>Pritam Mishra, Coloma Ballester, Dimosthenis Karatzas</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.20588">https://arxiv.org/abs/2506.20588</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.20588">https://arxiv.org/pdf/2506.20588</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.20588]] TRIM: A Self-Supervised Video Summarization Framework Maximizing Temporal Relative Information and Representativeness(https://arxiv.org/abs/2506.20588)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>The increasing ubiquity of video content and the corresponding demand for efficient access to meaningful information have elevated video summarization and video highlights as a vital research area. However, many state-of-the-art methods depend heavily either on supervised annotations or on attention-based models, which are computationally expensive and brittle in the face of distribution shifts that hinder cross-domain applicability across datasets. We introduce a pioneering self-supervised video summarization model that captures both spatial and temporal dependencies without the overhead of attention, RNNs, or transformers. Our framework integrates a novel set of Markov process-driven loss metrics and a two-stage self supervised learning paradigm that ensures both performance and efficiency. Our approach achieves state-of-the-art performance on the SUMME and TVSUM datasets, outperforming all existing unsupervised methods. It also rivals the best supervised models, demonstrating the potential for efficient, annotation-free architectures. This paves the way for more generalizable video summarization techniques and challenges the prevailing reliance on complex architectures.</li>
</ul>

<h3>Title: SFNet: Fusion of Spatial and Frequency-Domain Features for Remote Sensing Image Forgery Detection</h3>
<ul>
<li><strong>Authors: </strong>Ji Qi, Xinchang Zhang, Dingqi Ye, Yongjia Ruan, Xin Guo, Shaowen Wang, Haifeng Li</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.20599">https://arxiv.org/abs/2506.20599</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.20599">https://arxiv.org/pdf/2506.20599</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.20599]] SFNet: Fusion of Spatial and Frequency-Domain Features for Remote Sensing Image Forgery Detection(https://arxiv.org/abs/2506.20599)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, generative</a></li>
<li><strong>Abstract: </strong>The rapid advancement of generative artificial intelligence is producing fake remote sensing imagery (RSI) that is increasingly difficult to detect, potentially leading to erroneous intelligence, fake news, and even conspiracy theories. Existing forgery detection methods typically rely on single visual features to capture predefined artifacts, such as spatial-domain cues to detect forged objects like roads or buildings in RSI, or frequency-domain features to identify artifacts from up-sampling operations in adversarial generative networks (GANs). However, the nature of artifacts can significantly differ depending on geographic terrain, land cover types, or specific features within the RSI. Moreover, these complex artifacts evolve as generative models become more sophisticated. In short, over-reliance on a single visual cue makes existing forgery detectors struggle to generalize across diverse remote sensing data. This paper proposed a novel forgery detection framework called SFNet, designed to identify fake images in diverse remote sensing data by leveraging spatial and frequency domain features. Specifically, to obtain rich and comprehensive visual information, SFNet employs two independent feature extractors to capture spatial and frequency domain features from input RSIs. To fully utilize the complementary domain features, the domain feature mapping module and the hybrid domain feature refinement module(CBAM attention) of SFNet are designed to successively align and fuse the multi-domain features while suppressing redundant information. Experiments on three datasets show that SFNet achieves an accuracy improvement of 4%-15.18% over the state-of-the-art RS forgery detection methods and exhibits robust generalization capabilities. The code is available at this https URL.</li>
</ul>

<h3>Title: Video Perception Models for 3D Scene Synthesis</h3>
<ul>
<li><strong>Authors: </strong>Rui Huang, Guangyao Zhai, Zuria Bauer, Marc Pollefeys, Federico Tombari, Leonidas Guibas, Gao Huang, Francis Engelmann</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.20601">https://arxiv.org/abs/2506.20601</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.20601">https://arxiv.org/pdf/2506.20601</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.20601]] Video Perception Models for 3D Scene Synthesis(https://arxiv.org/abs/2506.20601)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Traditionally, 3D scene synthesis requires expert knowledge and significant manual effort. Automating this process could greatly benefit fields such as architectural design, robotics simulation, virtual reality, and gaming. Recent approaches to 3D scene synthesis often rely on the commonsense reasoning of large language models (LLMs) or strong visual priors of modern image generation models. However, current LLMs demonstrate limited 3D spatial reasoning ability, which restricts their ability to generate realistic and coherent 3D scenes. Meanwhile, image generation-based methods often suffer from constraints in viewpoint selection and multi-view inconsistencies. In this work, we present Video Perception models for 3D Scene synthesis (VIPScene), a novel framework that exploits the encoded commonsense knowledge of the 3D physical world in video generation models to ensure coherent scene layouts and consistent object placements across views. VIPScene accepts both text and image prompts and seamlessly integrates video generation, feedforward 3D reconstruction, and open-vocabulary perception models to semantically and geometrically analyze each object in a scene. This enables flexible scene synthesis with high realism and structural consistency. For more precise analysis, we further introduce First-Person View Score (FPVScore) for coherence and plausibility evaluation, utilizing continuous first-person perspective to capitalize on the reasoning ability of multimodal large language models. Extensive experiments show that VIPScene significantly outperforms existing methods and generalizes well across diverse scenarios. The code will be released.</li>
</ul>

<h3>Title: Model Editing as a Double-Edged Sword: Steering Agent Ethical Behavior Toward Beneficence or Harm</h3>
<ul>
<li><strong>Authors: </strong>Baixiang Huang, Zhen Tan, Haoran Wang, Zijie Liu, Dawei Li, Ali Payani, Huan Liu, Tianlong Chen, Kai Shu</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.20606">https://arxiv.org/abs/2506.20606</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.20606">https://arxiv.org/pdf/2506.20606</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.20606]] Model Editing as a Double-Edged Sword: Steering Agent Ethical Behavior Toward Beneficence or Harm(https://arxiv.org/abs/2506.20606)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Agents based on Large Language Models (LLMs) have demonstrated strong capabilities across a wide range of tasks. However, deploying LLM-based agents in high-stakes domains comes with significant safety and ethical risks. Unethical behavior by these agents can directly result in serious real-world consequences, including physical harm and financial loss. To efficiently steer the ethical behavior of agents, we frame agent behavior steering as a model editing task, which we term Behavior Editing. Model editing is an emerging area of research that enables precise and efficient modifications to LLMs while preserving their overall capabilities. To systematically study and evaluate this approach, we introduce BehaviorBench, a multi-tier benchmark grounded in psychological moral theories. This benchmark supports both the evaluation and editing of agent behaviors across a variety of scenarios, with each tier introducing more complex and ambiguous scenarios. We first demonstrate that Behavior Editing can dynamically steer agents toward the target behavior within specific scenarios. Moreover, Behavior Editing enables not only scenario-specific local adjustments but also more extensive shifts in an agent's global moral alignment. We demonstrate that Behavior Editing can be used to promote ethical and benevolent behavior or, conversely, to induce harmful or malicious behavior. Through comprehensive evaluations on agents based on frontier LLMs, BehaviorBench shows the effectiveness of Behavior Editing across different models and scenarios. Our findings offer key insights into a new paradigm for steering agent behavior, highlighting both the promise and perils of Behavior Editing.</li>
</ul>

<h3>Title: Shape2Animal: Creative Animal Generation from Natural Silhouettes</h3>
<ul>
<li><strong>Authors: </strong>Quoc-Duy Tran, Anh-Tuan Vo, Dinh-Khoi Vo, Tam V. Nguyen, Minh-Triet Tran, Trung-Nghia Le</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.20616">https://arxiv.org/abs/2506.20616</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.20616">https://arxiv.org/pdf/2506.20616</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.20616]] Shape2Animal: Creative Animal Generation from Natural Silhouettes(https://arxiv.org/abs/2506.20616)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, diffusion, segmentation</a></li>
<li><strong>Abstract: </strong>Humans possess a unique ability to perceive meaningful patterns in ambiguous stimuli, a cognitive phenomenon known as pareidolia. This paper introduces Shape2Animal framework to mimics this imaginative capacity by reinterpreting natural object silhouettes, such as clouds, stones, or flames, as plausible animal forms. Our automated framework first performs open-vocabulary segmentation to extract object silhouette and interprets semantically appropriate animal concepts using vision-language models. It then synthesizes an animal image that conforms to the input shape, leveraging text-to-image diffusion model and seamlessly blends it into the original scene to generate visually coherent and spatially consistent compositions. We evaluated Shape2Animal on a diverse set of real-world inputs, demonstrating its robustness and creative potential. Our Shape2Animal can offer new opportunities for visual storytelling, educational content, digital art, and interactive media design. Our project page is here: this https URL</li>
</ul>

<h3>Title: DiffuCoder: Understanding and Improving Masked Diffusion Models for Code Generation</h3>
<ul>
<li><strong>Authors: </strong>Shansan Gong, Ruixiang Zhang, Huangjie Zheng, Jiatao Gu, Navdeep Jaitly, Lingpeng Kong, Yizhe Zhang</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.20639">https://arxiv.org/abs/2506.20639</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.20639">https://arxiv.org/pdf/2506.20639</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.20639]] DiffuCoder: Understanding and Improving Masked Diffusion Models for Code Generation(https://arxiv.org/abs/2506.20639)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, large language model</a></li>
<li><strong>Abstract: </strong>Diffusion large language models (dLLMs) are compelling alternatives to autoregressive (AR) models because their denoising models operate over the entire sequence. The global planning and iterative refinement features of dLLMs are particularly useful for code generation. However, current training and inference mechanisms for dLLMs in coding are still under-explored. To demystify the decoding behavior of dLLMs and unlock their potential for coding, we systematically investigate their denoising processes and reinforcement learning (RL) methods. We train a 7B dLLM, \textbf{DiffuCoder}, on 130B tokens of code. Using this model as a testbed, we analyze its decoding behavior, revealing how it differs from that of AR models: (1) dLLMs can decide how causal their generation should be without relying on semi-AR decoding, and (2) increasing the sampling temperature diversifies not only token choices but also their generation order. This diversity creates a rich search space for RL rollouts. For RL training, to reduce the variance of token log-likelihood estimates and maintain training efficiency, we propose \textbf{coupled-GRPO}, a novel sampling scheme that constructs complementary mask noise for completions used in training. In our experiments, coupled-GRPO significantly improves DiffuCoder's performance on code generation benchmarks (+4.4\% on EvalPlus) and reduces reliance on AR causal during decoding. Our work provides deeper insight into the machinery of dLLM generation and offers an effective, diffusion-native RL training framework. this https URL.</li>
</ul>

<h3>Title: Memento: Note-Taking for Your Future Self</h3>
<ul>
<li><strong>Authors: </strong>Chao Wan, Albert Gong, Mihir Mishra, Carl-Leander Henneking, Claas Beger, Kilian Q. Weinberger</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.20642">https://arxiv.org/abs/2506.20642</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.20642">https://arxiv.org/pdf/2506.20642</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.20642]] Memento: Note-Taking for Your Future Self(https://arxiv.org/abs/2506.20642)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large language models (LLMs) excel at reasoning-only tasks, but struggle when reasoning must be tightly coupled with retrieval, as in multi-hop question answering. To overcome these limitations, we introduce a prompting strategy that first decomposes a complex question into smaller steps, then dynamically constructs a database of facts using LLMs, and finally pieces these facts together to solve the question. We show how this three-stage strategy, which we call Memento, can boost the performance of existing prompting strategies across diverse settings. On the 9-step PhantomWiki benchmark, Memento doubles the performance of chain-of-thought (CoT) when all information is provided in context. On the open-domain version of 2WikiMultiHopQA, CoT-RAG with Memento improves over vanilla CoT-RAG by more than 20 F1 percentage points and over the multi-hop RAG baseline, IRCoT, by more than 13 F1 percentage points. On the challenging MuSiQue dataset, Memento improves ReAct by more than 3 F1 percentage points, demonstrating its utility in agentic settings.</li>
</ul>

<h3>Title: Efficient Federated Learning with Encrypted Data Sharing for Data-Heterogeneous Edge Devices</h3>
<ul>
<li><strong>Authors: </strong>Hangyu Li, Hongyue Wu, Guodong Fan, Zhen Zhang, Shizhan Chen, Zhiyong Feng</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.20644">https://arxiv.org/abs/2506.20644</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.20644">https://arxiv.org/pdf/2506.20644</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.20644]] Efficient Federated Learning with Encrypted Data Sharing for Data-Heterogeneous Edge Devices(https://arxiv.org/abs/2506.20644)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, protect, federate</a></li>
<li><strong>Abstract: </strong>As privacy protection gains increasing importance, more models are being trained on edge devices and subsequently merged into the central server through Federated Learning (FL). However, current research overlooks the impact of network topology, physical distance, and data heterogeneity on edge devices, leading to issues such as increased latency and degraded model performance. To address these issues, we propose a new federated learning scheme on edge devices that called Federated Learning with Encrypted Data Sharing(FedEDS). FedEDS uses the client model and the model's stochastic layer to train the data encryptor. The data encryptor generates encrypted data and shares it with other clients. The client uses the corresponding client's stochastic layer and encrypted data to train and adjust the local model. FedEDS uses the client's local private data and encrypted shared data from other clients to train the model. This approach accelerates the convergence speed of federated learning training and mitigates the negative impact of data heterogeneity, making it suitable for application services deployed on edge devices requiring rapid convergence. Experiments results show the efficacy of FedEDS in promoting model performance.</li>
</ul>

<h3>Title: Disentangled representations of microscopy images</h3>
<ul>
<li><strong>Authors: </strong>Jacopo Dapueto, Vito Paolo Pastore, Nicoletta Noceti, Francesca Odone</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.20649">https://arxiv.org/abs/2506.20649</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.20649">https://arxiv.org/pdf/2506.20649</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.20649]] Disentangled representations of microscopy images(https://arxiv.org/abs/2506.20649)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability</a></li>
<li><strong>Abstract: </strong>Microscopy image analysis is fundamental for different applications, from diagnosis to synthetic engineering and environmental monitoring. Modern acquisition systems have granted the possibility to acquire an escalating amount of images, requiring a consequent development of a large collection of deep learning-based automatic image analysis methods. Although deep neural networks have demonstrated great performance in this field, interpretability, an essential requirement for microscopy image analysis, remains an open challenge. This work proposes a Disentangled Representation Learning (DRL) methodology to enhance model interpretability for microscopy image classification. Exploiting benchmark datasets from three different microscopic image domains (plankton, yeast vacuoles, and human cells), we show how a DRL framework, based on transferring a representation learnt from synthetic data, can provide a good trade-off between accuracy and interpretability in this domain.</li>
</ul>

<h3>Title: Hear No Evil: Detecting Gradient Leakage by Malicious Servers in Federated Learning</h3>
<ul>
<li><strong>Authors: </strong>Fei Wang, Baochun Li</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CR, cs.DC</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.20651">https://arxiv.org/abs/2506.20651</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.20651">https://arxiv.org/pdf/2506.20651</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.20651]] Hear No Evil: Detecting Gradient Leakage by Malicious Servers in Federated Learning(https://arxiv.org/abs/2506.20651)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, attack, steal, federate</a></li>
<li><strong>Abstract: </strong>Recent work has shown that gradient updates in federated learning (FL) can unintentionally reveal sensitive information about a client's local data. This risk becomes significantly greater when a malicious server manipulates the global model to provoke information-rich updates from clients. In this paper, we adopt a defender's perspective to provide the first comprehensive analysis of malicious gradient leakage attacks and the model manipulation techniques that enable them. Our investigation reveals a core trade-off: these attacks cannot be both highly effective in reconstructing private data and sufficiently stealthy to evade detection -- especially in realistic FL settings that incorporate common normalization techniques and federated averaging. Building on this insight, we argue that malicious gradient leakage attacks, while theoretically concerning, are inherently limited in practice and often detectable through basic monitoring. As a complementary contribution, we propose a simple, lightweight, and broadly applicable client-side detection mechanism that flags suspicious model updates before local training begins, despite the fact that such detection may not be strictly necessary in realistic FL settings. This mechanism further underscores the feasibility of defending against these attacks with minimal overhead, offering a deployable safeguard for privacy-conscious federated learning systems.</li>
</ul>

<h3>Title: MMSearch-R1: Incentivizing LMMs to Search</h3>
<ul>
<li><strong>Authors: </strong>Jinming Wu, Zihao Deng, Wei Li, Yiding Liu, Bo You, Bo Li, Zejun Ma, Ziwei Liu</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.20670">https://arxiv.org/abs/2506.20670</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.20670">https://arxiv.org/pdf/2506.20670</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.20670]] MMSearch-R1: Incentivizing LMMs to Search(https://arxiv.org/abs/2506.20670)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Robust deployment of large multimodal models (LMMs) in real-world scenarios requires access to external knowledge sources, given the complexity and dynamic nature of real-world information. Existing approaches such as retrieval-augmented generation (RAG) and prompt engineered search agents rely on rigid pipelines, often leading to inefficient or excessive search behaviors. We present MMSearch-R1, the first end-to-end reinforcement learning framework that enables LMMs to perform on-demand, multi-turn search in real-world Internet environments. Our framework integrates both image and text search tools, allowing the model to reason about when and how to invoke them guided by an outcome-based reward with a search penalty. To support training, We collect a multimodal search VQA dataset through a semi-automated pipeline that covers diverse visual and textual knowledge needs and curate a search-balanced subset with both search-required and search-free samples, which proves essential for shaping efficient and on-demand search behavior. Extensive experiments on knowledge-intensive and info-seeking VQA tasks show that our model not only outperforms RAG-based baselines of the same model size, but also matches the performance of a larger RAG-based model while reducing search calls by over 30%. We further analyze key empirical findings to offer actionable insights for advancing research in multimodal search.</li>
</ul>

<h3>Title: IPFormer: Visual 3D Panoptic Scene Completion with Context-Adaptive Instance Proposals</h3>
<ul>
<li><strong>Authors: </strong>Markus Gross, Aya Fahmy, Danit Niwattananan, Dominik Muhle, Rui Song, Daniel Cremers, Henri Meeß</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.20671">https://arxiv.org/abs/2506.20671</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.20671">https://arxiv.org/pdf/2506.20671</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.20671]] IPFormer: Visual 3D Panoptic Scene Completion with Context-Adaptive Instance Proposals(https://arxiv.org/abs/2506.20671)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Semantic Scene Completion (SSC) has emerged as a pivotal approach for jointly learning scene geometry and semantics, enabling downstream applications such as navigation in mobile robotics. The recent generalization to Panoptic Scene Completion (PSC) advances the SSC domain by integrating instance-level information, thereby enhancing object-level sensitivity in scene understanding. While PSC was introduced using LiDAR modality, methods based on camera images remain largely unexplored. Moreover, recent Transformer-based SSC approaches utilize a fixed set of learned queries to reconstruct objects within the scene volume. Although these queries are typically updated with image context during training, they remain static at test time, limiting their ability to dynamically adapt specifically to the observed scene. To overcome these limitations, we propose IPFormer, the first approach that leverages context-adaptive instance proposals at train and test time to address vision-based 3D Panoptic Scene Completion. Specifically, IPFormer adaptively initializes these queries as panoptic instance proposals derived from image context and further refines them through attention-based encoding and decoding to reason about semantic instance-voxel relationships. Experimental results show that our approach surpasses state-of-the-art methods in overall panoptic metrics PQ$^\dagger$ and PQ-All, matches performance in individual metrics, and achieves a runtime reduction exceeding 14$\times$. Furthermore, our ablation studies reveal that dynamically deriving instance proposals from image context, as opposed to random initialization, leads to a 3.62% increase in PQ-All and a remarkable average improvement of 18.65% in combined Thing-metrics. These results highlight our introduction of context-adaptive instance proposals as a pioneering effort in addressing vision-based 3D Panoptic Scene Completion.</li>
</ul>

<button id="copy">Copy All</button>
</article>
<script src="../../javascript/clipboard.min.js"></script>
<script src="../../javascript/clipboard.js"></script>
