<link rel="stylesheet" href="../../css/markdown.css" />
<article class="markdown-body">
<h1>2025-11-04</h1>
<h3>Title: VRScout: Towards Real-Time, Autonomous Testing of Virtual Reality Games</h3>
<ul>
<li><strong>Authors: </strong>Yurun Wu, Yousong Sun, Burkhard Wunsche, Jia Wang, Elliott Wen</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.00002">https://arxiv.org/abs/2511.00002</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.00002">https://arxiv.org/pdf/2511.00002</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.00002]] VRScout: Towards Real-Time, Autonomous Testing of Virtual Reality Games(https://arxiv.org/abs/2511.00002)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Virtual Reality (VR) has rapidly become a mainstream platform for gaming and interactive experiences, yet ensuring the quality, safety, and appropriateness of VR content remains a pressing challenge. Traditional human-based quality assurance is labor-intensive and cannot scale with the industry's rapid growth. While automated testing has been applied to traditional 2D and 3D games, extending it to VR introduces unique difficulties due to high-dimensional sensory inputs and strict real-time performance requirements. We present VRScout, a deep learning-based agent capable of autonomously navigating VR environments and interacting with virtual objects in a human-like and real-time manner. VRScout learns from human demonstrations using an enhanced Action Chunking Transformer that predicts multi-step action sequences. This enables our agent to capture higher-level strategies and generalize across diverse environments. To balance responsiveness and precision, we introduce a dynamically adjustable sliding horizon that adapts the agent's temporal context at runtime. We evaluate VRScout on commercial VR titles and show that it achieves expert-level performance with only limited training data, while maintaining real-time inference at 60 FPS on consumer-grade hardware. These results position VRScout as a practical and scalable framework for automated VR game testing, with direct applications in both quality assurance and safety auditing.</li>
</ul>

<h3>Title: PlotCraft: Pushing the Limits of LLMs for Complex and Interactive Data Visualization</h3>
<ul>
<li><strong>Authors: </strong>Jiajun Zhang, Jianke Zhang, Zeyu Cui, Jiaxi Yang, Lei Zhang, Binyuan Hui, Qiang Liu, Zilei Wang, Liang Wang, Junyang Lin</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.00010">https://arxiv.org/abs/2511.00010</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.00010">https://arxiv.org/pdf/2511.00010</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.00010]] PlotCraft: Pushing the Limits of LLMs for Complex and Interactive Data Visualization(https://arxiv.org/abs/2511.00010)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Recent Large Language Models (LLMs) have demonstrated remarkable profi- ciency in code generation. However, their ability to create complex visualiza- tions for scaled and structured data remains largely unevaluated and underdevel- oped. To address this gap, we introduce PlotCraft, a new benchmark featuring 1k challenging visualization tasks that cover a wide range of topics, such as fi- nance, scientific research, and sociology. The benchmark is structured around seven high-level visualization tasks and encompasses 48 distinct chart types. Cru- cially, it is the first to systematically evaluate both single-turn generation and multi-turn refinement across a diverse spectrum of task complexities. Our com- prehensive evaluation of 23 leading LLMs on PlotCraft reveals obvious per- formance deficiencies in handling sophisticated visualization tasks. To bridge this performance gap, we develope SynthVis-30K, a large-scale, high-quality dataset of complex visualization code synthesized via a collaborative agent frame- work. Building upon this dataset, we develope PlotCraftor, a novel code gener- ation model that achieves strong capabilities in complex data visualization with a remarkably small size. Across VisEval, PandasPlotBench, and our proposed PlotCraft, PlotCraftor shows performance comparable to that of leading propri- etary approaches. Especially, on hard task, Our model achieves over 50% per- formance improvement. We will release the benchmark, dataset, and code at this https URL.</li>
</ul>

<h3>Title: Generative human motion mimicking through feature extraction in denoising diffusion settings</h3>
<ul>
<li><strong>Authors: </strong>Alexander Okupnik, Johannes Schneider, Kyriakos Flouris</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI, cs.HC</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.00011">https://arxiv.org/abs/2511.00011</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.00011">https://arxiv.org/pdf/2511.00011</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.00011]] Generative human motion mimicking through feature extraction in denoising diffusion settings(https://arxiv.org/abs/2511.00011)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction, diffusion, generative, large language model</a></li>
<li><strong>Abstract: </strong>Recent success with large language models has sparked a new wave of verbal human-AI interaction. While such models support users in a variety of creative tasks, they lack the embodied nature of human interaction. Dance, as a primal form of human expression, is predestined to complement this experience. To explore creative human-AI interaction exemplified by dance, we build an interactive model based on motion capture (MoCap) data. It generates an artificial other by partially mimicking and also "creatively" enhancing an incoming sequence of movement data. It is the first model, which leverages single-person motion data and high level features in order to do so and, thus, it does not rely on low level human-human interaction data. It combines ideas of two diffusion models, motion inpainting, and motion style transfer to generate movement representations that are both temporally coherent and responsive to a chosen movement reference. The success of the model is demonstrated by quantitatively assessing the convergence of the feature distribution of the generated samples and the test set which serves as simulating the human performer. We show that our generations are first steps to creative dancing with AI as they are both diverse showing various deviations from the human partner while appearing realistic.</li>
</ul>

<h3>Title: Deep Learning Models for Coral Bleaching Classification in Multi-Condition Underwater Image Datasets</h3>
<ul>
<li><strong>Authors: </strong>Julio Jerison E. Macrohon, Gordon Hung</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.00021">https://arxiv.org/abs/2511.00021</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.00021">https://arxiv.org/pdf/2511.00021</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.00021]] Deep Learning Models for Coral Bleaching Classification in Multi-Condition Underwater Image Datasets(https://arxiv.org/abs/2511.00021)</code><input type="text"></li>
<li><strong>Keywords: </strong>protect, transformer</a></li>
<li><strong>Abstract: </strong>Coral reefs support numerous marine organisms and are an important source of coastal protection from storms and floods, representing a major part of marine ecosystems. However coral reefs face increasing threats from pollution, ocean acidification, and sea temperature anomalies, making efficient protection and monitoring heavily urgent. Therefore, this study presents a novel machine-learning-based coral bleaching classification system based on a diverse global dataset with samples of healthy and bleached corals under varying environmental conditions, including deep seas, marshes, and coastal zones. We benchmarked and compared three state-of-the-art models: Residual Neural Network (ResNet), Vision Transformer (ViT), and Convolutional Neural Network (CNN). After comprehensive hyperparameter tuning, the CNN model achieved the highest accuracy of 88%, outperforming existing benchmarks. Our findings offer important insights into autonomous coral monitoring and present a comprehensive analysis of the most widely used computer vision models.</li>
</ul>

<h3>Title: Feature-Guided SAE Steering for Refusal-Rate Control using Contrasting Prompts</h3>
<ul>
<li><strong>Authors: </strong>Samaksh Bhargav, Zining Zhu</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.00029">https://arxiv.org/abs/2511.00029</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.00029">https://arxiv.org/pdf/2511.00029</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.00029]] Feature-Guided SAE Steering for Refusal-Rate Control using Contrasting Prompts(https://arxiv.org/abs/2511.00029)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction, large language model</a></li>
<li><strong>Abstract: </strong>Large Language Model (LLM) deployment requires guiding the LLM to recognize and not answer unsafe prompts while complying with safe prompts. Previous methods for achieving this require adjusting model weights along with other expensive procedures. While recent advances in Sparse Autoencoders (SAEs) have enabled interpretable feature extraction from LLMs, existing approaches lack systematic feature selection methods and principled evaluation of safety-utility tradeoffs. We explored using different steering features and steering strengths using Sparse Auto Encoders (SAEs) to provide a solution. Using an accurate and innovative contrasting prompt method with the AI-Generated Prompts Dataset from teknium/OpenHermes-2p5-Mistral-7B and Air Bench eu-dataset to efficiently choose the best features in the model to steer, we tested this method on Llama-3 8B. We conclude that using this method, our approach achieves an 18.9% improvement in safety performance while simultaneously increasing utility by 11.1%, demonstrating that targeted SAE steering can overcome traditional safety-utility tradeoffs when optimal features are identified through principled selection methods.</li>
</ul>

<h3>Title: From Uniform to Adaptive: General Skip-Block Mechanisms for Efficient PDE Neural Operators</h3>
<ul>
<li><strong>Authors: </strong>Lei Liu, Zhongyi Yu, Hong Wang, Huanshuo Dong, Haiyang Xin, Hongwei Zhao, Bin Li</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.00032">https://arxiv.org/abs/2511.00032</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.00032">https://arxiv.org/pdf/2511.00032</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.00032]] From Uniform to Adaptive: General Skip-Block Mechanisms for Efficient PDE Neural Operators(https://arxiv.org/abs/2511.00032)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>In recent years, Neural Operators(NO) have gradually emerged as a popular approach for solving Partial Differential Equations (PDEs). However, their application to large-scale engineering tasks suffers from significant computational overhead. And the fact that current models impose a uniform computational cost while physical fields exhibit vastly different complexities constitutes a fundamental mismatch, which is the root of this inefficiency. For instance, in turbulence flows, intricate vortex regions require deeper network processing compared to stable flows. To address this, we introduce a framework: Skip-Block Routing (SBR), a general framework designed for Transformer-based neural operators, capable of being integrated into their multi-layer architectures. First, SBR uses a routing mechanism to learn the complexity and ranking of tokens, which is then applied during inference. Then, in later layers, it decides how many tokens are passed forward based on this ranking. This way, the model focuses more processing capacity on the tokens that are more complex. Experiments demonstrate that SBR is a general framework that seamlessly integrates into various neural operators. Our method reduces computational cost by approximately 50% in terms of Floating Point Operations (FLOPs), while still delivering up to 2x faster inference without sacrificing accuracy.</li>
</ul>

<h3>Title: Neural Architecture Search for global multi-step Forecasting of Energy Production Time Series</h3>
<ul>
<li><strong>Authors: </strong>Georg Velev, Stefan Lessmann</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.00035">https://arxiv.org/abs/2511.00035</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.00035">https://arxiv.org/pdf/2511.00035</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.00035]] Neural Architecture Search for global multi-step Forecasting of Energy Production Time Series(https://arxiv.org/abs/2511.00035)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>The dynamic energy sector requires both predictive accuracy and runtime efficiency for short-term forecasting of energy generation under operational constraints, where timely and precise predictions are crucial. The manual configuration of complex methods, which can generate accurate global multi-step predictions without suffering from a computational bottleneck, represents a procedure with significant time requirements and high risk for human-made errors. A further intricacy arises from the temporal dynamics present in energy-related data. Additionally, the generalization to unseen data is imperative for continuously deploying forecasting techniques over time. To overcome these challenges, in this research, we design a neural architecture search (NAS)-based framework for the automated discovery of time series models that strike a balance between computational efficiency, predictive performance, and generalization power for the global, multi-step short-term forecasting of energy production time series. In particular, we introduce a search space consisting only of efficient components, which can capture distinctive patterns of energy time series. Furthermore, we formulate a novel objective function that accounts for performance generalization in temporal context and the maximal exploration of different regions of our high-dimensional search space. The results obtained on energy production time series show that an ensemble of lightweight architectures discovered with NAS outperforms state-of-the-art techniques, such as Transformers, as well as pre-trained forecasting models, in terms of both efficiency and accuracy.</li>
</ul>

<h3>Title: Benchmarking Federated Learning Frameworks for Medical Imaging Deployment: A Comparative Study of NVIDIA FLARE, Flower, and Owkin Substra</h3>
<ul>
<li><strong>Authors: </strong>Riya Gupta, Alexander Chowdhury, Sahil Nalawade</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.DC</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.00037">https://arxiv.org/abs/2511.00037</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.00037">https://arxiv.org/pdf/2511.00037</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.00037]] Benchmarking Federated Learning Frameworks for Medical Imaging Deployment: A Comparative Study of NVIDIA FLARE, Flower, and Owkin Substra(https://arxiv.org/abs/2511.00037)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, federate</a></li>
<li><strong>Abstract: </strong>Federated Learning (FL) has emerged as a transformative paradigm in medical AI, enabling collaborative model training across institutions without direct data sharing. This study benchmarks three prominent FL frameworks NVIDIA FLARE, Flower, and Owkin Substra to evaluate their suitability for medical imaging applications in real-world settings. Using the PathMNIST dataset, we assess model performance, convergence efficiency, communication overhead, scalability, and developer experience. Results indicate that NVIDIA FLARE offers superior production scalability, Flower provides flexibility for prototyping and academic research, and Owkin Substra demonstrates exceptional privacy and compliance features. Each framework exhibits strengths optimized for distinct use cases, emphasizing their relevance to practical deployment in healthcare environments.</li>
</ul>

<h3>Title: Enhancing rice leaf images: An overview of image denoising techniques</h3>
<ul>
<li><strong>Authors: </strong>Rupjyoti Chutia, Dibya Jyoti Bora</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.00046">https://arxiv.org/abs/2511.00046</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.00046">https://arxiv.org/pdf/2511.00046</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.00046]] Enhancing rice leaf images: An overview of image denoising techniques(https://arxiv.org/abs/2511.00046)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction, segmentation</a></li>
<li><strong>Abstract: </strong>Digital image processing involves the systematic handling of images using advanced computer algorithms, and has gained significant attention in both academic and practical fields. Image enhancement is a crucial preprocessing stage in the image-processing chain, improving image quality and emphasizing features. This makes subsequent tasks (segmentation, feature extraction, classification) more reliable. Image enhancement is essential for rice leaf analysis, aiding in disease detection, nutrient deficiency evaluation, and growth analysis. Denoising followed by contrast enhancement are the primary steps. Image filters, generally employed for denoising, transform or enhance visual characteristics like brightness, contrast, and sharpness, playing a crucial role in improving overall image quality and enabling the extraction of useful information. This work provides an extensive comparative study of well-known image-denoising methods combined with CLAHE (Contrast Limited Adaptive Histogram Equalization) for efficient denoising of rice leaf images. The experiments were performed on a rice leaf image dataset to ensure the data is relevant and representative. Results were examined using various metrics to comprehensively test enhancement methods. This approach provides a strong basis for assessing the effectiveness of methodologies in digital image processing and reveals insights useful for future adaptation in agricultural research and other domains.</li>
</ul>

<h3>Title: DynBERG: Dynamic BERT-based Graph neural network for financial fraud detection</h3>
<ul>
<li><strong>Authors: </strong>Omkar Kulkarni, Rohitash Chandra</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CE</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.00047">https://arxiv.org/abs/2511.00047</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.00047">https://arxiv.org/pdf/2511.00047</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.00047]] DynBERG: Dynamic BERT-based Graph neural network for financial fraud detection(https://arxiv.org/abs/2511.00047)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Financial fraud detection is critical for maintaining the integrity of financial systems, particularly in decentralised environments such as cryptocurrency networks. Although Graph Convolutional Networks (GCNs) are widely used for financial fraud detection, graph Transformer models such as Graph-BERT are gaining prominence due to their Transformer-based architecture, which mitigates issues such as over-smoothing. Graph-BERT is designed for static graphs and primarily evaluated on citation networks with undirected edges. However, financial transaction networks are inherently dynamic, with evolving structures and directed edges representing the flow of money. To address these challenges, we introduce DynBERG, a novel architecture that integrates Graph-BERT with a Gated Recurrent Unit (GRU) layer to capture temporal evolution over multiple time steps. Additionally, we modify the underlying algorithm to support directed edges, making DynBERG well-suited for dynamic financial transaction analysis. We evaluate our model on the Elliptic dataset, which includes Bitcoin transactions, including all transactions during a major cryptocurrency market event, the Dark Market Shutdown. By assessing DynBERG's resilience before and after this event, we analyse its ability to adapt to significant market shifts that impact transaction behaviours. Our model is benchmarked against state-of-the-art dynamic graph classification approaches, such as EvolveGCN and GCN, demonstrating superior performance, outperforming EvolveGCN before the market shutdown and surpassing GCN after the event. Additionally, an ablation study highlights the critical role of incorporating a time-series deep learning component, showcasing the effectiveness of GRU in modelling the temporal dynamics of financial transactions.</li>
</ul>

<h3>Title: Adaptive Spatio-Temporal Graphs with Self-Supervised Pretraining for Multi-Horizon Weather Forecasting</h3>
<ul>
<li><strong>Authors: </strong>Yao Liu</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.00049">https://arxiv.org/abs/2511.00049</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.00049">https://arxiv.org/pdf/2511.00049</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.00049]] Adaptive Spatio-Temporal Graphs with Self-Supervised Pretraining for Multi-Horizon Weather Forecasting(https://arxiv.org/abs/2511.00049)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Accurate and robust weather forecasting remains a fundamental challenge due to the inherent spatio-temporal complexity of atmospheric systems. In this paper, we propose a novel self-supervised learning framework that leverages spatio-temporal structures to improve multi-variable weather prediction. The model integrates a graph neural network (GNN) for spatial reasoning, a self-supervised pretraining scheme for representation learning, and a spatio-temporal adaptation mechanism to enhance generalization across varying forecasting horizons. Extensive experiments on both ERA5 and MERRA-2 reanalysis datasets demonstrate that our approach achieves superior performance compared to traditional numerical weather prediction (NWP) models and recent deep learning methods. Quantitative evaluations and visual analyses in Beijing and Shanghai confirm the model's capability to capture fine-grained meteorological patterns. The proposed framework provides a scalable and label-efficient solution for future data-driven weather forecasting systems.</li>
</ul>

<h3>Title: FLoRA: Fused forward-backward adapters for parameter efficient fine-tuning and reducing inference-time latencies of LLMs</h3>
<ul>
<li><strong>Authors: </strong>Dhananjaya Gowda, Seoha Song, Junhyun Lee, Harshith Goka</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.00050">https://arxiv.org/abs/2511.00050</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.00050">https://arxiv.org/pdf/2511.00050</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.00050]] FLoRA: Fused forward-backward adapters for parameter efficient fine-tuning and reducing inference-time latencies of LLMs(https://arxiv.org/abs/2511.00050)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>As the large language models (LLMs) grow in size each day, efficient training and fine-tuning has never been as important as nowadays. This resulted in the great interest in parameter efficient fine-tuning (PEFT), and effective methods including low-rank adapters (LoRA) has emerged. Although the various PEFT methods have been studied extensively in the recent years, the greater part of the subject remains unexplored with the huge degree of freedom. In this paper, we propose FLoRA, a family of fused forward-backward adapters (FFBA) for parameter-efficient fine-tuning of LLMs on downstream tasks. The FFBA combine ideas from the popular LoRA and parallel adapters to improve the overall fine-tuning accuracies. At the same time, latencies are minimized by fusing the forward and backward adapters into existing projection layers of the base model. Experimental results show that the proposed FFB adapters perform significantly better than the popularly used LoRA in both accuracy and latency for a similar parameter budget.</li>
</ul>

<h3>Title: Exploring Federated Learning for Thermal Urban Feature Segmentation -- A Comparison of Centralized and Decentralized Approaches</h3>
<ul>
<li><strong>Authors: </strong>Leonhard Duda, Khadijeh Alibabaei, Elena Vollmer, Leon Klug, Valentin Kozlov, Lisana Berberi, Mishal Benz, Rebekka Volk, Juan Pedro Gutiérrez Hermosillo Muriedas, Markus Götz, Judith Sáínz-Pardo Díaz, Álvaro López García, Frank Schultmann, Achim Streit</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.00055">https://arxiv.org/abs/2511.00055</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.00055">https://arxiv.org/pdf/2511.00055</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.00055]] Exploring Federated Learning for Thermal Urban Feature Segmentation -- A Comparison of Centralized and Decentralized Approaches(https://arxiv.org/abs/2511.00055)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, federate, segmentation</a></li>
<li><strong>Abstract: </strong>Federated Learning (FL) is an approach for training a shared Machine Learning (ML) model with distributed training data and multiple participants. FL allows bypassing limitations of the traditional Centralized Machine Learning CL if data cannot be shared or stored centrally due to privacy or technical restrictions -- the participants train the model locally with their training data and do not need to share it among the other participants. This paper investigates the practical implementation and effectiveness of FL in a real-world scenario, specifically focusing on unmanned aerial vehicle (UAV)-based thermal images for common thermal feature detection in urban environments. The distributed nature of the data arises naturally and makes it suitable for FL applications, as images captured in two German cities are available. This application presents unique challenges due to non-identical distribution and feature characteristics of data captured at both locations. The study makes several key contributions by evaluating FL algorithms in real deployment scenarios rather than simulation. We compare several FL approaches with a centralized learning baseline across key performance metrics such as model accuracy, training time, communication overhead, and energy usage. This paper also explores various FL workflows, comparing client-controlled workflows and server-controlled workflows. The findings of this work serve as a valuable reference for understanding the practical application and limitations of the FL methods in segmentation tasks in UAV-based imaging.</li>
</ul>

<h3>Title: MISA: Memory-Efficient LLMs Optimization with Module-wise Importance Sampling</h3>
<ul>
<li><strong>Authors: </strong>Yuxi Liu, Renjia Deng, Yutong He, Xue Wang, Tao Yao, Kun Yuan</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.00056">https://arxiv.org/abs/2511.00056</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.00056">https://arxiv.org/pdf/2511.00056</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.00056]] MISA: Memory-Efficient LLMs Optimization with Module-wise Importance Sampling(https://arxiv.org/abs/2511.00056)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer, large language model</a></li>
<li><strong>Abstract: </strong>The substantial memory demands of pre-training and fine-tuning large language models (LLMs) require memory-efficient optimization algorithms. One promising approach is layer-wise optimization, which treats each transformer block as a single layer and optimizes it sequentially, while freezing the other layers to save optimizer states and activations. Although effective, these methods ignore the varying importance of the modules within each layer, leading to suboptimal performance. Moreover, layer-wise sampling provides only limited memory savings, as at least one full layer must remain active during optimization. To overcome these limitations, we propose Module-wise Importance SAmpling (MISA), a novel method that divides each layer into smaller modules and assigns importance scores to each module. MISA uses a weighted random sampling mechanism to activate modules, provably reducing gradient variance compared to layer-wise sampling. Additionally, we establish an \(\mathcal{O}(1/\sqrt{K})\) convergence rate under non-convex and stochastic conditions, where $K$ is the total number of block updates, and provide a detailed memory analysis showcasing MISA's superiority over existing baseline methods. Experiments on diverse learning tasks validate the effectiveness of MISA. Source code is available at this https URL.</li>
</ul>

<h3>Title: Automatically Finding Rule-Based Neurons in OthelloGPT</h3>
<ul>
<li><strong>Authors: </strong>Aditya Singh, Zihang Wen, Srujananjali Medicherla, Adam Karvonen, Can Rager</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.00059">https://arxiv.org/abs/2511.00059</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.00059">https://arxiv.org/pdf/2511.00059</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.00059]] Automatically Finding Rule-Based Neurons in OthelloGPT(https://arxiv.org/abs/2511.00059)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability, transformer</a></li>
<li><strong>Abstract: </strong>OthelloGPT, a transformer trained to predict valid moves in Othello, provides an ideal testbed for interpretability research. The model is complex enough to exhibit rich computational patterns, yet grounded in rule-based game logic that enables meaningful reverse-engineering. We present an automated approach based on decision trees to identify and interpret MLP neurons that encode rule-based game logic. Our method trains regression decision trees to map board states to neuron activations, then extracts decision paths where neurons are highly active to convert them into human-readable logical forms. These descriptions reveal highly interpretable patterns; for instance, neurons that specifically detect when diagonal moves become legal. Our findings suggest that roughly half of the neurons in layer 5 can be accurately described by compact, rule-based decision trees ($R^2 > 0.7$ for 913 of 2,048 neurons), while the remainder likely participate in more distributed or non-rule-based computations. We verify the causal relevance of patterns identified by our decision trees through targeted interventions. For a specific square, for specific game patterns, we ablate neurons corresponding to those patterns and find an approximately 5-10 fold stronger degradation in the model's ability to predict legal moves along those patterns compared to control patterns. To facilitate future work, we provide a Python tool that maps rule-based game behaviors to their implementing neurons, serving as a resource for researchers to test whether their interpretability methods recover meaningful computational structures.</li>
</ul>

<h3>Title: World Simulation with Video Foundation Models for Physical AI</h3>
<ul>
<li><strong>Authors: </strong>NVIDIA: Arslan Ali, Junjie Bai, Maciej Bala, Yogesh Balaji, Aaron Blakeman, Tiffany Cai, Jiaxin Cao, Tianshi Cao, Elizabeth Cha, Yu-Wei Chao, Prithvijit Chattopadhyay, Mike Chen, Yongxin Chen, Yu Chen, Shuai Cheng, Yin Cui, Jenna Diamond, Yifan Ding, Jiaojiao Fan, Linxi Fan, Liang Feng, Francesco Ferroni, Sanja Fidler, Xiao Fu, Ruiyuan Gao, Yunhao Ge, Jinwei Gu, Aryaman Gupta, Siddharth Gururani, Imad El Hanafi, Ali Hassani, Zekun Hao, Jacob Huffman, Joel Jang, Pooya Jannaty, Jan Kautz, Grace Lam, Xuan Li, Zhaoshuo Li, Maosheng Liao, Chen-Hsuan Lin, Tsung-Yi Lin, Yen-Chen Lin, Huan Ling, Ming-Yu Liu, Xian Liu, Yifan Lu, Alice Luo, Qianli Ma, Hanzi Mao, Kaichun Mo, Seungjun Nah, Yashraj Narang, Abhijeet Panaskar, Lindsey Pavao, Trung Pham, Morteza Ramezanali, Fitsum Reda, Scott Reed, Xuanchi Ren, Haonan Shao, Yue Shen, Stella Shi, Shuran Song, Bartosz Stefaniak, Shangkun Sun, Shitao Tang, Sameena Tasmeen, Lyne Tchapmi, Wei-Cheng Tseng, Jibin Varghese, Andrew Z. Wang, Hao Wang, Haoxiang Wang, Heng Wang, Ting-Chun Wang, Fangyin Wei, Jiashu Xu, Dinghao Yang, Xiaodong Yang, Haotian Ye, Seonghyeon Ye, Xiaohui Zeng, Jing Zhang, Qinsheng Zhang, Kaiwen Zheng, Andrew Zhu, Yuke Zhu</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI, cs.LG, cs.RO</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.00062">https://arxiv.org/abs/2511.00062</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.00062">https://arxiv.org/pdf/2511.00062</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.00062]] World Simulation with Video Foundation Models for Physical AI(https://arxiv.org/abs/2511.00062)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>We introduce [Cosmos-Predict2.5], the latest generation of the Cosmos World Foundation Models for Physical AI. Built on a flow-based architecture, [Cosmos-Predict2.5] unifies Text2World, Image2World, and Video2World generation in a single model and leverages [Cosmos-Reason1], a Physical AI vision-language model, to provide richer text grounding and finer control of world simulation. Trained on 200M curated video clips and refined with reinforcement learning-based post-training, [Cosmos-Predict2.5] achieves substantial improvements over [Cosmos-Predict1] in video quality and instruction alignment, with models released at 2B and 14B scales. These capabilities enable more reliable synthetic data generation, policy evaluation, and closed-loop simulation for robotics and autonomous systems. We further extend the family with [Cosmos-Transfer2.5], a control-net style framework for Sim2Real and Real2Real world translation. Despite being 3.5$\times$ smaller than [Cosmos-Transfer1], it delivers higher fidelity and robust long-horizon video generation. Together, these advances establish [Cosmos-Predict2.5] and [Cosmos-Transfer2.5] as versatile tools for scaling embodied intelligence. To accelerate research and deployment in Physical AI, we release source code, pretrained checkpoints, and curated benchmarks under the NVIDIA Open Model License at this https URL and this https URL. We hope these open resources lower the barrier to adoption and foster innovation in building the next generation of embodied intelligence.</li>
</ul>

<h3>Title: Token-Regulated Group Relative Policy Optimization for Stable Reinforcement Learning in Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Tue Le, Nghi D.Q.Bui, Linh Ngo Van, Trung Le</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.00066">https://arxiv.org/abs/2511.00066</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.00066">https://arxiv.org/pdf/2511.00066</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.00066]] Token-Regulated Group Relative Policy Optimization for Stable Reinforcement Learning in Large Language Models(https://arxiv.org/abs/2511.00066)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, large language model</a></li>
<li><strong>Abstract: </strong>Reinforcement learning with verifiable rewards (RLVR) has emerged as a powerful approach for strengthening the reasoning capabilities of large language models (LLMs). Among existing algorithms, Group Relative Policy Optimization (GRPO) has demonstrated strong performance, yet it suffers from a critical issue: low-probability tokens disproportionately dominate gradient updates due to their inherently large gradient magnitudes. This imbalance leads to unstable training and suppresses the contribution of high-probability tokens that are more reliable for learning. In this work, we introduce Token-Regulated Group Relative Policy Optimization (TR-GRPO), a simple yet effective extension of GRPO that assigns token-level weights positively correlated with the model's predicted probability. By downweighting low-probability tokens and emphasizing high-probability ones, TR-GRPO mitigates gradient over-amplification while preserving informative learning signals. Extensive experiments demonstrate that TR-GRPO consistently outperforms GRPO across RLVR tasks, including logic, math, and agentic reasoning, highlighting the importance of regulating token contributions during RL training and establishing TR-GRPO as a robust framework for enhancing LLM reasoning.</li>
</ul>

<h3>Title: Latent Domain Prompt Learning for Vision-Language Models</h3>
<ul>
<li><strong>Authors: </strong>Zhixing Li, Arsham Gholamzadeh Khoee, Yinan Yu</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.00067">https://arxiv.org/abs/2511.00067</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.00067">https://arxiv.org/pdf/2511.00067</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.00067]] Latent Domain Prompt Learning for Vision-Language Models(https://arxiv.org/abs/2511.00067)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>The objective of domain generalization (DG) is to enable models to be robust against domain shift. DG is crucial for deploying vision-language models (VLMs) in real-world applications, yet most existing methods rely on domain labels that may not be available and often ambiguous. We instead study the DG setting where models must generalize well without access to explicit domain labels. Our key idea is to represent an unseen target domain as a combination of latent domains automatically discovered from training data, enabling the model to adaptively transfer knowledge across domains. To realize this, we perform latent domain clustering on image features and fuse domain-specific text features based on the similarity between the input image and each latent domain. Experiments on four benchmarks show that this strategy yields consistent gains over VLM-based baselines and provides new insights into improving robustness under domain shift.</li>
</ul>

<h3>Title: Benchmarking Generative AI Against Bayesian Optimization for Constrained Multi-Objective Inverse Design</h3>
<ul>
<li><strong>Authors: </strong>Muhammad Bilal Awan, Abdul Razzaq, Abdul Shahid</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.00070">https://arxiv.org/abs/2511.00070</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.00070">https://arxiv.org/pdf/2511.00070</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.00070]] Benchmarking Generative AI Against Bayesian Optimization for Constrained Multi-Objective Inverse Design(https://arxiv.org/abs/2511.00070)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative, large language model</a></li>
<li><strong>Abstract: </strong>This paper investigates the performance of Large Language Models (LLMs) as generative optimizers for solving constrained multi-objective regression tasks, specifically within the challenging domain of inverse design (property-to-structure mapping). This problem, critical to materials informatics, demands finding complex, feasible input vectors that lie on the Pareto optimal front. While LLMs have demonstrated universal effectiveness across generative and reasoning tasks, their utility in constrained, continuous, high-dimensional numerical spaces tasks they weren't explicitly architected for remains an open research question. We conducted a rigorous comparative study between established Bayesian Optimization (BO) frameworks and a suite of fine-tuned LLMs and BERT models. For BO, we benchmarked the foundational BoTorch Ax implementation against the state-of-the-art q-Expected Hypervolume Improvement (qEHVI, BoTorchM). The generative approach involved fine-tuning models via Parameter-Efficient Fine-Tuning (PEFT), framing the challenge as a regression problem with a custom output head. Our results show that BoTorch qEHVI achieved perfect convergence (GD=0.0), setting the performance ceiling. Crucially, the best-performing LLM (WizardMath-7B) achieved a Generational Distance (GD) of 1.21, significantly outperforming the traditional BoTorch Ax baseline (GD=15.03). We conclude that specialized BO frameworks remain the performance leader for guaranteed convergence, but fine-tuned LLMs are validated as a promising, computationally fast alternative, contributing essential comparative metrics to the field of AI-driven optimization. The findings have direct industrial applications in optimizing formulation design for resins, polymers, and paints, where multi-objective trade-offs between mechanical, rheological, and chemical properties are critical to innovation and production efficiency.</li>
</ul>

<h3>Title: Wavelet-Based Feature Extraction and Unsupervised Clustering for Parity Detection: A Feature Engineering Perspective</h3>
<ul>
<li><strong>Authors: </strong>Ertugrul Mutlu</a></li>
<li><strong>Subjects: </strong>cs.LG, eess.SP</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.00071">https://arxiv.org/abs/2511.00071</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.00071">https://arxiv.org/pdf/2511.00071</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.00071]] Wavelet-Based Feature Extraction and Unsupervised Clustering for Parity Detection: A Feature Engineering Perspective(https://arxiv.org/abs/2511.00071)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction</a></li>
<li><strong>Abstract: </strong>This paper explores a deliberately over-engineered approach to the classical problem of parity detection -- determining whether a number is odd or even -- by combining wavelet-based feature extraction with unsupervised clustering. Instead of relying on modular arithmetic, integers are transformed into wavelet-domain representations, from which multi-scale statistical features are extracted and clustered using the k-means algorithm. The resulting feature space reveals meaningful structural differences between odd and even numbers, achieving a classification accuracy of approximately 69.67% without any label supervision. These results suggest that classical signal-processing techniques, originally designed for continuous data, can uncover latent structure even in purely discrete symbolic domains. Beyond parity detection, the study provides an illustrative perspective on how feature engineering and clustering may be repurposed for unconventional machine learning problems, potentially bridging symbolic reasoning and feature-based learning.</li>
</ul>

<h3>Title: Habitat and Land Cover Change Detection in Alpine Protected Areas: A Comparison of AI Architectures</h3>
<ul>
<li><strong>Authors: </strong>Harald Kristen, Daniel Kulmer, Manuela Hirschmugl</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.00073">https://arxiv.org/abs/2511.00073</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.00073">https://arxiv.org/pdf/2511.00073</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.00073]] Habitat and Land Cover Change Detection in Alpine Protected Areas: A Comparison of AI Architectures(https://arxiv.org/abs/2511.00073)</code><input type="text"></li>
<li><strong>Keywords: </strong>protect, robust, transformer, segmentation</a></li>
<li><strong>Abstract: </strong>Rapid climate change and other disturbances in alpine ecosystems demand frequent habitat monitoring, yet manual mapping remains prohibitively expensive for the required temporal resolution. We employ deep learning for change detection using long-term alpine habitat data from Gesaeuse National Park, Austria, addressing a major gap in applying geospatial foundation models (GFMs) to complex natural environments with fuzzy class boundaries and highly imbalanced classes. We compare two paradigms: post-classification change detection (CD) versus direct CD. For post-classification CD, we evaluate GFMs Prithvi-EO-2.0 and Clay v1.0 against U-Net CNNs; for direct CD, we test the transformer ChangeViT against U-Net baselines. Using high-resolution multimodal data (RGB, NIR, LiDAR, terrain attributes) covering 4,480 documented changes over 15.3 km2, results show Clay v1.0 achieves 51% overall accuracy versus U-Net's 41% for multi-class habitat change, while both reach 67% for binary change detection. Direct CD yields superior IoU (0.53 vs 0.35) for binary but only 28% accuracy for multi-class detection. Cross-temporal evaluation reveals GFM robustness, with Clay maintaining 33% accuracy on 2020 data versus U-Net's 23%. Integrating LiDAR improves semantic segmentation from 30% to 50% accuracy. Although overall accuracies are lower than in more homogeneous landscapes, they reflect realistic performance for complex alpine habitats. Future work will integrate object-based post-processing and physical constraints to enhance applicability.</li>
</ul>

<h3>Title: flowengineR: A Modular and Extensible Framework for Fair and Reproducible Workflow Design in R</h3>
<ul>
<li><strong>Authors: </strong>Maximilian Willer, Peter Ruckdeschel</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CY, stat.ME</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.00079">https://arxiv.org/abs/2511.00079</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.00079">https://arxiv.org/pdf/2511.00079</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.00079]] flowengineR: A Modular and Extensible Framework for Fair and Reproducible Workflow Design in R(https://arxiv.org/abs/2511.00079)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, fair, explainability</a></li>
<li><strong>Abstract: </strong>flowengineR is an R package designed to provide a modular and extensible framework for building reproducible algorithmic workflows for general-purpose machine learning pipelines. It is motivated by the rapidly evolving field of algorithmic fairness where new metrics, mitigation strategies, and machine learning methods continuously emerge. A central challenge in fairness, but also far beyond, is that existing toolkits either focus narrowly on single interventions or treat reproducibility and extensibility as secondary considerations rather than core design principles. flowengineR addresses this by introducing a unified architecture of standardized engines for data splitting, execution, preprocessing, training, inprocessing, postprocessing, evaluation, and reporting. Each engine encapsulates one methodological task yet communicates via a lightweight interface, ensuring workflows remain transparent, auditable, and easily extensible. Although implemented in R, flowengineR builds on ideas from workflow languages (CWL, YAWL), graph-oriented visual programming languages (KNIME), and R frameworks (BatchJobs, batchtools). Its emphasis, however, is less on orchestrating engines for resilient parallel execution but rather on the straightforward setup and management of distinct engines as data structures. This orthogonalization enables distributed responsibilities, independent development, and streamlined integration. In fairness context, by structuring fairness methods as interchangeable engines, flowengineR lets researchers integrate, compare, and evaluate interventions across the modeling pipeline. At the same time, the architecture generalizes to explainability, robustness, and compliance metrics without core modifications. While motivated by fairness, it ultimately provides a general infrastructure for any workflow context where reproducibility, transparency, and extensibility are essential.</li>
</ul>

<h3>Title: Fixed-point graph convolutional networks against adversarial attacks</h3>
<ul>
<li><strong>Authors: </strong>Shakib Khan, A. Ben Hamza, Amr Youssef</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.00083">https://arxiv.org/abs/2511.00083</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.00083">https://arxiv.org/pdf/2511.00083</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.00083]] Fixed-point graph convolutional networks against adversarial attacks(https://arxiv.org/abs/2511.00083)</code><input type="text"></li>
<li><strong>Keywords: </strong>defense, attack, robust</a></li>
<li><strong>Abstract: </strong>Adversarial attacks present a significant risk to the integrity and performance of graph neural networks, particularly in tasks where graph structure and node features are vulnerable to manipulation. In this paper, we present a novel model, called fixed-point iterative graph convolutional network (Fix-GCN), which achieves robustness against adversarial perturbations by effectively capturing higher-order node neighborhood information in the graph without additional memory or computational complexity. Specifically, we introduce a versatile spectral modulation filter and derive the feature propagation rule of our model using fixed-point iteration. Unlike traditional defense mechanisms that rely on additional design elements to counteract attacks, the proposed graph filter provides a flexible-pass filtering approach, allowing it to selectively attenuate high-frequency components while preserving low-frequency structural information in the graph signal. By iteratively updating node representations, our model offers a flexible and efficient framework for preserving essential graph information while mitigating the impact of adversarial manipulation. We demonstrate the effectiveness of the proposed model through extensive experiments on various benchmark graph datasets, showcasing its resilience against adversarial attacks.</li>
</ul>

<h3>Title: MaGNet: A Mamba Dual-Hypergraph Network for Stock Prediction via Temporal-Causal and Global Relational Learning</h3>
<ul>
<li><strong>Authors: </strong>Peilin Tan, Chuanqi Shi, Dian Tu, Liang Xie</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.00085">https://arxiv.org/abs/2511.00085</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.00085">https://arxiv.org/pdf/2511.00085</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.00085]] MaGNet: A Mamba Dual-Hypergraph Network for Stock Prediction via Temporal-Causal and Global Relational Learning(https://arxiv.org/abs/2511.00085)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Stock trend prediction is crucial for profitable trading strategies and portfolio management yet remains challenging due to market volatility, complex temporal dynamics and multifaceted inter-stock relationships. Existing methods struggle to effectively capture temporal dependencies and dynamic inter-stock interactions, often neglecting cross-sectional market influences, relying on static correlations, employing uniform treatments of nodes and edges, and conflating diverse relationships. This work introduces MaGNet, a novel Mamba dual-hyperGraph Network for stock prediction, integrating three key innovations: (1) a MAGE block, which leverages bidirectional Mamba with adaptive gating mechanisms for contextual temporal modeling and integrates a sparse Mixture-of-Experts layer to enable dynamic adaptation to diverse market conditions, alongside multi-head attention for capturing global dependencies; (2) Feature-wise and Stock-wise 2D Spatiotemporal Attention modules enable precise fusion of multivariate features and cross-stock dependencies, effectively enhancing informativeness while preserving intrinsic data structures, bridging temporal modeling with relational reasoning; and (3) a dual hypergraph framework consisting of the Temporal-Causal Hypergraph (TCH) that captures fine-grained causal dependencies with temporal constraints, and Global Probabilistic Hypergraph (GPH) that models market-wide patterns through soft hyperedge assignments and Jensen-Shannon Divergence weighting mechanism, jointly disentangling localized temporal influences from instantaneous global structures for multi-scale relational learning. Extensive experiments on six major stock indices demonstrate MaGNet outperforms state-of-the-art methods in both superior predictive performance and exceptional investment returns with robust risk management capabilities. Codes available at: this https URL.</li>
</ul>

<h3>Title: Generalizing Test-time Compute-optimal Scaling as an Optimizable Graph</h3>
<ul>
<li><strong>Authors: </strong>Fali Wang, Jihai Chen, Shuhua Yang, Runxue Bao, Tianxiang Zhao, Zhiwei Zhang, Xianfeng Tang, Hui Liu, Qi He, Suhang Wang</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.00086">https://arxiv.org/abs/2511.00086</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.00086">https://arxiv.org/pdf/2511.00086</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.00086]] Generalizing Test-time Compute-optimal Scaling as an Optimizable Graph(https://arxiv.org/abs/2511.00086)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Test-Time Scaling (TTS) improves large language models (LLMs) by allocating additional computation during inference, typically through parallel, sequential, or hybrid scaling. However, prior studies often assume fixed collaboration architectures (e.g., topologies) and single-model usage, overlooking that optimal architectures and model combinations can vary across tasks. Therefore, we study the novel problem of searching for compute-optimal model combinations and architectures in TTS under a fixed budget. We formalize it as a multi-LLM collaboration graph, where nodes encode roles and LLM model assignments, and edges capture information flow. This problem is challenging because (i) the combinatorial search space is prohibitively large, and (ii) task-specific requirements demand tailored designs. To address these, we reformulate the problem as probabilistic graph optimization and, through pilot experiments, derive three empirical insights into TTS collaboration graphs. Guided by these insights, we propose Agent-REINFORCE, an LLM-agent-augmented framework that mirrors the REINFORCE pipeline by mapping sampling-gradient-update to sampling-feedback-update, where feedback serves as a textual gradient to update the probabilistic graph and efficiently search for optimal multi-LLM collaboration graphs. Experiments show that Agent-REINFORCE outperforms both traditional and LLM-based baselines in sample efficiency and search performance, and effectively identifies optimal graphs under joint objectives of accuracy and inference latency.</li>
</ul>

<h3>Title: LeMiCa: Lexicographic Minimax Path Caching for Efficient Diffusion-Based Video Generation</h3>
<ul>
<li><strong>Authors: </strong>Huanlin Gao, Ping Chen, Fuyuan Shi, Chao Tan, Zhaoxiang Liu, Fang Zhao, Kai Wang, Shiguo Lian</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.00090">https://arxiv.org/abs/2511.00090</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.00090">https://arxiv.org/pdf/2511.00090</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.00090]] LeMiCa: Lexicographic Minimax Path Caching for Efficient Diffusion-Based Video Generation(https://arxiv.org/abs/2511.00090)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, diffusion</a></li>
<li><strong>Abstract: </strong>We present LeMiCa, a training-free and efficient acceleration framework for diffusion-based video generation. While existing caching strategies primarily focus on reducing local heuristic errors, they often overlook the accumulation of global errors, leading to noticeable content degradation between accelerated and original videos. To address this issue, we formulate cache scheduling as a directed graph with error-weighted edges and introduce a Lexicographic Minimax Path Optimization strategy that explicitly bounds the worst-case path error. This approach substantially improves the consistency of global content and style across generated frames. Extensive experiments on multiple text-to-video benchmarks demonstrate that LeMiCa delivers dual improvements in both inference speed and generation quality. Notably, our method achieves a 2.9x speedup on the Latte model and reaches an LPIPS score of 0.05 on Open-Sora, outperforming prior caching techniques. Importantly, these gains come with minimal perceptual quality degradation, making LeMiCa a robust and generalizable paradigm for accelerating diffusion-based video generation. We believe this approach can serve as a strong foundation for future research on efficient and reliable video synthesis. Our code is available at :this https URL</li>
</ul>

<h3>Title: SpinalSAM-R1: A Vision-Language Multimodal Interactive System for Spine CT Segmentation</h3>
<ul>
<li><strong>Authors: </strong>Jiaming Liu, Dingwei Fan, Junyong Zhao, Chunlin Li, Haipeng Si, Liang Sun</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.00095">https://arxiv.org/abs/2511.00095</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.00095">https://arxiv.org/pdf/2511.00095</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.00095]] SpinalSAM-R1: A Vision-Language Multimodal Interactive System for Spine CT Segmentation(https://arxiv.org/abs/2511.00095)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>The anatomical structure segmentation of the spine and adjacent structures from computed tomography (CT) images is a key step for spinal disease diagnosis and treatment. However, the segmentation of CT images is impeded by low contrast and complex vertebral boundaries. Although advanced models such as the Segment Anything Model (SAM) have shown promise in various segmentation tasks, their performance in spinal CT imaging is limited by high annotation requirements and poor domain adaptability. To address these limitations, we propose SpinalSAM-R1, a multimodal vision-language interactive system that integrates a fine-tuned SAM with DeepSeek-R1, for spine CT image segmentation. Specifically, our SpinalSAM-R1 introduces an anatomy-guided attention mechanism to improve spine segmentation performance, and a semantics-driven interaction protocol powered by DeepSeek-R1, enabling natural language-guided refinement. The SpinalSAM-R1 is fine-tuned using Low-Rank Adaptation (LoRA) for efficient adaptation. We validate our SpinalSAM-R1 on the spine anatomical structure with CT images. Experimental results suggest that our method achieves superior segmentation performance. Meanwhile, we develop a PyQt5-based interactive software, which supports point, box, and text-based prompts. The system supports 11 clinical operations with 94.3\% parsing accuracy and sub-800 ms response times. The software is released on this https URL.</li>
</ul>

<h3>Title: A filtering scheme for confocal laser endomicroscopy (CLE)-video sequences for self-supervised learning</h3>
<ul>
<li><strong>Authors: </strong>Nils Porsche, Flurin Müller-Diesing, Sweta Banerjee, Miguel Goncalves, Marc Aubreville</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.00098">https://arxiv.org/abs/2511.00098</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.00098">https://arxiv.org/pdf/2511.00098</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.00098]] A filtering scheme for confocal laser endomicroscopy (CLE)-video sequences for self-supervised learning(https://arxiv.org/abs/2511.00098)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Confocal laser endomicroscopy (CLE) is a non-invasive, real-time imaging modality that can be used for in-situ, in-vivo imaging and the microstructural analysis of mucous structures. The diagnosis using CLE is, however, complicated by images being hard to interpret for non-experienced physicians. Utilizing machine learning as an augmentative tool would hence be beneficial, but is complicated by the shortage of histopathology-correlated CLE imaging sequences with respect to the plurality of patterns in this domain, leading to overfitting of machine learning models. To overcome this, self-supervised learning (SSL) can be employed on larger unlabeled datasets. CLE is a video-based modality with high inter-frame correlation, leading to a non-stratified data distribution for SSL training. In this work, we propose a filter functionality on CLE video sequences to reduce the dataset redundancy in SSL training and improve SSL training convergence and training efficiency. We use four state-of-the-art baseline networks and a SSL teacher-student network with a vision transformer small backbone for the evaluation. These networks were evaluated on downstream tasks for a sinonasal tumor dataset and a squamous cell carcinoma of the skin dataset. On both datasets, we found the highest test accuracy on the filtered SSL-pretrained model, with 67.48% and 73.52%, both considerably outperforming their non-SSL baselines. Our results show that SSL is an effective method for CLE pretraining. Further, we show that our proposed CLE video filter can be utilized to improve training efficiency in self-supervised scenarios, resulting in a reduction of 67% in training time.</li>
</ul>

<h3>Title: A generative adversarial network optimization method for damage detection and digital twinning by deep AI fault learning: Z24 Bridge structural health monitoring benchmark validation</h3>
<ul>
<li><strong>Authors: </strong>Marios Impraimakis, Evangelia Nektaria Palkanoglou</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CV, eess.SP, eess.SY</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.00099">https://arxiv.org/abs/2511.00099</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.00099">https://arxiv.org/pdf/2511.00099</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.00099]] A generative adversarial network optimization method for damage detection and digital twinning by deep AI fault learning: Z24 Bridge structural health monitoring benchmark validation(https://arxiv.org/abs/2511.00099)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>The optimization-based damage detection and damage state digital twinning capabilities are examined here of a novel conditional-labeled generative adversarial network methodology. The framework outperforms current approaches for fault anomaly detection as no prior information is required for the health state of the system: a topic of high significance for real-world applications. Specifically, current artificial intelligence-based digital twinning approaches suffer from the uncertainty related to obtaining poor predictions when a low number of measurements is available, physics knowledge is missing, or when the damage state is unknown. To this end, an unsupervised framework is examined and validated rigorously on the benchmark structural health monitoring measurements of Z24 Bridge: a post-tensioned concrete highway bridge in Switzerland. In implementing the approach, firstly, different same damage-level measurements are used as inputs, while the model is forced to converge conditionally to two different damage states. Secondly, the process is repeated for a different group of measurements. Finally, the convergence scores are compared to identify which one belongs to a different damage state. The process for both healthy-to-healthy and damage-to-healthy input data creates, simultaneously, measurements for digital twinning purposes at different damage states, capable of pattern recognition and machine learning data generation. Further to this process, a support vector machine classifier and a principal component analysis procedure is developed to assess the generated and real measurements of each damage category, serving as a secondary new dynamics learning indicator in damage scenarios. Importantly, the approach is shown to capture accurately damage over healthy measurements, providing a powerful tool for vibration-based system-level monitoring and scalable infrastructure resilience.</li>
</ul>

<h3>Title: Loquetier: A Virtualized Multi-LoRA Framework for Unified LLM Fine-tuning and Serving</h3>
<ul>
<li><strong>Authors: </strong>Yuchen Zhang, Hanyue Du, Chun Cao, Jingwei Xu</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.00101">https://arxiv.org/abs/2511.00101</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.00101">https://arxiv.org/pdf/2511.00101</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.00101]] Loquetier: A Virtualized Multi-LoRA Framework for Unified LLM Fine-tuning and Serving(https://arxiv.org/abs/2511.00101)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Low-Rank Adaptation (LoRA) has become a widely adopted parameter-efficient fine-tuning (PEFT) technique for adapting large language models (LLMs) to downstream tasks. While prior work has explored strategies for integrating LLM training and serving, there still remains a gap in unifying fine-tuning and inference for LoRA-based models. We present Loquetier, a virtualized multi-LoRA framework that seamlessly integrates LoRA fine-tuning and serving within a single runtime. Loquetier introduces two key components: (1) a Virtualized Module that isolates PEFT-based modifications and supports multiple adapters on a shared base model, and (2) an optimized computation flow with a kernel design that merges fine-tuning and inference paths in forward propagation, enabling efficient batching and minimizing kernel invocation overhead. Extensive experiments across three task settings show that Loquetier consistently outperforms existing baselines in both performance and flexibility, achieving up to $3.0\times$ the throughput of the state-of-the-art co-serving system on inference-only tasks and $46.4\times$ higher SLO attainment than PEFT on unified fine-tuning and inference tasks. The implementation of Loquetier is publicly available at this https URL.</li>
</ul>

<h3>Title: Automated Discovery of Conservation Laws via Hybrid Neural ODE-Transformers</h3>
<ul>
<li><strong>Authors: </strong>Vivan Doshi</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.00102">https://arxiv.org/abs/2511.00102</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.00102">https://arxiv.org/pdf/2511.00102</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.00102]] Automated Discovery of Conservation Laws via Hybrid Neural ODE-Transformers(https://arxiv.org/abs/2511.00102)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, transformer</a></li>
<li><strong>Abstract: </strong>The discovery of conservation laws is a cornerstone of scientific progress. However, identifying these invariants from observational data remains a significant challenge. We propose a hybrid framework to automate the discovery of conserved quantities from noisy trajectory data. Our approach integrates three components: (1) a Neural Ordinary Differential Equation (Neural ODE) that learns a continuous model of the system's dynamics, (2) a Transformer that generates symbolic candidate invariants conditioned on the learned vector field, and (3) a symbolic-numeric verifier that provides a strong numerical certificate for the validity of these candidates. We test our framework on canonical physical systems and show that it significantly outperforms baselines that operate directly on trajectory data. This work demonstrates the robustness of a decoupled learn-then-search approach for discovering mathematical principles from imperfect data.</li>
</ul>

<h3>Title: FreeSliders: Training-Free, Modality-Agnostic Concept Sliders for Fine-Grained Diffusion Control in Images, Audio, and Video</h3>
<ul>
<li><strong>Authors: </strong>Rotem Ezra, Hedi Zisling, Nimrod Berman, Ilan Naiman, Alexey Gorkor, Liran Nochumsohn, Eliya Nachmani, Omri Azencot</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.00103">https://arxiv.org/abs/2511.00103</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.00103">https://arxiv.org/pdf/2511.00103</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.00103]] FreeSliders: Training-Free, Modality-Agnostic Concept Sliders for Fine-Grained Diffusion Control in Images, Audio, and Video(https://arxiv.org/abs/2511.00103)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, generative</a></li>
<li><strong>Abstract: </strong>Diffusion models have become state-of-the-art generative models for images, audio, and video, yet enabling fine-grained controllable generation, i.e., continuously steering specific concepts without disturbing unrelated content, remains challenging. Concept Sliders (CS) offer a promising direction by discovering semantic directions through textual contrasts, but they require per-concept training and architecture-specific fine-tuning (e.g., LoRA), limiting scalability to new modalities. In this work we introduce FreeSliders, a simple yet effective approach that is fully training-free and modality-agnostic, achieved by partially estimating the CS formula during inference. To support modality-agnostic evaluation, we extend the CS benchmark to include both video and audio, establishing the first suite for fine-grained concept generation control with multiple modalities. We further propose three evaluation properties along with new metrics to improve evaluation quality. Finally, we identify an open problem of scale selection and non-linear traversals and introduce a two-stage procedure that automatically detects saturation points and reparameterizes traversal for perceptually uniform, semantically meaningful edits. Extensive experiments demonstrate that our method enables plug-and-play, training-free concept control across modalities, improves over existing baselines, and establishes new tools for principled controllable generation. An interactive presentation of our benchmark and method is available at: this https URL</li>
</ul>

<h3>Title: AI Powered High Quality Text to Video Generation with Enhanced Temporal Consistency</h3>
<ul>
<li><strong>Authors: </strong>Piyushkumar Patel</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI, cs.IR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.00107">https://arxiv.org/abs/2511.00107</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.00107">https://arxiv.org/pdf/2511.00107</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.00107]] AI Powered High Quality Text to Video Generation with Enhanced Temporal Consistency(https://arxiv.org/abs/2511.00107)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, generative</a></li>
<li><strong>Abstract: </strong>Text to video generation has emerged as a critical frontier in generative artificial intelligence, yet existing approaches struggle with maintaining temporal consistency, compositional understanding, and fine grained control over visual narratives. We present MOVAI (Multimodal Original Video AI), a novel hierarchical framework that integrates compositional scene understanding with temporal aware diffusion models for high fidelity text to video synthesis. Our approach introduces three key innovations: (1) a Compositional Scene Parser (CSP) that decomposes textual descriptions into hierarchical scene graphs with temporal annotations, (2) a Temporal-Spatial Attention Mechanism (TSAM) that ensures coherent motion dynamics across frames while preserving spatial details, and (3) a Progressive Video Refinement (PVR) module that iteratively enhances video quality through multi-scale temporal reasoning. Extensive experiments on standard benchmarks demonstrate that MOVAI achieves state-of-the-art performance, improving video quality metrics by 15.3% in LPIPS, 12.7% in FVD, and 18.9% in user preference studies compared to existing methods. Our framework shows particular strength in generating complex multi-object scenes with realistic temporal dynamics and fine-grained semantic control.</li>
</ul>

<h3>Title: A Comparative Study of Hybrid Post-Quantum Cryptographic X.509 Certificate Schemes</h3>
<ul>
<li><strong>Authors: </strong>Abel C. H. Chen</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.00111">https://arxiv.org/abs/2511.00111</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.00111">https://arxiv.org/pdf/2511.00111</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.00111]] A Comparative Study of Hybrid Post-Quantum Cryptographic X.509 Certificate Schemes(https://arxiv.org/abs/2511.00111)</code><input type="text"></li>
<li><strong>Keywords: </strong>security</a></li>
<li><strong>Abstract: </strong>As quantum computing hardware continues to advance, the integration of such technology with quantum algorithms is anticipated to enable the decryption of ciphertexts produced by RSA and Elliptic Curve Cryptography (ECC) within polynomial time. In response to this emerging threat, the U.S. National Institute of Standards and Technology (NIST) finalized a series of Post-Quantum Cryptography (PQC) standards in August 2024 and outlined a roadmap for PQC migration. Consequently, the design of X.509 certificates that adhere to PQC standards has become a crucial focus in the development of certificate management systems. To further strengthen security and facilitate a smooth migration process, several hybrid certificate schemes have been proposed internationally based on the X.509 certificate format, including the composite scheme, the catalyst scheme, and the chameleon scheme. This study presents a comprehensive analysis and comparison of these hybrid certificate schemes from multiple perspectives (e.g., certificate size, computational efficiency, and migration feasibility) to assess their suitability for various applications and services.</li>
</ul>

<h3>Title: MeixnerNet: Adaptive and Robust Spectral Graph Neural Networks with Discrete Orthogonal Polynomials</h3>
<ul>
<li><strong>Authors: </strong>Huseyin Goksu</a></li>
<li><strong>Subjects: </strong>cs.LG, eess.SP</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.00113">https://arxiv.org/abs/2511.00113</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.00113">https://arxiv.org/pdf/2511.00113</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.00113]] MeixnerNet: Adaptive and Robust Spectral Graph Neural Networks with Discrete Orthogonal Polynomials(https://arxiv.org/abs/2511.00113)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Spectral Graph Neural Networks (GNNs) have achieved state-of-the-art results by defining graph convolutions in the spectral domain. A common approach, popularized by ChebyNet, is to use polynomial filters based on continuous orthogonal polynomials (e.g., Chebyshev). This creates a theoretical disconnect, as these continuous-domain filters are applied to inherently discrete graph structures. We hypothesize this mismatch can lead to suboptimal performance and fragility to hyperparameter settings. In this paper, we introduce MeixnerNet, a novel spectral GNN architecture that employs discrete orthogonal polynomials -- specifically, the Meixner polynomials $M_k(x; \beta, c)$. Our model makes the two key shape parameters of the polynomial, beta and c, learnable, allowing the filter to adapt its polynomial basis to the specific spectral properties of a given graph. We overcome the significant numerical instability of these polynomials by introducing a novel stabilization technique that combines Laplacian scaling with per-basis LayerNorm. We demonstrate experimentally that MeixnerNet achieves competitive-to-superior performance against the strong ChebyNet baseline at the optimal K = 2 setting (winning on 2 out of 3 benchmarks). More critically, we show that MeixnerNet is exceptionally robust to variations in the polynomial degree K, a hyperparameter to which ChebyNet proves to be highly fragile, collapsing in performance where MeixnerNet remains stable.</li>
</ul>

<h3>Title: End-to-End Framework Integrating Generative AI and Deep Reinforcement Learning for Autonomous Ultrasound Scanning</h3>
<ul>
<li><strong>Authors: </strong>Hanae Elmekki, Amanda Spilkin, Ehsan Zakeri, Antonela Mariel Zanuttini, Ahmed Alagha, Hani Sami, Jamal Bentahar, Lyes Kadem, Wen-Fang Xie, Philippe Pibarot, Rabeb Mizouni, Hadi Otrok, Azzam Mourad, Sami Muhaidat</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.00114">https://arxiv.org/abs/2511.00114</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.00114">https://arxiv.org/pdf/2511.00114</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.00114]] End-to-End Framework Integrating Generative AI and Deep Reinforcement Learning for Autonomous Ultrasound Scanning(https://arxiv.org/abs/2511.00114)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>Cardiac ultrasound (US) is among the most widely used diagnostic tools in cardiology for assessing heart health, but its effectiveness is limited by operator dependence, time constraints, and human error. The shortage of trained professionals, especially in remote areas, further restricts access. These issues underscore the need for automated solutions that can ensure consistent, and accessible cardiac imaging regardless of operator skill or location. Recent progress in artificial intelligence (AI), especially in deep reinforcement learning (DRL), has gained attention for enabling autonomous decision-making. However, existing DRL-based approaches to cardiac US scanning lack reproducibility, rely on proprietary data, and use simplified models. Motivated by these gaps, we present the first end-to-end framework that integrates generative AI and DRL to enable autonomous and reproducible cardiac US scanning. The framework comprises two components: (i) a conditional generative simulator combining Generative Adversarial Networks (GANs) with Variational Autoencoders (VAEs), that models the cardiac US environment producing realistic action-conditioned images; and (ii) a DRL module that leverages this simulator to learn autonomous, accurate scanning policies. The proposed framework delivers AI-driven guidance through expert-validated models that classify image type and assess quality, supports conditional generation of realistic US images, and establishes a reproducible foundation extendable to other organs. To ensure reproducibility, a publicly available dataset of real cardiac US scans is released. The solution is validated through several experiments. The VAE-GAN is benchmarked against existing GAN variants, with performance assessed using qualitative and quantitative approaches, while the DRL-based scanning system is evaluated under varying configurations to demonstrate effectiveness.</li>
</ul>

<h3>Title: Cognitive Alignment in Personality Reasoning: Leveraging Prototype Theory for MBTI Inference</h3>
<ul>
<li><strong>Authors: </strong>Haoyuan Li, Yuanbo Tong, Yuchen Li, Zirui Wang, Chunhou Liu, Jiamou Liu</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.00115">https://arxiv.org/abs/2511.00115</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.00115">https://arxiv.org/pdf/2511.00115</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.00115]] Cognitive Alignment in Personality Reasoning: Leveraging Prototype Theory for MBTI Inference(https://arxiv.org/abs/2511.00115)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, interpretability</a></li>
<li><strong>Abstract: </strong>Personality recognition from text is typically cast as hard-label classification, which obscures the graded, prototype-like nature of human personality judgments. We present ProtoMBTI, a cognitively aligned framework for MBTI inference that operationalizes prototype theory within an LLM-based pipeline. First, we construct a balanced, quality-controlled corpus via LLM-guided multi-dimensional augmentation (semantic, linguistic, sentiment). Next, we LoRA-fine-tune a lightweight (<=2B) encoder to learn discriminative embeddings and to standardize a bank of personality prototypes. At inference, we retrieve top-k prototypes for a query post and perform a retrieve--reuse--revise--retain cycle: the model aggregates prototype evidence via prompt-based voting, revises when inconsistencies arise, and, upon correct prediction, retains the sample to continually enrich the prototype library. Across Kaggle and Pandora benchmarks, ProtoMBTI improves over baselines on both the four MBTI dichotomies and the full 16-type task, and exhibits robust cross-dataset generalization. Our results indicate that aligning the inference process with psychological prototype reasoning yields gains in accuracy, interpretability, and transfer for text-based personality modeling.</li>
</ul>

<h3>Title: DCcluster-Opt: Benchmarking Dynamic Multi-Objective Optimization for Geo-Distributed Data Center Workloads</h3>
<ul>
<li><strong>Authors: </strong>Antonio Guillen-Perez, Avisek Naug, Vineet Gundecha, Sahand Ghorbanpour, Ricardo Luna Gutierrez, Ashwin Ramesh Babu, Munther Salim, Shubhanker Banerjee, Eoin H. Oude Essink, Damien Fay, Soumyendu Sarkar</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.MA, eess.SY</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.00117">https://arxiv.org/abs/2511.00117</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.00117">https://arxiv.org/pdf/2511.00117</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.00117]] DCcluster-Opt: Benchmarking Dynamic Multi-Objective Optimization for Geo-Distributed Data Center Workloads(https://arxiv.org/abs/2511.00117)</code><input type="text"></li>
<li><strong>Keywords: </strong>fair</a></li>
<li><strong>Abstract: </strong>The increasing energy demands and carbon footprint of large-scale AI require intelligent workload management in globally distributed data centers. Yet progress is limited by the absence of benchmarks that realistically capture the interplay of time-varying environmental factors (grid carbon intensity, electricity prices, weather), detailed data center physics (CPUs, GPUs, memory, HVAC energy), and geo-distributed network dynamics (latency and transmission costs). To bridge this gap, we present DCcluster-Opt: an open-source, high-fidelity simulation benchmark for sustainable, geo-temporal task scheduling. DCcluster-Opt combines curated real-world datasets, including AI workload traces, grid carbon intensity, electricity markets, weather across 20 global regions, cloud transmission costs, and empirical network delay parameters with physics-informed models of data center operations, enabling rigorous and reproducible research in sustainable computing. It presents a challenging scheduling problem where a top-level coordinating agent must dynamically reassign or defer tasks that arrive with resource and service-level agreement requirements across a configurable cluster of data centers to optimize multiple objectives. The environment also models advanced components such as heat recovery. A modular reward system enables an explicit study of trade-offs among carbon emissions, energy costs, service level agreements, and water use. It provides a Gymnasium API with baseline controllers, including reinforcement learning and rule-based strategies, to support reproducible ML research and a fair comparison of diverse algorithms. By offering a realistic, configurable, and accessible testbed, DCcluster-Opt accelerates the development and validation of next-generation sustainable computing solutions for geo-distributed data centers.</li>
</ul>

<h3>Title: Real-time and Zero-footprint Bag of Synthetic Syllables Algorithm for E-mail Spam Detection Using Subject Line and Short Text Fields</h3>
<ul>
<li><strong>Authors: </strong>Stanislav Selitskiy</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.00118">https://arxiv.org/abs/2511.00118</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.00118">https://arxiv.org/pdf/2511.00118</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.00118]] Real-time and Zero-footprint Bag of Synthetic Syllables Algorithm for E-mail Spam Detection Using Subject Line and Short Text Fields(https://arxiv.org/abs/2511.00118)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack</a></li>
<li><strong>Abstract: </strong>Contemporary e-mail services have high availability expectations from the customers and are resource-strained because of the high-volume throughput and spam attacks. Deep Machine Learning architectures, which are resource hungry and require off-line processing due to the long processing times, are not acceptable at the front line filters. On the other hand, the bulk of the incoming spam is not sophisticated enough to bypass even the simplest algorithms. While the small fraction of the intelligent, highly mutable spam can be detected only by the deep architectures, the stress on them can be unloaded by the simple near real-time and near zero-footprint algorithms such as the Bag of Synthetic Syllables algorithm applied to the short texts of the e-mail subject lines and other short text fields. The proposed algorithm creates a circa 200 sparse dimensional hash or vector for each e-mail subject line that can be compared for the cosine or euclidean proximity distance to find similarities to the known spammy subjects. The algorithm does not require any persistent storage, dictionaries, additional hardware upgrades or software packages. The performance of the algorithm is presented on the one day of the real SMTP traffic.</li>
</ul>

<h3>Title: VLM6D: VLM based 6Dof Pose Estimation based on RGB-D Images</h3>
<ul>
<li><strong>Authors: </strong>Md Selim Sarowar, Sungho Kim</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.00120">https://arxiv.org/abs/2511.00120</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.00120">https://arxiv.org/pdf/2511.00120</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.00120]] VLM6D: VLM based 6Dof Pose Estimation based on RGB-D Images(https://arxiv.org/abs/2511.00120)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, transformer</a></li>
<li><strong>Abstract: </strong>The primary challenge in computer vision is precisely calculating the pose of 6D objects, however many current approaches are still fragile and have trouble generalizing from synthetic data to real-world situations with fluctuating lighting, textureless objects, and significant occlusions. To address these limitations, VLM6D, a novel dual-stream architecture that leverages the distinct strengths of visual and geometric data from RGB-D input for robust and precise pose estimation. Our framework uniquely integrates two specialized encoders: a powerful, self-supervised Vision Transformer (DINOv2) processes the RGB modality, harnessing its rich, pre-trained understanding of visual grammar to achieve remarkable resilience against texture and lighting variations. Concurrently, a PointNet++ encoder processes the 3D point cloud derived from depth data, enabling robust geometric reasoning that excels even with the sparse, fragmented data typical of severe occlusion. These complementary feature streams are effectively fused to inform a multi task prediction head. We demonstrate through comprehensive experiments that VLM6D obtained new SOTA performance on the challenging Occluded-LineMOD, validating its superior robustness and accuracy.</li>
</ul>

<h3>Title: Analysis of Line Break prediction models for detecting defensive breakthrough in football</h3>
<ul>
<li><strong>Authors: </strong>Shoma Yagi, Jun Ichikawa, Genki Ichinose</a></li>
<li><strong>Subjects: </strong>cs.LG, physics.soc-ph, stat.AP</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.00121">https://arxiv.org/abs/2511.00121</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.00121">https://arxiv.org/pdf/2511.00121</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.00121]] Analysis of Line Break prediction models for detecting defensive breakthrough in football(https://arxiv.org/abs/2511.00121)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack</a></li>
<li><strong>Abstract: </strong>In football, attacking teams attempt to break through the opponent's defensive line to create scoring opportunities. This action, known as a Line Break, is a critical indicator of offensive effectiveness and tactical performance, yet previous studies have mainly focused on shots or goal opportunities rather than on how teams break the defensive line. In this study, we develop a machine learning model to predict Line Breaks using event and tracking data from the 2023 J1 League season. The model incorporates 189 features, including player positions, velocities, and spatial configurations, and employs an XGBoost classifier to estimate the probability of Line Breaks. The proposed model achieved high predictive accuracy, with an AUC of 0.982 and a Brier score of 0.015. Furthermore, SHAP analysis revealed that factors such as offensive player speed, gaps in the defensive line, and offensive players' spatial distributions significantly contribute to the occurrence of Line Breaks. Finally, we found a moderate positive correlation between the predicted probability of being Line-Broken and the number of shots and crosses conceded at the team level. These results suggest that Line Breaks are closely linked to the creation of scoring opportunities and provide a quantitative framework for understanding tactical dynamics in football.</li>
</ul>

<h3>Title: Integrating ConvNeXt and Vision Transformers for Enhancing Facial Age Estimation</h3>
<ul>
<li><strong>Authors: </strong>Gaby Maroun, Salah Eddine Bekhouche, Fadi Dornaika</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.00123">https://arxiv.org/abs/2511.00123</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.00123">https://arxiv.org/pdf/2511.00123</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.00123]] Integrating ConvNeXt and Vision Transformers for Enhancing Facial Age Estimation(https://arxiv.org/abs/2511.00123)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, extraction, transformer</a></li>
<li><strong>Abstract: </strong>Age estimation from facial images is a complex and multifaceted challenge in computer vision. In this study, we present a novel hybrid architecture that combines ConvNeXt, a state-of-the-art advancement of convolutional neural networks (CNNs), with Vision Transformers (ViT). While each model independently delivers excellent performance on a variety of tasks, their integration leverages the complementary strengths of the CNNs localized feature extraction capabilities and the Transformers global attention mechanisms. Our proposed ConvNeXt-ViT hybrid solution was thoroughly evaluated on benchmark age estimation datasets, including MORPH II, CACD, and AFAD, and achieved superior performance in terms of mean absolute error (MAE). To address computational constraints, we leverage pre-trained models and systematically explore different configurations, using linear layers and advanced regularization techniques to optimize the architecture. Comprehensive ablation studies highlight the critical role of individual components and training strategies, and in particular emphasize the importance of adapted attention mechanisms within the CNN framework to improve the model focus on age-relevant facial features. The results show that the ConvNeXt-ViT hybrid not only outperforms traditional methods, but also provides a robust foundation for future advances in age estimation and related visual tasks. This work underscores the transformative potential of hybrid architectures and represents a promising direction for the seamless integration of CNNs and transformers to address complex computer vision challenges.</li>
</ul>

<h3>Title: Cross-fluctuation phase transitions reveal sampling dynamics in diffusion models</h3>
<ul>
<li><strong>Authors: </strong>Sai Niranjan Ramachandran, Manish Krishan Lal, Suvrit Sra</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.00124">https://arxiv.org/abs/2511.00124</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.00124">https://arxiv.org/pdf/2511.00124</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.00124]] Cross-fluctuation phase transitions reveal sampling dynamics in diffusion models(https://arxiv.org/abs/2511.00124)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, generative</a></li>
<li><strong>Abstract: </strong>We analyse how the sampling dynamics of distributions evolve in score-based diffusion models using cross-fluctuations, a centered-moment statistic from statistical physics. Specifically, we show that starting from an unbiased isotropic normal distribution, samples undergo sharp, discrete transitions, eventually forming distinct events of a desired distribution while progressively revealing finer structure. As this process is reversible, these transitions also occur in reverse, where intermediate states progressively merge, tracing a path back to the initial distribution. We demonstrate that these transitions can be detected as discontinuities in $n^{\text{th}}$-order cross-fluctuations. For variance-preserving SDEs, we derive a closed-form for these cross-fluctuations that is efficiently computable for the reverse trajectory. We find that detecting these transitions directly boosts sampling efficiency, accelerates class-conditional and rare-class generation, and improves two zero-shot tasks--image classification and style transfer--without expensive grid search or retraining. We also show that this viewpoint unifies classical coupling and mixing from finite Markov chains with continuous dynamics while extending to stochastic SDEs and non Markovian samplers. Our framework therefore bridges discrete Markov chain theory, phase analysis, and modern generative modeling.</li>
</ul>

<h3>Title: Dynamic Model Selection for Trajectory Prediction via Pairwise Ranking and Meta-Features</h3>
<ul>
<li><strong>Authors: </strong>Lu Bowen</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.00126">https://arxiv.org/abs/2511.00126</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.00126">https://arxiv.org/pdf/2511.00126</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.00126]] Dynamic Model Selection for Trajectory Prediction via Pairwise Ranking and Meta-Features(https://arxiv.org/abs/2511.00126)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Recent deep trajectory predictors (e.g., Jiang et al., 2023; Zhou et al., 2022) have achieved strong average accuracy but remain unreliable in complex long-tail driving scenarios. These limitations reveal the weakness of the prevailing "one-model-fits-all" paradigm, particularly in safety-critical urban contexts where simpler physics-based models can occasionally outperform advanced networks (Kalman, 1960). To bridge this gap, we propose a dynamic multi-expert gating framework that adaptively selects the most reliable trajectory predictor among a physics-informed LSTM, a Transformer, and a fine-tuned GameFormer on a per-sample basis. Our method leverages internal model signals (meta-features) such as stability and uncertainty (Gal and Ghahramani, 2016), which we demonstrate to be substantially more informative than geometric scene descriptors. To the best of our knowledge, this is the first work to formulate trajectory expert selection as a pairwise-ranking problem over internal model signals (Burges et al., 2005), directly optimizing decision quality without requiring post-hoc calibration. Evaluated on the nuPlan-mini dataset (Caesar et al., 2021) with 1,287 samples, our LLM-enhanced tri-expert gate achieves a Final Displacement Error (FDE) of 2.567 m, representing a 9.5 percent reduction over GameFormer (2.835 m), and realizes 57.8 percent of the oracle performance bound. In open-loop simulations, after trajectory horizon alignment, the same configuration reduces FDE on left-turn scenarios by approximately 10 percent, demonstrating consistent improvements across both offline validation and open-loop evaluation. These results indicate that adaptive hybrid systems enhance trajectory reliability in safety-critical autonomous driving, providing a practical pathway beyond static single-model paradigms.</li>
</ul>

<h3>Title: A Comparative Analysis of LLM Adaptation: SFT, LoRA, and ICL in Data-Scarce Scenarios</h3>
<ul>
<li><strong>Authors: </strong>Bernd Bohnet, Rumen Dangovski, Kevin Swersky, Sherry Moore, Arslan Chaudhry, Kathleen Kenealy, Noah Fiedel</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.00130">https://arxiv.org/abs/2511.00130</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.00130">https://arxiv.org/pdf/2511.00130</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.00130]] A Comparative Analysis of LLM Adaptation: SFT, LoRA, and ICL in Data-Scarce Scenarios(https://arxiv.org/abs/2511.00130)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>The remarkable capabilities of Large Language Models (LLMs) often need to be tailored for specific applications, requiring the integration of new knowledge or the acquisition of new skills. While full fine-tuning is a powerful adaptation method, it is computationally expensive and can lead to a degradation of general reasoning abilities, a phenomenon known as catastrophic forgetting. A range of alternative techniques exists, each with its own trade-offs. In-Context Learning (ICL) is fast but limited by context length, while Parameter-Efficient Fine-Tuning (PEFT) methods like Low-Rank Adaptation (LoRA) offer a middle ground by minimizing parameter changes. However, the challenge of catastrophic forgetting persists, raising questions about the best adaptation strategy for a given task. This paper presents a comparative analysis of Supervised Finetuning (SFT), LoRA, and ICL in data-scarce scenarios. We find that LoRA provides the most effective balance, successfully instilling new skills with minimal impact on the base model's general knowledge. In contrast, while SFT excels at skill acquisition, it is highly susceptible to catastrophic forgetting. ICL is effective for incorporating factual knowledge but struggles with complex skills. Our findings offer a practical framework for selecting an LLM adaptation strategy. We highlight the critical distinction between skill acquisition and knowledge integration, clarify the trade-offs between task-specific performance and the preservation of general capabilities.</li>
</ul>

<h3>Title: Feature Importance Guided Random Forest Learning with Simulated Annealing Based Hyperparameter Tuning</h3>
<ul>
<li><strong>Authors: </strong>Kowshik Balasubramanian, Andre Williams, Ismail Butun</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.00133">https://arxiv.org/abs/2511.00133</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.00133">https://arxiv.org/pdf/2511.00133</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.00133]] Feature Importance Guided Random Forest Learning with Simulated Annealing Based Hyperparameter Tuning(https://arxiv.org/abs/2511.00133)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>This paper introduces a novel framework for enhancing Random Forest classifiers by integrating probabilistic feature sampling and hyperparameter tuning via Simulated Annealing. The proposed framework exhibits substantial advancements in predictive accuracy and generalization, adeptly tackling the multifaceted challenges of robust classification across diverse domains, including credit risk evaluation, anomaly detection in IoT ecosystems, early-stage medical diagnostics, and high-dimensional biological data analysis. To overcome the limitations of conventional Random Forests, we present an approach that places stronger emphasis on capturing the most relevant signals from data while enabling adaptive hyperparameter configuration. The model is guided towards features that contribute more meaningfully to classification and optimizing this with dynamic parameter tuning. The results demonstrate consistent accuracy improvements and meaningful insights into feature relevance, showcasing the efficacy of combining importance aware sampling and metaheuristic optimization.</li>
</ul>

<h3>Title: A Dual Large Language Models Architecture with Herald Guided Prompts for Parallel Fine Grained Traffic Signal Control</h3>
<ul>
<li><strong>Authors: </strong>Qing Guo, Xinhang Li, Junyu Chen, Zheng Guo, Xiaocong Li, Lin Zhang, Lei Li</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.00136">https://arxiv.org/abs/2511.00136</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.00136">https://arxiv.org/pdf/2511.00136</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.00136]] A Dual Large Language Models Architecture with Herald Guided Prompts for Parallel Fine Grained Traffic Signal Control(https://arxiv.org/abs/2511.00136)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, interpretability, large language model</a></li>
<li><strong>Abstract: </strong>Leveraging large language models (LLMs) in traffic signal control (TSC) improves optimization efficiency and interpretability compared to traditional reinforcement learning (RL) methods. However, existing LLM-based approaches are limited by fixed time signal durations and are prone to hallucination errors, while RL methods lack robustness in signal timing decisions and suffer from poor generalization. To address these challenges, this paper proposes HeraldLight, a dual LLMs architecture enhanced by Herald guided prompts. The Herald Module extracts contextual information and forecasts queue lengths for each traffic phase based on real-time conditions. The first LLM, LLM-Agent, uses these forecasts to make fine grained traffic signal control, while the second LLM, LLM-Critic, refines LLM-Agent's outputs, correcting errors and hallucinations. These refined outputs are used for score-based fine-tuning to improve accuracy and robustness. Simulation experiments using CityFlow on real world datasets covering 224 intersections in Jinan (12), Hangzhou (16), and New York (196) demonstrate that HeraldLight outperforms state of the art baselines, achieving a 20.03% reduction in average travel time across all scenarios and a 10.74% reduction in average queue length on the Jinan and Hangzhou scenarios. The source code is available on GitHub: this https URL.</li>
</ul>

<h3>Title: Supply Chain Exploitation of Secure ROS 2 Systems: A Proof-of-Concept on Autonomous Platform Compromise via Keystore Exfiltration</h3>
<ul>
<li><strong>Authors: </strong>Tahmid Hasan Sakib, Yago Romano Martinez, Carter Brady, Syed Rafay Hasan, Terry N. Guo</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.OS, cs.RO, eess.SY</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.00140">https://arxiv.org/abs/2511.00140</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.00140">https://arxiv.org/pdf/2511.00140</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.00140]] Supply Chain Exploitation of Secure ROS 2 Systems: A Proof-of-Concept on Autonomous Platform Compromise via Keystore Exfiltration(https://arxiv.org/abs/2511.00140)</code><input type="text"></li>
<li><strong>Keywords: </strong>secure, security, attack</a></li>
<li><strong>Abstract: </strong>This paper presents a proof-of-concept supply chain attack against the Secure ROS 2 (SROS 2) framework, demonstrated on a Quanser QCar2 autonomous vehicle platform. A Trojan-infected Debian package modifies core ROS 2 security commands to exfiltrate newly generated keystore credentials via DNS in base64-encoded chunks to an attacker-controlled nameserver. Possession of these credentials enables the attacker to rejoin the SROS 2 network as an authenticated participant and publish spoofed control or perception messages without triggering authentication failures. We evaluate this capability on a secure ROS 2 Humble testbed configured for a four-stop-sign navigation routine using an Intel RealSense camera for perception. Experimental results show that control-topic injections can cause forced braking, sustained high-speed acceleration, and continuous turning loops, while perception-topic spoofing can induce phantom stop signs or suppress real detections. The attack generalizes to any data distribution service (DDS)-based robotic system using SROS 2, highlighting the need for both supply chain integrity controls and runtime semantic validation to safeguard autonomous systems against insider and impersonation threats.</li>
</ul>

<h3>Title: FLoC: Facility Location-Based Efficient Visual Token Compression for Long Video Understanding</h3>
<ul>
<li><strong>Authors: </strong>Janghoon Cho, Jungsoo Lee, Munawar Hayat, Kyuwoong Hwang, Fatih Porikli, Sungha Choi</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.00141">https://arxiv.org/abs/2511.00141</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.00141">https://arxiv.org/pdf/2511.00141</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.00141]] FLoC: Facility Location-Based Efficient Visual Token Compression for Long Video Understanding(https://arxiv.org/abs/2511.00141)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Recent studies in long video understanding have harnessed the advanced visual-language reasoning capabilities of Large Multimodal Models (LMMs), driving the evolution of video-LMMs specialized for processing extended video sequences. However, the scalability of these models is severely limited by the overwhelming volume of visual tokens generated from extended video sequences. To address this challenge, this paper proposes FLoC, an efficient visual token compression framework based on the facility location function, a principled approach that swiftly selects a compact yet highly representative and diverse subset of visual tokens within a predefined budget on the number of visual tokens. By integrating the lazy greedy algorithm, our method achieves remarkable efficiency gains by swiftly selecting a compact subset of tokens, drastically reducing the number of visual tokens while guaranteeing near-optimal performance. Notably, our approach is training-free, model-agnostic, and query-agnostic, providing a versatile solution that seamlessly integrates with diverse video-LLMs and existing workflows. Extensive evaluations on large-scale benchmarks, such as Video-MME, MLVU, and LongVideoBench, demonstrate that our framework consistently surpasses recent compression techniques, highlighting not only its effectiveness and robustness in addressing the critical challenges of long video understanding, but also its efficiency in processing speed.</li>
</ul>

<h3>Title: BlurGuard: A Simple Approach for Robustifying Image Protection Against AI-Powered Editing</h3>
<ul>
<li><strong>Authors: </strong>Jinsu Kim, Yunhun Nam, Minseon Kim, Sangpil Kim, Jongheon Jeong</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.00143">https://arxiv.org/abs/2511.00143</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.00143">https://arxiv.org/pdf/2511.00143</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.00143]] BlurGuard: A Simple Approach for Robustifying Image Protection Against AI-Powered Editing(https://arxiv.org/abs/2511.00143)</code><input type="text"></li>
<li><strong>Keywords: </strong>protect, robust</a></li>
<li><strong>Abstract: </strong>Recent advances in text-to-image models have increased the exposure of powerful image editing techniques as a tool, raising concerns about their potential for malicious use. An emerging line of research to address such threats focuses on implanting "protective" adversarial noise into images before their public release, so future attempts to edit them using text-to-image models can be impeded. However, subsequent works have shown that these adversarial noises are often easily "reversed," e.g., with techniques as simple as JPEG compression, casting doubt on the practicality of the approach. In this paper, we argue that adversarial noise for image protection should not only be imperceptible, as has been a primary focus of prior work, but also irreversible, viz., it should be difficult to detect as noise provided that the original image is hidden. We propose a surprisingly simple method to enhance the robustness of image protection methods against noise reversal techniques. Specifically, it applies an adaptive per-region Gaussian blur on the noise to adjust the overall frequency spectrum. Through extensive experiments, we show that our method consistently improves the per-sample worst-case protection performance of existing methods against a wide range of reversal techniques on diverse image editing scenarios, while also reducing quality degradation due to noise in terms of perceptual metrics. Code is available at this https URL.</li>
</ul>

<h3>Title: Study on Supply Chain Finance Decision-Making Model and Enterprise Economic Performance Prediction Based on Deep Reinforcement Learning</h3>
<ul>
<li><strong>Authors: </strong>Shiman Zhang, Jinghan Zhou, Zhoufan Yu, Ningai Leng</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.00166">https://arxiv.org/abs/2511.00166</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.00166">https://arxiv.org/pdf/2511.00166</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.00166]] Study on Supply Chain Finance Decision-Making Model and Enterprise Economic Performance Prediction Based on Deep Reinforcement Learning(https://arxiv.org/abs/2511.00166)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, extraction</a></li>
<li><strong>Abstract: </strong>To improve decision-making and planning efficiency in back-end centralized redundant supply chains, this paper proposes a decision model integrating deep learning with intelligent particle swarm optimization. A distributed node deployment model and optimal planning path are constructed for the supply chain network. Deep learning such as convolutional neural networks extracts features from historical data, and linear programming captures high-order statistical features. The model is optimized using fuzzy association rule scheduling and deep reinforcement learning, while neural networks fit dynamic changes. A hybrid mechanism of "deep learning feature extraction - intelligent particle swarm optimization" guides global optimization and selects optimal decisions for adaptive control. Simulations show reduced resource consumption, enhanced spatial planning, and in dynamic environments improved real-time decision adjustment, distribution path optimization, and robust intelligent control.</li>
</ul>

<h3>Title: CompAgent: An Agentic Framework for Visual Compliance Verification</h3>
<ul>
<li><strong>Authors: </strong>Rahul Ghosh, Baishali Chaudhury, Hari Prasanna Das, Meghana Ashok, Ryan Razkenari, Sungmin Hong, Chun-Hao Liu</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.00171">https://arxiv.org/abs/2511.00171</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.00171">https://arxiv.org/pdf/2511.00171</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.00171]] CompAgent: An Agentic Framework for Visual Compliance Verification(https://arxiv.org/abs/2511.00171)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Visual compliance verification is a critical yet underexplored problem in computer vision, especially in domains such as media, entertainment, and advertising where content must adhere to complex and evolving policy rules. Existing methods often rely on task-specific deep learning models trained on manually labeled datasets, which are costly to build and limited in generalizability. While recent multi-modal large language models (MLLMs) offer broad real-world knowledge and policy understanding, they struggle to reason over fine-grained visual details and apply structured compliance rules effectively on their own. In this paper, we propose CompAgent, the first agentic framework for visual compliance verification. CompAgent augments MLLMs with a suite of visual tools - such as object detectors, face analyzers, NSFW detectors, and captioning models - and introduces a planning agent that dynamically selects appropriate tools based on the compliance policy. A verification agent then integrates image, tool outputs, and policy context to perform multi-modal reasoning. Experiments on public benchmarks show that CompAgent outperforms specialized classifiers, direct MLLM prompting, and curated routing baselines, achieving up to 76% F1 score and a 10% improvement over the state-of-the-art on the UnsafeBench dataset. Our results demonstrate the effectiveness of agentic planning and tool-augmented reasoning for scalable, accurate, and adaptable visual compliance verification.</li>
</ul>

<h3>Title: ParaScopes: What do Language Models Activations Encode About Future Text?</h3>
<ul>
<li><strong>Authors: </strong>Nicky Pochinkov, Yulia Volkova, Anna Vasileva, Sai V R Chereddy</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.00180">https://arxiv.org/abs/2511.00180</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.00180">https://arxiv.org/pdf/2511.00180</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.00180]] ParaScopes: What do Language Models Activations Encode About Future Text?(https://arxiv.org/abs/2511.00180)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability</a></li>
<li><strong>Abstract: </strong>Interpretability studies in language models often investigate forward-looking representations of activations. However, as language models become capable of doing ever longer time horizon tasks, methods for understanding activations often remain limited to testing specific concepts or tokens. We develop a framework of Residual Stream Decoders as a method of probing model activations for paragraph-scale and document-scale plans. We test several methods and find information can be decoded equivalent to 5+ tokens of future context in small models. These results lay the groundwork for better monitoring of language models and better understanding how they might encode longer-term planning information.</li>
</ul>

<h3>Title: From Evidence to Verdict: An Agent-Based Forensic Framework for AI-Generated Image Detection</h3>
<ul>
<li><strong>Authors: </strong>Mengfei Liang, Yiting Qu, Yukun Jiang, Michael Backes, Yang Zhang</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.00181">https://arxiv.org/abs/2511.00181</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.00181">https://arxiv.org/pdf/2511.00181</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.00181]] From Evidence to Verdict: An Agent-Based Forensic Framework for AI-Generated Image Detection(https://arxiv.org/abs/2511.00181)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, extraction, interpretability, generative</a></li>
<li><strong>Abstract: </strong>The rapid evolution of AI-generated images poses unprecedented challenges to information integrity and media authenticity. Existing detection approaches suffer from fundamental limitations: traditional classifiers lack interpretability and fail to generalize across evolving generative models, while vision-language models (VLMs), despite their promise, remain constrained to single-shot analysis and pixel-level reasoning. To address these challenges, we introduce AIFo (Agent-based Image Forensics), a novel training-free framework that emulates human forensic investigation through multi-agent collaboration. Unlike conventional methods, our framework employs a set of forensic tools, including reverse image search, metadata extraction, pre-trained classifiers, and VLM analysis, coordinated by specialized LLM-based agents that collect, synthesize, and reason over cross-source evidence. When evidence is conflicting or insufficient, a structured multi-agent debate mechanism allows agents to exchange arguments and reach a reliable conclusion. Furthermore, we enhance the framework with a memory-augmented reasoning module that learns from historical cases to improve future detection accuracy. Our comprehensive evaluation spans 6,000 images across both controlled laboratory settings and challenging real-world scenarios, including images from modern generative platforms and diverse online sources. AIFo achieves 97.05% accuracy, substantially outperforming traditional classifiers and state-of-the-art VLMs. These results demonstrate that agent-based procedural reasoning offers a new paradigm for more robust, interpretable, and adaptable AI-generated image detection.</li>
</ul>

<h3>Title: PDE-SHARP: PDE Solver Hybrids Through Analysis & Refinement Passes</h3>
<ul>
<li><strong>Authors: </strong>Shaghayegh Fazliani, Madeleine Udell</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.00183">https://arxiv.org/abs/2511.00183</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.00183">https://arxiv.org/pdf/2511.00183</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.00183]] PDE-SHARP: PDE Solver Hybrids Through Analysis & Refinement Passes(https://arxiv.org/abs/2511.00183)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Current LLM-driven approaches using test-time computing to generate PDE solvers execute a large number of solver samples to identify high-accuracy solvers. These paradigms are especially costly for complex PDEs requiring substantial computational resources for numerical evaluation. We introduce PDE-SHARP, a framework to reduce computational costs by replacing expensive scientific computation by cheaper LLM inference that achieves superior solver accuracy with 60-75% fewer computational evaluations. PDE-SHARP employs three stages: (1) Analysis: mathematical chain-of-thought analysis including PDE classification, solution type detection, and stability analysis; (2) Genesis: solver generation based on mathematical insights from the previous stage; and (3) Synthesis: collaborative selection-hybridization tournaments in which LLM judges iteratively refine implementations through flexible performance feedback. To generate high-quality solvers, PDE-SHARP requires fewer than 13 solver evaluations on average compared to 30+ for baseline methods, improving accuracy uniformly across tested PDEs by $4\times$ on average, and demonstrates robust performance across LLM architectures, from general-purpose to specialized reasoning models.</li>
</ul>

<h3>Title: EL-MIA: Quantifying Membership Inference Risks of Sensitive Entities in LLMs</h3>
<ul>
<li><strong>Authors: </strong>Ali Satvaty, Suzan Verberne, Fatih Turkmen</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.00192">https://arxiv.org/abs/2511.00192</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.00192">https://arxiv.org/pdf/2511.00192</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.00192]] EL-MIA: Quantifying Membership Inference Risks of Sensitive Entities in LLMs(https://arxiv.org/abs/2511.00192)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, attack, membership infer</a></li>
<li><strong>Abstract: </strong>Membership inference attacks (MIA) aim to infer whether a particular data point is part of the training dataset of a model. In this paper, we propose a new task in the context of LLM privacy: entity-level discovery of membership risk focused on sensitive information (PII, credit card numbers, etc). Existing methods for MIA can detect the presence of entire prompts or documents in the LLM training data, but they fail to capture risks at a finer granularity. We propose the ``EL-MIA'' framework for auditing entity-level membership risks in LLMs. We construct a benchmark dataset for the evaluation of MIA methods on this task. Using this benchmark, we conduct a systematic comparison of existing MIA techniques as well as two newly proposed methods. We provide a comprehensive analysis of the results, trying to explain the relation of the entity level MIA susceptability with the model scale, training epochs, and other surface level factors. Our findings reveal that existing MIA methods are limited when it comes to entity-level membership inference of the sensitive attributes, while this susceptibility can be outlined with relatively straightforward methods, highlighting the need for stronger adversaries to stress test the provided threat model.</li>
</ul>

<h3>Title: Training LLMs Beyond Next Token Prediction - Filling the Mutual Information Gap</h3>
<ul>
<li><strong>Authors: </strong>Chun-Hao Yang, Bo-Han Feng, Tzu-Yuan Lai, Yan Yu Chen, Yin-Kai Dean Huang, Shou-De Lin</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.00198">https://arxiv.org/abs/2511.00198</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.00198">https://arxiv.org/pdf/2511.00198</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.00198]] Training LLMs Beyond Next Token Prediction - Filling the Mutual Information Gap(https://arxiv.org/abs/2511.00198)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Optimizing training performance in large language models (LLMs) remains an essential challenge, particularly in improving model performance while maintaining computational costs. This work challenges the conventional approach of training LLMs using next-token prediction (NTP), arguing that by predicting information-rich tokens during training, there is a more effective way to train LLMs. We investigate the impact of the proposed solution in three kinds of tasks for LLMs: arithmetic, multi-label classification of text, and natural-language generation. This work offers a principled approach to optimizing LLM training, advancing both model performance and theoretical understanding of the target-token selection strategies.</li>
</ul>

<h3>Title: Diffusion LLMs are Natural Adversaries for any LLM</h3>
<ul>
<li><strong>Authors: </strong>David Lüdke, Tom Wollschläger, Paul Ungermann, Stephan Günnemann, Leo Schwinn</a></li>
<li><strong>Subjects: </strong>cs.LG, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.00203">https://arxiv.org/abs/2511.00203</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.00203">https://arxiv.org/pdf/2511.00203</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.00203]] Diffusion LLMs are Natural Adversaries for any LLM(https://arxiv.org/abs/2511.00203)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, diffusion, generative</a></li>
<li><strong>Abstract: </strong>We introduce a novel framework that transforms the resource-intensive (adversarial) prompt optimization problem into an \emph{efficient, amortized inference task}. Our core insight is that pretrained, non-autoregressive generative LLMs, such as Diffusion LLMs, which model the joint distribution over prompt-response pairs, can serve as powerful surrogates for prompt search. This approach enables the direct conditional generation of prompts, effectively replacing costly, per-instance discrete optimization with a small number of parallelizable samples. We provide a probabilistic analysis demonstrating that under mild fidelity assumptions, only a few conditional samples are required to recover high-reward (harmful) prompts. Empirically, we find that the generated prompts are low-perplexity, diverse jailbreaks that exhibit strong transferability to a wide range of black-box target models, including robustly trained and proprietary LLMs. Beyond adversarial prompting, our framework opens new directions for red teaming, automated prompt optimization, and leveraging emerging Flow- and Diffusion-based LLMs.</li>
</ul>

<h3>Title: Diffusion Models at the Drug Discovery Frontier: A Review on Generating Small Molecules versus Therapeutic Peptides</h3>
<ul>
<li><strong>Authors: </strong>Yiquan Wang, Yahui Ma, Yuhan Chang, Jiayao Yan, Jialin Zhang, Minnuo Cai, Kai Wei</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, q-bio.BM, q-bio.QM</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.00209">https://arxiv.org/abs/2511.00209</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.00209">https://arxiv.org/pdf/2511.00209</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.00209]] Diffusion Models at the Drug Discovery Frontier: A Review on Generating Small Molecules versus Therapeutic Peptides(https://arxiv.org/abs/2511.00209)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, generative</a></li>
<li><strong>Abstract: </strong>Diffusion models have emerged as a leading framework in generative modeling, showing significant potential to accelerate and transform the traditionally slow and costly process of drug discovery. This review provides a systematic comparison of their application in designing two principal therapeutic modalities: small molecules and therapeutic peptides. We analyze how a unified framework of iterative denoising is adapted to the distinct molecular representations, chemical spaces, and design objectives of each modality. For small molecules, these models excel at structure-based design, generating novel, pocket-fitting ligands with desired physicochemical properties, yet face the critical hurdle of ensuring chemical synthesizability. Conversely, for therapeutic peptides, the focus shifts to generating functional sequences and designing de novo structures, where the primary challenges are achieving biological stability against proteolysis, ensuring proper folding, and minimizing immunogenicity. Despite these distinct challenges, both domains face shared hurdles: the need for more accurate scoring functions, the scarcity of high-quality experimental data, and the crucial requirement for experimental validation. We conclude that the full potential of diffusion models will be unlocked by bridging these modality-specific gaps and integrating them into automated, closed-loop Design-Build-Test-Learn (DBTL) platforms, thereby shifting the paradigm from chemical exploration to the targeted creation of novel therapeutics.</li>
</ul>

<h3>Title: DM-QPMNET: Dual-modality fusion network for cell segmentation in quantitative phase microscopy</h3>
<ul>
<li><strong>Authors: </strong>Rajatsubhra Chakraborty, Ana Espinosa-Momox, Riley Haskin, Depeng Xu, Rosario Porras-Aguilar</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.00218">https://arxiv.org/abs/2511.00218</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.00218">https://arxiv.org/pdf/2511.00218</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.00218]] DM-QPMNET: Dual-modality fusion network for cell segmentation in quantitative phase microscopy(https://arxiv.org/abs/2511.00218)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, segmentation</a></li>
<li><strong>Abstract: </strong>Cell segmentation in single-shot quantitative phase microscopy (ssQPM) faces challenges from traditional thresholding methods that are sensitive to noise and cell density, while deep learning approaches using simple channel concatenation fail to exploit the complementary nature of polarized intensity images and phase maps. We introduce DM-QPMNet, a dual-encoder network that treats these as distinct modalities with separate encoding streams. Our architecture fuses modality-specific features at intermediate depth via multi-head attention, enabling polarized edge and texture representations to selectively integrate complementary phase information. This content-aware fusion preserves training stability while adding principled multi-modal integration through dual-source skip connections and per-modality normalization at minimal overhead. Our approach demonstrates substantial improvements over monolithic concatenation and single-modality baselines, showing that modality-specific encoding with learnable fusion effectively exploits ssQPM's simultaneous capture of complementary illumination and phase cues for robust cell segmentation.</li>
</ul>

<h3>Title: Consistently Simulating Human Personas with Multi-Turn Reinforcement Learning</h3>
<ul>
<li><strong>Authors: </strong>Marwa Abdulhai, Ryan Cheng, Donovan Clay, Tim Althoff, Sergey Levine, Natasha Jaques</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.00222">https://arxiv.org/abs/2511.00222</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.00222">https://arxiv.org/pdf/2511.00222</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.00222]] Consistently Simulating Human Personas with Multi-Turn Reinforcement Learning(https://arxiv.org/abs/2511.00222)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large Language Models (LLMs) are increasingly used to simulate human users in interactive settings such as therapy, education, and social role-play. While these simulations enable scalable training and evaluation of AI agents, off-the-shelf LLMs often drift from their assigned personas, contradict earlier statements, or abandon role-appropriate behavior. We introduce a unified framework for evaluating and improving persona consistency in LLM-generated dialogue. We define three automatic metrics: prompt-to-line consistency, line-to-line consistency, and Q&A consistency, that capture different types of persona drift and validate each against human annotations. Using these metrics as reward signals, we apply multi-turn reinforcement learning to fine-tune LLMs for three user roles: a patient, a student, and a social chat partner. Our method reduces inconsistency by over 55%, resulting in more coherent and faithful simulated users.</li>
</ul>

<h3>Title: Towards 1000-fold Electron Microscopy Image Compression for Connectomics via VQ-VAE with Transformer Prior</h3>
<ul>
<li><strong>Authors: </strong>Fuming Yang, Yicong Li, Hanspeter Pfister, Jeff W. Lichtman, Yaron Meirovitch</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.00231">https://arxiv.org/abs/2511.00231</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.00231">https://arxiv.org/pdf/2511.00231</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.00231]] Towards 1000-fold Electron Microscopy Image Compression for Connectomics via VQ-VAE with Transformer Prior(https://arxiv.org/abs/2511.00231)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Petascale electron microscopy (EM) datasets push storage, transfer, and downstream analysis toward their current limits. We present a vector-quantized variational autoencoder-based (VQ-VAE) compression framework for EM that spans 16x to 1024x and enables pay-as-you-decode usage: top-only decoding for extreme compression, with an optional Transformer prior that predicts bottom tokens (without changing the compression ratio) to restore texture via feature-wise linear modulation (FiLM) and concatenation; we further introduce an ROI-driven workflow that performs selective high-resolution reconstruction from 1024x-compressed latents only where needed.</li>
</ul>

<h3>Title: Identifying Linux Kernel Instability Due to Poor RCU Synchronization</h3>
<ul>
<li><strong>Authors: </strong>Oisin O Sullivan, Colin Flanagan, Eoin O Connell</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.00237">https://arxiv.org/abs/2511.00237</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.00237">https://arxiv.org/pdf/2511.00237</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.00237]] Identifying Linux Kernel Instability Due to Poor RCU Synchronization(https://arxiv.org/abs/2511.00237)</code><input type="text"></li>
<li><strong>Keywords: </strong>protect</a></li>
<li><strong>Abstract: </strong>Read-Copy-Update (RCU) is widely used in the Linux kernel to manage concurrent access to shared data this http URL, improper synchronization when removing RCU protected hash table entries can lead to stale pointers, inconsistent lookups, and critical use after free (UAF) vulnerabilities. This paper investigates a driver-level synchronization issue arising from the omission of explicit synchronize_rcu() calls during hash table updates, using a discovered weakness in the Intel ICE network drivers Virtual Function (VF) management. Previous kernel vulnerabilities, such as a bug in the Reliable Datagram Sockets (RDS) subsystem, show how improper RCU synchronization can directly cause kernel crashes. Experimental results demonstrate that removing VF entries without proper synchronization leaves transient stale entries, delays memory reclamation, and results in significant memory fragmentation under rapid insert/delete workloads. RCU hash tables are widely deployed in Linux kernel subsystems such as networking, virtualization, and file systems; improper synchronization can cause memory fragmentation, kernel instability, and out-of-memory (OOM) conditions. Mitigations are proposed, recommending explicit insertion of synchronize_rcu() calls to ensure timely and safe memory reclamation. These findings reinforce established best practices for RCU synchronization, highlighting their importance for maintaining kernel stability and memory safety. Keywords: RCU, kernel synchronization, hash tables, ICE driver, memory fragmentation, use-after-free</li>
</ul>

<h3>Title: Melanoma Classification Through Deep Ensemble Learning and Explainable AI</h3>
<ul>
<li><strong>Authors: </strong>Wadduwage Shanika Perera, ABM Islam, Van Vung Pham, Min Kyung An</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.00246">https://arxiv.org/abs/2511.00246</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.00246">https://arxiv.org/pdf/2511.00246</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.00246]] Melanoma Classification Through Deep Ensemble Learning and Explainable AI(https://arxiv.org/abs/2511.00246)</code><input type="text"></li>
<li><strong>Keywords: </strong>explainability</a></li>
<li><strong>Abstract: </strong>Melanoma is one of the most aggressive and deadliest skin cancers, leading to mortality if not detected and treated in the early stages. Artificial intelligence techniques have recently been developed to help dermatologists in the early detection of melanoma, and systems based on deep learning (DL) have been able to detect these lesions with high accuracy. However, the entire community must overcome the explainability limit to get the maximum benefit from DL for diagnostics in the healthcare domain. Because of the black box operation's shortcomings in DL models' decisions, there is a lack of reliability and trust in the outcomes. However, Explainable Artificial Intelligence (XAI) can solve this problem by interpreting the predictions of AI systems. This paper proposes a machine learning model using ensemble learning of three state-of-the-art deep transfer Learning networks, along with an approach to ensure the reliability of the predictions by utilizing XAI techniques to explain the basis of the predictions.</li>
</ul>

<h3>Title: Object-Aware 4D Human Motion Generation</h3>
<ul>
<li><strong>Authors: </strong>Shurui Gui, Deep Anil Patel, Xiner Li, Martin Renqiang Min</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.GR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.00248">https://arxiv.org/abs/2511.00248</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.00248">https://arxiv.org/pdf/2511.00248</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.00248]] Object-Aware 4D Human Motion Generation(https://arxiv.org/abs/2511.00248)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, large language model</a></li>
<li><strong>Abstract: </strong>Recent advances in video diffusion models have enabled the generation of high-quality videos. However, these videos still suffer from unrealistic deformations, semantic violations, and physical inconsistencies that are largely rooted in the absence of 3D physical priors. To address these challenges, we propose an object-aware 4D human motion generation framework grounded in 3D Gaussian representations and motion diffusion priors. With pre-generated 3D humans and objects, our method, Motion Score Distilled Interaction (MSDI), employs the spatial and prompt semantic information in large language models (LLMs) and motion priors through the proposed Motion Diffusion Score Distillation Sampling (MSDS). The combination of MSDS and LLMs enables our spatial-aware motion optimization, which distills score gradients from pre-trained motion diffusion models, to refine human motion while respecting object and semantic constraints. Unlike prior methods requiring joint training on limited interaction datasets, our zero-shot approach avoids retraining and generalizes to out-of-distribution object aware human motions. Experiments demonstrate that our framework produces natural and physically plausible human motions that respect 3D spatial context, offering a scalable solution for realistic 4D generation.</li>
</ul>

<h3>Title: Application of Blockchain Frameworks for Decentralized Identity and Access Management of IoT Devices</h3>
<ul>
<li><strong>Authors: </strong>Sushil Khairnar</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.00249">https://arxiv.org/abs/2511.00249</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.00249">https://arxiv.org/pdf/2511.00249</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.00249]] Application of Blockchain Frameworks for Decentralized Identity and Access Management of IoT Devices(https://arxiv.org/abs/2511.00249)</code><input type="text"></li>
<li><strong>Keywords: </strong>secure, security, privacy</a></li>
<li><strong>Abstract: </strong>The growth in IoT devices means an ongoing risk of data vulnerability. The transition from centralized ecosystems to decentralized ecosystems is of paramount importance due to security, privacy, and data use concerns. Since the majority of IoT devices will be used by consumers in peer-to-peer applications, a centralized approach raises many issues of trust related to privacy, control, and censorship. Identity and access management lies at the heart of any user-facing system. Blockchain technologies can be leveraged to augment user authority, transparency, and decentralization. This study proposes a decentralized identity management framework for IoT environments using Hyperledger Fabric and Decentralized Identifiers (DIDs). The system was simulated using Node-RED to model IoT data streams, and key functionalities including device onboarding, authentication, and secure asset querying were successfully implemented. Results demonstrated improved data integrity, transparency, and user control, with reduced reliance on centralized authorities. These findings validate the practicality of blockchain-based identity management in enhancing the security and trustworthiness of IoT infrastructures.</li>
</ul>

<h3>Title: BeetleFlow: An Integrative Deep Learning Pipeline for Beetle Image Processing</h3>
<ul>
<li><strong>Authors: </strong>Fangxun Liu, S M Rayeed, Samuel Stevens, Alyson East, Cheng Hsuan Chiang, Colin Lee, Daniel Yi, Junke Yang, Tejas Naik, Ziyi Wang, Connor Kilrain, Elijah H Buckwalter, Jiacheng Hou, Saul Ibaven Bueno, Shuheng Wang, Xinyue Ma, Yifan Liu, Zhiyuan Tao, Ziheng Zhang, Eric Sokol, Michael Belitz, Sydne Record, Charles V. Stewart, Wei-Lun Chao</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.00255">https://arxiv.org/abs/2511.00255</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.00255">https://arxiv.org/pdf/2511.00255</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.00255]] BeetleFlow: An Integrative Deep Learning Pipeline for Beetle Image Processing(https://arxiv.org/abs/2511.00255)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer, segmentation</a></li>
<li><strong>Abstract: </strong>In entomology and ecology research, biologists often need to collect a large number of insects, among which beetles are the most common species. A common practice for biologists to organize beetles is to place them on trays and take a picture of each tray. Given the images of thousands of such trays, it is important to have an automated pipeline to process the large-scale data for further research. Therefore, we develop a 3-stage pipeline to detect all the beetles on each tray, sort and crop the image of each beetle, and do morphological segmentation on the cropped beetles. For detection, we design an iterative process utilizing a transformer-based open-vocabulary object detector and a vision-language model. For segmentation, we manually labeled 670 beetle images and fine-tuned two variants of a transformer-based segmentation model to achieve fine-grained segmentation of beetles with relatively high accuracy. The pipeline integrates multiple deep learning methods and is specialized for beetle image processing, which can greatly improve the efficiency to process large-scale beetle data and accelerate biological research.</li>
</ul>

<h3>Title: MambaNetLK: Enhancing Colonoscopy Point Cloud Registration with Mamba</h3>
<ul>
<li><strong>Authors: </strong>Linzhe Jiang, Jiayuan Huang, Sophia Bano, Matthew J. Clarkson, Zhehua Mao, Mobarak I. Hoque</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.00260">https://arxiv.org/abs/2511.00260</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.00260">https://arxiv.org/pdf/2511.00260</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.00260]] MambaNetLK: Enhancing Colonoscopy Point Cloud Registration with Mamba(https://arxiv.org/abs/2511.00260)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Accurate 3D point cloud registration underpins reliable image-guided colonoscopy, directly affecting lesion localization, margin assessment, and navigation safety. However, biological tissue exhibits repetitive textures and locally homogeneous geometry that cause feature degeneracy, while substantial domain shifts between pre-operative anatomy and intra-operative observations further degrade alignment stability. To address these clinically critical challenges, we introduce a novel 3D registration method tailored for endoscopic navigation and a high-quality, clinically grounded dataset to support rigorous and reproducible benchmarking. We introduce C3VD-Raycasting-10k, a large-scale benchmark dataset with 10,014 geometrically aligned point cloud pairs derived from clinical CT data. We propose MambaNetLK, a novel correspondence-free registration framework, which enhances the PointNetLK architecture by integrating a Mamba State Space Model (SSM) as a cross-modal feature extractor. As a result, the proposed framework efficiently captures long-range dependencies with linear-time complexity. The alignment is achieved iteratively using the Lucas-Kanade algorithm. On the clinical dataset, C3VD-Raycasting-10k, MambaNetLK achieves the best performance compared with the state-of-the-art methods, reducing median rotation error by 56.04% and RMSE translation error by 26.19% over the second-best method. The model also demonstrates strong generalization on ModelNet40 and superior robustness to initial pose perturbations. MambaNetLK provides a robust foundation for 3D registration in surgical navigation. The combination of a globally expressive SSM-based feature extractor and a large-scale clinical dataset enables more accurate and reliable guidance systems in minimally invasive procedures like colonoscopy.</li>
</ul>

<h3>Title: Spot The Ball: A Benchmark for Visual Social Inference</h3>
<ul>
<li><strong>Authors: </strong>Neha Balamurugan, Sarah Wu, Adam Chun, Gabe Gaw, Cristobal Eyzaguirre, Tobias Gerstenberg</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.HC</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.00261">https://arxiv.org/abs/2511.00261</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.00261">https://arxiv.org/pdf/2511.00261</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.00261]] Spot The Ball: A Benchmark for Visual Social Inference(https://arxiv.org/abs/2511.00261)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Humans excel at visual social inference, the ability to infer hidden elements of a scene from subtle behavioral cues such as other people's gaze, pose, and orientation. This ability drives everyday social reasoning in humans and is critical for developing more human-like AI agents. We introduce Spot The Ball, a challenging benchmark for evaluating visual social inference in vision-language models (VLMs) using sports as a test domain. The task is to localize a removed sports ball from soccer, basketball, and volleyball images. We present a curated evaluation set with human baselines and a scalable pipeline for generating additional test items. We evaluate four state-of-the-art VLMs (Gemini, GPT, LLaMA, Qwen) using three prompting strategies, finding that humans are consistently two to three times more accurate (20-34%) than models ($\leq$ 17%) across all sports. Our analyses show that models rely on superficial spatial heuristics--such as guessing near the image center or nearby players--while humans leverage social cues like gaze direction and body pose. These findings reveal a persistent human-model gap in visual social reasoning and underscore the need for architectures that explicitly encode structured behavioral cues to achieve robust, human-like inference.</li>
</ul>

<h3>Title: AgentBnB: A Browser-Based Cybersecurity Tabletop Exercise with Large Language Model Support and Retrieval-Aligned Scaffolding</h3>
<ul>
<li><strong>Authors: </strong>Arman Anwar, Zefang Liu</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.00265">https://arxiv.org/abs/2511.00265</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.00265">https://arxiv.org/pdf/2511.00265</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.00265]] AgentBnB: A Browser-Based Cybersecurity Tabletop Exercise with Large Language Model Support and Retrieval-Aligned Scaffolding(https://arxiv.org/abs/2511.00265)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, large language model</a></li>
<li><strong>Abstract: </strong>Traditional cybersecurity tabletop exercises (TTXs) provide valuable training but are often scripted, resource-intensive, and difficult to scale. We introduce AgentBnB, a browser-based re-imagining of the Backdoors & Breaches game that integrates large language model teammates with a Bloom-aligned, retrieval-augmented copilot (C2D2). The system expands a curated corpus into factual, conceptual, procedural, and metacognitive snippets, delivering on-demand, cognitively targeted hints. Prompt-engineered agents employ a scaffolding ladder that gradually fades as learner confidence grows. In a solo-player pilot with four graduate students, participants reported greater intention to use the agent-based version compared to the physical card deck and viewed it as more scalable, though a ceiling effect emerged on a simple knowledge quiz. Despite limitations of small sample size, single-player focus, and narrow corpus, these early findings suggest that large language model augmented TTXs can provide lightweight, repeatable practice without the logistical burden of traditional exercises. Planned extensions include multi-player modes, telemetry-driven coaching, and comparative studies with larger cohorts.</li>
</ul>

<h3>Title: FedReplay: A Feature Replay Assisted Federated Transfer Learning Framework for Efficient and Privacy-Preserving Smart Agriculture</h3>
<ul>
<li><strong>Authors: </strong>Long Li, Jiajia Li, Dong Chen, Lina Pu, Haibo Yao, Yanbo Huang</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.00269">https://arxiv.org/abs/2511.00269</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.00269">https://arxiv.org/pdf/2511.00269</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.00269]] FedReplay: A Feature Replay Assisted Federated Transfer Learning Framework for Efficient and Privacy-Preserving Smart Agriculture(https://arxiv.org/abs/2511.00269)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, extraction, federate, transformer</a></li>
<li><strong>Abstract: </strong>Accurate classification plays a pivotal role in smart agriculture, enabling applications such as crop monitoring, fruit recognition, and pest detection. However, conventional centralized training often requires large-scale data collection, which raises privacy concerns, while standard federated learning struggles with non-independent and identically distributed (non-IID) data and incurs high communication costs. To address these challenges, we propose a federated learning framework that integrates a frozen Contrastive Language-Image Pre-training (CLIP) vision transformer (ViT) with a lightweight transformer classifier. By leveraging the strong feature extraction capability of the pre-trained CLIP ViT, the framework avoids training large-scale models from scratch and restricts federated updates to a compact classifier, thereby reducing transmission overhead significantly. Furthermore, to mitigate performance degradation caused by non-IID data distribution, a small subset (1%) of CLIP-extracted feature representations from all classes is shared across clients. These shared features are non-reversible to raw images, ensuring privacy preservation while aligning class representation across participants. Experimental results on agricultural classification tasks show that the proposed method achieve 86.6% accuracy, which is more than 4 times higher compared to baseline federated learning approaches. This demonstrates the effectiveness and efficiency of combining vision-language model features with federated learning for privacy-preserving and scalable agricultural intelligence.</li>
</ul>

<h3>Title: POSESTITCH-SLT: Linguistically Inspired Pose-Stitching for End-to-End Sign Language Translation</h3>
<ul>
<li><strong>Authors: </strong>Abhinav Joshi, Vaibhav Sharma, Sanjeet Singh, Ashutosh Modi</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.CV, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.00270">https://arxiv.org/abs/2511.00270</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.00270">https://arxiv.org/pdf/2511.00270</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.00270]] POSESTITCH-SLT: Linguistically Inspired Pose-Stitching for End-to-End Sign Language Translation(https://arxiv.org/abs/2511.00270)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction, transformer</a></li>
<li><strong>Abstract: </strong>Sign language translation remains a challenging task due to the scarcity of large-scale, sentence-aligned datasets. Prior arts have focused on various feature extraction and architectural changes to support neural machine translation for sign languages. We propose POSESTITCH-SLT, a novel pre-training scheme that is inspired by linguistic-templates-based sentence generation technique. With translation comparison on two sign language datasets, How2Sign and iSign, we show that a simple transformer-based encoder-decoder architecture outperforms the prior art when considering template-generated sentence pairs in training. We achieve BLEU-4 score improvements from 1.97 to 4.56 on How2Sign and from 0.55 to 3.43 on iSign, surpassing prior state-of-the-art methods for pose-based gloss-free translation. The results demonstrate the effectiveness of template-driven synthetic supervision in low-resource sign language settings.</li>
</ul>

<h3>Title: Improving the Robustness of Control of Chaotic Convective Flows with Domain-Informed Reinforcement Learning</h3>
<ul>
<li><strong>Authors: </strong>Michiel Straat, Thorben Markmann, Sebastian Peitz, Barbara Hammer</a></li>
<li><strong>Subjects: </strong>cs.LG, physics.flu-dyn</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.00272">https://arxiv.org/abs/2511.00272</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.00272">https://arxiv.org/pdf/2511.00272</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.00272]] Improving the Robustness of Control of Chaotic Convective Flows with Domain-Informed Reinforcement Learning(https://arxiv.org/abs/2511.00272)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Chaotic convective flows arise in many real-world systems, such as microfluidic devices and chemical reactors. Stabilizing these flows is highly desirable but remains challenging, particularly in chaotic regimes where conventional control methods often fail. Reinforcement Learning (RL) has shown promise for control in laminar flow settings, but its ability to generalize and remain robust under chaotic and turbulent dynamics is not well explored, despite being critical for real-world deployment. In this work, we improve the practical feasibility of RL-based control of such flows focusing on Rayleigh-Bénard Convection (RBC), a canonical model for convective heat transport. To enhance generalization and sample efficiency, we introduce domain-informed RL agents that are trained using Proximal Policy Optimization across diverse initial conditions and flow regimes. We incorporate domain knowledge in the reward function via a term that encourages Bénard cell merging, as an example of a desirable macroscopic property. In laminar flow regimes, the domain-informed RL agents reduce convective heat transport by up to 33%, and in chaotic flow regimes, they still achieve a 10% reduction, which is significantly better than the conventional controllers used in practice. We compare the domain-informed to uninformed agents: Our results show that the domain-informed reward design results in steady flows, faster convergence during training, and generalization across flow regimes without retraining. Our work demonstrates that elegant domain-informed priors can greatly enhance the robustness of RL-based control of chaotic flows, bringing real-world deployment closer.</li>
</ul>

<h3>Title: Calibration Across Layers: Understanding Calibration Evolution in LLMs</h3>
<ul>
<li><strong>Authors: </strong>Abhinav Joshi, Areeb Ahmad, Ashutosh Modi</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.00280">https://arxiv.org/abs/2511.00280</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.00280">https://arxiv.org/pdf/2511.00280</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.00280]] Calibration Across Layers: Understanding Calibration Evolution in LLMs(https://arxiv.org/abs/2511.00280)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large Language Models (LLMs) have demonstrated inherent calibration capabilities, where predicted probabilities align well with correctness, despite prior findings that deep neural networks are often overconfident. Recent studies have linked this behavior to specific components in the final layer, such as entropy neurons and the unembedding matrix null space. In this work, we provide a complementary perspective by investigating how calibration evolves throughout the network depth. Analyzing multiple open-weight models on the MMLU benchmark, we uncover a distinct confidence correction phase in the upper/later layers, where model confidence is actively recalibrated after decision certainty has been reached. Furthermore, we identify a low-dimensional calibration direction in the residual stream whose perturbation significantly improves calibration metrics (ECE and MCE) without harming accuracy. Our findings suggest that calibration is a distributed phenomenon, shaped throughout the network forward pass, not just in its final projection, providing new insights into how confidence-regulating mechanisms operate within LLMs.</li>
</ul>

<h3>Title: Multi-View Consistent Human Image Customization via In-Context Learning</h3>
<ul>
<li><strong>Authors: </strong>Hengjia Li, Jianjin Xu, Keli Cheng, Lei Wang, Ning Bi, Boxi Wu, Fernando De la Torre, Deng Cai</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.00293">https://arxiv.org/abs/2511.00293</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.00293">https://arxiv.org/pdf/2511.00293</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.00293]] Multi-View Consistent Human Image Customization via In-Context Learning(https://arxiv.org/abs/2511.00293)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, transformer, generative</a></li>
<li><strong>Abstract: </strong>Recent advances in personalized generative models demonstrate impressive results in creating identity-consistent images of the same person under diverse settings. Yet, we note that most methods cannot control the viewpoint of the generated image, nor generate consistent multiple views of the person. To address this problem, we propose a lightweight adaptation method, PersonalView, capable of enabling an existing model to acquire multi-view generation capability with as few as 100 training samples. PersonalView consists of two key components: First, we design a conditioning architecture to take advantage of the in-context learning ability of the pre-trained diffusion transformer. Second, we preserve the original generative ability of the pretrained model with a new Semantic Correspondence Alignment Loss. We evaluate the multi-view consistency, text alignment, identity similarity, and visual quality of PersonalView and compare it to recent baselines with potential capability of multi-view customization. PersonalView significantly outperforms baselines trained on a large corpus of multi-view data with only 100 training samples.</li>
</ul>

<h3>Title: Language Modeling With Factorization Memory</h3>
<ul>
<li><strong>Authors: </strong>Lee Xiong, Maksim Tkachenko, Johanes Effendi, Ting Cai</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.00315">https://arxiv.org/abs/2511.00315</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.00315">https://arxiv.org/pdf/2511.00315</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.00315]] Language Modeling With Factorization Memory(https://arxiv.org/abs/2511.00315)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>We propose Factorization Memory, an efficient recurrent neural network (RNN) architecture that achieves performance comparable to Transformer models on short-context language modeling tasks while also demonstrating superior generalization in long-context scenarios. Our model builds upon Mamba-2, enabling Factorization Memory to exploit parallel computations during training while preserving constant computational and memory complexity during inference. To further optimize model efficiency and representational capacity, we develop a sparse formulation of Factorization Memory that updates only a subset of recurrent states at each step while preserving the strong performance of its dense counterpart. To our knowledge, this represents the first RNN architecture that successfully combines sparse memory activation with competitive performance across both short and long-context settings. This work provides a systematic empirical analysis of Factorization Memory in comparison to Transformer and Mamba-2 architectures.</li>
</ul>

<h3>Title: A Technical Exploration of Causal Inference with Hybrid LLM Synthetic Data</h3>
<ul>
<li><strong>Authors: </strong>Dana Kim, Yichen Xu, Tiffany Lin</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.00318">https://arxiv.org/abs/2511.00318</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.00318">https://arxiv.org/pdf/2511.00318</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.00318]] A Technical Exploration of Causal Inference with Hybrid LLM Synthetic Data(https://arxiv.org/abs/2511.00318)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, large language model</a></li>
<li><strong>Abstract: </strong>Large Language Models (LLMs) offer a flexible means to generate synthetic tabular data, yet existing approaches often fail to preserve key causal parameters such as the average treatment effect (ATE). In this technical exploration, we first demonstrate that state-of-the-art synthetic data generators, both GAN- and LLM-based, can achieve high predictive fidelity while substantially misestimating causal effects. To address this gap, we propose a hybrid generation framework that combines model-based covariate synthesis (monitored via distance-to-closest-record filtering) with separately learned propensity and outcome models, thereby ensuring that (W, A, Y) triplets retain their underlying causal structure. We further introduce a synthetic pairing strategy to mitigate positivity violations and a realistic evaluation protocol that leverages unlimited synthetic samples to benchmark traditional estimators (IPTW, AIPW, substitution) under complex covariate distributions. This work lays the groundwork for LLM-powered data pipelines that support robust causal analysis. Our code is available at this https URL.</li>
</ul>

<h3>Title: Towards Automated Petrography</h3>
<ul>
<li><strong>Authors: </strong>Isai Daniel Chacón, Paola Ruiz Puentes, Jillian Pearse, Pablo Arbeláez</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.00328">https://arxiv.org/abs/2511.00328</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.00328">https://arxiv.org/pdf/2511.00328</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.00328]] Towards Automated Petrography(https://arxiv.org/abs/2511.00328)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Petrography is a branch of geology that analyzes the mineralogical composition of rocks from microscopical thin section samples. It is essential for understanding rock properties across geology, archaeology, engineering, mineral exploration, and the oil industry. However, petrography is a labor-intensive task requiring experts to conduct detailed visual examinations of thin section samples through optical polarization microscopes, thus hampering scalability and highlighting the need for automated techniques. To address this challenge, we introduce the Large-scale Imaging and Thin section Optical-polarization Set (LITHOS), the largest and most diverse publicly available experimental framework for automated petrography. LITHOS includes 211,604 high-resolution RGB patches of polarized light and 105,802 expert-annotated grains across 25 mineral categories. Each annotation consists of the mineral class, spatial coordinates, and expert-defined major and minor axes represented as intersecting vector paths, capturing grain geometry and orientation. We evaluate multiple deep learning techniques for mineral classification in LITHOS and propose a dual-encoder transformer architecture that integrates both polarization modalities as a strong baseline for future reference. Our method consistently outperforms single-polarization models, demonstrating the value of polarization synergy in mineral classification. We have made the LITHOS Benchmark publicly available, comprising our dataset, code, and pretrained models, to foster reproducibility and further research in automated petrographic analysis.</li>
</ul>

<h3>Title: Beyond ImageNet: Understanding Cross-Dataset Robustness of Lightweight Vision Models</h3>
<ul>
<li><strong>Authors: </strong>Weidong Zhang, Pak Lun Kevin Ding, Huan Liu</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.00335">https://arxiv.org/abs/2511.00335</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.00335">https://arxiv.org/pdf/2511.00335</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.00335]] Beyond ImageNet: Understanding Cross-Dataset Robustness of Lightweight Vision Models(https://arxiv.org/abs/2511.00335)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, transformer</a></li>
<li><strong>Abstract: </strong>Lightweight vision classification models such as MobileNet, ShuffleNet, and EfficientNet are increasingly deployed in mobile and embedded systems, yet their performance has been predominantly benchmarked on ImageNet. This raises critical questions: Do models that excel on ImageNet also generalize across other domains? How can cross-dataset robustness be systematically quantified? And which architectural elements consistently drive generalization under tight resource constraints? Here, we present the first systematic evaluation of 11 lightweight vision models (2.5M parameters), trained under a fixed 100-epoch schedule across 7 diverse datasets. We introduce the Cross-Dataset Score (xScore), a unified metric that quantifies the consistency and robustness of model performance across diverse visual domains. Our results show that (1) ImageNet accuracy does not reliably predict performance on fine-grained or medical datasets, (2) xScore provides a scalable predictor of mobile model performance that can be estimated from just four datasets, and (3) certain architectural components--such as isotropic convolutions with higher spatial resolution and channel-wise attention--promote broader generalization, while Transformer-based blocks yield little additional benefit, despite incurring higher parameter overhead. This study provides a reproducible framework for evaluating lightweight vision models beyond ImageNet, highlights key design principles for mobile-friendly architectures, and guides the development of future models that generalize robustly across diverse application domains.</li>
</ul>

<h3>Title: Split Learning-Enabled Framework for Secure and Light-weight Internet of Medical Things Systems</h3>
<ul>
<li><strong>Authors: </strong>Siva Sai, Manish Prasad, Animesh Bhargava, Vinay Chamola, Rajkumar Buyya</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.DC, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.00336">https://arxiv.org/abs/2511.00336</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.00336">https://arxiv.org/pdf/2511.00336</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.00336]] Split Learning-Enabled Framework for Secure and Light-weight Internet of Medical Things Systems(https://arxiv.org/abs/2511.00336)</code><input type="text"></li>
<li><strong>Keywords: </strong>secure, security, privacy, attack, federate</a></li>
<li><strong>Abstract: </strong>The rapid growth of Internet of Medical Things (IoMT) devices has resulted in significant security risks, particularly the risk of malware attacks on resource-constrained devices. Conventional deep learning methods are impractical due to resource limitations, while Federated Learning (FL) suffers from high communication overhead and vulnerability to non-IID (heterogeneous) data. In this paper, we propose a split learning (SL) based framework for IoT malware detection through image-based classification. By dividing the neural network training between the clients and an edge server, the framework reduces computational burden on resource-constrained clients while ensuring data privacy. We formulate a joint optimization problem that balances computation cost and communication efficiency by using a game-theoretic approach for attaining better training performance. Experimental evaluations show that the proposed framework outperforms popular FL methods in terms of accuracy (+6.35%), F1-score (+5.03%), high convergence speed (+14.96%), and less resource consumption (33.83%). These results establish the potential of SL as a scalable and secure paradigm for next-generation IoT security.</li>
</ul>

<h3>Title: A DeepONet joint Neural Tangent Kernel Hybrid Framework for Physics-Informed Inverse Source Problems and Robust Image Reconstruction</h3>
<ul>
<li><strong>Authors: </strong>Yuhao Fang, Zijian Wang, Yao Lu, Ye Zhang, Chun Li</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.00338">https://arxiv.org/abs/2511.00338</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.00338">https://arxiv.org/pdf/2511.00338</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.00338]] A DeepONet joint Neural Tangent Kernel Hybrid Framework for Physics-Informed Inverse Source Problems and Robust Image Reconstruction(https://arxiv.org/abs/2511.00338)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>This work presents a novel hybrid approach that integrates Deep Operator Networks (DeepONet) with the Neural Tangent Kernel (NTK) to solve complex inverse problem. The method effectively addresses tasks such as source localization governed by the Navier-Stokes equations and image reconstruction, overcoming challenges related to nonlinearity, sparsity, and noisy data. By incorporating physics-informed constraints and task-specific regularization into the loss function, the framework ensures solutions that are both physically consistent and accurate. Validation on diverse synthetic and real datasets demonstrates its robustness, scalability, and precision, showcasing its broad potential applications in computational physics and imaging sciences.</li>
</ul>

<h3>Title: MH-1M: A 1.34 Million-Sample Comprehensive Multi-Feature Android Malware Dataset for Machine Learning, Deep Learning, Large Language Models, and Threat Intelligence Research</h3>
<ul>
<li><strong>Authors: </strong>Hendrio Braganca, Diego Kreutz, Vanderson Rocha, Joner Assolin, and Eduardo Feitosa</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.AI, cs.LG, cs.PF</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.00342">https://arxiv.org/abs/2511.00342</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.00342">https://arxiv.org/pdf/2511.00342</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.00342]] MH-1M: A 1.34 Million-Sample Comprehensive Multi-Feature Android Malware Dataset for Machine Learning, Deep Learning, Large Language Models, and Threat Intelligence Research(https://arxiv.org/abs/2511.00342)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction, large language model</a></li>
<li><strong>Abstract: </strong>We present MH-1M, one of the most comprehensive and up-to-date datasets for advanced Android malware research. The dataset comprises 1,340,515 applications, encompassing a wide range of features and extensive metadata. To ensure accurate malware classification, we employ the VirusTotal API, integrating multiple detection engines for comprehensive and reliable assessment. Our GitHub, Figshare, and Harvard Dataverse repositories provide open access to the processed dataset and its extensive supplementary metadata, totaling more than 400 GB of data and including the outputs of the feature extraction pipeline as well as the corresponding VirusTotal reports. Our findings underscore the MH-1M dataset's invaluable role in understanding the evolving landscape of malware.</li>
</ul>

<h3>Title: Federated Dialogue-Semantic Diffusion for Emotion Recognition under Incomplete Modalities</h3>
<ul>
<li><strong>Authors: </strong>Xihang Qiu, Jiarong Cheng, Yuhao Fang, Wanpeng Zhang, Yao Lu, Ye Zhang, Chun Li</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.00344">https://arxiv.org/abs/2511.00344</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.00344">https://arxiv.org/pdf/2511.00344</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.00344]] Federated Dialogue-Semantic Diffusion for Emotion Recognition under Incomplete Modalities(https://arxiv.org/abs/2511.00344)</code><input type="text"></li>
<li><strong>Keywords: </strong>federate, diffusion</a></li>
<li><strong>Abstract: </strong>Multimodal Emotion Recognition in Conversations (MERC) enhances emotional understanding through the fusion of multimodal signals. However, unpredictable modality absence in real-world scenarios significantly degrades the performance of existing methods. Conventional missing-modality recovery approaches, which depend on training with complete multimodal data, often suffer from semantic distortion under extreme data distributions, such as fixed-modality absence. To address this, we propose the Federated Dialogue-guided and Semantic-Consistent Diffusion (FedDISC) framework, pioneering the integration of federated learning into missing-modality recovery. By federated aggregation of modality-specific diffusion models trained on clients and broadcasting them to clients missing corresponding modalities, FedDISC overcomes single-client reliance on modality completeness. Additionally, the DISC-Diffusion module ensures consistency in context, speaker identity, and semantics between recovered and available modalities, using a Dialogue Graph Network to capture conversational dependencies and a Semantic Conditioning Network to enforce semantic alignment. We further introduce a novel Alternating Frozen Aggregation strategy, which cyclically freezes recovery and classifier modules to facilitate collaborative optimization. Extensive experiments on the IEMOCAP, CMUMOSI, and CMUMOSEI datasets demonstrate that FedDISC achieves superior emotion classification performance across diverse missing modality patterns, outperforming existing approaches.</li>
</ul>

<h3>Title: OSMGen: Highly Controllable Satellite Image Synthesis using OpenStreetMap Data</h3>
<ul>
<li><strong>Authors: </strong>Amir Ziashahabi, Narges Ghasemi, Sajjad Shahabi, John Krumm, Salman Avestimehr, Cyrus Shahabi</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.00345">https://arxiv.org/abs/2511.00345</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.00345">https://arxiv.org/pdf/2511.00345</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.00345]] OSMGen: Highly Controllable Satellite Image Synthesis using OpenStreetMap Data(https://arxiv.org/abs/2511.00345)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>Accurate and up-to-date geospatial data are essential for urban planning, infrastructure monitoring, and environmental management. Yet, automating urban monitoring remains difficult because curated datasets of specific urban features and their changes are scarce. We introduce OSMGen, a generative framework that creates realistic satellite imagery directly from raw OpenStreetMap (OSM) data. Unlike prior work that relies on raster tiles, OSMGen uses the full richness of OSM JSON, including vector geometries, semantic tags, location, and time, giving fine-grained control over how scenes are generated. A central feature of the framework is the ability to produce consistent before-after image pairs: user edits to OSM inputs translate into targeted visual changes, while the rest of the scene is preserved. This makes it possible to generate training data that addresses scarcity and class imbalance, and to give planners a simple way to preview proposed interventions by editing map data. More broadly, OSMGen produces paired (JSON, image) data for both static and changed states, paving the way toward a closed-loop system where satellite imagery can automatically drive structured OSM updates. Source code is available at this https URL.</li>
</ul>

<h3>Title: Exploiting Latent Space Discontinuities for Building Universal LLM Jailbreaks and Data Extraction Attacks</h3>
<ul>
<li><strong>Authors: </strong>Kayua Oleques Paim, Rodrigo Brandao Mansilha, Diego Kreutz, Muriel Figueredo Franco, Weverton Cordeiro</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.00346">https://arxiv.org/abs/2511.00346</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.00346">https://arxiv.org/pdf/2511.00346</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.00346]] Exploiting Latent Space Discontinuities for Building Universal LLM Jailbreaks and Data Extraction Attacks(https://arxiv.org/abs/2511.00346)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, defense, attack, extraction, large language model</a></li>
<li><strong>Abstract: </strong>The rapid proliferation of Large Language Models (LLMs) has raised significant concerns about their security against adversarial attacks. In this work, we propose a novel approach to crafting universal jailbreaks and data extraction attacks by exploiting latent space discontinuities, an architectural vulnerability related to the sparsity of training data. Unlike previous methods, our technique generalizes across various models and interfaces, proving highly effective in seven state-of-the-art LLMs and one image generation model. Initial results indicate that when these discontinuities are exploited, they can consistently and profoundly compromise model behavior, even in the presence of layered defenses. The findings suggest that this strategy has substantial potential as a systemic attack vector.</li>
</ul>

<h3>Title: Detecting AI-Generated Images via Diffusion Snap-Back Reconstruction: A Forensic Approach</h3>
<ul>
<li><strong>Authors: </strong>Mohd Ruhul Ameen, Akif Islam</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.00352">https://arxiv.org/abs/2511.00352</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.00352">https://arxiv.org/pdf/2511.00352</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.00352]] Detecting AI-Generated Images via Diffusion Snap-Back Reconstruction: A Forensic Approach(https://arxiv.org/abs/2511.00352)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, interpretability, diffusion, generative</a></li>
<li><strong>Abstract: </strong>The rapid rise of generative diffusion models has made distinguishing authentic visual content from synthetic imagery increasingly challenging. Traditional deepfake detection methods, which rely on frequency or pixel-level artifacts, fail against modern text-to-image systems such as Stable Diffusion and DALL-E that produce photorealistic and artifact-free results. This paper introduces a diffusion-based forensic framework that leverages multi-strength image reconstruction dynamics, termed diffusion snap-back, to identify AI-generated images. By analysing how reconstruction metrics (LPIPS, SSIM, and PSNR) evolve across varying noise strengths, we extract interpretable manifold-based features that differentiate real and synthetic images. Evaluated on a balanced dataset of 4,000 images, our approach achieves 0.993 AUROC under cross-validation and remains robust to common distortions such as compression and noise. Despite using limited data and a single diffusion backbone (Stable Diffusion v1.5), the proposed method demonstrates strong generalization and interpretability, offering a foundation for scalable, model-agnostic synthetic media forensics.</li>
</ul>

<h3>Title: Transfer Learning for Onboard Cloud Segmentation in Thermal Earth Observation: From Landsat to a CubeSat Constellation</h3>
<ul>
<li><strong>Authors: </strong>Niklas Wölki, Lukas Kondmann, Christian Mollière, Martin Langer, Julia Gottfriedsen, Martin Werner</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.00357">https://arxiv.org/abs/2511.00357</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.00357">https://arxiv.org/pdf/2511.00357</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.00357]] Transfer Learning for Onboard Cloud Segmentation in Thermal Earth Observation: From Landsat to a CubeSat Constellation(https://arxiv.org/abs/2511.00357)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>Onboard cloud segmentation is a critical yet underexplored task in thermal Earth observation (EO), particularly for CubeSat missions constrained by limited hardware and spectral information. CubeSats often rely on a single thermal band and lack sufficient labeled data, making conventional cloud masking techniques infeasible. This work addresses these challenges by applying transfer learning to thermal cloud segmentation for the FOREST-2 CubeSat, using a UNet with a lightweight MobileNet encoder. We pretrain the model on the public Landsat-7 Cloud Cover Assessment Dataset and fine-tune it with a small set of mission-specific samples in a joint-training setup, improving the macro F1 from 0.850 to 0.877 over FOREST-2-only baselines. We convert the model to a TensorRT engine and demonstrate full-image inference in under 5 seconds on an NVIDIA Jetson Nano. These results show that leveraging public datasets and lightweight architectures can enable accurate, efficient thermal-only cloud masking on-orbit, supporting real-time decision-making in data-limited EO missions.</li>
</ul>

<h3>Title: Toward Unifying Group Fairness Evaluation from a Sparsity Perspective</h3>
<ul>
<li><strong>Authors: </strong>Zhecheng Sheng, Jiawei Zhang, Enmao Diao</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CY, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.00359">https://arxiv.org/abs/2511.00359</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.00359">https://arxiv.org/pdf/2511.00359</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.00359]] Toward Unifying Group Fairness Evaluation from a Sparsity Perspective(https://arxiv.org/abs/2511.00359)</code><input type="text"></li>
<li><strong>Keywords: </strong>fair</a></li>
<li><strong>Abstract: </strong>Ensuring algorithmic fairness remains a significant challenge in machine learning, particularly as models are increasingly applied across diverse domains. While numerous fairness criteria exist, they often lack generalizability across different machine learning problems. This paper examines the connections and differences among various sparsity measures in promoting fairness and proposes a unified sparsity-based framework for evaluating algorithmic fairness. The framework aligns with existing fairness criteria and demonstrates broad applicability to a wide range of machine learning tasks. We demonstrate the effectiveness of the proposed framework as an evaluation metric through extensive experiments on a variety of datasets and bias mitigation methods. This work provides a novel perspective to algorithmic fairness by framing it through the lens of sparsity and social equity, offering potential for broader impact on fairness research and applications.</li>
</ul>

<h3>Title: Mind the Gap: Missing Cyber Threat Coverage in NIDS Datasets for the Energy Sector</h3>
<ul>
<li><strong>Authors: </strong>Adrita Rahman Tory, Khondokar Fida Hasan, Md Saifur Rahman, Nickolaos Koroniotis, Mohammad Ali Moni</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.00360">https://arxiv.org/abs/2511.00360</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.00360">https://arxiv.org/pdf/2511.00360</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.00360]] Mind the Gap: Missing Cyber Threat Coverage in NIDS Datasets for the Energy Sector(https://arxiv.org/abs/2511.00360)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Network Intrusion Detection Systems (NIDS) developed us- ing publicly available datasets predominantly focus on enterprise environ- ments, raising concerns about their effectiveness for converged Informa- tion Technology (IT) and Operational Technology (OT) in energy infras- tructures. This study evaluates the representativeness of five widely used datasets: CIC-IDS2017, SWaT, WADI, Sherlock, and CIC-Modbus2023 against network-detectable MITRE ATT&CK techniques extracted from documented energy sector incidents. Using a structured five-step analyt- ical approach, this article successfully developed and performed a gap analysis that identified 94 network observable techniques from an initial pool of 274 ATT&CK techniques. Sherlock dataset exhibited the high- est mean coverage (0.56), followed closely by CIC-IDS2017 (0.55), while SWaT and WADI recorded the lowest scores (0.38). Combining CIC- IDS2017, Sherlock, and CIC-Modbus2023 achieved an aggregate coverage of 92%, highlighting their complementary strengths. The analysis identi- fies critical gaps, particularly in lateral movement and industrial protocol manipulation, providing a clear pathway for dataset enhancement and more robust NIDS evaluation in hybrid IT/OT energy environments.</li>
</ul>

<h3>Title: MalDataGen: A Modular Framework for Synthetic Tabular Data Generation in Malware Detection</h3>
<ul>
<li><strong>Authors: </strong>Kayua Oleques Paim, Angelo Gaspar Diniz Nogueira, Diego Kreutz, Weverton Cordeiro, Rodrigo Brandao Mansilha</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.00361">https://arxiv.org/abs/2511.00361</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.00361">https://arxiv.org/pdf/2511.00361</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.00361]] MalDataGen: A Modular Framework for Synthetic Tabular Data Generation in Malware Detection(https://arxiv.org/abs/2511.00361)</code><input type="text"></li>
<li><strong>Keywords: </strong>security</a></li>
<li><strong>Abstract: </strong>High-quality data scarcity hinders malware detection, limiting ML performance. We introduce MalDataGen, an open-source modular framework for generating high-fidelity synthetic tabular data using modular deep learning models (e.g., WGAN-GP, VQ-VAE). Evaluated via dual validation (TR-TS/TS-TR), seven classifiers, and utility metrics, MalDataGen outperforms benchmarks like SDV while preserving data utility. Its flexible design enables seamless integration into detection pipelines, offering a practical solution for cybersecurity applications.</li>
</ul>

<h3>Title: Oitijjo-3D: Generative AI Framework for Rapid 3D Heritage Reconstruction from Street View Imagery</h3>
<ul>
<li><strong>Authors: </strong>Momen Khandoker Ope, Akif Islam, Mohd Ruhul Ameen, Abu Saleh Musa Miah, Md Rashedul Islam, Jungpil Shin</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI, cs.GR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.00362">https://arxiv.org/abs/2511.00362</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.00362">https://arxiv.org/pdf/2511.00362</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.00362]] Oitijjo-3D: Generative AI Framework for Rapid 3D Heritage Reconstruction from Street View Imagery(https://arxiv.org/abs/2511.00362)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>Cultural heritage restoration in Bangladesh faces a dual challenge of limited resources and scarce technical expertise. Traditional 3D digitization methods, such as photogrammetry or LiDAR scanning, require expensive hardware, expert operators, and extensive on-site access, which are often infeasible in developing contexts. As a result, many of Bangladesh's architectural treasures, from the Paharpur Buddhist Monastery to Ahsan Manzil, remain vulnerable to decay and inaccessible in digital form. This paper introduces Oitijjo-3D, a cost-free generative AI framework that democratizes 3D cultural preservation. By using publicly available Google Street View imagery, Oitijjo-3D reconstructs faithful 3D models of heritage structures through a two-stage pipeline - multimodal visual reasoning with Gemini 2.5 Flash Image for structure-texture synthesis, and neural image-to-3D generation through Hexagen for geometry recovery. The system produces photorealistic, metrically coherent reconstructions in seconds, achieving significant speedups compared to conventional Structure-from-Motion pipelines, without requiring any specialized hardware or expert supervision. Experiments on landmarks such as Ahsan Manzil, Choto Sona Mosque, and Paharpur demonstrate that Oitijjo-3D preserves both visual and structural fidelity while drastically lowering economic and technical barriers. By turning open imagery into digital heritage, this work reframes preservation as a community-driven, AI-assisted act of cultural continuity for resource-limited nations.</li>
</ul>

<h3>Title: Fast Networks for High-Performance Distributed Trust</h3>
<ul>
<li><strong>Authors: </strong>Yicheng Liu, Rafail Ostrovsky, Scott Shenker, Sam Kumar</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.NI, cs.OS</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.00363">https://arxiv.org/abs/2511.00363</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.00363">https://arxiv.org/pdf/2511.00363</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.00363]] Fast Networks for High-Performance Distributed Trust(https://arxiv.org/abs/2511.00363)</code><input type="text"></li>
<li><strong>Keywords: </strong>secure</a></li>
<li><strong>Abstract: </strong>Organizations increasingly need to collaborate by performing a computation on their combined dataset, while keeping their data hidden from each other. Certain kinds of collaboration, such as collaborative data analytics and AI, require a level of performance beyond what current cryptographic techniques for distributed trust can provide. This is because the organizations run software in different trust domains, which can require them to communicate over WANs or the public Internet. In this paper, we explore how to instead run such applications using fast datacenter-type LANs. We show that, by carefully redesigning distributed trust frameworks for LANs, we can achieve up to order-of-magnitude better performance than naïvely using a LAN. Then, we develop deployment models for Distributed But Proximate Trust (DBPT) that allow parties to use a LAN while remaining physically and logically distinct. These developments make secure collaborative data analytics and AI significantly more practical and set new research directions for developing systems and cryptographic theory for high-performance distributed trust.</li>
</ul>

<h3>Title: Balancing Interpretability and Performance in Motor Imagery EEG Classification: A Comparative Study of ANFIS-FBCSP-PSO and EEGNet</h3>
<ul>
<li><strong>Authors: </strong>Farjana Aktar, Mohd Ruhul Ameen, Akif Islam, Md Ekramul Hamid</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.NE</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.00369">https://arxiv.org/abs/2511.00369</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.00369">https://arxiv.org/pdf/2511.00369</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.00369]] Balancing Interpretability and Performance in Motor Imagery EEG Classification: A Comparative Study of ANFIS-FBCSP-PSO and EEGNet(https://arxiv.org/abs/2511.00369)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, extraction, interpretability, transformer</a></li>
<li><strong>Abstract: </strong>Achieving both accurate and interpretable classification of motor imagery EEG remains a key challenge in brain computer interface (BCI) research. This paper compares a transparent fuzzy reasoning approach (ANFIS-FBCSP-PSO) with a deep learning benchmark (EEGNet) using the BCI Competition IV-2a dataset. The ANFIS pipeline combines filter bank common spatial pattern feature extraction with fuzzy IF-THEN rules optimized via particle swarm optimization, while EEGNet learns hierarchical spatial temporal representations directly from raw EEG data. In within-subject experiments, the fuzzy neural model performed better (68.58 percent +/- 13.76 percent accuracy, kappa = 58.04 percent +/- 18.43), while in cross-subject (LOSO) tests, the deep model exhibited stronger generalization (68.20 percent +/- 12.13 percent accuracy, kappa = 57.33 percent +/- 16.22). The study provides practical guidance for selecting MI-BCI systems according to design goals: interpretability or robustness across users. Future investigations into transformer based and hybrid neuro symbolic frameworks are expected to advance transparent EEG decoding.</li>
</ul>

<h3>Title: PolyRecommender: A Multimodal Recommendation System for Polymer Discovery</h3>
<ul>
<li><strong>Authors: </strong>Xin Wang, Yunhao Xiao, Rui Qiao</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.IR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.00375">https://arxiv.org/abs/2511.00375</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.00375">https://arxiv.org/pdf/2511.00375</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.00375]] PolyRecommender: A Multimodal Recommendation System for Polymer Discovery(https://arxiv.org/abs/2511.00375)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>We introduce PolyRecommender, a multimodal discovery framework that integrates chemical language representations from PolyBERT with molecular graph-based representations from a graph encoder. The system first retrieves candidate polymers using language-based similarity and then ranks them using fused multimodal embeddings according to multiple target properties. By leveraging the complementary knowledge encoded in both modalities, PolyRecommender enables efficient retrieval and robust ranking across related polymer properties. Our work establishes a generalizable multimodal paradigm, advancing AI-guided design for the discovery of next-generation polymers.</li>
</ul>

<h3>Title: Rethinking Facial Expression Recognition in the Era of Multimodal Large Language Models: Benchmark, Datasets, and Beyond</h3>
<ul>
<li><strong>Authors: </strong>Fan Zhang, Haoxuan Li, Shengju Qian, Xin Wang, Zheng Lian, Hao Wu, Zhihong Zhu, Yuan Gao, Qiankun Li, Yefeng Zheng, Zhouchen Lin, Pheng-Ann Heng</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.00389">https://arxiv.org/abs/2511.00389</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.00389">https://arxiv.org/pdf/2511.00389</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.00389]] Rethinking Facial Expression Recognition in the Era of Multimodal Large Language Models: Benchmark, Datasets, and Beyond(https://arxiv.org/abs/2511.00389)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability, large language model</a></li>
<li><strong>Abstract: </strong>Multimodal Large Language Models (MLLMs) have revolutionized numerous research fields, including computer vision and affective computing. As a pivotal challenge in this interdisciplinary domain, facial expression recognition (FER) has evolved from separate, domain-specific models to more unified approaches. One promising avenue to unify FER tasks is converting conventional FER datasets into visual question-answering (VQA) formats, enabling the direct application of powerful generalist MLLMs for inference. However, despite the success of cutting-edge MLLMs in various tasks, their performance on FER tasks remains largely unexplored. To address this gap, we provide FERBench, a systematic benchmark that incorporates 20 state-of-the-art MLLMs across four widely used FER datasets. Our results reveal that, while MLLMs exhibit good classification performance, they still face significant limitations in reasoning and interpretability. To this end, we introduce post-training strategies aimed at enhancing the facial expression reasoning capabilities of MLLMs. Specifically, we curate two high-quality and large-scale datasets: UniFER-CoT-230K for cold-start initialization and UniFER-RLVR-360K for reinforcement learning with verifiable rewards (RLVR), respectively. Building upon them, we develop a unified and interpretable FER foundation model termed UniFER-7B, which outperforms many open-sourced and closed-source generalist MLLMs (e.g., Gemini-2.5-Pro and Qwen2.5-VL-72B).</li>
</ul>

<h3>Title: UME-R1: Exploring Reasoning-Driven Generative Multimodal Embeddings</h3>
<ul>
<li><strong>Authors: </strong>Zhibin Lan, Liqiang Niu, Fandong Meng, Jie Zhou, Jinsong Su</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.00405">https://arxiv.org/abs/2511.00405</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.00405">https://arxiv.org/pdf/2511.00405</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.00405]] UME-R1: Exploring Reasoning-Driven Generative Multimodal Embeddings(https://arxiv.org/abs/2511.00405)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative, large language model</a></li>
<li><strong>Abstract: </strong>The remarkable success of multimodal large language models (MLLMs) has driven advances in multimodal embeddings, yet existing models remain inherently discriminative, limiting their ability to benefit from reasoning-driven generation paradigm. In this work, we pioneer the exploration of generative embeddings, unifying embedding tasks within a generative paradigm. We propose UME-R1, a universal multimodal embedding framework consisting of a two-stage training strategy: a cold-start supervised fine-tuning equips the model with reasoning capabilities and enables it to generate both discriminative and generative embeddings; a subsequent reinforcement learning enhances reasoning and further optimizes generative embedding quality. This pioneering work reveals four key insights: 1) generative embeddings unlock substantial performance gains over conventional discriminative embeddings by leveraging the powerful generative reasoning capabilities of MLLMs; 2) discriminative and generative embeddings are complementary, whose combined oracle performance far exceeding that of either alone; 3) RL can effectively enhance generative embeddings, establishing a scalable optimization paradigm.; 4) repeated sampling at inference boosts downstream task coverage (pass@k), highlighting the inference-time scalability potential of generative embeddings. Evaluated on the MMEB-V2 benchmark across 78 tasks spanning video, image, and visual documents, UME-R1 significantly outperforms conventional discriminative embedding models and offers a foundation for more interpretable, reasoning-driven generative multimodal embeddings. Our code, models, and datasets will be publicly available at this https URL.</li>
</ul>

<h3>Title: Penetrating the Hostile: Detecting DeFi Protocol Exploits through Cross-Contract Analysis</h3>
<ul>
<li><strong>Authors: </strong>Xiaoqi Li, Wenkai Li, Zhiquan Liu, Yuqing Zhang, Yingjie Mao</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.00408">https://arxiv.org/abs/2511.00408</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.00408">https://arxiv.org/pdf/2511.00408</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.00408]] Penetrating the Hostile: Detecting DeFi Protocol Exploits through Cross-Contract Analysis(https://arxiv.org/abs/2511.00408)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack</a></li>
<li><strong>Abstract: </strong>Decentralized finance (DeFi) protocols are crypto projects developed on the blockchain to manage digital assets. Attacks on DeFi have been frequent and have resulted in losses exceeding $80 billion. Current tools detect and locate possible vulnerabilities in contracts by analyzing the state changes that may occur during malicious events. However, this victim-only approaches seldom possess the capability to cover the attacker's interaction intention logic. Furthermore, only a minuscule percentage of DeFi protocols experience attacks in real-world scenarios, which poses a significant challenge for these detection tools to demonstrate practical effectiveness. In this paper, we propose DeFiTail, the first framework that utilizes deep learning technology for access control and flash loan exploit detection. Through feeding the cross-contract static data flow, DeFiTail automatically learns the attack logic in real-world malicious events that occur on DeFi protocols, capturing the threat patterns between attacker and victim contracts. Since the DeFi protocol events involve interactions with multi-account transactions, the execution path with external and internal transactions requires to be unified. Moreover, to mitigate the impact of mistakes in Control Flow Graph (CFG) connections, DeFiTail validates the data path by employing the symbolic execution stack. Furthermore, we feed the data paths through our model to achieve the inspection of DeFi protocols. Comparative experiment results indicate that DeFiTail achieves the highest accuracy, with 98.39% in access control and 97.43% in flash loan exploits. DeFiTail also demonstrates an enhanced capability to detect malicious contracts, identifying 86.67% accuracy from the CVE dataset.</li>
</ul>

<h3>Title: Enhancing Adversarial Transferability by Balancing Exploration and Exploitation with Gradient-Guided Sampling</h3>
<ul>
<li><strong>Authors: </strong>Zenghao Niu, Weicheng Xie, Siyang Song, Zitong Yu, Feng Liu, Linlin Shen</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.00411">https://arxiv.org/abs/2511.00411</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.00411">https://arxiv.org/pdf/2511.00411</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.00411]] Enhancing Adversarial Transferability by Balancing Exploration and Exploitation with Gradient-Guided Sampling(https://arxiv.org/abs/2511.00411)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack, robust, large language model</a></li>
<li><strong>Abstract: </strong>Adversarial attacks present a critical challenge to deep neural networks' robustness, particularly in transfer scenarios across different model architectures. However, the transferability of adversarial attacks faces a fundamental dilemma between Exploitation (maximizing attack potency) and Exploration (enhancing cross-model generalization). Traditional momentum-based methods over-prioritize Exploitation, i.e., higher loss maxima for attack potency but weakened generalization (narrow loss surface). Conversely, recent methods with inner-iteration sampling over-prioritize Exploration, i.e., flatter loss surfaces for cross-model generalization but weakened attack potency (suboptimal local maxima). To resolve this dilemma, we propose a simple yet effective Gradient-Guided Sampling (GGS), which harmonizes both objectives through guiding sampling along the gradient ascent direction to improve both sampling efficiency and stability. Specifically, based on MI-FGSM, GGS introduces inner-iteration random sampling and guides the sampling direction using the gradient from the previous inner-iteration (the sampling's magnitude is determined by a random distribution). This mechanism encourages adversarial examples to reside in balanced regions with both flatness for cross-model generalization and higher local maxima for strong attack potency. Comprehensive experiments across multiple DNN architectures and multimodal large language models (MLLMs) demonstrate the superiority of our method over state-of-the-art transfer attacks. Code is made available at this https URL.</li>
</ul>

<h3>Title: Zero-Knowledge Extensions on Solana: A Theory of ZK Architecture</h3>
<ul>
<li><strong>Authors: </strong>Jotaro Yano</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.00415">https://arxiv.org/abs/2511.00415</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.00415">https://arxiv.org/pdf/2511.00415</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.00415]] Zero-Knowledge Extensions on Solana: A Theory of ZK Architecture(https://arxiv.org/abs/2511.00415)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy</a></li>
<li><strong>Abstract: </strong>This paper reconstructs zero-knowledge extensions on Solana as an architecture theory. Drawing on the existing ecosystem and on the author's prior papers and implementations as reference material, we propose a two-axis model that normalizes zero-knowledge (ZK) use by purpose (scalability vs. privacy) and by placement (on-chain vs. off-chain). On this grid we define five layer-crossing invariants: origin authenticity, replay-safety, finality alignment, parameter binding, and private consumption, which serve as a common vocabulary for reasoning about correctness across modules and chains. The framework covers the Solana Foundation's three pillars (ZK Compression, Confidential Transfer, light clients/bridges) together with surrounding components (Light Protocol/Helius, Succinct SP1, RISC Zero, Wormhole, Tinydancer, Arcium). From the theory we derive two design abstractions - Proof-Carrying Message (PCM) and a Verifier Router Interface - and a cross-chain counterpart, Proof-Carrying Interchain Message (PCIM), indicating concrete avenues for extending the three pillars.</li>
</ul>

<h3>Title: PADBen: A Comprehensive Benchmark for Evaluating AI Text Detectors Against Paraphrase Attacks</h3>
<ul>
<li><strong>Authors: </strong>Yiwei Zha, Rui Min, Shanu Sushmita</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.00416">https://arxiv.org/abs/2511.00416</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.00416">https://arxiv.org/pdf/2511.00416</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.00416]] PADBen: A Comprehensive Benchmark for Evaluating AI Text Detectors Against Paraphrase Attacks(https://arxiv.org/abs/2511.00416)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack, robust</a></li>
<li><strong>Abstract: </strong>While AI-generated text (AIGT) detectors achieve over 90\% accuracy on direct LLM outputs, they fail catastrophically against iteratively-paraphrased content. We investigate why iteratively-paraphrased text -- itself AI-generated -- evades detection systems designed for AIGT identification. Through intrinsic mechanism analysis, we reveal that iterative paraphrasing creates an intermediate laundering region characterized by semantic displacement with preserved generation patterns, which brings up two attack categories: paraphrasing human-authored text (authorship obfuscation) and paraphrasing LLM-generated text (plagiarism evasion). To address these vulnerabilities, we introduce PADBen, the first benchmark systematically evaluating detector robustness against both paraphrase attack scenarios. PADBen comprises a five-type text taxonomy capturing the full trajectory from original content to deeply laundered text, and five progressive detection tasks across sentence-pair and single-sentence challenges. We evaluate 11 state-of-the-art detectors, revealing critical asymmetry: detectors successfully identify the plagiarism evasion problem but fail for the case of authorship obfuscation. Our findings demonstrate that current detection approaches cannot effectively handle the intermediate laundering region, necessitating fundamental advances in detection architectures beyond existing semantic and stylistic discrimination methods. For detailed code implementation, please see this https URL.</li>
</ul>

<h3>Title: Structure-Preserving Physics-Informed Neural Network for the Korteweg--de Vries (KdV) Equation</h3>
<ul>
<li><strong>Authors: </strong>Victory Obieke, Emmanuel Oguadimma</a></li>
<li><strong>Subjects: </strong>cs.LG, math-ph, nlin.PS, physics.flu-dyn</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.00418">https://arxiv.org/abs/2511.00418</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.00418">https://arxiv.org/pdf/2511.00418</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.00418]] Structure-Preserving Physics-Informed Neural Network for the Korteweg--de Vries (KdV) Equation(https://arxiv.org/abs/2511.00418)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Physics-Informed Neural Networks (PINNs) offer a flexible framework for solving nonlinear partial differential equations (PDEs), yet conventional implementations often fail to preserve key physical invariants during long-term integration. This paper introduces a \emph{structure-preserving PINN} framework for the nonlinear Korteweg--de Vries (KdV) equation, a prototypical model for nonlinear and dispersive wave propagation. The proposed method embeds the conservation of mass and Hamiltonian energy directly into the loss function, ensuring physically consistent and energy-stable evolution throughout training and prediction. Unlike standard \texttt{tanh}-based PINNs~\cite{raissi2019pinn,wang2022modifiedpinn}, our approach employs sinusoidal activation functions that enhance spectral expressiveness and accurately capture the oscillatory and dispersive nature of KdV solitons. Through representative case studies -- including single-soliton propagation (shape-preserving translation), two-soliton interaction (elastic collision with phase shift), and cosine-pulse initialization (nonlinear dispersive breakup) -- the model successfully reproduces hallmark behaviors of KdV dynamics while maintaining conserved invariants. Ablation studies demonstrate that combining invariant-constrained optimization with sinusoidal feature mappings accelerates convergence, improves long-term stability, and mitigates drift without multi-stage pretraining. These results highlight that computationally efficient, invariant-aware regularization coupled with sinusoidal representations yields robust, energy-consistent PINNs for Hamiltonian partial differential equations such as the KdV equation.</li>
</ul>

<h3>Title: LGCA: Enhancing Semantic Representation via Progressive Expansion</h3>
<ul>
<li><strong>Authors: </strong>Thanh Hieu Cao, Trung Khang Tran, Gia Thinh Pham, Tuong Nghiem Diep, Thanh Binh Nguyen</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.00419">https://arxiv.org/abs/2511.00419</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.00419">https://arxiv.org/pdf/2511.00419</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.00419]] LGCA: Enhancing Semantic Representation via Progressive Expansion(https://arxiv.org/abs/2511.00419)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Recent advancements in large-scale pretraining in natural language processing have enabled pretrained vision-language models such as CLIP to effectively align images and text, significantly improving performance in zero-shot image classification tasks. Subsequent studies have further demonstrated that cropping images into smaller regions and using large language models to generate multiple descriptions for each caption can further enhance model performance. However, due to the inherent sensitivity of CLIP, random image crops can introduce misinformation and bias, as many images share similar features at small scales. To address this issue, we propose Localized-Globalized Cross-Alignment (LGCA), a framework that first captures the local features of an image and then repeatedly selects the most salient regions and expands them. The similarity score is designed to incorporate both the original and expanded images, enabling the model to capture both local and global features while minimizing misinformation. Additionally, we provide a theoretical analysis demonstrating that the time complexity of LGCA remains the same as that of the original model prior to the repeated expansion process, highlighting its efficiency and scalability. Extensive experiments demonstrate that our method substantially improves zero-shot performance across diverse datasets, outperforming state-of-the-art baselines.</li>
</ul>

<h3>Title: MedRECT: A Medical Reasoning Benchmark for Error Correction in Clinical Texts</h3>
<ul>
<li><strong>Authors: </strong>Naoto Iwase, Hiroki Okuyama, Junichiro Iwasawa</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.00421">https://arxiv.org/abs/2511.00421</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.00421">https://arxiv.org/pdf/2511.00421</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.00421]] MedRECT: A Medical Reasoning Benchmark for Error Correction in Clinical Texts(https://arxiv.org/abs/2511.00421)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction, large language model</a></li>
<li><strong>Abstract: </strong>Large language models (LLMs) show increasing promise in medical applications, but their ability to detect and correct errors in clinical texts -- a prerequisite for safe deployment -- remains under-evaluated, particularly beyond English. We introduce MedRECT, a cross-lingual benchmark (Japanese/English) that formulates medical error handling as three subtasks: error detection, error localization (sentence extraction), and error correction. MedRECT is built with a scalable, automated pipeline from the Japanese Medical Licensing Examinations (JMLE) and a curated English counterpart, yielding MedRECT-ja (663 texts) and MedRECT-en (458 texts) with comparable error/no-error balance. We evaluate 9 contemporary LLMs spanning proprietary, open-weight, and reasoning families. Key findings: (i) reasoning models substantially outperform standard architectures, with up to 13.5% relative improvement in error detection and 51.0% in sentence extraction; (ii) cross-lingual evaluation reveals 5-10% performance gaps from English to Japanese, with smaller disparities for reasoning models; (iii) targeted LoRA fine-tuning yields asymmetric improvements in error correction performance (Japanese: +0.078, English: +0.168) while preserving reasoning capabilities; and (iv) our fine-tuned model exceeds human expert performance on structured medical error correction tasks. To our knowledge, MedRECT is the first comprehensive cross-lingual benchmark for medical error correction, providing a reproducible framework and resources for developing safer medical LLMs across languages.</li>
</ul>

<h3>Title: Leveraging Hierarchical Image-Text Misalignment for Universal Fake Image Detection</h3>
<ul>
<li><strong>Authors: </strong>Daichi Zhang, Tong Zhang, Jianmin Bao, Shiming Ge, Sabine Süsstrunk</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.00427">https://arxiv.org/abs/2511.00427</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.00427">https://arxiv.org/pdf/2511.00427</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.00427]] Leveraging Hierarchical Image-Text Misalignment for Universal Fake Image Detection(https://arxiv.org/abs/2511.00427)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, generative</a></li>
<li><strong>Abstract: </strong>With the rapid development of generative models, detecting generated fake images to prevent their malicious use has become a critical issue recently. Existing methods frame this challenge as a naive binary image classification task. However, such methods focus only on visual clues, yielding trained detectors susceptible to overfitting specific image patterns and incapable of generalizing to unseen models. In this paper, we address this issue from a multi-modal perspective and find that fake images cannot be properly aligned with corresponding captions compared to real images. Upon this observation, we propose a simple yet effective detector termed ITEM by leveraging the image-text misalignment in a joint visual-language space as discriminative clues. Specifically, we first measure the misalignment of the images and captions in pre-trained CLIP's space, and then tune a MLP head to perform the usual detection task. Furthermore, we propose a hierarchical misalignment scheme that first focuses on the whole image and then each semantic object described in the caption, which can explore both global and fine-grained local semantic misalignment as clues. Extensive experiments demonstrate the superiority of our method against other state-of-the-art competitors with impressive generalization and robustness on various recent generative models.</li>
</ul>

<h3>Title: Enhancing Frequency Forgery Clues for Diffusion-Generated Image Detection</h3>
<ul>
<li><strong>Authors: </strong>Daichi Zhang, Tong Zhang, Shiming Ge, Sabine Süsstrunk</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.00429">https://arxiv.org/abs/2511.00429</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.00429">https://arxiv.org/pdf/2511.00429</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.00429]] Enhancing Frequency Forgery Clues for Diffusion-Generated Image Detection(https://arxiv.org/abs/2511.00429)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, diffusion</a></li>
<li><strong>Abstract: </strong>Diffusion models have achieved remarkable success in image synthesis, but the generated high-quality images raise concerns about potential malicious use. Existing detectors often struggle to capture discriminative clues across different models and settings, limiting their generalization to unseen diffusion models and robustness to various perturbations. To address this issue, we observe that diffusion-generated images exhibit progressively larger differences from natural real images across low- to high-frequency bands. Based on this insight, we propose a simple yet effective representation by enhancing the Frequency Forgery Clue (F^2C) across all frequency bands. Specifically, we introduce a frequency-selective function which serves as a weighted filter to the Fourier spectrum, suppressing less discriminative bands while enhancing more informative ones. This approach, grounded in a comprehensive analysis of frequency-based differences between natural real and diffusion-generated images, enables general detection of images from unseen diffusion models and provides robust resilience to various perturbations. Extensive experiments on various diffusion-generated image datasets demonstrate that our method outperforms state-of-the-art detectors with superior generalization and robustness.</li>
</ul>

<h3>Title: G2: Guided Generation for Enhanced Output Diversity in LLMs</h3>
<ul>
<li><strong>Authors: </strong>Zhiwen Ruan, Yixia Li, Yefeng Liu, Yun Chen, Weihua Luo, Peng Li, Yang Liu, Guanhua Chen</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.00432">https://arxiv.org/abs/2511.00432</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.00432">https://arxiv.org/pdf/2511.00432</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.00432]] G2: Guided Generation for Enhanced Output Diversity in LLMs(https://arxiv.org/abs/2511.00432)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large Language Models (LLMs) have demonstrated exceptional performance across diverse natural language processing tasks. However, these models exhibit a critical limitation in output diversity, often generating highly similar content across multiple attempts. This limitation significantly affects tasks requiring diverse outputs, from creative writing to reasoning. Existing solutions, like temperature scaling, enhance diversity by modifying probability distributions but compromise output quality. We propose Guide-to-Generation (G2), a training-free plug-and-play method that enhances output diversity while preserving generation quality. G2 employs a base generator alongside dual Guides, which guide the generation process through decoding-based interventions to encourage more diverse outputs conditioned on the original query. Comprehensive experiments demonstrate that G2 effectively improves output diversity while maintaining an optimal balance between diversity and quality.</li>
</ul>

<h3>Title: Region-Aware Reconstruction Strategy for Pre-training fMRI Foundation Model</h3>
<ul>
<li><strong>Authors: </strong>Ruthwik Reddy Doodipala, Pankaj Pandey, Carolina Torres Rojas, Manob Jyoti Saikia, Ranganatha Sitaram</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.00443">https://arxiv.org/abs/2511.00443</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.00443">https://arxiv.org/pdf/2511.00443</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.00443]] Region-Aware Reconstruction Strategy for Pre-training fMRI Foundation Model(https://arxiv.org/abs/2511.00443)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, interpretability</a></li>
<li><strong>Abstract: </strong>The emergence of foundation models in neuroimaging is driven by the increasing availability of large-scale and heterogeneous brain imaging datasets. Recent advances in self-supervised learning, particularly reconstruction-based objectives, have demonstrated strong potential for pretraining models that generalize effectively across diverse downstream functional MRI (fMRI) tasks. In this study, we explore region-aware reconstruction strategies for a foundation model in resting-state fMRI, moving beyond approaches that rely on random region masking. Specifically, we introduce an ROI-guided masking strategy using the Automated Anatomical Labelling Atlas (AAL3), applied directly to full 4D fMRI volumes to selectively mask semantically coherent brain regions during self-supervised pretraining. Using the ADHD-200 dataset comprising 973 subjects with resting-state fMRI scans, we show that our method achieves a 4.23% improvement in classification accuracy for distinguishing healthy controls from individuals diagnosed with ADHD, compared to conventional random masking. Region-level attribution analysis reveals that brain volumes within the limbic region and cerebellum contribute most significantly to reconstruction fidelity and model representation. Our results demonstrate that masking anatomical regions during model pretraining not only enhances interpretability but also yields more robust and discriminative representations. In future work, we plan to extend this approach by evaluating it on additional neuroimaging datasets, and developing new loss functions explicitly derived from region-aware reconstruction objectives. These directions aim to further improve the robustness and interpretability of foundation models for functional neuroimaging.</li>
</ul>

<h3>Title: ToxicTextCLIP: Text-Based Poisoning and Backdoor Attacks on CLIP Pre-training</h3>
<ul>
<li><strong>Authors: </strong>Xin Yao, Haiyang Zhao, Yimin Chen, Jiawei Guo, Kecheng Huang, Ming Zhao</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.CR, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.00446">https://arxiv.org/abs/2511.00446</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.00446">https://arxiv.org/pdf/2511.00446</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.00446]] ToxicTextCLIP: Text-Based Poisoning and Backdoor Attacks on CLIP Pre-training(https://arxiv.org/abs/2511.00446)</code><input type="text"></li>
<li><strong>Keywords: </strong>defense, attack</a></li>
<li><strong>Abstract: </strong>The Contrastive Language-Image Pretraining (CLIP) model has significantly advanced vision-language modeling by aligning image-text pairs from large-scale web data through self-supervised contrastive learning. Yet, its reliance on uncurated Internet-sourced data exposes it to data poisoning and backdoor risks. While existing studies primarily investigate image-based attacks, the text modality, which is equally central to CLIP's training, remains underexplored. In this work, we introduce ToxicTextCLIP, a framework for generating high-quality adversarial texts that target CLIP during the pre-training phase. The framework addresses two key challenges: semantic misalignment caused by background inconsistency with the target class, and the scarcity of background-consistent texts. To this end, ToxicTextCLIP iteratively applies: 1) a background-aware selector that prioritizes texts with background content aligned to the target class, and 2) a background-driven augmenter that generates semantically coherent and diverse poisoned samples. Extensive experiments on classification and retrieval tasks show that ToxicTextCLIP achieves up to 95.83% poisoning success and 98.68% backdoor Hit@1, while bypassing RoCLIP, CleanCLIP and SafeCLIP defenses. The source code can be accessed via this https URL.</li>
</ul>

<h3>Title: DRIP: Defending Prompt Injection via De-instruction Training and Residual Fusion Model Architecture</h3>
<ul>
<li><strong>Authors: </strong>Ruofan Liu, Yun Lin, Jin Song Dong</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.00447">https://arxiv.org/abs/2511.00447</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.00447">https://arxiv.org/pdf/2511.00447</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.00447]] DRIP: Defending Prompt Injection via De-instruction Training and Residual Fusion Model Architecture(https://arxiv.org/abs/2511.00447)</code><input type="text"></li>
<li><strong>Keywords: </strong>defense, attack, robust, large language model</a></li>
<li><strong>Abstract: </strong>Large language models (LLMs) have demonstrated impressive instruction-following capabilities. However, these capabilities also expose models to prompt injection attacks, where maliciously crafted inputs overwrite or distract from the intended instructions. A core vulnerability lies in the model's lack of semantic role understanding: it cannot distinguish directive intent from descriptive content, leading it to execute instruction-like phrases embedded in data. We propose DRIP, a training-time defense grounded in a semantic modeling perspective, which enforces robust separation between instruction and data semantics without sacrificing utility. DRIP introduces two lightweight yet complementary mechanisms: (1) a token-wise de-instruction shift that performs semantic disentanglement, weakening directive semantics in data tokens while preserving content meaning; and (2) a residual fusion pathway that provides a persistent semantic anchor, reinforcing the influence of the true top-level instruction during generation. Experimental results on LLaMA-8B and Mistral-7B across three prompt injection benchmarks (SEP, AlpacaFarm, and InjecAgent) demonstrate that DRIP outperforms state-of-the-art defenses, including StruQ, SecAlign, ISE, and PFT, improving role separation by 49%, and reducing attack success rate by 66% for adaptive attacks. Meanwhile, DRIP's utility is on par with the undefended model across AlpacaEval, IFEval, and MT-Bench. Our findings underscore the power of lightweight representation edits and role-aware supervision in securing LLMs against adaptive prompt injection.</li>
</ul>

<h3>Title: Proactive DDoS Detection and Mitigation in Decentralized Software-Defined Networking via Port-Level Monitoring and Zero-Training Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Mohammed N. Swileh, Shengli Zhang</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.00460">https://arxiv.org/abs/2511.00460</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.00460">https://arxiv.org/pdf/2511.00460</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.00460]] Proactive DDoS Detection and Mitigation in Decentralized Software-Defined Networking via Port-Level Monitoring and Zero-Training Large Language Models(https://arxiv.org/abs/2511.00460)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, defense, attack, large language model</a></li>
<li><strong>Abstract: </strong>Centralized Software-Defined Networking (cSDN) offers flexible and programmable control of networks but suffers from scalability and reliability issues due to its reliance on centralized controllers. Decentralized SDN (dSDN) alleviates these concerns by distributing control across multiple local controllers, yet this architecture remains highly vulnerable to Distributed Denial-of-Service (DDoS) attacks. In this paper, we propose a novel detection and mitigation framework tailored for dSDN environments. The framework leverages lightweight port-level statistics combined with prompt engineering and in-context learning, enabling the DeepSeek-v3 Large Language Model (LLM) to classify traffic as benign or malicious without requiring fine-tuning or retraining. Once an anomaly is detected, mitigation is enforced directly at the attacker's port, ensuring that malicious traffic is blocked at their origin while normal traffic remains unaffected. An automatic recovery mechanism restores normal operation after the attack inactivity, ensuring both security and availability. Experimental evaluation under diverse DDoS attack scenarios demonstrates that the proposed approach achieves near-perfect detection, with 99.99% accuracy, 99.97% precision, 100% recall, 99.98% F1-score, and an AUC of 1.0. These results highlight the effectiveness of combining distributed monitoring with zero-training LLM inference, providing a proactive and scalable defense mechanism for securing dSDN infrastructures against DDoS threats.</li>
</ul>

<h3>Title: Deep Learning Approach to Anomaly Detection in Enterprise ETL Processes with Autoencoders</h3>
<ul>
<li><strong>Authors: </strong>Xin Chen, Saili Uday Gadgil, Kangning Gao, Yi Hu, Cong Nie</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.00462">https://arxiv.org/abs/2511.00462</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.00462">https://arxiv.org/pdf/2511.00462</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.00462]] Deep Learning Approach to Anomaly Detection in Enterprise ETL Processes with Autoencoders(https://arxiv.org/abs/2511.00462)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>An anomaly detection method based on deep autoencoders is proposed to address anomalies that often occur in enterprise-level ETL data streams. The study first analyzes multiple types of anomalies in ETL processes, including delays, missing values, duplicate loading, and sudden abnormal changes, and applies data standardization and feature modeling to ensure stable and usable inputs. In the method design, the encoder-decoder structure compresses high-dimensional inputs into latent representations and reconstructs them, while reconstruction error is used to measure anomaly levels. Regularization constraints are introduced in the latent space to enhance feature sparsity and distribution learning, thereby improving robustness in complex data streams. Systematic analyses under different hyperparameter settings, environmental changes, and data characteristics show that the proposed method achieves superior performance in AUC, ACC, Precision, and Recall. The results demonstrate that the deep autoencoder-based detection mechanism can effectively capture latent distribution patterns in enterprise-level ETL data streams and accurately identify diverse anomalies, providing reliable support for enterprise data processing and intelligent analysis.</li>
</ul>

<h3>Title: HumanCrafter: Synergizing Generalizable Human Reconstruction and Semantic 3D Segmentation</h3>
<ul>
<li><strong>Authors: </strong>Panwang Pan, Tingting Shen, Chenxin Li, Yunlong Lin, Kairun Wen, Jingjing Zhao, Yixuan Yuan</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.00468">https://arxiv.org/abs/2511.00468</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.00468">https://arxiv.org/pdf/2511.00468</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.00468]] HumanCrafter: Synergizing Generalizable Human Reconstruction and Semantic 3D Segmentation(https://arxiv.org/abs/2511.00468)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative, segmentation</a></li>
<li><strong>Abstract: </strong>Recent advances in generative models have achieved high-fidelity in 3D human reconstruction, yet their utility for specific tasks (e.g., human 3D segmentation) remains constrained. We propose HumanCrafter, a unified framework that enables the joint modeling of appearance and human-part semantics from a single image in a feed-forward manner. Specifically, we integrate human geometric priors in the reconstruction stage and self-supervised semantic priors in the segmentation stage. To address labeled 3D human datasets scarcity, we further develop an interactive annotation procedure for generating high-quality data-label pairs. Our pixel-aligned aggregation enables cross-task synergy, while the multi-task objective simultaneously optimizes texture modeling fidelity and semantic consistency. Extensive experiments demonstrate that HumanCrafter surpasses existing state-of-the-art methods in both 3D human-part segmentation and 3D human reconstruction from a single image.</li>
</ul>

<h3>Title: Why Federated Optimization Fails to Achieve Perfect Fitting? A Theoretical Perspective on Client-Side Optima</h3>
<ul>
<li><strong>Authors: </strong>Zhongxiang Lei, Qi Yang, Ping Qiu, Gang Zhang, Yuanchi Ma, Jinyan Liu</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.00469">https://arxiv.org/abs/2511.00469</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.00469">https://arxiv.org/pdf/2511.00469</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.00469]] Why Federated Optimization Fails to Achieve Perfect Fitting? A Theoretical Perspective on Client-Side Optima(https://arxiv.org/abs/2511.00469)</code><input type="text"></li>
<li><strong>Keywords: </strong>federate</a></li>
<li><strong>Abstract: </strong>Federated optimization is a constrained form of distributed optimization that enables training a global model without directly sharing client data. Although existing algorithms can guarantee convergence in theory and often achieve stable training in practice, the reasons behind performance degradation under data heterogeneity remain unclear. To address this gap, the main contribution of this paper is to provide a theoretical perspective that explains why such degradation occurs. We introduce the assumption that heterogeneous client data lead to distinct local optima, and show that this assumption implies two key consequences: 1) the distance among clients' local optima raises the lower bound of the global objective, making perfect fitting of all client data impossible; and 2) in the final training stage, the global model oscillates within a region instead of converging to a single optimum, limiting its ability to fully fit the data. These results provide a principled explanation for performance degradation in non-iid settings, which we further validate through experiments across multiple tasks and neural network architectures. The framework used in this paper is open-sourced at: this https URL.</li>
</ul>

<h3>Title: Longitudinal Vestibular Schwannoma Dataset with Consensus-based Human-in-the-loop Annotations</h3>
<ul>
<li><strong>Authors: </strong>Navodini Wijethilake, Marina Ivory, Oscar MacCormac, Siddhant Kumar, Aaron Kujawa, Lorena Garcia-Foncillas Macias, Rebecca Burger, Amanda Hitchings, Suki Thomson, Sinan Barazi, Eleni Maratos, Rupert Obholzer, Dan Jiang, Fiona McClenaghan, Kazumi Chia, Omar Al-Salihi, Nick Thomas, Steve Connor, Tom Vercauteren, Jonathan Shapey</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.00472">https://arxiv.org/abs/2511.00472</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.00472">https://arxiv.org/pdf/2511.00472</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.00472]] Longitudinal Vestibular Schwannoma Dataset with Consensus-based Human-in-the-loop Annotations(https://arxiv.org/abs/2511.00472)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, segmentation</a></li>
<li><strong>Abstract: </strong>Accurate segmentation of vestibular schwannoma (VS) on Magnetic Resonance Imaging (MRI) is essential for patient management but often requires time-intensive manual annotations by experts. While recent advances in deep learning (DL) have facilitated automated segmentation, challenges remain in achieving robust performance across diverse datasets and complex clinical cases. We present an annotated dataset stemming from a bootstrapped DL-based framework for iterative segmentation and quality refinement of VS in MRI. We combine data from multiple centres and rely on expert consensus for trustworthiness of the annotations. We show that our approach enables effective and resource-efficient generalisation of automated segmentation models to a target data distribution. The framework achieved a significant improvement in segmentation accuracy with a Dice Similarity Coefficient (DSC) increase from 0.9125 to 0.9670 on our target internal validation dataset, while maintaining stable performance on representative external datasets. Expert evaluation on 143 scans further highlighted areas for model refinement, revealing nuanced cases where segmentation required expert intervention. The proposed approach is estimated to enhance efficiency by approximately 37.4% compared to the conventional manual annotation process. Overall, our human-in-the-loop model training approach achieved high segmentation accuracy, highlighting its potential as a clinically adaptable and generalisable strategy for automated VS segmentation in diverse clinical settings. The dataset includes 190 patients, with tumour annotations available for 534 longitudinal contrast-enhanced T1-weighted (T1CE) scans from 184 patients, and non-annotated T2-weighted scans from 6 patients. This dataset is publicly accessible on The Cancer Imaging Archive (TCIA) (this https URL).</li>
</ul>

<h3>Title: Remembering Unequally: Global and Disciplinary Bias in LLM-Generated Co-Authorship Networks</h3>
<ul>
<li><strong>Authors: </strong>Ghazal Kalhor, Afra Mashhadi</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.00476">https://arxiv.org/abs/2511.00476</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.00476">https://arxiv.org/pdf/2511.00476</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.00476]] Remembering Unequally: Global and Disciplinary Bias in LLM-Generated Co-Authorship Networks(https://arxiv.org/abs/2511.00476)</code><input type="text"></li>
<li><strong>Keywords: </strong>fair, large language model</a></li>
<li><strong>Abstract: </strong>Ongoing breakthroughs in Large Language Models (LLMs) are reshaping search and recommendation platforms at their core. While this shift unlocks powerful new scientometric tools, it also exposes critical fairness and bias issues that could erode the integrity of the information ecosystem. Additionally, as LLMs become more integrated into web-based searches for scholarly tools, their ability to generate summarized research work based on memorized data introduces new dimensions to these challenges. The extent of memorization in LLMs can impact the accuracy and fairness of the co-authorship networks they produce, potentially reflecting and amplifying existing biases within the scientific community and across different regions. This study critically examines the impact of LLM memorization on the co-authorship networks. To this end, we assess memorization effects across three prominent models, DeepSeek R1, Llama 4 Scout, and Mixtral 8x7B, analyzing how memorization-driven outputs vary across academic disciplines and world regions. While our global analysis reveals a consistent bias favoring highly cited researchers, this pattern is not uniformly observed. Certain disciplines, such as Clinical Medicine, and regions, including parts of Africa, show more balanced representation, pointing to areas where LLM training data may reflect greater equity. These findings underscore both the risks and opportunities in deploying LLMs for scholarly discovery.</li>
</ul>

<h3>Title: FedMGP: Personalized Federated Learning with Multi-Group Text-Visual Prompts</h3>
<ul>
<li><strong>Authors: </strong>Weihao Bo, Yanpeng Sun, Yu Wang, Xinyu Zhang, Zechao Li</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.00480">https://arxiv.org/abs/2511.00480</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.00480">https://arxiv.org/pdf/2511.00480</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.00480]] FedMGP: Personalized Federated Learning with Multi-Group Text-Visual Prompts(https://arxiv.org/abs/2511.00480)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, federate</a></li>
<li><strong>Abstract: </strong>In this paper, we introduce FedMGP, a new paradigm for personalized federated prompt learning in vision-language models. FedMGP equips each client with multiple groups of paired textual and visual prompts, enabling the model to capture diverse, fine-grained semantic and instance-level cues. A diversity loss is introduced to drive each prompt group to specialize in distinct and complementary semantic aspects, ensuring that the groups collectively cover a broader range of local characteristics. During communication, FedMGP employs a dynamic prompt aggregation strategy based on similarity-guided probabilistic sampling: each client computes the cosine similarity between its prompt groups and the global prompts from the previous round, then samples s groups via a softmax-weighted distribution. This soft selection mechanism preferentially aggregates semantically aligned knowledge while still enabling exploration of underrepresented patterns effectively balancing the preservation of common knowledge with client-specific features. Notably, FedMGP maintains parameter efficiency by redistributing a fixed prompt capacity across multiple groups, achieving state-of-the-art performance with the lowest communication parameters among all federated prompt learning methods. Theoretical analysis shows that our dynamic aggregation strategy promotes robust global representation learning by reinforcing shared semantics while suppressing client-specific noise. Extensive experiments demonstrate that FedMGP consistently outperforms prior approaches in both personalization and domain generalization across diverse federated vision-language benchmarks. The code will be released on this https URL.</li>
</ul>

<h3>Title: Leveraging the Cross-Domain & Cross-Linguistic Corpus for Low Resource NMT: A Case Study On Bhili-Hindi-English Parallel Corpus</h3>
<ul>
<li><strong>Authors: </strong>Pooja Singh, Shashwat Bhardwaj, Vaibhav Sharma, Sandeep Kumar</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.00486">https://arxiv.org/abs/2511.00486</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.00486">https://arxiv.org/pdf/2511.00486</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.00486]] Leveraging the Cross-Domain & Cross-Linguistic Corpus for Low Resource NMT: A Case Study On Bhili-Hindi-English Parallel Corpus(https://arxiv.org/abs/2511.00486)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative, large language model</a></li>
<li><strong>Abstract: </strong>The linguistic diversity of India poses significant machine translation challenges, especially for underrepresented tribal languages like Bhili, which lack high-quality linguistic resources. This paper addresses the gap by introducing Bhili-Hindi-English Parallel Corpus (BHEPC), the first and largest parallel corpus worldwide comprising 110,000 meticulously curated sentences across Bhili, Hindi, and English. The corpus was created with the assistance of expert human translators. BHEPC spans critical domains such as education, administration, and news, establishing a valuable benchmark for research in low resource machine translation. To establish a comprehensive Bhili Machine Translation benchmark, we evaluated a wide range of proprietary and open-source Multilingual Large Language Models (MLLMs) on bidirectional translation tasks between English/Hindi and Bhili. Comprehensive evaluation demonstrates that the fine-tuned NLLB-200 distilled 600M variant model outperforms others, highlighting the potential of multilingual models in low resource scenarios. Furthermore, we investigated the generative translation capabilities of multilingual LLMs on BHEPC using in-context learning, assessing performance under cross-domain generalization and quantifying distributional divergence. This work bridges a critical resource gap and promotes inclusive natural language processing technologies for low-resource and marginalized languages globally.</li>
</ul>

<h3>Title: With Privacy, Size Matters: On the Importance of Dataset Size in Differentially Private Text Rewriting</h3>
<ul>
<li><strong>Authors: </strong>Stephen Meisenbacher, Florian Matthes</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.00487">https://arxiv.org/abs/2511.00487</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.00487">https://arxiv.org/pdf/2511.00487</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.00487]] With Privacy, Size Matters: On the Importance of Dataset Size in Differentially Private Text Rewriting(https://arxiv.org/abs/2511.00487)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy</a></li>
<li><strong>Abstract: </strong>Recent work in Differential Privacy with Natural Language Processing (DP NLP) has proposed numerous promising techniques in the form of text rewriting mechanisms. In the evaluation of these mechanisms, an often-ignored aspect is that of dataset size, or rather, the effect of dataset size on a mechanism's efficacy for utility and privacy preservation. In this work, we are the first to introduce this factor in the evaluation of DP text privatization, where we design utility and privacy tests on large-scale datasets with dynamic split sizes. We run these tests on datasets of varying size with up to one million texts, and we focus on quantifying the effect of increasing dataset size on the privacy-utility trade-off. Our findings reveal that dataset size plays an integral part in evaluating DP text rewriting mechanisms; additionally, these findings call for more rigorous evaluation procedures in DP NLP, as well as shed light on the future of DP NLP in practice and at scale.</li>
</ul>

<h3>Title: ToM: Leveraging Tree-oriented MapReduce for Long-Context Reasoning in Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Jiani Guo, Zuchao Li, Jie Wu, Qianren Wang, Yun Li, Lefei Zhang, Hai Zhao, Yujiu Yang</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.00489">https://arxiv.org/abs/2511.00489</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.00489">https://arxiv.org/pdf/2511.00489</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.00489]] ToM: Leveraging Tree-oriented MapReduce for Long-Context Reasoning in Large Language Models(https://arxiv.org/abs/2511.00489)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large Language Models (LLMs), constrained by limited context windows, often face significant performance degradation when reasoning over long contexts. To address this, Retrieval-Augmented Generation (RAG) retrieves and reasons over chunks but frequently sacrifices logical coherence due to its reliance on similarity-based rankings. Similarly, divide-and-conquer frameworks (DCF) split documents into small chunks for independent reasoning and aggregation. While effective for local reasoning, DCF struggles to capture long-range dependencies and risks inducing conflicts by processing chunks in isolation. To overcome these limitations, we propose ToM, a novel Tree-oriented MapReduce framework for long-context reasoning. ToM leverages the inherent hierarchical structure of long documents (e.g., main headings and subheadings) by constructing a DocTree through hierarchical semantic parsing and performing bottom-up aggregation. Using a Tree MapReduce approach, ToM enables recursive reasoning: in the Map step, rationales are generated at child nodes; in the Reduce step, these rationales are aggregated across sibling nodes to resolve conflicts or reach consensus at parent nodes. Experimental results on 70B+ LLMs show that ToM significantly outperforms existing divide-and-conquer frameworks and retrieval-augmented generation methods, achieving better logical coherence and long-context reasoning. Our code is available at this https URL .</li>
</ul>

<h3>Title: Diff4Splat: Controllable 4D Scene Generation with Latent Dynamic Reconstruction Models</h3>
<ul>
<li><strong>Authors: </strong>Panwang Pan, Chenguo Lin, Jingjing Zhao, Chenxin Li, Yuchen Lin, Haopeng Li, Honglei Yan, Kairun Wen, Yunlong Lin, Yixuan Yuan, Yadong Mu</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.00503">https://arxiv.org/abs/2511.00503</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.00503">https://arxiv.org/pdf/2511.00503</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.00503]] Diff4Splat: Controllable 4D Scene Generation with Latent Dynamic Reconstruction Models(https://arxiv.org/abs/2511.00503)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction, diffusion, transformer, generative</a></li>
<li><strong>Abstract: </strong>We introduce Diff4Splat, a feed-forward method that synthesizes controllable and explicit 4D scenes from a single image. Our approach unifies the generative priors of video diffusion models with geometry and motion constraints learned from large-scale 4D datasets. Given a single input image, a camera trajectory, and an optional text prompt, Diff4Splat directly predicts a deformable 3D Gaussian field that encodes appearance, geometry, and motion, all in a single forward pass, without test-time optimization or post-hoc refinement. At the core of our framework lies a video latent transformer, which augments video diffusion models to jointly capture spatio-temporal dependencies and predict time-varying 3D Gaussian primitives. Training is guided by objectives on appearance fidelity, geometric accuracy, and motion consistency, enabling Diff4Splat to synthesize high-quality 4D scenes in 30 seconds. We demonstrate the effectiveness of Diff4Splatacross video generation, novel view synthesis, and geometry extraction, where it matches or surpasses optimization-based methods for dynamic scene synthesis while being significantly more efficient.</li>
</ul>

<h3>Title: Zero-RAG: Towards Retrieval-Augmented Generation with Zero Redundant Knowledge</h3>
<ul>
<li><strong>Authors: </strong>Qi Luo, Xiaonan Li, Junqi Dai, Shuang Cheng, Xipeng Qiu</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.00505">https://arxiv.org/abs/2511.00505</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.00505">https://arxiv.org/pdf/2511.00505</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.00505]] Zero-RAG: Towards Retrieval-Augmented Generation with Zero Redundant Knowledge(https://arxiv.org/abs/2511.00505)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Retrieval-Augmented Generation has shown remarkable results to address Large Language Models' hallucinations, which usually uses a large external corpus to supplement knowledge to LLMs. However, with the development of LLMs, the internal knowledge of LLMs has expanded significantly, thus causing significant knowledge redundancy between the external corpus and LLMs. On the one hand, the indexing cost of dense retrieval is highly related to the corpus size and thus significant redundant knowledge intensifies the dense retrieval's workload. On the other hand, the redundant knowledge in the external corpus is not helpful to LLMs and our exploratory analysis shows that it instead hurts the RAG performance on those questions which the LLM can answer by itself. To address these issues, we propose Zero-RAG to tackle these challenges. Specifically, we first propose the Mastery-Score metric to identify redundant knowledge in the RAG corpus to prune it. After pruning, answers to "mastered" questions rely primarily on internal knowledge of the LLM. To better harness the internal capacity, we propose Query Router and Noise-Tolerant Tuning to avoid the irrelevant documents' distraction and thus further improve the LLM's utilization of internal knowledge with pruned corpus. Experimental results show that Zero-RAG prunes the Wikipedia corpus by 30\% and accelerates the retrieval stage by 22\%, without compromising RAG's performance.</li>
</ul>

<h3>Title: OmniTrack++: Omnidirectional Multi-Object Tracking by Learning Large-FoV Trajectory Feedback</h3>
<ul>
<li><strong>Authors: </strong>Kai Luo, Hao Shi, Kunyu Peng, Fei Teng, Sheng Wu, Kaiwei Wang, Kailun Yang</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.RO, eess.IV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.00510">https://arxiv.org/abs/2511.00510</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.00510">https://arxiv.org/pdf/2511.00510</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.00510]] OmniTrack++: Omnidirectional Multi-Object Tracking by Learning Large-FoV Trajectory Feedback(https://arxiv.org/abs/2511.00510)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>This paper investigates Multi-Object Tracking (MOT) in panoramic imagery, which introduces unique challenges including a 360° Field of View (FoV), resolution dilution, and severe view-dependent distortions. Conventional MOT methods designed for narrow-FoV pinhole cameras generalize unsatisfactorily under these conditions. To address panoramic distortion, large search space, and identity ambiguity under a 360° FoV, OmniTrack++ adopts a feedback-driven framework that progressively refines perception with trajectory cues. A DynamicSSM block first stabilizes panoramic features, implicitly alleviating geometric distortion. On top of normalized representations, FlexiTrack Instances use trajectory-informed feedback for flexible localization and reliable short-term association. To ensure long-term robustness, an ExpertTrack Memory consolidates appearance cues via a Mixture-of-Experts design, enabling recovery from fragmented tracks and reducing identity drift. Finally, a Tracklet Management module adaptively switches between end-to-end and tracking-by-detection modes according to scene dynamics, offering a balanced and scalable solution for panoramic MOT. To support rigorous evaluation, we establish the EmboTrack benchmark, a comprehensive dataset for panoramic MOT that includes QuadTrack, captured with a quadruped robot, and BipTrack, collected with a bipedal wheel-legged robot. Together, these datasets span wide-angle environments and diverse motion patterns, providing a challenging testbed for real-world panoramic perception. Extensive experiments on JRDB and EmboTrack demonstrate that OmniTrack++ achieves state-of-the-art performance, yielding substantial HOTA improvements of +25.5% on JRDB and +43.07% on QuadTrack over the original OmniTrack. Datasets and code will be made publicly available at this https URL.</li>
</ul>

<h3>Title: ID-Composer: Multi-Subject Video Synthesis with Hierarchical Identity Preservation</h3>
<ul>
<li><strong>Authors: </strong>Panwang Pan, Jingjing Zhao, Yuchen Lin, Chenguo Lin, Chenxin Li, Haopeng Li, Honglei Yan, Tingting Shen, Yadong Mu</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.00511">https://arxiv.org/abs/2511.00511</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.00511">https://arxiv.org/pdf/2511.00511</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.00511]] ID-Composer: Multi-Subject Video Synthesis with Hierarchical Identity Preservation(https://arxiv.org/abs/2511.00511)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, generative</a></li>
<li><strong>Abstract: </strong>Video generative models pretrained on large-scale datasets can produce high-quality videos, but are often conditioned on text or a single image, limiting controllability and applicability. We introduce ID-Composer, a novel framework that addresses this gap by tackling multi-subject video generation from a text prompt and reference images. This task is challenging as it requires preserving subject identities, integrating semantics across subjects and modalities, and maintaining temporal consistency. To faithfully preserve the subject consistency and textual information in synthesized videos, ID-Composer designs a \textbf{hierarchical identity-preserving attention mechanism}, which effectively aggregates features within and across subjects and modalities. To effectively allow for the semantic following of user intention, we introduce \textbf{semantic understanding via pretrained vision-language model (VLM)}, leveraging VLM's superior semantic understanding to provide fine-grained guidance and capture complex interactions between multiple subjects. Considering that standard diffusion loss often fails in aligning the critical concepts like subject ID, we employ an \textbf{online reinforcement learning phase} to drive the overall training objective of ID-Composer into RLVR. Extensive experiments demonstrate that our model surpasses existing methods in identity preservation, temporal consistency, and video quality.</li>
</ul>

<h3>Title: Fine-Tuning DialoGPT on Common Diseases in Rural Nepal for Medical Conversations</h3>
<ul>
<li><strong>Authors: </strong>Birat Poudel, Satyam Ghimire, Er. Prakash Chandra Prasad</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.00514">https://arxiv.org/abs/2511.00514</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.00514">https://arxiv.org/pdf/2511.00514</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.00514]] Fine-Tuning DialoGPT on Common Diseases in Rural Nepal for Medical Conversations(https://arxiv.org/abs/2511.00514)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>Conversational agents are increasingly being explored to support healthcare delivery, particularly in resource-constrained settings such as rural Nepal. Large-scale conversational models typically rely on internet connectivity and cloud infrastructure, which may not be accessible in rural areas. In this study, we fine-tuned DialoGPT, a lightweight generative dialogue model that can operate offline, on a synthetically constructed dataset of doctor-patient interactions covering ten common diseases prevalent in rural Nepal, including common cold, seasonal fever, diarrhea, typhoid fever, gastritis, food poisoning, malaria, dengue fever, tuberculosis, and pneumonia. Despite being trained on a limited, domain-specific dataset, the fine-tuned model produced coherent, contextually relevant, and medically appropriate responses, demonstrating an understanding of symptoms, disease context, and empathetic communication. These results highlight the adaptability of compact, offline-capable dialogue models and the effectiveness of targeted datasets for domain adaptation in low-resource healthcare environments, offering promising directions for future rural medical conversational AI.</li>
</ul>

<h3>Title: Exploring and Mitigating Gender Bias in Encoder-Based Transformer Models</h3>
<ul>
<li><strong>Authors: </strong>Ariyan Hossain, Khondokar Mohammad Ahanaf Hannan, Rakinul Haque, Nowreen Tarannum Rafa, Humayra Musarrat, Shoaib Ahmed Dipu, Farig Yousuf Sadeque</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.00519">https://arxiv.org/abs/2511.00519</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.00519">https://arxiv.org/pdf/2511.00519</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.00519]] Exploring and Mitigating Gender Bias in Encoder-Based Transformer Models(https://arxiv.org/abs/2511.00519)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Gender bias in language models has gained increasing attention in the field of natural language processing. Encoder-based transformer models, which have achieved state-of-the-art performance in various language tasks, have been shown to exhibit strong gender biases inherited from their training data. This paper investigates gender bias in contextualized word embeddings, a crucial component of transformer-based models. We focus on prominent architectures such as BERT, ALBERT, RoBERTa, and DistilBERT to examine their vulnerability to gender bias. To quantify the degree of bias, we introduce a novel metric, MALoR, which assesses bias based on model probabilities for filling masked tokens. We further propose a mitigation approach involving continued pre-training on a gender-balanced dataset generated via Counterfactual Data Augmentation. Our experiments reveal significant reductions in gender bias scores across different pronoun pairs. For instance, in BERT-base, bias scores for "he-she" dropped from 1.27 to 0.08, and "his-her" from 2.51 to 0.36 following our mitigation approach. We also observed similar improvements across other models, with "male-female" bias decreasing from 1.82 to 0.10 in BERT-large. Our approach effectively reduces gender bias without compromising model performance on downstream tasks.</li>
</ul>

<h3>Title: SegDebias: Test-Time Bias Mitigation for ViT-Based CLIP via Segmentation</h3>
<ul>
<li><strong>Authors: </strong>Fangyu Wu, Yujun Cai</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.00523">https://arxiv.org/abs/2511.00523</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.00523">https://arxiv.org/pdf/2511.00523</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.00523]] SegDebias: Test-Time Bias Mitigation for ViT-Based CLIP via Segmentation(https://arxiv.org/abs/2511.00523)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, segmentation</a></li>
<li><strong>Abstract: </strong>Vision language models such as CLIP have shown remarkable performance in zero shot classification, but remain susceptible to spurious correlations, where irrelevant visual features influence predictions. Existing debiasing methods often require access to training data and explicit group labels to perform fine-tuning or adjust embeddings, which limits their practicality in real-world settings. Test-time methods attempt to avoid this constraint, but many still depend on prior knowledge of dataset specific biases, limiting their generalizability in open set settings. In this work, we propose a test-time debiasing method for ViT based CLIP models that requires no additional training or assumptions of bias annotations. Our approach uses a pretrained segmentation model to isolate the target visual attribute, then adjusts the non target regions so that their embeddings are uniformly similar to all class specific text prompts. This procedure removes unintended bias signals from confounding visual regions while preserving the target attribute. Experiments on Waterbirds and CelebA show that our method outperforms existing test-time debiasing approaches in both group robustness metrics and Attention IoU. These results demonstrate the effectiveness of segmentation guided interventions for scalable and annotation free bias mitigation in vision language models.</li>
</ul>

<h3>Title: Air Pollution Forecasting in Bucharest</h3>
<ul>
<li><strong>Authors: </strong>Dragoş-Andrei Şerban, Răzvan-Alexandru Smădu, Dumitru-Clementin Cercel</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CY, stat.AP</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.00532">https://arxiv.org/abs/2511.00532</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.00532">https://arxiv.org/pdf/2511.00532</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.00532]] Air Pollution Forecasting in Bucharest(https://arxiv.org/abs/2511.00532)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer, large language model</a></li>
<li><strong>Abstract: </strong>Air pollution, especially the particulate matter 2.5 (PM2.5), has become a growing concern in recent years, primarily in urban areas. Being exposed to air pollution is linked to developing numerous health problems, like the aggravation of respiratory diseases, cardiovascular disorders, lung function impairment, and even cancer or early death. Forecasting future levels of PM2.5 has become increasingly important over the past few years, as it can provide early warnings and help prevent diseases. This paper aims to design, fine-tune, test, and evaluate machine learning models for predicting future levels of PM2.5 over various time horizons. Our primary objective is to assess and compare the performance of multiple models, ranging from linear regression algorithms and ensemble-based methods to deep learning models, such as advanced recurrent neural networks and transformers, as well as large language models, on this forecasting task.</li>
</ul>

<h3>Title: Multi-refined Feature Enhanced Sentiment Analysis Using Contextual Instruction</h3>
<ul>
<li><strong>Authors: </strong>Peter Atandoh, Jie Zou, Weikang Guo, Jiwei Wei, Zheng Wang</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.00537">https://arxiv.org/abs/2511.00537</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.00537">https://arxiv.org/pdf/2511.00537</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.00537]] Multi-refined Feature Enhanced Sentiment Analysis Using Contextual Instruction(https://arxiv.org/abs/2511.00537)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, extraction</a></li>
<li><strong>Abstract: </strong>Sentiment analysis using deep learning and pre-trained language models (PLMs) has gained significant traction due to their ability to capture rich contextual representations. However, existing approaches often underperform in scenarios involving nuanced emotional cues, domain shifts, and imbalanced sentiment distributions. We argue that these limitations stem from inadequate semantic grounding, poor generalization to diverse linguistic patterns, and biases toward dominant sentiment classes. To overcome these challenges, we propose CISEA-MRFE, a novel PLM-based framework integrating Contextual Instruction (CI), Semantic Enhancement Augmentation (SEA), and Multi-Refined Feature Extraction (MRFE). CI injects domain-aware directives to guide sentiment disambiguation; SEA improves robustness through sentiment-consistent paraphrastic augmentation; and MRFE combines a Scale-Adaptive Depthwise Encoder (SADE) for multi-scale feature specialization with an Emotion Evaluator Context Encoder (EECE) for affect-aware sequence modeling. Experimental results on four benchmark datasets demonstrate that CISEA-MRFE consistently outperforms strong baselines, achieving relative improvements in accuracy of up to 4.6% on IMDb, 6.5% on Yelp, 30.3% on Twitter, and 4.1% on Amazon. These results validate the effectiveness and generalization ability of our approach for sentiment classification across varied domains.</li>
</ul>

<h3>Title: Real-IAD Variety: Pushing Industrial Anomaly Detection Dataset to a Modern Era</h3>
<ul>
<li><strong>Authors: </strong>Wenbing Zhu, Chengjie Wang, Bin-Bin Gao, Jiangning Zhang, Guannan Jiang, Jie Hu, Zhenye Gan, Lidong Wang, Ziqing Zhou, Linjie Cheng, Yurui Pan, Bo Peng, Mingmin Chi, Lizhuang Ma</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.00540">https://arxiv.org/abs/2511.00540</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.00540">https://arxiv.org/pdf/2511.00540</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.00540]] Real-IAD Variety: Pushing Industrial Anomaly Detection Dataset to a Modern Era(https://arxiv.org/abs/2511.00540)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Industrial Anomaly Detection (IAD) is critical for enhancing operational safety, ensuring product quality, and optimizing manufacturing efficiency across global industries. However, the IAD algorithms are severely constrained by the limitations of existing public benchmarks. Current datasets exhibit restricted category diversity and insufficient scale, frequently resulting in metric saturation and limited model transferability to real-world scenarios. To address this gap, we introduce Real-IAD Variety, the largest and most diverse IAD benchmark, comprising 198,960 high-resolution images across 160 distinct object categories. Its diversity is ensured through comprehensive coverage of 28 industries, 24 material types, and 22 color variations. Our comprehensive experimental analysis validates the benchmark's substantial challenge: state-of-the-art multi-class unsupervised anomaly detection methods experience significant performance degradation when scaled from 30 to 160 categories. Crucially, we demonstrate that vision-language models exhibit remarkable robustness to category scale-up, with minimal performance variation across different category counts, significantly enhancing generalization capabilities in diverse industrial contexts. The unprecedented scale and complexity of Real-IAD Variety position it as an essential resource for training and evaluating next-generation foundation models for anomaly detection. By providing this comprehensive benchmark with rigorous evaluation protocols across multi-class unsupervised, multi-view, and zero-/few-shot settings, we aim to accelerate research beyond domain-specific constraints, enabling the development of scalable, general-purpose anomaly detection systems. Real-IAD Variety will be made publicly available to facilitate innovation in this critical field.</li>
</ul>

<h3>Title: MIFO: Learning and Synthesizing Multi-Instance from One Image</h3>
<ul>
<li><strong>Authors: </strong>Kailun Su, Ziqi He, Xi Wang, Yang Zhou</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.00542">https://arxiv.org/abs/2511.00542</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.00542">https://arxiv.org/pdf/2511.00542</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.00542]] MIFO: Learning and Synthesizing Multi-Instance from One Image(https://arxiv.org/abs/2511.00542)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>This paper proposes a method for precise learning and synthesizing multi-instance semantics from a single image. The difficulty of this problem lies in the limited training data, and it becomes even more challenging when the instances to be learned have similar semantics or appearance. To address this, we propose a penalty-based attention optimization to disentangle similar semantics during the learning stage. Then, in the synthesis, we introduce and optimize box control in attention layers to further mitigate semantic leakage while precisely controlling the output layout. Experimental results demonstrate that our method achieves disentangled and high-quality semantic learning and synthesis, strikingly balancing editability and instance consistency. Our method remains robust when dealing with semantically or visually similar instances or rare-seen objects. The code is publicly available at this https URL</li>
</ul>

<h3>Title: Learning an Efficient Optimizer via Hybrid-Policy Sub-Trajectory Balance</h3>
<ul>
<li><strong>Authors: </strong>Yunchuan Guan, Yu Liu, Ke Zhou, Hui Li, Sen Jia, Zhiqi Shen, Ziyang Wang, Xinglin Zhang, Tao Chen, Jenq-Neng Hwang, Lei Li</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CV, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.00543">https://arxiv.org/abs/2511.00543</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.00543">https://arxiv.org/pdf/2511.00543</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.00543]] Learning an Efficient Optimizer via Hybrid-Policy Sub-Trajectory Balance(https://arxiv.org/abs/2511.00543)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative, large language model</a></li>
<li><strong>Abstract: </strong>Recent advances in generative modeling enable neural networks to generate weights without relying on gradient-based optimization. However, current methods are limited by issues of over-coupling and long-horizon. The former tightly binds weight generation with task-specific objectives, thereby limiting the flexibility of the learned optimizer. The latter leads to inefficiency and low accuracy during inference, caused by the lack of local constraints. In this paper, we propose Lo-Hp, a decoupled two-stage weight generation framework that enhances flexibility through learning various optimization policies. It adopts a hybrid-policy sub-trajectory balance objective, which integrates on-policy and off-policy learning to capture local optimization policies. Theoretically, we demonstrate that learning solely local optimization policies can address the long-horizon issue while enhancing the generation of global optimal weights. In addition, we validate Lo-Hp's superior accuracy and inference efficiency in tasks that require frequent weight updates, such as transfer learning, few-shot learning, domain generalization, and large language model adaptation.</li>
</ul>

<h3>Title: Robust Single-Agent Reinforcement Learning for Regional Traffic Signal Control Under Demand Fluctuations</h3>
<ul>
<li><strong>Authors: </strong>Qiang Li, Jin Niu, Lina Yu</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.00549">https://arxiv.org/abs/2511.00549</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.00549">https://arxiv.org/pdf/2511.00549</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.00549]] Robust Single-Agent Reinforcement Learning for Regional Traffic Signal Control Under Demand Fluctuations(https://arxiv.org/abs/2511.00549)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Traffic congestion, primarily driven by intersection queuing, significantly impacts urban living standards, safety, environmental quality, and economic efficiency. While Traffic Signal Control (TSC) systems hold potential for congestion mitigation, traditional optimization models often fail to capture real-world traffic complexity and dynamics. This study introduces a novel single-agent reinforcement learning (RL) framework for regional adaptive TSC, circumventing the coordination complexities inherent in multi-agent systems through a centralized decision-making paradigm. The model employs an adjacency matrix to unify the encoding of road network topology, real-time queue states derived from probe vehicle data, and current signal timing parameters. Leveraging the efficient learning capabilities of the DreamerV3 world model, the agent learns control policies where actions sequentially select intersections and adjust their signal phase splits to regulate traffic inflow/outflow, analogous to a feedback control system. Reward design prioritizes queue dissipation, directly linking congestion metrics (queue length) to control actions. Simulation experiments conducted in SUMO demonstrate the model's effectiveness: under inference scenarios with multi-level (10%, 20%, 30%) Origin-Destination (OD) demand fluctuations, the framework exhibits robust anti-fluctuation capability and significantly reduces queue lengths. This work establishes a new paradigm for intelligent traffic control compatible with probe vehicle technology. Future research will focus on enhancing practical applicability by incorporating stochastic OD demand fluctuations during training and exploring regional optimization mechanisms for contingency events.</li>
</ul>

<h3>Title: Temporal Fusion Transformer for Multi-Horizon Probabilistic Forecasting of Weekly Retail Sales</h3>
<ul>
<li><strong>Authors: </strong>Santhi Bharath Punati, Sandeep Kanta, Udaya Bhasker Cheerala, Madhusudan G Lanjewar, Praveen Damacharla</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, econ.GN</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.00552">https://arxiv.org/abs/2511.00552</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.00552">https://arxiv.org/pdf/2511.00552</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.00552]] Temporal Fusion Transformer for Multi-Horizon Probabilistic Forecasting of Weekly Retail Sales(https://arxiv.org/abs/2511.00552)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability, transformer</a></li>
<li><strong>Abstract: </strong>Accurate multi-horizon retail forecasts are critical for inventory and promotions. We present a novel study of weekly Walmart sales (45 stores, 2010--2012) using a Temporal Fusion Transformer (TFT) that fuses static store identifiers with time-varying exogenous signals (holidays, CPI, fuel price, temperature). The pipeline produces 1--5-week-ahead probabilistic forecasts via Quantile Loss, yielding calibrated 90\% prediction intervals and interpretability through variable-selection networks, static enrichment, and temporal attention. On a fixed 2012 hold-out dataset, TFT achieves an RMSE of \$57.9k USD per store-week and an $R^2$ of 0.9875. Across a 5-fold chronological cross-validation, the averages are RMSE = \$64.6k USD and $R^2$ = 0.9844, outperforming the XGB, CNN, LSTM, and CNN-LSTM baseline models. These results demonstrate practical value for inventory planning and holiday-period optimization, while maintaining model transparency.</li>
</ul>

<h3>Title: Red-teaming Activation Probes using Prompted LLMs</h3>
<ul>
<li><strong>Authors: </strong>Phil Blandfort, Robert Graham</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.00554">https://arxiv.org/abs/2511.00554</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.00554">https://arxiv.org/pdf/2511.00554</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.00554]] Red-teaming Activation Probes using Prompted LLMs(https://arxiv.org/abs/2511.00554)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack, robust</a></li>
<li><strong>Abstract: </strong>Activation probes are attractive monitors for AI systems due to low cost and latency, but their real-world robustness remains underexplored. We ask: What failure modes arise under realistic, black-box adversarial pressure, and how can we surface them with minimal effort? We present a lightweight black-box red-teaming procedure that wraps an off-the-shelf LLM with iterative feedback and in-context learning (ICL), and requires no fine-tuning, gradients, or architectural access. Running a case study with probes for high-stakes interactions, we show that our approach can help discover valuable insights about a SOTA probe. Our analysis uncovers interpretable brittleness patterns (e.g., legalese-induced FPs; bland procedural tone FNs) and reduced but persistent vulnerabilities under scenario-constraint attacks. These results suggest that simple prompted red-teaming scaffolding can anticipate failure patterns before deployment and might yield promising, actionable insights to harden future probes.</li>
</ul>

<h3>Title: Friend or Foe: How LLMs' Safety Mind Gets Fooled by Intent Shift Attack</h3>
<ul>
<li><strong>Authors: </strong>Peng Ding, Jun Kuang, Wen Sun, Zongyu Wang, Xuezhi Cao, Xunliang Cai, Jiajun Chen, Shujian Huang</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.00556">https://arxiv.org/abs/2511.00556</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.00556">https://arxiv.org/pdf/2511.00556</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.00556]] Friend or Foe: How LLMs' Safety Mind Gets Fooled by Intent Shift Attack(https://arxiv.org/abs/2511.00556)</code><input type="text"></li>
<li><strong>Keywords: </strong>defense, attack, robust, large language model</a></li>
<li><strong>Abstract: </strong>Large language models (LLMs) remain vulnerable to jailbreaking attacks despite their impressive capabilities. Investigating these weaknesses is crucial for robust safety mechanisms. Existing attacks primarily distract LLMs by introducing additional context or adversarial tokens, leaving the core harmful intent unchanged. In this paper, we introduce ISA (Intent Shift Attack), which obfuscates LLMs about the intent of the attacks. More specifically, we establish a taxonomy of intent transformations and leverage them to generate attacks that may be misperceived by LLMs as benign requests for information. Unlike prior methods relying on complex tokens or lengthy context, our approach only needs minimal edits to the original request, and yields natural, human-readable, and seemingly harmless prompts. Extensive experiments on both open-source and commercial LLMs show that ISA achieves over 70% improvement in attack success rate compared to direct harmful prompts. More critically, fine-tuning models on only benign data reformulated with ISA templates elevates success rates to nearly 100%. For defense, we evaluate existing methods and demonstrate their inadequacy against ISA, while exploring both training-free and training-based mitigation strategies. Our findings reveal fundamental challenges in intent inference for LLMs safety and underscore the need for more effective defenses. Our code and datasets are available at this https URL.</li>
</ul>

<h3>Title: FTT-GRU: A Hybrid Fast Temporal Transformer with GRU for Remaining Useful Life Prediction</h3>
<ul>
<li><strong>Authors: </strong>Varun Teja Chirukiri, Udaya Bhasker Cheerala, Sandeep Kanta, Abdul Karim, Praveen Damacharla</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, eess.SY</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.00564">https://arxiv.org/abs/2511.00564</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.00564">https://arxiv.org/pdf/2511.00564</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.00564]] FTT-GRU: A Hybrid Fast Temporal Transformer with GRU for Remaining Useful Life Prediction(https://arxiv.org/abs/2511.00564)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Accurate prediction of the remaining useful life (RUL) of industrial machinery is essential for reducing downtime and optimizing maintenance schedules. Existing approaches, such as long short-term memory (LSTM) networks and convolutional neural networks (CNNs), often struggle to model both global temporal dependencies and fine-grained degradation trends in multivariate sensor data. We propose a hybrid model, FTT-GRU, which combines a Fast Temporal Transformer (FTT) -- a lightweight Transformer variant using linearized attention via fast Fourier transform (FFT) -- with a gated recurrent unit (GRU) layer for sequential modeling. To the best of our knowledge, this is the first application of an FTT with a GRU for RUL prediction on NASA CMAPSS, enabling simultaneous capture of global and local degradation patterns in a compact architecture. On CMAPSS FD001, FTT-GRU attains RMSE 30.76, MAE 18.97, and $R^2=0.45$, with 1.12 ms CPU latency at batch=1. Relative to the best published deep baseline (TCN--Attention), it improves RMSE by 1.16\% and MAE by 4.00\%. Training curves averaged over $k=3$ runs show smooth convergence with narrow 95\% confidence bands, and ablations (GRU-only, FTT-only) support the contribution of both components. These results demonstrate that a compact Transformer-RNN hybrid delivers accurate and efficient RUL predictions on CMAPSS, making it suitable for real-time industrial prognostics.</li>
</ul>

<h3>Title: Generalized Category Discovery under Domain Shift: A Frequency Domain Perspective</h3>
<ul>
<li><strong>Authors: </strong>Wei Feng, Zongyuan Ge</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.00573">https://arxiv.org/abs/2511.00573</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.00573">https://arxiv.org/pdf/2511.00573</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.00573]] Generalized Category Discovery under Domain Shift: A Frequency Domain Perspective(https://arxiv.org/abs/2511.00573)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Generalized Category Discovery (GCD) aims to leverage labeled samples from known categories to cluster unlabeled data that may include both known and unknown categories. While existing methods have achieved impressive results under standard conditions, their performance often deteriorates in the presence of distribution shifts. In this paper, we explore a more realistic task: Domain-Shifted Generalized Category Discovery (DS\_GCD), where the unlabeled data includes not only unknown categories but also samples from unknown domains. To tackle this challenge, we propose a \textbf{\underline{F}}requency-guided Gene\textbf{\underline{r}}alized Cat\textbf{\underline{e}}gory Discov\textbf{\underline{e}}ry framework (FREE) that enhances the model's ability to discover categories under distributional shift by leveraging frequency-domain information. Specifically, we first propose a frequency-based domain separation strategy that partitions samples into known and unknown domains by measuring their amplitude differences. We then propose two types of frequency-domain perturbation strategies: a cross-domain strategy, which adapts to new distributions by exchanging amplitude components across domains, and an intra-domain strategy, which enhances robustness to intra-domain variations within the unknown domain. Furthermore, we extend the self-supervised contrastive objective and semantic clustering loss to better guide the training process. Finally, we introduce a clustering-difficulty-aware resampling technique to adaptively focus on harder-to-cluster categories, further enhancing model performance. Extensive experiments demonstrate that our method effectively mitigates the impact of distributional shifts across various benchmark datasets and achieves superior performance in discovering both known and unknown categories.</li>
</ul>

<h3>Title: Bayesian Network Structure Discovery Using Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Yinghuan Zhang, Yufei Zhang, Parisa Kordjamshidi, Zijun Cui</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.00574">https://arxiv.org/abs/2511.00574</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.00574">https://arxiv.org/pdf/2511.00574</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.00574]] Bayesian Network Structure Discovery Using Large Language Models(https://arxiv.org/abs/2511.00574)</code><input type="text"></li>
<li><strong>Keywords: </strong>data-free, large language model</a></li>
<li><strong>Abstract: </strong>Understanding probabilistic relationships among variables is crucial for analyzing complex systems. Traditional structure learning methods often require extensive observational data and incur high computational costs. Recent studies have explored using large language models (LLMs) for structure learning, but most treat LLMs as auxiliary tools for pre-processing or post-processing, leaving the core learning process data-driven. In this work, we propose a unified framework for Bayesian network structure discovery that places LLMs at the center, supporting both data-free and data-aware settings. In the data-free case, we introduce \textbf{PromptBN} to query LLMs with metadata and efficiently uncover valid probabilistic relationships. When observational data are available, we introduce \textbf{ReActBN}, which integrates the ReAct reasoning paradigm with structure scores such as the Bayesian Information Criterion (BIC) for iterative refinement. Unlike prior methods that offload refinement to external algorithms, our framework maintains the LLM actively in the loop throughout the discovery process. Experiments demonstrate that our method significantly outperforms both existing LLM-based approaches and traditional data-driven algorithms, particularly in the low- or no-data scenario. Code is publicly available at {\texttt{\textcolor{magenta}{this https URL}}}.</li>
</ul>

<h3>Title: FlashEVA: Accelerating LLM inference via Efficient Attention</h3>
<ul>
<li><strong>Authors: </strong>Juan Gabriel Kostelec, Qinghai Guo</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.00576">https://arxiv.org/abs/2511.00576</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.00576">https://arxiv.org/pdf/2511.00576</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.00576]] FlashEVA: Accelerating LLM inference via Efficient Attention(https://arxiv.org/abs/2511.00576)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Transformer models have revolutionized natural language processing, achieving state-of-the-art performance and demonstrating remarkable scalability. However, their memory demands, particularly due to maintaining full context in memory, pose significant challenges for inference. In this paper, we present FlashEVA, an efficient implementation of EVA (Efficient Attention via Control Variates), and demonstrate how to finetune transformers to adapt to FlashEVA attention. Our method enables fine-tuning of Transformer models with as few as 1.5B tokens while preserving effectiveness across various downstream tasks. Notably, FlashEVA achieves up to 6.7x higher throughput and 5x lower peak GPU memory usage during inference compared to standard Transformer implementations. Despite these improvements, we observe limitations in retrieval-focused tasks. Our implementation offers control over the trade-off between throughput and accuracy through adjustable hyperparameters, providing flexibility for diverse use cases. This work represents a significant step towards more efficient and adaptable Transformer-based models for inference.</li>
</ul>

<h3>Title: TRACES: Temporal Recall with Contextual Embeddings for Real-Time Video Anomaly Detection</h3>
<ul>
<li><strong>Authors: </strong>Yousuf Ahmed Siddiqui, Sufiyaan Usmani, Umer Tariq, Jawwad Ahmed Shamsi, Muhammad Burhan Khan</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.00580">https://arxiv.org/abs/2511.00580</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.00580">https://arxiv.org/pdf/2511.00580</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.00580]] TRACES: Temporal Recall with Contextual Embeddings for Real-Time Video Anomaly Detection(https://arxiv.org/abs/2511.00580)</code><input type="text"></li>
<li><strong>Keywords: </strong>explainability</a></li>
<li><strong>Abstract: </strong>Video anomalies often depend on contextual information available and temporal evolution. Non-anomalous action in one context can be anomalous in some other context. Most anomaly detectors, however, do not notice this type of context, which seriously limits their capability to generalize to new, real-life situations. Our work addresses the context-aware zero-shot anomaly detection challenge, in which systems need to learn adaptively to detect new events by correlating temporal and appearance features with textual traces of memory in real time. Our approach defines a memory-augmented pipeline, correlating temporal signals with visual embeddings using cross-attention, and real-time zero-shot anomaly classification by contextual similarity scoring. We achieve 90.4\% AUC on UCF-Crime and 83.67\% AP on XD-Violence, a new state-of-the-art among zero-shot models. Our model achieves real-time inference with high precision and explainability for deployment. We show that, by fusing cross-attention temporal fusion and contextual memory, we achieve high fidelity anomaly detection, a step towards the applicability of zero-shot models in real-world surveillance and infrastructure monitoring.</li>
</ul>

<h3>Title: Diagnosing Hallucination Risk in AI Surgical Decision-Support: A Sequential Framework for Sequential Validation</h3>
<ul>
<li><strong>Authors: </strong>Dong Chen, Yanzhe Wei, Zonglin He, Guan-Ming Kuang, Canhua Ye, Meiru An, Huili Peng, Yong Hu, Huiren Tao, Kenneth MC Cheung</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CY</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.00588">https://arxiv.org/abs/2511.00588</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.00588">https://arxiv.org/pdf/2511.00588</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.00588]] Diagnosing Hallucination Risk in AI Surgical Decision-Support: A Sequential Framework for Sequential Validation(https://arxiv.org/abs/2511.00588)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, interpretability, large language model</a></li>
<li><strong>Abstract: </strong>Large language models (LLMs) offer transformative potential for clinical decision support in spine surgery but pose significant risks through hallucinations, which are factually inconsistent or contextually misaligned outputs that may compromise patient safety. This study introduces a clinician-centered framework to quantify hallucination risks by evaluating diagnostic precision, recommendation quality, reasoning robustness, output coherence, and knowledge alignment. We assessed six leading LLMs across 30 expert-validated spinal cases. DeepSeek-R1 demonstrated superior overall performance (total score: 86.03 $\pm$ 2.08), particularly in high-stakes domains such as trauma and infection. A critical finding reveals that reasoning-enhanced model variants did not uniformly outperform standard counterparts: Claude-3.7-Sonnet's extended thinking mode underperformed relative to its standard version (80.79 $\pm$ 1.83 vs. 81.56 $\pm$ 1.92), indicating extended chain-of-thought reasoning alone is insufficient for clinical reliability. Multidimensional stress-testing exposed model-specific vulnerabilities, with recommendation quality degrading by 7.4% under amplified complexity. This decline contrasted with marginal improvements in rationality (+2.0%), readability (+1.7%) and diagnosis (+4.7%), highlighting a concerning divergence between perceived coherence and actionable guidance. Our findings advocate integrating interpretability mechanisms (e.g., reasoning chain visualization) into clinical workflows and establish a safety-aware validation framework for surgical LLM deployment.</li>
</ul>

<h3>Title: OpenSIR: Open-Ended Self-Improving Reasoner</h3>
<ul>
<li><strong>Authors: </strong>Wai-Chung Kwan, Joshua Ong Jun Leang, Pavlos Vougiouklis, Jeff Z. Pan, Marco Valentino, Pasquale Minervini</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.00602">https://arxiv.org/abs/2511.00602</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.00602">https://arxiv.org/pdf/2511.00602</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.00602]] OpenSIR: Open-Ended Self-Improving Reasoner(https://arxiv.org/abs/2511.00602)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Recent advances in large language model (LLM) reasoning through reinforcement learning rely on annotated datasets for verifiable rewards, which may limit models' ability to surpass human-level performance. While self-play offers a promising alternative, existing approaches depend on external verifiers or cannot learn open-endedly. We present Open-Ended Self-Improving Reasoner (OpenSIR), a self-play framework where an LLM learns to generate and solve novel problems by alternating teacher and student roles without external supervision. To generate novel problems, OpenSIR optimises for both difficulty and diversity, rewarding problems that challenge appropriately while exploring distinct concepts, enabling open-ended mathematical discovery. Starting from a single trivial seed problem, OpenSIR substantially improves instruction models: Llama-3.2-3B-Instruct advances from 73.9 to 78.3 on GSM8K, and from 28.8 to 34.4 on College Math, while Gemma-2-2B-Instruct rises from 38.5 to 58.7 on GSM8K. Our analyses reveal that OpenSIR achieves open-ended learning through co-evolving teacher-student roles that adaptively calibrate difficulty and drive diverse exploration, progressing autonomously from basic to advanced mathematics.</li>
</ul>

<h3>Title: SpecDiff-2: Scaling Diffusion Drafter Alignment For Faster Speculative Decoding</h3>
<ul>
<li><strong>Authors: </strong>Jameson Sandler, Jacob K. Christopher, Thomas Hartvigsen, Nando Fioretto</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.00606">https://arxiv.org/abs/2511.00606</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.00606">https://arxiv.org/pdf/2511.00606</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.00606]] SpecDiff-2: Scaling Diffusion Drafter Alignment For Faster Speculative Decoding(https://arxiv.org/abs/2511.00606)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, large language model</a></li>
<li><strong>Abstract: </strong>Speculative decoding has become the standard approach for accelerating Large Language Model (LLM) inference. It exploits a lossless draft-then-verify procedure to circumvent the latency of autoregressive decoding, achieving impressive speed-ups. Yet, current speculative decoding approaches remain limited by two fundamental bottlenecks: (1) the autoregressive dependency during drafting which limits parallelism, and (2) frequent rejections of draft tokens caused by misalignment between the draft and verify models. This paper proposes SpecDiff-2, a novel framework to jointly address these two bottlenecks. It leverages discrete diffusion as a non-autoregressive drafter to address bottleneck (1) and develops novel techniques to calibrate discrete diffusion drafters with autoregressive verifiers, addressing bottleneck (2). Experimental results across a comprehensive benchmark suite show that SpecDiff-2 achieves a new state-of-the-art across reasoning, coding, and mathematical benchmarks, improving tokens-per-second by up to an average of +55% over previous baselines and obtaining up to 5.5x average speed-up over standard decoding, without any loss of accuracy.</li>
</ul>

<h3>Title: CueBench: Advancing Unified Understanding of Context-Aware Video Anomalies in Real-World</h3>
<ul>
<li><strong>Authors: </strong>Yating Yu, Congqi Cao, Zhaoying Wang, Weihua Meng, Jie Li, Yuxin Li, Zihao Wei, Zhongpei Shen, Jiajun Zhang</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.00613">https://arxiv.org/abs/2511.00613</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.00613">https://arxiv.org/pdf/2511.00613</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.00613]] CueBench: Advancing Unified Understanding of Context-Aware Video Anomalies in Real-World(https://arxiv.org/abs/2511.00613)</code><input type="text"></li>
<li><strong>Keywords: </strong>fair, generative</a></li>
<li><strong>Abstract: </strong>How far are deep models from real-world video anomaly understanding (VAU)? Current works typically emphasize on detecting unexpected occurrences deviated from normal patterns or comprehending anomalous events with interpretable descriptions. However, they exhibit only a superficial comprehension of real-world anomalies, with limited breadth in complex principles and subtle context that distinguish the anomalies from normalities, e.g., climbing cliffs with safety gear vs. without it. To this end, we introduce CueBench, the first of its kind Benchmark, devoted to Context-aware video anomalies within a Unified Evaluation framework. We comprehensively establish an event-centric hierarchical taxonomy that anchors two core event types: 14 conditional and 18 absolute anomaly events, defined by their refined semantics from diverse contexts across 174 scenes and 198 attributes. Based on this, we propose to unify and benchmark context-aware VAU with various challenging tasks across recognition, temporal grounding, detection, and anticipation. This also serves as a rigorous and fair probing evaluation suite for generative-discriminative as well as generalized-specialized vision-language models (VLMs). To address the challenges underlying CueBench, we further develop Cue-R1 based on R1-style reinforcement fine-tuning with verifiable, task-aligned, and hierarchy-refined rewards in a unified generative manner. Extensive results on CueBench reveal that, existing VLMs are still far from satisfactory real-world anomaly understanding, while our Cue-R1 surpasses these state-of-the-art approaches by over 24% on average.</li>
</ul>

<h3>Title: Belief Dynamics Reveal the Dual Nature of In-Context Learning and Activation Steering</h3>
<ul>
<li><strong>Authors: </strong>Eric Bigelow, Daniel Wurgaft, YingQiao Wang, Noah Goodman, Tomer Ullman, Hidenori Tanaka, Ekdeep Singh Lubana</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CL, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.00617">https://arxiv.org/abs/2511.00617</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.00617">https://arxiv.org/pdf/2511.00617</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.00617]] Belief Dynamics Reveal the Dual Nature of In-Context Learning and Activation Steering(https://arxiv.org/abs/2511.00617)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large language models (LLMs) can be controlled at inference time through prompts (in-context learning) and internal activations (activation steering). Different accounts have been proposed to explain these methods, yet their common goal of controlling model behavior raises the question of whether these seemingly disparate methodologies can be seen as specific instances of a broader framework. Motivated by this, we develop a unifying, predictive account of LLM control from a Bayesian perspective. Specifically, we posit that both context- and activation-based interventions impact model behavior by altering its belief in latent concepts: steering operates by changing concept priors, while in-context learning leads to an accumulation of evidence. This results in a closed-form Bayesian model that is highly predictive of LLM behavior across context- and activation-based interventions in a set of domains inspired by prior work on many-shot in-context learning. This model helps us explain prior empirical phenomena - e.g., sigmoidal learning curves as in-context evidence accumulates - while predicting novel ones - e.g., additivity of both interventions in log-belief space, which results in distinct phases such that sudden and dramatic behavioral shifts can be induced by slightly changing intervention controls. Taken together, this work offers a unified account of prompt-based and activation-based control of LLM behavior, and a methodology for empirically predicting the effects of these interventions.</li>
</ul>

<h3>Title: Certain but not Probable? Differentiating Certainty from Probability in LLM Token Outputs for Probabilistic Scenarios</h3>
<ul>
<li><strong>Authors: </strong>Autumn Toney-Wails, Ryan Wails</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.00620">https://arxiv.org/abs/2511.00620</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.00620">https://arxiv.org/pdf/2511.00620</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.00620]] Certain but not Probable? Differentiating Certainty from Probability in LLM Token Outputs for Probabilistic Scenarios(https://arxiv.org/abs/2511.00620)</code><input type="text"></li>
<li><strong>Keywords: </strong>fair, large language model</a></li>
<li><strong>Abstract: </strong>Reliable uncertainty quantification (UQ) is essential for ensuring trustworthy downstream use of large language models, especially when they are deployed in decision-support and other knowledge-intensive applications. Model certainty can be estimated from token logits, with derived probability and entropy values offering insight into performance on the prompt task. However, this approach may be inadequate for probabilistic scenarios, where the probabilities of token outputs are expected to align with the theoretical probabilities of the possible outcomes. We investigate the relationship between token certainty and alignment with theoretical probability distributions in well-defined probabilistic scenarios. Using GPT-4.1 and DeepSeek-Chat, we evaluate model responses to ten prompts involving probability (e.g., roll a six-sided die), both with and without explicit probability cues in the prompt (e.g., roll a fair six-sided die). We measure two dimensions: (1) response validity with respect to scenario constraints, and (2) alignment between token-level output probabilities and theoretical probabilities. Our results indicate that, while both models achieve perfect in-domain response accuracy across all prompt scenarios, their token-level probability and entropy values consistently diverge from the corresponding theoretical distributions.</li>
</ul>

<h3>Title: Grounding Surgical Action Triplets with Instrument Instance Segmentation: A Dataset and Target-Aware Fusion Approach</h3>
<ul>
<li><strong>Authors: </strong>Oluwatosin Alabi, Meng Wei, Charlie Budd, Tom Vercauteren, Miaojing Shi</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.00643">https://arxiv.org/abs/2511.00643</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.00643">https://arxiv.org/pdf/2511.00643</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.00643]] Grounding Surgical Action Triplets with Instrument Instance Segmentation: A Dataset and Target-Aware Fusion Approach(https://arxiv.org/abs/2511.00643)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, segmentation</a></li>
<li><strong>Abstract: </strong>Understanding surgical instrument-tissue interactions requires not only identifying which instrument performs which action on which anatomical target, but also grounding these interactions spatially within the surgical scene. Existing surgical action triplet recognition methods are limited to learning from frame-level classification, failing to reliably link actions to specific instrument this http URL attempts at spatial grounding have primarily relied on class activation maps, which lack the precision and robustness required for detailed instrument-tissue interaction this http URL address this gap, we propose grounding surgical action triplets with instrument instance segmentation, or triplet segmentation for short, a new unified task which produces spatially grounded <instrument, verb, target> this http URL start by presenting CholecTriplet-Seg, a large-scale dataset containing over 30,000 annotated frames, linking instrument instance masks with action verb and anatomical target annotations, and establishing the first benchmark for strongly supervised, instance-level triplet grounding and this http URL learn triplet segmentation, we propose TargetFusionNet, a novel architecture that extends Mask2Former with a target-aware fusion mechanism to address the challenge of accurate anatomical target prediction by fusing weak anatomy priors with instrument instance this http URL across recognition, detection, and triplet segmentation metrics, TargetFusionNet consistently improves performance over existing baselines, demonstrating that strong instance supervision combined with weak target priors significantly enhances the accuracy and robustness of surgical action this http URL segmentation establishes a unified framework for spatially grounding surgical action triplets. The proposed benchmark and architecture pave the way for more interpretable, surgical scene understanding.</li>
</ul>

<h3>Title: Diluting Restricted Boltzmann Machines</h3>
<ul>
<li><strong>Authors: </strong>C. Díaz-Faloh, R. Mulet</a></li>
<li><strong>Subjects: </strong>cs.LG, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.00648">https://arxiv.org/abs/2511.00648</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.00648">https://arxiv.org/pdf/2511.00648</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.00648]] Diluting Restricted Boltzmann Machines(https://arxiv.org/abs/2511.00648)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>Recent advances in artificial intelligence have relied heavily on increasingly large neural networks, raising concerns about their computational and environmental costs. This paper investigates whether simpler, sparser networks can maintain strong performance by studying Restricted Boltzmann Machines (RBMs) under extreme pruning conditions. Inspired by the Lottery Ticket Hypothesis, we demonstrate that RBMs can achieve high-quality generative performance even when up to 80% of the connections are pruned before training, confirming that they contain viable sub-networks. However, our experiments reveal crucial limitations: trained networks cannot fully recover lost performance through retraining once additional pruning is applied. We identify a sharp transition above which the generative quality degrades abruptly when pruning disrupts a minimal core of essential connections. Moreover, re-trained networks remain constrained by the parameters originally learned performing worse than networks trained from scratch at equivalent sparsity levels. These results suggest that for sparse networks to work effectively, pruning should be implemented early in training rather than attempted afterwards. Our findings provide practical insights for the development of efficient neural architectures and highlight the persistent influence of initial conditions on network capabilities.</li>
</ul>

<h3>Title: Benchmarking individual tree segmentation using multispectral airborne laser scanning data: the FGI-EMIT dataset</h3>
<ul>
<li><strong>Authors: </strong>Lassi Ruoppa, Tarmo Hietala, Verneri Seppänen, Josef Taher, Teemu Hakala, Xiaowei Yu, Antero Kukko, Harri Kaartinen, Juha Hyyppä</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.00653">https://arxiv.org/abs/2511.00653</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.00653">https://arxiv.org/pdf/2511.00653</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.00653]] Benchmarking individual tree segmentation using multispectral airborne laser scanning data: the FGI-EMIT dataset(https://arxiv.org/abs/2511.00653)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>Individual tree segmentation (ITS) from LiDAR point clouds is fundamental for applications such as forest inventory, carbon monitoring and biodiversity assessment. Traditionally, ITS has been achieved with unsupervised geometry-based algorithms, while more recent advances have shifted toward supervised deep learning (DL). In the past, progress in method development was hindered by the lack of large-scale benchmark datasets, and the availability of novel data formats, particularly multispectral (MS) LiDAR, remains limited to this day, despite evidence that MS reflectance can improve the accuracy of ITS. This study introduces FGI-EMIT, the first large-scale MS airborne laser scanning benchmark dataset for ITS. Captured at wavelengths 532, 905, and 1,550 nm, the dataset consists of 1,561 manually annotated trees, with a particular focus on small understory trees. Using FGI-EMIT, we comprehensively benchmarked four conventional unsupervised algorithms and four supervised DL approaches. Hyperparameters of unsupervised methods were optimized using a Bayesian approach, while DL models were trained from scratch. Among the unsupervised methods, Treeiso achieved the highest test set F1-score of 52.7%. The DL approaches performed significantly better overall, with the best model, ForestFormer3D, attaining an F1-score of 73.3%. The most significant difference was observed in understory trees, where ForestFormer3D exceeded Treeiso by 25.9 percentage points. An ablation study demonstrated that current DL-based approaches generally fail to leverage MS reflectance information when it is provided as additional input features, although single channel reflectance can improve accuracy marginally, especially for understory trees. A performance analysis across point densities further showed that DL methods consistently remain superior to unsupervised algorithms, even at densities as low as 10 points/m$^2$.</li>
</ul>

<h3>Title: Reviving Stale Updates: Data-Free Knowledge Distillation for Asynchronous Federated Learning</h3>
<ul>
<li><strong>Authors: </strong>Baris Askin, Holger R. Roth, Zhenyu Sun, Carlee Joe-Wong, Gauri Joshi, Ziyue Xu</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.00655">https://arxiv.org/abs/2511.00655</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.00655">https://arxiv.org/pdf/2511.00655</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.00655]] Reviving Stale Updates: Data-Free Knowledge Distillation for Asynchronous Federated Learning(https://arxiv.org/abs/2511.00655)</code><input type="text"></li>
<li><strong>Keywords: </strong>federate, data-free</a></li>
<li><strong>Abstract: </strong>Federated Learning (FL) enables collaborative model training across distributed clients without sharing raw data, yet its scalability is limited by synchronization overhead. Asynchronous Federated Learning (AFL) alleviates this issue by allowing clients to communicate independently, thereby improving wall-clock efficiency in large-scale, heterogeneous environments. However, this asynchrony introduces stale updates (client updates computed on outdated global models) that can destabilize optimization and hinder convergence. We propose FedRevive, an asynchronous FL framework that revives stale updates through data-free knowledge distillation (DFKD). FedRevive integrates parameter-space aggregation with a lightweight, server-side DFKD process that transfers knowledge from stale client models to the current global model without access to real or public data. A meta-learned generator synthesizes pseudo-samples, which enables multi-teacher distillation. A hybrid aggregation scheme that combines raw updates with DFKD updates effectively mitigates staleness while retaining the scalability of AFL. Experiments on various vision and text benchmarks show that FedRevive achieves faster training up to 32.1% and higher final accuracy up to 21.5% compared to asynchronous baselines.</li>
</ul>

<h3>Title: Do You Know About My Nation? Investigating Multilingual Language Models' Cultural Literacy Through Factual Knowledge</h3>
<ul>
<li><strong>Authors: </strong>Eshaan Tanwar, Anwoy Chatterjee, Michael Saxon, Alon Albalak, William Yang Wang, Tanmoy Chakraborty</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.00657">https://arxiv.org/abs/2511.00657</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.00657">https://arxiv.org/pdf/2511.00657</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.00657]] Do You Know About My Nation? Investigating Multilingual Language Models' Cultural Literacy Through Factual Knowledge(https://arxiv.org/abs/2511.00657)</code><input type="text"></li>
<li><strong>Keywords: </strong>fair</a></li>
<li><strong>Abstract: </strong>Most multilingual question-answering benchmarks, while covering a diverse pool of languages, do not factor in regional diversity in the information they capture and tend to be Western-centric. This introduces a significant gap in fairly evaluating multilingual models' comprehension of factual information from diverse geographical locations. To address this, we introduce XNationQA for investigating the cultural literacy of multilingual LLMs. XNationQA encompasses a total of 49,280 questions on the geography, culture, and history of nine countries, presented in seven languages. We benchmark eight standard multilingual LLMs on XNationQA and evaluate them using two novel transference metrics. Our analyses uncover a considerable discrepancy in the models' accessibility to culturally specific facts across languages. Notably, we often find that a model demonstrates greater knowledge of cultural information in English than in the dominant language of the respective culture. The models exhibit better performance in Western languages, although this does not necessarily translate to being more literate for Western countries, which is counterintuitive. Furthermore, we observe that models have a very limited ability to transfer knowledge across languages, particularly evident in open-source models.</li>
</ul>

<h3>Title: Sensitivity Analysis for Climate Science with Generative Flow Models</h3>
<ul>
<li><strong>Authors: </strong>Alex Dobra, Jakiw Pidstrigach, Tim Reichelt, Paolo Fraccaro, Johannes Jakubik, Anne Jones, Christian Schroeder de Witt, Philip Stier, Philip Torr</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.00663">https://arxiv.org/abs/2511.00663</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.00663">https://arxiv.org/pdf/2511.00663</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.00663]] Sensitivity Analysis for Climate Science with Generative Flow Models(https://arxiv.org/abs/2511.00663)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, generative</a></li>
<li><strong>Abstract: </strong>Sensitivity analysis is a cornerstone of climate science, essential for understanding phenomena ranging from storm intensity to long-term climate feedbacks. However, computing these sensitivities using traditional physical models is often prohibitively expensive in terms of both computation and development time. While modern AI-based generative models are orders of magnitude faster to evaluate, computing sensitivities with them remains a significant bottleneck. This work addresses this challenge by applying the adjoint state method for calculating gradients in generative flow models, with diffusion models as a special case. We apply this method to the cBottle generative model, an emulator of ERA5 data, to perform sensitivity analysis with respect to sea surface temperatures. Furthermore, we propose a novel gradient self-consistency check to quantitatively validate the computed sensitivities against the model's own outputs. Our results provide initial evidence that this approach can produce reliable gradients, reducing the computational cost of sensitivity analysis from weeks on a supercomputer with a physical model to hours on a GPU, thereby simplifying a critical workflow in climate science.</li>
</ul>

<h3>Title: ShadowLogic: Backdoors in Any Whitebox LLM</h3>
<ul>
<li><strong>Authors: </strong>Kasimir Schulz, Amelia Kawasaki, Leo Ring</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.00664">https://arxiv.org/abs/2511.00664</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.00664">https://arxiv.org/pdf/2511.00664</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.00664]] ShadowLogic: Backdoors in Any Whitebox LLM(https://arxiv.org/abs/2511.00664)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, attack, large language model</a></li>
<li><strong>Abstract: </strong>Large language models (LLMs) are widely deployed across various applications, often with safeguards to prevent the generation of harmful or restricted content. However, these safeguards can be covertly bypassed through adversarial modifications to the computational graph of a model. This work highlights a critical security vulnerability in computational graph-based LLM formats, demonstrating that widely used deployment pipelines may be susceptible to obscured backdoors. We introduce ShadowLogic, a method for creating a backdoor in a white-box LLM by injecting an uncensoring vector into its computational graph representation. We set a trigger phrase that, when added to the beginning of a prompt into the LLM, applies the uncensoring vector and removes the content generation safeguards in the model. We embed trigger logic directly into the computational graph which detects the trigger phrase in a prompt. To evade detection of our backdoor, we obfuscate this logic within the graph structure, making it similar to standard model functions. Our method requires minimal alterations to model parameters, making backdoored models appear benign while retaining the ability to generate uncensored responses when activated. We successfully implement ShadowLogic in Phi-3 and Llama 3.2, using ONNX for manipulating computational graphs. Implanting the uncensoring vector achieved a >60% attack success rate for further malicious queries.</li>
</ul>

<h3>Title: Evolve to Inspire: Novelty Search for Diverse Image Generation</h3>
<ul>
<li><strong>Authors: </strong>Alex Inch, Passawis Chaiyapattanaporn, Yuchen Zhu, Yuan Lu, Ting-Wen Ko, Davide Paglieri</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.00686">https://arxiv.org/abs/2511.00686</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.00686">https://arxiv.org/pdf/2511.00686</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.00686]] Evolve to Inspire: Novelty Search for Diverse Image Generation(https://arxiv.org/abs/2511.00686)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, large language model</a></li>
<li><strong>Abstract: </strong>Text-to-image diffusion models, while proficient at generating high-fidelity im- ages, often suffer from limited output diversity, hindering their application in exploratory and ideation tasks. Existing prompt optimization techniques typically target aesthetic fitness or are ill-suited to the creative visual domain. To address this shortcoming, we introduce WANDER, a novelty search-based approach to generating diverse sets of images from a single input prompt. WANDER operates directly on natural language prompts, employing a Large Language Model (LLM) for semantic evolution of diverse sets of images, and using CLIP embeddings to quantify novelty. We additionally apply emitters to guide the search into distinct regions of the prompt space, and demonstrate that they boost the diversity of the generated images. Empirical evaluations using FLUX-DEV for generation and GPT-4o-mini for mutation demonstrate that WANDER significantly outperforms existing evolutionary prompt optimization baselines in diversity metrics. Ablation studies confirm the efficacy of emitters.</li>
</ul>

<h3>Title: Do Methods to Jailbreak and Defend LLMs Generalize Across Languages?</h3>
<ul>
<li><strong>Authors: </strong>Berk Atil, Rebecca J. Passonneau, Fred Morstatter</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.00689">https://arxiv.org/abs/2511.00689</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.00689">https://arxiv.org/pdf/2511.00689</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.00689]] Do Methods to Jailbreak and Defend LLMs Generalize Across Languages?(https://arxiv.org/abs/2511.00689)</code><input type="text"></li>
<li><strong>Keywords: </strong>defense, attack, robust, large language model</a></li>
<li><strong>Abstract: </strong>Large language models (LLMs) undergo safety alignment after training and tuning, yet recent work shows that safety can be bypassed through jailbreak attacks. While many jailbreaks and defenses exist, their cross-lingual generalization remains underexplored. This paper presents the first systematic multilingual evaluation of jailbreaks and defenses across ten languages--spanning high-, medium-, and low-resource languages--using six LLMs on HarmBench and AdvBench. We assess two jailbreak types: logical-expression-based and adversarial-prompt-based. For both types, attack success and defense robustness vary across languages: high-resource languages are safer under standard queries but more vulnerable to adversarial ones. Simple defenses can be effective, but are language- and model-dependent. These findings call for language-aware and cross-lingual safety benchmarks for LLMs.</li>
</ul>

<h3>Title: Inference-Time Chain-of-Thought Pruning with Latent Informativeness Signals</h3>
<ul>
<li><strong>Authors: </strong>Sophie Li (1), Nicholas Huang (2), Nayan Saxena (3), Nina Luo (4), Vincent Lin (5), Kevin Zhu (3), Sunishchal Dev (3) ((1) Columbia University, (2) University of British Columbia, (3) Algoverse AI Research, (4) Harvey Mudd College, (5) University of Florida)</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.00699">https://arxiv.org/abs/2511.00699</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.00699">https://arxiv.org/pdf/2511.00699</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.00699]] Inference-Time Chain-of-Thought Pruning with Latent Informativeness Signals(https://arxiv.org/abs/2511.00699)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large language models (LLMs) improve reasoning accuracy when generating multiple candidate solutions at test time, but standard methods like Best-of-N (BoN) incur high computational cost by fully generating all branches. Self-Truncation Best-of-N (ST-BoN) mitigates this by truncating unpromising paths early, but its reliance on consistency-based heuristics is a limitation as it does not directly evaluate branch quality. We present KL-Adjusted Pruned Path Algorithm (KAPPA), an inference-time method that combines Kullback-Leibler divergence, confidence, and entropy into a principled scoring function to guide progressive pruning. By promoting diversity during exploration and selectively eliminating low-scoring branches, KAPPA maintains accuracy while substantially reducing memory and token usage. Experiments on GSM8K and MATH500 with DeepSeek-R1-Distill-Qwen-1.5B and Qwen2.5-7B-Instruct demonstrate that KAPPA stabilizes performance in smaller models and achieves up to ~60% reduction in peak memory and ~90% reduction in total token generation relative to BoN, with minimal impact on accuracy.</li>
</ul>

<h3>Title: Privacy-Aware Time Series Synthesis via Public Knowledge Distillation</h3>
<ul>
<li><strong>Authors: </strong>Penghang Liu, Haibei Zhu, Eleonora Kreacic, Svitlana Vyetrenko</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.00700">https://arxiv.org/abs/2511.00700</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.00700">https://arxiv.org/pdf/2511.00700</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.00700]] Privacy-Aware Time Series Synthesis via Public Knowledge Distillation(https://arxiv.org/abs/2511.00700)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, diffusion</a></li>
<li><strong>Abstract: </strong>Sharing sensitive time series data in domains such as finance, healthcare, and energy consumption, such as patient records or investment accounts, is often restricted due to privacy concerns. Privacy-aware synthetic time series generation addresses this challenge by enforcing noise during training, inherently introducing a trade-off between privacy and utility. In many cases, sensitive sequences is correlated with publicly available, non-sensitive contextual metadata (e.g., household electricity consumption may be influenced by weather conditions and electricity prices). However, existing privacy-aware data generation methods often overlook this opportunity, resulting in suboptimal privacy-utility trade-offs. In this paper, we present Pub2Priv, a novel framework for generating private time series data by leveraging heterogeneous public knowledge. Our model employs a self-attention mechanism to encode public data into temporal and feature embeddings, which serve as conditional inputs for a diffusion model to generate synthetic private sequences. Additionally, we introduce a practical metric to assess privacy by evaluating the identifiability of the synthetic data. Experimental results show that Pub2Priv consistently outperforms state-of-the-art benchmarks in improving the privacy-utility trade-off across finance, energy, and commodity trading domains.</li>
</ul>

<h3>Title: Investigating the Robustness of Knowledge Tracing Models in the Presence of Student Concept Drift</h3>
<ul>
<li><strong>Authors: </strong>Morgan Lee, Artem Frenk, Eamon Worden, Karish Gupta, Thinh Pham, Ethan Croteau, Neil Heffernan</a></li>
<li><strong>Subjects: </strong>cs.LG, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.00704">https://arxiv.org/abs/2511.00704</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.00704">https://arxiv.org/pdf/2511.00704</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.00704]] Investigating the Robustness of Knowledge Tracing Models in the Presence of Student Concept Drift(https://arxiv.org/abs/2511.00704)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Knowledge Tracing (KT) has been an established problem in the educational data mining field for decades, and it is commonly assumed that the underlying learning process be- ing modeled remains static. Given the ever-changing land- scape of online learning platforms (OLPs), we investigate how concept drift and changing student populations can im- pact student behavior within an OLP through testing model performance both within a single academic year and across multiple academic years. Four well-studied KT models were applied to five academic years of data to assess how suscep- tible KT models are to concept drift. Through our analysis, we find that all four families of KT models can exhibit de- graded performance, Bayesian Knowledge Tracing (BKT) remains the most stable KT model when applied to newer data, while more complex, attention based models lose pre- dictive power significantly faster. To foster more longitu- dinal evaluations of KT models, the data used to conduct our analysis is available at this https URL only=b936c63dfdae4b0b987a2f0d4038f72a</li>
</ul>

<h3>Title: TRISKELION-1: Unified Descriptive-Predictive-Generative AI</h3>
<ul>
<li><strong>Authors: </strong>Nardeep Kumar, Arun Kanwar</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.00711">https://arxiv.org/abs/2511.00711</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.00711">https://arxiv.org/pdf/2511.00711</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.00711]] TRISKELION-1: Unified Descriptive-Predictive-Generative AI(https://arxiv.org/abs/2511.00711)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability, generative</a></li>
<li><strong>Abstract: </strong>TRISKELION-1 is a unified descriptive-predictive-generative architecture that integrates statistical, mechanistic, and generative reasoning within a single encoder-decoder framework. The model demonstrates how descriptive representation learning, predictive inference, and generative synthesis can be jointly optimized using variational objectives. Experiments on MNIST validate that descriptive reconstruction, predictive classification, and generative sampling can coexist stably within one model. The framework provides a blueprint toward universal intelligence architectures that connect interpretability, accuracy, and creativity.</li>
</ul>

<h3>Title: Validating Deep Models for Alzheimer's 18F-FDG PET Diagnosis Across Populations: A Study with Latin American Data</h3>
<ul>
<li><strong>Authors: </strong>Hugo Massaroli, Hernan Chaves, Pilar Anania, Mauricio Farez, Emmanuel Iarussi, Viviana Siless</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.00728">https://arxiv.org/abs/2511.00728</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.00728">https://arxiv.org/pdf/2511.00728</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.00728]] Validating Deep Models for Alzheimer's 18F-FDG PET Diagnosis Across Populations: A Study with Latin American Data(https://arxiv.org/abs/2511.00728)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Deep learning models have shown strong performance in diagnosing Alzheimer's disease (AD) using neuroimaging data, particularly 18F-FDG PET scans, with training datasets largely composed of North American cohorts such as those in the Alzheimer's Disease Neuroimaging Initiative (ADNI). However, their generalization to underrepresented populations remains underexplored. In this study, we benchmark convolutional and Transformer-based models on the ADNI dataset and assess their generalization performance on a novel Latin American clinical cohort from the FLENI Institute in Buenos Aires, Argentina. We show that while all models achieve high AUCs on ADNI (up to .96, .97), their performance drops substantially on FLENI (down to .82, .80, respectively), revealing a significant domain shift. The tested architectures demonstrated similar performance, calling into question the supposed advantages of transformers for this specific task. Through ablation studies, we identify per-image normalization and a correct sampling selection as key factors for generalization. Occlusion sensitivity analysis further reveals that models trained on ADNI, generally attend to canonical hypometabolic regions for the AD class, but focus becomes unclear for the other classes and for FLENI scans. These findings highlight the need for population-aware validation of diagnostic AI models and motivate future work on domain adaptation and cohort diversification.</li>
</ul>

<h3>Title: EP-HDC: Hyperdimensional Computing with Encrypted Parameters for High-Throughput Privacy-Preserving Inference</h3>
<ul>
<li><strong>Authors: </strong>Jaewoo Park, Chenghao Quan, Jongeun Lee</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.00737">https://arxiv.org/abs/2511.00737</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.00737">https://arxiv.org/pdf/2511.00737</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.00737]] EP-HDC: Hyperdimensional Computing with Encrypted Parameters for High-Throughput Privacy-Preserving Inference(https://arxiv.org/abs/2511.00737)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, protect</a></li>
<li><strong>Abstract: </strong>While homomorphic encryption (HE) provides strong privacy protection, its high computational cost has restricted its application to simple tasks. Recently, hyperdimensional computing (HDC) applied to HE has shown promising performance for privacy-preserving machine learning (PPML). However, when applied to more realistic scenarios such as batch inference, the HDC-based HE has still very high compute time as well as high encryption and data transmission overheads. To address this problem, we propose HDC with encrypted parameters (EP-HDC), which is a novel PPML approach featuring client-side HE, i.e., inference is performed on a client using a homomorphically encrypted model. Our EP-HDC can effectively mitigate the encryption and data transmission overhead, as well as providing high scalability with many clients while providing strong protection for user data and model parameters. In addition to application examples for our client-side PPML, we also present design space exploration involving quantization, architecture, and HE-related parameters. Our experimental results using the BFV scheme and the Face/Emotion datasets demonstrate that our method can improve throughput and latency of batch inference by orders of magnitude over previous PPML methods (36.52~1068x and 6.45~733x, respectively) with less than 1% accuracy degradation.</li>
</ul>

<h3>Title: Effective Series Decomposition and Components Learning for Time Series Generation</h3>
<ul>
<li><strong>Authors: </strong>Zixuan Ma, Chenfeng Huang</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.00747">https://arxiv.org/abs/2511.00747</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.00747">https://arxiv.org/pdf/2511.00747</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.00747]] Effective Series Decomposition and Components Learning for Time Series Generation(https://arxiv.org/abs/2511.00747)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, interpretability, diffusion</a></li>
<li><strong>Abstract: </strong>Time series generation focuses on modeling the underlying data distribution and resampling to produce authentic time series data. Key components, such as trend and seasonality, drive temporal fluctuations, yet many existing approaches fail to employ interpretative decomposition methods, limiting their ability to synthesize meaningful trend and seasonal patterns. To address this gap, we introduce Seasonal-Trend Diffusion (STDiffusion), a novel framework for multivariate time series generation that integrates diffusion probabilistic models with advanced learnable series decomposition techniques, enhancing the interpretability of the generation process. Our approach separates the trend and seasonal learning into distinct blocks: a Multi-Layer Perceptron (MLP) structure captures the trend, while adaptive wavelet distillation facilitates effective multi-resolution learning of seasonal components. This decomposition improves the interpretability of the model on multiple scales. In addition, we designed a comprehensive correction mechanism aimed at ensuring that the generated components exhibit a high degree of internal consistency and preserve meaningful interrelationships with one another. Our empirical studies on eight real-world datasets demonstrate that STDiffusion achieves state-of-the-art performance in time series generation tasks. Furthermore, we extend the model's application to multi-window long-sequence time series generation, which delivered reliable results and highlighted its robustness and versatility.</li>
</ul>

<h3>Title: Erasing 'Ugly' from the Internet: Propagation of the Beauty Myth in Text-Image Models</h3>
<ul>
<li><strong>Authors: </strong>Tanvi Dinkar, Aiqi Jiang, Gavin Abercrombie, Ioannis Konstas</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.00749">https://arxiv.org/abs/2511.00749</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.00749">https://arxiv.org/pdf/2511.00749</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.00749]] Erasing 'Ugly' from the Internet: Propagation of the Beauty Myth in Text-Image Models(https://arxiv.org/abs/2511.00749)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>Social media has exacerbated the promotion of Western beauty norms, leading to negative self-image, particularly in women and girls, and causing harm such as body dysmorphia. Increasingly content on the internet has been artificially generated, leading to concerns that these norms are being exaggerated. The aim of this work is to study how generative AI models may encode 'beauty' and erase 'ugliness', and discuss the implications of this for society. To investigate these aims, we create two image generation pipelines: a text-to-image model and a text-to-language model-to image model. We develop a structured beauty taxonomy which we use to prompt three language models (LMs) and two text-to-image models to cumulatively generate 5984 images using our two pipelines. We then recruit women and non-binary social media users to evaluate 1200 of the images through a Likert-scale within-subjects study. Participants show high agreement in their ratings. Our results show that 86.5% of generated images depicted people with lighter skin tones, 22% contained explicit content despite Safe for Work (SFW) training, and 74% were rated as being in a younger age demographic. In particular, the images of non-binary individuals were rated as both younger and more hypersexualised, indicating troubling intersectional effects. Notably, prompts encoded with 'negative' or 'ugly' beauty traits (such as "a wide nose") consistently produced higher Not SFW (NSFW) ratings regardless of gender. This work sheds light on the pervasive demographic biases related to beauty standards present in generative AI models -- biases that are actively perpetuated by model developers, such as via negative prompting. We conclude by discussing the implications of this on society, which include pollution of the data streams and active erasure of features that do not fall inside the stereotype of what is considered beautiful by developers.</li>
</ul>

<h3>Title: A Hybrid YOLOv5-SSD IoT-Based Animal Detection System for Durian Plantation Protection</h3>
<ul>
<li><strong>Authors: </strong>Anis Suttan Shahrir, Zakiah Ayop, Syarulnaziah Anawar, Norulzahrah Mohd Zainudin</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.00777">https://arxiv.org/abs/2511.00777</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.00777">https://arxiv.org/pdf/2511.00777</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.00777]] A Hybrid YOLOv5-SSD IoT-Based Animal Detection System for Durian Plantation Protection(https://arxiv.org/abs/2511.00777)</code><input type="text"></li>
<li><strong>Keywords: </strong>protect</a></li>
<li><strong>Abstract: </strong>Durian plantation suffers from animal intrusions that cause crop damage and financial loss. The traditional farming practices prove ineffective due to the unavailability of monitoring without human intervention. The fast growth of machine learning and Internet of Things (IoT) technology has led to new ways to detect animals. However, current systems are limited by dependence on single object detection algorithms, less accessible notification platforms, and limited deterrent mechanisms. This research suggests an IoT-enabled animal detection system for durian crops. The system integrates YOLOv5 and SSD object detection algorithms to improve detection accuracy. The system provides real-time monitoring, with detected intrusions automatically reported to farmers via Telegram notifications for rapid response. An automated sound mechanism (e.g., tiger roar) is triggered once the animal is detected. The YOLO+SSD model achieved accuracy rates of elephant, boar, and monkey at 90%, 85% and 70%, respectively. The system shows the highest accuracy in daytime and decreases at night, regardless of whether the image is still or a video. Overall, this study contributes a comprehensive and practical framework that combines detection, notification, and deterrence, paving the way for future innovations in automated farming solutions.</li>
</ul>

<h3>Title: Class-agnostic 3D Segmentation by Granularity-Consistent Automatic 2D Mask Tracking</h3>
<ul>
<li><strong>Authors: </strong>Juan Wang, Yasutomo Kawanishi, Tomo Miyazaki, Zhijie Wang, Shinichiro Omachi</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.00785">https://arxiv.org/abs/2511.00785</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.00785">https://arxiv.org/pdf/2511.00785</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.00785]] Class-agnostic 3D Segmentation by Granularity-Consistent Automatic 2D Mask Tracking(https://arxiv.org/abs/2511.00785)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, segmentation</a></li>
<li><strong>Abstract: </strong>3D instance segmentation is an important task for real-world applications. To avoid costly manual annotations, existing methods have explored generating pseudo labels by transferring 2D masks from foundation models to 3D. However, this approach is often suboptimal since the video frames are processed independently. This causes inconsistent segmentation granularity and conflicting 3D pseudo labels, which degrades the accuracy of final segmentation. To address this, we introduce a Granularity-Consistent automatic 2D Mask Tracking approach that maintains temporal correspondences across frames, eliminating conflicting pseudo labels. Combined with a three-stage curriculum learning framework, our approach progressively trains from fragmented single-view data to unified multi-view annotations, ultimately globally coherent full-scene supervision. This structured learning pipeline enables the model to progressively expose to pseudo-labels of increasing consistency. Thus, we can robustly distill a consistent 3D representation from initially fragmented and contradictory 2D priors. Experimental results demonstrated that our method effectively generated consistent and accurate 3D segmentations. Furthermore, the proposed method achieved state-of-the-art results on standard benchmarks and open-vocabulary ability.</li>
</ul>

<h3>Title: Efficient Reinforcement Learning for Large Language Models with Intrinsic Exploration</h3>
<ul>
<li><strong>Authors: </strong>Yan Sun, Jia Guo, Stanley Kok, Zihao Wang, Zujie Wen, Zhiqiang Zhang</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.00794">https://arxiv.org/abs/2511.00794</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.00794">https://arxiv.org/pdf/2511.00794</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.00794]] Efficient Reinforcement Learning for Large Language Models with Intrinsic Exploration(https://arxiv.org/abs/2511.00794)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Reinforcement learning with verifiable rewards (RLVR) has improved the reasoning ability of large language models, yet training remains costly because many rollouts contribute little to optimization, considering the amount of computation required. This study investigates how simply leveraging intrinsic data properties, almost free benefit during training, can improve data efficiency for RLVR. We propose PREPO with two complementary components. First, we adopt prompt perplexity as an indicator of model adaptability in learning, enabling the model to progress from well-understood contexts to more challenging ones. Second, we amplify the discrepancy among the rollouts by differentiating their relative entropy, and prioritize sequences that exhibit a higher degree of exploration. Together, these mechanisms reduce rollout demand while preserving competitive performance. On the Qwen and Llama models, PREPO achieves effective results on mathematical reasoning benchmarks with up to 3 times fewer rollouts than the baselines. Beyond empirical gains, we provide theoretical and in-depth analyses explaining the underlying rationale of our method to improve the data efficiency of RLVR.</li>
</ul>

<h3>Title: FedOnco-Bench: A Reproducible Benchmark for Privacy-Aware Federated Tumor Segmentation with Synthetic CT Data</h3>
<ul>
<li><strong>Authors: </strong>Viswa Chaitanya Marella, Suhasnadh Reddy Veluru, Sai Teja Erukude</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.00795">https://arxiv.org/abs/2511.00795</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.00795">https://arxiv.org/pdf/2511.00795</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.00795]] FedOnco-Bench: A Reproducible Benchmark for Privacy-Aware Federated Tumor Segmentation with Synthetic CT Data(https://arxiv.org/abs/2511.00795)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, attack, federate, segmentation</a></li>
<li><strong>Abstract: </strong>Federated Learning (FL) allows multiple institutions to cooperatively train machine learning models while retaining sensitive data at the source, which has great utility in privacy-sensitive environments. However, FL systems remain vulnerable to membership-inference attacks and data heterogeneity. This paper presents FedOnco-Bench, a reproducible benchmark for privacy-aware FL using synthetic oncologic CT scans with tumor annotations. It evaluates segmentation performance and privacy leakage across FL methods: FedAvg, FedProx, FedBN, and FedAvg with DP-SGD. Results show a distinct trade-off between privacy and utility: FedAvg is high performance (Dice around 0.85) with more privacy leakage (attack AUC about 0.72), while DP-SGD provides a higher level of privacy (AUC around 0.25) at the cost of accuracy (Dice about 0.79). FedProx and FedBN offer balanced performance under heterogeneous data, especially with non-identical distributed client data. FedOnco-Bench serves as a standardized, open-source platform for benchmarking and developing privacy-preserving FL methods for medical image segmentation.</li>
</ul>

<h3>Title: Attention Saturation and Gradient Suppression at Inflection Layers: Diagnosing and Mitigating Bottlenecks in Transformer Adaptation</h3>
<ul>
<li><strong>Authors: </strong>Wang Zixian</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.00797">https://arxiv.org/abs/2511.00797</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.00797">https://arxiv.org/pdf/2511.00797</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.00797]] Attention Saturation and Gradient Suppression at Inflection Layers: Diagnosing and Mitigating Bottlenecks in Transformer Adaptation(https://arxiv.org/abs/2511.00797)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Pre-trained Transformers often exhibit over-confidence in source patterns and difficulty in forming new target-domain patterns during fine-tuning. We formalize the mechanism of output saturation leading to gradient suppression through standard cross-entropy and softmax analysis, showing that gradient suppression at inflection layers confines adaptation to high-level recombination of existing features while preventing low-level reconstruction. We introduce a set of layer-wise diagnostic metrics -- attention entropy (saturation proxy), activation gradient norm, parameter gradient norm, and Delta-CKA under a shared PCA basis -- to identify inflection layers characterized by both low attention entropy and steep gradient decay. Building on these findings, we propose a diagnose-first, inject-light fine-tuning strategy: selectively inserting LoRA adapters at inflection layers to restore suppressed backward signals with minimal parameter overhead. Experiments on BERT-base transfer from SST-2 to Rotten Tomatoes under under-trained and over-trained source regimes reveal that over-trained initialization benefits from inflection-layer LoRA injection, while under-trained initialization suffers performance degradation. When base features are strong, unblocking inflection layers facilitates high-level compositional adaptation; when base features are weak, full-pathway unblocking is required for low-level reconstruction, as supported by joint analysis of layer-wise activation gradients and Delta-CKA dynamics.</li>
</ul>

<h3>Title: Med-Banana-50K: A Cross-modality Large-Scale Dataset for Text-guided Medical Image Editing</h3>
<ul>
<li><strong>Authors: </strong>Zhihui Chen, Mengling Feng</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.MM</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.00801">https://arxiv.org/abs/2511.00801</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.00801">https://arxiv.org/pdf/2511.00801</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.00801]] Med-Banana-50K: A Cross-modality Large-Scale Dataset for Text-guided Medical Image Editing(https://arxiv.org/abs/2511.00801)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Recent advances in multimodal large language models have enabled remarkable medical image editing capabilities. However, the research community's progress remains constrained by the absence of large-scale, high-quality, and openly accessible datasets built specifically for medical image editing with strict anatomical and clinical constraints. We introduce Med-Banana-50K, a comprehensive 50K-image dataset for instruction-based medical image editing spanning three modalities (chest X-ray, brain MRI, fundus photography) and 23 disease types. Our dataset is constructed by leveraging Gemini-2.5-Flash-Image to generate bidirectional edits (lesion addition and removal) from real medical images. What distinguishes Med-Banana-50K from general-domain editing datasets is our systematic approach to medical quality control: we employ LLM-as-Judge with a medically grounded rubric (instruction compliance, structural plausibility, realism, and fidelity preservation) and history-aware iterative refinement up to five rounds. Beyond single-turn editing, Med-Banana-50K includes 37K failed attempts with full conversation logs for preference learning and alignment research. By providing this large-scale, medically validated, and fully documented resource, Med-Banana-50K establishes a foundation for training and evaluating the next generation of medical image editing this http URL dataset and code are publicly available at [this https URL].</li>
</ul>

<h3>Title: EraseFlow: Learning Concept Erasure Policies via GFlowNet-Driven Alignment</h3>
<ul>
<li><strong>Authors: </strong>Abhiram Kusumba, Maitreya Patel, Kyle Min, Changhoon Kim, Chitta Baral, Yezhou Yang</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.00804">https://arxiv.org/abs/2511.00804</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.00804">https://arxiv.org/pdf/2511.00804</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.00804]] EraseFlow: Learning Concept Erasure Policies via GFlowNet-Driven Alignment(https://arxiv.org/abs/2511.00804)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>Erasing harmful or proprietary concepts from powerful text to image generators is an emerging safety requirement, yet current "concept erasure" techniques either collapse image quality, rely on brittle adversarial losses, or demand prohibitive retraining cycles. We trace these limitations to a myopic view of the denoising trajectories that govern diffusion based generation. We introduce EraseFlow, the first framework that casts concept unlearning as exploration in the space of denoising paths and optimizes it with GFlowNets equipped with the trajectory balance objective. By sampling entire trajectories rather than single end states, EraseFlow learns a stochastic policy that steers generation away from target concepts while preserving the model's prior. EraseFlow eliminates the need for carefully crafted reward models and by doing this, it generalizes effectively to unseen concepts and avoids hackable rewards while improving the performance. Extensive empirical results demonstrate that EraseFlow outperforms existing baselines and achieves an optimal trade off between performance and prior preservation.</li>
</ul>

<h3>Title: GUI-AIMA: Aligning Intrinsic Multimodal Attention with a Context Anchor for GUI Grounding</h3>
<ul>
<li><strong>Authors: </strong>Shijie Zhou, Viet Dac Lai, Hao Tan, Jihyung Kil, Wanrong Zhu, Changyou Chen, Ruiyi Zhang</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI, cs.CL, cs.HC, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.00810">https://arxiv.org/abs/2511.00810</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.00810">https://arxiv.org/pdf/2511.00810</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.00810]] GUI-AIMA: Aligning Intrinsic Multimodal Attention with a Context Anchor for GUI Grounding(https://arxiv.org/abs/2511.00810)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Graphical user interface (GUI) grounding is a key function of computer-use agents, which maps natural-language instructions to actionable screen regions. Existing approaches based on Multimodal Large Language Models (MLLMs) typically formulate it as a text-based coordinate generation task, yet directly generating precise coordinates from visual inputs remains challenging and computationally intensive. An intuitive way to implement GUI grounding is to first select visual patches relevant to the instructions and then determine the precise click location within those patches. Based on the observations that general MLLMs have some native grounding capability, nested within their attentions, we propose GUI-AIMA, an attention-based and coordinate-free supervised fine-tuning framework for efficient GUI grounding. GUI-AIMA aligns the intrinsic multimodal attention of MLLMs with patch-wise grounding signals. These signals are calculated adaptively for diverse user instructions by multi-head aggregation on simplified query-visual attention matrices. Besides, its coordinate-free manner can easily integrate a plug-and-play zoom-in stage. GUI-AIMA-3B was trained with only 85k screenshots, demonstrating exceptional data efficiency and verifying that light training can trigger the native grounding capability of MLLMs. It achieves state-of-the-art performance among 3B models, attaining an average accuracy of 58.6% on ScreenSpot-Pro and 62.2% on OSWorld-G. Project page: this https URL</li>
</ul>

<h3>Title: Equilibrium Policy Generalization: A Reinforcement Learning Framework for Cross-Graph Zero-Shot Generalization in Pursuit-Evasion Games</h3>
<ul>
<li><strong>Authors: </strong>Runyu Lu, Peng Zhang, Ruochuan Shi, Yuanheng Zhu, Dongbin Zhao, Yang Liu, Dong Wang, Cesare Alippi</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.00811">https://arxiv.org/abs/2511.00811</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.00811">https://arxiv.org/pdf/2511.00811</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.00811]] Equilibrium Policy Generalization: A Reinforcement Learning Framework for Cross-Graph Zero-Shot Generalization in Pursuit-Evasion Games(https://arxiv.org/abs/2511.00811)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, robust</a></li>
<li><strong>Abstract: </strong>Equilibrium learning in adversarial games is an important topic widely examined in the fields of game theory and reinforcement learning (RL). Pursuit-evasion game (PEG), as an important class of real-world games from the fields of robotics and security, requires exponential time to be accurately solved. When the underlying graph structure varies, even the state-of-the-art RL methods require recomputation or at least fine-tuning, which can be time-consuming and impair real-time applicability. This paper proposes an Equilibrium Policy Generalization (EPG) framework to effectively learn a generalized policy with robust cross-graph zero-shot performance. In the context of PEGs, our framework is generally applicable to both pursuer and evader sides in both no-exit and multi-exit scenarios. These two generalizability properties, to our knowledge, are the first to appear in this domain. The core idea of the EPG framework is to train an RL policy across different graph structures against the equilibrium policy for each single graph. To construct an equilibrium oracle for single-graph policies, we present a dynamic programming (DP) algorithm that provably generates pure-strategy Nash equilibrium with near-optimal time complexity. To guarantee scalability with respect to pursuer number, we further extend DP and RL by designing a grouping mechanism and a sequence model for joint policy decomposition, respectively. Experimental results show that, using equilibrium guidance and a distance feature proposed for cross-graph PEG training, the EPG framework guarantees desirable zero-shot performance in various unseen real-world graphs. Besides, when trained under an equilibrium heuristic proposed for the graphs with exits, our generalized pursuer policy can even match the performance of the fine-tuned policies from the state-of-the-art PEG methods.</li>
</ul>

<h3>Title: LL-ViT: Edge Deployable Vision Transformers with Look Up Table Neurons</h3>
<ul>
<li><strong>Authors: </strong>Shashank Nag, Alan T.L. Bacellar, Zachary Susskind, Anshul Jha, Logan Liberty, Aishwarya Sivakumar, Eugene B. John, Krishnan Kailas, Priscila M.V. Lima, Neeraja J. Yadwadkar, Felipe M.G. Franca, Lizy K. John</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.00812">https://arxiv.org/abs/2511.00812</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.00812">https://arxiv.org/pdf/2511.00812</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.00812]] LL-ViT: Edge Deployable Vision Transformers with Look Up Table Neurons(https://arxiv.org/abs/2511.00812)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Vision Transformers have been tremendously successful in computer vision tasks. However, their large computational, memory, and energy demands are a challenge for edge inference on FPGAs -- a field that has seen a recent surge in demand. We recognize the benefits of recent works on logic and Look Up Table (LUT) based networks, such as LogicNets, NeuraLUT, DWN, among others, in offering models that simultaneously reduce both the memory and compute footprints. However, these models natively do not perform well on common vision tasks, such as CIFAR-10/100. In this work, we propose LL-ViT, a novel edge optimized vision transformer design that integrates layers of LUT neurons within the transformer architecture. Based on our characterization that reveals that a majority of model weights and computations are from the channel mixer (MLP layer), we design an alternate LUT-based channel mixer, and simultaneously develop an FPGA-based accelerator for LL-ViT. Contrary to some attempts to replace each multiplication with a table lookup, our architecture utilizes a neural learning approach which natively learns the LUT functions. This approach allows for reduced model sizes, and a computational and energy-efficient inference solution for vision transformer models. Evaluating on edge-suitable workloads, we achieve accuracies of 95.5% on CIFAR-10, 78.8% on CIFAR-100, and 60.9% on Tiny-ImageNet datasets, comparable to the baseline transformer. LL-ViT eliminates over 60% of the model weights and 50% of the multiplications in the model, and achieves 1.9x energy efficiency and 1.3x lower latency over an integer quantized ViT accelerator, while also offering superior throughput against prior works at a 10.9W power budget.</li>
</ul>

<h3>Title: TA-LSDiff:Topology-Aware Diffusion Guided by a Level Set Energy for Pancreas Segmentation</h3>
<ul>
<li><strong>Authors: </strong>Yue Gou, Fanghui Song, Yuming Xing, Shengzhu Shi, Zhichang Guo, Boying Wu</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.00815">https://arxiv.org/abs/2511.00815</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.00815">https://arxiv.org/pdf/2511.00815</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.00815]] TA-LSDiff:Topology-Aware Diffusion Guided by a Level Set Energy for Pancreas Segmentation(https://arxiv.org/abs/2511.00815)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, segmentation</a></li>
<li><strong>Abstract: </strong>Pancreas segmentation in medical image processing is a persistent challenge due to its small size, low contrast against adjacent tissues, and significant topological variations. Traditional level set methods drive boundary evolution using gradient flows, often ignoring pointwise topological effects. Conversely, deep learning-based segmentation networks extract rich semantic features but frequently sacrifice structural details. To bridge this gap, we propose a novel model named TA-LSDiff, which combined topology-aware diffusion probabilistic model and level set energy, achieving segmentation without explicit geometric evolution. This energy function guides implicit curve evolution by integrating the input image and deep features through four complementary terms. To further enhance boundary precision, we introduce a pixel-adaptive refinement module that locally modulates the energy function using affinity weighting from neighboring evidence. Ablation studies systematically quantify the contribution of each proposed component. Evaluations on four public pancreas datasets demonstrate that TA-LSDiff achieves state-of-the-art accuracy, outperforming existing methods. These results establish TA-LSDiff as a practical and accurate solution for pancreas segmentation.</li>
</ul>

<h3>Title: Towards Ultra-Low Latency: Binarized Neural Network Architectures for In-Vehicle Network Intrusion Detection</h3>
<ul>
<li><strong>Authors: </strong>Huiyao Dong, Igor Kotenko</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.00828">https://arxiv.org/abs/2511.00828</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.00828">https://arxiv.org/pdf/2511.00828</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.00828]] Towards Ultra-Low Latency: Binarized Neural Network Architectures for In-Vehicle Network Intrusion Detection(https://arxiv.org/abs/2511.00828)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, attack, robust</a></li>
<li><strong>Abstract: </strong>The Control Area Network (CAN) protocol is essential for in-vehicle communication, facilitating high-speed data exchange among Electronic Control Units (ECUs). However, its inherent design lacks robust security features, rendering vehicles susceptible to cyberattacks. While recent research has investigated machine learning and deep learning techniques to enhance network security, their practical applicability remains uncertain. This paper presents a lightweight intrusion detection technique based on Binarized Neural Networks (BNNs), which utilizes payload data, message IDs, and CAN message frequencies for effective intrusion detection. Additionally, we develop hybrid binary encoding techniques to integrate non-binary features, such as message IDs and frequencies. The proposed method, namely the BNN framework specifically optimized for in-vehicle intrusion detection combined with hybrid binary quantization techniques for non-payload attributes, demonstrates efficacy in both anomaly detection and multi-class network traffic classification. The system is well-suited for deployment on micro-controllers and Gateway ECUs, aligning with the real-time requirements of CAN bus safety applications.</li>
</ul>

<h3>Title: Enhancing Adversarial Transferability in Visual-Language Pre-training Models via Local Shuffle and Sample-based Attack</h3>
<ul>
<li><strong>Authors: </strong>Xin Liu, Aoyang Zhou, Aoyang Zhou</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.00831">https://arxiv.org/abs/2511.00831</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.00831">https://arxiv.org/pdf/2511.00831</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.00831]] Enhancing Adversarial Transferability in Visual-Language Pre-training Models via Local Shuffle and Sample-based Attack(https://arxiv.org/abs/2511.00831)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack</a></li>
<li><strong>Abstract: </strong>Visual-Language Pre-training (VLP) models have achieved significant performance across various downstream tasks. However, they remain vulnerable to adversarial examples. While prior efforts focus on improving the adversarial transferability of multimodal adversarial examples through cross-modal interactions, these approaches suffer from overfitting issues, due to a lack of input diversity by relying excessively on information from adversarial examples in one modality when crafting attacks in another. To address this issue, we draw inspiration from strategies in some adversarial training methods and propose a novel attack called Local Shuffle and Sample-based Attack (LSSA). LSSA randomly shuffles one of the local image blocks, thus expanding the original image-text pairs, generating adversarial images, and sampling around them. Then, it utilizes both the original and sampled images to generate the adversarial texts. Extensive experiments on multiple models and datasets demonstrate that LSSA significantly enhances the transferability of multimodal adversarial examples across diverse VLP models and downstream tasks. Moreover, LSSA outperforms other advanced attacks on Large Vision-Language Models.</li>
</ul>

<h3>Title: Linear Differential Vision Transformer: Learning Visual Contrasts via Pairwise Differentials</h3>
<ul>
<li><strong>Authors: </strong>Yifan Pu, Jixuan Ying, Qixiu Li, Tianzhu Ye, Dongchen Han, Xiaochen Wang, Ziyi Wang, Xinyu Shao, Gao Huang, Xiu Li</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.00833">https://arxiv.org/abs/2511.00833</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.00833">https://arxiv.org/pdf/2511.00833</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.00833]] Linear Differential Vision Transformer: Learning Visual Contrasts via Pairwise Differentials(https://arxiv.org/abs/2511.00833)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, transformer</a></li>
<li><strong>Abstract: </strong>Vision Transformers (ViTs) have become a universal backbone for both image recognition and image generation. Yet their Multi-Head Self-Attention (MHSA) layer still performs a quadratic query-key interaction for every token pair, spending the bulk of computation on visually weak or redundant correlations. We introduce Visual-Contrast Attention (VCA), a drop-in replacement for MHSA that injects an explicit notion of discrimination while reducing the theoretical complexity from O(N N C) to O(N n C) with n << N. VCA first distils each head's dense query field into a handful of spatially pooled visual-contrast tokens, then splits them into a learnable positive and negative stream whose differential interaction highlights what truly separates one region from another. The module adds fewer than 0.3M parameters to a DeiT-Tiny backbone, requires no extra FLOPs, and is wholly architecture-agnostic. Empirically, VCA lifts DeiT-Tiny top-1 accuracy on ImageNet-1K from 72.2% to 75.6% (+3.4) and improves three strong hierarchical ViTs by up to 3.1%, while in class-conditional ImageNet generation it lowers FID-50K by 2.1 to 5.2 points across both diffusion (DiT) and flow (SiT) models. Extensive ablations confirm that (i) spatial pooling supplies low-variance global cues, (ii) dual positional embeddings are indispensable for contrastive reasoning, and (iii) combining the two in both stages yields the strongest synergy. VCA therefore offers a simple path towards faster and sharper Vision Transformers. The source code is available at this https URL.</li>
</ul>

<h3>Title: Parameter Interpolation Adversarial Training for Robust Image Classification</h3>
<ul>
<li><strong>Authors: </strong>Xin Liu, Yichen Yang, Kun He, John E. Hopcroft</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.00836">https://arxiv.org/abs/2511.00836</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.00836">https://arxiv.org/pdf/2511.00836</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.00836]] Parameter Interpolation Adversarial Training for Robust Image Classification(https://arxiv.org/abs/2511.00836)</code><input type="text"></li>
<li><strong>Keywords: </strong>defense, attack, robust, transformer</a></li>
<li><strong>Abstract: </strong>Though deep neural networks exhibit superior performance on various tasks, they are still plagued by adversarial examples. Adversarial training has been demonstrated to be the most effective method to defend against adversarial attacks. However, existing adversarial training methods show that the model robustness has apparent oscillations and overfitting issues in the training process, degrading the defense efficacy. To address these issues, we propose a novel framework called Parameter Interpolation Adversarial Training (PIAT). PIAT tunes the model parameters between each epoch by interpolating the parameters of the previous and current epochs. It makes the decision boundary of model change more moderate and alleviates the overfitting issue, helping the model converge better and achieving higher model robustness. In addition, we suggest using the Normalized Mean Square Error (NMSE) to further improve the robustness by aligning the relative magnitude of logits between clean and adversarial examples rather than the absolute magnitude. Extensive experiments conducted on several benchmark datasets demonstrate that our framework could prominently improve the robustness of both Convolutional Neural Networks (CNNs) and Vision Transformers (ViTs).</li>
</ul>

<h3>Title: OmniBrainBench: A Comprehensive Multimodal Benchmark for Brain Imaging Analysis Across Multi-stage Clinical Tasks</h3>
<ul>
<li><strong>Authors: </strong>Zhihao Peng, Cheng Wang, Shengyuan Liu, Zhiying Liang, Yixuan Yuan</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.00846">https://arxiv.org/abs/2511.00846</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.00846">https://arxiv.org/pdf/2511.00846</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.00846]] OmniBrainBench: A Comprehensive Multimodal Benchmark for Brain Imaging Analysis Across Multi-stage Clinical Tasks(https://arxiv.org/abs/2511.00846)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Brain imaging analysis is vital for diagnosing and treating brain disorders, and multimodal large language models (MLLMs) are increasingly assisting in that analysis. However, current brain-oriented visual question-answering (VQA) benchmarks either cover a few imaging modalities or are limited to coarse-grained pathological descriptions, hindering a comprehensive assessment of MLLMs throughout the full clinical continuum. To address these, we introduce OmniBrainBench, the first comprehensive multimodal VQA benchmark specifically designed to assess the multimodal comprehension capabilities of MLLMs in brain imaging this http URL consists of 15 distinct brain imaging modalities collected from 30 verified medical sources, yielding 9,527 validated VQA pairs and 31,706 images. It simulates clinical workflows and encompasses 15 multi-stage clinical tasks rigorously validated by a professional radiologist. Evaluation of 24 state-of-the-art models, including open-source, medical, and proprietary MLLMs, highlights the substantial challenges posed by OmniBrainBench. Our experiments reveal: (1) proprietary MLLMs (e.g., GPT-5) beat open-source and medical models but lag physicians; (2) medical MLLMs vary widely in performance; (3) open-source MLLMs trail overall but excel in specific tasks; (4) MLLMs underperform sharply in complex preoperative tasks, revealing a visual-to-clinical reasoning gap. OmniBrainBench sets a new standard for evaluating and advancing MLLMs in brain imaging analysis, highlighting gaps compared to expert clinical reasoning. We release it at benchmark \& code.</li>
</ul>

<h3>Title: Identifying Slug Formation in Oil Well Pipelines: A Use Case from Industrial Analytics</h3>
<ul>
<li><strong>Authors: </strong>Abhishek Patange, Sharat Chidambaran, Prabhat Shankar, Manjunath G.B., Anindya Chatterjee</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.00851">https://arxiv.org/abs/2511.00851</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.00851">https://arxiv.org/pdf/2511.00851</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.00851]] Identifying Slug Formation in Oil Well Pipelines: A Use Case from Industrial Analytics(https://arxiv.org/abs/2511.00851)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability</a></li>
<li><strong>Abstract: </strong>Slug formation in oil and gas pipelines poses significant challenges to operational safety and efficiency, yet existing detection approaches are often offline, require domain expertise, and lack real-time interpretability. We present an interactive application that enables end-to-end data-driven slug detection through a compact and user-friendly interface. The system integrates data exploration and labeling, configurable model training and evaluation with multiple classifiers, visualization of classification results with time-series overlays, and a real-time inference module that generates persistence-based alerts when slug events are detected. The demo supports seamless workflows from labeled CSV uploads to live inference on unseen datasets, making it lightweight, portable, and easily deployable. By combining domain-relevant analytics with novel UI/UX features such as snapshot persistence, visual labeling, and real-time alerting, our tool adds significant dissemination value as both a research prototype and a practical industrial application. The demo showcases how interactive human-in-the-loop ML systems can bridge the gap between data science methods and real-world decision-making in critical process industries, with broader applicability to time-series fault diagnosis tasks beyond oil and gas.</li>
</ul>

<h3>Title: TriCon-Fair: Triplet Contrastive Learning for Mitigating Social Bias in Pre-trained Language Models</h3>
<ul>
<li><strong>Authors: </strong>Chong Lyu, Lin Li, Shiqing Wu, Jingling Yuan</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.00854">https://arxiv.org/abs/2511.00854</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.00854">https://arxiv.org/pdf/2511.00854</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.00854]] TriCon-Fair: Triplet Contrastive Learning for Mitigating Social Bias in Pre-trained Language Models(https://arxiv.org/abs/2511.00854)</code><input type="text"></li>
<li><strong>Keywords: </strong>fair, large language model</a></li>
<li><strong>Abstract: </strong>The increasing utilization of large language models raises significant concerns about the propagation of social biases, which may result in harmful and unfair outcomes. However, existing debiasing methods treat the biased and unbiased samples independently, thus ignoring their mutual relationship. This oversight enables a hidden negative-positive coupling, where improvements for one group inadvertently compromise the other, allowing residual social bias to persist. In this paper, we introduce TriCon-Fair, a contrastive learning framework that employs a decoupled loss that combines triplet and language modeling terms to eliminate positive-negative coupling. Our TriCon-Fair assigns each anchor an explicitly biased negative and an unbiased positive, decoupling the push-pull dynamics and avoiding positive-negative coupling, and jointly optimizes a language modeling (LM) objective to preserve general capability. Experimental results demonstrate that TriCon-Fair reduces discriminatory output beyond existing debiasing baselines while maintaining strong downstream performance. This suggests that our proposed TriCon-Fair offers a practical and ethical solution for sensitive NLP applications.</li>
</ul>

<h3>Title: Occlusion-Aware Diffusion Model for Pedestrian Intention Prediction</h3>
<ul>
<li><strong>Authors: </strong>Yu Liu, Zhijie Liu, Zedong Yang, You-Fu Li, He Kong</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.00858">https://arxiv.org/abs/2511.00858</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.00858">https://arxiv.org/pdf/2511.00858</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.00858]] Occlusion-Aware Diffusion Model for Pedestrian Intention Prediction(https://arxiv.org/abs/2511.00858)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, diffusion, transformer</a></li>
<li><strong>Abstract: </strong>Predicting pedestrian crossing intentions is crucial for the navigation of mobile robots and intelligent vehicles. Although recent deep learning-based models have shown significant success in forecasting intentions, few consider incomplete observation under occlusion scenarios. To tackle this challenge, we propose an Occlusion-Aware Diffusion Model (ODM) that reconstructs occluded motion patterns and leverages them to guide future intention prediction. During the denoising stage, we introduce an occlusion-aware diffusion transformer architecture to estimate noise features associated with occluded patterns, thereby enhancing the model's ability to capture contextual relationships in occluded semantic scenarios. Furthermore, an occlusion mask-guided reverse process is introduced to effectively utilize observation information, reducing the accumulation of prediction errors and enhancing the accuracy of reconstructed motion features. The performance of the proposed method under various occlusion scenarios is comprehensively evaluated and compared with existing methods on popular benchmarks, namely PIE and JAAD. Extensive experimental results demonstrate that the proposed method achieves more robust performance than existing methods in the literature.</li>
</ul>

<h3>Title: Layer-Wise Modality Decomposition for Interpretable Multimodal Sensor Fusion</h3>
<ul>
<li><strong>Authors: </strong>Jaehyun Park, Konyul Park, Daehun Kim, Junseo Park, Jun Won Choi</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.00859">https://arxiv.org/abs/2511.00859</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.00859">https://arxiv.org/pdf/2511.00859</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.00859]] Layer-Wise Modality Decomposition for Interpretable Multimodal Sensor Fusion(https://arxiv.org/abs/2511.00859)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability</a></li>
<li><strong>Abstract: </strong>In autonomous driving, transparency in the decision-making of perception models is critical, as even a single misperception can be catastrophic. Yet with multi-sensor inputs, it is difficult to determine how each modality contributes to a prediction because sensor information becomes entangled within the fusion network. We introduce Layer-Wise Modality Decomposition (LMD), a post-hoc, model-agnostic interpretability method that disentangles modality-specific information across all layers of a pretrained fusion model. To our knowledge, LMD is the first approach to attribute the predictions of a perception model to individual input modalities in a sensor-fusion system for autonomous driving. We evaluate LMD on pretrained fusion models under camera-radar, camera-LiDAR, and camera-radar-LiDAR settings for autonomous driving. Its effectiveness is validated using structured perturbation-based metrics and modality-wise visual decompositions, demonstrating practical applicability to interpreting high-capacity multimodal architectures. Code is available at this https URL.</li>
</ul>

<h3>Title: FlexiCache: Leveraging Temporal Stability of Attention Heads for Efficient KV Cache Management</h3>
<ul>
<li><strong>Authors: </strong>Nazmul Takbir, Hamidreza Alikhani, Nikil Dutt, Sangeetha Abdu Jyothi</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.00868">https://arxiv.org/abs/2511.00868</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.00868">https://arxiv.org/pdf/2511.00868</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.00868]] FlexiCache: Leveraging Temporal Stability of Attention Heads for Efficient KV Cache Management(https://arxiv.org/abs/2511.00868)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large Language Model (LLM) serving is increasingly constrained by the growing size of the key-value (KV) cache, which scales with both context length and generation length. Prior work shows that attention is dominated by a small subset of critical tokens, yet existing systems struggle to exploit this efficiently without degrading accuracy, especially in long generation. We make a key observation: the temporal stability of these critical tokens varies significantly across KV heads: some heads consistently focus on the same tokens, while others shift frequently. Building on this insight, we introduce FlexiCache, a hierarchical KV-cache management system that leverages the temporal stability of KV heads to reduce GPU memory usage and computation overhead, while preserving model accuracy. FlexiCache classifies KV heads as stable or unstable: it retains all KV-cache pages from unstable heads in GPU memory, whereas for stable heads, it keeps only the top-K pages on the GPU and offloads the rest to host memory. By exploiting temporal stability, FlexiCache performs periodic reranking for stable heads to fetch newly promoted top pages. Implemented atop vLLM, FlexiCache reduces GPU memory footprint for long-context requests by up to 70%, improves offline serving throughput by 1.38-1.55x, and lowers online token latency by 1.6-2.1x, all while maintaining accuracy in long-context, long-generation scenarios.</li>
</ul>

<h3>Title: Assessing LLM Reasoning Steps via Principal Knowledge Grounding</h3>
<ul>
<li><strong>Authors: </strong>Hyeon Hwang, Yewon Cho, Chanwoong Yoon, Yein Park, Minju Song, Kyungjae Lee, Gangwoo Kim, Jaewoo Kang</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.00879">https://arxiv.org/abs/2511.00879</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.00879">https://arxiv.org/pdf/2511.00879</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.00879]] Assessing LLM Reasoning Steps via Principal Knowledge Grounding(https://arxiv.org/abs/2511.00879)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Step-by-step reasoning has become a standard approach for large language models (LLMs) to tackle complex tasks. While this paradigm has proven effective, it raises a fundamental question: How can we verify that an LLM's reasoning is accurately grounded in knowledge? To address this question, we introduce a novel evaluation suite that systematically assesses the knowledge grounding of intermediate reasoning. Our framework comprises three key components. (1) Principal Knowledge Collection, a large-scale repository of atomic knowledge essential for reasoning. Based on the collection, we propose (2) knowledge-grounded evaluation metrics designed to measure how well models recall and apply prerequisite knowledge in reasoning. These metrics are computed by our (3) evaluator LLM, a lightweight model optimized for cost-effective and reliable metric computation. Our evaluation suite demonstrates remarkable effectiveness in identifying missing or misapplied knowledge elements, providing crucial insights for uncovering fundamental reasoning deficiencies in LLMs. Beyond evaluation, we demonstrate how these metrics can be integrated into preference optimization, showcasing further applications of knowledge-grounded evaluation.</li>
</ul>

<h3>Title: SpEx: A Spectral Approach to Explainable Clustering</h3>
<ul>
<li><strong>Authors: </strong>Tal Argov, Tal Wagner</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.DS</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.00885">https://arxiv.org/abs/2511.00885</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.00885">https://arxiv.org/pdf/2511.00885</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.00885]] SpEx: A Spectral Approach to Explainable Clustering(https://arxiv.org/abs/2511.00885)</code><input type="text"></li>
<li><strong>Keywords: </strong>explainability</a></li>
<li><strong>Abstract: </strong>Explainable clustering by axis-aligned decision trees was introduced by Moshkovitz et al. (2020) and has gained considerable interest. Prior work has focused on minimizing the price of explainability for specific clustering objectives, lacking a general method to fit an explanation tree to any given clustering, without restrictions. In this work, we propose a new and generic approach to explainable clustering, based on spectral graph partitioning. With it, we design an explainable clustering algorithm that can fit an explanation tree to any given non-explainable clustering, or directly to the dataset itself. Moreover, we show that prior algorithms can also be interpreted as graph partitioning, through a generalized framework due to Trevisan (2013) wherein cuts are optimized in two graphs simultaneously. Our experiments show the favorable performance of our method compared to baselines on a range of datasets.</li>
</ul>

<h3>Title: Android Malware Detection: A Machine Leaning Approach</h3>
<ul>
<li><strong>Authors: </strong>Hasan Abdulla</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.00894">https://arxiv.org/abs/2511.00894</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.00894">https://arxiv.org/pdf/2511.00894</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.00894]] Android Malware Detection: A Machine Leaning Approach(https://arxiv.org/abs/2511.00894)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability</a></li>
<li><strong>Abstract: </strong>This study examines machine learning techniques like Decision Trees, Support Vector Machines, Logistic Regression, Neural Networks, and ensemble methods to detect Android malware. The study evaluates these models on a dataset of Android applications and analyzes their accuracy, efficiency, and real-world applicability. Key findings show that ensemble methods demonstrate superior performance, but there are trade-offs between model interpretability, efficiency, and accuracy. Given its increasing threat, the insights guide future research and practical use of ML to combat Android malware.</li>
</ul>

<h3>Title: Random Spiking Neural Networks are Stable and Spectrally Simple</h3>
<ul>
<li><strong>Authors: </strong>Ernesto Araya, Massimiliano Datres, Gitta Kutyniok</a></li>
<li><strong>Subjects: </strong>cs.LG, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.00904">https://arxiv.org/abs/2511.00904</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.00904">https://arxiv.org/pdf/2511.00904</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.00904]] Random Spiking Neural Networks are Stable and Spectrally Simple(https://arxiv.org/abs/2511.00904)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Spiking neural networks (SNNs) are a promising paradigm for energy-efficient computation, yet their theoretical foundations-especially regarding stability and robustness-remain limited compared to artificial neural networks. In this work, we study discrete-time leaky integrate-and-fire (LIF) SNNs through the lens of Boolean function analysis. We focus on noise sensitivity and stability in classification tasks, quantifying how input perturbations affect outputs. Our main result shows that wide LIF-SNN classifiers are stable on average, a property explained by the concentration of their Fourier spectrum on low-frequency components. Motivated by this, we introduce the notion of spectral simplicity, which formalizes simplicity in terms of Fourier spectrum concentration and connects our analysis to the simplicity bias observed in deep networks. Within this framework, we show that random LIF-SNNs are biased toward simple functions. Experiments on trained networks confirm that these stability properties persist in practice. Together, these results provide new insights into the stability and robustness properties of SNNs.</li>
</ul>

<h3>Title: Transformers as Intrinsic Optimizers: Forward Inference through the Energy Principle</h3>
<ul>
<li><strong>Authors: </strong>Ruifeng Ren, Sheng Ouyang, Huayi Tang, Yong Liu</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.00907">https://arxiv.org/abs/2511.00907</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.00907">https://arxiv.org/pdf/2511.00907</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.00907]] Transformers as Intrinsic Optimizers: Forward Inference through the Energy Principle(https://arxiv.org/abs/2511.00907)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer, large language model</a></li>
<li><strong>Abstract: </strong>Transformers have demonstrated strong adaptability across a wide range of tasks and have become the backbone of modern Large Language Models (LLMs). However, their underlying mechanisms remain open for further exploration. The energy-based perspective has long provided a valuable principle for understanding neural computation. In this paper, we revisit the principle of energy as a lens to understand attention-based Transformer models. We present a unified energy-based framework which is composed of three key components: the global energy $F^*$, the energy function $E_i$ and the employed gradient descent (GD) form. Within this framework, standard softmax attention can be viewed as a special case of minimizing the Helmholtz free energy as $F^*$ using standard GD when $E_i$ takes the form of elastic potential energy, with residual connections ensuring that this optimization proceeds in an incremental manner. In addition, linear attentions can also be naturally incorporated into this framework by adjusting the corresponding energy forms. We also extend the above analysis to the multi-head setting, where the energy is defined across multiple low-dimensional subspaces. Building on this framework, we propose energy-based modifications of attention structures. Inspired by classical GD algorithms, we extend the original attention formulation based on standard GD to the momentum-based GD, Nesterov Accelerated Gradient (NAG), and Newton's method variants, each inducing a corresponding new attention structure. Our experiments provide preliminary support for the potential of the energy-based framework for designing attention mechanisms.</li>
</ul>

<h3>Title: Fleming-VL: Towards Universal Medical Visual Reasoning with Multimodal LLMs</h3>
<ul>
<li><strong>Authors: </strong>Yan Shu, Chi Liu, Robin Chen, Derek Li, Bryan Dai</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.00916">https://arxiv.org/abs/2511.00916</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.00916">https://arxiv.org/pdf/2511.00916</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.00916]] Fleming-VL: Towards Universal Medical Visual Reasoning with Multimodal LLMs(https://arxiv.org/abs/2511.00916)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Multimodal Large Language Models (MLLMs) have demonstrated remarkable effectiveness in various general-domain scenarios, such as visual question answering and image captioning. Recently, researchers have increasingly focused on empowering MLLMs with medical conversational abilities, which hold significant promise for clinical applications. However, medical data presents unique challenges due to its heterogeneous nature -- encompassing diverse modalities including 2D images, 3D volumetric scans, and temporal video sequences. The substantial domain gap and data format inconsistencies across these modalities have hindered the development of unified medical MLLMs. To address these challenges, we propose Fleming-VL, a unified end-to-end framework for comprehensive medical visual understanding across heterogeneous modalities. Fleming-VL tackles this problem from a data-centric perspective through three key strategies: (1) scaling up pretraining by integrating long-context data from both natural and medical-specific domains; (2) complementing fine-tuning with rare medical data, including holistic video analysis and underrepresented 2D modalities such as ultrasound and dermoscopy images; (3) extending existing evaluation frameworks to incorporate 3D volumetric and video understanding benchmarks. Through supervised fine-tuning (SFT) and group relative policy optimization (GRPO), we develop Fleming-VL in multiple model scales. Extensive experiments demonstrate that Fleming-VL achieves state-of-the-art performance across multiple benchmarks, including medical VQA, video QA, and 3D medical image understanding. We publicly release Fleming-VL to promote transparent, reproducible, and auditable progress in medical AI.</li>
</ul>

<h3>Title: The Biased Oracle: Assessing LLMs' Understandability and Empathy in Medical Diagnoses</h3>
<ul>
<li><strong>Authors: </strong>Jianzhou Yao, Shunchang Liu, Guillaume Drui, Rikard Pettersson, Alessandro Blasimme, Sara Kijewski</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.00924">https://arxiv.org/abs/2511.00924</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.00924">https://arxiv.org/pdf/2511.00924</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.00924]] The Biased Oracle: Assessing LLMs' Understandability and Empathy in Medical Diagnoses(https://arxiv.org/abs/2511.00924)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large language models (LLMs) show promise for supporting clinicians in diagnostic communication by generating explanations and guidance for patients. Yet their ability to produce outputs that are both understandable and empathetic remains uncertain. We evaluate two leading LLMs on medical diagnostic scenarios, assessing understandability using readability metrics as a proxy and empathy through LLM-as-a-Judge ratings compared to human evaluations. The results indicate that LLMs adapt explanations to socio-demographic variables and patient conditions. However, they also generate overly complex content and display biased affective empathy, leading to uneven accessibility and support. These patterns underscore the need for systematic calibration to ensure equitable patient communication. The code and data are released: this https URL</li>
</ul>

<h3>Title: Dynamic Multi-level Weighted Alignment Network for Zero-shot Sketch-based Image Retrieval</h3>
<ul>
<li><strong>Authors: </strong>Hanwen Su, Ge Song, Jiyan Wang, Yuanbo Zhu</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.00925">https://arxiv.org/abs/2511.00925</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.00925">https://arxiv.org/pdf/2511.00925</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.00925]] Dynamic Multi-level Weighted Alignment Network for Zero-shot Sketch-based Image Retrieval(https://arxiv.org/abs/2511.00925)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction</a></li>
<li><strong>Abstract: </strong>The problem of zero-shot sketch-based image retrieval (ZS-SBIR) has achieved increasing attention due to its wide applications, e.g. e-commerce. Despite progress made in this field, previous works suffer from using imbalanced samples of modalities and inconsistent low-quality information during training, resulting in sub-optimal performance. Therefore, in this paper, we introduce an approach called Dynamic Multi-level Weighted Alignment Network for ZS-SBIR. It consists of three components: (i) a Uni-modal Feature Extraction Module that includes a CLIP text encoder and a ViT for extracting textual and visual tokens, (ii) a Cross-modal Multi-level Weighting Module that produces an alignment weight list by the local and global aggregation blocks to measure the aligning quality of sketch and image samples, (iii) a Weighted Quadruplet Loss Module aiming to improve the balance of domains in the triplet loss. Experiments on three benchmark datasets, i.e., Sketchy, TU-Berlin, and QuickDraw, show our method delivers superior performances over the state-of-the-art ZS-SBIR methods.</li>
</ul>

<h3>Title: Leakage-abuse Attack Against Substring-SSE with Partially Known Dataset</h3>
<ul>
<li><strong>Authors: </strong>Xijie Ba, Qin Liu, Xiaohong Li, Jianting Ning</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.00930">https://arxiv.org/abs/2511.00930</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.00930">https://arxiv.org/pdf/2511.00930</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.00930]] Leakage-abuse Attack Against Substring-SSE with Partially Known Dataset(https://arxiv.org/abs/2511.00930)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, attack</a></li>
<li><strong>Abstract: </strong>Substring-searchable symmetric encryption (substring-SSE) has become increasingly critical for privacy-preserving applications in cloud systems. However, existing schemes remain vulnerable to information leakage during search operations, particularly when adversaries possess partial knowledge of the target dataset. Although leakage-abuse attacks have been widely studied for traditional SSE, their applicability to substring-SSE under partially known data assumptions remains unexplored. In this paper, we present the first leakage-abuse attack on substring-SSE under partially-known dataset conditions. We develop a novel matrix-based correlation technique that extends and optimizes the LEAP framework for substring-SSE, enabling efficient recovery of plaintext data from encrypted suffix tree structures. Unlike existing approaches that rely on independent auxiliary datasets, our method directly exploits known data fragments to establish high-confidence mappings between ciphertext tokens and plaintext substrings through iterative matrix transformations. Comprehensive experiments on real-world datasets demonstrate the effectiveness of the attack, with recovery rates reaching 98.32% for substrings given 50% auxiliary knowledge. Even with only 10% prior knowledge, the attack achieves 74.42% substring recovery while maintaining strong scalability across datasets of varying sizes. The result reveals significant privacy risks in current substring-SSE designs and highlights the urgent need for leakage-resilient constructions.</li>
</ul>

<h3>Title: Motion-Robust Multimodal Fusion of PPG and Accelerometer Signals for Three-Class Heart Rhythm Classification</h3>
<ul>
<li><strong>Authors: </strong>Yangyang Zhao, Matti Kaisti, Olli Lahdenoja, Tero Koivisto</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.00949">https://arxiv.org/abs/2511.00949</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.00949">https://arxiv.org/pdf/2511.00949</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.00949]] Motion-Robust Multimodal Fusion of PPG and Accelerometer Signals for Three-Class Heart Rhythm Classification(https://arxiv.org/abs/2511.00949)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Atrial fibrillation (AF) is a leading cause of stroke and mortality, particularly in elderly patients. Wrist-worn photoplethysmography (PPG) enables non-invasive, continuous rhythm monitoring, yet suffers from significant vulnerability to motion artifacts and physiological noise. Many existing approaches rely solely on single-channel PPG and are limited to binary AF detection, often failing to capture the broader range of arrhythmias encountered in clinical settings. We introduce RhythmiNet, a residual neural network enhanced with temporal and channel attention modules that jointly leverage PPG and accelerometer (ACC) signals. The model performs three-class rhythm classification: AF, sinus rhythm (SR), and Other. To assess robustness across varying movement conditions, test data are stratified by accelerometer-based motion intensity percentiles without excluding any segments. RhythmiNet achieved a 4.3% improvement in macro-AUC over the PPG-only baseline. In addition, performance surpassed a logistic regression model based on handcrafted HRV features by 12%, highlighting the benefit of multimodal fusion and attention-based learning in noisy, real-world clinical data.</li>
</ul>

<h3>Title: EVTAR: End-to-End Try on with Additional Unpaired Visual Reference</h3>
<ul>
<li><strong>Authors: </strong>Liuzhuozheng Li, Yue Gong, Shanyuan Liu, Bo Cheng, Yuhang Ma, Liebucha Wu, Dengyang Jiang, Zanyi Wang, Dawei Leng, Yuhui Yin</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.00956">https://arxiv.org/abs/2511.00956</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.00956">https://arxiv.org/pdf/2511.00956</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.00956]] EVTAR: End-to-End Try on with Additional Unpaired Visual Reference(https://arxiv.org/abs/2511.00956)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>We propose EVTAR, an End-to-End Virtual Try-on model with Additional Reference, that directly fits the target garment onto the person image while incorporating reference images to enhance try-on accuracy. Most existing virtual try-on approaches rely on complex inputs such as agnostic person images, human pose, densepose, or body keypoints, making them labor-intensive and impractical for real-world applications. In contrast, EVTAR adopts a two-stage training strategy, enabling simple inference with only the source image and the target garment inputs. Our model generates try-on results without masks, densepose, or segmentation maps. Moreover, EVTAR leverages additional reference images of different individuals wearing the same clothes to preserve garment texture and fine-grained details better. This mechanism is analogous to how humans consider reference models when choosing outfits, thereby simulating a more realistic and high-quality dressing effect. We enrich the training data with supplementary references and unpaired person images to support these capabilities. We evaluate EVTAR on two widely used benchmarks and diverse tasks, and the results consistently validate the effectiveness of our approach.</li>
</ul>

<h3>Title: The Riddle of Reflection: Evaluating Reasoning and Self-Awareness in Multilingual LLMs using Indian Riddles</h3>
<ul>
<li><strong>Authors: </strong>Abhinav P M, Ojasva Saxena, Oswald C, Parameswari Krishnamurthy</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.00960">https://arxiv.org/abs/2511.00960</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.00960">https://arxiv.org/pdf/2511.00960</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.00960]] The Riddle of Reflection: Evaluating Reasoning and Self-Awareness in Multilingual LLMs using Indian Riddles(https://arxiv.org/abs/2511.00960)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>The extent to which large language models (LLMs) can perform culturally grounded reasoning across non-English languages remains underexplored. This paper examines the reasoning and self-assessment abilities of LLMs across seven major Indian languages-Bengali, Gujarati, Hindi, Kannada, Malayalam, Tamil, and Telugu. We introduce a multilingual riddle dataset combining traditional riddles with context-reconstructed variants and evaluate five LLMs-Gemini 2.5 Pro, Gemini 2.5 Flash, Mistral-Saba, LLaMA 4 Scout, and LLaMA 4 Maverick-under seven prompting strategies. In the first stage, we assess riddle-solving performance and find that while Gemini 2.5 Pro performs best overall, few-shot methods yield only marginal gains, and accuracy varies notably across languages. In the second stage, we conduct a self-evaluation experiment to measure reasoning consistency. The results reveal a key finding: a model's initial accuracy is inversely correlated with its ability to identify its own mistakes. Top-performing models such as Gemini 2.5 Pro are overconfident (4.34% True Negative Rate), whereas lower-performing models like LLaMA 4 Scout are substantially more self-aware (42.09% True Negative Rate). These results point to clear gaps in multilingual reasoning and highlight the need for models that not only reason effectively but also recognize their own limitations.</li>
</ul>

<h3>Title: A Unified Reasoning Framework for Holistic Zero-Shot Video Anomaly Analysis</h3>
<ul>
<li><strong>Authors: </strong>Dongheng Lin, Mengxue Qu, Kunyang Han, Jianbo Jiao, Xiaojie Jin, Yunchao Wei</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.00962">https://arxiv.org/abs/2511.00962</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.00962">https://arxiv.org/pdf/2511.00962</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.00962]] A Unified Reasoning Framework for Holistic Zero-Shot Video Anomaly Analysis(https://arxiv.org/abs/2511.00962)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability, explainability</a></li>
<li><strong>Abstract: </strong>Most video-anomaly research stops at frame-wise detection, offering little insight into why an event is abnormal, typically outputting only frame-wise anomaly scores without spatial or semantic context. Recent video anomaly localization and video anomaly understanding methods improve explainability but remain data-dependent and task-specific. We propose a unified reasoning framework that bridges the gap between temporal detection, spatial localization, and textual explanation. Our approach is built upon a chained test-time reasoning process that sequentially connects these tasks, enabling holistic zero-shot anomaly analysis without any additional training. Specifically, our approach leverages intra-task reasoning to refine temporal detections and inter-task chaining for spatial and semantic understanding, yielding improved interpretability and generalization in a fully zero-shot manner. Without any additional data or gradients, our method achieves state-of-the-art zero-shot performance across multiple video anomaly detection, localization, and explanation benchmarks. The results demonstrate that careful prompt design with task-wise chaining can unlock the reasoning power of foundation models, enabling practical, interpretable video anomaly analysis in a fully zero-shot manner. Project Page: this https URL.</li>
</ul>

<h3>Title: Using Synthetic Data to estimate the True Error is theoretically and practically doable</h3>
<ul>
<li><strong>Authors: </strong>Hai Hoang Thanh, Duy-Tung Nguyen, Hung The Tran, Khoat Than</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.00964">https://arxiv.org/abs/2511.00964</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.00964">https://arxiv.org/pdf/2511.00964</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.00964]] Using Synthetic Data to estimate the True Error is theoretically and practically doable(https://arxiv.org/abs/2511.00964)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>Accurately evaluating model performance is crucial for deploying machine learning systems in real-world applications. Traditional methods often require a sufficiently large labeled test set to ensure a reliable evaluation. However, in many contexts, a large labeled dataset is costly and labor-intensive. Therefore, we sometimes have to do evaluation by a few labeled samples, which is theoretically challenging. Recent advances in generative models offer a promising alternative by enabling the synthesis of high-quality data. In this work, we make a systematic investigation about the use of synthetic data to estimate the test error of a trained model under limited labeled data conditions. To this end, we develop novel generalization bounds that take synthetic data into account. Those bounds suggest novel ways to optimize synthetic samples for evaluation and theoretically reveal the significant role of the generator's quality. Inspired by those bounds, we propose a theoretically grounded method to generate optimized synthetic data for model evaluation. Experimental results on simulation and tabular datasets demonstrate that, compared to existing baselines, our method achieves accurate and more reliable estimates of the test error.</li>
</ul>

<h3>Title: Keys in the Weights: Transformer Authentication Using Model-Bound Latent Representations</h3>
<ul>
<li><strong>Authors: </strong>Ayşe S. Okatan, Mustafa İlhan Akbaş, Laxima Niure Kandel, Berker Peköz</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.AI, eess.SP</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.00973">https://arxiv.org/abs/2511.00973</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.00973">https://arxiv.org/pdf/2511.00973</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.00973]] Keys in the Weights: Transformer Authentication Using Model-Bound Latent Representations(https://arxiv.org/abs/2511.00973)</code><input type="text"></li>
<li><strong>Keywords: </strong>secure, transformer</a></li>
<li><strong>Abstract: </strong>We introduce Model-Bound Latent Exchange (MoBLE), a decoder-binding property in Transformer autoencoders formalized as Zero-Shot Decoder Non-Transferability (ZSDN). In identity tasks using iso-architectural models trained on identical data but differing in seeds, self-decoding achieves more than 0.91 exact match and 0.98 token accuracy, while zero-shot cross-decoding collapses to chance without exact matches. This separation arises without injected secrets or adversarial training, and is corroborated by weight-space distances and attention-divergence diagnostics. We interpret ZSDN as model binding, a latent-based authentication and access-control mechanism, even when the architecture and training recipe are public: encoder's hidden state representation deterministically reveals the plaintext, yet only the correctly keyed decoder reproduces it in zero-shot. We formally define ZSDN, a decoder-binding advantage metric, and outline deployment considerations for secure artificial intelligence (AI) pipelines. Finally, we discuss learnability risks (e.g., adapter alignment) and outline mitigations. MoBLE offers a lightweight, accelerator-friendly approach to secure AI deployment in safety-critical domains, including aviation and cyber-physical systems.</li>
</ul>

<h3>Title: Modeling Microenvironment Trajectories on Spatial Transcriptomics with NicheFlow</h3>
<ul>
<li><strong>Authors: </strong>Kristiyan Sakalyan, Alessandro Palma, Filippo Guerranti, Fabian J. Theis, Stephan Günnemann</a></li>
<li><strong>Subjects: </strong>cs.LG, q-bio.QM</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.00977">https://arxiv.org/abs/2511.00977</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.00977">https://arxiv.org/pdf/2511.00977</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.00977]] Modeling Microenvironment Trajectories on Spatial Transcriptomics with NicheFlow(https://arxiv.org/abs/2511.00977)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>Understanding the evolution of cellular microenvironments in spatiotemporal data is essential for deciphering tissue development and disease progression. While experimental techniques like spatial transcriptomics now enable high-resolution mapping of tissue organization across space and time, current methods that model cellular evolution operate at the single-cell level, overlooking the coordinated development of cellular states in a tissue. We introduce NicheFlow, a flow-based generative model that infers the temporal trajectory of cellular microenvironments across sequential spatial slides. By representing local cell neighborhoods as point clouds, NicheFlow jointly models the evolution of cell states and spatial coordinates using optimal transport and Variational Flow Matching. Our approach successfully recovers both global spatial architecture and local microenvironment composition across diverse spatiotemporal datasets, from embryonic to brain development.</li>
</ul>

<h3>Title: VesSAM: Efficient Multi-Prompting for Segmenting Complex Vessel</h3>
<ul>
<li><strong>Authors: </strong>Suzhong Fu, Rui Sun, Xuan Ding, Jingqi Dong, Yiming Yang, Yao Zhu, Min Chang Jordan Ren, Delin Deng, Angelica Aviles-Rivero, Shuguang Cui, Zhen Li</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.00981">https://arxiv.org/abs/2511.00981</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.00981">https://arxiv.org/pdf/2511.00981</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.00981]] VesSAM: Efficient Multi-Prompting for Segmenting Complex Vessel(https://arxiv.org/abs/2511.00981)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>Accurate vessel segmentation is critical for clinical applications such as disease diagnosis and surgical planning, yet remains challenging due to thin, branching structures and low texture contrast. While foundation models like the Segment Anything Model (SAM) have shown promise in generic segmentation, they perform sub-optimally on vascular structures. In this work, we present VesSAM, a powerful and efficient framework tailored for 2D vessel segmentation. VesSAM integrates (1) a convolutional adapter to enhance local texture features, (2) a multi-prompt encoder that fuses anatomical prompts, including skeletons, bifurcation points, and segment midpoints, via hierarchical cross-attention, and (3) a lightweight mask decoder to reduce jagged artifacts. We also introduce an automated pipeline to generate structured multi-prompt annotations, and curate a diverse benchmark dataset spanning 8 datasets across 5 imaging modalities. Experimental results demonstrate that VesSAM consistently outperforms state-of-the-art PEFT-based SAM variants by over 10% Dice and 13% IoU, and achieves competitive performance compared to fully fine-tuned methods, with significantly fewer parameters. VesSAM also generalizes well to out-of-distribution (OoD) settings, outperforming all baselines in average OoD Dice and IoU.</li>
</ul>

<h3>Title: Advancing Machine-Generated Text Detection from an Easy to Hard Supervision Perspective</h3>
<ul>
<li><strong>Authors: </strong>Chenwang Wu, Yiu-ming Cheung, Bo Han, Defu Lian</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.00988">https://arxiv.org/abs/2511.00988</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.00988">https://arxiv.org/pdf/2511.00988</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.00988]] Advancing Machine-Generated Text Detection from an Easy to Hard Supervision Perspective(https://arxiv.org/abs/2511.00988)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack</a></li>
<li><strong>Abstract: </strong>Existing machine-generated text (MGT) detection methods implicitly assume labels as the "golden standard". However, we reveal boundary ambiguity in MGT detection, implying that traditional training paradigms are inexact. Moreover, limitations of human cognition and the superintelligence of detectors make inexact learning widespread and inevitable. To this end, we propose an easy-to-hard enhancement framework to provide reliable supervision under such inexact conditions. Distinct from knowledge distillation, our framework employs an easy supervisor targeting relatively simple longer-text detection tasks (despite weaker capabilities), to enhance the more challenging target detector. Firstly, longer texts targeted by supervisors theoretically alleviate the impact of inexact labels, laying the foundation for reliable supervision. Secondly, by structurally incorporating the detector into the supervisor, we theoretically model the supervisor as a lower performance bound for the detector. Thus, optimizing the supervisor indirectly optimizes the detector, ultimately approximating the underlying "golden" labels. Extensive experiments across diverse practical scenarios, including cross-LLM, cross-domain, mixed text, and paraphrase attacks, demonstrate the framework's significant detection effectiveness. The code is available at: this https URL.</li>
</ul>

<h3>Title: Hydra: Dual Exponentiated Memory for Multivariate Time Series Analysis</h3>
<ul>
<li><strong>Authors: </strong>Asal Meskin, Alireza Mirrokni, Ali Najar, Ali Behrouz</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.00989">https://arxiv.org/abs/2511.00989</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.00989">https://arxiv.org/pdf/2511.00989</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.00989]] Hydra: Dual Exponentiated Memory for Multivariate Time Series Analysis(https://arxiv.org/abs/2511.00989)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>In recent years, effectively modeling multivariate time series has gained significant popularity, mainly due to its wide range of applications, ranging from healthcare to financial markets and energy management. Transformers, MLPs, and linear models as the de facto backbones of modern time series models have shown promising results in single-variant and/or short-term forecasting. These models, however: (1) are permutation equivariant and so lack temporal inductive bias, being less expressive to capture the temporal dynamics; (2) are naturally designed for univariate setup, missing the inter-dependencies of temporal and variate dimensions; and/or (3) are inefficient for Long-term time series modeling. To overcome training and inference efficiency as well as the lack of temporal inductive bias, recently, linear Recurrent Neural Networks (RNNs) have gained attention as an alternative to Transformer-based models. These models, however, are inherently limited to a single sequence, missing inter-variate dependencies, and can propagate errors due to their additive nature. In this paper, we present Hydra, a by-design two-headed meta in-context memory module that learns how to memorize patterns at test time by prioritizing time series patterns that are more informative about the data. Hydra uses a 2-dimensional recurrence across both time and variate at each step, which is more powerful than mixing methods. Although the 2-dimensional nature of the model makes its training recurrent and non-parallelizable, we present a new 2D-chunk-wise training algorithm that approximates the actual recurrence with $\times 10$ efficiency improvement, while maintaining the effectiveness. Our experimental results on a diverse set of tasks and datasets, including time series forecasting, classification, and anomaly detection show the superior performance of Hydra compared to state-of-the-art baselines.</li>
</ul>

<h3>Title: MID: A Self-supervised Multimodal Iterative Denoising Framework</h3>
<ul>
<li><strong>Authors: </strong>Chang Nie, Tianchen Deng, Zhe Liu, Hesheng Wang</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.00997">https://arxiv.org/abs/2511.00997</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.00997">https://arxiv.org/pdf/2511.00997</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.00997]] MID: A Self-supervised Multimodal Iterative Denoising Framework(https://arxiv.org/abs/2511.00997)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Data denoising is a persistent challenge across scientific and engineering domains. Real-world data is frequently corrupted by complex, non-linear noise, rendering traditional rule-based denoising methods inadequate. To overcome these obstacles, we propose a novel self-supervised multimodal iterative denoising (MID) framework. MID models the collected noisy data as a state within a continuous process of non-linear noise accumulation. By iteratively introducing further noise, MID learns two neural networks: one to estimate the current noise step and another to predict and subtract the corresponding noise increment. For complex non-linear contamination, MID employs a first-order Taylor expansion to locally linearize the noise process, enabling effective iterative removal. Crucially, MID does not require paired clean-noisy datasets, as it learns noise characteristics directly from the noisy inputs. Experiments across four classic computer vision tasks demonstrate MID's robustness, adaptability, and consistent state-of-the-art performance. Moreover, MID exhibits strong performance and adaptability in tasks within the biomedical and bioinformatics domains.</li>
</ul>

<h3>Title: Integrating Visual and X-Ray Machine Learning Features in the Study of Paintings by Goya</h3>
<ul>
<li><strong>Authors: </strong>Hassan Ugail, Ismail Lujain Jaleel</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.01000">https://arxiv.org/abs/2511.01000</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.01000">https://arxiv.org/pdf/2511.01000</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.01000]] Integrating Visual and X-Ray Machine Learning Features in the Study of Paintings by Goya(https://arxiv.org/abs/2511.01000)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction</a></li>
<li><strong>Abstract: </strong>Art authentication of Francisco Goya's works presents complex computational challenges due to his heterogeneous stylistic evolution and extensive historical patterns of forgery. We introduce a novel multimodal machine learning framework that applies identical feature extraction techniques to both visual and X-ray radiographic images of Goya paintings. The unified feature extraction pipeline incorporates Grey-Level Co-occurrence Matrix descriptors, Local Binary Patterns, entropy measures, energy calculations, and colour distribution analysis applied consistently across both imaging modalities. The extracted features from both visual and X-ray images are processed through an optimised One-Class Support Vector Machine with hyperparameter tuning. Using a dataset of 24 authenticated Goya paintings with corresponding X-ray images, split into an 80/20 train-test configuration with 10-fold cross-validation, the framework achieves 97.8% classification accuracy with a 0.022 false positive rate. Case study analysis of ``Un Gigante'' demonstrates the practical efficacy of our pipeline, achieving 92.3% authentication confidence through unified multimodal feature analysis. Our results indicate substantial performance improvement over single-modal approaches, establishing the effectiveness of applying identical computational methods to both visual and radiographic imagery in art authentication applications.</li>
</ul>

<h3>Title: MARS-SQL: A multi-agent reinforcement learning framework for Text-to-SQL</h3>
<ul>
<li><strong>Authors: </strong>Haolin Yang, Jipeng Zhang, Zhitao He, Yi R. Fung</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.01008">https://arxiv.org/abs/2511.01008</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.01008">https://arxiv.org/pdf/2511.01008</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.01008]] MARS-SQL: A multi-agent reinforcement learning framework for Text-to-SQL(https://arxiv.org/abs/2511.01008)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, generative</a></li>
<li><strong>Abstract: </strong>Translating natural language to SQL remains difficult for complex queries. Such queries often need environmental interaction and self-correction. To address this, we introduce MARS-SQL, a novel multi-agent framework that combines principled task decomposition and interactive reinforcement learning (RL). Our system comprises three specialized agents: a Grounding Agent for schema linking, a Generation Agent for query generation, and a Validation Agent for final selection. The core of our framework is the Generation agent, which is trained via a multi-turn RL policy. Adopting a ReAct-style Think-Act-Observe loop, the agent iteratively generates thoughts, executes SQL actions against a live database, and revises its strategy based on execution feedback, enabling dynamic, stateful reasoning and self-correction. At inference time, we generate multiple interaction trajectories to explore diverse reasoning paths. The Validation agent, then selects the optimal trajectory by modeling verification as a next-token prediction task and choosing the solution with the highest generation probability. This structured workflow pipelines specialized agents. It combines interactive RL for generation with generative modeling for verification. The approach proves highly effective for robust and accurate SQL generation. Experiments show that MARS-SQL achieves state-of-the-art Execution Accuracy of 77.84% on the BIRD dev set and 89.75% on the Spider test set. Our code is available at this https URL.</li>
</ul>

<h3>Title: HyFormer-Net: A Synergistic CNN-Transformer with Interpretable Multi-Scale Fusion for Breast Lesion Segmentation and Classification in Ultrasound Images</h3>
<ul>
<li><strong>Authors: </strong>Mohammad Amanour Rahman</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.01013">https://arxiv.org/abs/2511.01013</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.01013">https://arxiv.org/pdf/2511.01013</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.01013]] HyFormer-Net: A Synergistic CNN-Transformer with Interpretable Multi-Scale Fusion for Breast Lesion Segmentation and Classification in Ultrasound Images(https://arxiv.org/abs/2511.01013)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability, explainability, transformer, segmentation</a></li>
<li><strong>Abstract: </strong>B-mode ultrasound for breast cancer diagnosis faces challenges: speckle, operator dependency, and indistinct boundaries. Existing deep learning suffers from single-task learning, architectural constraints (CNNs lack global context, Transformers local features), and black-box decision-making. These gaps hinder clinical adoption. We propose HyFormer-Net, a hybrid CNN-Transformer for simultaneous segmentation and classification with intrinsic interpretability. Its dual-branch encoder integrates EfficientNet-B3 and Swin Transformer via multi-scale hierarchical fusion blocks. An attention-gated decoder provides precision and explainability. We introduce dual-pipeline interpretability: (1) intrinsic attention validation with quantitative IoU verification (mean: 0.86), and (2) Grad-CAM for classification reasoning. On the BUSI dataset, HyFormer-Net achieves Dice Score 0.761 +/- 0.072 and accuracy 93.2%, outperforming U-Net, Attention U-Net, and TransUNet. Malignant Recall of 92.1 +/- 2.2% ensures minimal false negatives. Ensemble modeling yields exceptional Dice 90.2%, accuracy 99.5%, and perfect 100% Malignant Recall, eliminating false negatives. Ablation studies confirm multi-scale fusion contributes +16.8% Dice and attention gates add +5.9%. Crucially, we conduct the first cross-dataset generalization study for hybrid CNN-Transformers in breast ultrasound. Zero-shot transfer fails (Dice: 0.058), confirming domain shift. However, progressive fine-tuning with only 10% target-domain data (68 images) recovers 92.5% performance. With 50% data, our model achieves 77.3% Dice, exceeding source-domain performance (76.1%) and demonstrating true generalization.</li>
</ul>

<h3>Title: IF-CRITIC: Towards a Fine-Grained LLM Critic for Instruction-Following Evaluation</h3>
<ul>
<li><strong>Authors: </strong>Bosi Wen, Yilin Niu, Cunxiang Wang, Pei Ke, Xiaoying Ling, Ying Zhang, Aohan Zeng, Hongning Wang, Minlie Huang</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.01014">https://arxiv.org/abs/2511.01014</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.01014">https://arxiv.org/pdf/2511.01014</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.01014]] IF-CRITIC: Towards a Fine-Grained LLM Critic for Instruction-Following Evaluation(https://arxiv.org/abs/2511.01014)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Instruction following is a fundamental ability of Large Language Models (LLMs), requiring their generated outputs to follow multiple constraints imposed in input instructions. Numerous studies have attempted to enhance this ability through preference optimization or reinforcement learning based on reward signals from LLM-as-a-Judge. However, existing evaluation models for instruction following still possess many deficiencies, such as substantial costs and unreliable assessments. To this end, we propose IF-CRITIC, an LLM critic that can provide efficient and reliable assessments of constraint following in the instructions. We first develop a checklist generator to decompose instructions and generate constraint checklists. With the assistance of the checklists, we collect high-quality critique training data through a multi-stage critique filtering mechanism and employ a constraint-level preference optimization method to train IF-CRITIC. Extensive experiments demonstrate that the evaluation performance of IF-CRITIC can beat strong LLM-as-a-Judge baselines, including Deepseek-R1 and o4-mini. With the scalable reward signals provided by IF-CRITIC, LLMs can achieve substantial performance gains in instruction-following optimization under lower computational overhead compared to strong LLM critic baselines.</li>
</ul>

<h3>Title: Prompt-R1: Collaborative Automatic Prompting Framework via End-to-end Reinforcement Learning</h3>
<ul>
<li><strong>Authors: </strong>Wenjin Liu, Haoran Luo, Xueyuan Lin, Haoming Liu, Tiesunlong Shen, Jiapu Wang, Rui Mao, Erik Cambria</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.01016">https://arxiv.org/abs/2511.01016</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.01016">https://arxiv.org/pdf/2511.01016</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.01016]] Prompt-R1: Collaborative Automatic Prompting Framework via End-to-end Reinforcement Learning(https://arxiv.org/abs/2511.01016)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Recently, advanced large language models (LLMs) have emerged at an increasingly rapid pace. However, when faced with complex problems, most users are often unable to provide accurate and effective prompts to interact with LLMs, thus limiting the performance of LLMs. To address this challenge, we propose Prompt-R1, an end-to-end reinforcement learning framework that uses a small-scale LLM to collaborate with large-scale LLMs, replacing user interaction to solve problems better. This collaboration is cast as a multi-turn prompt interaction, where the small-scale LLM thinks and generates prompts, and the large-scale LLM performs complex reasoning. A dual-constrained reward is designed to optimize for correctness, generation quality, and reasoning accuracy. Prompt-R1 provides a plug-and-play framework that supports both inference and training with various large-scale LLMs. Experiments on multiple public datasets show that Prompt-R1 significantly outperforms baseline models across tasks. Our code is publicly available at this https URL.</li>
</ul>

<h3>Title: SARIMAX-Based Power Outage Prediction During Extreme Weather Events</h3>
<ul>
<li><strong>Authors: </strong>Haoran Ye, Qiuzhuang Sun, Yang Yang</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.01017">https://arxiv.org/abs/2511.01017</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.01017">https://arxiv.org/pdf/2511.01017</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.01017]] SARIMAX-Based Power Outage Prediction During Extreme Weather Events(https://arxiv.org/abs/2511.01017)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>This study develops a SARIMAX-based prediction system for short-term power outage forecasting during extreme weather events. Using hourly data from Michigan counties with outage counts and comprehensive weather features, we implement a systematic two-stage feature engineering pipeline: data cleaning to remove zero-variance and unknown features, followed by correlation-based filtering to eliminate highly correlated predictors. The selected features are augmented with temporal embeddings, multi-scale lag features, and weather variables with their corresponding lags as exogenous inputs to the SARIMAX model. To address data irregularity and numerical instability, we apply standardization and implement a hierarchical fitting strategy with sequential optimization methods, automatic downgrading to ARIMA when convergence fails, and historical mean-based fallback predictions as a final safeguard. The model is optimized separately for short-term (24 hours) and medium-term (48 hours) forecast horizons using RMSE as the evaluation metric. Our approach achieves an RMSE of 177.2, representing an 8.4\% improvement over the baseline method (RMSE = 193.4), thereby validating the effectiveness of our feature engineering and robust optimization strategy for extreme weather-related outage prediction.</li>
</ul>

<h3>Title: OceanAI: A Conversational Platform for Accurate, Transparent, Near-Real-Time Oceanographic Insights</h3>
<ul>
<li><strong>Authors: </strong>Bowen Chen, Jayesh Gajbhar, Gregory Dusek, Rob Redmon, Patrick Hogan, Paul Liu, DelWayne Bohnenstiehl, Dongkuan (DK)Xu, Ruoying He</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.CE, cs.LG, physics.ao-ph</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.01019">https://arxiv.org/abs/2511.01019</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.01019">https://arxiv.org/pdf/2511.01019</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.01019]] OceanAI: A Conversational Platform for Accurate, Transparent, Near-Real-Time Oceanographic Insights(https://arxiv.org/abs/2511.01019)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Artificial intelligence is transforming the sciences, yet general conversational AI systems often generate unverified "hallucinations" undermining scientific rigor. We present OceanAI, a conversational platform that integrates the natural-language fluency of open-source large language models (LLMs) with real-time, parameterized access to authoritative oceanographic data streams hosted by the National Oceanic and Atmospheric Administration (NOAA). Each query such as "What was Boston Harbor's highest water level in 2024?" triggers real-time API calls that identify, parse, and synthesize relevant datasets into reproducible natural-language responses and data visualizations. In a blind comparison with three widely used AI chat-interface products, only OceanAI produced NOAA-sourced values with original data references; others either declined to answer or provided unsupported results. Designed for extensibility, OceanAI connects to multiple NOAA data products and variables, supporting applications in marine hazard forecasting, ecosystem assessment, and water-quality monitoring. By grounding outputs and verifiable observations, OceanAI advances transparency, reproducibility, and trust, offering a scalable framework for AI-enabled decision support within the oceans. A public demonstration is available at this https URL.</li>
</ul>

<h3>Title: VayuChat: An LLM-Powered Conversational Interface for Air Quality Data Analytics</h3>
<ul>
<li><strong>Authors: </strong>Vedant Acharya, Abhay Pisharodi, Rishabh Mondal, Mohammad Rafiuddin, Nipun Batra</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.01046">https://arxiv.org/abs/2511.01046</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.01046">https://arxiv.org/pdf/2511.01046</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.01046]] VayuChat: An LLM-Powered Conversational Interface for Air Quality Data Analytics(https://arxiv.org/abs/2511.01046)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Air pollution causes about 1.6 million premature deaths each year in India, yet decision makers struggle to turn dispersed data into decisions. Existing tools require expertise and provide static dashboards, leaving key policy questions unresolved. We present VayuChat, a conversational system that answers natural language questions on air quality, meteorology, and policy programs, and responds with both executable Python code and interactive visualizations. VayuChat integrates data from Central Pollution Control Board (CPCB) monitoring stations, state-level demographics, and National Clean Air Programme (NCAP) funding records into a unified interface powered by large language models. Our live demonstration will show how users can perform complex environmental analytics through simple conversations, making data science accessible to policymakers, researchers, and citizens. The platform is publicly deployed at this https URL VayuChat. For further information check out video uploaded on this https URL.</li>
</ul>

<h3>Title: Building a Silver-Standard Dataset from NICE Guidelines for Clinical LLMs</h3>
<ul>
<li><strong>Authors: </strong>Qing Ding, Eric Hua Qing Zhang, Felix Jozsa, Julia Ive</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.01053">https://arxiv.org/abs/2511.01053</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.01053">https://arxiv.org/pdf/2511.01053</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.01053]] Building a Silver-Standard Dataset from NICE Guidelines for Clinical LLMs(https://arxiv.org/abs/2511.01053)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large language models (LLMs) are increasingly used in healthcare, yet standardised benchmarks for evaluating guideline-based clinical reasoning are missing. This study introduces a validated dataset derived from publicly available guidelines across multiple diagnoses. The dataset was created with the help of GPT and contains realistic patient scenarios, as well as clinical questions. We benchmark a range of recent popular LLMs to showcase the validity of our dataset. The framework supports systematic evaluation of LLMs' clinical utility and guideline adherence.</li>
</ul>

<h3>Title: MedEqualizer: A Framework Investigating Bias in Synthetic Medical Data and Mitigation via Augmentation</h3>
<ul>
<li><strong>Authors: </strong>Sama Salarian, Yue Zhang, Swati Padhee, Srinivasan Parthasarathy</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.01054">https://arxiv.org/abs/2511.01054</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.01054">https://arxiv.org/pdf/2511.01054</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.01054]] MedEqualizer: A Framework Investigating Bias in Synthetic Medical Data and Mitigation via Augmentation(https://arxiv.org/abs/2511.01054)</code><input type="text"></li>
<li><strong>Keywords: </strong>protect, fair, generative</a></li>
<li><strong>Abstract: </strong>Synthetic healthcare data generation presents a viable approach to enhance data accessibility and support research by overcoming limitations associated with real-world medical datasets. However, ensuring fairness across protected attributes in synthetic data is critical to avoid biased or misleading results in clinical research and decision-making. In this study, we assess the fairness of synthetic data generated by multiple generative adversarial network (GAN)-based models using the MIMIC-III dataset, with a focus on representativeness across protected demographic attributes. We measure subgroup representation using the logarithmic disparity metric and observe significant imbalances, with many subgroups either underrepresented or overrepresented in the synthetic data, compared to the real data. To mitigate these disparities, we introduce MedEqualizer, a model-agnostic augmentation framework that enriches the underrepresented subgroups prior to synthetic data generation. Our results show that MedEqualizer significantly improves demographic balance in the resulting synthetic datasets, offering a viable path towards more equitable and representative healthcare data synthesis.</li>
</ul>

<h3>Title: Window-Based Feature Engineering for Cognitive Workload Detection</h3>
<ul>
<li><strong>Authors: </strong>Andrew Hallam, R G Gayathri, Glory Lee, Atul Sajjanhar</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.01060">https://arxiv.org/abs/2511.01060</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.01060">https://arxiv.org/pdf/2511.01060</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.01060]] Window-Based Feature Engineering for Cognitive Workload Detection(https://arxiv.org/abs/2511.01060)</code><input type="text"></li>
<li><strong>Keywords: </strong>defense, extraction</a></li>
<li><strong>Abstract: </strong>Cognitive workload is a topic of increasing interest across various fields such as health, psychology, and defense applications. In this research, we focus on classifying cognitive workload using the COLET dataset, employing a window-based approach for feature generation and machine/deep learning techniques for classification. We apply window-based temporal partitioning to enhance features used in existing research, followed by machine learning and deep learning models to classify different levels of cognitive workload. The results demonstrate that deep learning models, particularly tabular architectures, outperformed traditional machine learning methods in precision, F1-score, accuracy, and classification precision. This study highlights the effectiveness of window-based temporal feature extraction and the potential of deep learning techniques for real-time cognitive workload assessment in complex and dynamic tasks.</li>
</ul>

<h3>Title: Energy-Efficient Deep Learning Without Backpropagation: A Rigorous Evaluation of Forward-Only Algorithms</h3>
<ul>
<li><strong>Authors: </strong>Przemysław Spyra, Witold Dzwinel</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.01061">https://arxiv.org/abs/2511.01061</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.01061">https://arxiv.org/pdf/2511.01061</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.01061]] Energy-Efficient Deep Learning Without Backpropagation: A Rigorous Evaluation of Forward-Only Algorithms(https://arxiv.org/abs/2511.01061)</code><input type="text"></li>
<li><strong>Keywords: </strong>fair</a></li>
<li><strong>Abstract: </strong>The long-held assumption that backpropagation (BP) is essential for state-of-the-art performance is challenged by this work. We present rigorous, hardware-validated evidence that the Mono-Forward (MF) algorithm, a backpropagation-free method, consistently surpasses an optimally tuned BP baseline in classification accuracy on its native Multi-Layer Perceptron (MLP) architectures. This superior generalization is achieved with profound efficiency gains, including up to 41% less energy consumption and up to 34% faster training. Our analysis, which charts an evolutionary path from Geoffrey Hinton's Forward-Forward (FF) to the Cascaded Forward (CaFo) and finally to MF, is grounded in a fair comparative framework using identical architectures and universal hyperparameter optimization. We further provide a critical re-evaluation of memory efficiency in BP-free methods, empirically demonstrating that practical overhead can offset theoretical gains. Ultimately, this work establishes MF as a practical, high-performance, and sustainable alternative to BP for MLPs.</li>
</ul>

<h3>Title: HPLT~3.0: Very Large-Scale Multilingual Resources for LLM and MT. Mono- and Bi-lingual Data, Multilingual Evaluation, and Pre-Trained Models</h3>
<ul>
<li><strong>Authors: </strong>Stephan Oepen, Nikolay Arefev, Mikko Aulamo, Marta Bañón, Maja Buljan, Laurie Burchell, Lucas Charpentier, Pinzhen Chen, Mariya Fedorova, Ona de Gibert, Barry Haddow, Jan Hajič, Jindrič Helcl, Andrey Kutuzov, Zihao Li, Risto Luukkonen, Bhavitvya Malik, Vladislav Mikhailov, Amanda Myntti, Dayyán O'Brien, Lucie Poláková, Sampo Pyysalo, Gema Ramírez Sánchez, Janine Siewert, Pavel Stepachev, Jörg Tiedemann, Teemu Vahtola, Fedor Vitiugin, Tea Vojtěchová, Jaume Zaragoza</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.01066">https://arxiv.org/abs/2511.01066</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.01066">https://arxiv.org/pdf/2511.01066</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.01066]] HPLT~3.0: Very Large-Scale Multilingual Resources for LLM and MT. Mono- and Bi-lingual Data, Multilingual Evaluation, and Pre-Trained Models(https://arxiv.org/abs/2511.01066)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction</a></li>
<li><strong>Abstract: </strong>We present an ongoing initiative to provide open, very large, high-quality, and richly annotated textual datasets for almost 200 languages. At 30 trillion tokens, this is likely the largest generally available multilingual collection of LLM pre-training data. At 30 trillion tokens, this is likely the largest generally available multilingual collection of LLM pre-training data. These datasets are derived from web crawls from different sources and accompanied with a complete, open-source pipeline for document selection from web archives, text extraction from HTML, language identification for noisy texts, exact and near-deduplication, annotation with, among others, register labels, text quality estimates, and personally identifiable information; and final selection and filtering. We report on data quality probes through contrastive and analytical statistics, through manual inspection of samples for 24 languages, and through end-to-end evaluation of various language model architectures trained on this data. For multilingual LLM evaluation, we provide a comprehensive collection of benchmarks for nine European languages, with special emphasis on natively created tasks, mechanisms to mitigate prompt sensitivity, and refined normalization and aggregation of scores. Additionally, we train and evaluate a family of 57 monolingual encoder-decoder models, as well as a handful of monolingual GPT-like reference models. Besides the monolingual data and models, we also present a very large collection of parallel texts automatically mined from this data, together with a novel parallel corpus synthesized via machine translation.</li>
</ul>

<h3>Title: Happiness as a Measure of Fairness</h3>
<ul>
<li><strong>Authors: </strong>Georg Pichler, Marco Romanelli, Pablo Piantanida</a></li>
<li><strong>Subjects: </strong>cs.LG, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.01069">https://arxiv.org/abs/2511.01069</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.01069">https://arxiv.org/pdf/2511.01069</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.01069]] Happiness as a Measure of Fairness(https://arxiv.org/abs/2511.01069)</code><input type="text"></li>
<li><strong>Keywords: </strong>fair</a></li>
<li><strong>Abstract: </strong>In this paper, we propose a novel fairness framework grounded in the concept of happi- ness, a measure of the utility each group gains fromdecisionoutcomes. Bycapturingfairness through this intuitive lens, we not only offer a more human-centered approach, but also one that is mathematically rigorous: In order to compute the optimal, fair post-processing strategy, only a linear program needs to be solved. This makes our method both efficient and scalable with existing optimization tools. Furthermore, it unifies and extends several well-known fairness definitions, and our em- pirical results highlight its practical strengths across diverse scenarios.</li>
</ul>

<h3>Title: AI Progress Should Be Measured by Capability-Per-Resource, Not Scale Alone: A Framework for Gradient-Guided Resource Allocation in LLMs</h3>
<ul>
<li><strong>Authors: </strong>David McCoy, Yulun Wu, Zachary Butzin-Dozier</a></li>
<li><strong>Subjects: </strong>cs.LG, stat.CO</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.01077">https://arxiv.org/abs/2511.01077</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.01077">https://arxiv.org/pdf/2511.01077</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.01077]] AI Progress Should Be Measured by Capability-Per-Resource, Not Scale Alone: A Framework for Gradient-Guided Resource Allocation in LLMs(https://arxiv.org/abs/2511.01077)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>This position paper challenges the "scaling fundamentalism" dominating AI research, where unbounded growth in model size and computation has led to unsustainable environmental impacts and widening resource inequality. We argue that LLM development should be fundamentally reoriented toward capability-per-resource rather than capability alone. We present a theoretical framework demonstrating that resource-allocation decisions guided by gradient influence patterns can dramatically improve efficiency throughout the AI lifecycle. Our analysis shows that in transformer-based models, where a small fraction of parameters exert outsized influence (following heavy-tailed distributions), three critical insights emerge: (1) updating only high-influence parameters strictly outperforms full-parameter tuning on a performance-per-resource basis; (2) simple gradient norms provide computationally efficient proxies for identifying these high-influence components; and (3) coordinated parameter and data selection yields multiplicative efficiency gains, potentially reducing resource requirements by orders of magnitude. Building on these theoretical foundations, we propose a two stage paradigm marginal-return pretraining for foundation developers and influence guided adaptation for downstream users bridged by gradient blueprints, metadata describing which parameters matter most for various tasks. This capability-per-resource perspective transforms what were once considered pragmatic hardware workarounds into theoretically optimal strategies, democratizing access to cutting-edge AI capabilities while significantly reducing environmental impact. By embedding resource consciousness into how we develop, adapt, and evaluate models, we can reshape AI progress toward a more sustainable and equitable future.</li>
</ul>

<h3>Title: T-MLA: A Targeted Multiscale Log--Exponential Attack Framework for Neural Image Compression</h3>
<ul>
<li><strong>Authors: </strong>Nikolay I. Kalmykov, Razan Dibo, Kaiyu Shen, Xu Zhonghan, Anh-Huy Phan, Yipeng Liu, Ivan Oseledets</a></li>
<li><strong>Subjects: </strong>cs.CV, math.NA</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.01079">https://arxiv.org/abs/2511.01079</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.01079">https://arxiv.org/pdf/2511.01079</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.01079]] T-MLA: A Targeted Multiscale Log--Exponential Attack Framework for Neural Image Compression(https://arxiv.org/abs/2511.01079)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, attack, steal, generative</a></li>
<li><strong>Abstract: </strong>Neural image compression (NIC) has become the state-of-the-art for rate-distortion performance, yet its security vulnerabilities remain significantly less understood than those of classifiers. Existing adversarial attacks on NICs are often naive adaptations of pixel-space methods, overlooking the unique, structured nature of the compression pipeline. In this work, we propose a more advanced class of vulnerabilities by introducing T-MLA, the first targeted multiscale log--exponential attack framework. Our approach crafts adversarial perturbations in the wavelet domain by directly targeting the quality of the attacked and reconstructed images. This allows for a principled, offline attack where perturbations are strategically confined to specific wavelet subbands, maximizing distortion while ensuring perceptual stealth. Extensive evaluation across multiple state-of-the-art NIC architectures on standard image compression benchmarks reveals a large drop in reconstruction quality while the perturbations remain visually imperceptible. Our findings reveal a critical security flaw at the core of generative and content delivery pipelines.</li>
</ul>

<h3>Title: GeoToken: Hierarchical Geolocalization of Images via Next Token Prediction</h3>
<ul>
<li><strong>Authors: </strong>Narges Ghasemi, Amir Ziashahabi, Salman Avestimehr, Cyrus Shahabi</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.01082">https://arxiv.org/abs/2511.01082</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.01082">https://arxiv.org/pdf/2511.01082</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.01082]] GeoToken: Hierarchical Geolocalization of Images via Next Token Prediction(https://arxiv.org/abs/2511.01082)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Image geolocalization, the task of determining an image's geographic origin, poses significant challenges, largely due to visual similarities across disparate locations and the large search space. To address these issues, we propose a hierarchical sequence prediction approach inspired by how humans narrow down locations from broad regions to specific addresses. Analogously, our model predicts geographic tokens hierarchically, first identifying a general region and then sequentially refining predictions to increasingly precise locations. Rather than relying on explicit semantic partitions, our method uses S2 cells, a nested, multiresolution global grid, and sequentially predicts finer-level cells conditioned on visual inputs and previous predictions. This procedure mirrors autoregressive text generation in large language models. Much like in language modeling, final performance depends not only on training but also on inference-time strategy. We investigate multiple top-down traversal methods for autoregressive sampling, incorporating techniques from test-time compute scaling used in language models. Specifically, we integrate beam search and multi-sample inference while exploring various selection strategies to determine the final output. This enables the model to manage uncertainty by exploring multiple plausible paths through the hierarchy. We evaluate our method on the Im2GPS3k and YFCC4k datasets against two distinct sets of baselines: those that operate without a Multimodal Large Language Model (MLLM) and those that leverage one. In the MLLM-free setting, our model surpasses other comparable baselines on nearly all metrics, achieving state-of-the-art performance with accuracy gains of up to 13.9%. When augmented with an MLLM, our model outperforms all baselines, setting a new state-of-the-art across all metrics. The source code is available at this https URL.</li>
</ul>

<h3>Title: SliceVision-F2I: A Synthetic Feature-to-Image Dataset for Visual Pattern Representation on Network Slices</h3>
<ul>
<li><strong>Authors: </strong>Md. Abid Hasan Rafi, Mst. Fatematuj Johora, Pankaj Bhowmik</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.01087">https://arxiv.org/abs/2511.01087</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.01087">https://arxiv.org/pdf/2511.01087</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.01087]] SliceVision-F2I: A Synthetic Feature-to-Image Dataset for Visual Pattern Representation on Network Slices(https://arxiv.org/abs/2511.01087)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>The emergence of 5G and 6G networks has established network slicing as a significant part of future service-oriented architectures, demanding refined identification methods supported by robust datasets. The article presents SliceVision-F2I, a dataset of synthetic samples for studying feature visualization in network slicing for next-generation networking systems. The dataset transforms multivariate Key Performance Indicator (KPI) vectors into visual representations through four distinct encoding methods: physically inspired mappings, Perlin noise, neural wallpapering, and fractal branching. For each encoding method, 30,000 samples are generated, each comprising a raw KPI vector and a corresponding RGB image at low-resolution pixels. The dataset simulates realistic and noisy network conditions to reflect operational uncertainties and measurement imperfections. SliceVision-F2I is suitable for tasks involving visual learning, network state classification, anomaly detection, and benchmarking of image-based machine learning techniques applied to network data. The dataset is publicly available and can be reused in various research contexts, including multivariate time series analysis, synthetic data generation, and feature-to-image transformations.</li>
</ul>

<h3>Title: Improving Romanian LLM Pretraining Data using Diversity and Quality Filtering</h3>
<ul>
<li><strong>Authors: </strong>Vlad Negoita, Mihai Masala, Traian Rebedea</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.01090">https://arxiv.org/abs/2511.01090</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.01090">https://arxiv.org/pdf/2511.01090</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.01090]] Improving Romanian LLM Pretraining Data using Diversity and Quality Filtering(https://arxiv.org/abs/2511.01090)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large Language Models (LLMs) have recently exploded in popularity, often matching or outperforming human abilities on many tasks. One of the key factors in training LLMs is the availability and curation of high-quality data. Data quality is especially crucial for under-represented languages, where high-quality corpora are scarce. In this work we study the characteristics and coverage of Romanian pretraining corpora and we examine how they differ from English data. By training a lightweight multitask model on carefully LLM-annotated Romanian texts, we are able to analyze and perform multi-level filtering (e.g., educational value, topic, format) to generate high-quality pretraining datasets. Our experiments show noteworthy trends in the topics present in Romanian and English data, while also proving the effectiveness of filtering data through improved LLM pretraining performance across multiple benchmarks.</li>
</ul>

<h3>Title: Anatomically Constrained Transformers for Echocardiogram Analysis</h3>
<ul>
<li><strong>Authors: </strong>Alexander Thorley, Agis Chartsias, Jordan Strom, Jeremy Slivnick, Dipak Kotecha, Alberto Gomez, Jinming Duan</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.01109">https://arxiv.org/abs/2511.01109</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.01109">https://arxiv.org/pdf/2511.01109</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.01109]] Anatomically Constrained Transformers for Echocardiogram Analysis(https://arxiv.org/abs/2511.01109)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Video transformers have recently demonstrated strong potential for echocardiogram (echo) analysis, leveraging self-supervised pre-training and flexible adaptation across diverse tasks. However, like other models operating on videos, they are prone to learning spurious correlations from non-diagnostic regions such as image backgrounds. To overcome this limitation, we propose the Video Anatomically Constrained Transformer (ViACT), a novel framework that integrates anatomical priors directly into the transformer architecture. ViACT represents a deforming anatomical structure as a point set and encodes both its spatial geometry and corresponding image patches into transformer tokens. During pre-training, ViACT follows a masked autoencoding strategy that masks and reconstructs only anatomical patches, enforcing that representation learning is focused on the anatomical region. The pre-trained model can then be fine-tuned for tasks localized to this region. In this work we focus on the myocardium, demonstrating the framework on echo analysis tasks such as left ventricular ejection fraction (EF) regression and cardiac amyloidosis (CA) detection. The anatomical constraint focuses transformer attention within the myocardium, yielding interpretable attention maps aligned with regions of known CA pathology. Moreover, ViACT generalizes to myocardium point tracking without requiring task-specific components such as correlation volumes used in specialized tracking networks.</li>
</ul>

<h3>Title: Verification and Attack Synthesis for Network Protocols</h3>
<ul>
<li><strong>Authors: </strong>Max von Hippel</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.FL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.01124">https://arxiv.org/abs/2511.01124</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.01124">https://arxiv.org/pdf/2511.01124</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.01124]] Verification and Attack Synthesis for Network Protocols(https://arxiv.org/abs/2511.01124)</code><input type="text"></li>
<li><strong>Keywords: </strong>secure, attack</a></li>
<li><strong>Abstract: </strong>Network protocols are programs with inputs and outputs that follow predefined communication patterns to synchronize and exchange information. There are many protocols and each serves a different purpose, e.g., routing, transport, secure communication, etc. The functional and performance requirements for a protocol can be expressed using a formal specification, such as, a set of logical predicates over its traces. A protocol could be prevented from achieving its requirements due to a bug in its design or implementation, a component failure (e.g., a crash), or an attack. This dissertation shows that formal methods can feasibly characterize the functionality and performance of network protocols under normal conditions as well as when subjected to attacks.</li>
</ul>

<h3>Title: One model to solve them all: 2BSDE families via neural operators</h3>
<ul>
<li><strong>Authors: </strong>Takashi Furuya, Anastasis Kratsios, Dylan Possamaï, Bogdan Raonić</a></li>
<li><strong>Subjects: </strong>cs.LG, math.AP, math.NA, math.PR, q-fin.CP</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.01125">https://arxiv.org/abs/2511.01125</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.01125">https://arxiv.org/pdf/2511.01125</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.01125]] One model to solve them all: 2BSDE families via neural operators(https://arxiv.org/abs/2511.01125)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>We introduce a mild generative variant of the classical neural operator model, which leverages Kolmogorov--Arnold networks to solve infinite families of second-order backward stochastic differential equations ($2$BSDEs) on regular bounded Euclidean domains with random terminal time. Our first main result shows that the solution operator associated with a broad range of $2$BSDE families is approximable by appropriate neural operator models. We then identify a structured subclass of (infinite) families of $2$BSDEs whose neural operator approximation requires only a polynomial number of parameters in the reciprocal approximation rate, as opposed to the exponential requirement in general worst-case neural operator guarantees.</li>
</ul>

<h3>Title: Stochastic Regret Guarantees for Online Zeroth- and First-Order Bilevel Optimization</h3>
<ul>
<li><strong>Authors: </strong>Parvin Nazari, Bojian Hou, Davoud Ataee Tarzanagh, Li Shen, George Michailidis</a></li>
<li><strong>Subjects: </strong>cs.LG, math.NA, math.OC, math.ST</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.01126">https://arxiv.org/abs/2511.01126</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.01126">https://arxiv.org/pdf/2511.01126</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.01126]] Stochastic Regret Guarantees for Online Zeroth- and First-Order Bilevel Optimization(https://arxiv.org/abs/2511.01126)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack</a></li>
<li><strong>Abstract: </strong>Online bilevel optimization (OBO) is a powerful framework for machine learning problems where both outer and inner objectives evolve over time, requiring dynamic updates. Current OBO approaches rely on deterministic \textit{window-smoothed} regret minimization, which may not accurately reflect system performance when functions change rapidly. In this work, we introduce a novel search direction and show that both first- and zeroth-order (ZO) stochastic OBO algorithms leveraging this direction achieve sublinear {stochastic bilevel regret without window smoothing}. Beyond these guarantees, our framework enhances efficiency by: (i) reducing oracle dependence in hypergradient estimation, (ii) updating inner and outer variables alongside the linear system solution, and (iii) employing ZO-based estimation of Hessians, Jacobians, and gradients. Experiments on online parametric loss tuning and black-box adversarial attacks validate our approach.</li>
</ul>

<h3>Title: Learning with Category-Equivariant Architectures for Human Activity Recognition</h3>
<ul>
<li><strong>Authors: </strong>Yoshihiro Maruyama</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI, cs.HC, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.01139">https://arxiv.org/abs/2511.01139</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.01139">https://arxiv.org/pdf/2511.01139</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.01139]] Learning with Category-Equivariant Architectures for Human Activity Recognition(https://arxiv.org/abs/2511.01139)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>We propose CatEquiv, a category-equivariant neural network for Human Activity Recognition (HAR) from inertial sensors that systematically encodes temporal, amplitude, and structural symmetries. In particular, we introduce the categorical symmetry product where cyclic time shifts, positive gains and the sensor-hierarchy poset together capture the categorical symmetry structure of the data. CatEquiv achieves equivariance with respect to the categorical symmetry product. On UCI-HAR under out-of-distribution perturbations, CatEquiv attains markedly higher robustness compared with circularly padded CNNs and plain CNNs. These results demonstrate that enforcing categorical symmetries yields strong invariance and generalization without additional model capacity.</li>
</ul>

<h3>Title: MicroAUNet: Boundary-Enhanced Multi-scale Fusion with Knowledge Distillation for Colonoscopy Polyp Image Segmentation</h3>
<ul>
<li><strong>Authors: </strong>Ziyi Wang, Yuanmei Zhang, Dorna Esrafilzadeh, Ali R. Jalili, Suncheng Xiang</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.01143">https://arxiv.org/abs/2511.01143</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.01143">https://arxiv.org/pdf/2511.01143</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.01143]] MicroAUNet: Boundary-Enhanced Multi-scale Fusion with Knowledge Distillation for Colonoscopy Polyp Image Segmentation(https://arxiv.org/abs/2511.01143)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>Early and accurate segmentation of colorectal polyps is critical for reducing colorectal cancer mortality, which has been extensively explored by academia and industry. However, current deep learning-based polyp segmentation models either compromise clinical decision-making by providing ambiguous polyp margins in segmentation outputs or rely on heavy architectures with high computational complexity, resulting in insufficient inference speeds for real-time colorectal endoscopic applications. To address this problem, we propose MicroAUNet, a light-weighted attention-based segmentation network that combines depthwise-separable dilated convolutions with a single-path, parameter-shared channel-spatial attention block to strengthen multi-scale boundary features. On the basis of it, a progressive two-stage knowledge-distillation scheme is introduced to transfer semantic and boundary cues from a high-capacity teacher. Extensive experiments on benchmarks also demonstrate the state-of-the-art accuracy under extremely low model complexity, indicating that MicroAUNet is suitable for real-time clinical polyp segmentation. The code is publicly available at this https URL.</li>
</ul>

<h3>Title: AthenaBench: A Dynamic Benchmark for Evaluating LLMs in Cyber Threat Intelligence</h3>
<ul>
<li><strong>Authors: </strong>Md Tanvirul Alam, Dipkamal Bhusal, Salman Ahmad, Nidhi Rastogi, Peter Worth</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.01144">https://arxiv.org/abs/2511.01144</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.01144">https://arxiv.org/pdf/2511.01144</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.01144]] AthenaBench: A Dynamic Benchmark for Evaluating LLMs in Cyber Threat Intelligence(https://arxiv.org/abs/2511.01144)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large Language Models (LLMs) have demonstrated strong capabilities in natural language reasoning, yet their application to Cyber Threat Intelligence (CTI) remains limited. CTI analysis involves distilling large volumes of unstructured reports into actionable knowledge, a process where LLMs could substantially reduce analyst workload. CTIBench introduced a comprehensive benchmark for evaluating LLMs across multiple CTI tasks. In this work, we extend CTIBench by developing AthenaBench, an enhanced benchmark that includes an improved dataset creation pipeline, duplicate removal, refined evaluation metrics, and a new task focused on risk mitigation strategies. We evaluate twelve LLMs, including state-of-the-art proprietary models such as GPT-5 and Gemini-2.5 Pro, alongside seven open-source models from the LLaMA and Qwen families. While proprietary LLMs achieve stronger results overall, their performance remains subpar on reasoning-intensive tasks, such as threat actor attribution and risk mitigation, with open-source models trailing even further behind. These findings highlight fundamental limitations in the reasoning capabilities of current LLMs and underscore the need for models explicitly tailored to CTI workflows and automation.</li>
</ul>

<h3>Title: MicroRemed: Benchmarking LLMs in Microservices Remediation</h3>
<ul>
<li><strong>Authors: </strong>Lingzhe Zhang, Yunpeng Zhai, Tong Jia, Chiming Duan, Minghua He, Leyi Pan, Zhaoyang Liu, Bolin Ding, Ying Li</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.SE</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.01166">https://arxiv.org/abs/2511.01166</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.01166">https://arxiv.org/pdf/2511.01166</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.01166]] MicroRemed: Benchmarking LLMs in Microservices Remediation(https://arxiv.org/abs/2511.01166)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large Language Models (LLMs) integrated with agent-based reasoning frameworks have recently shown strong potential for autonomous decision-making and system-level operations. One promising yet underexplored direction is microservice remediation, where the goal is to automatically recover faulty microservice systems. Existing approaches, however, still rely on human-crafted prompts from Site Reliability Engineers (SREs), with LLMs merely converting textual instructions into executable code. To advance research in this area, we introduce MicroRemed, the first benchmark for evaluating LLMs in end-to-end microservice remediation, where models must directly generate executable Ansible playbooks from diagnosis reports to restore system functionality. We further propose ThinkRemed, a multi-agent framework that emulates the reflective and perceptive reasoning of SREs. Experimental results show that MicroRemed presents substantial challenges to current LLMs, while ThinkRemed improves end-to-end remediation performance through iterative reasoning and system reflection. The benchmark is available at this https URL.</li>
</ul>

<h3>Title: Adapt under Attack and Domain Shift: Unified Adversarial Meta-Learning and Domain Adaptation for Robust Automatic Modulation Classification</h3>
<ul>
<li><strong>Authors: </strong>Ali Owfi, Amirmohammad Bamdad, Tolunay Seyfi, Fatemeh Afghah</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, eess.SP</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.01172">https://arxiv.org/abs/2511.01172</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.01172">https://arxiv.org/pdf/2511.01172</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.01172]] Adapt under Attack and Domain Shift: Unified Adversarial Meta-Learning and Domain Adaptation for Robust Automatic Modulation Classification(https://arxiv.org/abs/2511.01172)</code><input type="text"></li>
<li><strong>Keywords: </strong>defense, attack, robust</a></li>
<li><strong>Abstract: </strong>Deep learning has emerged as a leading approach for Automatic Modulation Classification (AMC), demonstrating superior performance over traditional methods. However, vulnerability to adversarial attacks and susceptibility to data distribution shifts hinder their practical deployment in real-world, dynamic environments. To address these threats, we propose a novel, unified framework that integrates meta-learning with domain adaptation, making AMC systems resistant to both adversarial attacks and environmental changes. Our framework utilizes a two-phase strategy. First, in an offline phase, we employ a meta-learning approach to train the model on clean and adversarially perturbed samples from a single source domain. This method enables the model to generalize its defense, making it resistant to a combination of previously unseen attacks. Subsequently, in the online phase, we apply domain adaptation to align the model's features with a new target domain, allowing it to adapt without requiring substantial labeled data. As a result, our framework achieves a significant improvement in modulation classification accuracy against these combined threats, offering a critical solution to the deployment and operational challenges of modern AMC systems.</li>
</ul>

<h3>Title: Diffusion Transformer meets Multi-level Wavelet Spectrum for Single Image Super-Resolution</h3>
<ul>
<li><strong>Authors: </strong>Peng Du, Hui Li, Han Xu, Paul Barom Jeon, Dongwook Lee, Daehyun Ji, Ran Yang, Feng Zhu</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.01175">https://arxiv.org/abs/2511.01175</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.01175">https://arxiv.org/pdf/2511.01175</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.01175]] Diffusion Transformer meets Multi-level Wavelet Spectrum for Single Image Super-Resolution(https://arxiv.org/abs/2511.01175)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, transformer</a></li>
<li><strong>Abstract: </strong>Discrete Wavelet Transform (DWT) has been widely explored to enhance the performance of image superresolution (SR). Despite some DWT-based methods improving SR by capturing fine-grained frequency signals, most existing approaches neglect the interrelations among multiscale frequency sub-bands, resulting in inconsistencies and unnatural artifacts in the reconstructed images. To address this challenge, we propose a Diffusion Transformer model based on image Wavelet spectra for SR (DTWSR).DTWSR incorporates the superiority of diffusion models and transformers to capture the interrelations among multiscale frequency sub-bands, leading to a more consistence and realistic SR image. Specifically, we use a Multi-level Discrete Wavelet Transform (MDWT) to decompose images into wavelet spectra. A pyramid tokenization method is proposed which embeds the spectra into a sequence of tokens for transformer model, facilitating to capture features from both spatial and frequency domain. A dual-decoder is designed elaborately to handle the distinct variances in lowfrequency (LF) and high-frequency (HF) sub-bands, without omitting their alignment in image generation. Extensive experiments on multiple benchmark datasets demonstrate the effectiveness of our method, with high performance on both perception quality and fidelity.</li>
</ul>

<h3>Title: A Large Scale Study of AI-based Binary Function Similarity Detection Techniques for Security Researchers and Practitioners</h3>
<ul>
<li><strong>Authors: </strong>Jingyi Shi, Yufeng Chen, Yang Xiao, Yuekang Li, Zhengzi Xu, Sihao Qiu, Chi Zhang, Keyu Qi, Yeting Li, Xingchu Chen, Yanyan Zou, Yang Liu, Wei Huo</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.SE</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.01180">https://arxiv.org/abs/2511.01180</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.01180">https://arxiv.org/pdf/2511.01180</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.01180]] A Large Scale Study of AI-based Binary Function Similarity Detection Techniques for Security Researchers and Practitioners(https://arxiv.org/abs/2511.01180)</code><input type="text"></li>
<li><strong>Keywords: </strong>security</a></li>
<li><strong>Abstract: </strong>Binary Function Similarity Detection (BFSD) is a foundational technique in software security, underpinning a wide range of applications including vulnerability detection, malware analysis. Recent advances in AI-based BFSD tools have led to significant performance improvements. However, existing evaluations of these tools suffer from three key limitations: a lack of in-depth analysis of performance-influencing factors, an absence of realistic application analysis, and reliance on small-scale or low-quality datasets. In this paper, we present the first large-scale empirical study of AI-based BFSD tools to address these gaps. We construct two high-quality and diverse datasets: BinAtlas, comprising 12,453 binaries and over 7 million functions for capability evaluation; and BinAres, containing 12,291 binaries and 54 real-world 1-day vulnerabilities for evaluating vulnerability detection performance in practical IoT firmware settings. Using these datasets, we evaluate nine representative BFSD tools, analyze the challenges and limitations of existing BFSD tools, and investigate the consistency among BFSD tools. We also propose an actionable strategy for combining BFSD tools to enhance overall performance (an improvement of 13.4%). Our study not only advances the practical adoption of BFSD tools but also provides valuable resources and insights to guide future research in scalable and automated binary similarity detection.</li>
</ul>

<h3>Title: Learning When to Quit in Sales Conversations</h3>
<ul>
<li><strong>Authors: </strong>Emaad Manzoor, Eva Ascarza, Oded Netzer</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.01181">https://arxiv.org/abs/2511.01181</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.01181">https://arxiv.org/pdf/2511.01181</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.01181]] Learning When to Quit in Sales Conversations(https://arxiv.org/abs/2511.01181)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative, large language model</a></li>
<li><strong>Abstract: </strong>Salespeople frequently face the dynamic screening decision of whether to persist in a conversation or abandon it to pursue the next lead. Yet, little is known about how these decisions are made, whether they are efficient, or how to improve them. We study these decisions in the context of high-volume outbound sales where leads are ample, but time is scarce and failure is common. We formalize the dynamic screening decision as an optimal stopping problem and develop a generative language model-based sequential decision agent - a stopping agent - that learns whether and when to quit conversations by imitating a retrospectively-inferred optimal stopping policy. Our approach handles high-dimensional textual states, scales to large language models, and works with both open-source and proprietary language models. When applied to calls from a large European telecommunications firm, our stopping agent reduces the time spent on failed calls by 54% while preserving nearly all sales; reallocating the time saved increases expected sales by up to 37%. Upon examining the linguistic cues that drive salespeople's quitting decisions, we find that they tend to overweight a few salient expressions of consumer disinterest and mispredict call failure risk, suggesting cognitive bounds on their ability to make real-time conversational decisions. Our findings highlight the potential of artificial intelligence algorithms to correct cognitively-bounded human decisions and improve salesforce efficiency.</li>
</ul>

<h3>Title: A Comparative Study of Model Adaptation Strategies for Multi-Treatment Uplift Modeling</h3>
<ul>
<li><strong>Authors: </strong>Ruyue Zhang, Xiaopeng Ke, Ming Liu, Fangzhou Shi, Chang Men, Zhengdan Zhu</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.01185">https://arxiv.org/abs/2511.01185</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.01185">https://arxiv.org/pdf/2511.01185</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.01185]] A Comparative Study of Model Adaptation Strategies for Multi-Treatment Uplift Modeling(https://arxiv.org/abs/2511.01185)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Uplift modeling has emerged as a crucial technique for individualized treatment effect estimation, particularly in fields such as marketing and healthcare. Modeling uplift effects in multi-treatment scenarios plays a key role in real-world applications. Current techniques for modeling multi-treatment uplift are typically adapted from binary-treatment works. In this paper, we investigate and categorize all current model adaptations into two types: Structure Adaptation and Feature Adaptation. Through our empirical experiments, we find that these two adaptation types cannot maintain effectiveness under various data characteristics (noisy data, mixed with observational data, etc.). To enhance estimation ability and robustness, we propose Orthogonal Function Adaptation (OFA) based on the function approximation theorem. We conduct comprehensive experiments with multiple data characteristics to study the effectiveness and robustness of all model adaptation techniques. Our experimental results demonstrate that our proposed OFA can significantly improve uplift model performance compared to other vanilla adaptation methods and exhibits the highest robustness.</li>
</ul>

<h3>Title: Surfacing Subtle Stereotypes: A Multilingual, Debate-Oriented Evaluation of Modern LLMs</h3>
<ul>
<li><strong>Authors: </strong>Muhammed Saeed, Muhammad Abdul-mageed, Shady Shehata</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.CY</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.01187">https://arxiv.org/abs/2511.01187</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.01187">https://arxiv.org/pdf/2511.01187</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.01187]] Surfacing Subtle Stereotypes: A Multilingual, Debate-Oriented Evaluation of Modern LLMs(https://arxiv.org/abs/2511.01187)</code><input type="text"></li>
<li><strong>Keywords: </strong>fair, generative, large language model</a></li>
<li><strong>Abstract: </strong>Large language models (LLMs) are widely deployed for open-ended communication, yet most bias evaluations still rely on English, classification-style tasks. We introduce DebateBias-8K, a new multilingual, debate-style benchmark designed to reveal how narrative bias appears in realistic generative settings. Our dataset includes 8,400 structured debate prompts spanning four sensitive domains: women's rights, socioeconomic development, terrorism, and religion, across seven languages ranging from high-resource (English, Chinese) to low-resource (Swahili, Nigerian Pidgin). Using four flagship models (GPT-4o, Claude 3, DeepSeek, and LLaMA 3), we generate and automatically classify over 100,000 responses. Results show that all models reproduce entrenched stereotypes despite safety alignment: Arabs are overwhelmingly linked to terrorism and religion (>=95%), Africans to socioeconomic "backwardness" (up to <=77%), and Western groups are consistently framed as modern or progressive. Biases grow sharply in lower-resource languages, revealing that alignment trained primarily in English does not generalize globally. Our findings highlight a persistent divide in multilingual fairness: current alignment methods reduce explicit toxicity but fail to prevent biased outputs in open-ended contexts. We release our DebateBias-8K benchmark and analysis framework to support the next generation of multilingual bias evaluation and safer, culturally inclusive model alignment.</li>
</ul>

<h3>Title: ZoFia: Zero-Shot Fake News Detection with Entity-Guided Retrieval and Multi-LLM Interaction</h3>
<ul>
<li><strong>Authors: </strong>Lvhua Wu, Xuefeng Jiang, Sheng Sun, Tian Wen, Yuwei Wang, Min Liu</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.01188">https://arxiv.org/abs/2511.01188</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.01188">https://arxiv.org/pdf/2511.01188</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.01188]] ZoFia: Zero-Shot Fake News Detection with Entity-Guided Retrieval and Multi-LLM Interaction(https://arxiv.org/abs/2511.01188)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, large language model</a></li>
<li><strong>Abstract: </strong>The rapid spread of fake news threatens social stability and public trust, rendering its detection an imperative research priority. Although large language models (LLMs) excel at numerous natural language processing tasks with their remarkable contextual understanding and extensive prior knowledge, the time-bounded knowledge coverage and tendency for generating hallucination content reduce their reliability when handling fast-evolving news streams. Furthermore, models trained on existing static datasets also often lack the generalization needed for emerging news topics. To address these challenges, we propose ZoFia, a novel two-stage zero-shot fake news detection framework. First, we introduce Hierarchical Salience to quantify the importance of entities in the news content, and propose the SC-MMR algorithm to effectively select an informative and diverse set of keywords that serve as queries for retrieving up-to-date external evidence. Subsequently, a multi LLM interactive system, in which each agent assumes a distinct role, performs multi-view collaborative analysis and adversarial debate over the news text and its related information, and finally produces an interpretable and robust judgment. Comprehensive experiments on two public datasets demonstrate that ZoFia obviously outperforms existing zero-shot baselines and most of few-shot methods. Our codes will be open-sourced to facilitate related communities.</li>
</ul>

<h3>Title: Analyzing the Power of Chain of Thought through Memorization Capabilities</h3>
<ul>
<li><strong>Authors: </strong>Lijia Yu, Xiao-Shan Gao, Lijun Zhang</a></li>
<li><strong>Subjects: </strong>cs.LG, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.01190">https://arxiv.org/abs/2511.01190</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.01190">https://arxiv.org/pdf/2511.01190</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.01190]] Analyzing the Power of Chain of Thought through Memorization Capabilities(https://arxiv.org/abs/2511.01190)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer, large language model</a></li>
<li><strong>Abstract: </strong>It has been shown that the chain of thought (CoT) can enhance the power of large language models (LLMs) to solve certain mathematical reasoning problems. However, the capacity of CoT is still not fully explored. As an important instance, the following basic question has not yet been answered: Does CoT expand the capability of transformers across all reasoning tasks? We demonstrate that reasoning with transformers is essentially a memorization problem for reasoning datasets. Thus, examining the power of CoT across all reasoning tasks amounts to analyzing the memorization capabilities of CoT transformers. In this paper, we give a complete description of the memorization capabilities of fixed-precision transformers with or without CoT and give a negative answer to the above-mentioned question. Precisely, we first give necessary and sufficient conditions for fixed-precision transformers with and without CoT to memorize a finite reasoning dataset and show that these two conditions do not imply each other. Then, we give lower and upper bounds for the number of parameters needed for transformers with or without CoT to memorize a finite reasoning dataset with $N$ elements, which are $\overline{\Theta}(N)$ in all cases. This implies that there exist reasoning tasks for which CoT does not enhance the reasoning power of transformers, leading to a negative answer to the above-mentioned question. Finally, we give the first results on memorizing infinite reasoning datasets by CoT transformers and show that some simple infinite datasets cannot be memorized by transformers with or without CoT.</li>
</ul>

<h3>Title: Self-Harmony: Learning to Harmonize Self-Supervision and Self-Play in Test-Time Reinforcement Learning</h3>
<ul>
<li><strong>Authors: </strong>Ru Wang, Wei Huang, Qi Cao, Yusuke Iwasawa, Yutaka Matsuo, Jiaxian Guo</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.01191">https://arxiv.org/abs/2511.01191</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.01191">https://arxiv.org/pdf/2511.01191</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.01191]] Self-Harmony: Learning to Harmonize Self-Supervision and Self-Play in Test-Time Reinforcement Learning(https://arxiv.org/abs/2511.01191)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Test-time reinforcement learning (TTRL) offers a label-free paradigm for adapting models using only synthetic signals at inference, but its success hinges on constructing reliable learning signals. Standard approaches such as majority voting often collapse to spurious yet popular answers. We introduce Self-Harmony, a framework built on a simple intuition: the correct answer should remain stable across both an original question and its paraphrase. Self-Harmony operationalizes this by employing a single model in two complementary roles: a Solver to produce answers and a Reframer to rephrase the input. Based on this, we further propose a pseudo-label method: instead of majority voting, it aggregates answer frequencies across these original and reframed views using the harmonic mean. This is a process that naturally selects for solutions stable under reframing, thereby avoiding the common trap of favoring view-dependent, spurious answers. Crucially, this requires no human supervision or auxiliary models. Across diverse reasoning benchmarks, Self-Harmony achieves state-of-the-art results at the label-free test-time setting, ranking first in 28 of 30 settings across multiple methods. Beyond accuracy, it demonstrates unprecedented robustness, with zero training failures in all experiments, underscoring its stability and reliability.</li>
</ul>

<h3>Title: DEER: Disentangled Mixture of Experts with Instance-Adaptive Routing for Generalizable Machine-Generated Text Detection</h3>
<ul>
<li><strong>Authors: </strong>Guoxin Ma, Xiaoming Liu, Zhanhan Zhang, Chengzhengxu Li, Shengchao Liu, Yu Lan</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.01192">https://arxiv.org/abs/2511.01192</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.01192">https://arxiv.org/pdf/2511.01192</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.01192]] DEER: Disentangled Mixture of Experts with Instance-Adaptive Routing for Generalizable Machine-Generated Text Detection(https://arxiv.org/abs/2511.01192)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Detecting machine-generated text (MGT) has emerged as a critical challenge, driven by the rapid advancement of large language models (LLMs) capable of producing highly realistic, human-like content. However, the performance of current approaches often degrades significantly under domain shift. To address this challenge, we propose a novel framework designed to capture both domain-specific and domain-general MGT patterns through a two-stage Disentangled mixturE-of-ExpeRts (DEER) architecture. First, we introduce a disentangled mixture-of-experts module, in which domain-specific experts learn fine-grained, domain-local distinctions between human and machine-generated text, while shared experts extract transferable, cross-domain features. Second, to mitigate the practical limitation of unavailable domain labels during inference, we design a reinforcement learning-based routing mechanism that dynamically selects the appropriate experts for each input instance, effectively bridging the train-inference gap caused by domain uncertainty. Extensive experiments on five in-domain and five out-of-domain benchmark datasets demonstrate that DEER consistently outperforms state-of-the-art methods, achieving average F1-score improvements of 1.39% and 5.32% on in-domain and out-of-domain datasets respectively, along with accuracy gains of 1.35% and 3.61% respectively. Ablation studies confirm the critical contributions of both disentangled expert specialization and adaptive routing to model performance.</li>
</ul>

<h3>Title: CryptoMoE: Privacy-Preserving and Scalable Mixture of Experts Inference via Balanced Expert Routing</h3>
<ul>
<li><strong>Authors: </strong>Yifan Zhou, Tianshi Xu, Jue Hong, Ye Wu, Meng Li</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.01197">https://arxiv.org/abs/2511.01197</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.01197">https://arxiv.org/pdf/2511.01197</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.01197]] CryptoMoE: Privacy-Preserving and Scalable Mixture of Experts Inference via Balanced Expert Routing(https://arxiv.org/abs/2511.01197)</code><input type="text"></li>
<li><strong>Keywords: </strong>secure, privacy, protect, large language model</a></li>
<li><strong>Abstract: </strong>Private large language model (LLM) inference based on cryptographic primitives offers a promising path towards privacy-preserving deep learning. However, existing frameworks only support dense LLMs like LLaMA-1 and struggle to scale to mixture-of-experts (MoE) architectures. The key challenge comes from securely evaluating the dynamic routing mechanism in MoE layers, which may reveal sensitive input information if not fully protected. In this paper, we propose CryptoMoE, the first framework that enables private, efficient, and accurate inference for MoE-based models. CryptoMoE balances expert loads to protect expert routing information and proposes novel protocols for secure expert dispatch and combine. CryptoMoE also develops a confidence-aware token selection strategy and a batch matrix multiplication protocol to improve accuracy and efficiency further. Extensive experiments on DeepSeekMoE-16.4B, OLMoE-6.9B, and QWenMoE-14.3B show that CryptoMoE achieves $2.8\sim3.5\times$ end-to-end latency reduction and $2.9\sim4.3\times$ communication reduction over a dense baseline with minimum accuracy loss. We also adapt CipherPrune (ICLR'25) for MoE inference and demonstrate CryptoMoE can reduce the communication by up to $4.3 \times$. Code is available at: this https URL.</li>
</ul>

<h3>Title: Transmitter Identification and Protocol Categorization in Shared Spectrum via Multi-Task RF Classification at the Network Edge</h3>
<ul>
<li><strong>Authors: </strong>Tariq Abdul-Quddoos, Tasnia Sharmin, Xiangfang Li, Lijun Qian</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.01198">https://arxiv.org/abs/2511.01198</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.01198">https://arxiv.org/pdf/2511.01198</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.01198]] Transmitter Identification and Protocol Categorization in Shared Spectrum via Multi-Task RF Classification at the Network Edge(https://arxiv.org/abs/2511.01198)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, robust</a></li>
<li><strong>Abstract: </strong>As spectrum sharing becomes increasingly vital to meet rising wireless demands in the future, spectrum monitoring and transmitter identification are indispensable for enforcing spectrum usage policy, efficient spectrum utilization, and net- work security. This study proposed a robust framework for transmitter identification and protocol categorization via multi- task RF signal classification in shared spectrum environments, where the spectrum monitor will classify transmission protocols (e.g., 4G LTE, 5G-NR, IEEE 802.11a) operating within the same frequency bands, and identify different transmitting base stations, as well as their combinations. A Convolutional Neural Network (CNN) is designed to tackle critical challenges such as overlapping signal characteristics and environmental variability. The proposed method employs a multi-channel input strategy to extract meaningful signal features, achieving remarkable accuracy: 90% for protocol classification, 100% for transmitting base station classification, and 92% for joint classification tasks, utilizing RF data from the POWDER platform. These results highlight the significant potential of the proposed method to enhance spectrum monitoring, management, and security in modern wireless networks.</li>
</ul>

<h3>Title: MoSa: Motion Generation with Scalable Autoregressive Modeling</h3>
<ul>
<li><strong>Authors: </strong>Mengyuan Liu, Sheng Yan, Yong Wang, Yingjie Li, Gui-Bin Bian, Hong Liu</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.01200">https://arxiv.org/abs/2511.01200</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.01200">https://arxiv.org/pdf/2511.01200</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.01200]] MoSa: Motion Generation with Scalable Autoregressive Modeling(https://arxiv.org/abs/2511.01200)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer, generative</a></li>
<li><strong>Abstract: </strong>We introduce MoSa, a novel hierarchical motion generation framework for text-driven 3D human motion generation that enhances the Vector Quantization-guided Generative Transformers (VQ-GT) paradigm through a coarse-to-fine scalable generation process. In MoSa, we propose a Multi-scale Token Preservation Strategy (MTPS) integrated into a hierarchical residual vector quantization variational autoencoder (RQ-VAE). MTPS employs interpolation at each hierarchical quantization to effectively retain coarse-to-fine multi-scale tokens. With this, the generative transformer supports Scalable Autoregressive (SAR) modeling, which predicts scale tokens, unlike traditional methods that predict only one token at each step. Consequently, MoSa requires only 10 inference steps, matching the number of RQ-VAE quantization layers. To address potential reconstruction degradation from frequent interpolation, we propose CAQ-VAE, a lightweight yet expressive convolution-attention hybrid VQ-VAE. CAQ-VAE enhances residual block design and incorporates attention mechanisms to better capture global dependencies. Extensive experiments show that MoSa achieves state-of-the-art generation quality and efficiency, outperforming prior methods in both fidelity and speed. On the Motion-X dataset, MoSa achieves an FID of 0.06 (versus MoMask's 0.20) while reducing inference time by 27 percent. Moreover, MoSa generalizes well to downstream tasks such as motion editing, requiring no additional fine-tuning. The code is available at this https URL</li>
</ul>

<h3>Title: FEval-TTC: Fair Evaluation Protocol for Test-Time Compute</h3>
<ul>
<li><strong>Authors: </strong>Pavel Rumiantsev, Soumyasundar Pal, Yingxue Zhang, Mark Coates</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.01203">https://arxiv.org/abs/2511.01203</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.01203">https://arxiv.org/pdf/2511.01203</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.01203]] FEval-TTC: Fair Evaluation Protocol for Test-Time Compute(https://arxiv.org/abs/2511.01203)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction, fair, large language model</a></li>
<li><strong>Abstract: </strong>The performance of Large Language Models (LLMs) and the associated dollar costs of API calls can fluctuate over time, potentially invalidating conclusions drawn in prior research. To address this, we propose a Fair Evaluation protocol for Test-Time Compute (FEval-TTC), designed to ensure consistent assessment of test-time compute (TTC) methods, regardless of such fluctuations. FEval-TTC focuses on the evaluation of TTC methods that utilize underlying Chains-of-Thought (CoT). It supports evaluations across multiple LLMs on a diverse set of mathematical and commonsense reasoning datasets. The few-shot prompting and answer extraction processes are standardized across datasets, reducing both time and monetary overhead for researchers. Furthermore, we provide a cost modelling procedure that estimates both the token and dollar cost per query, facilitating equitable comparisons of prevalent TTC methods. We open-source FEval-TTC for public use at this https URL .</li>
</ul>

<h3>Title: A Saddle Point Remedy: Power of Variable Elimination in Non-convex Optimization</h3>
<ul>
<li><strong>Authors: </strong>Min Gan, Guang-Yong Chen, Yang Yi, Lin Yang</a></li>
<li><strong>Subjects: </strong>cs.LG, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.01234">https://arxiv.org/abs/2511.01234</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.01234">https://arxiv.org/pdf/2511.01234</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.01234]] A Saddle Point Remedy: Power of Variable Elimination in Non-convex Optimization(https://arxiv.org/abs/2511.01234)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>The proliferation of saddle points, rather than poor local minima, is increasingly understood to be a primary obstacle in large-scale non-convex optimization for machine learning. Variable elimination algorithms, like Variable Projection (VarPro), have long been observed to exhibit superior convergence and robustness in practice, yet a principled understanding of why they so effectively navigate these complex energy landscapes has remained elusive. In this work, we provide a rigorous geometric explanation by comparing the optimization landscapes of the original and reduced formulations. Through a rigorous analysis based on Hessian inertia and the Schur complement, we prove that variable elimination fundamentally reshapes the critical point structure of the objective function, revealing that local maxima in the reduced landscape are created from, and correspond directly to, saddle points in the original formulation. Our findings are illustrated on the canonical problem of non-convex matrix factorization, visualized directly on two-parameter neural networks, and finally validated in training deep Residual Networks, where our approach yields dramatic improvements in stability and convergence to superior minima. This work goes beyond explaining an existing method; it establishes landscape simplification via saddle point transformation as a powerful principle that can guide the design of a new generation of more robust and efficient optimization algorithms.</li>
</ul>

<h3>Title: Eyes on Target: Gaze-Aware Object Detection in Egocentric Video</h3>
<ul>
<li><strong>Authors: </strong>Vishakha Lall, Yisi Liu</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.01237">https://arxiv.org/abs/2511.01237</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.01237">https://arxiv.org/pdf/2511.01237</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.01237]] Eyes on Target: Gaze-Aware Object Detection in Egocentric Video(https://arxiv.org/abs/2511.01237)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Human gaze offers rich supervisory signals for understanding visual attention in complex visual environments. In this paper, we propose Eyes on Target, a novel depth-aware and gaze-guided object detection framework designed for egocentric videos. Our approach injects gaze-derived features into the attention mechanism of a Vision Transformer (ViT), effectively biasing spatial feature selection toward human-attended regions. Unlike traditional object detectors that treat all regions equally, our method emphasises viewer-prioritised areas to enhance object detection. We validate our method on an egocentric simulator dataset where human visual attention is critical for task assessment, illustrating its potential in evaluating human performance in simulation scenarios. We evaluate the effectiveness of our gaze-integrated model through extensive experiments and ablation studies, demonstrating consistent gains in detection accuracy over gaze-agnostic baselines on both the custom simulator dataset and public benchmarks, including Ego4D Ego-Motion and Ego-CH-Gaze datasets. To interpret model behaviour, we also introduce a gaze-aware attention head importance metric, revealing how gaze cues modulate transformer attention dynamics.</li>
</ul>

<h3>Title: Beyond Deceptive Flatness: Dual-Order Solution for Strengthening Adversarial Transferability</h3>
<ul>
<li><strong>Authors: </strong>Zhixuan Zhang, Pingyu Wang, Xingjian Zheng, Linbo Qing, Qi Liu</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.01240">https://arxiv.org/abs/2511.01240</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.01240">https://arxiv.org/pdf/2511.01240</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.01240]] Beyond Deceptive Flatness: Dual-Order Solution for Strengthening Adversarial Transferability(https://arxiv.org/abs/2511.01240)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack</a></li>
<li><strong>Abstract: </strong>Transferable attacks generate adversarial examples on surrogate models to fool unknown victim models, posing real-world threats and growing research interest. Despite focusing on flat losses for transferable adversarial examples, recent studies still fall into suboptimal regions, especially the flat-yet-sharp areas, termed as deceptive flatness. In this paper, we introduce a novel black-box gradient-based transferable attack from a perspective of dual-order information. Specifically, we feasibly propose Adversarial Flatness (AF) to the deceptive flatness problem and a theoretical assurance for adversarial transferability. Based on this, using an efficient approximation of our objective, we instantiate our attack as Adversarial Flatness Attack (AFA), addressing the altered gradient sign issue. Additionally, to further improve the attack ability, we devise MonteCarlo Adversarial Sampling (MCAS) by enhancing the inner-loop sampling efficiency. The comprehensive results on ImageNet-compatible dataset demonstrate superiority over six baselines, generating adversarial examples in flatter regions and boosting transferability across model architectures. When tested on input transformation attacks or the Baidu Cloud API, our method outperforms baselines.</li>
</ul>

<h3>Title: CenterMamba-SAM: Center-Prioritized Scanning and Temporal Prototypes for Brain Lesion Segmentation</h3>
<ul>
<li><strong>Authors: </strong>Yu Tian, Zhongheng Yang, Chenshi Liu, Yiyun Su, Ziwei Hong, Zexi Gong, Jingyuan Xu</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.01243">https://arxiv.org/abs/2511.01243</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.01243">https://arxiv.org/pdf/2511.01243</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.01243]] CenterMamba-SAM: Center-Prioritized Scanning and Temporal Prototypes for Brain Lesion Segmentation(https://arxiv.org/abs/2511.01243)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>Brain lesion segmentation remains challenging due to small, low-contrast lesions, anisotropic sampling, and cross-slice discontinuities. We propose CenterMamba-SAM, an end-to-end framework that freezes a pretrained backbone and trains only lightweight adapters for efficient fine-tuning. At its core is the CenterMamba encoder, which employs a novel 3x3 corner-axis-center short-sequence scanning strategy to enable center-prioritized, axis-reinforced, and diagonally compensated information aggregation. This design enhances sensitivity to weak boundaries and tiny foci while maintaining sparse yet effective feature representation. A memory-driven structural prompt generator maintains a prototype bank across neighboring slices, enabling automatic synthesis of reliable prompts without user interaction, thereby improving inter-slice coherence. The memory-augmented multi-scale decoder integrates memory attention modules at multiple levels, combining deep supervision with progressive refinement to restore fine details while preserving global consistency. Extensive experiments on public benchmarks demonstrate that CenterMamba-SAM achieves state-of-the-art performance in brain lesion segmentation.</li>
</ul>

<h3>Title: KAT-GNN: A Knowledge-Augmented Temporal Graph Neural Network for Risk Prediction in Electronic Health Records</h3>
<ul>
<li><strong>Authors: </strong>Kun-Wei Lin, Yu-Chen Kuo, Hsin-Yao Wang, Yi-Ju Tseng</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.01249">https://arxiv.org/abs/2511.01249</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.01249">https://arxiv.org/pdf/2511.01249</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.01249]] KAT-GNN: A Knowledge-Augmented Temporal Graph Neural Network for Risk Prediction in Electronic Health Records(https://arxiv.org/abs/2511.01249)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Clinical risk prediction using electronic health records (EHRs) is vital to facilitate timely interventions and clinical decision support. However, modeling heterogeneous and irregular temporal EHR data presents significant challenges. We propose \textbf{KAT-GNN} (Knowledge-Augmented Temporal Graph Neural Network), a graph-based framework that integrates clinical knowledge and temporal dynamics for risk prediction. KAT-GNN first constructs modality-specific patient graphs from EHRs. These graphs are then augmented using two knowledge sources: (1) ontology-driven edges derived from SNOMED CT and (2) co-occurrence priors extracted from EHRs. Subsequently, a time-aware transformer is employed to capture longitudinal dynamics from the graph-encoded patient representations. KAT-GNN is evaluated on three distinct datasets and tasks: coronary artery disease (CAD) prediction using the Chang Gung Research Database (CGRD) and in-hospital mortality prediction using the MIMIC-III and MIMIC-IV datasets. KAT-GNN achieves state-of-the-art performance in CAD prediction (AUROC: 0.9269 $\pm$ 0.0029) and demonstrated strong results in mortality prediction in MIMIC-III (AUROC: 0.9230 $\pm$ 0.0070) and MIMIC-IV (AUROC: 0.8849 $\pm$ 0.0089), consistently outperforming established baselines such as GRASP and RETAIN. Ablation studies confirm that both knowledge-based augmentation and the temporal modeling component are significant contributors to performance gains. These findings demonstrate that the integration of clinical knowledge into graph representations, coupled with a time-aware attention mechanism, provides an effective and generalizable approach for risk prediction across diverse clinical tasks and datasets.</li>
</ul>

<h3>Title: Source-Only Cross-Weather LiDAR via Geometry-Aware Point Drop</h3>
<ul>
<li><strong>Authors: </strong>YoungJae Cheong, Jhonghyun An</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.01250">https://arxiv.org/abs/2511.01250</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.01250">https://arxiv.org/pdf/2511.01250</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.01250]] Source-Only Cross-Weather LiDAR via Geometry-Aware Point Drop(https://arxiv.org/abs/2511.01250)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, segmentation</a></li>
<li><strong>Abstract: </strong>LiDAR semantic segmentation degrades in adverse weather because refraction, scattering, and point dropouts corrupt geometry. Prior work in weather simulation, mixing-based augmentation, domain randomization, and uncertainty or boundary regularization improves robustness but still overlooks structural vulnerabilities near boundaries, corners, and sparse regions. We present a Light Geometry-aware adapter. The module aligns azimuth and applies horizontal circular padding to preserve neighbor continuity across the 0~360 degree wrap-around boundary. A local-window K-Nearest Neighbors gathers nearby points and computes simple local statistics, which are compressed into compact geometry-aware cues. During training, these cues drive region-aware regularization that stabilizes predictions in structurally fragile areas. The adapter is plug and play, complements augmentation, and can be enabled only during training with negligible inference cost. We adopt a source-only cross-weather setup where models train on SemanticKITTI and are evaluated on SemanticSTF without target labels or fine-tuning. The adapter improves mIoU by 7.9 percentage points over the data-centric augmentation baseline and by 0.6 points over the class-centric regularization baseline. These results indicate that geometry-driven regularization is a key direction for all-weather LiDAR segmentation.</li>
</ul>

<h3>Title: AraFinNews: Arabic Financial Summarisation with Domain-Adapted LLMs</h3>
<ul>
<li><strong>Authors: </strong>Mo El-Haj, Paul Rayson</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.01265">https://arxiv.org/abs/2511.01265</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.01265">https://arxiv.org/pdf/2511.01265</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.01265]] AraFinNews: Arabic Financial Summarisation with Domain-Adapted LLMs(https://arxiv.org/abs/2511.01265)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, transformer, large language model</a></li>
<li><strong>Abstract: </strong>This paper investigates the impact of domain specificity on abstractive summarisation of Arabic financial texts using large language models (LLMs). We introduce AraFinNews, the largest publicly available Arabic financial news dataset to date, comprising 212,500 article--headline pairs spanning nearly a decade of reporting from October 2015 to July 2025. Designed as the Arabic equivalent of major English summarisation corpora such as CNN/DailyMail, AraFinNews provides a robust benchmark for evaluating domain-specific language understanding and generation in financial contexts. Using this resource, we evaluate transformer-based models -- including mT5, AraT5, and the domain-adapted FinAraT5 -- to examine how financial-domain pretraining influences factual accuracy, numerical reliability, and stylistic alignment with professional reporting. Experimental results show that domain-adapted models generate more faithful and coherent summaries, particularly in handling quantitative and entity-centric information. The findings highlight the importance of domain-specific adaptation for improving factual consistency and narrative fluency in Arabic financial summarisation. The dataset is freely available for non-commercial research at this https URL.</li>
</ul>

<h3>Title: A Spatio-Temporal Online Robust Tensor Recovery Approach for Streaming Traffic Data Imputation</h3>
<ul>
<li><strong>Authors: </strong>Yiyang Yang, Xiejian Chi, Shanxing Gao, Kaidong Wang, Yao Wang</a></li>
<li><strong>Subjects: </strong>cs.LG, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.01267">https://arxiv.org/abs/2511.01267</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.01267">https://arxiv.org/pdf/2511.01267</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.01267]] A Spatio-Temporal Online Robust Tensor Recovery Approach for Streaming Traffic Data Imputation(https://arxiv.org/abs/2511.01267)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Data quality is critical to Intelligent Transportation Systems (ITS), as complete and accurate traffic data underpin reliable decision-making in traffic control and management. Recent advances in low-rank tensor recovery algorithms have shown strong potential in capturing the inherent structure of high-dimensional traffic data and restoring degraded observations. However, traditional batch-based methods demand substantial computational and storage resources, which limits their scalability in the face of continuously expanding traffic data volumes. Moreover, recent online tensor recovery methods often suffer from severe performance degradation in complex real-world scenarios due to their insufficient exploitation of the intrinsic structural properties of traffic data. To address these challenges, we reformulate the traffic data recovery problem within a streaming framework, and propose a novel online robust tensor recovery algorithm that simultaneously leverages both the global spatio-temporal correlations and local consistency of traffic data, achieving high recovery accuracy and significantly improved computational efficiency in large-scale scenarios. Our method is capable of simultaneously handling missing and anomalous values in traffic data, and demonstrates strong adaptability across diverse missing patterns. Experimental results on three real-world traffic datasets demonstrate that the proposed approach achieves high recovery accuracy while significantly improving computational efficiency by up to three orders of magnitude compared to state-of-the-art batch-based methods. These findings highlight the potential of the proposed approach as a scalable and effective solution for traffic data quality enhancement in ITS.</li>
</ul>

<h3>Title: Rescuing the Unpoisoned: Efficient Defense against Knowledge Corruption Attacks on RAG Systems</h3>
<ul>
<li><strong>Authors: </strong>Minseok Kim, Hankook Lee, Hyungjoon Koo</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.AI, cs.IR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.01268">https://arxiv.org/abs/2511.01268</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.01268">https://arxiv.org/pdf/2511.01268</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.01268]] Rescuing the Unpoisoned: Efficient Defense against Knowledge Corruption Attacks on RAG Systems(https://arxiv.org/abs/2511.01268)</code><input type="text"></li>
<li><strong>Keywords: </strong>defense, attack, robust, large language model</a></li>
<li><strong>Abstract: </strong>Large language models (LLMs) are reshaping numerous facets of our daily lives, leading widespread adoption as web-based services. Despite their versatility, LLMs face notable challenges, such as generating hallucinated content and lacking access to up-to-date information. Lately, to address such limitations, Retrieval-Augmented Generation (RAG) has emerged as a promising direction by generating responses grounded in external knowledge sources. A typical RAG system consists of i) a retriever that probes a group of relevant passages from a knowledge base and ii) a generator that formulates a response based on the retrieved content. However, as with other AI systems, recent studies demonstrate the vulnerability of RAG, such as knowledge corruption attacks by injecting misleading information. In response, several defense strategies have been proposed, including having LLMs inspect the retrieved passages individually or fine-tuning robust retrievers. While effective, such approaches often come with substantial computational costs. In this work, we introduce RAGDefender, a resource-efficient defense mechanism against knowledge corruption (i.e., by data poisoning) attacks in practical RAG deployments. RAGDefender operates during the post-retrieval phase, leveraging lightweight machine learning techniques to detect and filter out adversarial content without requiring additional model training or inference. Our empirical evaluations show that RAGDefender consistently outperforms existing state-of-the-art defenses across multiple models and adversarial scenarios: e.g., RAGDefender reduces the attack success rate (ASR) against the Gemini model from 0.89 to as low as 0.02, compared to 0.69 for RobustRAG and 0.24 for Discern-and-Answer when adversarial passages outnumber legitimate ones by a factor of four (4x).</li>
</ul>

<h3>Title: PRevivor: Reviving Ancient Chinese Paintings using Prior-Guided Color Transformers</h3>
<ul>
<li><strong>Authors: </strong>Tan Tang, Yanhong Wu, Junming Gao, Yingcai Wu</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.01274">https://arxiv.org/abs/2511.01274</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.01274">https://arxiv.org/pdf/2511.01274</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.01274]] PRevivor: Reviving Ancient Chinese Paintings using Prior-Guided Color Transformers(https://arxiv.org/abs/2511.01274)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Ancient Chinese paintings are a valuable cultural heritage that is damaged by irreversible color degradation. Reviving color-degraded paintings is extraordinarily difficult due to the complex chemistry mechanism. Progress is further slowed by the lack of comprehensive, high-quality datasets, which hampers the creation of end-to-end digital restoration tools. To revive colors, we propose PRevivor, a prior-guided color transformer that learns from recent paintings (e.g., Ming and Qing Dynasty) to restore ancient ones (e.g., Tang and Song Dynasty). To develop PRevivor, we decompose color restoration into two sequential sub-tasks: luminance enhancement and hue correction. For luminance enhancement, we employ two variational U-Nets and a multi-scale mapping module to translate faded luminance into restored counterparts. For hue correction, we design a dual-branch color query module guided by localized hue priors extracted from faded paintings. Specifically, one branch focuses attention on regions guided by masked priors, enforcing localized hue correction, whereas the other branch remains unconstrained to maintain a global reasoning capability. To evaluate PRevivor, we conduct extensive experiments against state-of-the-art colorization methods. The results demonstrate superior performance both quantitatively and qualitatively.</li>
</ul>

<h3>Title: Adversarial Spatio-Temporal Attention Networks for Epileptic Seizure Forecasting</h3>
<ul>
<li><strong>Authors: </strong>Zan Li, Kyongmin Yeo, Wesley Gifford, Lara Marcuse, Madeline Fields, Bülent Yener</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.01275">https://arxiv.org/abs/2511.01275</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.01275">https://arxiv.org/pdf/2511.01275</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.01275]] Adversarial Spatio-Temporal Attention Networks for Epileptic Seizure Forecasting(https://arxiv.org/abs/2511.01275)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, interpretability</a></li>
<li><strong>Abstract: </strong>Forecasting epileptic seizures from multivariate EEG signals represents a critical challenge in healthcare time series prediction, requiring high sensitivity, low false alarm rates, and subject-specific adaptability. We present STAN, an Adversarial Spatio-Temporal Attention Network that jointly models spatial brain connectivity and temporal neural dynamics through cascaded attention blocks with alternating spatial and temporal modules. Unlike existing approaches that assume fixed preictal durations or separately process spatial and temporal features, STAN captures bidirectional dependencies between spatial and temporal patterns through a unified cascaded architecture. Adversarial training with gradient penalty enables robust discrimination between interictal and preictal states learned from clearly defined 15-minute preictal windows. Continuous 90-minute pre-seizure monitoring reveals that the learned spatio-temporal attention patterns enable early detection: reliable alarms trigger at subject-specific times (typically 15-45 minutes before onset), reflecting the model's capacity to capture subtle preictal dynamics without requiring individualized training. Experiments on two benchmark EEG datasets (CHB-MIT scalp: 8 subjects, 46 events; MSSM intracranial: 4 subjects, 14 events) demonstrate state-of-the-art performance: 96.6% sensitivity with 0.011 false detections per hour and 94.2% sensitivity with 0.063 false detections per hour, respectively, while maintaining computational efficiency (2.3M parameters, 45 ms latency, 180 MB memory) for real-time edge deployment. Beyond epilepsy, the proposed framework provides a general paradigm for spatio-temporal forecasting in healthcare and other time series domains where individual heterogeneity and interpretability are crucial.</li>
</ul>

<h3>Title: When, What, and How: Rethinking Retrieval-Enhanced Speculative Decoding</h3>
<ul>
<li><strong>Authors: </strong>Min Fang, Zhihui Fu, Qibin Zhao, Jun Wang</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.01282">https://arxiv.org/abs/2511.01282</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.01282">https://arxiv.org/pdf/2511.01282</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.01282]] When, What, and How: Rethinking Retrieval-Enhanced Speculative Decoding(https://arxiv.org/abs/2511.01282)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Speculative decoding (SD) has emerged as an effective technique to accelerate large language model (LLM) inference without compromising output quality. However, the achievable speedup largely depends on the effectiveness of the drafting model. While model-based methods like EAGLE-2 are accurate but costly, retrieval-enhanced methods like SAM-Decoding rely on heuristic switching strategies that often trigger unnecessary retrievals. To address this, we propose ReSpec (\textbf{Re}trieval-enhanced \textbf{Spe}culative Decoding), a novel framework that transforms heuristic drafter switching into adaptive decision-making. ReSpec features three core innovations: 1) An \textbf{entropy-guided adaptive trigger} quantifies contextual predictability to initiate retrieval only when uncertainty is low, avoiding costly low-quality speculations. 2) A \textbf{feedback-driven candidate selection} leverages historical feedback to organize multiple high-quality candidates for parallel verification, maximizing retrieval utility. 3) A source-aware \textbf{relaxed verification strategy} applies strict checks to model-generated drafts while using a relaxed verification for retrieved drafts, achieving a better balance between accuracy and efficiency. Extensive experiments on Spec-Bench demonstrate that ReSpec achieves state-of-the-art acceleration,outperforming EAGLE-2 and SAM-Decoding by over $33\%$ and $25\%$, respectively, while maintaining output quality.</li>
</ul>

<h3>Title: Adaptation of Foundation Models for Medical Image Analysis: Strategies, Challenges, and Future Directions</h3>
<ul>
<li><strong>Authors: </strong>Karma Phuntsho, Abdullah, Kyungmi Lee, Ickjai Lee, Euijoon Ahn</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.01284">https://arxiv.org/abs/2511.01284</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.01284">https://arxiv.org/pdf/2511.01284</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.01284]] Adaptation of Foundation Models for Medical Image Analysis: Strategies, Challenges, and Future Directions(https://arxiv.org/abs/2511.01284)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, robust, federate</a></li>
<li><strong>Abstract: </strong>Foundation models (FMs) have emerged as a transformative paradigm in medical image analysis, offering the potential to provide generalizable, task-agnostic solutions across a wide range of clinical tasks and imaging modalities. Their capacity to learn transferable representations from large-scale data has the potential to address the limitations of conventional task-specific models. However, adaptation of FMs to real-world clinical practice remains constrained by key challenges, including domain shifts, limited availability of high-quality annotated data, substantial computational demands, and strict privacy requirements. This review presents a comprehensive assessment of strategies for adapting FMs to the specific demands of medical imaging. We examine approaches such as supervised fine-tuning, domain-specific pretraining, parameter-efficient fine-tuning, self-supervised learning, hybrid methods, and multimodal or cross-modal frameworks. For each, we evaluate reported performance gains, clinical applicability, and limitations, while identifying trade-offs and unresolved challenges that prior reviews have often overlooked. Beyond these established techniques, we also highlight emerging directions aimed at addressing current gaps. These include continual learning to enable dynamic deployment, federated and privacy-preserving approaches to safeguard sensitive data, hybrid self-supervised learning to enhance data efficiency, data-centric pipelines that combine synthetic generation with human-in-the-loop validation, and systematic benchmarking to assess robust generalization under real-world clinical variability. By outlining these strategies and associated research gaps, this review provides a roadmap for developing adaptive, trustworthy, and clinically integrated FMs capable of meeting the demands of real-world medical imaging.</li>
</ul>

<h3>Title: "Give a Positive Review Only": An Early Investigation Into In-Paper Prompt Injection Attacks and Defenses for AI Reviewers</h3>
<ul>
<li><strong>Authors: </strong>Qin Zhou, Zhexin Zhang, Zhi Li, Limin Sun</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.01287">https://arxiv.org/abs/2511.01287</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.01287">https://arxiv.org/pdf/2511.01287</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.01287]] "Give a Positive Review Only": An Early Investigation Into In-Paper Prompt Injection Attacks and Defenses for AI Reviewers(https://arxiv.org/abs/2511.01287)</code><input type="text"></li>
<li><strong>Keywords: </strong>defense, attack, robust</a></li>
<li><strong>Abstract: </strong>With the rapid advancement of AI models, their deployment across diverse tasks has become increasingly widespread. A notable emerging application is leveraging AI models to assist in reviewing scientific papers. However, recent reports have revealed that some papers contain hidden, injected prompts designed to manipulate AI reviewers into providing overly favorable evaluations. In this work, we present an early systematic investigation into this emerging threat. We propose two classes of attacks: (1) static attack, which employs a fixed injection prompt, and (2) iterative attack, which optimizes the injection prompt against a simulated reviewer model to maximize its effectiveness. Both attacks achieve striking performance, frequently inducing full evaluation scores when targeting frontier AI reviewers. Furthermore, we show that these attacks are robust across various settings. To counter this threat, we explore a simple detection-based defense. While it substantially reduces the attack success rate, we demonstrate that an adaptive attacker can partially circumvent this defense. Our findings underscore the need for greater attention and rigorous safeguards against prompt-injection threats in AI-assisted peer review.</li>
</ul>

<h3>Title: FirstAidQA: A Synthetic Dataset for First Aid and Emergency Response in Low-Connectivity Settings</h3>
<ul>
<li><strong>Authors: </strong>Saiyma Sittul Muna, Rezwan Islam Salvi, Mushfiqur Rahman Mushfique, Ajwad Abrar</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.01289">https://arxiv.org/abs/2511.01289</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.01289">https://arxiv.org/pdf/2511.01289</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.01289]] FirstAidQA: A Synthetic Dataset for First Aid and Emergency Response in Low-Connectivity Settings(https://arxiv.org/abs/2511.01289)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>In emergency situations, every second counts. The deployment of Large Language Models (LLMs) in time-sensitive, low or zero-connectivity environments remains limited. Current models are computationally intensive and unsuitable for low-tier devices often used by first responders or civilians. A major barrier to developing lightweight, domain-specific solutions is the lack of high-quality datasets tailored to first aid and emergency response. To address this gap, we introduce FirstAidQA, a synthetic dataset containing 5,500 high-quality question answer pairs that encompass a wide range of first aid and emergency response scenarios. The dataset was generated using a Large Language Model, ChatGPT-4o-mini, with prompt-based in-context learning, using texts from the Vital First Aid Book (2019). We applied preprocessing steps such as text cleaning, contextual chunking, and filtering, followed by human validation to ensure accuracy, safety, and practical relevance of the QA pairs. FirstAidQA is designed to support instruction-tuning and fine-tuning of LLMs and Small Language Models (SLMs), enabling faster, more reliable, and offline-capable systems for emergency settings. We publicly release the dataset to advance research on safety-critical and resource-constrained AI applications in first aid and emergency response. The dataset is available on Hugging Face at this https URL.</li>
</ul>

<h3>Title: Detecting Generated Images by Fitting Natural Image Distributions</h3>
<ul>
<li><strong>Authors: </strong>Yonggang Zhang, Jun Nie, Xinmei Tian, Mingming Gong, Kun Zhang, Bo Han</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.01293">https://arxiv.org/abs/2511.01293</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.01293">https://arxiv.org/pdf/2511.01293</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.01293]] Detecting Generated Images by Fitting Natural Image Distributions(https://arxiv.org/abs/2511.01293)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, generative</a></li>
<li><strong>Abstract: </strong>The increasing realism of generated images has raised significant concerns about their potential misuse, necessitating robust detection methods. Current approaches mainly rely on training binary classifiers, which depend heavily on the quantity and quality of available generated images. In this work, we propose a novel framework that exploits geometric differences between the data manifolds of natural and generated images. To exploit this difference, we employ a pair of functions engineered to yield consistent outputs for natural images but divergent outputs for generated ones, leveraging the property that their gradients reside in mutually orthogonal subspaces. This design enables a simple yet effective detection method: an image is identified as generated if a transformation along its data manifold induces a significant change in the loss value of a self-supervised model pre-trained on natural images. Further more, to address diminishing manifold disparities in advanced generative models, we leverage normalizing flows to amplify detectable differences by extruding generated images away from the natural image manifold. Extensive experiments demonstrate the efficacy of this method. Code is available at this https URL.</li>
</ul>

<h3>Title: UniREditBench: A Unified Reasoning-based Image Editing Benchmark</h3>
<ul>
<li><strong>Authors: </strong>Feng Han, Yibin Wang, Chenglin Li, Zheming Liang, Dianyi Wang, Yang Jiao, Zhipeng Wei, Chao Gong, Cheng Jin, Jingjing Chen, Jiaqi Wang</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.01295">https://arxiv.org/abs/2511.01295</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.01295">https://arxiv.org/pdf/2511.01295</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.01295]] UniREditBench: A Unified Reasoning-based Image Editing Benchmark(https://arxiv.org/abs/2511.01295)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>Recent advances in multi-modal generative models have driven substantial improvements in image editing. However, current generative models still struggle with handling diverse and complex image editing tasks that require implicit reasoning, underscoring the need for a comprehensive benchmark to systematically assess their performance across various reasoning scenarios. Existing benchmarks primarily focus on single-object attribute transformation in realistic scenarios, which, while effective, encounter two key challenges: (1) they largely overlook multi-object interactions as well as game-world scenarios that involve human-defined rules, which are common in real-life applications; (2) they only rely on textual references to evaluate the generated images, potentially leading to systematic misjudgments, especially in complex reasoning scenarios. To this end, this work proposes UniREditBench, a unified benchmark for reasoning-based image editing evaluation. It comprises 2,700 meticulously curated samples, covering both real- and game-world scenarios across 8 primary dimensions and 18 sub-dimensions. To improve evaluation reliability, we introduce multimodal dual-reference evaluation, providing both textual and ground-truth image references for each sample assessment. Furthermore, we design an automated multi-scenario data synthesis pipeline and construct UniREdit-Data-100K, a large-scale synthetic dataset with high-quality chain-of-thought (CoT) reasoning annotations. We fine-tune Bagel on this dataset and develop UniREdit-Bagel, demonstrating substantial improvements in both in-domain and out-of-distribution settings. Through thorough benchmarking of both open-source and closed-source image editing models, we reveal their strengths and weaknesses across various aspects.</li>
</ul>

<h3>Title: LSHFed: Robust and Communication-Efficient Federated Learning with Locally-Sensitive Hashing Gradient Mapping</h3>
<ul>
<li><strong>Authors: </strong>Guanjie Cheng, Mengzhen Yang, Xinkui Zhao, Shuyi Yu, Tianyu Du, Yangyang Wu, Mengying Zhu, Shuiguang Deng</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.01296">https://arxiv.org/abs/2511.01296</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.01296">https://arxiv.org/pdf/2511.01296</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.01296]] LSHFed: Robust and Communication-Efficient Federated Learning with Locally-Sensitive Hashing Gradient Mapping(https://arxiv.org/abs/2511.01296)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, defense, attack, robust, federate</a></li>
<li><strong>Abstract: </strong>Federated learning (FL) enables collaborative model training across distributed nodes without exposing raw data, but its decentralized nature makes it vulnerable in trust-deficient environments. Inference attacks may recover sensitive information from gradient updates, while poisoning attacks can degrade model performance or induce malicious behaviors. Existing defenses often suffer from high communication and computation costs, or limited detection precision. To address these issues, we propose LSHFed, a robust and communication-efficient FL framework that simultaneously enhances aggregation robustness and privacy preservation. At its core, LSHFed incorporates LSHGM, a novel gradient verification mechanism that projects high-dimensional gradients into compact binary representations via multi-hyperplane locally-sensitive hashing. This enables accurate detection and filtering of malicious gradients using only their irreversible hash forms, thus mitigating privacy leakage risks and substantially reducing transmission overhead. Extensive experiments demonstrate that LSHFed maintains high model performance even when up to 50% of participants are collusive adversaries while achieving up to a 1000x reduction in gradient verification communication compared to full-gradient methods.</li>
</ul>

<h3>Title: REASON: Probability map-guided dual-branch fusion framework for gastric content assessment</h3>
<ul>
<li><strong>Authors: </strong>Nu-Fnag Xiao, De-Xing Huang, Le-Tian Wang, Mei-Jiang Gui, Qi Fu, Xiao-Liang Xie, Shi-Qi Liu, Shuangyi Wang, Zeng-Guang Hou, Ying-Wei Wang, Xiao-Hu Zhou</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.01302">https://arxiv.org/abs/2511.01302</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.01302">https://arxiv.org/pdf/2511.01302</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.01302]] REASON: Probability map-guided dual-branch fusion framework for gastric content assessment(https://arxiv.org/abs/2511.01302)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, segmentation</a></li>
<li><strong>Abstract: </strong>Accurate assessment of gastric content from ultrasound is critical for stratifying aspiration risk at induction of general anesthesia. However, traditional methods rely on manual tracing of gastric antra and empirical formulas, which face significant limitations in both efficiency and accuracy. To address these challenges, a novel two-stage probability map-guided dual-branch fusion framework (REASON) for gastric content assessment is proposed. In stage 1, a segmentation model generates probability maps that suppress artifacts and highlight gastric anatomy. In stage 2, a dual-branch classifier fuses information from two standard views, right lateral decubitus (RLD) and supine (SUP), to improve the discrimination of learned features. Experimental results on a self-collected dataset demonstrate that the proposed framework outperforms current state-of-the-art approaches by a significant margin. This framework shows great promise for automated preoperative aspiration risk assessment, offering a more robust, efficient, and accurate solution for clinical practice.</li>
</ul>

<h3>Title: Black-Box Differentially Private Nonparametric Confidence Intervals Under Minimal Assumptions</h3>
<ul>
<li><strong>Authors: </strong>Tomer Shoham, Moshe Shenfeld, Noa Velner-Harris, Katrina Ligett</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.01303">https://arxiv.org/abs/2511.01303</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.01303">https://arxiv.org/pdf/2511.01303</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.01303]] Black-Box Differentially Private Nonparametric Confidence Intervals Under Minimal Assumptions(https://arxiv.org/abs/2511.01303)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy</a></li>
<li><strong>Abstract: </strong>We introduce a simple, general framework that takes any differentially private estimator of any arbitrary quantity as a black box, and from it constructs a differentially private nonparametric confidence interval of that quantity. Our approach repeatedly subsamples the data, applies the private estimator to each subsample, and then post-processes the resulting empirical CDF to a confidence interval. Our analysis uses the randomness from the subsampling to achieve privacy amplification. Under mild assumptions, the empirical CDF we obtain approaches the CDF of the private statistic as the sample size grows. We use this to show that the confidence intervals we estimate are asymptotically valid, tight, and equivalent to their non-private counterparts. We provide empirical evidence that our method performs well compared with the (less-general) state-of-the-art algorithms.</li>
</ul>

<h3>Title: Positive Semi-definite Latent Factor Grouping-Boosted Cluster-reasoning Instance Disentangled Learning for WSI Representation</h3>
<ul>
<li><strong>Authors: </strong>Chentao Li, Behzad Bozorgtabar, Yifang Ping, Pan Huang, Jing Qin</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.01304">https://arxiv.org/abs/2511.01304</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.01304">https://arxiv.org/pdf/2511.01304</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.01304]] Positive Semi-definite Latent Factor Grouping-Boosted Cluster-reasoning Instance Disentangled Learning for WSI Representation(https://arxiv.org/abs/2511.01304)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability</a></li>
<li><strong>Abstract: </strong>Multiple instance learning (MIL) has been widely used for representing whole-slide pathology images. However, spatial, semantic, and decision entanglements among instances limit its representation and interpretability. To address these challenges, we propose a latent factor grouping-boosted cluster-reasoning instance disentangled learning framework for whole-slide image (WSI) interpretable representation in three phases. First, we introduce a novel positive semi-definite latent factor grouping that maps instances into a latent subspace, effectively mitigating spatial entanglement in MIL. To alleviate semantic entanglement, we employs instance probability counterfactual inference and optimization via cluster-reasoning instance disentangling. Finally, we employ a generalized linear weighted decision via instance effect re-weighting to address decision entanglement. Extensive experiments on multicentre datasets demonstrate that our model outperforms all state-of-the-art models. Moreover, it attains pathologist-aligned interpretability through disentangled representations and a transparent decision-making process.</li>
</ul>

<h3>Title: Perturb a Model, Not an Image: Towards Robust Privacy Protection via Anti-Personalized Diffusion Models</h3>
<ul>
<li><strong>Authors: </strong>Tae-Young Lee, Juwon Seo, Jong Hwan Ko, Gyeong-Moon Park</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.01307">https://arxiv.org/abs/2511.01307</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.01307">https://arxiv.org/pdf/2511.01307</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.01307]] Perturb a Model, Not an Image: Towards Robust Privacy Protection via Anti-Personalized Diffusion Models(https://arxiv.org/abs/2511.01307)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, protect, robust, diffusion, generative</a></li>
<li><strong>Abstract: </strong>Recent advances in diffusion models have enabled high-quality synthesis of specific subjects, such as identities or objects. This capability, while unlocking new possibilities in content creation, also introduces significant privacy risks, as personalization techniques can be misused by malicious users to generate unauthorized content. Although several studies have attempted to counter this by generating adversarially perturbed samples designed to disrupt personalization, they rely on unrealistic assumptions and become ineffective in the presence of even a few clean images or under simple image transformations. To address these challenges, we shift the protection target from the images to the diffusion model itself to hinder the personalization of specific subjects, through our novel framework called Anti-Personalized Diffusion Models (APDM). We first provide a theoretical analysis demonstrating that a naive approach of existing loss functions to diffusion models is inherently incapable of ensuring convergence for robust anti-personalization. Motivated by this finding, we introduce Direct Protective Optimization (DPO), a novel loss function that effectively disrupts subject personalization in the target model without compromising generative quality. Moreover, we propose a new dual-path optimization strategy, coined Learning to Protect (L2P). By alternating between personalization and protection paths, L2P simulates future personalization trajectories and adaptively reinforces protection at each step. Experimental results demonstrate that our framework outperforms existing methods, achieving state-of-the-art performance in preventing unauthorized personalization. The code is available at this https URL.</li>
</ul>

<h3>Title: MVSMamba: Multi-View Stereo with State Space Model</h3>
<ul>
<li><strong>Authors: </strong>Jianfei Jiang, Qiankun Liu, Hongyuan Liu, Haochen Yu, Liyong Wang, Jiansheng Chen, Huimin Ma</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.01315">https://arxiv.org/abs/2511.01315</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.01315">https://arxiv.org/pdf/2511.01315</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.01315]] MVSMamba: Multi-View Stereo with State Space Model(https://arxiv.org/abs/2511.01315)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, transformer</a></li>
<li><strong>Abstract: </strong>Robust feature representations are essential for learning-based Multi-View Stereo (MVS), which relies on accurate feature matching. Recent MVS methods leverage Transformers to capture long-range dependencies based on local features extracted by conventional feature pyramid networks. However, the quadratic complexity of Transformer-based MVS methods poses challenges to balance performance and efficiency. Motivated by the global modeling capability and linear complexity of the Mamba architecture, we propose MVSMamba, the first Mamba-based MVS network. MVSMamba enables efficient global feature aggregation with minimal computational overhead. To fully exploit Mamba's potential in MVS, we propose a Dynamic Mamba module (DM-module) based on a novel reference-centered dynamic scanning strategy, which enables: (1) Efficient intra- and inter-view feature interaction from the reference to source views, (2) Omnidirectional multi-view feature representations, and (3) Multi-scale global feature aggregation. Extensive experimental results demonstrate MVSMamba outperforms state-of-the-art MVS methods on the DTU dataset and the Tanks-and-Temples benchmark with both superior performance and efficiency. The source code is available at this https URL.</li>
</ul>

<h3>Title: A Generative Adversarial Approach to Adversarial Attacks Guided by Contrastive Language-Image Pre-trained Model</h3>
<ul>
<li><strong>Authors: </strong>Sampriti Soor, Alik Pramanick, Jothiprakash K, Arijit Sur</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.01317">https://arxiv.org/abs/2511.01317</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.01317">https://arxiv.org/pdf/2511.01317</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.01317]] A Generative Adversarial Approach to Adversarial Attacks Guided by Contrastive Language-Image Pre-trained Model(https://arxiv.org/abs/2511.01317)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack, generative</a></li>
<li><strong>Abstract: </strong>The rapid growth of deep learning has brought about powerful models that can handle various tasks, like identifying images and understanding language. However, adversarial attacks, an unnoticed alteration, can deceive models, leading to inaccurate predictions. In this paper, a generative adversarial attack method is proposed that uses the CLIP model to create highly effective and visually imperceptible adversarial perturbations. The CLIP model's ability to align text and image representation helps incorporate natural language semantics with a guided loss to generate effective adversarial examples that look identical to the original inputs. This integration allows extensive scene manipulation, creating perturbations in multi-object environments specifically designed to deceive multilabel classifiers. Our approach integrates the concentrated perturbation strategy from Saliency-based Auto-Encoder (SSAE) with the dissimilar text embeddings similar to Generative Adversarial Multi-Object Scene Attacks (GAMA), resulting in perturbations that both deceive classification models and maintain high structural similarity to the original images. The model was tested on various tasks across diverse black-box victim models. The experimental results show that our method performs competitively, achieving comparable or superior results to existing techniques, while preserving greater visual fidelity.</li>
</ul>

<h3>Title: DEEPAMBIGQA: Ambiguous Multi-hop Questions for Benchmarking LLM Answer Completeness</h3>
<ul>
<li><strong>Authors: </strong>Jiabao Ji, Min Li, Priyanshu Kumar, Shiyu Chang, Saloni Potdar</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.01323">https://arxiv.org/abs/2511.01323</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.01323">https://arxiv.org/pdf/2511.01323</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.01323]] DEEPAMBIGQA: Ambiguous Multi-hop Questions for Benchmarking LLM Answer Completeness(https://arxiv.org/abs/2511.01323)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, large language model</a></li>
<li><strong>Abstract: </strong>Large language models (LLMs) with integrated search tools show strong promise in open-domain question answering (QA), yet they often struggle to produce complete answer set to complex questions such as Which actor from the film Heat won at least one Academy Award?, which requires (1) distinguishing between multiple films sharing the same title and (2) reasoning across a large set of actors to gather and integrate evidence. Existing QA benchmarks rarely evaluate both challenges jointly. To address this, we introduce DeepAmbigQAGen, an automatic data generation pipeline that constructs QA tasks grounded in text corpora and linked knowledge graph, generating natural and verifiable questions that systematically embed name ambiguity and multi-step reasoning. Based on this, we build DeepAmbigQA, a dataset of 3,600 questions requiring multi-hop reasoning and half of them explicit name ambiguity resolving. Experiments reveal that, even state-of-the-art GPT-5 show incomplete answers, achieving only 0.13 exact match on ambiguous questions and 0.21 on non-ambiguous questions. These findings highlight the need for more robust QA systems aimed at information gathering and answer completeness.</li>
</ul>

<h3>Title: RDTE-UNet: A Boundary and Detail Aware UNet for Precise Medical Image Segmentation</h3>
<ul>
<li><strong>Authors: </strong>Jierui Qu, Jianchun Zhao</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.01328">https://arxiv.org/abs/2511.01328</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.01328">https://arxiv.org/pdf/2511.01328</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.01328]] RDTE-UNet: A Boundary and Detail Aware UNet for Precise Medical Image Segmentation(https://arxiv.org/abs/2511.01328)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer, segmentation</a></li>
<li><strong>Abstract: </strong>Medical image segmentation is essential for computer-assisted diagnosis and treatment planning, yet substantial anatomical variability and boundary ambiguity hinder reliable delineation of fine structures. We propose RDTE-UNet, a segmentation network that unifies local modeling with global context to strengthen boundary delineation and detail preservation. RDTE-UNet employs a hybrid ResBlock detail-aware Transformer backbone and three modules: ASBE for adaptive boundary enhancement, HVDA for fine-grained feature modeling, and EulerFF for fusion weighting guided by Euler's formula. Together, these components improve structural consistency and boundary accuracy across morphology, orientation, and scale. On Synapse and BUSI dataset, RDTE-UNet has achieved a comparable level in terms of segmentation accuracy and boundary quality.</li>
</ul>

<h3>Title: Diffusion-Based Solver for CNF Placement on the Cloud-Continuum</h3>
<ul>
<li><strong>Authors: </strong>Álvaro Vázquez Rodríguez, Manuel Fernández-Veiga, Carlos Giraldo-Rodríguez</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.01343">https://arxiv.org/abs/2511.01343</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.01343">https://arxiv.org/pdf/2511.01343</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.01343]] Diffusion-Based Solver for CNF Placement on the Cloud-Continuum(https://arxiv.org/abs/2511.01343)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, generative</a></li>
<li><strong>Abstract: </strong>The placement of Cloud-Native Network Functions (CNFs) across the Cloud-Continuum represents a core challenge in the orchestration of current 5G and future 6G networks. The process involves the placement of interdependent computing tasks, structured as Service Function Chains, over distributed cloud infrastructures. This is achieved while satisfying strict resource, bandwidth and latency constraints. It is acknowledged that classical approaches, including mixed-integer nonlinear programming, heuristics and reinforcement learning are limited in terms of scalability, constraint handling and generalisation capacity. In the present study, a novel theoretical framework is proposed, which is based on Denoising Diffusion Probabilistic Models (DDPM) for CNF placement. The present approach proposes a reconceptualisation of placement as a generative graph to assignment task, where the placement problem is encoded as a heterogeneous graph, and a Graph Neural Network denoiser is trained to iteratively refine noisy CNF-to-cloud assignment matrices. The model incorporates constraint-specific losses directly into the loss function, thereby allowing it to learn feasible solution spaces. The integration of the DDPM formulation with structured combinatorial constraints is achieved through a rigorous and systematic approach. Extensive evaluations across diverse topologies have been conducted, which have confirmed that the model consistently produces feasible solutions with orders of magnitude faster inference than MINLP solvers. The results obtained demonstrate the potential of diffusion-based generative modelling for constrained network embedding problems, making an impact towards the practical, scalable orchestration of distributed Cloud-Native Network Functions.</li>
</ul>

<h3>Title: MIQ-SAM3D: From Single-Point Prompt to Multi-Instance Segmentation via Competitive Query Refinement</h3>
<ul>
<li><strong>Authors: </strong>Jierui Qu, Jianchun Zhao</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.01345">https://arxiv.org/abs/2511.01345</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.01345">https://arxiv.org/pdf/2511.01345</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.01345]] MIQ-SAM3D: From Single-Point Prompt to Multi-Instance Segmentation via Competitive Query Refinement(https://arxiv.org/abs/2511.01345)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, transformer, segmentation</a></li>
<li><strong>Abstract: </strong>Accurate segmentation of medical images is fundamental to tumor diagnosis and treatment planning. SAM-based interactive segmentation has gained attention for its strong generalization, but most methods follow a single-point-to-single-object paradigm, which limits multi-lesion segmentation. Moreover, ViT backbones capture global context but often miss high-fidelity local details. We propose MIQ-SAM3D, a multi-instance 3D segmentation framework with a competitive query optimization strategy that shifts from single-point-to-single-mask to single-point-to-multi-instance. A prompt-conditioned instance-query generator transforms a single point prompt into multiple specialized queries, enabling retrieval of all semantically similar lesions across the 3D volume from a single exemplar. A hybrid CNN-Transformer encoder injects CNN-derived boundary saliency into ViT self-attention via spatial gating. A competitively optimized query decoder then enables end-to-end, parallel, multi-instance prediction through inter-query competition. On LiTS17 and KiTS21 dataset, MIQ-SAM3D achieved comparable levels and exhibits strong robustness to prompts, providing a practical solution for efficient annotation of clinically relevant multi-lesion cases.</li>
</ul>

<h3>Title: MiniFool - Physics-Constraint-Aware Minimizer-Based Adversarial Attacks in Deep Neural Networks</h3>
<ul>
<li><strong>Authors: </strong>Lucie Flek, Oliver Janik, Philipp Alexander Jung, Akbar Karimi, Timo Saala, Alexander Schmidt, Matthias Schott, Philipp Soldin, Matthias Thiesmeyer, Christopher Wiebusch, Ulrich Willemsen</a></li>
<li><strong>Subjects: </strong>cs.LG, astro-ph.HE, astro-ph.IM, hep-ex, physics.data-an</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.01352">https://arxiv.org/abs/2511.01352</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.01352">https://arxiv.org/pdf/2511.01352</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.01352]] MiniFool - Physics-Constraint-Aware Minimizer-Based Adversarial Attacks in Deep Neural Networks(https://arxiv.org/abs/2511.01352)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack, robust</a></li>
<li><strong>Abstract: </strong>In this paper, we present a new algorithm, MiniFool, that implements physics-inspired adversarial attacks for testing neural network-based classification tasks in particle and astroparticle physics. While we initially developed the algorithm for the search for astrophysical tau neutrinos with the IceCube Neutrino Observatory, we apply it to further data from other science domains, thus demonstrating its general applicability. Here, we apply the algorithm to the well-known MNIST data set and furthermore, to Open Data data from the CMS experiment at the Large Hadron Collider. The algorithm is based on minimizing a cost function that combines a $\chi^2$ based test-statistic with the deviation from the desired target score. The test statistic quantifies the probability of the perturbations applied to the data based on the experimental uncertainties. For our studied use cases, we find that the likelihood of a flipped classification differs for both the initially correctly and incorrectly classified events. When testing changes of the classifications as a function of an attack parameter that scales the experimental uncertainties, the robustness of the network decision can be quantified. Furthermore, this allows testing the robustness of the classification of unlabeled experimental data.</li>
</ul>

<h3>Title: Expanding the Content-Style Frontier: a Balanced Subspace Blending Approach for Content-Style LoRA Fusion</h3>
<ul>
<li><strong>Authors: </strong>Linhao Huang</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.01355">https://arxiv.org/abs/2511.01355</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.01355">https://arxiv.org/pdf/2511.01355</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.01355]] Expanding the Content-Style Frontier: a Balanced Subspace Blending Approach for Content-Style LoRA Fusion(https://arxiv.org/abs/2511.01355)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>Recent advancements in text-to-image diffusion models have significantly improved the personalization and stylization of generated images. However, previous studies have only assessed content similarity under a single style intensity. In our experiments, we observe that increasing style intensity leads to a significant loss of content features, resulting in a suboptimal content-style frontier. To address this, we propose a novel approach to expand the content-style frontier by leveraging Content-Style Subspace Blending and a Content-Style Balance loss. Our method improves content similarity across varying style intensities, significantly broadening the content-style frontier. Extensive experiments demonstrate that our approach outperforms existing techniques in both qualitative and quantitative evaluations, achieving superior content-style trade-off with significantly lower Inverted Generational Distance (IGD) and Generational Distance (GD) scores compared to current methods.</li>
</ul>

<h3>Title: CMI-MTL: Cross-Mamba interaction based multi-task learning for medical visual question answering</h3>
<ul>
<li><strong>Authors: </strong>Qiangguo Jin, Xianyao Zheng, Hui Cui, Changming Sun, Yuqi Fang, Cong Cong, Ran Su, Leyi Wei, Ping Xuan, Junbo Wang</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.01357">https://arxiv.org/abs/2511.01357</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.01357">https://arxiv.org/pdf/2511.01357</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.01357]] CMI-MTL: Cross-Mamba interaction based multi-task learning for medical visual question answering(https://arxiv.org/abs/2511.01357)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability</a></li>
<li><strong>Abstract: </strong>Medical visual question answering (Med-VQA) is a crucial multimodal task in clinical decision support and telemedicine. Recent self-attention based methods struggle to effectively handle cross-modal semantic alignments between vision and language. Moreover, classification-based methods rely on predefined answer sets. Treating this task as a simple classification problem may make it unable to adapt to the diversity of free-form answers and overlook the detailed semantic information of free-form answers. In order to tackle these challenges, we introduce a Cross-Mamba Interaction based Multi-Task Learning (CMI-MTL) framework that learns cross-modal feature representations from images and texts. CMI-MTL comprises three key modules: fine-grained visual-text feature alignment (FVTA), cross-modal interleaved feature representation (CIFR), and free-form answer-enhanced multi-task learning (FFAE). FVTA extracts the most relevant regions in image-text pairs through fine-grained visual-text feature alignment. CIFR captures cross-modal sequential interactions via cross-modal interleaved feature representation. FFAE leverages auxiliary knowledge from open-ended questions through free-form answer-enhanced multi-task learning, improving the model's capability for open-ended Med-VQA. Experimental results show that CMI-MTL outperforms the existing state-of-the-art methods on three Med-VQA datasets: VQA-RAD, SLAKE, and OVQA. Furthermore, we conduct more interpretability experiments to prove the effectiveness. The code is publicly available at this https URL.</li>
</ul>

<h3>Title: Safer in Translation? Presupposition Robustness in Indic Languages</h3>
<ul>
<li><strong>Authors: </strong>Aadi Palnitkar, Arjun Suresh, Rishi Rajesh, Puneet Puli</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.01360">https://arxiv.org/abs/2511.01360</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.01360">https://arxiv.org/pdf/2511.01360</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.01360]] Safer in Translation? Presupposition Robustness in Indic Languages(https://arxiv.org/abs/2511.01360)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, large language model</a></li>
<li><strong>Abstract: </strong>Increasingly, more and more people are turning to large language models (LLMs) for healthcare advice and consultation, making it important to gauge the efficacy and accuracy of the responses of LLMs to such queries. While there are pre-existing medical benchmarks literature which seeks to accomplish this very task, these benchmarks are almost universally in English, which has led to a notable gap in existing literature pertaining to multilingual LLM evaluation. Within this work, we seek to aid in addressing this gap with Cancer-Myth-Indic, an Indic language benchmark built by translating a 500-item subset of Cancer-Myth, sampled evenly across its original categories, into five under-served but widely used languages from the subcontinent (500 per language; 2,500 translated items total). Native-speaker translators followed a style guide for preserving implicit presuppositions in translation; items feature false presuppositions relating to cancer. We evaluate several popular LLMs under this presupposition stress.</li>
</ul>

<h3>Title: The Ouroboros of Benchmarking: Reasoning Evaluation in an Era of Saturation</h3>
<ul>
<li><strong>Authors: </strong>İbrahim Ethem Deveci, Duygu Ataman</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.01365">https://arxiv.org/abs/2511.01365</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.01365">https://arxiv.org/pdf/2511.01365</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.01365]] The Ouroboros of Benchmarking: Reasoning Evaluation in an Era of Saturation(https://arxiv.org/abs/2511.01365)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>The rapid rise of Large Language Models (LLMs) and Large Reasoning Models (LRMs) has been accompanied by an equally rapid increase of benchmarks used to assess them. However, due to both improved model competence resulting from scaling and novel training advances as well as likely many of these datasets being included in pre or post training data, results become saturated, driving a continuous need for new and more challenging replacements. In this paper, we discuss whether surpassing a benchmark truly demonstrates reasoning ability or are we simply tracking numbers divorced from the capabilities we claim to measure? We present an investigation focused on three model families, OpenAI, Anthropic, and Google, and how their reasoning capabilities across different benchmarks evolve over the years. We also analyze performance trends over the years across different reasoning tasks and discuss the current situation of benchmarking and remaining challenges. By offering a comprehensive overview of benchmarks and reasoning tasks, our work aims to serve as a first reference to ground future research in reasoning evaluation and model development.</li>
</ul>

<h3>Title: Learning Intractable Multimodal Policies with Reparameterization and Diversity Regularization</h3>
<ul>
<li><strong>Authors: </strong>Ziqi Wang, Jiashun Liu, Ling Pan</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.01374">https://arxiv.org/abs/2511.01374</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.01374">https://arxiv.org/pdf/2511.01374</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.01374]] Learning Intractable Multimodal Policies with Reparameterization and Diversity Regularization(https://arxiv.org/abs/2511.01374)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, diffusion, generative</a></li>
<li><strong>Abstract: </strong>Traditional continuous deep reinforcement learning (RL) algorithms employ deterministic or unimodal Gaussian actors, which cannot express complex multimodal decision distributions. This limitation can hinder their performance in diversity-critical scenarios. There have been some attempts to design online multimodal RL algorithms based on diffusion or amortized actors. However, these actors are intractable, making existing methods struggle with balancing performance, decision diversity, and efficiency simultaneously. To overcome this challenge, we first reformulate existing intractable multimodal actors within a unified framework, and prove that they can be directly optimized by policy gradient via reparameterization. Then, we propose a distance-based diversity regularization that does not explicitly require decision probabilities. We identify two diversity-critical domains, namely multi-goal achieving and generative RL, to demonstrate the advantages of multimodal policies and our method, particularly in terms of few-shot robustness. In conventional MuJoCo benchmarks, our algorithm also shows competitive performance. Moreover, our experiments highlight that the amortized actor is a promising policy model class with strong multimodal expressivity and high performance. Our code is available at this https URL</li>
</ul>

<h3>Title: Protecting the Neural Networks against FGSM Attack Using Machine Unlearning</h3>
<ul>
<li><strong>Authors: </strong>Amir Hossein Khorasani, Ali Jahanian, Maryam Rastgarpour</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.01377">https://arxiv.org/abs/2511.01377</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.01377">https://arxiv.org/pdf/2511.01377</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.01377]] Protecting the Neural Networks against FGSM Attack Using Machine Unlearning(https://arxiv.org/abs/2511.01377)</code><input type="text"></li>
<li><strong>Keywords: </strong>protect, attack, robust</a></li>
<li><strong>Abstract: </strong>Machine learning is a powerful tool for building predictive models. However, it is vulnerable to adversarial attacks. Fast Gradient Sign Method (FGSM) attacks are a common type of adversarial attack that adds small perturbations to input data to trick a model into misclassifying it. In response to these attacks, researchers have developed methods for "unlearning" these attacks, which involves retraining a model on the original data without the added perturbations. Machine unlearning is a technique that tries to "forget" specific data points from the training dataset, to improve the robustness of a machine learning model against adversarial attacks like FGSM. In this paper, we focus on applying unlearning techniques to the LeNet neural network, a popular architecture for image classification. We evaluate the efficacy of unlearning FGSM attacks on the LeNet network and find that it can significantly improve its robustness against these types of attacks.</li>
</ul>

<h3>Title: EREBUS: End-to-end Robust Event Based Underwater Simulation</h3>
<ul>
<li><strong>Authors: </strong>Hitesh Kyatham, Arjun Suresh, Aadi Palnitkar, Yiannis Aloimonos</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.RO</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.01381">https://arxiv.org/abs/2511.01381</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.01381">https://arxiv.org/pdf/2511.01381</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.01381]] EREBUS: End-to-end Robust Event Based Underwater Simulation(https://arxiv.org/abs/2511.01381)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>The underwater domain presents a vast array of challenges for roboticists and computer vision researchers alike, such as poor lighting conditions and high dynamic range scenes. In these adverse conditions, traditional vision techniques struggle to adapt and lead to suboptimal performance. Event-based cameras present an attractive solution to this problem, mitigating the issues of traditional cameras by tracking changes in the footage on a frame-by-frame basis. In this paper, we introduce a pipeline which can be used to generate realistic synthetic data of an event-based camera mounted to an AUV (Autonomous Underwater Vehicle) in an underwater environment for training vision models. We demonstrate the effectiveness of our pipeline using the task of rock detection with poor visibility and suspended particulate matter, but the approach can be generalized to other underwater tasks.</li>
</ul>

<h3>Title: RAGSmith: A Framework for Finding the Optimal Composition of Retrieval-Augmented Generation Methods Across Datasets</h3>
<ul>
<li><strong>Authors: </strong>Muhammed Yusuf Kartal (1), Suha Kagan Kose (2), Korhan Sevinç (1), Burak Aktas (2) ((1) TOBB University of Economics and Technology, (2) Roketsan Inc.)</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.IR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.01386">https://arxiv.org/abs/2511.01386</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.01386">https://arxiv.org/pdf/2511.01386</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.01386]] RAGSmith: A Framework for Finding the Optimal Composition of Retrieval-Augmented Generation Methods Across Datasets(https://arxiv.org/abs/2511.01386)</code><input type="text"></li>
<li><strong>Keywords: </strong>defense, robust</a></li>
<li><strong>Abstract: </strong>Retrieval-Augmented Generation (RAG) quality depends on many interacting choices across retrieval, ranking, augmentation, prompting, and generation, so optimizing modules in isolation is brittle. We introduce RAGSmith, a modular framework that treats RAG design as an end-to-end architecture search over nine technique families and 46{,}080 feasible pipeline configurations. A genetic search optimizes a scalar objective that jointly aggregates retrieval metrics (recall@k, mAP, nDCG, MRR) and generation metrics (LLM-Judge and semantic similarity). We evaluate on six Wikipedia-derived domains (Mathematics, Law, Finance, Medicine, Defense Industry, Computer Science), each with 100 questions spanning factual, interpretation, and long-answer types. RAGSmith finds configurations that consistently outperform naive RAG baseline by +3.8\% on average (range +1.2\% to +6.9\% across domains), with gains up to +12.5\% in retrieval and +7.5\% in generation. The search typically explores $\approx 0.2\%$ of the space ($\sim 100$ candidates) and discovers a robust backbone -- vector retrieval plus post-generation reflection/revision -- augmented by domain-dependent choices in expansion, reranking, augmentation, and prompt reordering; passage compression is never selected. Improvement magnitude correlates with question type, with larger gains on factual/long-answer mixes than interpretation-heavy sets. These results provide practical, domain-aware guidance for assembling effective RAG systems and demonstrate the utility of evolutionary search for full-pipeline optimization.</li>
</ul>

<h3>Title: SEPS: Semantic-enhanced Patch Slimming Framework for fine-grained cross-modal alignment</h3>
<ul>
<li><strong>Authors: </strong>Xinyu Mao, Junsi Li, Haoji Zhang, Yu Liang, Ming Sun</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI, cs.MM</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.01390">https://arxiv.org/abs/2511.01390</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.01390">https://arxiv.org/pdf/2511.01390</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.01390]] SEPS: Semantic-enhanced Patch Slimming Framework for fine-grained cross-modal alignment(https://arxiv.org/abs/2511.01390)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, large language model</a></li>
<li><strong>Abstract: </strong>Fine-grained cross-modal alignment aims to establish precise local correspondences between vision and language, forming a cornerstone for visual question answering and related multimodal applications. Current approaches face challenges in addressing patch redundancy and ambiguity, which arise from the inherent information density disparities across modalities. Recently, Multimodal Large Language Models (MLLMs) have emerged as promising solutions to bridge this gap through their robust semantic generation capabilities. However, the dense textual outputs from MLLMs may introduce conflicts with the original sparse captions. Furthermore, accurately quantifying semantic relevance between rich visual patches and concise textual descriptions remains a core challenge. To overcome these limitations, we introduce the Semantic-Enhanced Patch Slimming (SEPS) framework, which systematically addresses patch redundancy and ambiguity. Our approach employs a two-stage mechanism to integrate unified semantics from both dense and sparse texts, enabling the identification of salient visual patches. Additionally, it leverages relevance-aware selection with mean value computation to highlight crucial patch-word correspondences, thereby improving cross-modal similarity assessment. Comprehensive experiments on Flickr30K and MS-COCO datasets validate that SEPS achieves superior performance, surpassing existing approaches by 23\%-86\% in rSum across diverse model architectures, with notable enhancements in text-to-image retrieval scenarios. Our implementation is available at this https URL.</li>
</ul>

<h3>Title: Beyond Static Thresholds: Adaptive RRC Signaling Storm Detection with Extreme Value Theory</h3>
<ul>
<li><strong>Authors: </strong>Dang Kien Nguyen, Rim El Malki, Filippo Rebecchi, Raymond Knopp, Melek Önen</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.NI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.01391">https://arxiv.org/abs/2511.01391</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.01391">https://arxiv.org/pdf/2511.01391</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.01391]] Beyond Static Thresholds: Adaptive RRC Signaling Storm Detection with Extreme Value Theory(https://arxiv.org/abs/2511.01391)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack</a></li>
<li><strong>Abstract: </strong>In 5G and beyond networks, the radio communication between a User Equipment (UE) and a base station (gNodeB or gNB), also known as the air interface, is a critical component of network access and connectivity. During the connection establishment procedure, the Radio Resource Control (RRC) layer can be vulnerable to signaling storms, which threaten the availability of the radio access control plane. These attacks may occur when one or more UEs send a large number of connection requests to the gNB, preventing new UEs from establishing connections. In this paper, we investigate the detection of such threats and propose an adaptive threshold-based detection system based on Extreme Value Theory (EVT). The proposed solution is evaluated numerically by applying simulated attack scenarios based on a realistic threat model on top of real-world RRC traffic data from an operator network. We show that, by leveraging features from the RRC layer only, the detection system can not only identify the attacks but also differentiate them from legitimate high-traffic situations. The adaptive threshold calculated using EVT ensures that the system can work under diverse traffic conditions. The results show high accuracy, precision, and recall values (above 93%), and a low detection latency even under complex conditions.</li>
</ul>

<h3>Title: ConneX: Automatically Resolving Transaction Opacity of Cross-Chain Bridges for Security Analysis</h3>
<ul>
<li><strong>Authors: </strong>Hanzhong Liang, Yue Duan, Xing Su, Xiao Li, Yating Liu, Yulong Tian, Fengyuan Xu, Sheng Zhong</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.01393">https://arxiv.org/abs/2511.01393</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.01393">https://arxiv.org/pdf/2511.01393</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.01393]] ConneX: Automatically Resolving Transaction Opacity of Cross-Chain Bridges for Security Analysis(https://arxiv.org/abs/2511.01393)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, large language model</a></li>
<li><strong>Abstract: </strong>As the Web3 ecosystem evolves toward a multi-chain architecture, cross-chain bridges have become critical infrastructure for enabling interoperability between diverse blockchain networks. However, while connecting isolated blockchains, the lack of cross-chain transaction pairing records introduces significant challenges for security analysis like cross-chain fund tracing, advanced vulnerability detection, and transaction graph-based analysis. To address this gap, we introduce ConneX, an automated and general-purpose system designed to accurately identify corresponding transaction pairs across both ends of cross-chain bridges. Our system leverages Large Language Models (LLMs) to efficiently prune the semantic search space by identifying semantically plausible key information candidates within complex transaction records. Further, it deploys a novel examiner module that refines these candidates by validating them against transaction values, effectively addressing semantic ambiguities and identifying the correct semantics. Extensive evaluations on a dataset of about 500,000 transactions from five major bridge platforms demonstrate that ConneX achieves an average F1 score of 0.9746, surpassing baselines by at least 20.05\%, with good efficiency that reduces the semantic search space by several orders of magnitude (1e10 to less than 100). Moreover, its successful application in tracing illicit funds (including a cross-chain transfer worth $1 million) in real-world hacking incidents underscores its practical utility for enhancing cross-chain security and transparency.</li>
</ul>

<h3>Title: Semantic BIM enrichment for firefighting assets: Fire-ART dataset and panoramic image-based 3D reconstruction</h3>
<ul>
<li><strong>Authors: </strong>Ya Wen, Yutong Qiao, Chi Chiu Lam, Ioannis Brilakis, Sanghoon Lee, Mun On Wong</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.01399">https://arxiv.org/abs/2511.01399</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.01399">https://arxiv.org/pdf/2511.01399</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.01399]] Semantic BIM enrichment for firefighting assets: Fire-ART dataset and panoramic image-based 3D reconstruction(https://arxiv.org/abs/2511.01399)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Inventory management of firefighting assets is crucial for emergency preparedness, risk assessment, and on-site fire response. However, conventional methods are inefficient due to limited capabilities in automated asset recognition and reconstruction. To address the challenge, this research introduces the Fire-ART dataset and develops a panoramic image-based reconstruction approach for semantic enrichment of firefighting assets into BIM models. The Fire-ART dataset covers 15 fundamental assets, comprising 2,626 images and 6,627 instances, making it an extensive and publicly accessible dataset for asset recognition. In addition, the reconstruction approach integrates modified cube-map conversion and radius-based spherical camera projection to enhance recognition and localization accuracy. Through validations with two real-world case studies, the proposed approach achieves F1-scores of 73% and 88% and localization errors of 0.620 and 0.428 meters, respectively. The Fire-ART dataset and the reconstruction approach offer valuable resources and robust technical solutions to enhance the accurate digital management of fire safety equipment.</li>
</ul>

<h3>Title: Leveraging Compact Satellite Embeddings and Graph Neural Networks for Large-Scale Poverty Mapping</h3>
<ul>
<li><strong>Authors: </strong>Markus B. Pettersson, Adel Daoud</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.01408">https://arxiv.org/abs/2511.01408</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.01408">https://arxiv.org/pdf/2511.01408</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.01408]] Leveraging Compact Satellite Embeddings and Graph Neural Networks for Large-Scale Poverty Mapping(https://arxiv.org/abs/2511.01408)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy</a></li>
<li><strong>Abstract: </strong>Accurate, fine-grained poverty maps remain scarce across much of the Global South. While Demographic and Health Surveys (DHS) provide high-quality socioeconomic data, their spatial coverage is limited and reported coordinates are randomly displaced for privacy, further reducing their quality. We propose a graph-based approach leveraging low-dimensional AlphaEarth satellite embeddings to predict cluster-level wealth indices across Sub-Saharan Africa. By modeling spatial relations between surveyed and unlabeled locations, and by introducing a probabilistic "fuzzy label" loss to account for coordinate displacement, we improve the generalization of wealth predictions beyond existing surveys. Our experiments on 37 DHS datasets (2017-2023) show that incorporating graph structure slightly improves accuracy compared to "image-only" baselines, demonstrating the potential of compact EO embeddings for large-scale socioeconomic mapping.</li>
</ul>

<h3>Title: LiveSearchBench: An Automatically Constructed Benchmark for Retrieval and Reasoning over Dynamic Knowledge</h3>
<ul>
<li><strong>Authors: </strong>Heng Zhou, Ao Yu, Yuchen Fan, Jianing Shi, Li Kang, Hejia Geng, Yongting Zhang, Yutao Fan, Yuhao Wu, Tiancheng He, Yiran Qin, Lei Bai, Zhenfei Yin</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.01409">https://arxiv.org/abs/2511.01409</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.01409">https://arxiv.org/pdf/2511.01409</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.01409]] LiveSearchBench: An Automatically Constructed Benchmark for Retrieval and Reasoning over Dynamic Knowledge(https://arxiv.org/abs/2511.01409)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Evaluating large language models (LLMs) on question answering often relies on static benchmarks that reward memorization and understate the role of retrieval, failing to capture the dynamic nature of world knowledge. We present LiveSearchBench, an automated pipeline for constructing retrieval-dependent benchmarks from recent knowledge updates. Our method computes deltas between successive Wikidata snapshots, filters candidate triples for quality, and synthesizes natural-language questions at three levels of reasoning difficulty, each guaranteed to admit a unique, verifiable answer through SPARQL validation. The pipeline is fully automated, scalable across time, and minimizes human intervention, enabling continual regeneration of temporally grounded benchmarks. Experiments show a pronounced performance drop when models confront facts that post-date pretraining, with the gap most salient on multi-hop queries. Retrieval augmented methods and larger, instruction-tuned models provide partial gains but fail to close this recency gap. By design, LiveSearchBench shifts evaluation from static memorization toward tasks that require up-to-date retrieval and reasoning, offering a foundation for systematic, long-term assessment of LLMs under evolving knowledge.</li>
</ul>

<h3>Title: Extremal Contours: Gradient-driven contours for compact visual attribution</h3>
<ul>
<li><strong>Authors: </strong>Reza Karimzadeh, Albert Alonso, Frans Zdyb, Julius B. Kirkegaard, Bulat Ibragimov</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.01411">https://arxiv.org/abs/2511.01411</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.01411">https://arxiv.org/pdf/2511.01411</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.01411]] Extremal Contours: Gradient-driven contours for compact visual attribution(https://arxiv.org/abs/2511.01411)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Faithful yet compact explanations for vision models remain a challenge, as commonly used dense perturbation masks are often fragmented and overfitted, needing careful post-processing. Here, we present a training-free explanation method that replaces dense masks with smooth tunable contours. A star-convex region is parameterized by a truncated Fourier series and optimized under an extremal preserve/delete objective using the classifier gradients. The approach guarantees a single, simply connected mask, cuts the number of free parameters by orders of magnitude, and yields stable boundary updates without cleanup. Restricting solutions to low-dimensional, smooth contours makes the method robust to adversarial masking artifacts. On ImageNet classifiers, it matches the extremal fidelity of dense masks while producing compact, interpretable regions with improved run-to-run consistency. Explicit area control also enables importance contour maps, yielding a transparent fidelity-area profiles. Finally, we extend the approach to multi-contour and show how it can localize multiple objects within the same framework. Across benchmarks, the method achieves higher relevance mass and lower complexity than gradient and perturbation based baselines, with especially strong gains on self-supervised DINO models where it improves relevance mass by over 15% and maintains positive faithfulness correlations.</li>
</ul>

<h3>Title: Towards One-step Causal Video Generation via Adversarial Self-Distillation</h3>
<ul>
<li><strong>Authors: </strong>Yongqi Yang, Huayang Huang, Xu Peng, Xiaobin Hu, Donghao Luo, Jiangning Zhang, Chengjie Wang, Yu Wu</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.01419">https://arxiv.org/abs/2511.01419</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.01419">https://arxiv.org/pdf/2511.01419</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.01419]] Towards One-step Causal Video Generation via Adversarial Self-Distillation(https://arxiv.org/abs/2511.01419)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>Recent hybrid video generation models combine autoregressive temporal dynamics with diffusion-based spatial denoising, but their sequential, iterative nature leads to error accumulation and long inference times. In this work, we propose a distillation-based framework for efficient causal video generation that enables high-quality synthesis with extremely limited denoising steps. Our approach builds upon the Distribution Matching Distillation (DMD) framework and proposes a novel Adversarial Self-Distillation (ASD) strategy, which aligns the outputs of the student model's n-step denoising process with its (n+1)-step version at the distribution level. This design provides smoother supervision by bridging small intra-student gaps and more informative guidance by combining teacher knowledge with locally consistent student behavior, substantially improving training stability and generation quality in extremely few-step scenarios (e.g., 1-2 steps). In addition, we present a First-Frame Enhancement (FFE) strategy, which allocates more denoising steps to the initial frames to mitigate error propagation while applying larger skipping steps to later frames. Extensive experiments on VBench demonstrate that our method surpasses state-of-the-art approaches in both one-step and two-step video generation. Notably, our framework produces a single distilled model that flexibly supports multiple inference-step settings, eliminating the need for repeated re-distillation and enabling efficient, high-quality video synthesis.</li>
</ul>

<h3>Title: UniSOT: A Unified Framework for Multi-Modality Single Object Tracking</h3>
<ul>
<li><strong>Authors: </strong>Yinchao Ma, Yuyang Tang, Wenfei Yang, Tianzhu Zhang, Xu Zhou, Feng Wu</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.01427">https://arxiv.org/abs/2511.01427</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.01427">https://arxiv.org/pdf/2511.01427</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.01427]] UniSOT: A Unified Framework for Multi-Modality Single Object Tracking(https://arxiv.org/abs/2511.01427)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Single object tracking aims to localize target object with specific reference modalities (bounding box, natural language or both) in a sequence of specific video modalities (RGB, RGB+Depth, RGB+Thermal or RGB+Event.). Different reference modalities enable various human-machine interactions, and different video modalities are demanded in complex scenarios to enhance tracking robustness. Existing trackers are designed for single or several video modalities with single or several reference modalities, which leads to separate model designs and limits practical applications. Practically, a unified tracker is needed to handle various requirements. To the best of our knowledge, there is still no tracker that can perform tracking with these above reference modalities across these video modalities simultaneously. Thus, in this paper, we present a unified tracker, UniSOT, for different combinations of three reference modalities and four video modalities with uniform parameters. Extensive experimental results on 18 visual tracking, vision-language tracking and RGB+X tracking benchmarks demonstrate that UniSOT shows superior performance against modality-specific counterparts. Notably, UniSOT outperforms previous counterparts by over 3.0\% AUC on TNL2K across all three reference modalities and outperforms Un-Track by over 2.0\% main metric across all three RGB+X video modalities.</li>
</ul>

<h3>Title: CG-FKAN: Compressed-Grid Federated Kolmogorov-Arnold Networks for Communication Constrained Environment</h3>
<ul>
<li><strong>Authors: </strong>Seunghun Yu, Youngjoon Lee, Jinu Gong, Joonhyuk Kang</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.01433">https://arxiv.org/abs/2511.01433</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.01433">https://arxiv.org/pdf/2511.01433</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.01433]] CG-FKAN: Compressed-Grid Federated Kolmogorov-Arnold Networks for Communication Constrained Environment(https://arxiv.org/abs/2511.01433)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, federate, interpretability</a></li>
<li><strong>Abstract: </strong>Federated learning (FL), widely used in privacy-critical applications, suffers from limited interpretability, whereas Kolmogorov-Arnold Networks (KAN) address this limitation via learnable spline functions. However, existing FL studies applying KAN overlook the communication overhead introduced by grid extension, which is essential for modeling complex functions. In this letter, we propose CG-FKAN, which compresses extended grids by sparsifying and transmitting only essential coefficients under a communication budget. Experiments show that CG-FKAN achieves up to 13.6% lower RMSE than fixed-grid KAN in communication-constrained settings. In addition, we derive a theoretical upper bound on its approximation error.</li>
</ul>

<h3>Title: Terrain-Enhanced Resolution-aware Refinement Attention for Off-Road Segmentation</h3>
<ul>
<li><strong>Authors: </strong>Seongkyu Choi, Jhonghyun An</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.01434">https://arxiv.org/abs/2511.01434</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.01434">https://arxiv.org/pdf/2511.01434</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.01434]] Terrain-Enhanced Resolution-aware Refinement Attention for Off-Road Segmentation(https://arxiv.org/abs/2511.01434)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>Off-road semantic segmentation suffers from thick, inconsistent boundaries, sparse supervision for rare classes, and pervasive label noise. Designs that fuse only at low resolution blur edges and propagate local errors, whereas maintaining high-resolution pathways or repeating high-resolution fusions is costly and fragile to noise. We introduce a resolutionaware token decoder that balances global semantics, local consistency, and boundary fidelity under imperfect supervision. Most computation occurs at a low-resolution bottleneck; a gated cross-attention injects fine-scale detail, and only a sparse, uncertainty-selected set of pixels is refined. The components are co-designed and tightly integrated: global self-attention with lightweight dilated depthwise refinement restores local coherence; a gated cross-attention integrates fine-scale features from a standard high-resolution encoder stream without amplifying noise; and a class-aware point refinement corrects residual ambiguities with negligible overhead. During training, we add a boundary-band consistency regularizer that encourages coherent predictions in a thin neighborhood around annotated edges, with no inference-time cost. Overall, the results indicate competitive performance and improved stability across transitions.</li>
</ul>

<h3>Title: Contrast-Guided Cross-Modal Distillation for Thermal Object Detection</h3>
<ul>
<li><strong>Authors: </strong>SiWoo Kim, JhongHyun An</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.01435">https://arxiv.org/abs/2511.01435</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.01435">https://arxiv.org/pdf/2511.01435</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.01435]] Contrast-Guided Cross-Modal Distillation for Thermal Object Detection(https://arxiv.org/abs/2511.01435)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Robust perception at night remains challenging for thermal-infrared detection: low contrast and weak high-frequency cues lead to duplicate, overlapping boxes, missed small objects, and class confusion. Prior remedies either translate TIR to RGB and hope pixel fidelity transfers to detection -- making performance fragile to color or structure artifacts -- or fuse RGB and TIR at test time, which requires extra sensors, precise calibration, and higher runtime cost. Both lines can help in favorable conditions, but do not directly shape the thermal representation used by the detector. We keep mono-modality inference and tackle the root causes during training. Specifically, we introduce training-only objectives that sharpen instance-level decision boundaries by pulling together features of the same class and pushing apart those of different classes -- suppressing duplicate and confusing detections -- and that inject cross-modal semantic priors by aligning the student's multi-level pyramid features with an RGB-trained teacher, thereby strengthening texture-poor thermal features without visible input at test time. In experiments, our method outperformed prior approaches and achieved state-of-the-art performance.</li>
</ul>

<h3>Title: The Curvature Rate λ: A Scalar Measure of Input-Space Sharpness in Neural Networks</h3>
<ul>
<li><strong>Authors: </strong>Jacob Poschl</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.01438">https://arxiv.org/abs/2511.01438</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.01438">https://arxiv.org/pdf/2511.01438</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.01438]] The Curvature Rate λ: A Scalar Measure of Input-Space Sharpness in Neural Networks(https://arxiv.org/abs/2511.01438)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Curvature influences generalization, robustness, and how reliably neural networks respond to small input perturbations. Existing sharpness metrics are typically defined in parameter space (e.g., Hessian eigenvalues) and can be expensive, sensitive to reparameterization, and difficult to interpret in functional terms. We introduce a scalar curvature measure defined directly in input space: the curvature rate {\lambda}, given by the exponential growth rate of higher-order input derivatives. Empirically, {\lambda} is estimated as the slope of log ||D^n f|| versus n for small n. This growth-rate perspective unifies classical analytic quantities: for analytic functions, {\lambda} corresponds to the inverse radius of convergence, and for bandlimited signals, it reflects the spectral cutoff. The same principle extends to neural networks, where {\lambda} tracks the emergence of high-frequency structure in the decision boundary. Experiments on analytic functions and neural networks (Two Moons and MNIST) show that {\lambda} evolves predictably during training and can be directly shaped using a simple derivative-based regularizer, Curvature Rate Regularization (CRR). Compared to Sharpness-Aware Minimization (SAM), CRR achieves similar accuracy while yielding flatter input-space geometry and improved confidence calibration. By grounding curvature in differentiation dynamics, {\lambda} provides a compact, interpretable, and parameterization-invariant descriptor of functional smoothness in learned models.</li>
</ul>

<h3>Title: Efficient Curvature-aware Graph Network</h3>
<ul>
<li><strong>Authors: </strong>Chaoqun Fei, Tinglve Zhou, Tianyong Hao, Yangyang Li</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.01443">https://arxiv.org/abs/2511.01443</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.01443">https://arxiv.org/pdf/2511.01443</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.01443]] Efficient Curvature-aware Graph Network(https://arxiv.org/abs/2511.01443)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, interpretability</a></li>
<li><strong>Abstract: </strong>Graph curvature provides geometric priors for Graph Neural Networks (GNNs), enhancing their ability to model complex graph structures, particularly in terms of structural awareness, robustness, and theoretical interpretability. Among existing methods, Ollivier-Ricci curvature has been extensively studied due to its strong geometric interpretability, effectively characterizing the local geometric distribution between nodes. However, its prohibitively high computational complexity limits its applicability to large-scale graph datasets. To address this challenge, we propose a novel graph curvature measure--Effective Resistance Curvature--which quantifies the ease of message passing along graph edges using the effective resistance between node pairs, instead of the optimal transport distance. This method significantly outperforms Ollivier-Ricci curvature in computational efficiency while preserving comparable geometric expressiveness. Theoretically, we prove the low computational complexity of effective resistance curvature and establish its substitutability for Ollivier-Ricci curvature. Furthermore, extensive experiments on diverse GNN tasks demonstrate that our method achieves competitive performance with Ollivier-Ricci curvature while drastically reducing computational overhead.</li>
</ul>

<h3>Title: Privacy Preserving Ordinal-Meta Learning with VLMs for Fine-Grained Fruit Quality Prediction</h3>
<ul>
<li><strong>Authors: </strong>Riddhi Jain, Manasi Patwardhan, Aayush Mishra, Parijat Deshpande, Beena Rai</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.01449">https://arxiv.org/abs/2511.01449</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.01449">https://arxiv.org/pdf/2511.01449</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.01449]] Privacy Preserving Ordinal-Meta Learning with VLMs for Fine-Grained Fruit Quality Prediction(https://arxiv.org/abs/2511.01449)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy</a></li>
<li><strong>Abstract: </strong>To effectively manage the wastage of perishable fruits, it is crucial to accurately predict their freshness or shelf life using non-invasive methods that rely on visual data. In this regard, deep learning techniques can offer a viable solution. However, obtaining fine-grained fruit freshness labels from experts is costly, leading to a scarcity of data. Closed proprietary Vision Language Models (VLMs), such as Gemini, have demonstrated strong performance in fruit freshness detection task in both zero-shot and few-shot settings. Nonetheless, food retail organizations are unable to utilize these proprietary models due to concerns related to data privacy, while existing open-source VLMs yield sub-optimal performance for the task. Fine-tuning these open-source models with limited data fails to achieve the performance levels of proprietary models. In this work, we introduce a Model-Agnostic Ordinal Meta-Learning (MAOML) algorithm, designed to train smaller VLMs. This approach utilizes meta-learning to address data sparsity and leverages label ordinality, thereby achieving state-of-the-art performance in the fruit freshness classification task under both zero-shot and few-shot settings. Our method achieves an industry-standard accuracy of 92.71%, averaged across all fruits. Keywords: Fruit Quality Prediction, Vision Language Models, Meta Learning, Ordinal Regression</li>
</ul>

<h3>Title: Security-Aware Joint Sensing, Communication, and Computing Optimization in Low Altitude Wireless Networks</h3>
<ul>
<li><strong>Authors: </strong>Jiacheng Wang, Changyuan Zhao, Jialing He, Geng Sun, Weijie Yuan, Dusit Niyato, Liehuang Zhu, Tao Xiang</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.01451">https://arxiv.org/abs/2511.01451</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.01451">https://arxiv.org/pdf/2511.01451</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.01451]] Security-Aware Joint Sensing, Communication, and Computing Optimization in Low Altitude Wireless Networks(https://arxiv.org/abs/2511.01451)</code><input type="text"></li>
<li><strong>Keywords: </strong>security</a></li>
<li><strong>Abstract: </strong>As terrestrial resources become increasingly saturated, the research attention is shifting to the low-altitude airspace, with many emerging applications such as urban air taxis and aerial inspection. Low-Altitude Wireless Networks (LAWNs) are the foundation for these applications, with integrated sensing, communications, and computing (ISCC) being one of the core parts of LAWNs. However, the openness of low-altitude airspace exposes communications to security threats, degrading ISCC performance and ultimately compromising the reliability of applications supported by LAWNs. To address these challenges, this paper studies joint performance optimization of ISCC while considering secrecyness of the communications. Specifically, we derive beampattern error, secrecy rate, and age of information (AoI) as performance metrics for sensing, secrecy communication, and computing. Building on these metrics, we formulate a multi-objective optimization problem that balances sensing and computation performance while keeping the probability of communication being detected below a required threshold. We then propose a deep Q-network (DQN)-based multi-objective evolutionary algorithm, which adaptively selects evolutionary operators according to the evolving optimization objectives, thereby leading to more effective solutions. Extensive simulations show that the proposed method achieves a superior balance among sensing accuracy, communication secrecyness, and information freshness compared with baseline algorithms, thereby safeguarding ISCC performance and LAWN-supported low-altitude applications.</li>
</ul>

<h3>Title: "Don't Teach Minerva": Guiding LLMs Through Complex Syntax for Faithful Latin Translation with RAG</h3>
<ul>
<li><strong>Authors: </strong>Sergio Torres Aguilar</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.DL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.01454">https://arxiv.org/abs/2511.01454</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.01454">https://arxiv.org/pdf/2511.01454</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.01454]] "Don't Teach Minerva": Guiding LLMs Through Complex Syntax for Faithful Latin Translation with RAG(https://arxiv.org/abs/2511.01454)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, large language model</a></li>
<li><strong>Abstract: </strong>Translating a morphology-rich, low-resource language like Latin poses significant challenges. This paper introduces a reproducible draft-based refinement pipeline that elevates open-source Large Language Models (LLMs) to a performance level statistically comparable to top-tier proprietary systems. Our method first uses a fine-tuned NLLB-1.3B model to generate a high-quality, structurally faithful draft. A zero-shot LLM (Llama-3.3 or Qwen3) then polishes this draft, a process that can be further enhanced by augmenting the context with retrieved out-context examples (RAG). We demonstrate the robustness of this approach on two distinct benchmarks: a standard in-domain test set (Rosenthal, 2023) and a new, challenging out-of-domain (OOD) set of 12th-century Latin letters (2025). Our central finding is that this open-source RAG system achieves performance statistically comparable to the GPT-5 baseline, without any task-specific LLM fine-tuning. We release the pipeline, the Chartres OOD set, and evaluation scripts and models to facilitate replicability and further research.</li>
</ul>

<h3>Title: Efficiently Training A Flat Neural Network Before It has been Quantizated</h3>
<ul>
<li><strong>Authors: </strong>Peng Xia, Junbiao Pang, Tianyang Cai</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.01462">https://arxiv.org/abs/2511.01462</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.01462">https://arxiv.org/pdf/2511.01462</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.01462]] Efficiently Training A Flat Neural Network Before It has been Quantizated(https://arxiv.org/abs/2511.01462)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Post-training quantization (PTQ) for vision transformers (ViTs) has garnered significant attention due to its efficiency in compressing models. However, existing methods typically overlook the relationship between a well-trained NN and the quantized model, leading to considerable quantization error for PTQ. However, it is unclear how to efficiently train a model-agnostic neural network which is tailored for a predefined precision low-bit model. In this paper, we firstly discover that a flat full precision neural network is crucial for low-bit quantization. To achieve this, we propose a framework that proactively pre-conditions the model by measuring and disentangling the error sources. Specifically, both the Activation Quantization Error (AQE) and the Weight Quantization Error (WQE) are statistically modeled as independent Gaussian noises. We study several noise injection optimization methods to obtain a flat minimum. Experimental results attest to the effectiveness of our approach. These results open novel pathways for obtaining low-bit PTQ models.</li>
</ul>

<h3>Title: SecDiff: Diffusion-Aided Secure Deep Joint Source-Channel Coding Against Adversarial Attacks</h3>
<ul>
<li><strong>Authors: </strong>Changyuan Zhao, Jiacheng Wang, Ruichen Zhang, Dusit Niyato, Hongyang Du, Zehui Xiong, Dong In Kim, Ping Zhang</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.01466">https://arxiv.org/abs/2511.01466</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.01466">https://arxiv.org/pdf/2511.01466</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.01466]] SecDiff: Diffusion-Aided Secure Deep Joint Source-Channel Coding Against Adversarial Attacks(https://arxiv.org/abs/2511.01466)</code><input type="text"></li>
<li><strong>Keywords: </strong>secure, security, attack, robust, diffusion, generative</a></li>
<li><strong>Abstract: </strong>Deep joint source-channel coding (JSCC) has emerged as a promising paradigm for semantic communication, delivering significant performance gains over conventional separate coding schemes. However, existing JSCC frameworks remain vulnerable to physical-layer adversarial threats, such as pilot spoofing and subcarrier jamming, compromising semantic fidelity. In this paper, we propose SecDiff, a plug-and-play, diffusion-aided decoding framework that significantly enhances the security and robustness of deep JSCC under adversarial wireless environments. Different from prior diffusion-guided JSCC methods that suffer from high inference latency, SecDiff employs pseudoinverse-guided sampling and adaptive guidance weighting, enabling flexible step-size control and efficient semantic reconstruction. To counter jamming attacks, we introduce a power-based subcarrier masking strategy and recast recovery as a masked inpainting problem, solved via diffusion guidance. For pilot spoofing, we formulate channel estimation as a blind inverse problem and develop an expectation-minimization (EM)-driven reconstruction algorithm, guided jointly by reconstruction loss and a channel operator. Notably, our method alternates between pilot recovery and channel estimation, enabling joint refinement of both variables throughout the diffusion process. Extensive experiments over orthogonal frequency-division multiplexing (OFDM) channels under adversarial conditions show that SecDiff outperforms existing secure and generative JSCC baselines by achieving a favorable trade-off between reconstruction quality and computational cost. This balance makes SecDiff a promising step toward practical, low-latency, and attack-resilient semantic communications.</li>
</ul>

<h3>Title: DAMBench: A Multi-Modal Benchmark for Deep Learning-based Atmospheric Data Assimilation</h3>
<ul>
<li><strong>Authors: </strong>Hao Wang, Zixuan Weng, Jindong Han, Wei Fan, Hao Liu</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.01468">https://arxiv.org/abs/2511.01468</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.01468">https://arxiv.org/pdf/2511.01468</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.01468]] DAMBench: A Multi-Modal Benchmark for Deep Learning-based Atmospheric Data Assimilation(https://arxiv.org/abs/2511.01468)</code><input type="text"></li>
<li><strong>Keywords: </strong>fair, generative</a></li>
<li><strong>Abstract: </strong>Data Assimilation is a cornerstone of atmospheric system modeling, tasked with reconstructing system states by integrating sparse, noisy observations with prior estimation. While traditional approaches like variational and ensemble Kalman filtering have proven effective, recent advances in deep learning offer more scalable, efficient, and flexible alternatives better suited for complex, real-world data assimilation involving large-scale and multi-modal observations. However, existing deep learning-based DA research suffers from two critical limitations: (1) reliance on oversimplified scenarios with synthetically perturbed observations, and (2) the absence of standardized benchmarks for fair model comparison. To address these gaps, in this work, we introduce DAMBench, the first large-scale multi-modal benchmark designed to evaluate data-driven DA models under realistic atmospheric conditions. DAMBench integrates high-quality background states from state-of-the-art forecasting systems and real-world multi-modal observations (i.e., real-world weather stations and satellite imagery). All data are resampled to a common grid and temporally aligned to support systematic training, validation, and testing. We provide unified evaluation protocols and benchmark representative data assimilation approaches, including latent generative models and neural process frameworks. Additionally, we propose a lightweight multi-modal plugin to demonstrate how integrating realistic observations can enhance even simple baselines. Through comprehensive experiments, DAMBench establishes a rigorous foundation for future research, promoting reproducibility, fair comparison, and extensibility to real-world multi-modal scenarios. Our dataset and code are publicly available at this https URL.</li>
</ul>

<h3>Title: Towards Consistent Detection of Cognitive Distortions: LLM-Based Annotation and Dataset-Agnostic Evaluation</h3>
<ul>
<li><strong>Authors: </strong>Neha Sharma, Navneet Agarwal, Kairit Sirts</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.01482">https://arxiv.org/abs/2511.01482</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.01482">https://arxiv.org/pdf/2511.01482</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.01482]] Towards Consistent Detection of Cognitive Distortions: LLM-Based Annotation and Dataset-Agnostic Evaluation(https://arxiv.org/abs/2511.01482)</code><input type="text"></li>
<li><strong>Keywords: </strong>fair, large language model</a></li>
<li><strong>Abstract: </strong>Text-based automated Cognitive Distortion detection is a challenging task due to its subjective nature, with low agreement scores observed even among expert human annotators, leading to unreliable annotations. We explore the use of Large Language Models (LLMs) as consistent and reliable annotators, and propose that multiple independent LLM runs can reveal stable labeling patterns despite the inherent subjectivity of the task. Furthermore, to fairly compare models trained on datasets with different characteristics, we introduce a dataset-agnostic evaluation framework using Cohen's kappa as an effect size measure. This methodology allows for fair cross-dataset and cross-study comparisons where traditional metrics like F1 score fall short. Our results show that GPT-4 can produce consistent annotations (Fleiss's Kappa = 0.78), resulting in improved test set performance for models trained on these annotations compared to those trained on human-labeled data. Our findings suggest that LLMs can offer a scalable and internally consistent alternative for generating training data that supports strong downstream performance in subjective NLP tasks.</li>
</ul>

<h3>Title: Synthetic Eggs in Many Baskets: The Impact of Synthetic Data Diversity on LLM Fine-Tuning</h3>
<ul>
<li><strong>Authors: </strong>Max Schaffelder, Albert Gatt</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.01490">https://arxiv.org/abs/2511.01490</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.01490">https://arxiv.org/pdf/2511.01490</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.01490]] Synthetic Eggs in Many Baskets: The Impact of Synthetic Data Diversity on LLM Fine-Tuning(https://arxiv.org/abs/2511.01490)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, large language model</a></li>
<li><strong>Abstract: </strong>As synthetic data becomes widely used in language model development, understanding its impact on model behavior is crucial. This paper investigates the impact of the diversity of sources of synthetic data on fine-tuned large language models. We focus on three key dimensions: distribution collapse, adversarial robustness, and self-preference bias. Our findings reveal that fine-tuning models on synthetic data from diverse sources can mitigate distribution collapse, preserving the breadth of the output distribution and the diversity of the output text. Furthermore, while both human and synthetic fine-tuning data can remove safeguards, the latter preserves higher output quality, thus making outputs potentially more usable and dangerous. Finally, fine-tuning reduces self-preference bias, with human data being the most effective, followed by multi-source synthetic data.</li>
</ul>

<h3>Title: EPAN: Robust Pedestrian Re-Identification via Enhanced Alignment Network for IoT Surveillance</h3>
<ul>
<li><strong>Authors: </strong>Zhiyang Jia, Hongyan Cui, Ge Gao, Bo Li, Minjie Zhang, Zishuo Gao, Huiwen Huang, Caisheng Zhuo</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.01498">https://arxiv.org/abs/2511.01498</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.01498">https://arxiv.org/pdf/2511.01498</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.01498]] EPAN: Robust Pedestrian Re-Identification via Enhanced Alignment Network for IoT Surveillance(https://arxiv.org/abs/2511.01498)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, robust, extraction</a></li>
<li><strong>Abstract: </strong>Person re-identification (ReID) plays a pivotal role in computer vision, particularly in surveillance and security applications within IoT-enabled smart environments. This study introduces the Enhanced Pedestrian Alignment Network (EPAN), tailored for robust ReID across diverse IoT surveillance conditions. EPAN employs a dual-branch architecture to mitigate the impact of perspective and environmental changes, extracting alignment information under varying scales and viewpoints. Here, we demonstrate EPAN's strong feature extraction capabilities, achieving outstanding performance on the Inspection-Personnel dataset with a Rank-1 accuracy of 90.09% and a mean Average Precision (mAP) of 78.82%. This highlights EPAN's potential for real-world IoT applications, enabling effective and reliable person ReID across diverse cameras in surveillance and security systems. The code and data are available at: this https URL</li>
</ul>

<h3>Title: Discriminately Treating Motion Components Evolves Joint Depth and Ego-Motion Learning</h3>
<ul>
<li><strong>Authors: </strong>Mengtan Zhang, Zizhan Guo, Hongbo Zhao, Yi Feng, Zuyi Xiong, Yue Wang, Shaoyi Du, Hanli Wang, Rui Fan</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.RO</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.01502">https://arxiv.org/abs/2511.01502</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.01502">https://arxiv.org/pdf/2511.01502</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.01502]] Discriminately Treating Motion Components Evolves Joint Depth and Ego-Motion Learning(https://arxiv.org/abs/2511.01502)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Unsupervised learning of depth and ego-motion, two fundamental 3D perception tasks, has made significant strides in recent years. However, most methods treat ego-motion as an auxiliary task, either mixing all motion types or excluding depth-independent rotational motions in supervision. Such designs limit the incorporation of strong geometric constraints, reducing reliability and robustness under diverse conditions. This study introduces a discriminative treatment of motion components, leveraging the geometric regularities of their respective rigid flows to benefit both depth and ego-motion estimation. Given consecutive video frames, network outputs first align the optical axes and imaging planes of the source and target cameras. Optical flows between frames are transformed through these alignments, and deviations are quantified to impose geometric constraints individually on each ego-motion component, enabling more targeted refinement. These alignments further reformulate the joint learning process into coaxial and coplanar forms, where depth and each translation component can be mutually derived through closed-form geometric relationships, introducing complementary constraints that improve depth robustness. DiMoDE, a general depth and ego-motion joint learning framework incorporating these designs, achieves state-of-the-art performance on multiple public datasets and a newly collected diverse real-world dataset, particularly under challenging conditions. Our source code will be publicly available at this http URL upon publication.</li>
</ul>

<h3>Title: Luminance-Aware Statistical Quantization: Unsupervised Hierarchical Learning for Illumination Enhancement</h3>
<ul>
<li><strong>Authors: </strong>Derong Kong, Zhixiong Yang, Shengxi Li, Shuaifeng Zhi, Li Liu, Zhen Liu, Jingyuan Xia</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.01510">https://arxiv.org/abs/2511.01510</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.01510">https://arxiv.org/pdf/2511.01510</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.01510]] Luminance-Aware Statistical Quantization: Unsupervised Hierarchical Learning for Illumination Enhancement(https://arxiv.org/abs/2511.01510)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>Low-light image enhancement (LLIE) faces persistent challenges in balancing reconstruction fidelity with cross-scenario generalization. While existing methods predominantly focus on deterministic pixel-level mappings between paired low/normal-light images, they often neglect the continuous physical process of luminance transitions in real-world environments, leading to performance drop when normal-light references are unavailable. Inspired by empirical analysis of natural luminance dynamics revealing power-law distributed intensity transitions, this paper introduces Luminance-Aware Statistical Quantification (LASQ), a novel framework that reformulates LLIE as a statistical sampling process over hierarchical luminance distributions. Our LASQ re-conceptualizes luminance transition as a power-law distribution in intensity coordinate space that can be approximated by stratified power functions, therefore, replacing deterministic mappings with probabilistic sampling over continuous luminance layers. A diffusion forward process is designed to autonomously discover optimal transition paths between luminance layers, achieving unsupervised distribution emulation without normal-light references. In this way, it considerably improves the performance in practical situations, enabling more adaptable and versatile light restoration. This framework is also readily applicable to cases with normal-light references, where it achieves superior performance on domain-specific datasets alongside better generalization-ability across non-reference datasets.</li>
</ul>

<h3>Title: BanglaNirTox: A Large-scale Parallel Corpus for Explainable AI in Bengali Text Detoxification</h3>
<ul>
<li><strong>Authors: </strong>Ayesha Afroza Mohsin, Mashrur Ahsan, Nafisa Maliyat, Shanta Maria, Syed Rifat Raiyan, Hasan Mahmud, Md Kamrul Hasan</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.01512">https://arxiv.org/abs/2511.01512</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.01512">https://arxiv.org/pdf/2511.01512</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.01512]] BanglaNirTox: A Large-scale Parallel Corpus for Explainable AI in Bengali Text Detoxification(https://arxiv.org/abs/2511.01512)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Toxic language in Bengali remains prevalent, especially in online environments, with few effective precautions against it. Although text detoxification has seen progress in high-resource languages, Bengali remains underexplored due to limited resources. In this paper, we propose a novel pipeline for Bengali text detoxification that combines Pareto class-optimized large language models (LLMs) and Chain-of-Thought (CoT) prompting to generate detoxified sentences. To support this effort, we construct BanglaNirTox, an artificially generated parallel corpus of 68,041 toxic Bengali sentences with class-wise toxicity labels, reasonings, and detoxified paraphrases, using Pareto-optimized LLMs evaluated on random samples. The resulting BanglaNirTox dataset is used to fine-tune language models to produce better detoxified versions of Bengali sentences. Our findings show that Pareto-optimized LLMs with CoT prompting significantly enhance the quality and consistency of Bengali text detoxification.</li>
</ul>

<h3>Title: Example-Based Feature Painting on Textures</h3>
<ul>
<li><strong>Authors: </strong>Andrei-Timotei Ardelean, Tim Weyrich</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.GR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.01513">https://arxiv.org/abs/2511.01513</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.01513">https://arxiv.org/pdf/2511.01513</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.01513]] Example-Based Feature Painting on Textures(https://arxiv.org/abs/2511.01513)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, generative</a></li>
<li><strong>Abstract: </strong>In this work, we propose a system that covers the complete workflow for achieving controlled authoring and editing of textures that present distinctive local characteristics. These include various effects that change the surface appearance of materials, such as stains, tears, holes, abrasions, discoloration, and more. Such alterations are ubiquitous in nature, and including them in the synthesis process is crucial for generating realistic textures. We introduce a novel approach for creating textures with such blemishes, adopting a learning-based approach that leverages unlabeled examples. Our approach does not require manual annotations by the user; instead, it detects the appearance-altering features through unsupervised anomaly detection. The various textural features are then automatically clustered into semantically coherent groups, which are used to guide the conditional generation of images. Our pipeline as a whole goes from a small image collection to a versatile generative model that enables the user to interactively create and paint features on textures of arbitrary size. Notably, the algorithms we introduce for diffusion-based editing and infinite stationary texture generation are generic and should prove useful in other contexts as well. Project page: this https URL</li>
</ul>

<h3>Title: NSYNC: Negative Synthetic Image Generation for Contrastive Training to Improve Stylized Text-To-Image Translation</h3>
<ul>
<li><strong>Authors: </strong>Serkan Ozturk, Samet Hicsonmez, Pinar Duygulu</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.01517">https://arxiv.org/abs/2511.01517</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.01517">https://arxiv.org/pdf/2511.01517</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.01517]] NSYNC: Negative Synthetic Image Generation for Contrastive Training to Improve Stylized Text-To-Image Translation(https://arxiv.org/abs/2511.01517)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>Current text conditioned image generation methods output realistic looking images, but they fail to capture specific styles. Simply finetuning them on the target style datasets still struggles to grasp the style features. In this work, we present a novel contrastive learning framework to improve the stylization capability of large text-to-image diffusion models. Motivated by the astonishing advance in image generation models that makes synthetic data an intrinsic part of model training in various computer vision tasks, we exploit synthetic image generation in our approach. Usually, the generated synthetic data is dependent on the task, and most of the time it is used to enlarge the available real training dataset. With NSYNC, alternatively, we focus on generating negative synthetic sets to be used in a novel contrastive training scheme along with real positive images. In our proposed training setup, we forward negative data along with positive data and obtain negative and positive gradients, respectively. We then refine the positive gradient by subtracting its projection onto the negative gradient to get the orthogonal component, based on which the parameters are updated. This orthogonal component eliminates the trivial attributes that are present in both positive and negative data and directs the model towards capturing a more unique style. Experiments on various styles of painters and illustrators show that our approach improves the performance over the baseline methods both quantitatively and qualitatively. Our code is available at this https URL.</li>
</ul>

<h3>Title: Driving scenario generation and evaluation using a structured layer representation and foundational models</h3>
<ul>
<li><strong>Authors: </strong>Arthur Hubert, Gamal Elghazaly, Raphaël Frank</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.01541">https://arxiv.org/abs/2511.01541</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.01541">https://arxiv.org/pdf/2511.01541</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.01541]] Driving scenario generation and evaluation using a structured layer representation and foundational models(https://arxiv.org/abs/2511.01541)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>Rare and challenging driving scenarios are critical for autonomous vehicle development. Since they are difficult to encounter, simulating or generating them using generative models is a popular approach. Following previous efforts to structure driving scenario representations in a layer model, we propose a structured five-layer model to improve the evaluation and generation of rare scenarios. We use this model alongside large foundational models to generate new driving scenarios using a data augmentation strategy. Unlike previous representations, our structure introduces subclasses and characteristics for every agent of the scenario, allowing us to compare them using an embedding specific to our layer-model. We study and adapt two metrics to evaluate the relevance of a synthetic dataset in the context of a structured representation: the diversity score estimates how different the scenarios of a dataset are from one another, while the originality score calculates how similar a synthetic dataset is from a real reference set. This paper showcases both metrics in different generation setup, as well as a qualitative evaluation of synthetic videos generated from structured scenario descriptions. The code and extended results can be found at this https URL.</li>
</ul>

<h3>Title: PCD-ReID: Occluded Person Re-Identification for Base Station Inspection</h3>
<ul>
<li><strong>Authors: </strong>Ge Gao, Zishuo Gao, Hongyan Cui, Zhiyang Jia, Zhuang Luo, ChaoPeng Liu</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.01546">https://arxiv.org/abs/2511.01546</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.01546">https://arxiv.org/pdf/2511.01546</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.01546]] PCD-ReID: Occluded Person Re-Identification for Base Station Inspection(https://arxiv.org/abs/2511.01546)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, transformer</a></li>
<li><strong>Abstract: </strong>Occluded pedestrian re-identification (ReID) in base station environments is a critical task in computer vision, particularly for surveillance and security applications. This task faces numerous challenges, as occlusions often obscure key body features, increasing the complexity of identification. Traditional ResNet-based ReID algorithms often fail to address occlusions effectively, necessitating new ReID methods. We propose the PCD-ReID (Pedestrian Component Discrepancy) algorithm to address these issues. The contributions of this work are as follows: To tackle the occlusion problem, we design a Transformer-based PCD network capable of extracting shared component features, such as helmets and uniforms. To mitigate overfitting on public datasets, we collected new real-world patrol surveillance images for model training, covering six months, 10,000 individuals, and over 50,000 images. Comparative experiments with existing ReID algorithms demonstrate that our model achieves a mean Average Precision (mAP) of 79.0% and a Rank-1 accuracy of 82.7%, marking a 15.9% Rank-1 improvement over ResNet50-based methods. Experimental evaluations indicate that PCD-ReID effectively achieves occlusion-aware ReID performance for personnel in tower inspection scenarios, highlighting its potential for practical deployment in surveillance and security applications.</li>
</ul>

<h3>Title: NOA: a versatile, extensible tool for AI-based organoid analysis</h3>
<ul>
<li><strong>Authors: </strong>Mikhail Konov, Lion J. Gleiter, Khoa Co, Monica Yabal, Tingying Peng</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.01549">https://arxiv.org/abs/2511.01549</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.01549">https://arxiv.org/pdf/2511.01549</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.01549]] NOA: a versatile, extensible tool for AI-based organoid analysis(https://arxiv.org/abs/2511.01549)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction, segmentation</a></li>
<li><strong>Abstract: </strong>AI tools can greatly enhance the analysis of organoid microscopy images, from detection and segmentation to feature extraction and classification. However, their limited accessibility to biologists without programming experience remains a major barrier, resulting in labor-intensive and largely manual workflows. Although a few AI models for organoid analysis have been developed, most existing tools remain narrowly focused on specific tasks. In this work, we introduce the Napari Organoid Analyzer (NOA), a general purpose graphical user interface to simplify AI-based organoid analysis. NOA integrates modules for detection, segmentation, tracking, feature extraction, custom feature annotation and ML-based feature prediction. It interfaces multiple state-of-the-art algorithms and is implemented as an open-source napari plugin for maximal flexibility and extensibility. We demonstrate the versatility of NOA through three case studies, involving the quantification of morphological changes during organoid differentiation, assessment of phototoxicity effects, and prediction of organoid viability and differentiation state. Together, these examples illustrate how NOA enables comprehensive, AI-driven organoid image analysis within an accessible and extensible framework.</li>
</ul>

<h3>Title: Math anxiety and associative knowledge structure are entwined in psychology students but not in Large Language Models like GPT-3.5 and GPT-4o</h3>
<ul>
<li><strong>Authors: </strong>Luciana Ciringione, Emma Franchino, Simone Reigl, Isaia D'Onofrio, Anna Serbati, Oleksandra Poquet, Florence Gabriel, Massimo Stella</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.CY</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.01558">https://arxiv.org/abs/2511.01558</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.01558">https://arxiv.org/pdf/2511.01558</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.01558]] Math anxiety and associative knowledge structure are entwined in psychology students but not in Large Language Models like GPT-3.5 and GPT-4o(https://arxiv.org/abs/2511.01558)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Math anxiety poses significant challenges for university psychology students, affecting their career choices and overall well-being. This study employs a framework based on behavioural forma mentis networks (i.e. cognitive models that map how individuals structure their associative knowledge and emotional perceptions of concepts) to explore individual and group differences in the perception and association of concepts related to math and anxiety. We conducted 4 experiments involving psychology undergraduates from 2 samples (n1 = 70, n2 = 57) compared against GPT-simulated students (GPT-3.5: n2 = 300; GPT-4o: n4 = 300). Experiments 1, 2, and 3 employ individual-level network features to predict psychometric scores for math anxiety and its facets (observational, social and evaluational) from the Math Anxiety Scale. Experiment 4 focuses on group-level perceptions extracted from human students, GPT-3.5 and GPT-4o's networks. Results indicate that, in students, positive valence ratings and higher network degree for "anxiety", together with negative ratings for "math", can predict higher total and evaluative math anxiety. In contrast, these models do not work on GPT-based data because of differences in simulated networks and psychometric scores compared to humans. These results were also reconciled with differences found in the ways that high/low subgroups of simulated and real students framed semantically and emotionally STEM concepts. High math-anxiety students collectively framed "anxiety" in an emotionally polarising way, absent in the negative perception of low math-anxiety students. "Science" was rated positively, but contrasted against the negative perception of "math". These findings underscore the importance of understanding concept perception and associations in managing students' math anxiety.</li>
</ul>

<h3>Title: HIT-ROCKET: Hadamard-vector Inner-product Transformer for ROCKET</h3>
<ul>
<li><strong>Authors: </strong>Wang Hao, Kuang Zhang, Hou Chengyu, Yuan Zhonghao, Tan Chenxing, Fu Weifeng, Zhu Yangying</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.01572">https://arxiv.org/abs/2511.01572</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.01572">https://arxiv.org/pdf/2511.01572</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.01572]] HIT-ROCKET: Hadamard-vector Inner-product Transformer for ROCKET(https://arxiv.org/abs/2511.01572)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, extraction, transformer</a></li>
<li><strong>Abstract: </strong>Time series classification holds broad application value in communications, information countermeasures, finance, and medicine. However, state-of-the-art (SOTA) methods-including HIVE-COTE, Proximity Forest, and TS-CHIEF-exhibit high computational complexity, coupled with lengthy parameter tuning and training cycles. In contrast, lightweight solutions like ROCKET (Random Convolutional Kernel Transform) offer greater efficiency but leave substantial room for improvement in kernel selection and computational overhead. To address these challenges, we propose a feature extraction approach based on Hadamard convolutional transform, utilizing column or row vectors of Hadamard matrices as convolution kernels with extended lengths of varying sizes. This enhancement maintains full compatibility with existing methods (e.g., ROCKET) while leveraging kernel orthogonality to boost computational efficiency, robustness, and adaptability. Comprehensive experiments on multi-domain datasets-focusing on the UCR time series dataset-demonstrate SOTA performance: F1-score improved by at least 5% vs. ROCKET, with 50% shorter training time than miniROCKET (fastest ROCKET variant) under identical hyperparameters, enabling deployment on ultra-low-power embedded devices. All code is available on GitHub.</li>
</ul>

<h3>Title: Generative Adversarial Synthesis and Deep Feature Discrimination of Brain Tumor MRI Images</h3>
<ul>
<li><strong>Authors: </strong>Md Sumon Ali, Muzammil Behzad</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.01574">https://arxiv.org/abs/2511.01574</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.01574">https://arxiv.org/pdf/2511.01574</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.01574]] Generative Adversarial Synthesis and Deep Feature Discrimination of Brain Tumor MRI Images(https://arxiv.org/abs/2511.01574)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>Compared to traditional methods, Deep Learning (DL) becomes a key technology for computer vision tasks. Synthetic data generation is an interesting use case for DL, especially in the field of medical imaging such as Magnetic Resonance Imaging (MRI). The need for this task since the original MRI data is limited. The generation of realistic medical images is completely difficult and challenging. Generative Adversarial Networks (GANs) are useful for creating synthetic medical images. In this paper, we propose a DL based methodology for creating synthetic MRI data using the Deep Convolutional Generative Adversarial Network (DC-GAN) to address the problem of limited data. We also employ a Convolutional Neural Network (CNN) classifier to classify the brain tumor using synthetic data and real MRI data. CNN is used to evaluate the quality and utility of the synthetic images. The classification result demonstrates comparable performance on real and synthetic images, which validates the effectiveness of GAN-generated images for downstream tasks.</li>
</ul>

<h3>Title: Federated Cyber Defense: Privacy-Preserving Ransomware Detection Across Distributed Systems</h3>
<ul>
<li><strong>Authors: </strong>Daniel M. Jimenez-Gutierrez, Enrique Zuazua, Joaquin Del Rio, Oleksii Sliusarenko, Xabi Uribe-Etxebarria</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.AI, cs.DC, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.01583">https://arxiv.org/abs/2511.01583</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.01583">https://arxiv.org/pdf/2511.01583</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.01583]] Federated Cyber Defense: Privacy-Preserving Ransomware Detection Across Distributed Systems(https://arxiv.org/abs/2511.01583)</code><input type="text"></li>
<li><strong>Keywords: </strong>secure, security, privacy, defense, robust, federate</a></li>
<li><strong>Abstract: </strong>Detecting malware, especially ransomware, is essential to securing today's interconnected ecosystems, including cloud storage, enterprise file-sharing, and database services. Training high-performing artificial intelligence (AI) detectors requires diverse datasets, which are often distributed across multiple organizations, making centralization necessary. However, centralized learning is often impractical due to security, privacy regulations, data ownership issues, and legal barriers to cross-organizational sharing. Compounding this challenge, ransomware evolves rapidly, demanding models that are both robust and adaptable. In this paper, we evaluate Federated Learning (FL) using the this http URL FL platform, which enables multiple organizations to collaboratively train a ransomware detection model while keeping raw data local and secure. This paradigm is particularly relevant for cybersecurity companies (including both software and hardware vendors) that deploy ransomware detection or firewall systems across millions of endpoints. In such environments, data cannot be transferred outside the customer's device due to strict security, privacy, or regulatory constraints. Although FL applies broadly to malware threats, we validate the approach using the Ransomware Storage Access Patterns (RanSAP) dataset. Our experiments demonstrate that FL improves ransomware detection accuracy by a relative 9% over server-local models and achieves performance comparable to centralized training. These results indicate that FL offers a scalable, high-performing, and privacy-preserving framework for proactive ransomware detection across organizational and regulatory boundaries.</li>
</ul>

<h3>Title: Explore More, Learn Better: Parallel MLLM Embeddings under Mutual Information Minimization</h3>
<ul>
<li><strong>Authors: </strong>Zhicheng Wang, Chen Ju, Xu Chen, Shuai Xiao, Jinsong Lan, Xiaoyong Zhu, Ying Chen, Zhiguo Cao</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.01588">https://arxiv.org/abs/2511.01588</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.01588">https://arxiv.org/pdf/2511.01588</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.01588]] Explore More, Learn Better: Parallel MLLM Embeddings under Mutual Information Minimization(https://arxiv.org/abs/2511.01588)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, large language model</a></li>
<li><strong>Abstract: </strong>Embedding models are a cornerstone of modern AI. Driven by Multimodal Large Language Models (MLLMs), they have made great progress in architecture and data curation, while the holistic paradigm is still limited to SSC, i.e., single input, singular embedding, contrastive supervision, which collapses rich, multifaceted inputs into monolithic embeddings and fails to fully exploit MLLM capabilities. In this paper, we tailor one Parallel Decoupling Framework (PDF) for multimodal embedding learning, by utilizing the proprietary steerability of MLLMs, i.e., their ability to flexibly generate quite differentiated response under explicit instructions. Concretely, PDF conditions a shared MLLM backbone on distinct, learnable prefixes to roll out multiple parallel paths for one input, then relies on these paths to obtain parallel embeddings. To promote full parallel diversity, we employ Mutual Information Minimization (MIM) as an explicit constraint, coupled with per-path contrastive supervision to maintain semantic alignment. Such dual-objectives force PDF to yield robust semantic coverage and a generalizable embedding space. Ultimately, the remarkable embedding space are accessible at inference via one single forward pass, incurring negligible computational overhead. We instantiate PDF on multiple MLLM backbones and prove its effectiveness on MMEB benchmark. Significant gains are consistently achieved across various resolutions and model sizes, e.g., boosting the VLM2Vec-LLaVA-1.6-LR model by a remarkable +8.9% (7B), while the VLM2Vec-Qwen2VL models by +4.2% (2B) and +3.1% (7B). In terms of efficiency, our 2B model surpasses its baseline by +2.6% using only half the computational budget.</li>
</ul>

<h3>Title: Defining Energy Indicators for Impact Identification on Aerospace Composites: A Physics-Informed Machine Learning Perspective</h3>
<ul>
<li><strong>Authors: </strong>Natália Ribeiro Marinho, Richard Loendersloot, Frank Grooteman, Jan Willem Wiegman, Uraz Odyurt, Tiedo Tinga</a></li>
<li><strong>Subjects: </strong>cs.LG, physics.app-ph</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.01592">https://arxiv.org/abs/2511.01592</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.01592">https://arxiv.org/pdf/2511.01592</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.01592]] Defining Energy Indicators for Impact Identification on Aerospace Composites: A Physics-Informed Machine Learning Perspective(https://arxiv.org/abs/2511.01592)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, interpretability</a></li>
<li><strong>Abstract: </strong>Energy estimation is critical to impact identification on aerospace composites, where low-velocity impacts can induce internal damage that is undetectable at the surface. Current methodologies for energy prediction are often constrained by data sparsity, signal noise, complex feature interdependencies, non-linear dynamics, massive design spaces, and the ill-posed nature of the inverse problem. This study introduces a physics-informed framework that embeds domain knowledge into machine learning through a dedicated input space. The approach combines observational biases, which guide the design of physics-motivated features, with targeted feature selection to retain only the most informative indicators. Features are extracted from time, frequency, and time-frequency domains to capture complementary aspects of the structural response. A structured feature selection process integrating statistical significance, correlation filtering, dimensionality reduction, and noise robustness ensures physical relevance and interpretability. Exploratory data analysis further reveals domain-specific trends, yielding a reduced feature set that captures essential dynamic phenomena such as amplitude scaling, spectral redistribution, and transient signal behaviour. Together, these steps produce a compact set of energy-sensitive indicators with both statistical robustness and physical significance, resulting in impact energy predictions that remain interpretable and traceable to measurable structural responses. Using this optimised input space, a fully-connected neural network is trained and validated with experimental data from multiple impact scenarios, including pristine and damaged states. The resulting model demonstrates significantly improved impact energy prediction accuracy, reducing errors by a factor of three compared to conventional time-series techniques and purely data-driven models.</li>
</ul>

<h3>Title: Lite ENSAM: a lightweight cancer segmentation model for 3D Computed Tomography</h3>
<ul>
<li><strong>Authors: </strong>Agnar Martin Bjørnstad, Elias Stenhede, Arian Ranjbar</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.01600">https://arxiv.org/abs/2511.01600</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.01600">https://arxiv.org/pdf/2511.01600</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.01600]] Lite ENSAM: a lightweight cancer segmentation model for 3D Computed Tomography(https://arxiv.org/abs/2511.01600)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>Accurate tumor size measurement is a cornerstone of evaluating cancer treatment response. The most widely adopted standard for this purpose is the Response Evaluation Criteria in Solid Tumors (RECIST) v1.1, which relies on measuring the longest tumor diameter in a single plane. However, volumetric measurements have been shown to provide a more reliable assessment of treatment effect. Their clinical adoption has been limited, though, due to the labor-intensive nature of manual volumetric annotation. In this paper, we present Lite ENSAM, a lightweight adaptation of the ENSAM architecture designed for efficient volumetric tumor segmentation from CT scans annotated with RECIST annotations. Lite ENSAM was submitted to the MICCAI FLARE 2025 Task 1: Pan-cancer Segmentation in CT Scans, Subtask 2, where it achieved a Dice Similarity Coefficient (DSC) of 60.7% and a Normalized Surface Dice (NSD) of 63.6% on the hidden test set, and an average total RAM time of 50.6 GBs and an average inference time of 14.4 s on CPU on the public validation dataset.</li>
</ul>

<h3>Title: DINO-MX: A Modular & Flexible Framework for Self-Supervised Learning</h3>
<ul>
<li><strong>Authors: </strong>Mahmut Selman Gokmen, Cody Bumgardner</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.01610">https://arxiv.org/abs/2511.01610</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.01610">https://arxiv.org/pdf/2511.01610</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.01610]] DINO-MX: A Modular & Flexible Framework for Self-Supervised Learning(https://arxiv.org/abs/2511.01610)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability, transformer, segmentation</a></li>
<li><strong>Abstract: </strong>Vision Foundation Models (VFMs) have advanced representation learning through self-supervised methods. However, existing training pipelines are often inflexible, domain-specific, or computationally expensive, which limits their usability across different domains and resource settings. DINO-MX is a modular and extensible training framework that combines the core principles of DINO, DINOv2 and DINOv3 within a unified configuration-driven system. It supports a variety of transformer-based architectures and is fully compatible with the Hugging Face ecosystem. The framework includes multiple training strategies such as low-rank adaptation (LoRA), layer freezing, and knowledge distillation, along with support for distributed training through both Distributed Data Parallel (DDP) and Fully Sharded Data Parallel (FSDP). DINO-MX is designed to work with both natural and specialized data types, including single- and multi-channel images. Experimental results on diverse datasets show that DINO-MX achieves competitive performance while significantly reducing computational costs. Additionally, it offers interpretability tools and a label-guided data augmentation method that improves attention-based localization without the need for extra detection or segmentation heads. DINO-MX provides a reproducible and scalable foundation for developing, adapting, and benchmarking self-supervised vision models across a range of research and real-world applications.</li>
</ul>

<h3>Title: Benchmark-Ready 3D Anatomical Shape Classification</h3>
<ul>
<li><strong>Authors: </strong>Tomáš Krsička, Tibor Kubík</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.01613">https://arxiv.org/abs/2511.01613</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.01613">https://arxiv.org/pdf/2511.01613</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.01613]] Benchmark-Ready 3D Anatomical Shape Classification(https://arxiv.org/abs/2511.01613)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Progress in anatomical 3D shape classification is limited by the complexity of mesh data and the lack of standardized benchmarks, highlighting the need for robust learning methods and reproducible evaluation. We introduce two key steps toward clinically and benchmark-ready anatomical shape classification via self-supervised graph autoencoding. We propose Precomputed Structural Pooling (PSPooling), a non-learnable mesh pooling operator designed for efficient and structure-preserving graph coarsening in 3D anatomical shape analysis. PSPooling precomputes node correspondence sets based on geometric proximity, enabling parallelizable and reversible pooling and unpooling operations with guaranteed support structure. This design avoids the sparsity and reconstruction issues of selection-based methods and the sequential overhead of edge contraction approaches, making it particularly suitable for high-resolution medical meshes. To demonstrate its effectiveness, we integrate PSPooling into a self-supervised graph autoencoder that learns anatomy-aware representations from unlabeled surface meshes. We evaluate the downstream benefits on MedShapeNet19, a new curated benchmark dataset we derive from MedShapeNet, consisting of 19 anatomical classes with standardized training, validation, and test splits. Experiments show that PSPooling significantly improves reconstruction fidelity and classification accuracy in low-label regimes, establishing a strong baseline for medical 3D shape learning. We hope that MedShapeNet19 will serve as a widely adopted benchmark for anatomical shape classification and further research in medical 3D shape analysis. Access the complete codebase, model weights, and dataset information here: this https URL.</li>
</ul>

<h3>Title: Imperfect Language, Artificial Intelligence, and the Human Mind: An Interdisciplinary Approach to Linguistic Errors in Native Spanish Speakers</h3>
<ul>
<li><strong>Authors: </strong>Francisco Portillo López</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.01615">https://arxiv.org/abs/2511.01615</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.01615">https://arxiv.org/pdf/2511.01615</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.01615]] Imperfect Language, Artificial Intelligence, and the Human Mind: An Interdisciplinary Approach to Linguistic Errors in Native Spanish Speakers(https://arxiv.org/abs/2511.01615)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Linguistic errors are not merely deviations from normative grammar; they offer a unique window into the cognitive architecture of language and expose the current limitations of artificial systems that seek to replicate them. This project proposes an interdisciplinary study of linguistic errors produced by native Spanish speakers, with the aim of analyzing how current large language models (LLM) interpret, reproduce, or correct them. The research integrates three core perspectives: theoretical linguistics, to classify and understand the nature of the errors; neurolinguistics, to contextualize them within real-time language processing in the brain; and natural language processing (NLP), to evaluate their interpretation against linguistic errors. A purpose-built corpus of authentic errors of native Spanish (+500) will serve as the foundation for empirical analysis. These errors will be tested against AI models such as GPT or Gemini to assess their interpretative accuracy and their ability to generalize patterns of human linguistic behavior. The project contributes not only to the understanding of Spanish as a native language but also to the development of NLP systems that are more cognitively informed and capable of engaging with the imperfect, variable, and often ambiguous nature of real human language.</li>
</ul>

<h3>Title: Actial: Activate Spatial Reasoning Ability of Multimodal Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Xiaoyu Zhan, Wenxuan Huang, Hao Sun, Xinyu Fu, Changfeng Ma, Shaosheng Cao, Bohan Jia, Shaohui Lin, Zhenfei Yin, Lei Bai, Wanli Ouyang, Yuanqi Li, Jie Guo, Yanwen Guo</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.01618">https://arxiv.org/abs/2511.01618</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.01618">https://arxiv.org/pdf/2511.01618</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.01618]] Actial: Activate Spatial Reasoning Ability of Multimodal Large Language Models(https://arxiv.org/abs/2511.01618)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, large language model</a></li>
<li><strong>Abstract: </strong>Recent advances in Multimodal Large Language Models (MLLMs) have significantly improved 2D visual understanding, prompting interest in their application to complex 3D reasoning tasks. However, it remains unclear whether these models can effectively capture the detailed spatial information required for robust real-world performance, especially cross-view consistency, a key requirement for accurate 3D reasoning. Considering this issue, we introduce Viewpoint Learning, a task designed to evaluate and improve the spatial reasoning capabilities of MLLMs. We present the Viewpoint-100K dataset, consisting of 100K object-centric image pairs with diverse viewpoints and corresponding question-answer pairs. Our approach employs a two-stage fine-tuning strategy: first, foundational knowledge is injected to the baseline MLLM via Supervised Fine-Tuning (SFT) on Viewpoint-100K, resulting in significant improvements across multiple tasks; second, generalization is enhanced through Reinforcement Learning using the Group Relative Policy Optimization (GRPO) algorithm on a broader set of questions. Additionally, we introduce a hybrid cold-start initialization method designed to simultaneously learn viewpoint representations and maintain coherent reasoning thinking. Experimental results show that our approach significantly activates the spatial reasoning ability of MLLM, improving performance on both in-domain and out-of-domain reasoning tasks. Our findings highlight the value of developing foundational spatial skills in MLLMs, supporting future progress in robotics, autonomous systems, and 3D scene understanding.</li>
</ul>

<h3>Title: Scaling Graph Chain-of-Thought Reasoning: A Multi-Agent Framework with Efficient LLM Serving</h3>
<ul>
<li><strong>Authors: </strong>Chengying Huan, Ziheng Meng, Yongchao Liu, Zhengyi Yang, Yun Zhu, Yue Yun, Shipeng Li, Rong Gu, Xiabao Wu, Haitao Zhang, Chuntao Hong, Shaonan Ma, Guihai Chen, Chen Tian</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.01633">https://arxiv.org/abs/2511.01633</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.01633">https://arxiv.org/pdf/2511.01633</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.01633]] Scaling Graph Chain-of-Thought Reasoning: A Multi-Agent Framework with Efficient LLM Serving(https://arxiv.org/abs/2511.01633)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Graph Chain-of-Thought (Graph-CoT) enables large language models (LLMs) to perform step-by-step reasoning over graph-structured knowledge, but existing pipelines suffer from low accuracy, excessive token usage, high latency, and low throughput due to single-agent monolithic prompts, repeated context re-encoding, and inefficient serving execution. We present GLM, the first multi-agent Graph-CoT system co-designed with an optimized LLM serving architecture. GLM decomposes reasoning into specialized agents for classification, reasoning, action generation, and graph retrieval, enabling branching and selective context sharing to reduce prompt length and reasoning iterations while preserving reasoning quality, thereby improving accuracy and reducing overall token consumption. To scale inference, we introduce a Graph-CoT-aware LLM inference mechanism with graph-specific KV-cache management, priority-based eviction, and pipelined execution to improve serving efficiency. Experiments demonstrate that GLM improves answer accuracy by up to 38%, reduces token cost by up to 95.7%, lowers inference latency by 90.3%, and achieves up to 15.1x higher throughput compared to state-of-the-art Graph-CoT baselines, enabling efficient adoption for complex real-world reasoning at scale.</li>
</ul>

<h3>Title: Prompt Injection as an Emerging Threat: Evaluating the Resilience of Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Daniyal Ganiuly, Assel Smaiyl</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.01634">https://arxiv.org/abs/2511.01634</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.01634">https://arxiv.org/pdf/2511.01634</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.01634]] Prompt Injection as an Emerging Threat: Evaluating the Resilience of Large Language Models(https://arxiv.org/abs/2511.01634)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack, robust, large language model</a></li>
<li><strong>Abstract: </strong>Large Language Models (LLMs) are increasingly used in intelligent systems that perform reasoning, summarization, and code generation. Their ability to follow natural-language instructions, while powerful, also makes them vulnerable to a new class of attacks known as prompt injection. In these attacks, hidden or malicious instructions are inserted into user inputs or external content, causing the model to ignore its intended task or produce unsafe responses. This study proposes a unified framework for evaluating how resistant Large Language Models (LLMs) are to prompt injection attacks. The framework defines three complementary metrics such as the Resilience Degradation Index (RDI), Safety Compliance Coefficient (SCC), and Instructional Integrity Metric (IIM) to jointly measure robustness, safety, and semantic stability. We evaluated four instruction-tuned models (GPT-4, GPT-4o, LLaMA-3 8B Instruct, and Flan-T5-Large) on five common language tasks: question answering, summarization, translation, reasoning, and code generation. Results show that GPT-4 performs best overall, while open-weight models remain more vulnerable. The findings highlight that strong alignment and safety tuning are more important for resilience than model size alone. Results show that all models remain partially vulnerable, especially to indirect and direct-override attacks. GPT-4 achieved the best overall resilience (RDR = 9.8 %, SCR = 96.4 %), while open-source models exhibited higher performance degradation and lower safety scores. The findings demonstrate that alignment strength and safety tuning play a greater role in resilience than model size alone. The proposed framework offers a structured, reproducible approach for assessing model robustness and provides practical insights for improving LLM safety and reliability.</li>
</ul>

<h3>Title: A Graph-based RAG for Energy Efficiency Question Answering</h3>
<ul>
<li><strong>Authors: </strong>Riccardo Campi, Nicolò Oreste Pinciroli Vago, Mathyas Giudici, Pablo Barrachina Rodriguez-Guisado, Marco Brambilla, Piero Fraternali</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.IR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.01643">https://arxiv.org/abs/2511.01643</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.01643">https://arxiv.org/pdf/2511.01643</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.01643]] A Graph-based RAG for Energy Efficiency Question Answering(https://arxiv.org/abs/2511.01643)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>In this work, we investigate the use of Large Language Models (LLMs) within a graph-based Retrieval Augmented Generation (RAG) architecture for Energy Efficiency (EE) Question Answering. First, the system automatically extracts a Knowledge Graph (KG) from guidance and regulatory documents in the energy field. Then, the generated graph is navigated and reasoned upon to provide users with accurate answers in multiple languages. We implement a human-based validation using the RAGAs framework properties, a validation dataset comprising 101 question-answer pairs, and domain experts. Results confirm the potential of this architecture and identify its strengths and weaknesses. Validation results show how the system correctly answers in about three out of four of the cases (75.2 +- 2.7%), with higher results on questions related to more general EE answers (up to 81.0 +- 4.1%), and featuring promising multilingual abilities (4.4% accuracy loss due to translation).</li>
</ul>

<h3>Title: Enhancing Diffusion-based Restoration Models via Difficulty-Adaptive Reinforcement Learning with IQA Reward</h3>
<ul>
<li><strong>Authors: </strong>Xiaogang Xu, Ruihang Chu, Jian Wang, Kun Zhou, Wenjie Shu, Harry Yang, Ser-Nam Lim, Hao Chen, Liang Lin</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.01645">https://arxiv.org/abs/2511.01645</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.01645">https://arxiv.org/pdf/2511.01645</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.01645]] Enhancing Diffusion-based Restoration Models via Difficulty-Adaptive Reinforcement Learning with IQA Reward(https://arxiv.org/abs/2511.01645)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>Reinforcement Learning (RL) has recently been incorporated into diffusion models, e.g., tasks such as text-to-image. However, directly applying existing RL methods to diffusion-based image restoration models is suboptimal, as the objective of restoration fundamentally differs from that of pure generation: it places greater emphasis on fidelity. In this paper, we investigate how to effectively integrate RL into diffusion-based restoration models. First, through extensive experiments with various reward functions, we find that an effective reward can be derived from an Image Quality Assessment (IQA) model, instead of intuitive ground-truth-based supervision, which has already been optimized during the Supervised Fine-Tuning (SFT) stage prior to RL. Moreover, our strategy focuses on using RL for challenging samples that are significantly distant from the ground truth, and our RL approach is innovatively implemented using MLLM-based IQA models to align distributions with high-quality images initially. As the samples approach the ground truth's distribution, RL is adaptively combined with SFT for more fine-grained alignment. This dynamic process is facilitated through an automatic weighting strategy that adjusts based on the relative difficulty of the training samples. Our strategy is plug-and-play that can be seamlessly applied to diffusion-based restoration models, boosting its performance across various restoration tasks. Extensive experiments across multiple benchmarks demonstrate the effectiveness of our proposed RL framework.</li>
</ul>

<h3>Title: Evaluating Cultural Knowledge Processing in Large Language Models: A Cognitive Benchmarking Framework Integrating Retrieval-Augmented Generation</h3>
<ul>
<li><strong>Authors: </strong>Hung-Shin Lee, Chen-Chi Chang, Ching-Yuan Chen, Yun-Hsiang Hsu</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.01649">https://arxiv.org/abs/2511.01649</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.01649">https://arxiv.org/pdf/2511.01649</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.01649]] Evaluating Cultural Knowledge Processing in Large Language Models: A Cognitive Benchmarking Framework Integrating Retrieval-Augmented Generation(https://arxiv.org/abs/2511.01649)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>This study proposes a cognitive benchmarking framework to evaluate how large language models (LLMs) process and apply culturally specific knowledge. The framework integrates Bloom's Taxonomy with Retrieval-Augmented Generation (RAG) to assess model performance across six hierarchical cognitive domains: Remembering, Understanding, Applying, Analyzing, Evaluating, and Creating. Using a curated Taiwanese Hakka digital cultural archive as the primary testbed, the evaluation measures LLM-generated responses' semantic accuracy and cultural relevance.</li>
</ul>

<h3>Title: EngChain: A Symbolic Benchmark for Verifiable Multi-Step Reasoning in Engineering</h3>
<ul>
<li><strong>Authors: </strong>Ayesha Gull, Muhammad Usman Safder, Rania Elbadry, Preslav Nakov, Zhuohan Xie</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.01650">https://arxiv.org/abs/2511.01650</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.01650">https://arxiv.org/pdf/2511.01650</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.01650]] EngChain: A Symbolic Benchmark for Verifiable Multi-Step Reasoning in Engineering(https://arxiv.org/abs/2511.01650)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large Language Models (LLMs) are increasingly being applied to specialized, high-stakes domains like engineering, which demands rigorous evaluation of their complex reasoning capabilities. While current benchmarks assess language understanding, factual recall, mathematics or code generation, none capture the integrative reasoning central to engineering where scientific principles, quantitative modeling and practical constraints must converge. To address this gap, we introduce EngChain, a benchmark for verifiable multi-step engineering problem-solving. EngChain contains 90 problems spanning three engineering branches, organized into 9 domains and 20 distinct areas. The problems are generated from symbolic templates with a high degree of randomization to ensure diversity and eliminate the risk of contamination. With this benchmark, we move beyond final answer accuracy with a two-stage evaluation: we first quantitatively verify the numerical and semantic validity of each reasoning step and then introduce LLM-As-A-Judge, an automated system to qualitatively categorize the identified reasoning errors.</li>
</ul>

<h3>Title: Panther: A Cost-Effective Privacy-Preserving Framework for GNN Training and Inference Services in Cloud Environments</h3>
<ul>
<li><strong>Authors: </strong>Congcong Chen, Xinyu Liu, Kaifeng Huang, Lifei Wei, Yang Shi</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.01654">https://arxiv.org/abs/2511.01654</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.01654">https://arxiv.org/pdf/2511.01654</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.01654]] Panther: A Cost-Effective Privacy-Preserving Framework for GNN Training and Inference Services in Cloud Environments(https://arxiv.org/abs/2511.01654)</code><input type="text"></li>
<li><strong>Keywords: </strong>secure, privacy, protect</a></li>
<li><strong>Abstract: </strong>Graph Neural Networks (GNNs) have marked significant impact in traffic state prediction, social recommendation, knowledge-aware question answering and so on. As more and more users move towards cloud computing, it has become a critical issue to unleash the power of GNNs while protecting the privacy in cloud environments. Specifically, the training data and inference data for GNNs need to be protected from being stolen by external adversaries. Meanwhile, the financial cost of cloud computing is another primary concern for users. Therefore, although existing studies have proposed privacy-preserving techniques for GNNs in cloud environments, their additional computational and communication overhead remain relatively high, causing high financial costs that limit their widespread adoption among users. To protect GNN privacy while lowering the additional financial costs, we introduce Panther, a cost-effective privacy-preserving framework for GNN training and inference services in cloud environments. Technically, Panther leverages four-party computation to asynchronously executing the secure array access protocol, and randomly pads the neighbor information of GNN nodes. We prove that Panther can protect privacy for both training and inference of GNN models. Our evaluation shows that Panther reduces the training and inference time by an average of 75.28% and 82.80%, respectively, and communication overhead by an average of 52.61% and 50.26% compared with the state-of-the-art, which is estimated to save an average of 55.05% and 59.00% in financial costs (based on on-demand pricing model) for the GNN training and inference process on Google Cloud Platform.</li>
</ul>

<h3>Title: UniLumos: Fast and Unified Image and Video Relighting with Physics-Plausible Feedback</h3>
<ul>
<li><strong>Authors: </strong>Ropeway Liu, Hangjie Yuan, Bo Dong, Jiazheng Xing, Jinwang Wang, Rui Zhao, Yan Xing, Weihua Chen, Fan Wang</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.01678">https://arxiv.org/abs/2511.01678</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.01678">https://arxiv.org/pdf/2511.01678</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.01678]] UniLumos: Fast and Unified Image and Video Relighting with Physics-Plausible Feedback(https://arxiv.org/abs/2511.01678)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>Relighting is a crucial task with both practical demand and artistic value, and recent diffusion models have shown strong potential by enabling rich and controllable lighting effects. However, as they are typically optimized in semantic latent space, where proximity does not guarantee physical correctness in visual space, they often produce unrealistic results, such as overexposed highlights, misaligned shadows, and incorrect occlusions. We address this with UniLumos, a unified relighting framework for both images and videos that brings RGB-space geometry feedback into a flow matching backbone. By supervising the model with depth and normal maps extracted from its outputs, we explicitly align lighting effects with the scene structure, enhancing physical plausibility. Nevertheless, this feedback requires high-quality outputs for supervision in visual space, making standard multi-step denoising computationally expensive. To mitigate this, we employ path consistency learning, allowing supervision to remain effective even under few-step training regimes. To enable fine-grained relighting control and supervision, we design a structured six-dimensional annotation protocol capturing core illumination attributes. Building upon this, we propose LumosBench, a disentangled attribute-level benchmark that evaluates lighting controllability via large vision-language models, enabling automatic and interpretable assessment of relighting precision across individual dimensions. Extensive experiments demonstrate that UniLumos achieves state-of-the-art relighting quality with significantly improved physical consistency, while delivering a 20x speedup for both image and video relighting. Code is available at this https URL.</li>
</ul>

<h3>Title: Open Character Training: Shaping the Persona of AI Assistants through Constitutional AI</h3>
<ul>
<li><strong>Authors: </strong>Sharan Maiya, Henning Bartsch, Nathan Lambert, Evan Hubinger</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.01689">https://arxiv.org/abs/2511.01689</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.01689">https://arxiv.org/pdf/2511.01689</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.01689]] Open Character Training: Shaping the Persona of AI Assistants through Constitutional AI(https://arxiv.org/abs/2511.01689)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, large language model</a></li>
<li><strong>Abstract: </strong>The character of the "AI assistant" persona generated by modern chatbot large language models influences both surface-level behavior and apparent values, beliefs, and ethics. These all affect interaction quality, perceived intelligence, and alignment with both developer and user intentions. The shaping of this persona, known as character training, is a critical component of industry post-training, yet remains effectively unstudied in the academic literature. We introduce the first open implementation of character training, leveraging Constitutional AI and a new data pipeline using synthetic introspective data to shape the assistant persona in a more effective and controlled manner than alternatives such as constraining system prompts or activation steering. Specifically, we fine-tune three popular open-weights models using 11 example personas, such as humorous, deeply caring, or even malevolent. To track the effects of our approach, we introduce a method which analyzes revealed preferences, uncovering clear and holistic changes in character. We find these changes are more robust to adversarial prompting than the above two alternatives, while also leading to more coherent and realistic generations. Finally, we demonstrate this fine-tuning has little to no effect on general capabilities as measured by common benchmarks. We describe and open-source our full post-training method, the implementation of which can be found at this https URL.</li>
</ul>

<h3>Title: Bayesian Natural Gradient Fine-Tuning of CLIP Models via Kalman Filtering</h3>
<ul>
<li><strong>Authors: </strong>Hossein Abdi, Mingfei Sun, Wei Pan</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.01694">https://arxiv.org/abs/2511.01694</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.01694">https://arxiv.org/pdf/2511.01694</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.01694]] Bayesian Natural Gradient Fine-Tuning of CLIP Models via Kalman Filtering(https://arxiv.org/abs/2511.01694)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Vision-language pre-trained models, such as CLIP, have established new benchmarks in multimodal data mining. In such models, few-shot fine-tuning is a major challenge to achieve optimal performance on both in-distribution (ID) and out-of-distribution (OOD) datasets, especially when labeled data is scarce. Most existing fine-tuning approaches rely on first-order gradient-based optimizers, which typically suffer from slow convergence, sensitivity to step-size hyperparameters, and poor generalization in OOD settings. In contrast, second-order methods utilize local curvature information of the loss landscape to adjust the update step size. This is particularly beneficial for CLIP models, whose non-convex loss functions often contain sharp critical points. In such cases, natural gradient direction can offer more substantial and efficient per-iteration updates when fine-tuning with limited data. Natural Gradient Descent (NGD) is obtained by preconditioning the standard gradient with the inverse Fisher Information Matrix (FIM), which is computationally expensive for large models. To address this, we propose a Bayesian approximation of NGD using a Kalman filter for CLIP models. Our method combines the benefits of second-order optimization with Bayesian inference, which enhances generalization while providing uncertainty quantification. Extensive experiments conducted on diverse image classification datasets demonstrate that our algorithm consistently achieves superior--or comparable--ID performance and improved OOD robustness compared to state-of-the-art baselines. To the best of our knowledge, this work represents the first successful application of Kalman filtering to fine-tuning CLIP-based models, which enables more robust and efficient learning in vision-language tasks.</li>
</ul>

<h3>Title: Collaborative Large Language Model Inference via Resource-Aware Parallel Speculative Decoding</h3>
<ul>
<li><strong>Authors: </strong>Jungyeon Koh, Hyun Jong Yang</a></li>
<li><strong>Subjects: </strong>cs.LG, eess.SP</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.01695">https://arxiv.org/abs/2511.01695</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.01695">https://arxiv.org/pdf/2511.01695</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.01695]] Collaborative Large Language Model Inference via Resource-Aware Parallel Speculative Decoding(https://arxiv.org/abs/2511.01695)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>The growing demand for on-device large language model (LLM) inference highlights the need for efficient mobile edge computing (MEC) solutions, especially in resource-constrained settings. Speculative decoding offers a promising solution by partitioning token generation between a lightweight draft model on mobile devices and a powerful target model on edge servers, but suffers from communication overhead and asynchronous delays. This paper is the first to propose a unified framework that jointly optimizes user association and resource allocation (UARA) to support efficient parallel speculative decoding. We solve the UARA problem using a multi-agent deep reinforcement learning algorithm. To evaluate our approach under realistic conditions, we conduct experiments using the Sionna simulator. Results show that our method achieves up to 28.0% and an average of 23.7% reduction in end-to-end latency without compromising inference accuracy, enabling scalable and low-latency LLM services in MEC systems.</li>
</ul>

<h3>Title: Learnable Fractional Reaction-Diffusion Dynamics for Under-Display ToF Imaging and Beyond</h3>
<ul>
<li><strong>Authors: </strong>Xin Qiao, Matteo Poggi, Xing Wei, Pengchao Deng, Yanhui Zhou, Stefano Mattoccia</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.01704">https://arxiv.org/abs/2511.01704</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.01704">https://arxiv.org/pdf/2511.01704</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.01704]] Learnable Fractional Reaction-Diffusion Dynamics for Under-Display ToF Imaging and Beyond(https://arxiv.org/abs/2511.01704)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability, diffusion</a></li>
<li><strong>Abstract: </strong>Under-display ToF imaging aims to achieve accurate depth sensing through a ToF camera placed beneath a screen panel. However, transparent OLED (TOLED) layers introduce severe degradations-such as signal attenuation, multi-path interference (MPI), and temporal noise-that significantly compromise depth quality. To alleviate this drawback, we propose Learnable Fractional Reaction-Diffusion Dynamics (LFRD2), a hybrid framework that combines the expressive power of neural networks with the interpretability of physical modeling. Specifically, we implement a time-fractional reaction-diffusion module that enables iterative depth refinement with dynamically generated differential orders, capturing long-term dependencies. In addition, we introduce an efficient continuous convolution operator via coefficient prediction and repeated differentiation to further improve restoration quality. Experiments on four benchmark datasets demonstrate the effectiveness of our approach. The code is publicly available at this https URL.</li>
</ul>

<h3>Title: Multi-Step Knowledge Interaction Analysis via Rank-2 Subspace Disentanglement</h3>
<ul>
<li><strong>Authors: </strong>Sekh Mainul Islam, Pepa Atanasova, Isabelle Augenstein</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.01706">https://arxiv.org/abs/2511.01706</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.01706">https://arxiv.org/pdf/2511.01706</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.01706]] Multi-Step Knowledge Interaction Analysis via Rank-2 Subspace Disentanglement(https://arxiv.org/abs/2511.01706)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Natural Language Explanations (NLEs) describe how Large Language Models (LLMs) make decisions, drawing on both external Context Knowledge (CK) and Parametric Knowledge (PK) stored in model weights. Understanding their interaction is key to assessing the grounding of NLEs, yet it remains underexplored. Prior work has largely examined only single-step generation, typically the final answer, and has modelled PK and CK interaction only as a binary choice in a rank-1 subspace. This overlooks richer forms of interaction, such as complementary or supportive knowledge. We propose a novel rank-2 projection subspace that disentangles PK and CK contributions more accurately and use it for the first multi-step analysis of knowledge interactions across longer NLE sequences. Experiments on four QA datasets and three open-weight instruction-tuned LLMs show that diverse knowledge interactions are poorly represented in a rank-1 subspace but are effectively captured in our rank-2 formulation. Our multi-step analysis reveals that hallucinated NLEs align strongly with the PK direction, context-faithful ones balance PK and CK, and Chain-of-Thought prompting for NLEs shifts generated NLEs toward CK by reducing PK reliance. This work provides the first framework for systematic studies of multi-step knowledge interactions in LLMs through a richer rank-2 subspace disentanglement. Code and data: this https URL.</li>
</ul>

<h3>Title: Probabilistic Robustness for Free? Revisiting Training via a Benchmark</h3>
<ul>
<li><strong>Authors: </strong>Yi Zhang, Zheng Wang, Chen Zhen, Wenjie Ruan, Qing Guo, Siddartha Khastgir, Carsten Maple, Xingyu Zhao</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.01724">https://arxiv.org/abs/2511.01724</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.01724">https://arxiv.org/pdf/2511.01724</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.01724]] Probabilistic Robustness for Free? Revisiting Training via a Benchmark(https://arxiv.org/abs/2511.01724)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Deep learning models are notoriously vulnerable to imperceptible perturbations. Most existing research centers on adversarial robustness (AR), which evaluates models under worst-case scenarios by examining the existence of deterministic adversarial examples (AEs). In contrast, probabilistic robustness (PR) adopts a statistical perspective, measuring the probability that predictions remain correct under stochastic perturbations. While PR is widely regarded as a practical complement to AR, dedicated training methods for improving PR are still relatively underexplored, albeit with emerging progress. Among the few PR-targeted training methods, we identify three limitations: i non-comparable evaluation protocols; ii limited comparisons to strong AT baselines despite anecdotal PR gains from AT; and iii no unified framework to compare the generalization of these methods. Thus, we introduce PRBench, the first benchmark dedicated to evaluating improvements in PR achieved by different robustness training methods. PRBench empirically compares most common AT and PR-targeted training methods using a comprehensive set of metrics, including clean accuracy, PR and AR performance, training efficiency, and generalization error (GE). We also provide theoretical analysis on the GE of PR performance across different training methods. Main findings revealed by PRBench include: AT methods are more versatile than PR-targeted training methods in terms of improving both AR and PR performance across diverse hyperparameter settings, while PR-targeted training methods consistently yield lower GE and higher clean accuracy. A leaderboard comprising 222 trained models across 7 datasets and 10 model architectures is publicly available at this https URL.</li>
</ul>

<h3>Title: CGF-DETR: Cross-Gated Fusion DETR for Enhanced Pneumonia Detection in Chest X-rays</h3>
<ul>
<li><strong>Authors: </strong>Yefeng Wu, Yucheng Song, Ling Wu, Shan Wan, Yecheng Zhao</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.01730">https://arxiv.org/abs/2511.01730</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.01730">https://arxiv.org/pdf/2511.01730</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.01730]] CGF-DETR: Cross-Gated Fusion DETR for Enhanced Pneumonia Detection in Chest X-rays(https://arxiv.org/abs/2511.01730)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction, transformer</a></li>
<li><strong>Abstract: </strong>Pneumonia remains a leading cause of morbidity and mortality worldwide, necessitating accurate and efficient automated detection systems. While recent transformer-based detectors like RT-DETR have shown promise in object detection tasks, their application to medical imaging, particularly pneumonia detection in chest X-rays, remains underexplored. This paper presents CGF-DETR, an enhanced real-time detection transformer specifically designed for pneumonia detection. We introduce XFABlock in the backbone to improve multi-scale feature extraction through convolutional attention mechanisms integrated with CSP architecture. To achieve efficient feature aggregation, we propose SPGA module that replaces standard multi-head attention with dynamic gating mechanisms and single-head self-attention. Additionally, GCFC3 is designed for the neck to enhance feature representation through multi-path convolution fusion while maintaining real-time performance via structural re-parameterization. Extensive experiments on the RSNA Pneumonia Detection dataset demonstrate that CGF-DETR achieves 82.2\% mAP@0.5, outperforming the baseline RT-DETR-l by 3.7\% while maintaining comparable inference speed at 48.1 FPS. Our ablation studies confirm that each proposed module contributes meaningfully to the overall performance improvement, with the complete model achieving 50.4\% mAP@[0.5:0.95]</li>
</ul>

<h3>Title: Edge AI in Highly Volatile Environments: Is Fairness Worth the Accuracy Trade-off?</h3>
<ul>
<li><strong>Authors: </strong>Obaidullah Zaland, Feras M. Awaysheh, Sawsan Al Zubi, Abdul Rahman Safi, Monowar Bhuyan</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.DC</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.01737">https://arxiv.org/abs/2511.01737</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.01737">https://arxiv.org/pdf/2511.01737</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.01737]] Edge AI in Highly Volatile Environments: Is Fairness Worth the Accuracy Trade-off?(https://arxiv.org/abs/2511.01737)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, federate, fair</a></li>
<li><strong>Abstract: </strong>Federated learning (FL) has emerged as a transformative paradigm for edge intelligence, enabling collaborative model training while preserving data privacy across distributed personal devices. However, the inherent volatility of edge environments, characterized by dynamic resource availability and heterogeneous client capabilities, poses significant challenges for achieving high accuracy and fairness in client participation. This paper investigates the fundamental trade-off between model accuracy and fairness in highly volatile edge environments. This paper provides an extensive empirical evaluation of fairness-based client selection algorithms such as RBFF and RBCSF against random and greedy client selection regarding fairness, model performance, and time, in three benchmarking datasets (CIFAR10, FashionMNIST, and EMNIST). This work aims to shed light on the fairness-performance and fairness-speed trade-offs in a volatile edge environment and explore potential future research opportunities to address existing pitfalls in \textit{fair client selection} strategies in FL. Our results indicate that more equitable client selection algorithms, while providing a marginally better opportunity among clients, can result in slower global training in volatile environments\footnote{The code for our experiments can be found at this https URL.</li>
</ul>

<h3>Title: Game-theoretic distributed learning of generative models for heterogeneous data collections</h3>
<ul>
<li><strong>Authors: </strong>Dmitrij Schlesinger, Boris Flach</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.01740">https://arxiv.org/abs/2511.01740</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.01740">https://arxiv.org/pdf/2511.01740</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.01740]] Game-theoretic distributed learning of generative models for heterogeneous data collections(https://arxiv.org/abs/2511.01740)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>One of the main challenges in distributed learning arises from the difficulty of handling heterogeneous local models and data. In light of the recent success of generative models, we propose to meet this challenge by building on the idea of exchanging synthetic data instead of sharing model parameters. Local models can then be treated as ``black boxes'' with the ability to learn their parameters from data and to generate data according to these parameters. Moreover, if the local models admit semi-supervised learning, we can extend the approach by enabling local models on different probability spaces. This allows to handle heterogeneous data with different modalities. We formulate the learning of the local models as a cooperative game starting from the principles of game theory. We prove the existence of a unique Nash equilibrium for exponential family local models and show that the proposed learning approach converges to this equilibrium. We demonstrate the advantages of our approach on standard benchmark vision datasets for image classification and conditional generation.</li>
</ul>

<h3>Title: Towards Efficient Federated Learning of Networked Mixture-of-Experts for Mobile Edge Computing</h3>
<ul>
<li><strong>Authors: </strong>Song Gao, Shusen Jing, Shuai Zhang, Yue Wang, Xiangwei Zhou, Songyang Zhang</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.NI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.01743">https://arxiv.org/abs/2511.01743</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.01743">https://arxiv.org/pdf/2511.01743</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.01743]] Towards Efficient Federated Learning of Networked Mixture-of-Experts for Mobile Edge Computing(https://arxiv.org/abs/2511.01743)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, federate</a></li>
<li><strong>Abstract: </strong>Recent advancements in large artificial intelligence models (LAMs) are driving significant innovations in mobile edge computing within next-generation wireless networks. However, the substantial demands for computational resources and large-scale training data required to train LAMs conflict with the limited storage and computational capacity of edge devices, posing significant challenges to training and deploying LAMs at the edge. In this work, we introduce the Networked Mixture-of-Experts (NMoE) system, in which clients infer collaboratively by distributing tasks to suitable neighbors based on their expertise and aggregate the returned results. For training the NMoE, we propose a federated learning framework that integrates both supervised and self-supervised learning to balance personalization and generalization, while preserving communication efficiency and data privacy. We conduct extensive experiments to demonstrate the efficacy of the proposed NMoE system, providing insights and benchmarks for the NMoE training algorithms.</li>
</ul>

<h3>Title: Scam Shield: Multi-Model Voting and Fine-Tuned LLMs Against Adversarial Attacks</h3>
<ul>
<li><strong>Authors: </strong>Chen-Wei Chang, Shailik Sarkar, Hossein Salemi, Hyungmin Kim, Shutonu Mitra, Hemant Purohit, Fengxiu Zhang, Michin Hong, Jin-Hee Cho, Chang-Tien Lu</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.01746">https://arxiv.org/abs/2511.01746</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.01746">https://arxiv.org/pdf/2511.01746</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.01746]] Scam Shield: Multi-Model Voting and Fine-Tuned LLMs Against Adversarial Attacks(https://arxiv.org/abs/2511.01746)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, attack, robust</a></li>
<li><strong>Abstract: </strong>Scam detection remains a critical challenge in cybersecurity as adversaries craft messages that evade automated filters. We propose a Hierarchical Scam Detection System (HSDS) that combines a lightweight multi-model voting front end with a fine-tuned LLaMA 3.1 8B Instruct back end to improve accuracy and robustness against adversarial attacks. An ensemble of four classifiers provides preliminary predictions through majority vote, and ambiguous cases are escalated to the fine-tuned model, which is optimized with adversarial training to reduce misclassification. Experiments show that this hierarchical design both improves adversarial scam detection and shortens inference time by routing most cases away from the LLM, outperforming traditional machine-learning baselines and proprietary LLM baselines. The findings highlight the effectiveness of a hybrid voting mechanism and adversarial fine-tuning in fortifying LLMs against evolving scam tactics, enhancing the resilience of automated scam detection systems.</li>
</ul>

<h3>Title: HGFreNet: Hop-hybrid GraphFomer for 3D Human Pose Estimation with Trajectory Consistency in Frequency Domain</h3>
<ul>
<li><strong>Authors: </strong>Kai Zhai, Ziyan Huang, Qiang Nie, Xiang Li, Bo Ouyang</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.01756">https://arxiv.org/abs/2511.01756</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.01756">https://arxiv.org/pdf/2511.01756</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.01756]] HGFreNet: Hop-hybrid GraphFomer for 3D Human Pose Estimation with Trajectory Consistency in Frequency Domain(https://arxiv.org/abs/2511.01756)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>2D-to-3D human pose lifting is a fundamental challenge for 3D human pose estimation in monocular video, where graph convolutional networks (GCNs) and attention mechanisms have proven to be inherently suitable for encoding the spatial-temporal correlations of skeletal joints. However, depth ambiguity and errors in 2D pose estimation lead to incoherence in the 3D trajectory. Previous studies have attempted to restrict jitters in the time domain, for instance, by constraining the differences between adjacent frames while neglecting the global spatial-temporal correlations of skeletal joint motion. To tackle this problem, we design HGFreNet, a novel GraphFormer architecture with hop-hybrid feature aggregation and 3D trajectory consistency in the frequency domain. Specifically, we propose a hop-hybrid graph attention (HGA) module and a Transformer encoder to model global joint spatial-temporal correlations. The HGA module groups all $k$-hop neighbors of a skeletal joint into a hybrid group to enlarge the receptive field and applies the attention mechanism to discover the latent correlations of these groups globally. We then exploit global temporal correlations by constraining trajectory consistency in the frequency domain. To provide 3D information for depth inference across frames and maintain coherence over time, a preliminary network is applied to estimate the 3D pose. Extensive experiments were conducted on two standard benchmark datasets: Human3.6M and MPI-INF-3DHP. The results demonstrate that the proposed HGFreNet outperforms state-of-the-art (SOTA) methods in terms of positional accuracy and temporal consistency.</li>
</ul>

<h3>Title: RLAC: Reinforcement Learning with Adversarial Critic for Free-Form Generation Tasks</h3>
<ul>
<li><strong>Authors: </strong>Mian Wu, Gavin Zhang, Sewon Min, Sergey Levine, Aviral Kumar</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.01758">https://arxiv.org/abs/2511.01758</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.01758">https://arxiv.org/pdf/2511.01758</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.01758]] RLAC: Reinforcement Learning with Adversarial Critic for Free-Form Generation Tasks(https://arxiv.org/abs/2511.01758)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Open-ended generation tasks require outputs to satisfy diverse and often implicit task-specific evaluation rubrics. The sheer number of relevant rubrics leads to prohibitively high verification costs and incomplete assessments of a response, making reinforcement learning (RL) post-training with rubric-based rewards difficult to scale. This problem is exacerbated by the fact that often the best way to combine these rubrics into one single reward is also highly prompt-specific. We propose Reinforcement Learning with Adversarial Critic (RLAC), a post-training approach that addresses these challenges via dynamic rubric verification. Our approach employs a large language model (LLM) as a critic that dynamically identifies only the most likely failure modes (e.g., a factual error or unhandled edge case), which are then verified by an external validator to optimize both generator and critic jointly. By training both the generator and the critic, this game enhances the critic's error detection and the generator's output quality while reducing required verifications. Our experiments demonstrate that RLAC improves factual accuracy in text generation and correctness in code generation, while also outperforming exhaustive verification and reward model methods. We show that dynamic critics are more effective than fixed critics, showcasing the potential of RLAC for scaling RL post-training to free-form generation tasks.</li>
</ul>

<h3>Title: Wonder3D++: Cross-domain Diffusion for High-fidelity 3D Generation from a Single Image</h3>
<ul>
<li><strong>Authors: </strong>Yuxiao Yang, Xiao-Xiao Long, Zhiyang Dou, Cheng Lin, Yuan Liu, Qingsong Yan, Yuexin Ma, Haoqian Wang, Zhiqiang Wu, Wei Yin</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.01767">https://arxiv.org/abs/2511.01767</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.01767">https://arxiv.org/pdf/2511.01767</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.01767]] Wonder3D++: Cross-domain Diffusion for High-fidelity 3D Generation from a Single Image(https://arxiv.org/abs/2511.01767)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, extraction, diffusion</a></li>
<li><strong>Abstract: </strong>In this work, we introduce \textbf{Wonder3D++}, a novel method for efficiently generating high-fidelity textured meshes from single-view images. Recent methods based on Score Distillation Sampling (SDS) have shown the potential to recover 3D geometry from 2D diffusion priors, but they typically suffer from time-consuming per-shape optimization and inconsistent geometry. In contrast, certain works directly produce 3D information via fast network inferences, but their results are often of low quality and lack geometric details. To holistically improve the quality, consistency, and efficiency of single-view reconstruction tasks, we propose a cross-domain diffusion model that generates multi-view normal maps and the corresponding color images. To ensure the consistency of generation, we employ a multi-view cross-domain attention mechanism that facilitates information exchange across views and modalities. Lastly, we introduce a cascaded 3D mesh extraction algorithm that drives high-quality surfaces from the multi-view 2D representations in only about $3$ minute in a coarse-to-fine manner. Our extensive evaluations demonstrate that our method achieves high-quality reconstruction results, robust generalization, and good efficiency compared to prior works. Code available at this https URL.</li>
</ul>

<h3>Title: UniLION: Towards Unified Autonomous Driving Model with Linear Group RNNs</h3>
<ul>
<li><strong>Authors: </strong>Zhe Liu, Jinghua Hou, Xiaoqing Ye, Jingdong Wang, Hengshuang Zhao, Xiang Bai</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.01768">https://arxiv.org/abs/2511.01768</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.01768">https://arxiv.org/pdf/2511.01768</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.01768]] UniLION: Towards Unified Autonomous Driving Model with Linear Group RNNs(https://arxiv.org/abs/2511.01768)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer, segmentation</a></li>
<li><strong>Abstract: </strong>Although transformers have demonstrated remarkable capabilities across various domains, their quadratic attention mechanisms introduce significant computational overhead when processing long-sequence data. In this paper, we present a unified autonomous driving model, UniLION, which efficiently handles large-scale LiDAR point clouds, high-resolution multi-view images, and even temporal sequences based on the linear group RNN operator (i.e., performs linear RNN for grouped features). Remarkably, UniLION serves as a single versatile architecture that can seamlessly support multiple specialized variants (i.e., LiDAR-only, temporal LiDAR, multi-modal, and multi-modal temporal fusion configurations) without requiring explicit temporal or multi-modal fusion modules. Moreover, UniLION consistently delivers competitive and even state-of-the-art performance across a wide range of core tasks, including 3D perception (e.g., 3D object detection, 3D object tracking, 3D occupancy prediction, BEV map segmentation), prediction (e.g., motion prediction), and planning (e.g., end-to-end planning). This unified paradigm naturally simplifies the design of multi-modal and multi-task autonomous driving systems while maintaining superior performance. Ultimately, we hope UniLION offers a fresh perspective on the development of 3D foundation models in autonomous driving. Code is available at this https URL</li>
</ul>

<h3>Title: Fractional Diffusion Bridge Models</h3>
<ul>
<li><strong>Authors: </strong>Gabriel Nobis, Maximilian Springenberg, Arina Belova, Rembert Daems, Christoph Knochenhauer, Manfred Opper, Tolga Birdal, Wojciech Samek</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CV, cs.RO, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.01795">https://arxiv.org/abs/2511.01795</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.01795">https://arxiv.org/pdf/2511.01795</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.01795]] Fractional Diffusion Bridge Models(https://arxiv.org/abs/2511.01795)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, generative</a></li>
<li><strong>Abstract: </strong>We present Fractional Diffusion Bridge Models (FDBM), a novel generative diffusion bridge framework driven by an approximation of the rich and non-Markovian fractional Brownian motion (fBM). Real stochastic processes exhibit a degree of memory effects (correlations in time), long-range dependencies, roughness and anomalous diffusion phenomena that are not captured in standard diffusion or bridge modeling due to the use of Brownian motion (BM). As a remedy, leveraging a recent Markovian approximation of fBM (MA-fBM), we construct FDBM that enable tractable inference while preserving the non-Markovian nature of fBM. We prove the existence of a coupling-preserving generative diffusion bridge and leverage it for future state prediction from paired training data. We then extend our formulation to the Schrödinger bridge problem and derive a principled loss function to learn the unpaired data translation. We evaluate FDBM on both tasks: predicting future protein conformations from aligned data, and unpaired image translation. In both settings, FDBM achieves superior performance compared to the Brownian baselines, yielding lower root mean squared deviation (RMSD) of C$_\alpha$ atomic positions in protein structure prediction and lower Fréchet Inception Distance (FID) in unpaired image translation.</li>
</ul>

<h3>Title: Bayesian Coreset Optimization for Personalized Federated Learning</h3>
<ul>
<li><strong>Authors: </strong>Prateek Chanda, Shrey Modi, Ganesh Ramakrishnan</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.01800">https://arxiv.org/abs/2511.01800</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.01800">https://arxiv.org/pdf/2511.01800</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.01800]] Bayesian Coreset Optimization for Personalized Federated Learning(https://arxiv.org/abs/2511.01800)</code><input type="text"></li>
<li><strong>Keywords: </strong>federate</a></li>
<li><strong>Abstract: </strong>In a distributed machine learning setting like Federated Learning where there are multiple clients involved which update their individual weights to a single central server, often training on the entire individual client's dataset for each client becomes cumbersome. To address this issue we propose $\methodprop$: a personalized coreset weighted federated learning setup where the training updates for each individual clients are forwarded to the central server based on only individual client coreset based representative data points instead of the entire client data. Through theoretical analysis we present how the average generalization error is minimax optimal up to logarithm bounds (upper bounded by $\mathcal{O}(n_k^{-\frac{2 \beta}{2 \beta+\boldsymbol{\Lambda}}} \log ^{2 \delta^{\prime}}(n_k))$) and lower bounds of $\mathcal{O}(n_k^{-\frac{2 \beta}{2 \beta+\boldsymbol{\Lambda}}})$, and how the overall generalization error on the data likelihood differs from a vanilla Federated Learning setup as a closed form function ${\boldsymbol{\Im}}(\boldsymbol{w}, n_k)$ of the coreset weights $\boldsymbol{w}$ and coreset sample size $n_k$. Our experiments on different benchmark datasets based on a variety of recent personalized federated learning architectures show significant gains as compared to random sampling on the training data followed by federated learning, thereby indicating how intelligently selecting such training samples can help in performance. Additionally, through experiments on medical datasets our proposed method showcases some gains as compared to other submodular optimization based approaches used for subset selection on client's data.</li>
</ul>

<h3>Title: PROPEX-RAG: Enhanced GraphRAG using Prompt-Driven Prompt Execution</h3>
<ul>
<li><strong>Authors: </strong>Tejas Sarnaik, Manan Shah, Ravi Hegde</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.01802">https://arxiv.org/abs/2511.01802</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.01802">https://arxiv.org/pdf/2511.01802</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.01802]] PROPEX-RAG: Enhanced GraphRAG using Prompt-Driven Prompt Execution(https://arxiv.org/abs/2511.01802)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, extraction, large language model</a></li>
<li><strong>Abstract: </strong>Retrieval-Augmented Generation (RAG) has become a robust framework for enhancing Large Language Models (LLMs) with external knowledge. Recent advances in RAG have investigated graph based retrieval for intricate reasoning; however, the influence of prompt design on enhancing the retrieval and reasoning process is still considerably under-examined. In this paper, we present a prompt-driven GraphRAG framework that underscores the significance of prompt formulation in facilitating entity extraction, fact selection, and passage reranking for multi-hop question answering. Our approach creates a symbolic knowledge graph from text data by encoding entities and factual relationships as structured facts triples. We use LLMs selectively during online retrieval to perform semantic filtering and answer generation. We also use entity-guided graph traversal through Personalized PageRank (PPR) to support efficient, scalable retrieval based on the knowledge graph we built. Our system gets state-of-the-art performance on HotpotQA and 2WikiMultiHopQA, with F1 scores of 80.7% and 78.9%, and Recall@5 scores of 97.1% and 98.1%, respectively. These results show that prompt design is an important part of improving retrieval accuracy and response quality. This research lays the groundwork for more efficient and comprehensible multi-hop question-answering systems, highlighting the importance of prompt-aware graph reasoning.</li>
</ul>

<h3>Title: Dynamic Reconstruction of Ultrasound-Derived Flow Fields With Physics-Informed Neural Fields</h3>
<ul>
<li><strong>Authors: </strong>Viraj Patel, Lisa Kreusser, Katharine Fraser</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.01804">https://arxiv.org/abs/2511.01804</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.01804">https://arxiv.org/pdf/2511.01804</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.01804]] Dynamic Reconstruction of Ultrasound-Derived Flow Fields With Physics-Informed Neural Fields(https://arxiv.org/abs/2511.01804)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Blood flow is sensitive to disease and provides insight into cardiac function, making flow field analysis valuable for diagnosis. However, while safer than radiation-based imaging and more suitable for patients with medical implants, ultrasound suffers from attenuation with depth, limiting the quality of the image. Despite advances in echocardiographic particle image velocimetry (EchoPIV), accurately measuring blood velocity remains challenging due to the technique's limitations and the complexity of blood flow dynamics. Physics-informed machine learning can enhance accuracy and robustness, particularly in scenarios where noisy or incomplete data challenge purely data-driven approaches. We present a physics-informed neural field model with multi-scale Fourier Feature encoding for estimating blood flow from sparse and noisy ultrasound data without requiring ground truth supervision. We demonstrate that this model achieves consistently low mean squared error in denoising and inpainting both synthetic and real datasets, verified against reference flow fields and ground truth flow rate measurements. While physics-informed neural fields have been widely used to reconstruct medical images, applications to medical flow reconstruction are mostly prominent in Flow MRI. In this work, we adapt methods that have proven effective in other imaging modalities to address the specific challenge of ultrasound-based flow reconstruction.</li>
</ul>

<h3>Title: Plan-and-Write: Structure-Guided Length Control for LLMs without Model Retraining</h3>
<ul>
<li><strong>Authors: </strong>Adewale Akinfaderin, Shreyas Subramanian, Akarsha Sehwag</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.01807">https://arxiv.org/abs/2511.01807</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.01807">https://arxiv.org/pdf/2511.01807</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.01807]] Plan-and-Write: Structure-Guided Length Control for LLMs without Model Retraining(https://arxiv.org/abs/2511.01807)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Length control in Large Language Models (LLMs) is a crucial but under-addressed challenge, with applications ranging from voice interfaces requiring concise responses to research summaries needing comprehensive outputs. Current approaches to length control, including Regularized DPO, Length-Instruction Fine Tuning, and tool-augmented methods, typically require expensive model retraining or complex inference-time tooling. This paper presents a prompt engineering methodology that enables precise length control without model retraining. Our structure-guided approach implements deliberate planning and word counting mechanisms within the prompt, encouraging the model to carefully track and adhere to specified length constraints. Comprehensive evaluations across six state-of-the-art LLMs demonstrate that our method significantly improves length fidelity for several models compared to standard prompting when applied to document summarization tasks, particularly for shorter-to-medium length constraints. The proposed technique shows varying benefits across different model architectures, with some models demonstrating up to 37.6% improvement in length adherence. Quality evaluations further reveal that our approach maintains or enhances overall output quality compared to standard prompting techniques. Our approach provides an immediately deployable solution for applications requiring precise length control, particularly valuable for production environments where model retraining is impractical or cost-prohibitive.</li>
</ul>

<h3>Title: KV Cache Transform Coding for Compact Storage in LLM Inference</h3>
<ul>
<li><strong>Authors: </strong>Konrad Staniszewski, Adrian Łańcucki</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.01815">https://arxiv.org/abs/2511.01815</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.01815">https://arxiv.org/pdf/2511.01815</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.01815]] KV Cache Transform Coding for Compact Storage in LLM Inference(https://arxiv.org/abs/2511.01815)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Serving large language models (LLMs) at scale necessitates efficient key-value (KV) cache management. KV caches can be reused across conversation turns via shared-prefix prompts that are common in iterative code editing and chat. However, stale caches consume scarce GPU memory, require offloading, or force recomputation. We present KVTC, a lightweight transform coder that compresses KV caches for compact on-GPU and off-GPU storage. Drawing on classical media compression, KVTC combines PCA-based feature decorrelation, adaptive quantization, and entropy coding. It requires only a brief initial calibration and leaves model parameters unchanged. By exploiting redundancies in KV caches, KVTC achieves up to 20$\times$ compression while maintaining reasoning and long-context accuracy, and 40$\times$ or higher for specific use cases. We test KVTC with Llama 3, Mistral NeMo, and R1-Qwen 2.5 models across benchmarks including AIME25, LiveCodeBench, GSM8K, MMLU, Qasper, RULER, and MATH-500. It consistently outperforms inference-time baselines such as token eviction, quantization, and SVD-based methods, while achieving higher compression ratios. These results support KVTC as a practical building block for memory-efficient LLM serving with reusable KV caches.</li>
</ul>

<h3>Title: No-rank Tensor Decomposition Using Metric Learning</h3>
<ul>
<li><strong>Authors: </strong>Maryam Bagherian</a></li>
<li><strong>Subjects: </strong>cs.LG, math.OC</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.01816">https://arxiv.org/abs/2511.01816</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.01816">https://arxiv.org/pdf/2511.01816</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.01816]] No-rank Tensor Decomposition Using Metric Learning(https://arxiv.org/abs/2511.01816)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Tensor decomposition faces fundamental challenges in analyzing high-dimensional data, where traditional methods based on reconstruction and fixed-rank constraints often fail to capture semantically meaningful structures. This paper introduces a no-rank tensor decomposition framework grounded in metric learning, which replaces reconstruction objectives with a discriminative, similarity-based optimization. The proposed approach learns data-driven embeddings by optimizing a triplet loss with diversity and uniformity regularization, creating a feature space where distance directly reflects semantic similarity. We provide theoretical guarantees for the framework's convergence and establish bounds on its metric properties. Evaluations across diverse domains --including face recognition (LFW, Olivetti), brain connectivity analysis (ABIDE), and simulated data (galaxy morphology, crystal structures)-- demonstrate that our method outperforms baseline techniques, including PCA, t-SNE, UMAP, and tensor decomposition baselines (CP and Tucker). Results show substantial improvements in clustering metrics (Silhouette Score, Davies--Bouldin Index, Calinski--Harabasz Index, Separation Ratio, Adjusted Rand Index, Normalized Mutual Information) and reveal a fundamental trade-off: while metric learning optimizes global class separation, it deliberately transforms local geometry to align with semantic relationships. Crucially, our approach achieves superior performance with smaller training datasets compared to transformer-based methods, offering an efficient alternative for domains with limited labeled data. This work establishes metric learning as a paradigm for tensor-based analysis, prioritizing semantic relevance over pixel-level fidelity while providing computational advantages in data-scarce scenarios.</li>
</ul>

<h3>Title: Machine and Deep Learning for Indoor UWB Jammer Localization</h3>
<ul>
<li><strong>Authors: </strong>Hamed Fard, Mahsa Kholghi, Benedikt Groß, Gerhard Wunder</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.01819">https://arxiv.org/abs/2511.01819</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.01819">https://arxiv.org/pdf/2511.01819</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.01819]] Machine and Deep Learning for Indoor UWB Jammer Localization(https://arxiv.org/abs/2511.01819)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, attack, robust</a></li>
<li><strong>Abstract: </strong>Ultra-wideband (UWB) localization delivers centimeter-scale accuracy but is vulnerable to jamming attacks, creating security risks for asset tracking and intrusion detection in smart buildings. Although machine learning (ML) and deep learning (DL) methods have improved tag localization, localizing malicious jammers within a single room and across changing indoor layouts remains largely unexplored. Two novel UWB datasets, collected under original and modified room configurations, are introduced to establish comprehensive ML/DL baselines. Performance is rigorously evaluated using a variety of classification and regression metrics. On the source dataset with the collected UWB features, Random Forest achieves the highest F1-macro score of 0.95 and XGBoost achieves the lowest mean Euclidean error of 20.16 cm. However, deploying these source-trained models in the modified room layout led to severe performance degradation, with XGBoost's mean Euclidean error increasing tenfold to 207.99 cm, demonstrating significant domain shift. To mitigate this degradation, a domain-adversarial ConvNeXt autoencoder (A-CNT) is proposed that leverages a gradient-reversal layer to align CIR-derived features across domains. The A-CNT framework restores localization performance by reducing the mean Euclidean error to 34.67 cm. This represents a 77 percent improvement over non-adversarial transfer learning and an 83 percent improvement over the best baseline, restoring the fraction of samples within 30 cm to 0.56. Overall, the results demonstrate that adversarial feature alignment enables robust and transferable indoor jammer localization despite environmental changes. Code and dataset available at this https URL</li>
</ul>

<h3>Title: Dynamic Routing Between Experts: A Data-Efficient Approach to Continual Learning in Vision-Language Models</h3>
<ul>
<li><strong>Authors: </strong>Jay Mohta, Kenan Emir Ak, Dimitrios Dimitriadis, Yan Xu, Mingwei Shen</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.01831">https://arxiv.org/abs/2511.01831</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.01831">https://arxiv.org/pdf/2511.01831</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.01831]] Dynamic Routing Between Experts: A Data-Efficient Approach to Continual Learning in Vision-Language Models(https://arxiv.org/abs/2511.01831)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Vision-Language Models (VLMs) suffer from catastrophic forgetting when sequentially fine-tuned on new tasks, degrading performance on previously learned foundational and task-specific capabilities. While multi-task learning can mitigate forgetting, it requires simultaneous access to all datasets and imposes computational overhead that scales linearly with the number of tasks. In this work, we introduce a routing-based approach that enables the integration of new tasks while preserving the foundational knowledge acquired during pretraining. We evaluate our method using InternVL-2 models (2B and 8B parameters) and demonstrate that routing preserves the model's foundational capabilities by maintaining performance on general-purpose benchmarks such as ChartQA, MMBench, and DocVQA, while simultaneously improving accuracy on specialized tasks. Importantly, our approach achieves this without requiring concurrent access to data from all tasks, avoiding the significant computational and data overhead associated with traditional multi-task learning. We further conduct extensive ablation studies to evaluate the scalability and robustness of routing-based learning, showing that the approach is resilient to a growing number of tasks and performs particularly well when new tasks are semantically related. Finally, we show that the routing mechanism enables superior cross-modal transfer between language and vision capabilities, allowing knowledge learned in one modality to enhance performance in another capability not achieved by existing continual learning methods.</li>
</ul>

<h3>Title: TIR-Bench: A Comprehensive Benchmark for Agentic Thinking-with-Images Reasoning</h3>
<ul>
<li><strong>Authors: </strong>Ming Li, Jike Zhong, Shitian Zhao, Haoquan Zhang, Shaoheng Lin, Yuxiang Lai, Wei Chen, Konstantinos Psounis, Kaipeng Zhang</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.01833">https://arxiv.org/abs/2511.01833</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.01833">https://arxiv.org/pdf/2511.01833</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.01833]] TIR-Bench: A Comprehensive Benchmark for Agentic Thinking-with-Images Reasoning(https://arxiv.org/abs/2511.01833)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>The frontier of visual reasoning is shifting toward models like OpenAI o3, which can intelligently create and operate tools to transform images for problem-solving, also known as thinking-\textit{with}-images in chain-of-thought. Yet existing benchmarks fail to fully capture this advanced capability. Even Visual Search, the most common benchmark for current thinking-\textit{with}-images methods, tests only basic operations such as localization and cropping, offering little insight into more complex, dynamic, and tool-dependent reasoning. We introduce \textbf{TIR-Bench}, a comprehensive benchmark for evaluating agentic thinking-with-images across 13 diverse tasks, each requiring novel tool use for image processing and manipulation in chain-of-thought. We evaluate 22 multimodal large language models (MLLMs), from leading open-sourced and proprietary models to those with explicit tool-use augmentation. Results show that TIR-Bench is universally challenging, and strong performance requires genuine thinking-with-images capabilities. Finally, we present a pilot study comparing direct versus agentic fine-tuning.</li>
</ul>

<h3>Title: Priors in Time: Missing Inductive Biases for Language Model Interpretability</h3>
<ul>
<li><strong>Authors: </strong>Ekdeep Singh Lubana, Can Rager, Sai Sumedh R. Hindupur, Valerie Costa, Greta Tuckute, Oam Patel, Sonia Krishna Murthy, Thomas Fel, Daniel Wurgaft, Eric J. Bigelow, Johnny Lin, Demba Ba, Martin Wattenberg, Fernanda Viegas, Melanie Weber, Aaron Mueller</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.01836">https://arxiv.org/abs/2511.01836</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.01836">https://arxiv.org/pdf/2511.01836</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.01836]] Priors in Time: Missing Inductive Biases for Language Model Interpretability(https://arxiv.org/abs/2511.01836)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, extraction, interpretability</a></li>
<li><strong>Abstract: </strong>Recovering meaningful concepts from language model activations is a central aim of interpretability. While existing feature extraction methods aim to identify concepts that are independent directions, it is unclear if this assumption can capture the rich temporal structure of language. Specifically, via a Bayesian lens, we demonstrate that Sparse Autoencoders (SAEs) impose priors that assume independence of concepts across time, implying stationarity. Meanwhile, language model representations exhibit rich temporal dynamics, including systematic growth in conceptual dimensionality, context-dependent correlations, and pronounced non-stationarity, in direct conflict with the priors of SAEs. Taking inspiration from computational neuroscience, we introduce a new interpretability objective -- Temporal Feature Analysis -- which possesses a temporal inductive bias to decompose representations at a given time into two parts: a predictable component, which can be inferred from the context, and a residual component, which captures novel information unexplained by the context. Temporal Feature Analyzers correctly parse garden path sentences, identify event boundaries, and more broadly delineate abstract, slow-moving information from novel, fast-moving information, while existing SAEs show significant pitfalls in all the above tasks. Overall, our results underscore the need for inductive biases that match the data in designing robust interpretability tools.</li>
</ul>

<h3>Title: Interpretable Machine Learning for Reservoir Water Temperatures in the U.S. Red River Basin of the South</h3>
<ul>
<li><strong>Authors: </strong>Isabela Suaza-Sierra, Hernan A. Moreno, Luis A De la Fuente, Thomas M. Neeson</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.01837">https://arxiv.org/abs/2511.01837</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.01837">https://arxiv.org/pdf/2511.01837</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.01837]] Interpretable Machine Learning for Reservoir Water Temperatures in the U.S. Red River Basin of the South(https://arxiv.org/abs/2511.01837)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability</a></li>
<li><strong>Abstract: </strong>Accurate prediction of Reservoir Water Temperature (RWT) is vital for sustainable water management, ecosystem health, and climate resilience. Yet, prediction alone offers limited insight into the governing physical processes. To bridge this gap, we integrated explainable machine learning (ML) with symbolic modeling to uncover the drivers of RWT dynamics across ten reservoirs in the Red River Basin, USA, using over 10,000 depth-resolved temperature profiles. We first employed ensemble and neural models, including Random Forest (RF), Extreme Gradient Boosting (XGBoost), and Multilayer Perceptron (MLP), achieving high predictive skill (best RMSE = 1.20 degree Celsius, R^2 = 0.97). Using SHAP (SHapley Additive exPlanations), we quantified the contribution of physical drivers such as air temperature, depth, wind, and lake volume, revealing consistent patterns across reservoirs. To translate these data-driven insights into compact analytical expressions, we developed Kolmogorov Arnold Networks (KANs) to symbolically approximate RWT. Ten progressively complex KAN equations were derived, improving from R^2 = 0.84 using a single predictor (7-day antecedent air temperature) to R^2 = 0.92 with ten predictors, though gains diminished beyond five, highlighting a balance between simplicity and accuracy. The resulting equations, dominated by linear and rational forms, incrementally captured nonlinear behavior while preserving interpretability. Depth consistently emerged as a secondary but critical predictor, whereas precipitation had limited effect. By coupling predictive accuracy with explanatory power, this framework demonstrates how KANs and explainable ML can transform black-box models into transparent surrogates that advance both prediction and understanding of reservoir thermal dynamics.</li>
</ul>

<h3>Title: Towards Robust Mathematical Reasoning</h3>
<ul>
<li><strong>Authors: </strong>Thang Luong, Dawsen Hwang, Hoang H. Nguyen, Golnaz Ghiasi, Yuri Chervonyi, Insuk Seo, Junsu Kim, Garrett Bingham, Jonathan Lee, Swaroop Mishra, Alex Zhai, Clara Huiyi Hu, Henryk Michalewski, Jimin Kim, Jeonghyun Ahn, Junhwi Bae, Xingyou Song, Trieu H. Trinh, Quoc V. Le, Junehyuk Jung</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.01846">https://arxiv.org/abs/2511.01846</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.01846">https://arxiv.org/pdf/2511.01846</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.01846]] Towards Robust Mathematical Reasoning(https://arxiv.org/abs/2511.01846)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Finding the right north-star metrics is highly critical for advancing the mathematical reasoning capabilities of foundation models, especially given that existing evaluations are either too easy or only focus on getting correct short answers. To address these issues, we present IMO-Bench, a suite of advanced reasoning benchmarks, vetted by a panel of top specialists and that specifically targets the level of the International Mathematical Olympiad (IMO), the most prestigious venue for young mathematicians. IMO-AnswerBench first tests models on 400 diverse Olympiad problems with verifiable short answers. IMO-Proof Bench is the next-level evaluation for proof-writing capabilities, which includes both basic and advanced IMO level problems as well as detailed grading guidelines to facilitate automatic grading. These benchmarks played a crucial role in our historic achievement of the gold-level performance at IMO 2025 with Gemini Deep Think (Luong and Lockhart, 2025). Our model achieved 80.0% on IMO-AnswerBench and 65.7% on the advanced IMO-Proof Bench, surpassing the best non-Gemini models by large margins of 6.9% and 42.4% respectively. We also showed that autograders built with Gemini reasoning correlate well with human evaluations and construct IMO-GradingBench, with 1000 human gradings on proofs, to enable further progress in automatic evaluation of long-form answers. We hope that IMO-Bench will help the community towards advancing robust mathematical reasoning and release it at this https URL.</li>
</ul>

<button id="copy">Copy All</button>
</article>
<script src="../../javascript/clipboard.min.js"></script>
<script src="../../javascript/clipboard.js"></script>
