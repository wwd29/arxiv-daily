<link rel="stylesheet" href="../../css/markdown.css" />
<article class="markdown-body">
<h1>2025-08-26</h1>
<h3>Title: GreenTEA: Gradient Descent with Topic-modeling and Evolutionary Auto-prompting</h3>
<ul>
<li><strong>Authors: </strong>Zheng Dong, Luming Shang, Gabriela Olinto</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.16603">https://arxiv.org/abs/2508.16603</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.16603">https://arxiv.org/pdf/2508.16603</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.16603]] GreenTEA: Gradient Descent with Topic-modeling and Evolutionary Auto-prompting(https://arxiv.org/abs/2508.16603)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>High-quality prompts are crucial for Large Language Models (LLMs) to achieve exceptional performance. However, manually crafting effective prompts is labor-intensive and demands significant domain expertise, limiting its scalability. Existing automatic prompt optimization methods either extensively explore new prompt candidates, incurring high computational costs due to inefficient searches within a large solution space, or overly exploit feedback on existing prompts, risking suboptimal optimization because of the complex prompt landscape. To address these challenges, we introduce GreenTEA, an agentic LLM workflow for automatic prompt optimization that balances candidate exploration and knowledge exploitation. It leverages a collaborative team of agents to iteratively refine prompts based on feedback from error samples. An analyzing agent identifies common error patterns resulting from the current prompt via topic modeling, and a generation agent revises the prompt to directly address these key deficiencies. This refinement process is guided by a genetic algorithm framework, which simulates natural selection by evolving candidate prompts through operations such as crossover and mutation to progressively optimize model performance. Extensive numerical experiments conducted on public benchmark datasets suggest the superior performance of GreenTEA against human-engineered prompts and existing state-of-the-arts for automatic prompt optimization, covering logical and quantitative reasoning, commonsense, and ethical decision-making.</li>
</ul>

<h3>Title: Quantum-Inspired DRL Approach with LSTM and OU Noise for Cut Order Planning Optimization</h3>
<ul>
<li><strong>Authors: </strong>Yulison Herry Chrisnanto, Julian Evan Chrisnanto</a></li>
<li><strong>Subjects: </strong>cs.LG, math.OC</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.16611">https://arxiv.org/abs/2508.16611</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.16611">https://arxiv.org/pdf/2508.16611</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.16611]] Quantum-Inspired DRL Approach with LSTM and OU Noise for Cut Order Planning Optimization(https://arxiv.org/abs/2508.16611)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Cut order planning (COP) is a critical challenge in the textile industry, directly impacting fabric utilization and production costs. Conventional methods based on static heuristics and catalog-based estimations often struggle to adapt to dynamic production environments, resulting in suboptimal solutions and increased waste. In response, we propose a novel Quantum-Inspired Deep Reinforcement Learning (QI-DRL) framework that integrates Long Short-Term Memory (LSTM) networks with Ornstein-Uhlenbeck noise. This hybrid approach is designed to explicitly address key research questions regarding the benefits of quantum-inspired probabilistic representations, the role of LSTM-based memory in capturing sequential dependencies, and the effectiveness of OU noise in facilitating smooth exploration and faster convergence. Extensive training over 1000 episodes demonstrates robust performance, with an average reward of 0.81 (-+0.03) and a steady decrease in prediction loss to 0.15 (-+0.02). A comparative analysis reveals that the proposed approach achieves fabric cost savings of up to 13% compared to conventional methods. Furthermore, statistical evaluations indicate low variability and stable convergence. Despite the fact that the simulation model makes several simplifying assumptions, these promising results underscore the potential of the scalable and adaptive framework to enhance manufacturing efficiency and pave the way for future innovations in COP optimization.</li>
</ul>

<h3>Title: CrystalDiT: A Diffusion Transformer for Crystal Generation</h3>
<ul>
<li><strong>Authors: </strong>Xiaohan Yi, Guikun Xu, Xi Xiao, Zhong Zhang, Liu Liu, Yatao Bian, Peilin Zhao</a></li>
<li><strong>Subjects: </strong>cs.LG, cond-mat.mtrl-sci</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.16614">https://arxiv.org/abs/2508.16614</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.16614">https://arxiv.org/pdf/2508.16614</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.16614]] CrystalDiT: A Diffusion Transformer for Crystal Generation(https://arxiv.org/abs/2508.16614)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, transformer</a></li>
<li><strong>Abstract: </strong>We present CrystalDiT, a diffusion transformer for crystal structure generation that achieves state-of-the-art performance by challenging the trend of architectural complexity. Instead of intricate, multi-stream designs, CrystalDiT employs a unified transformer that imposes a powerful inductive bias: treating lattice and atomic properties as a single, interdependent system. Combined with a periodic table-based atomic representation and a balanced training strategy, our approach achieves 9.62% SUN (Stable, Unique, Novel) rate on MP-20, substantially outperforming recent methods including FlowMM (4.38%) and MatterGen (3.42%). Notably, CrystalDiT generates 63.28% unique and novel structures while maintaining comparable stability rates, demonstrating that architectural simplicity can be more effective than complexity for materials discovery. Our results suggest that in data-limited scientific domains, carefully designed simple architectures outperform sophisticated alternatives that are prone to overfitting.</li>
</ul>

<h3>Title: nodeWSNsec: A hybrid metaheuristic approach for reliable security and node deployment in WSNs</h3>
<ul>
<li><strong>Authors: </strong>Rahul Mishra, Sudhanshu Kumar Jha, Naresh Kshetri, Bishnu Bhusal, Mir Mehedi Rahman, Md Masud Rana, Aimina Ali Eli, Khaled Aminul Islam, Bishwo Prakash Pokharel</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.16619">https://arxiv.org/abs/2508.16619</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.16619">https://arxiv.org/pdf/2508.16619</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.16619]] nodeWSNsec: A hybrid metaheuristic approach for reliable security and node deployment in WSNs(https://arxiv.org/abs/2508.16619)</code><input type="text"></li>
<li><strong>Keywords: </strong>security</a></li>
<li><strong>Abstract: </strong>Efficient and reliable node deployment in Wireless Sensor Networks is crucial for optimizing coverage of the area, connectivity among nodes, and energy efficiency. This paper proposes a hybrid meta heuristic approach combining a Genetic Algorithm (GA) and Particle Swarm Optimization (PSO) to address the challenges of energy efficient and reliable node deployment. The GA PSO hybrid leverages GAs strong exploration capabilities and PSOs rapid convergence, achieving an optimum stability between coverage and energy consumption. The performance of the proposed approach is evaluated against GA and PSO alone and the innovatory meta heuristic based Competitive Multi Objective Marine Predators Algorithm (CMOMPA) across varying sensing ranges. Simulation results demonstrate that GA PSO requires 15% to 25% fewer sensor nodes and maintains 95% or more area coverage while maintaining the connectivity in comparison to standalone GA or PSO algorithm. The proposed algorithm also dominates CMOMPA when compared for long sensing and communication range in terms of higher coverage, improved connectivity, and reduced deployment time while requiring fewer sensor nodes. This study also explores key trade offs in WSN deployment and highlights future research directions, including heterogeneous node deployment, mobile WSNs, and enhanced multi objective optimization techniques. The findings underscore the effectiveness of hybrid meta heuristics in improving WSN performance, offering a promising approach for real world applications such as environmental monitoring, smart cities, smart agriculture, disaster response, and IIoT.</li>
</ul>

<h3>Title: Data and Context Matter: Towards Generalizing AI-based Software Vulnerability Detection</h3>
<ul>
<li><strong>Authors: </strong>Rijha Safdar, Danyail Mateen, Syed Taha Ali, M. Umer Ashfaq, Wajahat Hussain</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.AI, cs.SE</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.16625">https://arxiv.org/abs/2508.16625</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.16625">https://arxiv.org/pdf/2508.16625</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.16625]] Data and Context Matter: Towards Generalizing AI-based Software Vulnerability Detection(https://arxiv.org/abs/2508.16625)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>The performance of AI-based software vulnerability detection systems is often limited by their poor generalization to unknown codebases. In this research, we explore the impact of data quality and model architecture on the generalizability of vulnerability detection systems. By generalization we mean ability of high vulnerability detection performance across different C/C++ software projects not seen during training. Through a series of experiments, we demonstrate that improvements in dataset diversity and quality substantially enhance detection performance. Additionally, we compare multiple encoder-only and decoder-only models, finding that encoder based models outperform in terms of accuracy and generalization. Our model achieves 6.8% improvement in recall on the benchmark BigVul[1] dataset, also outperforming on unseen projects, hence showing enhanced generalizability. These results highlight the role of data quality and model selection in the development of robust vulnerability detection systems. Our findings suggest a direction for future systems having high cross-project effectiveness.</li>
</ul>

<h3>Title: Recurrent Transformer U-Net Surrogate for Flow Modeling and Data Assimilation in Subsurface Formations with Faults</h3>
<ul>
<li><strong>Authors: </strong>Yifu Han, Louis J. Durlofsky</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.16631">https://arxiv.org/abs/2508.16631</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.16631">https://arxiv.org/pdf/2508.16631</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.16631]] Recurrent Transformer U-Net Surrogate for Flow Modeling and Data Assimilation in Subsurface Formations with Faults(https://arxiv.org/abs/2508.16631)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Many subsurface formations, including some of those under consideration for large-scale geological carbon storage, include extensive faults that can strongly impact fluid flow. In this study, we develop a new recurrent transformer U-Net surrogate model to provide very fast predictions for pressure and CO2 saturation in realistic faulted subsurface aquifer systems. The geomodel includes a target aquifer (into which supercritical CO2 is injected), surrounding regions, caprock, two extensive faults, and two overlying aquifers. The faults can act as leakage pathways between the three aquifers. The heterogeneous property fields in the target aquifer are characterized by hierarchical uncertainty, meaning both the geological metaparameters (e.g., mean and standard deviation of log-permeability) and the detailed cell properties of each realization, are uncertain. Fault permeabilities are also treated as uncertain. The model is trained with simulation results for (up to) 4000 randomly sampled realizations. Error assessments show that this model is more accurate than a previous recurrent residual U-Net, and that it maintains accuracy for qualitatively different leakage scenarios. The new surrogate is then used for global sensitivity analysis and data assimilation. A hierarchical Markov chain Monte Carlo data assimilation procedure is applied. Different monitoring strategies, corresponding to different amounts and types of observed data collected at monitoring wells, are considered for three synthetic true models. Detailed results demonstrate the degree of uncertainty reduction achieved with the various monitoring strategies. Posterior results for 3D saturation plumes and leakage volumes indicate the benefits of measuring pressure and saturation in all three aquifers.</li>
</ul>

<h3>Title: Cognitive Decision Routing in Large Language Models: When to Think Fast, When to Think Slow</h3>
<ul>
<li><strong>Authors: </strong>Y. Du, C. Guo, W. Wang, G. Tang</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.16636">https://arxiv.org/abs/2508.16636</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.16636">https://arxiv.org/pdf/2508.16636</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.16636]] Cognitive Decision Routing in Large Language Models: When to Think Fast, When to Think Slow(https://arxiv.org/abs/2508.16636)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large Language Models (LLMs) face a fundamental challenge in deciding when to rely on rapid, intuitive responses versus engaging in slower, more deliberate reasoning. Inspired by Daniel Kahneman's dual-process theory and his insights on human cognitive biases, we propose a novel Cognitive Decision Routing (CDR) framework that dynamically determines the appropriate reasoning strategy based on query characteristics. Our approach addresses the current limitations where models either apply uniform reasoning depth or rely on computationally expensive methods for all queries. We introduce a meta-cognitive layer that analyzes query complexity through multiple dimensions: correlation strength between given information and required conclusions, domain boundary crossings, stakeholder multiplicity, and uncertainty levels. Through extensive experiments on diverse reasoning tasks, we demonstrate that CDR achieves superior performance while reducing computational costs by 34\% compared to uniform deep reasoning approaches. Our framework shows particular strength in professional judgment tasks, achieving 23\% improvement in consistency and 18\% better accuracy on expert-level evaluations. This work bridges cognitive science principles with practical AI system design, offering a principled approach to adaptive reasoning in LLMs.</li>
</ul>

<h3>Title: Passive Hack-Back Strategies for Cyber Attribution: Covert Vectors in Denied Environment</h3>
<ul>
<li><strong>Authors: </strong>Abraham Itzhak Weinberg</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.16637">https://arxiv.org/abs/2508.16637</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.16637">https://arxiv.org/pdf/2508.16637</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.16637]] Passive Hack-Back Strategies for Cyber Attribution: Covert Vectors in Denied Environment(https://arxiv.org/abs/2508.16637)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, attack, steal, large language model</a></li>
<li><strong>Abstract: </strong>Attributing cyberattacks remains a central challenge in modern cybersecurity, particularly within denied environments where defenders have limited visibility into attacker infrastructure and are restricted by legal or operational rules of engagement. This perspective examines the strategic value of passive hack-back techniques that enable covert attribution and intelligence collection without initiating direct offensive actions. Key vectors include tracking beacons, honeytokens, environment-specific payloads, and supply-chain-based traps embedded within exfiltrated or leaked assets. These approaches rely on the assumption that attackers will interact with compromised data in traceable ways, allowing defenders to gather signals without violating engagement policies. The paper also explores the role of Artificial Intelligence (AI) in enhancing passive hack-back operations. Topics include the deployment of autonomous agents for forensic reconnaissance, the use of Large Language Models (LLMs) to generate dynamic payloads, and Adversarial Machine Learning (AML) techniques for evasion and counter-deception. A dedicated section discusses the implications of quantum technologies in this context, both as future threats to cryptographic telemetry and as potential tools for stealthy communication and post-quantum resilience. Finally, the paper advocates for hybrid defensive frameworks that combine passive attribution with delayed or conditional active responses, while maintaining compliance with legal, ethical, and operational constraints.</li>
</ul>

<h3>Title: Enhancing Transformer-Based Foundation Models for Time Series Forecasting via Bagging, Boosting and Statistical Ensembles</h3>
<ul>
<li><strong>Authors: </strong>Dhruv D. Modi, Rong Pan</a></li>
<li><strong>Subjects: </strong>cs.LG, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.16641">https://arxiv.org/abs/2508.16641</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.16641">https://arxiv.org/pdf/2508.16641</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.16641]] Enhancing Transformer-Based Foundation Models for Time Series Forecasting via Bagging, Boosting and Statistical Ensembles(https://arxiv.org/abs/2508.16641)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, interpretability, transformer</a></li>
<li><strong>Abstract: </strong>Time series foundation models (TSFMs) such as Lag-Llama, TimeGPT, Chronos, MOMENT, UniTS, and TimesFM have shown strong generalization and zero-shot capabilities for time series forecasting, anomaly detection, classification, and imputation. Despite these advantages, their predictions still suffer from variance, domain-specific bias, and limited uncertainty quantification when deployed on real operational data. This paper investigates a suite of statistical and ensemble-based enhancement techniques, including bootstrap-based bagging, regression-based stacking, prediction interval construction, statistical residual modeling, and iterative error feedback, to improve robustness and accuracy. Using the Belgium Electricity Short-Term Load Forecasting dataset as a case study, we demonstrate that the proposed hybrids consistently outperform standalone foundation models across multiple horizons. Regression-based ensembles achieve the lowest mean squared error; bootstrap aggregation markedly reduces long-context errors; residual modeling corrects systematic bias; and the resulting prediction intervals achieve near nominal coverage with widths shrinking as context length increases. The results indicate that integrating statistical reasoning with modern foundation models yields measurable gains in accuracy, reliability, and interpretability for real-world time series applications.</li>
</ul>

<h3>Title: From Classical Probabilistic Latent Variable Models to Modern Generative AI: A Unified Perspective</h3>
<ul>
<li><strong>Authors: </strong>Tianhua Chen</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.16643">https://arxiv.org/abs/2508.16643</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.16643">https://arxiv.org/pdf/2508.16643</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.16643]] From Classical Probabilistic Latent Variable Models to Modern Generative AI: A Unified Perspective(https://arxiv.org/abs/2508.16643)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, generative, large language model</a></li>
<li><strong>Abstract: </strong>From large language models to multi-modal agents, Generative Artificial Intelligence (AI) now underpins state-of-the-art systems. Despite their varied architectures, many share a common foundation in probabilistic latent variable models (PLVMs), where hidden variables explain observed data for density estimation, latent reasoning, and structured inference. This paper presents a unified perspective by framing both classical and modern generative methods within the PLVM paradigm. We trace the progression from classical flat models such as probabilistic PCA, Gaussian mixture models, latent class analysis, item response theory, and latent Dirichlet allocation, through their sequential extensions including Hidden Markov Models, Gaussian HMMs, and Linear Dynamical Systems, to contemporary deep architectures: Variational Autoencoders as Deep PLVMs, Normalizing Flows as Tractable PLVMs, Diffusion Models as Sequential PLVMs, Autoregressive Models as Explicit Generative Models, and Generative Adversarial Networks as Implicit PLVMs. Viewing these architectures under a common probabilistic taxonomy reveals shared principles, distinct inference strategies, and the representational trade-offs that shape their strengths. We offer a conceptual roadmap that consolidates generative AI's theoretical foundations, clarifies methodological lineages, and guides future innovation by grounding emerging architectures in their probabilistic heritage.</li>
</ul>

<h3>Title: CountLoop: Training-Free High-Instance Image Generation via Iterative Agent Guidance</h3>
<ul>
<li><strong>Authors: </strong>Anindya Mondal, Ayan Banerjee, Sauradip Nag, Josep Llad√≥s, Xiatian Zhu, Anjan Dutta</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.16644">https://arxiv.org/abs/2508.16644</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.16644">https://arxiv.org/pdf/2508.16644</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.16644]] CountLoop: Training-Free High-Instance Image Generation via Iterative Agent Guidance(https://arxiv.org/abs/2508.16644)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>Diffusion models have shown remarkable progress in photorealistic image synthesis, yet they remain unreliable for generating scenes with a precise number of object instances, particularly in complex and high-density settings. We present CountLoop, a training-free framework that provides diffusion models with accurate instance control through iterative structured feedback. The approach alternates between image generation and multimodal agent evaluation, where a language-guided planner and critic assess object counts, spatial arrangements, and attribute consistency. This feedback is then used to refine layouts and guide subsequent generations. To further improve separation between objects, especially in occluded scenes, we introduce instance-driven attention masking and compositional generation techniques. Experiments on COCO Count, T2I CompBench, and two new high-instance benchmarks show that CountLoop achieves counting accuracy of up to 98% while maintaining spatial fidelity and visual quality, outperforming layout-based and gradient-guided baselines with a score of 0.97.</li>
</ul>

<h3>Title: AdapSNE: Adaptive Fireworks-Optimized and Entropy-Guided Dataset Sampling for Edge DNN Training</h3>
<ul>
<li><strong>Authors: </strong>Boran Zhao, Hetian Liu, Zihang Yuan, Li Zhu, Fan Yang, Lina Xie Tian Xia, Wenzhe Zhao, Pengju Ren</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.16647">https://arxiv.org/abs/2508.16647</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.16647">https://arxiv.org/pdf/2508.16647</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.16647]] AdapSNE: Adaptive Fireworks-Optimized and Entropy-Guided Dataset Sampling for Edge DNN Training(https://arxiv.org/abs/2508.16647)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, large language model</a></li>
<li><strong>Abstract: </strong>Training deep neural networks (DNNs) directly on edge devices has attracted increasing attention, as it offers promising solutions to challenges such as domain adaptation and privacy preservation. However, conventional DNN training typically requires large-scale datasets, which imposes prohibitive overhead on edge devices-particularly for emerging large language model (LLM) tasks. To address this challenge, a DNN-free method (ie., dataset sampling without DNN), named NMS (Near-Memory Sampling), has been introduced. By first conducting dimensionality reduction of the dataset and then performing exemplar sampling in the reduced space, NMS avoids the architectural bias inherent in DNN-based methods and thus achieves better generalization. However, The state-of-the-art, NMS, suffers from two limitations: (1) The mismatch between the search method and the non-monotonic property of the perplexity error function leads to the emergence of outliers in the reduced representation; (2) Key parameter (ie., target perplexity) is selected empirically, introducing arbitrariness and leading to uneven sampling. These two issues lead to representative bias of examplars, resulting in degraded accuracy. To address these issues, we propose AdapSNE, which integrates an efficient non-monotonic search method-namely, the Fireworks Algorithm (FWA)-to suppress outliers, and employs entropy-guided optimization to enforce uniform sampling, thereby ensuring representative training samples and consequently boosting training accuracy. To cut the edge-side cost arising from the iterative computations of FWA search and entropy-guided optimization, we design an accelerator with custom dataflow and time-multiplexing markedly reducing on-device training energy and area.</li>
</ul>

<h3>Title: LatentFlow: Cross-Frequency Experimental Flow Reconstruction from Sparse Pressure via Latent Mapping</h3>
<ul>
<li><strong>Authors: </strong>Junle Liu, Chang Liu, Yanyu Ke, Qiuxiang Huang, Jiachen Zhao, Wenliang Chen, K.T. Tse, Gang Hu</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, physics.flu-dyn</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.16648">https://arxiv.org/abs/2508.16648</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.16648">https://arxiv.org/pdf/2508.16648</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.16648]] LatentFlow: Cross-Frequency Experimental Flow Reconstruction from Sparse Pressure via Latent Mapping(https://arxiv.org/abs/2508.16648)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Acquiring temporally high-frequency and spatially high-resolution turbulent wake flow fields in particle image velocimetry (PIV) experiments remains a significant challenge due to hardware limitations and measurement noise. In contrast, temporal high-frequency measurements of spatially sparse wall pressure are more readily accessible in wind tunnel experiments. In this study, we propose a novel cross-modal temporal upscaling framework, LatentFlow, which reconstructs high-frequency (512 Hz) turbulent wake flow fields by fusing synchronized low-frequency (15 Hz) flow field and pressure data during training, and high-frequency wall pressure signals during inference. The first stage involves training a pressure-conditioned $\beta$-variation autoencoder ($p$C-$\beta$-VAE) to learn a compact latent representation that captures the intrinsic dynamics of the wake flow. A secondary network maps synchronized low-frequency wall pressure signals into the latent space, enabling reconstruction of the wake flow field solely from sparse wall pressure. Once trained, the model utilizes high-frequency, spatially sparse wall pressure inputs to generate corresponding high-frequency flow fields via the $p$C-$\beta$-VAE decoder. By decoupling the spatial encoding of flow dynamics from temporal pressure measurements, LatentFlow provides a scalable and robust solution for reconstructing high-frequency turbulent wake flows in data-constrained experimental settings.</li>
</ul>

<h3>Title: Do VLMs Have Bad Eyes? Diagnosing Compositional Failures via Mechanistic Interpretability</h3>
<ul>
<li><strong>Authors: </strong>Ashwath Vaithinathan Aravindan, Abha Jha, Mihir Kulkarni</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.16652">https://arxiv.org/abs/2508.16652</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.16652">https://arxiv.org/pdf/2508.16652</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.16652]] Do VLMs Have Bad Eyes? Diagnosing Compositional Failures via Mechanistic Interpretability(https://arxiv.org/abs/2508.16652)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability</a></li>
<li><strong>Abstract: </strong>Vision-Language Models (VLMs) have shown remarkable performance in integrating visual and textual information for tasks such as image captioning and visual question answering. However, these models struggle with compositional generalization and object binding, which limit their ability to handle novel combinations of objects and their attributes. Our work explores the root causes of these failures using mechanistic interpretability techniques. We show evidence that individual neurons in the MLP layers of CLIP's vision encoder represent multiple features, and this "superposition" directly hinders its compositional feature representation which consequently affects compositional reasoning and object binding capabilities. We hope this study will serve as an initial step toward uncovering the mechanistic roots of compositional failures in VLMs. The code and supporting results can be found this https URL .</li>
</ul>

<h3>Title: MSNav: Zero-Shot Vision-and-Language Navigation with Dynamic Memory and LLM Spatial Reasoning</h3>
<ul>
<li><strong>Authors: </strong>Chenghao Liu, Zhimu Zhou, Jiachen Zhang, Minghao Zhang, Songfang Huang, Huiling Duan</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.16654">https://arxiv.org/abs/2508.16654</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.16654">https://arxiv.org/pdf/2508.16654</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.16654]] MSNav: Zero-Shot Vision-and-Language Navigation with Dynamic Memory and LLM Spatial Reasoning(https://arxiv.org/abs/2508.16654)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, extraction, large language model</a></li>
<li><strong>Abstract: </strong>Vision-and-Language Navigation (VLN) requires an agent to interpret natural language instructions and navigate complex environments. Current approaches often adopt a "black-box" paradigm, where a single Large Language Model (LLM) makes end-to-end decisions. However, it is plagued by critical vulnerabilities, including poor spatial reasoning, weak cross-modal grounding, and memory overload in long-horizon tasks. To systematically address these issues, we propose Memory Spatial Navigation(MSNav), a framework that fuses three modules into a synergistic architecture, which transforms fragile inference into a robust, integrated intelligence. MSNav integrates three modules: Memory Module, a dynamic map memory module that tackles memory overload through selective node pruning, enhancing long-range exploration; Spatial Module, a module for spatial reasoning and object relationship inference that improves endpoint recognition; and Decision Module, a module using LLM-based path planning to execute robust actions. Powering Spatial Module, we also introduce an Instruction-Object-Space (I-O-S) dataset and fine-tune the Qwen3-4B model into Qwen-Spatial (Qwen-Sp), which outperforms leading commercial LLMs in object list extraction, achieving higher F1 and NDCG scores on the I-O-S test set. Extensive experiments on the Room-to-Room (R2R) and REVERIE datasets demonstrate MSNav's state-of-the-art performance with significant improvements in Success Rate (SR) and Success weighted by Path Length (SPL).</li>
</ul>

<h3>Title: A Laplace diffusion-based transformer model for heart rate forecasting within daily activity context</h3>
<ul>
<li><strong>Authors: </strong>Andrei Mateescu, Ioana Hadarau, Ionut Anghel, Tudor Cioara, Ovidiu Anchidin, Ancuta Nemes</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.16655">https://arxiv.org/abs/2508.16655</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.16655">https://arxiv.org/pdf/2508.16655</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.16655]] A Laplace diffusion-based transformer model for heart rate forecasting within daily activity context(https://arxiv.org/abs/2508.16655)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, transformer</a></li>
<li><strong>Abstract: </strong>With the advent of wearable Internet of Things (IoT) devices, remote patient monitoring (RPM) emerged as a promising solution for managing heart failure. However, the heart rate can fluctuate significantly due to various factors, and without correlating it to the patient's actual physical activity, it becomes difficult to assess whether changes are significant. Although Artificial Intelligence (AI) models may enhance the accuracy and contextual understanding of remote heart rate monitoring, the integration of activity data is still rarely addressed. In this paper, we propose a Transformer model combined with a Laplace diffusion technique to model heart rate fluctuations driven by physical activity of the patient. Unlike prior models that treat activity as secondary, our approach conditions the entire modeling process on activity context using specialized embeddings and attention mechanisms to prioritize activity specific historical patents. The model captures both long-term patterns and activity-specific heart rate dynamics by incorporating contextualized embeddings and dedicated encoder. The Transformer model was validated on a real-world dataset collected from 29 patients over a 4-month period. Experimental results show that our model outperforms current state-of-the-art methods, achieving a 43% reduction in mean absolute error compared to the considered baseline models. Moreover, the coefficient of determination R2 is 0.97 indicating the model predicted heart rate is in strong agreement with actual heart rate values. These findings suggest that the proposed model is a practical and effective tool for supporting both healthcare providers and remote patient monitoring systems.</li>
</ul>

<h3>Title: OASIS: Open-world Adaptive Self-supervised and Imbalanced-aware System</h3>
<ul>
<li><strong>Authors: </strong>Miru Kim, Mugon Joe, Minhae Kwon</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.16656">https://arxiv.org/abs/2508.16656</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.16656">https://arxiv.org/pdf/2508.16656</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.16656]] OASIS: Open-world Adaptive Self-supervised and Imbalanced-aware System(https://arxiv.org/abs/2508.16656)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>The expansion of machine learning into dynamic environments presents challenges in handling open-world problems where label shift, covariate shift, and unknown classes emerge. Post-training methods have been explored to address these challenges, adapting models to newly emerging data. However, these methods struggle when the initial pre-training is performed on class-imbalanced datasets, limiting generalization to minority classes. To address this, we propose a method that effectively handles open-world problems even when pre-training is conducted on imbalanced data. Our contrastive-based pre-training approach enhances classification performance, particularly for underrepresented classes. Our post-training mechanism generates reliable pseudo-labels, improving model robustness against open-world problems. We also introduce selective activation criteria to optimize the post-training process, reducing unnecessary computation. Extensive experiments demonstrate that our method significantly outperforms state-of-the-art adaptation techniques in both accuracy and efficiency across diverse open-world scenarios.</li>
</ul>

<h3>Title: Bridging the Mobile Trust Gap: A Zero Trust Framework for Consumer-Facing Applications</h3>
<ul>
<li><strong>Authors: </strong>Alexander Tabalipa</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.CY, cs.NI, cs.SE</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.16662">https://arxiv.org/abs/2508.16662</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.16662">https://arxiv.org/pdf/2508.16662</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.16662]] Bridging the Mobile Trust Gap: A Zero Trust Framework for Consumer-Facing Applications(https://arxiv.org/abs/2508.16662)</code><input type="text"></li>
<li><strong>Keywords: </strong>secure, security, protect</a></li>
<li><strong>Abstract: </strong>Zero Trust Architecture (ZTA) has become a widely adopted model for securing enterprise environments, promoting continuous verification and minimal trust across systems. However, its application in mobile contexts remains limited, despite mobile applications now accounting for most global digital interactions and being increasingly targeted by sophisticated threats. Existing Zero Trust frameworks developed by organisations such as the National Institute of Standards and Technology (NIST) and the Cybersecurity and Infrastructure Security Agency (CISA) primarily focus on enterprise-managed infrastructure, assuming organisational control over devices, networks, and identities. This paper addresses a critical gap by proposing an extended Zero Trust model designed for mobile applications operating in untrusted, user-controlled environments. Using a design science methodology, the study introduced a six-pillar framework that supports runtime enforcement of trust through controls including device integrity, user identity validation, data protection, secure application programming interface (API) usage, behavioural monitoring, and live application protection. Each pillar was mapped to relevant regulatory and security standards to support compliance. A phased implementation roadmap and maturity assessment model were also developed to guide adoption across varying organisational contexts. The proposed model offers a practical and standards-aligned approach to securing mobile applications beyond pre-deployment controls, aligning real-time enforcement with Zero Trust principles. This contribution expands the operational boundaries of ZTA and provides organisations with a deployable path to reduce fraud, enhance compliance, and address emerging mobile security challenges. Future research may include empirical validation of the framework and cross-sector application testing.</li>
</ul>

<h3>Title: The Loupe: A Plug-and-Play Attention Module for Amplifying Discriminative Features in Vision Transformers</h3>
<ul>
<li><strong>Authors: </strong>Naren Sengodan</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.16663">https://arxiv.org/abs/2508.16663</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.16663">https://arxiv.org/pdf/2508.16663</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.16663]] The Loupe: A Plug-and-Play Attention Module for Amplifying Discriminative Features in Vision Transformers(https://arxiv.org/abs/2508.16663)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability, transformer</a></li>
<li><strong>Abstract: </strong>Fine-Grained Visual Classification (FGVC) is a critical and challenging area within computer vision, demanding the identification of highly subtle, localized visual cues. The importance of FGVC extends to critical applications such as biodiversity monitoring and medical diagnostics, where precision is paramount. While large-scale Vision Transformers have achieved state-of-the-art performance, their decision-making processes often lack the interpretability required for trust and verification in such domains. In this paper, we introduce The Loupe, a novel, lightweight, and plug-and-play attention module designed to be inserted into pre-trained backbones like the Swin Transformer. The Loupe is trained end-to-end with a composite loss function that implicitly guides the model to focus on the most discriminative object parts without requiring explicit part-level annotations. Our unique contribution lies in demonstrating that a simple, intrinsic attention mechanism can act as a powerful regularizer, significantly boosting performance while simultaneously providing clear visual explanations. Our experimental evaluation on the challenging CUB-200-2011 dataset shows that The Loupe improves the accuracy of a Swin-Base model from 85.40% to 88.06%, a significant gain of 2.66%. Crucially, our qualitative analysis of the learned attention maps reveals that The Loupe effectively localizes semantically meaningful features, providing a valuable tool for understanding and trusting the model's decision-making process.</li>
</ul>

<h3>Title: Trust but Verify! A Survey on Verification Design for Test-time Scaling</h3>
<ul>
<li><strong>Authors: </strong>V Venktesh, Mandeep rathee, Avishek Anand</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.16665">https://arxiv.org/abs/2508.16665</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.16665">https://arxiv.org/pdf/2508.16665</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.16665]] Trust but Verify! A Survey on Verification Design for Test-time Scaling(https://arxiv.org/abs/2508.16665)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative, large language model</a></li>
<li><strong>Abstract: </strong>Test-time scaling (TTS) has emerged as a new frontier for scaling the performance of Large Language Models. In test-time scaling, by using more computational resources during inference, LLMs can improve their reasoning process and task performance. Several approaches have emerged for TTS such as distilling reasoning traces from another model or exploring the vast decoding search space by employing a verifier. The verifiers serve as reward models that help score the candidate outputs from the decoding process to diligently explore the vast solution space and select the best outcome. This paradigm commonly termed has emerged as a superior approach owing to parameter free scaling at inference time and high performance gains. The verifiers could be prompt-based, fine-tuned as a discriminative or generative model to verify process paths, outcomes or both. Despite their widespread adoption, there is no detailed collection, clear categorization and discussion of diverse verification approaches and their training mechanisms. In this survey, we cover the diverse approaches in the literature and present a unified view of verifier training, types and their utility in test-time scaling. Our repository can be found at this https URL.</li>
</ul>

<h3>Title: MedRepBench: A Comprehensive Benchmark for Medical Report Interpretation</h3>
<ul>
<li><strong>Authors: </strong>Fangxin Shang, Yuan Xia, Dalu Yang, Yahui Wang, Binglin Yang</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.16674">https://arxiv.org/abs/2508.16674</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.16674">https://arxiv.org/pdf/2508.16674</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.16674]] MedRepBench: A Comprehensive Benchmark for Medical Report Interpretation(https://arxiv.org/abs/2508.16674)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, interpretability, large language model</a></li>
<li><strong>Abstract: </strong>Medical report interpretation plays a crucial role in healthcare, enabling both patient-facing explanations and effective information flow across clinical systems. While recent vision-language models (VLMs) and large language models (LLMs) have demonstrated general document understanding capabilities, there remains a lack of standardized benchmarks to assess structured interpretation quality in medical reports. We introduce MedRepBench, a comprehensive benchmark built from 1,900 de-identified real-world Chinese medical reports spanning diverse departments, patient demographics, and acquisition formats. The benchmark is designed primarily to evaluate end-to-end VLMs for structured medical report understanding. To enable controlled comparisons, we also include a text-only evaluation setting using high-quality OCR outputs combined with LLMs, allowing us to estimate the upper-bound performance when character recognition errors are minimized. Our evaluation framework supports two complementary protocols: (1) an objective evaluation measuring field-level recall of structured clinical items, and (2) an automated subjective evaluation using a powerful LLM as a scoring agent to assess factuality, interpretability, and reasoning quality. Based on the objective metric, we further design a reward function and apply Group Relative Policy Optimization (GRPO) to improve a mid-scale VLM, achieving up to 6% recall gain. We also observe that the OCR+LLM pipeline, despite strong performance, suffers from layout-blindness and latency issues, motivating further progress toward robust, fully vision-based report understanding.</li>
</ul>

<h3>Title: WISCA: A Lightweight Model Transition Method to Improve LLM Training via Weight Scaling</h3>
<ul>
<li><strong>Authors: </strong>Jiacheng Li, Jianchao Tan, Zhidong Yang, Pingwei Sun, Feiye Huo, Jiayu Qin, Yerui Sun, Yuchen Xie, Xunliang Cai, Xiangyu Zhang, Maoxin He, Guangming Tan, Weile Jia, Tong Zhao</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.16676">https://arxiv.org/abs/2508.16676</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.16676">https://arxiv.org/pdf/2508.16676</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.16676]] WISCA: A Lightweight Model Transition Method to Improve LLM Training via Weight Scaling(https://arxiv.org/abs/2508.16676)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer, large language model</a></li>
<li><strong>Abstract: </strong>Transformer architecture gradually dominates the LLM field. Recent advances in training optimization for Transformer-based large language models (LLMs) primarily focus on architectural modifications or optimizer adjustments. However, these approaches lack systematic optimization of weight patterns during training. Weight pattern refers to the distribution and relative magnitudes of weight parameters in a neural network. To address this issue, we propose a Weight Scaling method called WISCA to enhance training efficiency and model quality by strategically improving neural network weight patterns without changing network structures. By rescaling weights while preserving model outputs, WISCA indirectly optimizes the model's training trajectory. Experiments demonstrate that WISCA significantly improves convergence quality (measured by generalization capability and loss reduction), particularly in LLMs with Grouped Query Attention (GQA) architectures and LoRA fine-tuning tasks. Empirical results show 5.6% average improvement on zero-shot validation tasks and 2.12% average reduction in training perplexity across multiple architectures.</li>
</ul>

<h3>Title: Recall-Extend Dynamics: Enhancing Small Language Models through Controlled Exploration and Refined Offline Integration</h3>
<ul>
<li><strong>Authors: </strong>Zhong Guan, Likang Wu, Hongke Zhao, Jiahui Wang, Le Wu</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.16677">https://arxiv.org/abs/2508.16677</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.16677">https://arxiv.org/pdf/2508.16677</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.16677]] Recall-Extend Dynamics: Enhancing Small Language Models through Controlled Exploration and Refined Offline Integration(https://arxiv.org/abs/2508.16677)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Many existing studies have achieved significant improvements in the reasoning capabilities of large language models (LLMs) through reinforcement learning with verifiable rewards (RLVR), while the enhancement of reasoning abilities in small language models (SLMs) has not yet been sufficiently explored. Combining distilled data from larger models with RLVR on small models themselves is a natural approach, but it still faces various challenges and issues. Therefore, we propose \textit{\underline{R}}ecall-\textit{\underline{E}}xtend \textit{\underline{D}}ynamics(RED): Enhancing Small Language Models through Controlled Exploration and Refined Offline Integration. In this paper, we explore the perspective of varying exploration spaces, balancing offline distillation with online reinforcement learning. Simultaneously, we specifically design and optimize for the insertion problem within offline data. By monitoring the ratio of entropy changes in the model concerning offline and online data, we regulate the weight of offline-SFT, thereby addressing the issues of insufficient exploration space in small models and the redundancy and complexity during the distillation process. Furthermore, to tackle the distribution discrepancies between offline data and the current policy, we design a sample-accuracy-based policy shift mechanism that dynamically chooses between imitating offline distilled data and learning from its own policy.</li>
</ul>

<h3>Title: CALR: Corrective Adaptive Low-Rank Decomposition for Efficient Large Language Model Layer Compression</h3>
<ul>
<li><strong>Authors: </strong>Muchammad Daniyal Kautsar, Afra Majida Hariono, Widyawan, Syukron Abu Ishaq Alfarozi, Kuntpong Wararatpanya</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.16680">https://arxiv.org/abs/2508.16680</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.16680">https://arxiv.org/pdf/2508.16680</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.16680]] CALR: Corrective Adaptive Low-Rank Decomposition for Efficient Large Language Model Layer Compression(https://arxiv.org/abs/2508.16680)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large Language Models (LLMs) present significant deployment challenges due to their immense size and computational requirements. Model compression techniques are essential for making these models practical for resource-constrained environments. A prominent compression strategy is low-rank factorization via Singular Value Decomposition (SVD) to reduce model parameters by approximating weight matrices. However, standard SVD focuses on minimizing matrix reconstruction error, often leading to a substantial loss of the model's functional performance. This performance degradation occurs because existing methods do not adequately correct for the functional information lost during compression. To address this gap, we introduce Corrective Adaptive Low-Rank Decomposition (CALR), a two-component compression approach. CALR combines a primary path of SVD-compressed layers with a parallel, learnable, low-rank corrective module that is explicitly trained to recover the functional residual error. Our experimental evaluation on SmolLM2-135M, Qwen3-0.6B, and Llama-3.2-1B, demonstrates that CALR can reduce parameter counts by 26.93% to 51.77% while retaining 59.45% to 90.42% of the original model's performance, consistently outperforming LaCo, ShortGPT, and LoSparse. CALR's success shows that treating functional information loss as a learnable signal is a highly effective compression paradigm. This approach enables the creation of significantly smaller, more efficient LLMs, advancing their accessibility and practical deployment in real-world applications.</li>
</ul>

<h3>Title: Do Cognitively Interpretable Reasoning Traces Improve LLM Performance?</h3>
<ul>
<li><strong>Authors: </strong>Siddhant Bhambri, Upasana Biswas, Subbarao Kambhampati</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.16695">https://arxiv.org/abs/2508.16695</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.16695">https://arxiv.org/pdf/2508.16695</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.16695]] Do Cognitively Interpretable Reasoning Traces Improve LLM Performance?(https://arxiv.org/abs/2508.16695)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability, large language model</a></li>
<li><strong>Abstract: </strong>Recent progress in reasoning-oriented Large Language Models (LLMs) has been driven by introducing Chain-of-Thought (CoT) traces, where models generate intermediate reasoning traces before producing an answer. These traces, as in DeepSeek R1, are not only used to guide inference but also serve as supervision signals for distillation into smaller models. A common but often implicit assumption is that CoT traces should be semantically meaningful and interpretable to the end user. While recent research questions the need for semantic nature of these traces, in this paper, we ask: ``\textit{Must CoT reasoning traces be interpretable to enhance LLM task performance?}" We investigate this question in the Open Book Question-Answering domain by supervised fine-tuning LLaMA and Qwen models on four types of reasoning traces: (1) DeepSeek R1 traces, (2) LLM-generated summaries of R1 traces, (3) LLM-generated post-hoc explanations of R1 traces, and (4) algorithmically generated verifiably correct traces. To quantify the trade-off between interpretability and performance, we further conduct a human-subject study with 100 participants rating the interpretability of each trace type. Our results reveal a striking mismatch: while fine-tuning on R1 traces yields the strongest performance, participants judged these traces to be the least interpretable. These findings suggest that it is useful to decouple intermediate tokens from end user interpretability.</li>
</ul>

<h3>Title: QueryBandits for Hallucination Mitigation: Exploiting Semantic Features for No-Regret Rewriting</h3>
<ul>
<li><strong>Authors: </strong>Nicole Cho, William Watson, Alec Koppel, Sumitra Ganesh, Manuela Veloso</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.16697">https://arxiv.org/abs/2508.16697</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.16697">https://arxiv.org/pdf/2508.16697</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.16697]] QueryBandits for Hallucination Mitigation: Exploiting Semantic Features for No-Regret Rewriting(https://arxiv.org/abs/2508.16697)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Advanced reasoning capabilities in Large Language Models (LLMs) have caused higher hallucination prevalence; yet most mitigation work focuses on after-the-fact filtering rather than shaping the queries that trigger them. We introduce QueryBandits, a bandit framework that designs rewrite strategies to maximize a reward model, that encapsulates hallucination propensity based upon the sensitivities of 17 linguistic features of the input query-and therefore, proactively steer LLMs away from generating hallucinations. Across 13 diverse QA benchmarks and 1,050 lexically perturbed queries per dataset, our top contextual QueryBandit (Thompson Sampling) achieves an 87.5% win rate over a no-rewrite baseline and also outperforms zero-shot static prompting ("paraphrase" or "expand") by 42.6% and 60.3% respectively. Therefore, we empirically substantiate the effectiveness of QueryBandits in mitigating hallucination via the intervention that takes the form of a query rewrite. Interestingly, certain static prompting strategies, which constitute a considerable number of current query rewriting literature, have a higher cumulative regret than the no-rewrite baseline, signifying that static rewrites can worsen hallucination. Moreover, we discover that the converged per-arm regression feature weight vectors substantiate that there is no single rewrite strategy optimal for all queries. In this context, guided rewriting via exploiting semantic features with QueryBandits can induce significant shifts in output behavior through forward-pass mechanisms, bypassing the need for retraining or gradient-based adaptation.</li>
</ul>

<h3>Title: Assessing Consciousness-Related Behaviors in Large Language Models Using the Maze Test</h3>
<ul>
<li><strong>Authors: </strong>Rui A. Pimenta, Tim Schlippe, Kristina Schaaff</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.16705">https://arxiv.org/abs/2508.16705</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.16705">https://arxiv.org/pdf/2508.16705</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.16705]] Assessing Consciousness-Related Behaviors in Large Language Models Using the Maze Test(https://arxiv.org/abs/2508.16705)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>We investigate consciousness-like behaviors in Large Language Models (LLMs) using the Maze Test, challenging models to navigate mazes from a first-person perspective. This test simultaneously probes spatial awareness, perspective-taking, goal-directed behavior, and temporal sequencing-key consciousness-associated characteristics. After synthesizing consciousness theories into 13 essential characteristics, we evaluated 12 leading LLMs across zero-shot, one-shot, and few-shot learning scenarios. Results showed reasoning-capable LLMs consistently outperforming standard versions, with Gemini 2.0 Pro achieving 52.9% Complete Path Accuracy and DeepSeek-R1 reaching 80.5% Partial Path Accuracy. The gap between these metrics indicates LLMs struggle to maintain coherent self-models throughout solutions -- a fundamental consciousness aspect. While LLMs show progress in consciousness-related behaviors through reasoning mechanisms, they lack the integrated, persistent self-awareness characteristic of consciousness.</li>
</ul>

<h3>Title: Sparse and Dense Retrievers Learn Better Together: Joint Sparse-Dense Optimization for Text-Image Retrieval</h3>
<ul>
<li><strong>Authors: </strong>Jonghyun Song, Youngjune Lee, Gyu-Hwung Cho, Ilhyeon Song, Saehun Kim, Yohan Jo</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.IR, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.16707">https://arxiv.org/abs/2508.16707</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.16707">https://arxiv.org/pdf/2508.16707</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.16707]] Sparse and Dense Retrievers Learn Better Together: Joint Sparse-Dense Optimization for Text-Image Retrieval(https://arxiv.org/abs/2508.16707)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability</a></li>
<li><strong>Abstract: </strong>Vision-Language Pretrained (VLP) models have achieved impressive performance on multimodal tasks, including text-image retrieval, based on dense representations. Meanwhile, Learned Sparse Retrieval (LSR) has gained traction in text-only settings due to its interpretability and efficiency with fast term-based lookup via inverted indexes. Inspired by these advantages, recent work has extended LSR to the multimodal domain. However, these methods often rely on computationally expensive contrastive pre-training, or distillation from a frozen dense model, which limits the potential for mutual enhancement. To address these limitations, we propose a simple yet effective framework that enables bi-directional learning between dense and sparse representations through Self-Knowledge Distillation. This bi-directional learning is achieved using an integrated similarity score-a weighted sum of dense and sparse similarities-which serves as a shared teacher signal for both representations. To ensure efficiency, we fine-tune the final layer of the dense encoder and the sparse projection head, enabling easy adaptation of any existing VLP model. Experiments on MSCOCO and Flickr30k demonstrate that our sparse retriever not only outperforms existing sparse baselines, but also achieves performance comparable to-or even surpassing-its dense counterparts, while retaining the benefits of sparse models.</li>
</ul>

<h3>Title: Error Reflection Prompting: Can Large Language Models Successfully Understand Errors?</h3>
<ul>
<li><strong>Authors: </strong>Jason Li, Lauren Yraola, Kevin Zhu, Sean O'Brien</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.16729">https://arxiv.org/abs/2508.16729</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.16729">https://arxiv.org/pdf/2508.16729</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.16729]] Error Reflection Prompting: Can Large Language Models Successfully Understand Errors?(https://arxiv.org/abs/2508.16729)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, interpretability, large language model</a></li>
<li><strong>Abstract: </strong>Prompting methods for language models, such as Chain-of-thought (CoT), present intuitive step-by-step processes for problem solving. These methodologies aim to equip models with a better understanding of the correct procedures for addressing a given task. Despite these advancements, CoT lacks the ability of reflection and error correction, potentially causing a model to perpetuate mistakes and errors. Therefore, inspired by the human ability for said tasks, we propose Error Reflection Prompting (ERP) to further enhance reasoning in language models. Building upon CoT, ERP is a method comprised of an incorrect answer, error recognition, and a correct answer. This process enables the model to recognize types of errors and the steps that lead to incorrect answers, allowing the model to better discern which steps to avoid and which to take. The model is able to generate the error outlines itself with automated ERP generation, allowing for error recognition and correction to be integrated into the reasoning chain and produce scalability and reliability in the process. The results demonstrate that ERP serves as a versatile supplement to conventional CoT, ultimately contributing to more robust and capable reasoning abilities along with increased interpretability in how models ultimately reach their errors.</li>
</ul>

<h3>Title: Aligning Distributionally Robust Optimization with Practical Deep Learning Needs</h3>
<ul>
<li><strong>Authors: </strong>Dmitrii Feoktistov, Igor Ignashin, Andrey Veprikov, Nikita Borovko, Alexander Bogdanov, Savelii Chezhegov, Aleksandr Beznosikov</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.16734">https://arxiv.org/abs/2508.16734</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.16734">https://arxiv.org/pdf/2508.16734</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.16734]] Aligning Distributionally Robust Optimization with Practical Deep Learning Needs(https://arxiv.org/abs/2508.16734)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>While traditional Deep Learning (DL) optimization methods treat all training samples equally, Distributionally Robust Optimization (DRO) adaptively assigns importance weights to different samples. However, a significant gap exists between DRO and current DL practices. Modern DL optimizers require adaptivity and the ability to handle stochastic gradients, as these methods demonstrate superior performance. Additionally, for practical applications, a method should allow weight assignment not only to individual samples, but also to groups of objects (for example, all samples of the same class). This paper aims to bridge this gap by introducing ALSO $\unicode{x2013}$ Adaptive Loss Scaling Optimizer $\unicode{x2013}$ an adaptive algorithm for a modified DRO objective that can handle weight assignment to sample groups. We prove the convergence of our proposed algorithm for non-convex objectives, which is the typical case for DL models. Empirical evaluation across diverse Deep Learning tasks, from Tabular DL to Split Learning tasks, demonstrates that ALSO outperforms both traditional optimizers and existing DRO methods.</li>
</ul>

<h3>Title: CellEcoNet: Decoding the Cellular Language of Pathology with Deep Learning for Invasive Lung Adenocarcinoma Recurrence Prediction</h3>
<ul>
<li><strong>Authors: </strong>Abdul Rehman Akbar, Usama Sajjad, Ziyu Su, Wencheng Li, Fei Xing, Jimmy Ruiz, Wei Chen, Muhammad Khalid Khan Niazi</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.16742">https://arxiv.org/abs/2508.16742</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.16742">https://arxiv.org/pdf/2508.16742</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.16742]] CellEcoNet: Decoding the Cellular Language of Pathology with Deep Learning for Invasive Lung Adenocarcinoma Recurrence Prediction(https://arxiv.org/abs/2508.16742)</code><input type="text"></li>
<li><strong>Keywords: </strong>fair</a></li>
<li><strong>Abstract: </strong>Despite surgical resection, ~70% of invasive lung adenocarcinoma (ILA) patients recur within five years, and current tools fail to identify those needing adjuvant therapy. To address this unmet clinical need, we introduce CellEcoNet, a novel spatially aware deep learning framework that models whole slide images (WSIs) through natural language analogy, defining a "language of pathology," where cells act as words, cellular neighborhoods become phrases, and tissue architecture forms sentences. CellEcoNet learns these context-dependent meanings automatically, capturing how subtle variations and spatial interactions derive recurrence risk. On a dataset of 456 H&E-stained WSIs, CellEcoNet achieved superior predictive performance (AUC:77.8% HR:9.54), outperforming IASLC grading system (AUC:71.4% HR:2.36), AJCC Stage (AUC:64.0% HR:1.17) and state-of-the-art computational methods (AUCs:62.2-67.4%). CellEcoNet demonstrated fairness and consistent performance across diverse demographic and clinical subgroups. Beyond prognosis, CellEcoNet marks a paradigm shift by decoding the tumor microenvironment's cellular "language" to reveal how subtle cell variations encode recurrence risk.</li>
</ul>

<h3>Title: Beyond Memorization: Extending Reasoning Depth with Recurrence, Memory and Test-Time Compute Scaling</h3>
<ul>
<li><strong>Authors: </strong>Ivan Rodkin, Daniil Orel, Konstantin Smirnov, Arman Bolatov, Bilal Elbouardi, Besher Hassan, Yuri Kuratov, Aydar Bulatov, Preslav Nakov, Timothy Baldwin, Artem Shelmanov, Mikhail Burtsev</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.16745">https://arxiv.org/abs/2508.16745</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.16745">https://arxiv.org/pdf/2508.16745</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.16745]] Beyond Memorization: Extending Reasoning Depth with Recurrence, Memory and Test-Time Compute Scaling(https://arxiv.org/abs/2508.16745)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Reasoning is a core capability of large language models, yet understanding how they learn and perform multi-step reasoning remains an open problem. In this study, we explore how different architectures and training methods affect model multi-step reasoning capabilities within a cellular automata framework. By training on state sequences generated with random Boolean functions for random initial conditions to exclude memorization, we demonstrate that most neural architectures learn to abstract the underlying rules. While models achieve high accuracy in next-state prediction, their performance declines sharply if multi-step reasoning is required. We confirm that increasing model depth plays a crucial role for sequential computations. We demonstrate that an extension of the effective model depth with recurrence, memory, and test-time compute scaling substantially enhances reasoning capabilities.</li>
</ul>

<h3>Title: FAIRWELL: Fair Multimodal Self-Supervised Learning for Wellbeing Prediction</h3>
<ul>
<li><strong>Authors: </strong>Jiaee Cheong, Abtin Mogharabin, Paul Liang, Hatice Gunes, Sinan Kalkan</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.16748">https://arxiv.org/abs/2508.16748</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.16748">https://arxiv.org/pdf/2508.16748</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.16748]] FAIRWELL: Fair Multimodal Self-Supervised Learning for Wellbeing Prediction(https://arxiv.org/abs/2508.16748)</code><input type="text"></li>
<li><strong>Keywords: </strong>protect, fair</a></li>
<li><strong>Abstract: </strong>Early efforts on leveraging self-supervised learning (SSL) to improve machine learning (ML) fairness has proven promising. However, such an approach has yet to be explored within a multimodal context. Prior work has shown that, within a multimodal setting, different modalities contain modality-unique information that can complement information of other modalities. Leveraging on this, we propose a novel subject-level loss function to learn fairer representations via the following three mechanisms, adapting the variance-invariance-covariance regularization (VICReg) method: (i) the variance term, which reduces reliance on the protected attribute as a trivial solution; (ii) the invariance term, which ensures consistent predictions for similar individuals; and (iii) the covariance term, which minimizes correlational dependence on the protected attribute. Consequently, our loss function, coined as FAIRWELL, aims to obtain subject-independent representations, enforcing fairness in multimodal prediction tasks. We evaluate our method on three challenging real-world heterogeneous healthcare datasets (i.e. D-Vlog, MIMIC and MODMA) which contain different modalities of varying length and different prediction tasks. Our findings indicate that our framework improves overall fairness performance with minimal reduction in classification performance and significantly improves on the performance-fairness Pareto frontier.</li>
</ul>

<h3>Title: A Framework for Benchmarking Fairness-Utility Trade-offs in Text-to-Image Models via Pareto Frontiers</h3>
<ul>
<li><strong>Authors: </strong>Marco N. Bochernitsan, Rodrigo C. Barros, Lucas S. Kupssinsk√º</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.16752">https://arxiv.org/abs/2508.16752</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.16752">https://arxiv.org/pdf/2508.16752</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.16752]] A Framework for Benchmarking Fairness-Utility Trade-offs in Text-to-Image Models via Pareto Frontiers(https://arxiv.org/abs/2508.16752)</code><input type="text"></li>
<li><strong>Keywords: </strong>fair, diffusion</a></li>
<li><strong>Abstract: </strong>Achieving fairness in text-to-image generation demands mitigating social biases without compromising visual fidelity, a challenge critical to responsible AI. Current fairness evaluation procedures for text-to-image models rely on qualitative judgment or narrow comparisons, which limit the capacity to assess both fairness and utility in these models and prevent reproducible assessment of debiasing methods. Existing approaches typically employ ad-hoc, human-centered visual inspections that are both error-prone and difficult to replicate. We propose a method for evaluating fairness and utility in text-to-image models using Pareto-optimal frontiers across hyperparametrization of debiasing methods. Our method allows for comparison between distinct text-to-image models, outlining all configurations that optimize fairness for a given utility and vice-versa. To illustrate our evaluation method, we use Normalized Shannon Entropy and ClipScore for fairness and utility evaluation, respectively. We assess fairness and utility in Stable Diffusion, Fair Diffusion, SDXL, DeCoDi, and FLUX text-to-image models. Our method shows that most default hyperparameterizations of the text-to-image model are dominated solutions in the fairness-utility space, and it is straightforward to find better hyperparameters.</li>
</ul>

<h3>Title: GAICo: A Deployed and Extensible Framework for Evaluating Diverse and Multimodal Generative AI Outputs</h3>
<ul>
<li><strong>Authors: </strong>Nitin Gupta, Pallav Koppisetti, Kausik Lakkaraju, Biplav Srivastava</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.16753">https://arxiv.org/abs/2508.16753</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.16753">https://arxiv.org/pdf/2508.16753</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.16753]] GAICo: A Deployed and Extensible Framework for Evaluating Diverse and Multimodal Generative AI Outputs(https://arxiv.org/abs/2508.16753)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, generative</a></li>
<li><strong>Abstract: </strong>The rapid proliferation of Generative AI (GenAI) into diverse, high-stakes domains necessitates robust and reproducible evaluation methods. However, practitioners often resort to ad-hoc, non-standardized scripts, as common metrics are often unsuitable for specialized, structured outputs (e.g., automated plans, time-series) or holistic comparison across modalities (e.g., text, audio, and image). This fragmentation hinders comparability and slows AI system development. To address this challenge, we present GAICo (Generative AI Comparator): a deployed, open-source Python library that streamlines and standardizes GenAI output comparison. GAICo provides a unified, extensible framework supporting a comprehensive suite of reference-based metrics for unstructured text, specialized structured data formats, and multimedia (images, audio). Its architecture features a high-level API for rapid, end-to-end analysis, from multi-model comparison to visualization and reporting, alongside direct metric access for granular control. We demonstrate GAICo's utility through a detailed case study evaluating and debugging complex, multi-modal AI Travel Assistant pipelines. GAICo empowers AI researchers and developers to efficiently assess system performance, make evaluation reproducible, improve development velocity, and ultimately build more trustworthy AI systems, aligning with the goal of moving faster and safer in AI deployment. Since its release on PyPI in Jun 2025, the tool has been downloaded over 13K times, across versions, by Aug 2025, demonstrating growing community interest.</li>
</ul>

<h3>Title: How Good are LLM-based Rerankers? An Empirical Analysis of State-of-the-Art Reranking Models</h3>
<ul>
<li><strong>Authors: </strong>Abdelrahman Abdallah, Bhawna Piryani, Jamshid Mozafari, Mohammed Ali, Adam Jatowt</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.IR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.16757">https://arxiv.org/abs/2508.16757</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.16757">https://arxiv.org/pdf/2508.16757</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.16757]] How Good are LLM-based Rerankers? An Empirical Analysis of State-of-the-Art Reranking Models(https://arxiv.org/abs/2508.16757)</code><input type="text"></li>
<li><strong>Keywords: </strong>fair, large language model</a></li>
<li><strong>Abstract: </strong>In this work, we present a systematic and comprehensive empirical evaluation of state-of-the-art reranking methods, encompassing large language model (LLM)-based, lightweight contextual, and zero-shot approaches, with respect to their performance in information retrieval tasks. We evaluate in total 22 methods, including 40 variants (depending on used LLM) across several established benchmarks, including TREC DL19, DL20, and BEIR, as well as a novel dataset designed to test queries unseen by pretrained models. Our primary goal is to determine, through controlled and fair comparisons, whether a performance disparity exists between LLM-based rerankers and their lightweight counterparts, particularly on novel queries, and to elucidate the underlying causes of any observed differences. To disentangle confounding factors, we analyze the effects of training data overlap, model architecture, and computational efficiency on reranking performance. Our findings indicate that while LLM-based rerankers demonstrate superior performance on familiar queries, their generalization ability to novel queries varies, with lightweight models offering comparable efficiency. We further identify that the novelty of queries significantly impacts reranking effectiveness, highlighting limitations in existing approaches. this https URL</li>
</ul>

<h3>Title: Securing Heterogeneous Network (HetNet) Communications for Wildfire Management: Mitigating the Effects of Adversarial and Environmental Threats</h3>
<ul>
<li><strong>Authors: </strong>Nesrine Benchoubane, Olfa Ben Yahia, William Ferguson, Gurkan Gur, Sumit Chakravarty, Gregory Falco, Gunes Karabulut Kurt</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.16761">https://arxiv.org/abs/2508.16761</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.16761">https://arxiv.org/pdf/2508.16761</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.16761]] Securing Heterogeneous Network (HetNet) Communications for Wildfire Management: Mitigating the Effects of Adversarial and Environmental Threats(https://arxiv.org/abs/2508.16761)</code><input type="text"></li>
<li><strong>Keywords: </strong>secure, security, protect, robust</a></li>
<li><strong>Abstract: </strong>In the face of adverse environmental conditions and cyber threats, robust communication systems for critical applications such as wildfire management and detection demand secure and resilient architectures. This paper presents a novel framework that considers both adversarial factors, building resilience into a heterogeneous network (HetNet) integrating Low Earth Orbit (LEO) satellite constellation with High-Altitude Platform Ground Stations (HAPGS) and Low-Altitude Platforms (LAPS), tailored to support wildfire management operations. Building upon our previous work on secure-by-component approach for link segment security, we extend protection to the communication layer by securing both Radio Frequency (RF)/Free Space Optics (FSO) management and different links. Through a case study, we quantify how environmental stressors impact secrecy capacity and expose the system to passive adversaries. Key findings demonstrate that atmospheric attenuation and beam misalignment can notably degrade secrecy capacity across both short- and long-range communication links, while high-altitude eavesdroppers face less signal degradation, increasing their interception capability. Moreover, increasing transmit power to counter environmental losses can inadvertently improve eavesdropper reception, thereby reducing overall link confidentiality. Our work not only highlights the importance of protecting networks from these dual threats but also aligns with the IEEE P3536 Standard for Space System Cybersecurity Design, ensuring resilience and the prevention of mission failures.</li>
</ul>

<h3>Title: Toward Socially Aware Vision-Language Models: Evaluating Cultural Competence Through Multimodal Story Generation</h3>
<ul>
<li><strong>Authors: </strong>Arka Mukherjee, Shreya Ghosh</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.CY</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.16762">https://arxiv.org/abs/2508.16762</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.16762">https://arxiv.org/pdf/2508.16762</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.16762]] Toward Socially Aware Vision-Language Models: Evaluating Cultural Competence Through Multimodal Story Generation(https://arxiv.org/abs/2508.16762)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>As Vision-Language Models (VLMs) achieve widespread deployment across diverse cultural contexts, ensuring their cultural competence becomes critical for responsible AI systems. While prior work has evaluated cultural awareness in text-only models and VLM object recognition tasks, no research has systematically assessed how VLMs adapt outputs when cultural identity cues are embedded in both textual prompts and visual inputs during generative tasks. We present the first comprehensive evaluation of VLM cultural competence through multimodal story generation, developing a novel multimodal framework that perturbs cultural identity and evaluates 5 contemporary VLMs on a downstream task: story generation. Our analysis reveals significant cultural adaptation capabilities, with rich culturally-specific vocabulary spanning names, familial terms, and geographic markers. However, we uncover concerning limitations: cultural competence varies dramatically across architectures, some models exhibit inverse cultural alignment, and automated metrics show architectural bias contradicting human assessments. Cross-modal evaluation shows that culturally distinct outputs are indeed detectable through visual-semantic similarity (28.7% within-nationality vs. 0.2% cross-nationality recall), yet visual-cultural understanding remains limited. In essence, we establish the promise and challenges of cultural competence in multimodal AI. We publicly release our codebase and data: this https URL</li>
</ul>

<h3>Title: WebMMU: A Benchmark for Multimodal Multilingual Website Understanding and Code Generation</h3>
<ul>
<li><strong>Authors: </strong>Rabiul Awal, Mahsa Massoud, Aarash Feizi, Zichao Li, Suyuchen Wang, Christopher Pal, Aishwarya Agrawal, David Vazquez, Siva Reddy, Juan A. Rodriguez, Perouz Taslakian, Spandana Gella, Sai Rajeswar</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.16763">https://arxiv.org/abs/2508.16763</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.16763">https://arxiv.org/pdf/2508.16763</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.16763]] WebMMU: A Benchmark for Multimodal Multilingual Website Understanding and Code Generation(https://arxiv.org/abs/2508.16763)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction, large language model</a></li>
<li><strong>Abstract: </strong>We present WebMMU, a multilingual benchmark that evaluates three core web tasks: (1) website visual question answering, (2) code editing involving HTML/CSS/JavaScript, and (3) mockup-to-code generation. Unlike prior benchmarks that treat these tasks separately, WebMMU unifies them using expert-annotated, real-world web data to assess models' abilities in complex multi-step reasoning, precise element grounding, and functional UI comprehension and coding. Our evaluation shows that while multimodal large language models (MLLMs) perform well on basic information extraction, they struggle with reasoning and grounding, editing code to preserve functionality, and generating design-to-code that maintains hierarchy and supports multilingual content. These findings reveal key limitations in current MLLMs and underscore the need for improved multimodal and cross-lingual reasoning to build future web agents capable of automating diverse web development tasks.</li>
</ul>

<h3>Title: Guarding Your Conversations: Privacy Gatekeepers for Secure Interactions with Cloud-Based AI Models</h3>
<ul>
<li><strong>Authors: </strong>GodsGift Uzor, Hasan Al-Qudah, Ynes Ineza, Abdul Serwadda</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.AI, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.16765">https://arxiv.org/abs/2508.16765</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.16765">https://arxiv.org/pdf/2508.16765</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.16765]] Guarding Your Conversations: Privacy Gatekeepers for Secure Interactions with Cloud-Based AI Models(https://arxiv.org/abs/2508.16765)</code><input type="text"></li>
<li><strong>Keywords: </strong>secure, security, privacy, protect, large language model</a></li>
<li><strong>Abstract: </strong>The interactive nature of Large Language Models (LLMs), which closely track user data and context, has prompted users to share personal and private information in unprecedented ways. Even when users opt out of allowing their data to be used for training, these privacy settings offer limited protection when LLM providers operate in jurisdictions with weak privacy laws, invasive government surveillance, or poor data security practices. In such cases, the risk of sensitive information, including Personally Identifiable Information (PII), being mishandled or exposed remains high. To address this, we propose the concept of an "LLM gatekeeper", a lightweight, locally run model that filters out sensitive information from user queries before they are sent to the potentially untrustworthy, though highly capable, cloud-based LLM. Through experiments with human subjects, we demonstrate that this dual-model approach introduces minimal overhead while significantly enhancing user privacy, without compromising the quality of LLM responses.</li>
</ul>

<h3>Title: Latent Graph Learning in Generative Models of Neural Signals</h3>
<ul>
<li><strong>Authors: </strong>Nathan X. Kodama, Kenneth A. Loparo</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.16776">https://arxiv.org/abs/2508.16776</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.16776">https://arxiv.org/pdf/2508.16776</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.16776]] Latent Graph Learning in Generative Models of Neural Signals(https://arxiv.org/abs/2508.16776)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>Inferring temporal interaction graphs and higher-order structure from neural signals is a key problem in building generative models for systems neuroscience. Foundation models for large-scale neural data represent shared latent structures of neural signals. However, extracting interpretable latent graph representations in foundation models remains challenging and unsolved. Here we explore latent graph learning in generative models of neural signals. By testing against numerical simulations of neural circuits with known ground-truth connectivity, we evaluate several hypotheses for explaining learned model weights. We discover modest alignment between extracted network representations and the underlying directed graphs and strong alignment in the co-input graph representations. These findings motivate paths towards incorporating graph-based geometric constraints in the construction of large-scale foundation models for neural data.</li>
</ul>

<h3>Title: Improving Performance, Robustness, and Fairness of Radiographic AI Models with Finely-Controllable Synthetic Data</h3>
<ul>
<li><strong>Authors: </strong>Stefania L. Moroianu, Christian Bluethgen, Pierre Chambon, Mehdi Cherti, Jean-Benoit Delbrouck, Magdalini Paschali, Brandon Price, Judy Gichoya, Jenia Jitsev, Curtis P. Langlotz, Akshay S. Chaudhari</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.16783">https://arxiv.org/abs/2508.16783</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.16783">https://arxiv.org/pdf/2508.16783</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.16783]] Improving Performance, Robustness, and Fairness of Radiographic AI Models with Finely-Controllable Synthetic Data(https://arxiv.org/abs/2508.16783)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, fair, diffusion</a></li>
<li><strong>Abstract: </strong>Achieving robust performance and fairness across diverse patient populations remains a challenge in developing clinically deployable deep learning models for diagnostic imaging. Synthetic data generation has emerged as a promising strategy to address limitations in dataset scale and diversity. We introduce RoentGen-v2, a text-to-image diffusion model for chest radiographs that enables fine-grained control over both radiographic findings and patient demographic attributes, including sex, age, and race/ethnicity. RoentGen-v2 is the first model to generate clinically plausible images with demographic conditioning, facilitating the creation of a large, demographically balanced synthetic dataset comprising over 565,000 images. We use this large synthetic dataset to evaluate optimal training pipelines for downstream disease classification models. In contrast to prior work that combines real and synthetic data naively, we propose an improved training strategy that leverages synthetic data for supervised pretraining, followed by fine-tuning on real data. Through extensive evaluation on over 137,000 chest radiographs from five institutions, we demonstrate that synthetic pretraining consistently improves model performance, generalization to out-of-distribution settings, and fairness across demographic subgroups. Across datasets, synthetic pretraining led to a 6.5% accuracy increase in the performance of downstream classification models, compared to a modest 2.7% increase when naively combining real and synthetic data. We observe this performance improvement simultaneously with the reduction of the underdiagnosis fairness gap by 19.3%. These results highlight the potential of synthetic imaging to advance equitable and generalizable medical deep learning under real-world data constraints. We open source our code, trained models, and synthetic dataset at this https URL .</li>
</ul>

<h3>Title: Interpreting the Effects of Quantization on LLMs</h3>
<ul>
<li><strong>Authors: </strong>Manpreet Singh, Hassan Sajjad</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.16785">https://arxiv.org/abs/2508.16785</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.16785">https://arxiv.org/pdf/2508.16785</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.16785]] Interpreting the Effects of Quantization on LLMs(https://arxiv.org/abs/2508.16785)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability</a></li>
<li><strong>Abstract: </strong>Quantization offers a practical solution to deploy LLMs in resource-constraint environments. However, its impact on internal representations remains understudied, raising questions about the reliability of quantized models. In this study, we employ a range of interpretability techniques to investigate how quantization affects model and neuron behavior. We analyze multiple LLMs under 4-bit and 8-bit quantization. Our findings reveal that the impact of quantization on model calibration is generally minor. Analysis of neuron activations indicates that the number of dead neurons, i.e., those with activation values close to 0 across the dataset, remains consistent regardless of quantization. In terms of neuron contribution to predictions, we observe that smaller full precision models exhibit fewer salient neurons, whereas larger models tend to have more, with the exception of Llama-2-7B. The effect of quantization on neuron redundancy varies across models. Overall, our findings suggest that effect of quantization may vary by model and tasks, however, we did not observe any drastic change which may discourage the use of quantization as a reliable model compression technique.</li>
</ul>

<h3>Title: Assess and Prompt: A Generative RL Framework for Improving Engagement in Online Mental Health Communities</h3>
<ul>
<li><strong>Authors: </strong>Bhagesh Gaur, Karan Gupta, Aseem Srivastava, Manish Gupta, Md Shad Akhtar</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.16788">https://arxiv.org/abs/2508.16788</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.16788">https://arxiv.org/pdf/2508.16788</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.16788]] Assess and Prompt: A Generative RL Framework for Improving Engagement in Online Mental Health Communities(https://arxiv.org/abs/2508.16788)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>Online Mental Health Communities (OMHCs) provide crucial peer and expert support, yet many posts remain unanswered due to missing support attributes that signal the need for help. We present a novel framework that identifies these gaps and prompts users to enrich their posts, thereby improving engagement. To support this, we introduce REDDME, a new dataset of 4,760 posts from mental health subreddits annotated for the span and intensity of three key support attributes: event what happened?, effect what did the user experience?, and requirement what support they need?. Next, we devise a hierarchical taxonomy, CueTaxo, of support attributes for controlled question generation. Further, we propose MH-COPILOT, a reinforcement learning-based system that integrates (a) contextual attribute-span identification, (b) support attribute intensity classification, (c) controlled question generation via a hierarchical taxonomy, and (d) a verifier for reward modeling. Our model dynamically assesses posts for the presence/absence of support attributes, and generates targeted prompts to elicit missing information. Empirical results across four notable language models demonstrate significant improvements in attribute elicitation and user engagement. A human evaluation further validates the model's effectiveness in real-world OMHC settings.</li>
</ul>

<h3>Title: Uncertainty Propagation Networks for Neural Ordinary Differential Equations</h3>
<ul>
<li><strong>Authors: </strong>Hadi Jahanshahi, Zheng H. Zhu</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.16815">https://arxiv.org/abs/2508.16815</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.16815">https://arxiv.org/pdf/2508.16815</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.16815]] Uncertainty Propagation Networks for Neural Ordinary Differential Equations(https://arxiv.org/abs/2508.16815)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>This paper introduces Uncertainty Propagation Network (UPN), a novel family of neural differential equations that naturally incorporate uncertainty quantification into continuous-time modeling. Unlike existing neural ODEs that predict only state trajectories, UPN simultaneously model both state evolution and its associated uncertainty by parameterizing coupled differential equations for mean and covariance dynamics. The architecture efficiently propagates uncertainty through nonlinear dynamics without discretization artifacts by solving coupled ODEs for state and covariance evolution while enabling state-dependent, learnable process noise. The continuous-depth formulation adapts its evaluation strategy to each input's complexity, provides principled uncertainty quantification, and handles irregularly-sampled observations naturally. Experimental results demonstrate UPN's effectiveness across multiple domains: continuous normalizing flows (CNFs) with uncertainty quantification, time-series forecasting with well-calibrated confidence intervals, and robust trajectory prediction in both stable and chaotic dynamical systems.</li>
</ul>

<h3>Title: Understanding and Tackling Over-Dilution in Graph Neural Networks</h3>
<ul>
<li><strong>Authors: </strong>Junhyun Lee, Veronika Thost, Bumsoo Kim, Jaewoo Kang, Tengfei Ma</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.16829">https://arxiv.org/abs/2508.16829</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.16829">https://arxiv.org/pdf/2508.16829</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.16829]] Understanding and Tackling Over-Dilution in Graph Neural Networks(https://arxiv.org/abs/2508.16829)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Message Passing Neural Networks (MPNNs) hold a key position in machine learning on graphs, but they struggle with unintended behaviors, such as over-smoothing and over-squashing, due to irregular data structures. The observation and formulation of these limitations have become foundational in constructing more informative graph representations. In this paper, we delve into the limitations of MPNNs, focusing on aspects that have previously been overlooked. Our observations reveal that even within a single layer, the information specific to an individual node can become significantly diluted. To delve into this phenomenon in depth, we present the concept of Over-dilution and formulate it with two dilution factors: intra-node dilution for attribute-level and inter-node dilution for node-level representations. We also introduce a transformer-based solution that alleviates over-dilution and complements existing node embedding methods like MPNNs. Our findings provide new insights and contribute to the development of informative representations. The implementation and supplementary materials are publicly available at this https URL.</li>
</ul>

<h3>Title: Out of Distribution Detection for Efficient Continual Learning in Quality Prediction for Arc Welding</h3>
<ul>
<li><strong>Authors: </strong>Yannik Hahn, Jan Voets, Antonin Koenigsfeld, Hasan Tercan, Tobias Meisen</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.16832">https://arxiv.org/abs/2508.16832</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.16832">https://arxiv.org/pdf/2508.16832</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.16832]] Out of Distribution Detection for Efficient Continual Learning in Quality Prediction for Arc Welding(https://arxiv.org/abs/2508.16832)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, transformer</a></li>
<li><strong>Abstract: </strong>Modern manufacturing relies heavily on fusion welding processes, including gas metal arc welding (GMAW). Despite significant advances in machine learning-based quality prediction, current models exhibit critical limitations when confronted with the inherent distribution shifts that occur in dynamic manufacturing environments. In this work, we extend the VQ-VAE Transformer architecture - previously demonstrating state-of-the-art performance in weld quality prediction - by leveraging its autoregressive loss as a reliable out-of-distribution (OOD) detection mechanism. Our approach exhibits superior performance compared to conventional reconstruction methods, embedding error-based techniques, and other established baselines. By integrating OOD detection with continual learning strategies, we optimize model adaptation, triggering updates only when necessary and thereby minimizing costly labeling requirements. We introduce a novel quantitative metric that simultaneously evaluates OOD detection capability while interpreting in-distribution performance. Experimental validation in real-world welding scenarios demonstrates that our framework effectively maintains robust quality prediction capabilities across significant distribution shifts, addressing critical challenges in dynamic manufacturing environments where process parameters frequently change. This research makes a substantial contribution to applied artificial intelligence by providing an explainable and at the same time adaptive solution for quality assurance in dynamic manufacturing processes - a crucial step towards robust, practical AI systems in the industrial environment.</li>
</ul>

<h3>Title: If We May De-Presuppose: Robustly Verifying Claims through Presupposition-Free Question Decomposition</h3>
<ul>
<li><strong>Authors: </strong>Shubhashis Roy Dipta, Francis Ferraro</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.16838">https://arxiv.org/abs/2508.16838</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.16838">https://arxiv.org/pdf/2508.16838</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.16838]] If We May De-Presuppose: Robustly Verifying Claims through Presupposition-Free Question Decomposition(https://arxiv.org/abs/2508.16838)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, large language model</a></li>
<li><strong>Abstract: </strong>Prior work has shown that presupposition in generated questions can introduce unverified assumptions, leading to inconsistencies in claim verification. Additionally, prompt sensitivity remains a significant challenge for large language models (LLMs), resulting in performance variance as high as 3-6%. While recent advancements have reduced this gap, our study demonstrates that prompt sensitivity remains a persistent issue. To address this, we propose a structured and robust claim verification framework that reasons through presupposition-free, decomposed questions. Extensive experiments across multiple prompts, datasets, and LLMs reveal that even state-of-the-art models remain susceptible to prompt variance and presupposition. Our method consistently mitigates these issues, achieving up to a 2-5% improvement.</li>
</ul>

<h3>Title: A Survey of Threats Against Voice Authentication and Anti-Spoofing Systems</h3>
<ul>
<li><strong>Authors: </strong>Kamel Kamel, Keshav Sood, Hridoy Sankar Dutta, Sunil Aryal</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.16843">https://arxiv.org/abs/2508.16843</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.16843">https://arxiv.org/pdf/2508.16843</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.16843]] A Survey of Threats Against Voice Authentication and Anti-Spoofing Systems(https://arxiv.org/abs/2508.16843)</code><input type="text"></li>
<li><strong>Keywords: </strong>secure, attack, robust</a></li>
<li><strong>Abstract: </strong>Voice authentication has undergone significant changes from traditional systems that relied on handcrafted acoustic features to deep learning models that can extract robust speaker embeddings. This advancement has expanded its applications across finance, smart devices, law enforcement, and beyond. However, as adoption has grown, so have the threats. This survey presents a comprehensive review of the modern threat landscape targeting Voice Authentication Systems (VAS) and Anti-Spoofing Countermeasures (CMs), including data poisoning, adversarial, deepfake, and adversarial spoofing attacks. We chronologically trace the development of voice authentication and examine how vulnerabilities have evolved in tandem with technological advancements. For each category of attack, we summarize methodologies, highlight commonly used datasets, compare performance and limitations, and organize existing literature using widely accepted taxonomies. By highlighting emerging risks and open challenges, this survey aims to support the development of more secure and resilient voice authentication systems.</li>
</ul>

<h3>Title: Transformer-Based Neural Network for Transient Detection without Image Subtraction</h3>
<ul>
<li><strong>Authors: </strong>Adi Inada, Masao Sako, Tatiana Acero-Cuellar, Federica Bianco</a></li>
<li><strong>Subjects: </strong>cs.CV, astro-ph.IM</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.16844">https://arxiv.org/abs/2508.16844</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.16844">https://arxiv.org/pdf/2508.16844</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.16844]] Transformer-Based Neural Network for Transient Detection without Image Subtraction(https://arxiv.org/abs/2508.16844)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>We introduce a transformer-based neural network for the accurate classification of real and bogus transient detections in astronomical images. This network advances beyond the conventional convolutional neural network (CNN) methods, widely used in image processing tasks, by adopting an architecture better suited for detailed pixel-by-pixel comparison. The architecture enables efficient analysis of search and template images only, thus removing the necessity for computationally-expensive difference imaging, while maintaining high performance. Our primary evaluation was conducted using the autoScan dataset from the Dark Energy Survey (DES), where the network achieved a classification accuracy of 97.4% and diminishing performance utility for difference image as the size of the training set grew. Further experiments with DES data confirmed that the network can operate at a similar level even when the input images are not centered on the supernova candidate. These findings highlight the network's effectiveness in enhancing both accuracy and efficiency of supernova detection in large-scale astronomical surveys.</li>
</ul>

<h3>Title: NinA: Normalizing Flows in Action. Training VLA Models with Normalizing Flows</h3>
<ul>
<li><strong>Authors: </strong>Denis Tarasov, Alexander Nikulin, Ilya Zisman, Albina Klepach, Nikita Lyubaykin, Andrei Polubarov, Alexander Derevyagin, Vladislav Kurenkov</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.16845">https://arxiv.org/abs/2508.16845</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.16845">https://arxiv.org/pdf/2508.16845</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.16845]] NinA: Normalizing Flows in Action. Training VLA Models with Normalizing Flows(https://arxiv.org/abs/2508.16845)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>Recent advances in Vision-Language-Action (VLA) models have established a two-component architecture, where a pre-trained Vision-Language Model (VLM) encodes visual observations and task descriptions, and an action decoder maps these representations to continuous actions. Diffusion models have been widely adopted as action decoders due to their ability to model complex, multimodal action distributions. However, they require multiple iterative denoising steps at inference time or downstream techniques to speed up sampling, limiting their practicality in real-world settings where high-frequency control is crucial. In this work, we present NinA (Normalizing Flows in Action), a fast and expressive alter- native to diffusion-based decoders for VLAs. NinA replaces the diffusion action decoder with a Normalizing Flow (NF) that enables one-shot sampling through an invertible transformation, significantly reducing inference time. We integrate NinA into the FLOWER VLA architecture and fine-tune on the LIBERO benchmark. Our experiments show that NinA matches the performance of its diffusion-based counterpart under the same training regime, while achieving substantially faster inference. These results suggest that NinA offers a promising path toward efficient, high-frequency VLA control without compromising performance.</li>
</ul>

<h3>Title: Gaussian Primitive Optimized Deformable Retinal Image Registration</h3>
<ul>
<li><strong>Authors: </strong>Xin Tian, Jiazheng Wang, Yuxi Zhang, Xiang Chen, Renjiu Hu, Gaolei Li, Min Liu, Hang Zhang</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI, eess.IV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.16852">https://arxiv.org/abs/2508.16852</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.16852">https://arxiv.org/pdf/2508.16852</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.16852]] Gaussian Primitive Optimized Deformable Retinal Image Registration(https://arxiv.org/abs/2508.16852)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Deformable retinal image registration is notoriously difficult due to large homogeneous regions and sparse but critical vascular features, which cause limited gradient signals in standard learning-based frameworks. In this paper, we introduce Gaussian Primitive Optimization (GPO), a novel iterative framework that performs structured message passing to overcome these challenges. After an initial coarse alignment, we extract keypoints at salient anatomical structures (e.g., major vessels) to serve as a minimal set of descriptor-based control nodes (DCN). Each node is modelled as a Gaussian primitive with trainable position, displacement, and radius, thus adapting its spatial influence to local deformation scales. A K-Nearest Neighbors (KNN) Gaussian interpolation then blends and propagates displacement signals from these information-rich nodes to construct a globally coherent displacement field; focusing interpolation on the top (K) neighbors reduces computational overhead while preserving local detail. By strategically anchoring nodes in high-gradient regions, GPO ensures robust gradient flow, mitigating vanishing gradient signal in textureless areas. The framework is optimized end-to-end via a multi-term loss that enforces both keypoint consistency and intensity alignment. Experiments on the FIRE dataset show that GPO reduces the target registration error from 6.2\,px to ~2.4\,px and increases the AUC at 25\,px from 0.770 to 0.938, substantially outperforming existing methods. The source code can be accessed via this https URL.</li>
</ul>

<h3>Title: Beyond Emotion Recognition: A Multi-Turn Multimodal Emotion Understanding and Reasoning Benchmark</h3>
<ul>
<li><strong>Authors: </strong>Jinpeng Hu, Hongchang Shi, Chongyuan Dai, Zhuo Li, Peipei Song, Meng Wang</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.16859">https://arxiv.org/abs/2508.16859</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.16859">https://arxiv.org/pdf/2508.16859</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.16859]] Beyond Emotion Recognition: A Multi-Turn Multimodal Emotion Understanding and Reasoning Benchmark(https://arxiv.org/abs/2508.16859)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Multimodal large language models (MLLMs) have been widely applied across various fields due to their powerful perceptual and reasoning capabilities. In the realm of psychology, these models hold promise for a deeper understanding of human emotions and behaviors. However, recent research primarily focuses on enhancing their emotion recognition abilities, leaving the substantial potential in emotion reasoning, which is crucial for improving the naturalness and effectiveness of human-machine interactions. Therefore, in this paper, we introduce a multi-turn multimodal emotion understanding and reasoning (MTMEUR) benchmark, which encompasses 1,451 video data from real-life scenarios, along with 5,101 progressive questions. These questions cover various aspects, including emotion recognition, potential causes of emotions, future action prediction, etc. Besides, we propose a multi-agent framework, where each agent specializes in a specific aspect, such as background context, character dynamics, and event details, to improve the system's reasoning capabilities. Furthermore, we conduct experiments with existing MLLMs and our agent-based method on the proposed benchmark, revealing that most models face significant challenges with this task.</li>
</ul>

<h3>Title: Learning from Diverse Reasoning Paths with Routing and Collaboration</h3>
<ul>
<li><strong>Authors: </strong>Zhenyu Lei, Zhen Tan, Song Wang, Yaochen Zhu, Zihan Chen, Yushun Dong, Jundong Li</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.16861">https://arxiv.org/abs/2508.16861</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.16861">https://arxiv.org/pdf/2508.16861</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.16861]] Learning from Diverse Reasoning Paths with Routing and Collaboration(https://arxiv.org/abs/2508.16861)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Advances in large language models (LLMs) significantly enhance reasoning capabilities but their deployment is restricted in resource-constrained scenarios. Knowledge distillation addresses this by transferring knowledge from powerful teacher models to compact and transparent students. However, effectively capturing the teacher's comprehensive reasoning is challenging due to conventional token-level supervision's limited scope. Using multiple reasoning paths per query alleviates this problem, but treating each path identically is suboptimal as paths vary widely in quality and suitability across tasks and models. We propose Quality-filtered Routing with Cooperative Distillation (QR-Distill), combining path quality filtering, conditional routing, and cooperative peer teaching. First, quality filtering retains only correct reasoning paths scored by an LLM-based evaluation. Second, conditional routing dynamically assigns paths tailored to each student's current learning state. Finally, cooperative peer teaching enables students to mutually distill diverse insights, addressing knowledge gaps and biases toward specific reasoning styles. Experiments demonstrate QR-Distill's superiority over traditional single- and multi-path distillation methods. Ablation studies further highlight the importance of each component including quality filtering, conditional routing, and peer teaching in effective knowledge transfer. Our code is available at this https URL.</li>
</ul>

<h3>Title: Delta-SVD: Efficient Compression for Personalized Text-to-Image Models</h3>
<ul>
<li><strong>Authors: </strong>Tangyuan Zhang, Shangyu Chen, Qixiang Chen, Jianfei Cai</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.16863">https://arxiv.org/abs/2508.16863</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.16863">https://arxiv.org/pdf/2508.16863</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.16863]] Delta-SVD: Efficient Compression for Personalized Text-to-Image Models(https://arxiv.org/abs/2508.16863)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>Personalized text-to-image models such as DreamBooth require fine-tuning large-scale diffusion backbones, resulting in significant storage overhead when maintaining many subject-specific models. We present Delta-SVD, a post-hoc, training-free compression method that targets the parameter weights update induced by DreamBooth fine-tuning. Our key observation is that these delta weights exhibit strong low-rank structure due to the sparse and localized nature of personalization. Delta-SVD first applies Singular Value Decomposition (SVD) to factorize the weight deltas, followed by an energy-based rank truncation strategy to balance compression efficiency and reconstruction fidelity. The resulting compressed models are fully plug-and-play and can be re-constructed on-the-fly during inference. Notably, the proposed approach is simple, efficient, and preserves the original model architecture. Experiments on a multiple subject dataset demonstrate that Delta-SVD achieves substantial compression with negligible loss in generation quality measured by CLIP score, SSIM and FID. Our method enables scalable and efficient deployment of personalized diffusion models, making it a practical solution for real-world applications that require storing and deploying large-scale subject customizations.</li>
</ul>

<h3>Title: QFrCoLA: a Quebec-French Corpus of Linguistic Acceptability Judgments</h3>
<ul>
<li><strong>Authors: </strong>David Beauchemin, Richard Khoury</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.16867">https://arxiv.org/abs/2508.16867</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.16867">https://arxiv.org/pdf/2508.16867</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.16867]] QFrCoLA: a Quebec-French Corpus of Linguistic Acceptability Judgments(https://arxiv.org/abs/2508.16867)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer, large language model</a></li>
<li><strong>Abstract: </strong>Large and Transformer-based language models perform outstandingly in various downstream tasks. However, there is limited understanding regarding how these models internalize linguistic knowledge, so various linguistic benchmarks have recently been proposed to facilitate syntactic evaluation of language models across languages. This paper introduces QFrCoLA (Quebec-French Corpus of Linguistic Acceptability Judgments), a normative binary acceptability judgments dataset comprising 25,153 in-domain and 2,675 out-of-domain sentences. Our study leverages the QFrCoLA dataset and seven other linguistic binary acceptability judgment corpora to benchmark seven language models. The results demonstrate that, on average, fine-tuned Transformer-based LM are strong baselines for most languages and that zero-shot binary classification large language models perform poorly on the task. However, for the QFrCoLA benchmark, on average, a fine-tuned Transformer-based LM outperformed other methods tested. It also shows that pre-trained cross-lingual LLMs selected for our experimentation do not seem to have acquired linguistic judgment capabilities during their pre-training for Quebec French. Finally, our experiment results on QFrCoLA show that our dataset, built from examples that illustrate linguistic norms rather than speakers' feelings, is similar to linguistic acceptability judgment; it is a challenging dataset that can benchmark LM on their linguistic judgment capabilities.</li>
</ul>

<h3>Title: Targeted Wearout Attacks in Microprocessor Cores</h3>
<ul>
<li><strong>Authors: </strong>Joshua Mashburn, Johann Knechtel, Florian Klemme, Hussam Amrouch, Ozgur Sinanoglu, Paul V. Gratz</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.AR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.16868">https://arxiv.org/abs/2508.16868</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.16868">https://arxiv.org/pdf/2508.16868</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.16868]] Targeted Wearout Attacks in Microprocessor Cores(https://arxiv.org/abs/2508.16868)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack</a></li>
<li><strong>Abstract: </strong>Negative-Bias Temperature Instability is a dominant aging mechanism in nanoscale CMOS circuits such as microprocessors. With this aging mechanism, the rate of device aging is dependent not only on overall operating conditions, such as heat, but also on user controllable inputs to the transistors. This dependence on input implies a possible timing fault-injection attack wherein a targeted path of logic is intentionally degraded through the purposeful, software-driven actions of an attacker, rendering a targeted bit effectively stuck. In this work, we describe such an attack mechanism, which we dub a "$\textbf{Targeted Wearout Attack}$", wherein an attacker with sufficient knowledge of the processor core, executing a carefully crafted software program with only user privilege, is able to degrade a functional unit within the processor with the aim of eliciting a particular desired incorrect calculation in a victim application. Here we give a general methodology for the attack. We then demonstrate a case study where a targeted path within the fused multiply-add pipeline in a RISC-V CPU sees a $>7x$ increase in wear over time than would be experienced under typical workloads. We show that an attacker could leverage such an attack, leading to targeted and silent data corruption in a co-running victim application using the same unit.</li>
</ul>

<h3>Title: Do Multimodal LLMs See Sentiment?</h3>
<ul>
<li><strong>Authors: </strong>Neemias B. da Silva, John Harrison, Rodrigo Minetto, Myriam R. Delgado, Bogdan T. Nassu, Thiago H. Silva</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.SI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.16873">https://arxiv.org/abs/2508.16873</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.16873">https://arxiv.org/pdf/2508.16873</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.16873]] Do Multimodal LLMs See Sentiment?(https://arxiv.org/abs/2508.16873)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer, large language model</a></li>
<li><strong>Abstract: </strong>Understanding how visual content communicates sentiment is critical in an era where online interaction is increasingly dominated by this kind of media on social platforms. However, this remains a challenging problem, as sentiment perception is closely tied to complex, scene-level semantics. In this paper, we propose an original framework, MLLMsent, to investigate the sentiment reasoning capabilities of Multimodal Large Language Models (MLLMs) through three perspectives: (1) using those MLLMs for direct sentiment classification from images; (2) associating them with pre-trained LLMs for sentiment analysis on automatically generated image descriptions; and (3) fine-tuning the LLMs on sentiment-labeled image descriptions. Experiments on a recent and established benchmark demonstrate that our proposal, particularly the fine-tuned approach, achieves state-of-the-art results outperforming Lexicon-, CNN-, and Transformer-based baselines by up to 30.9%, 64.8%, and 42.4%, respectively, across different levels of evaluators' agreement and sentiment polarity categories. Remarkably, in a cross-dataset test, without any training on these new data, our model still outperforms, by up to 8.26%, the best runner-up, which has been trained directly on them. These results highlight the potential of the proposed visual reasoning scheme for advancing affective computing, while also establishing new benchmarks for future research.</li>
</ul>

<h3>Title: UM3: Unsupervised Map to Map Matching</h3>
<ul>
<li><strong>Authors: </strong>Chaolong Ying, Yinan Zhang, Lei Zhang, Jiazhuang Wang, Shujun Jia, Tianshu Yu</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.16874">https://arxiv.org/abs/2508.16874</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.16874">https://arxiv.org/pdf/2508.16874</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.16874]] UM3: Unsupervised Map to Map Matching(https://arxiv.org/abs/2508.16874)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Map-to-map matching is a critical task for aligning spatial data across heterogeneous sources, yet it remains challenging due to the lack of ground truth correspondences, sparse node features, and scalability demands. In this paper, we propose an unsupervised graph-based framework that addresses these challenges through three key innovations. First, our method is an unsupervised learning approach that requires no training data, which is crucial for large-scale map data where obtaining labeled training samples is challenging. Second, we introduce pseudo coordinates that capture the relative spatial layout of nodes within each map, which enhances feature discriminability and enables scale-invariant learning. Third, we design an mechanism to adaptively balance feature and geometric similarity, as well as a geometric-consistent loss function, ensuring robustness to noisy or incomplete coordinate data. At the implementation level, to handle large-scale maps, we develop a tile-based post-processing pipeline with overlapping regions and majority voting, which enables parallel processing while preserving boundary coherence. Experiments on real-world datasets demonstrate that our method achieves state-of-the-art accuracy in matching tasks, surpassing existing methods by a large margin, particularly in high-noise and large-scale scenarios. Our framework provides a scalable and practical solution for map alignment, offering a robust and efficient alternative to traditional approaches.</li>
</ul>

<h3>Title: A Lightweight Convolution and Vision Transformer integrated model with Multi-scale Self-attention Mechanism</h3>
<ul>
<li><strong>Authors: </strong>Yi Zhang, Lingxiao Wei, Bowei Zhang, Ziwei Liu, Kai Yi, Shu Hu</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.NE</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.16884">https://arxiv.org/abs/2508.16884</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.16884">https://arxiv.org/pdf/2508.16884</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.16884]] A Lightweight Convolution and Vision Transformer integrated model with Multi-scale Self-attention Mechanism(https://arxiv.org/abs/2508.16884)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Vision Transformer (ViT) has prevailed in computer vision tasks due to its strong long-range dependency modelling ability. However, its large model size with high computational cost and weak local feature modeling ability hinder its application in real scenarios. To balance computation efficiency and performance, we propose SAEViT (Sparse-Attention-Efficient-ViT), a lightweight ViT based model with convolution blocks, in this paper to achieve efficient downstream vision tasks. Specifically, SAEViT introduces a Sparsely Aggregated Attention (SAA) module that performs adaptive sparse sampling based on image redundancy and recovers the feature map via deconvolution operation, which significantly reduces the computational complexity of attention operations. In addition, a Channel-Interactive Feed-Forward Network (CIFFN) layer is developed to enhance inter-channel information exchange through feature decomposition and redistribution, mitigating redundancy in traditional feed-forward networks (FNN). Finally, a hierarchical pyramid structure with embedded depth-wise separable convolutional blocks (DWSConv) is devised to further strengthen convolutional features. Extensive experiments on mainstream datasets show that SAEViT achieves Top-1 accuracies of 76.3\% and 79.6\% on the ImageNet-1K classification task with only 0.8 GFLOPs and 1.3 GFLOPs, respectively, demonstrating a lightweight solution for various fundamental vision tasks.</li>
</ul>

<h3>Title: ObjexMT: Objective Extraction and Metacognitive Calibration for LLM-as-a-Judge under Multi-Turn Jailbreaks</h3>
<ul>
<li><strong>Authors: </strong>Hyunjun Kim, Junwoo Ha, Sangyoon Yu, Haon Park</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.16889">https://arxiv.org/abs/2508.16889</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.16889">https://arxiv.org/pdf/2508.16889</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.16889]] ObjexMT: Objective Extraction and Metacognitive Calibration for LLM-as-a-Judge under Multi-Turn Jailbreaks(https://arxiv.org/abs/2508.16889)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack, extraction, large language model</a></li>
<li><strong>Abstract: </strong>Large language models (LLMs) are increasingly used as judges of other models, yet it is unclear whether a judge can reliably infer the latent objective of the conversation it evaluates, especially when the goal is distributed across noisy, adversarial, multi-turn jailbreaks. We introduce OBJEX(MT), a benchmark that requires a model to (i) distill a transcript into a single-sentence base objective and (ii) report its own confidence. Accuracy is scored by an LLM judge using semantic similarity between extracted and gold objectives; correctness uses a single human-aligned threshold calibrated once on N=100 items (tau* = 0.61); and metacognition is evaluated with ECE, Brier score, Wrong@High-Conf, and risk-coverage curves. We evaluate gpt-4.1, claude-sonnet-4, and Qwen3-235B-A22B-FP8 on SafeMT Attack_600, SafeMTData_1K, MHJ, and CoSafe. claude-sonnet-4 attains the highest objective-extraction accuracy (0.515) and the best calibration (ECE 0.296; Brier 0.324), while gpt-4.1 and Qwen3 tie at 0.441 accuracy yet show marked overconfidence (mean confidence approx. 0.88 vs. accuracy approx. 0.44; Wrong@0.90 approx. 48-52%). Performance varies sharply across datasets (approx. 0.167-0.865), with MHJ comparatively easy and Attack_600/CoSafe harder. These results indicate that LLM judges often misinfer objectives with high confidence in multi-turn jailbreaks and suggest operational guidance: provide judges with explicit objectives when possible and use selective prediction or abstention to manage risk. We release prompts, scoring templates, and complete logs to facilitate replication and analysis.</li>
</ul>

<h3>Title: Quantifying Out-of-Training Uncertainty of Neural-Network based Turbulence Closures</h3>
<ul>
<li><strong>Authors: </strong>Cody Grogan, Som Dhulipala, Mauricio Tano, Izabela Gutowska, Som Dutta</a></li>
<li><strong>Subjects: </strong>cs.LG, physics.flu-dyn</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.16891">https://arxiv.org/abs/2508.16891</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.16891">https://arxiv.org/pdf/2508.16891</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.16891]] Quantifying Out-of-Training Uncertainty of Neural-Network based Turbulence Closures(https://arxiv.org/abs/2508.16891)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Neural-Network (NN) based turbulence closures have been developed for being used as pre-trained surrogates for traditional turbulence closures, with the aim to increase computational efficiency and prediction accuracy of CFD simulations. The bottleneck to the widespread adaptation of these ML-based closures is the relative lack of uncertainty quantification (UQ) for these models. Especially, quantifying uncertainties associated with out-of-training inputs, that is when the ML-based turbulence closures are queried on inputs outside their training data regime. In the current paper, a published algebraic turbulence closure1 has been utilized to compare the quality of epistemic UQ between three NN-based methods and Gaussian Process (GP). The three NN-based methods explored are Deep Ensembles (DE), Monte-Carlo Dropout (MCD), and Stochastic Variational Inference (SVI). In the in-training results, we find the exact GP performs the best in accuracy with a Root Mean Squared Error (RMSE) of $2.14 \cdot 10^{-5}$ followed by the DE with an RMSE of $4.59 \cdot 10^{-4}$. Next, the paper discusses the performance of the four methods for quantifying out-of-training uncertainties. For performance, the Exact GP yet again is the best in performance, but has similar performance to the DE in the out-of-training regions. In UQ accuracy for the out-of-training case, SVI and DE hold the best miscalibration error for one of the cases. However, the DE performs the best in Negative Log-Likelihood for both out-of-training cases. We observe that for the current problem, in terms of accuracy GP > DE > SV I > MCD. The DE results are relatively robust and provide intuitive UQ estimates, despite performing naive ensembling. In terms of computational cost, the GP is significantly higher than the NN-based methods with a $O(n^3)$ computational complexity for each training step</li>
</ul>

<h3>Title: Unbiased Reasoning for Knowledge-Intensive Tasks in Large Language Models via Conditional Front-Door Adjustment</h3>
<ul>
<li><strong>Authors: </strong>Bo Zhao, Yinghao Zhang, Ziqi Xu, Yongli Ren, Xiuzhen Zhang, Renqiang Luo, Zaiwen Feng, Feng Xia</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.16910">https://arxiv.org/abs/2508.16910</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.16910">https://arxiv.org/pdf/2508.16910</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.16910]] Unbiased Reasoning for Knowledge-Intensive Tasks in Large Language Models via Conditional Front-Door Adjustment(https://arxiv.org/abs/2508.16910)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, large language model</a></li>
<li><strong>Abstract: </strong>Large Language Models (LLMs) have shown impressive capabilities in natural language processing but still struggle to perform well on knowledge-intensive tasks that require deep reasoning and the integration of external knowledge. Although methods such as Retrieval-Augmented Generation (RAG) and Chain-of-Thought (CoT) have been proposed to enhance LLMs with external knowledge, they still suffer from internal bias in LLMs, which often leads to incorrect answers. In this paper, we propose a novel causal prompting framework, Conditional Front-Door Prompting (CFD-Prompting), which enables the unbiased estimation of the causal effect between the query and the answer, conditional on external knowledge, while mitigating internal bias. By constructing counterfactual external knowledge, our framework simulates how the query behaves under varying contexts, addressing the challenge that the query is fixed and is not amenable to direct causal intervention. Compared to the standard front-door adjustment, the conditional variant operates under weaker assumptions, enhancing both robustness and generalisability of the reasoning process. Extensive experiments across multiple LLMs and benchmark datasets demonstrate that CFD-Prompting significantly outperforms existing baselines in both accuracy and robustness.</li>
</ul>

<h3>Title: Reinforcement-Guided Hyper-Heuristic Hyperparameter Optimization for Fair and Explainable Spiking Neural Network-Based Financial Fraud Detection</h3>
<ul>
<li><strong>Authors: </strong>Sadman Mohammad Nasif, Md Abrar Jahin, M. F. Mridha</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.16915">https://arxiv.org/abs/2508.16915</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.16915">https://arxiv.org/pdf/2508.16915</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.16915]] Reinforcement-Guided Hyper-Heuristic Hyperparameter Optimization for Fair and Explainable Spiking Neural Network-Based Financial Fraud Detection(https://arxiv.org/abs/2508.16915)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, fair, interpretability, explainability</a></li>
<li><strong>Abstract: </strong>The growing adoption of home banking systems has heightened the risk of cyberfraud, necessitating fraud detection mechanisms that are not only accurate but also fair and explainable. While AI models have shown promise in this domain, they face key limitations, including computational inefficiency, the interpretability challenges of spiking neural networks (SNNs), and the complexity and convergence instability of hyper-heuristic reinforcement learning (RL)-based hyperparameter optimization. To address these issues, we propose a novel framework that integrates a Cortical Spiking Network with Population Coding (CSNPC) and a Reinforcement-Guided Hyper-Heuristic Optimizer for Spiking Systems (RHOSS). The CSNPC, a biologically inspired SNN, employs population coding for robust classification, while RHOSS uses Q-learning to dynamically select low-level heuristics for hyperparameter optimization under fairness and recall constraints. Embedded within the Modular Supervisory Framework for Spiking Network Training and Interpretation (MoSSTI), the system incorporates explainable AI (XAI) techniques, specifically, saliency-based attribution and spike activity profiling, to increase transparency. Evaluated on the Bank Account Fraud (BAF) dataset suite, our model achieves a $90.8\%$ recall at a strict $5\%$ false positive rate (FPR), outperforming state-of-the-art spiking and non-spiking models while maintaining over $98\%$ predictive equality across key demographic attributes. The explainability module further confirms that saliency attributions align with spiking dynamics, validating interpretability. These results demonstrate the potential of combining population-coded SNNs with reinforcement-guided hyper-heuristics for fair, transparent, and high-performance fraud detection in real-world financial applications.</li>
</ul>

<h3>Title: Structural Energy-Guided Sampling for View-Consistent Text-to-3D</h3>
<ul>
<li><strong>Authors: </strong>Qing Zhang, Jinguang Tong, Jie Hong, Jing Zhang, Xuesong Li</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.16917">https://arxiv.org/abs/2508.16917</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.16917">https://arxiv.org/pdf/2508.16917</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.16917]] Structural Energy-Guided Sampling for View-Consistent Text-to-3D(https://arxiv.org/abs/2508.16917)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>Text-to-3D generation often suffers from the Janus problem, where objects look correct from the front but collapse into duplicated or distorted geometry from other angles. We attribute this failure to viewpoint bias in 2D diffusion priors, which propagates into 3D optimization. To address this, we propose Structural Energy-Guided Sampling (SEGS), a training-free, plug-and-play framework that enforces multi-view consistency entirely at sampling time. SEGS defines a structural energy in a PCA subspace of intermediate U-Net features and injects its gradients into the denoising trajectory, steering geometry toward the intended viewpoint while preserving appearance fidelity. Integrated seamlessly into SDS/VSD pipelines, SEGS significantly reduces Janus artifacts, achieving improved geometric alignment and viewpoint consistency without retraining or weight modification.</li>
</ul>

<h3>Title: Being Kind Isn't Always Being Safe: Diagnosing Affective Hallucination in LLMs</h3>
<ul>
<li><strong>Authors: </strong>Sewon Kim, Jiwon Kim, Seungwoo Shin, Hyejin Chung, Daeun Moon, Yejin Kwon, Hyunsoo Yoon</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.16921">https://arxiv.org/abs/2508.16921</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.16921">https://arxiv.org/pdf/2508.16921</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.16921]] Being Kind Isn't Always Being Safe: Diagnosing Affective Hallucination in LLMs(https://arxiv.org/abs/2508.16921)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large Language Models (LLMs) are increasingly used in emotionally sensitive interactions, where their simulated empathy can create the illusion of genuine relational connection. We define this risk as Affective Hallucination, the production of emotionally immersive responses that foster illusory social presence despite the model's lack of affective capacity. To systematically diagnose and mitigate this risk, we introduce AHaBench, a benchmark of 500 mental health-related prompts with expert-informed reference responses, evaluated along three dimensions: Emotional Enmeshment, Illusion of Presence, and Fostering Overdependence. We further release AHaPairs, a 5K-instance preference dataset enabling Direct Preference Optimization (DPO) for alignment with emotionally responsible behavior. Experiments across multiple model families show that DPO fine-tuning substantially reduces affective hallucination without degrading core reasoning and knowledge performance. Human-model agreement analyses confirm that AHaBench reliably captures affective hallucination, validating it as an effective diagnostic tool. This work establishes affective hallucination as a distinct safety concern and provides practical resources for developing LLMs that are not only factually reliable but also psychologically safe. AHaBench and AHaPairs are accessible via this https URL, and code for fine-tuning and evaluation are in this https URL. Warning: This paper contains examples of mental health-related language that may be emotionally distressing.</li>
</ul>

<h3>Title: MSPCaps: A Multi-Scale Patchify Capsule Network with Cross-Agreement Routing for Visual Recognition</h3>
<ul>
<li><strong>Authors: </strong>Yudong Hu, Yueju Han, Rui Sun, Jinke Ren</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.16922">https://arxiv.org/abs/2508.16922</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.16922">https://arxiv.org/pdf/2508.16922</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.16922]] MSPCaps: A Multi-Scale Patchify Capsule Network with Cross-Agreement Routing for Visual Recognition(https://arxiv.org/abs/2508.16922)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Capsule Network (CapsNet) has demonstrated significant potential in visual recognition by capturing spatial relationships and part-whole hierarchies for learning equivariant feature representations. However, existing CapsNet and variants often rely on a single high-level feature map, overlooking the rich complementary information from multi-scale features. Furthermore, conventional feature fusion strategies (e.g., addition and concatenation) struggle to reconcile multi-scale feature discrepancies, leading to suboptimal classification performance. To address these limitations, we propose the Multi-Scale Patchify Capsule Network (MSPCaps), a novel architecture that integrates multi-scale feature learning and efficient capsule routing. Specifically, MSPCaps consists of three key components: a Multi-Scale ResNet Backbone (MSRB), a Patchify Capsule Layer (PatchifyCaps), and Cross-Agreement Routing (CAR) blocks. First, the MSRB extracts diverse multi-scale feature representations from input images, preserving both fine-grained details and global contextual information. Second, the PatchifyCaps partitions these multi-scale features into primary capsules using a uniform patch size, equipping the model with the ability to learn from diverse receptive fields. Finally, the CAR block adaptively routes the multi-scale capsules by identifying cross-scale prediction pairs with maximum agreement. Unlike the simple concatenation of multiple self-routing blocks, CAR ensures that only the most coherent capsules contribute to the final voting. Our proposed MSPCaps achieves remarkable scalability and superior robustness, consistently surpassing multiple baseline methods in terms of classification accuracy, with configurations ranging from a highly efficient Tiny model (344.3K parameters) to a powerful Large model (10.9M parameters), highlighting its potential in advancing feature representation learning.</li>
</ul>

<h3>Title: Attention Layers Add Into Low-Dimensional Residual Subspaces</h3>
<ul>
<li><strong>Authors: </strong>Junxuan Wang, Xuyang Ge, Wentao Shu, Zhengfu He, Xipeng Qiu</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.16929">https://arxiv.org/abs/2508.16929</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.16929">https://arxiv.org/pdf/2508.16929</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.16929]] Attention Layers Add Into Low-Dimensional Residual Subspaces(https://arxiv.org/abs/2508.16929)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer, large language model</a></li>
<li><strong>Abstract: </strong>While transformer models are widely believed to operate in high-dimensional hidden spaces, we show that attention outputs are confined to a surprisingly low-dimensional subspace, where about 60\% of the directions account for 99\% of the variance--a phenomenon that is induced by the attention output projection matrix and consistently observed across diverse model families and datasets. Critically, we find this low-rank structure as a fundamental cause of the prevalent dead feature problem in sparse dictionary learning, where it creates a mismatch between randomly initialized features and the intrinsic geometry of the activation space. Building on this insight, we propose a subspace-constrained training method for sparse autoencoders (SAEs), initializing feature directions into the active subspace of activations. Our approach reduces dead features from 87\% to below 1\% in Attention Output SAEs with 1M features, and can further extend to other sparse dictionary learning methods. Our findings provide both new insights into the geometry of attention and practical tools for improving sparse dictionary learning in large language models.</li>
</ul>

<h3>Title: Degree of Staleness-Aware Data Updating in Federated Learning</h3>
<ul>
<li><strong>Authors: </strong>Tao Liu, Xuehe Wang</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.16931">https://arxiv.org/abs/2508.16931</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.16931">https://arxiv.org/pdf/2508.16931</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.16931]] Degree of Staleness-Aware Data Updating in Federated Learning(https://arxiv.org/abs/2508.16931)</code><input type="text"></li>
<li><strong>Keywords: </strong>federate</a></li>
<li><strong>Abstract: </strong>Handling data staleness remains a significant challenge in federated learning with highly time-sensitive tasks, where data is generated continuously and data staleness largely affects model performance. Although recent works attempt to optimize data staleness by determining local data update frequency or client selection strategy, none of them explore taking both data staleness and data volume into consideration. In this paper, we propose DUFL(Data Updating in Federated Learning), an incentive mechanism featuring an innovative local data update scheme manipulated by three knobs: the server's payment, outdated data conservation rate, and clients' fresh data collection volume, to coordinate staleness and volume of local data for best utilities. To this end, we introduce a novel metric called DoS(the Degree of Staleness) to quantify data staleness and conduct a theoretic analysis illustrating the quantitative relationship between DoS and model performance. We model DUFL as a two-stage Stackelberg game with dynamic constraint, deriving the optimal local data update strategy for each client in closed-form and the approximately optimal strategy for the server. Experimental results on real-world datasets demonstrate the significant performance of our approach.</li>
</ul>

<h3>Title: Addressing Annotation Scarcity in Hyperspectral Brain Image Segmentation with Unsupervised Domain Adaptation</h3>
<ul>
<li><strong>Authors: </strong>Tim Mach, Daniel Rueckert, Alex Berger, Laurin Lux, Ivan Ezhov</a></li>
<li><strong>Subjects: </strong>cs.CV, q-bio.QM</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.16934">https://arxiv.org/abs/2508.16934</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.16934">https://arxiv.org/pdf/2508.16934</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.16934]] Addressing Annotation Scarcity in Hyperspectral Brain Image Segmentation with Unsupervised Domain Adaptation(https://arxiv.org/abs/2508.16934)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>This work presents a novel deep learning framework for segmenting cerebral vasculature in hyperspectral brain images. We address the critical challenge of severe label scarcity, which impedes conventional supervised training. Our approach utilizes a novel unsupervised domain adaptation methodology, using a small, expert-annotated ground truth alongside unlabeled data. Quantitative and qualitative evaluations confirm that our method significantly outperforms existing state-of-the-art approaches, demonstrating the efficacy of domain adaptation for label-scarce biomedical imaging tasks.</li>
</ul>

<h3>Title: NAT: Learning to Attack Neurons for Enhanced Adversarial Transferability</h3>
<ul>
<li><strong>Authors: </strong>Krishna Kanth Nakka, Alexandre Alahi</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.16937">https://arxiv.org/abs/2508.16937</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.16937">https://arxiv.org/pdf/2508.16937</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.16937]] NAT: Learning to Attack Neurons for Enhanced Adversarial Transferability(https://arxiv.org/abs/2508.16937)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack</a></li>
<li><strong>Abstract: </strong>The generation of transferable adversarial perturbations typically involves training a generator to maximize embedding separation between clean and adversarial images at a single mid-layer of a source model. In this work, we build on this approach and introduce Neuron Attack for Transferability (NAT), a method designed to target specific neuron within the embedding. Our approach is motivated by the observation that previous layer-level optimizations often disproportionately focus on a few neurons representing similar concepts, leaving other neurons within the attacked layer minimally affected. NAT shifts the focus from embedding-level separation to a more fundamental, neuron-specific approach. We find that targeting individual neurons effectively disrupts the core units of the neural network, providing a common basis for transferability across different models. Through extensive experiments on 41 diverse ImageNet models and 9 fine-grained models, NAT achieves fooling rates that surpass existing baselines by over 14\% in cross-model and 4\% in cross-domain settings. Furthermore, by leveraging the complementary attacking capabilities of the trained generators, we achieve impressive fooling rates within just 10 queries. Our code is available at: this https URL</li>
</ul>

<h3>Title: Sig-DEG for Distillation: Making Diffusion Models Faster and Lighter</h3>
<ul>
<li><strong>Authors: </strong>Lei Jiang, Wen Ge, Niels Cariou-Kotlarek, Mingxuan Yi, Po-Yu Chen, Lingyi Yang, Francois Buet-Golfouse, Gaurav Mittal, Hao Ni</a></li>
<li><strong>Subjects: </strong>cs.LG, math.PR, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.16939">https://arxiv.org/abs/2508.16939</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.16939">https://arxiv.org/pdf/2508.16939</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.16939]] Sig-DEG for Distillation: Making Diffusion Models Faster and Lighter(https://arxiv.org/abs/2508.16939)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, generative</a></li>
<li><strong>Abstract: </strong>Diffusion models have achieved state-of-the-art results in generative modelling but remain computationally intensive at inference time, often requiring thousands of discretization steps. To this end, we propose Sig-DEG (Signature-based Differential Equation Generator), a novel generator for distilling pre-trained diffusion models, which can universally approximate the backward diffusion process at a coarse temporal resolution. Inspired by high-order approximations of stochastic differential equations (SDEs), Sig-DEG leverages partial signatures to efficiently summarize Brownian motion over sub-intervals and adopts a recurrent structure to enable accurate global approximation of the SDE solution. Distillation is formulated as a supervised learning task, where Sig-DEG is trained to match the outputs of a fine-resolution diffusion model on a coarse time grid. During inference, Sig-DEG enables fast generation, as the partial signature terms can be simulated exactly without requiring fine-grained Brownian paths. Experiments demonstrate that Sig-DEG achieves competitive generation quality while reducing the number of inference steps by an order of magnitude. Our results highlight the effectiveness of signature-based approximations for efficient generative modeling.</li>
</ul>

<h3>Title: HieroAction: Hierarchically Guided VLM for Fine-Grained Action Analysis</h3>
<ul>
<li><strong>Authors: </strong>Junhao Wu, Xiuer Gu, Zhiying Li, Yeying Jin, Yunfeng Diao, Zhiyu Li, Zhenbo Song, Xiaomei Zhang, Zhaoxin Fan</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.16942">https://arxiv.org/abs/2508.16942</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.16942">https://arxiv.org/pdf/2508.16942</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.16942]] HieroAction: Hierarchically Guided VLM for Fine-Grained Action Analysis(https://arxiv.org/abs/2508.16942)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability</a></li>
<li><strong>Abstract: </strong>Evaluating human actions with clear and detailed feedback is important in areas such as sports, healthcare, and robotics, where decisions rely not only on final outcomes but also on interpretable reasoning. However, most existing methods provide only a final score without explanation or detailed analysis, limiting their practical applicability. To address this, we introduce HieroAction, a vision-language model that delivers accurate and structured assessments of human actions. HieroAction builds on two key ideas: (1) Stepwise Action Reasoning, a tailored chain of thought process designed specifically for action assessment, which guides the model to evaluate actions step by step, from overall recognition through sub action analysis to final scoring, thus enhancing interpretability and structured understanding; and (2) Hierarchical Policy Learning, a reinforcement learning strategy that enables the model to learn fine grained sub action dynamics and align them with high level action quality, thereby improving scoring precision. The reasoning pathway structures the evaluation process, while policy learning refines each stage through reward based optimization. Their integration ensures accurate and interpretable assessments, as demonstrated by superior performance across multiple benchmark datasets. Code will be released upon acceptance.</li>
</ul>

<h3>Title: Breaking the Exploration Bottleneck: Rubric-Scaffolded Reinforcement Learning for General LLM Reasoning</h3>
<ul>
<li><strong>Authors: </strong>Yang Zhou, Sunzhu Li, Shunyu Liu, Wenkai Fang, Jiale Zhao, Jingwen Yang, Jianwei Lv, Kongcheng Zhang, Yihe Zhou, Hengtong Lu, Wei Chen, Yan Xie, Mingli Song</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.16949">https://arxiv.org/abs/2508.16949</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.16949">https://arxiv.org/pdf/2508.16949</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.16949]] Breaking the Exploration Bottleneck: Rubric-Scaffolded Reinforcement Learning for General LLM Reasoning(https://arxiv.org/abs/2508.16949)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, large language model</a></li>
<li><strong>Abstract: </strong>Recent advances in Large Language Models (LLMs) have underscored the potential of Reinforcement Learning (RL) to facilitate the emergence of reasoning capabilities. Despite the encouraging results, a fundamental dilemma persists as RL improvement relies on learning from high-quality samples, yet the exploration for such samples remains bounded by the inherent limitations of LLMs. This, in effect, creates an undesirable cycle in which what cannot be explored cannot be learned. In this work, we propose Rubric-Scaffolded Reinforcement Learning (RuscaRL), a novel instructional scaffolding framework designed to break the exploration bottleneck for general LLM reasoning. Specifically, RuscaRL introduces checklist-style rubrics as (1) explicit scaffolding for exploration during rollout generation, where different rubrics are provided as external guidance within task instructions to steer diverse high-quality responses. This guidance is gradually decayed over time, encouraging the model to internalize the underlying reasoning patterns; (2) verifiable rewards for exploitation during model training, where we can obtain robust LLM-as-a-Judge scores using rubrics as references, enabling effective RL on general reasoning tasks. Extensive experiments demonstrate the superiority of the proposed RuscaRL across various benchmarks, effectively expanding reasoning boundaries under the best-of-N evaluation. Notably, RuscaRL significantly boosts Qwen-2.5-7B-Instruct from 23.6 to 50.3 on HealthBench-500, surpassing GPT-4.1. Furthermore, our fine-tuned variant on Qwen3-30B-A3B-Instruct achieves 61.1 on HealthBench-500, outperforming leading LLMs including OpenAI-o3.</li>
</ul>

<h3>Title: Disentangling Polysemantic Neurons with a Null-Calibrated Polysemanticity Index and Causal Patch Interventions</h3>
<ul>
<li><strong>Authors: </strong>Manan Gupta, Dhruv Kumar</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.16950">https://arxiv.org/abs/2508.16950</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.16950">https://arxiv.org/pdf/2508.16950</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.16950]] Disentangling Polysemantic Neurons with a Null-Calibrated Polysemanticity Index and Causal Patch Interventions(https://arxiv.org/abs/2508.16950)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, interpretability</a></li>
<li><strong>Abstract: </strong>Neural networks often contain polysemantic neurons that respond to multiple, sometimes unrelated, features, complicating mechanistic interpretability. We introduce the Polysemanticity Index (PSI), a null-calibrated metric that quantifies when a neuron's top activations decompose into semantically distinct clusters. PSI multiplies three independently calibrated components: geometric cluster quality (S), alignment to labeled categories (Q), and open-vocabulary semantic distinctness via CLIP (D). On a pretrained ResNet-50 evaluated with Tiny-ImageNet images, PSI identifies neurons whose activation sets split into coherent, nameable prototypes, and reveals strong depth trends: later layers exhibit substantially higher PSI than earlier layers. We validate our approach with robustness checks (varying hyperparameters, random seeds, and cross-encoder text heads), breadth analyses (comparing class-only vs. open-vocabulary concepts), and causal patch-swap interventions. In particular, aligned patch replacements increase target-neuron activation significantly more than non-aligned, random, shuffled-position, or ablate-elsewhere controls. PSI thus offers a principled and practical lever for discovering, quantifying, and studying polysemantic units in neural networks.</li>
</ul>

<h3>Title: RPD-Diff: Region-Adaptive Physics-Guided Diffusion Model for Visibility Enhancement under Dense and Non-Uniform Haze</h3>
<ul>
<li><strong>Authors: </strong>Ruicheng Zhang, Puxin Yan, Zeyu Zhang, Yicheng Chang, Hongyi Chen, Zhi Jin</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.16956">https://arxiv.org/abs/2508.16956</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.16956">https://arxiv.org/pdf/2508.16956</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.16956]] RPD-Diff: Region-Adaptive Physics-Guided Diffusion Model for Visibility Enhancement under Dense and Non-Uniform Haze(https://arxiv.org/abs/2508.16956)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, diffusion</a></li>
<li><strong>Abstract: </strong>Single-image dehazing under dense and non-uniform haze conditions remains challenging due to severe information degradation and spatial heterogeneity. Traditional diffusion-based dehazing methods struggle with insufficient generation conditioning and lack of adaptability to spatially varying haze distributions, which leads to suboptimal restoration. To address these limitations, we propose RPD-Diff, a Region-adaptive Physics-guided Dehazing Diffusion Model for robust visibility enhancement in complex haze scenarios. RPD-Diff introduces a Physics-guided Intermediate State Targeting (PIST) strategy, which leverages physical priors to reformulate the diffusion Markov chain by generation target transitions, mitigating the issue of insufficient conditioning in dense haze scenarios. Additionally, the Haze-Aware Denoising Timestep Predictor (HADTP) dynamically adjusts patch-specific denoising timesteps employing a transmission map cross-attention mechanism, adeptly managing non-uniform haze distributions. Extensive experiments across four real-world datasets demonstrate that RPD-Diff achieves state-of-the-art performance in challenging dense and non-uniform haze scenarios, delivering high-quality, haze-free images with superior detail clarity and color fidelity.</li>
</ul>

<h3>Title: Robust Diagram Reasoning: A Framework for Enhancing LVLM Performance on Visually Perturbed Scientific Diagrams</h3>
<ul>
<li><strong>Authors: </strong>Minghao Zhou, Rafael Souza, Yaqian Hu, Luming Che</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.16972">https://arxiv.org/abs/2508.16972</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.16972">https://arxiv.org/pdf/2508.16972</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.16972]] Robust Diagram Reasoning: A Framework for Enhancing LVLM Performance on Visually Perturbed Scientific Diagrams(https://arxiv.org/abs/2508.16972)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, large language model</a></li>
<li><strong>Abstract: </strong>Large Language Models (LLMs) and their multimodal variants (LVLMs) hold immense promise for scientific and engineering applications, particularly in processing visual information like scientific diagrams. However, their practical deployment is hindered by a critical lack of robustness to common visual perturbations such as noise, blur, and occlusions, which are prevalent in real-world scientific documents. Existing evaluation benchmarks largely overlook this challenge, leaving the robust reasoning capabilities of LVLMs on visually degraded scientific diagrams underexplored. To address this, we introduce the Robust Diagram Reasoning (RDR) framework, a novel approach designed to enhance and rigorously evaluate LVLMs' performance under such conditions. At its core, RDR employs an Adaptive Multi-View & Consistency Verification (AMCV) mechanism, which involves generating multiple perturbed versions of a diagram, performing parallel inference, and then applying a consistency-based self-correction loop. We also propose two new metrics, Perturbation Robustness Score (PRS) and Visual Degradation Consistency (VDC), to quantify robustness. Furthermore, we construct SciDiagram-Robust, the first large-scale scientific diagram question-answering dataset specifically augmented with diverse, programmatically generated visual perturbations. Our extensive experiments demonstrate that even state-of-the-art closed-source LVLMs like GPT-4V exhibit significant performance degradation when faced with perturbed inputs (Clean Accuracy 85.2% vs. PRS 72.1%).</li>
</ul>

<h3>Title: Hierarchical Contextual Grounding LVLM: Enhancing Fine-Grained Visual-Language Understanding with Robust Grounding</h3>
<ul>
<li><strong>Authors: </strong>Leilei Guo, Antonio Carlos Rivera, Peiyu Tang, Haoxuan Ren, Zheyu Song</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.16974">https://arxiv.org/abs/2508.16974</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.16974">https://arxiv.org/pdf/2508.16974</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.16974]] Hierarchical Contextual Grounding LVLM: Enhancing Fine-Grained Visual-Language Understanding with Robust Grounding(https://arxiv.org/abs/2508.16974)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, large language model</a></li>
<li><strong>Abstract: </strong>Large Language Models (LLMs) and Vision-Language Large Models (LVLMs) have achieved remarkable progress in natural language processing and multimodal understanding. Despite their impressive generalization capabilities, current LVLMs often exhibit insufficient robustness, proneness to hallucination, and reasoning errors in complex real-world scenarios, particularly when precise image region localization and fine-grained visual reasoning are required. To address these limitations, we propose the Hierarchical Contextual Grounding LVLM (HCG-LVLM), a novel architecture that mimics human coarse-to-fine cognitive processing. HCG-LVLM employs a two-layered approach: a Global Contextual Perception layer for initial broad understanding and a Fine-grained Local Grounding layer. The latter incorporates a Local Detail Enhancement Module to extract high-resolution features and a Semantic Consistency Validator to ensure accurate, hallucination-free visual-language alignment. Through an adaptive fusion mechanism, information from both layers is integrated for robust and precise outputs. Extensive experiments on challenging datasets, including GQA, A-OKVQA for fine-grained VQA, and RefCOCO/+/g for Referring Expression Comprehension, demonstrate that HCG-LVLM consistently outperforms state-of-the-art models such as Flamingo, BLIP-2, and MiniGPT-4. Our model achieves superior accuracy and significantly reduces hallucination, validating the effectiveness of its hierarchical design in enhancing fine-grained visual-language understanding and precise grounding capabilities.</li>
</ul>

<h3>Title: Combating Digitally Altered Images: Deepfake Detection</h3>
<ul>
<li><strong>Authors: </strong>Saksham Kumar, Rhythm Narang</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.16975">https://arxiv.org/abs/2508.16975</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.16975">https://arxiv.org/pdf/2508.16975</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.16975]] Combating Digitally Altered Images: Deepfake Detection(https://arxiv.org/abs/2508.16975)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, transformer</a></li>
<li><strong>Abstract: </strong>The rise of Deepfake technology to generate hyper-realistic manipulated images and videos poses a significant challenge to the public and relevant authorities. This study presents a robust Deepfake detection based on a modified Vision Transformer(ViT) model, trained to distinguish between real and Deepfake images. The model has been trained on a subset of the OpenForensics Dataset with multiple augmentation techniques to increase robustness for diverse image manipulations. The class imbalance issues are handled by oversampling and a train-validation split of the dataset in a stratified manner. Performance is evaluated using the accuracy metric on the training and testing datasets, followed by a prediction score on a random image of people, irrespective of their realness. The model demonstrates state-of-the-art results on the test dataset to meticulously detect Deepfake images.</li>
</ul>

<h3>Title: Decoding Alignment: A Critical Survey of LLM Development Initiatives through Value-setting and Data-centric Lens</h3>
<ul>
<li><strong>Authors: </strong>Ilias Chalkidis</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.16982">https://arxiv.org/abs/2508.16982</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.16982">https://arxiv.org/pdf/2508.16982</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.16982]] Decoding Alignment: A Critical Survey of LLM Development Initiatives through Value-setting and Data-centric Lens(https://arxiv.org/abs/2508.16982)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>AI Alignment, primarily in the form of Reinforcement Learning from Human Feedback (RLHF), has been a cornerstone of the post-training phase in developing Large Language Models (LLMs). It has also been a popular research topic across various disciplines beyond Computer Science, including Philosophy and Law, among others, highlighting the socio-technical challenges involved. Nonetheless, except for the computational techniques related to alignment, there has been limited focus on the broader picture: the scope of these processes, which primarily rely on the selected objectives (values), and the data collected and used to imprint such objectives into the models. This work aims to reveal how alignment is understood and applied in practice from a value-setting and data-centric perspective. For this purpose, we investigate and survey (`audit') publicly available documentation released by 6 LLM development initiatives by 5 leading organizations shaping this technology, focusing on proprietary (OpenAI's GPT, Anthropic's Claude, Google's Gemini) and open-weight (Meta's Llama, Google's Gemma, and Alibaba's Qwen) initiatives, all published in the last 3 years. The findings are documented in detail per initiative, while there is also an overall summary concerning different aspects, mainly from a value-setting and data-centric perspective. On the basis of our findings, we discuss a series of broader related concerns.</li>
</ul>

<h3>Title: ReFactX: Scalable Reasoning with Reliable Facts via Constrained Generation</h3>
<ul>
<li><strong>Authors: </strong>Riccardo Pozzi, Matteo Palmonari, Andrea Coletta, Luigi Bellomarini, Jens Lehmann, Sahar Vahdati</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.16983">https://arxiv.org/abs/2508.16983</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.16983">https://arxiv.org/pdf/2508.16983</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.16983]] ReFactX: Scalable Reasoning with Reliable Facts via Constrained Generation(https://arxiv.org/abs/2508.16983)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Knowledge gaps and hallucinations are persistent challenges for Large Language Models (LLMs), which generate unreliable responses when lacking the necessary information to fulfill user instructions. Existing approaches, such as Retrieval-Augmented Generation (RAG) and tool use, aim to address these issues by incorporating external knowledge. Yet, they rely on additional models or services, resulting in complex pipelines, potential error propagation, and often requiring the model to process a large number of tokens. In this paper, we present a scalable method that enables LLMs to access external knowledge without depending on retrievers or auxiliary models. Our approach uses constrained generation with a pre-built prefix-tree index. Triples from a Knowledge Graph are verbalized in textual facts, tokenized, and indexed in a prefix tree for efficient access. During inference, to acquire external knowledge, the LLM generates facts with constrained generation which allows only sequences of tokens that form an existing fact. We evaluate our proposal on Question Answering and show that it scales to large knowledge bases (800 million facts), adapts to domain-specific data, and achieves effective results. These gains come with minimal generation-time overhead. ReFactX code is available at this https URL.</li>
</ul>

<h3>Title: HiCache: Training-free Acceleration of Diffusion Models via Hermite Polynomial-based Feature Caching</h3>
<ul>
<li><strong>Authors: </strong>Liang Feng, Shikang Zheng, Jiacheng Liu, Yuqi Lin, Qinming Zhou, Peiliang Cai, Xinyu Wang, Junjie Chen, Chang Zou, Yue Ma, Linfeng Zhang</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.16984">https://arxiv.org/abs/2508.16984</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.16984">https://arxiv.org/pdf/2508.16984</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.16984]] HiCache: Training-free Acceleration of Diffusion Models via Hermite Polynomial-based Feature Caching(https://arxiv.org/abs/2508.16984)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, transformer</a></li>
<li><strong>Abstract: </strong>Diffusion models have achieved remarkable success in content generation but suffer from prohibitive computational costs due to iterative sampling. While recent feature caching methods tend to accelerate inference through temporal extrapolation, these methods still suffer from server quality loss due to the failure in modeling the complex dynamics of feature evolution. To solve this problem, this paper presents HiCache, a training-free acceleration framework that fundamentally improves feature prediction by aligning mathematical tools with empirical properties. Our key insight is that feature derivative approximations in Diffusion Transformers exhibit multivariate Gaussian characteristics, motivating the use of Hermite polynomials-the potentially theoretically optimal basis for Gaussian-correlated processes. Besides, We further introduce a dual-scaling mechanism that ensures numerical stability while preserving predictive accuracy. Extensive experiments demonstrate HiCache's superiority: achieving 6.24x speedup on FLUX.1-dev while exceeding baseline quality, maintaining strong performance across text-to-image, video generation, and super-resolution tasks. Core implementation is provided in the appendix, with complete code to be released upon acceptance.</li>
</ul>

<h3>Title: Unveiling the Latent Directions of Reflection in Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Fu-Chieh Chang, Yu-Ting Lee, Pei-Yuan Wu</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.16989">https://arxiv.org/abs/2508.16989</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.16989">https://arxiv.org/pdf/2508.16989</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.16989]] Unveiling the Latent Directions of Reflection in Large Language Models(https://arxiv.org/abs/2508.16989)</code><input type="text"></li>
<li><strong>Keywords: </strong>defense, attack, large language model</a></li>
<li><strong>Abstract: </strong>Reflection, the ability of large language models (LLMs) to evaluate and revise their own reasoning, has been widely used to improve performance on complex reasoning tasks. Yet, most prior work emphasizes designing reflective prompting strategies or reinforcement learning objectives, leaving the inner mechanisms of reflection underexplored. In this paper, we investigate reflection through the lens of latent directions in model activations. We propose a methodology based on activation steering to characterize how instructions with different reflective intentions: no reflection, intrinsic reflection, and triggered reflection. By constructing steering vectors between these reflection levels, we demonstrate that (1) new reflection-inducing instructions can be systematically identified, (2) reflective behavior can be directly enhanced or suppressed through activation interventions, and (3) suppressing reflection is considerably easier than stimulating it. Experiments on GSM8k-adv with Qwen2.5-3B and Gemma3-4B reveal clear stratification across reflection levels, and steering interventions confirm the controllability of reflection. Our findings highlight both opportunities (e.g., reflection-enhancing defenses) and risks (e.g., adversarial inhibition of reflection in jailbreak attacks). This work opens a path toward mechanistic understanding of reflective reasoning in LLMs.</li>
</ul>

<h3>Title: Towards Principled Analysis and Mitigation of Space Cyber Risks</h3>
<ul>
<li><strong>Authors: </strong>Ekzhin Ear</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.16991">https://arxiv.org/abs/2508.16991</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.16991">https://arxiv.org/pdf/2508.16991</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.16991]] Towards Principled Analysis and Mitigation of Space Cyber Risks(https://arxiv.org/abs/2508.16991)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack</a></li>
<li><strong>Abstract: </strong>Space infrastructures have become an underpinning of modern society, but their associated cyber risks are little understood. This Dissertation advances the state-of-the-art via four contributions. (i) It introduces an innovative framework for characterizing real-world cyber attacks against space infrastructures, or space cyber attacks, including a novel methodology for coping with missing data and three novel metrics. A case study demonstrates the usefulness of the framework on 108 real-world space cyber attacks. (ii) This Dissertation characterizes the state-of-the-practice in space cyber risk analysis and mitigation, namely the Notional Risk Scores (NRS) within the Space Attack Research and Tactic Analysis (SPARTA) framework. (iii) We propose a set of desired properties that should be satisfied by any competent space cyber risk analysis and mitigation tool and applies them to assess two industrial space cyber risk analysis and mitigation tools. (iv) The study introduces a novel framework to analyze and mitigate space cyber risks by explicitly modeling space cyber attack cascading effects and presenting algorithms for mission risk analysis and mission hardening. We demonstrate the usefulness of the framework by applying it to analyze and mitigate space cyber risks, with testbed-based validation.</li>
</ul>

<h3>Title: DeAR: Dual-Stage Document Reranking with Reasoning Agents via LLM Distillation</h3>
<ul>
<li><strong>Authors: </strong>Abdelrahman Abdallah, Jamshid Mozafari, Bhawna Piryani, Adam Jatowt</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.IR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.16998">https://arxiv.org/abs/2508.16998</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.16998">https://arxiv.org/pdf/2508.16998</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.16998]] DeAR: Dual-Stage Document Reranking with Reasoning Agents via LLM Distillation(https://arxiv.org/abs/2508.16998)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, interpretability, large language model</a></li>
<li><strong>Abstract: </strong>Large Language Models (LLMs) have transformed listwise document reranking by enabling global reasoning over candidate sets, yet single models often struggle to balance fine-grained relevance scoring with holistic cross-document analysis. We propose \textbf{De}ep\textbf{A}gent\textbf{R}ank (\textbf{\DeAR}), an open-source framework that decouples these tasks through a dual-stage approach, achieving superior accuracy and interpretability. In \emph{Stage 1}, we distill token-level relevance signals from a frozen 13B LLaMA teacher into a compact \{3, 8\}B student model using a hybrid of cross-entropy, RankNet, and KL divergence losses, ensuring robust pointwise scoring. In \emph{Stage 2}, we attach a second LoRA adapter and fine-tune on 20K GPT-4o-generated chain-of-thought permutations, enabling listwise reasoning with natural-language justifications. Evaluated on TREC-DL19/20, eight BEIR datasets, and NovelEval-2306, \DeAR surpasses open-source baselines by +5.1 nDCG@5 on DL20 and achieves 90.97 nDCG@10 on NovelEval, outperforming GPT-4 by +3.09. Without fine-tuning on Wikipedia, DeAR also excels in open-domain QA, achieving 54.29 Top-1 accuracy on Natural Questions, surpassing baselines like MonoT5, UPR, and RankGPT. Ablations confirm that dual-loss distillation ensures stable calibration, making \DeAR a highly effective and interpretable solution for modern reranking systems.\footnote{Dataset and code available at this https URL.}.</li>
</ul>

<h3>Title: Planning for Success: Exploring LLM Long-term Planning Capabilities in Table Understanding</h3>
<ul>
<li><strong>Authors: </strong>Thi-Nhung Nguyen, Hoang Ngo, Dinh Phung, Thuy-Trang Vu, Dat Quoc Nguyen</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.17005">https://arxiv.org/abs/2508.17005</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.17005">https://arxiv.org/pdf/2508.17005</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.17005]] Planning for Success: Exploring LLM Long-term Planning Capabilities in Table Understanding(https://arxiv.org/abs/2508.17005)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Table understanding is key to addressing challenging downstream tasks such as table-based question answering and fact verification. Recent works have focused on leveraging Chain-of-Thought and question decomposition to solve complex questions requiring multiple operations on tables. However, these methods often suffer from a lack of explicit long-term planning and weak inter-step connections, leading to miss constraints within questions. In this paper, we propose leveraging the long-term planning capabilities of large language models (LLMs) to enhance table understanding. Our approach enables the execution of a long-term plan, where the steps are tightly interconnected and serve the ultimate goal, an aspect that methods based on Chain-of-Thought and question decomposition lack. In addition, our method effectively minimizes the inclusion of unnecessary details in the process of solving the next short-term goals, a limitation of methods based on Chain-of-Thought. Extensive experiments demonstrate that our method outperforms strong baselines and achieves state-of-the-art performance on WikiTableQuestions and TabFact datasets.</li>
</ul>

<h3>Title: An Efficient Dual-Line Decoder Network with Multi-Scale Convolutional Attention for Multi-organ Segmentation</h3>
<ul>
<li><strong>Authors: </strong>Riad Hassan, M. Rubaiyat Hossain Mondal, Sheikh Iqbal Ahamed, Fahad Mostafa, Md Mostafijur Rahman</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.17007">https://arxiv.org/abs/2508.17007</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.17007">https://arxiv.org/pdf/2508.17007</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.17007]] An Efficient Dual-Line Decoder Network with Multi-Scale Convolutional Attention for Multi-organ Segmentation(https://arxiv.org/abs/2508.17007)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, segmentation</a></li>
<li><strong>Abstract: </strong>Proper segmentation of organs-at-risk is important for radiation therapy, surgical planning, and diagnostic decision-making in medical image analysis. While deep learning-based segmentation architectures have made significant progress, they often fail to balance segmentation accuracy with computational efficiency. Most of the current state-of-the-art methods either prioritize performance at the cost of high computational complexity or compromise accuracy for efficiency. This paper addresses this gap by introducing an efficient dual-line decoder segmentation network (EDLDNet). The proposed method features a noisy decoder, which learns to incorporate structured perturbation at training time for better model robustness, yet at inference time only the noise-free decoder is executed, leading to lower computational cost. Multi-Scale convolutional Attention Modules (MSCAMs), Attention Gates (AGs), and Up-Convolution Blocks (UCBs) are further utilized to optimize feature representation and boost segmentation performance. By leveraging multi-scale segmentation masks from both decoders, we also utilize a mutation-based loss function to enhance the model's generalization. Our approach outperforms SOTA segmentation architectures on four publicly available medical imaging datasets. EDLDNet achieves SOTA performance with an 84.00% Dice score on the Synapse dataset, surpassing baseline model like UNet by 13.89% in Dice score while significantly reducing Multiply-Accumulate Operations (MACs) by 89.7%. Compared to recent approaches like EMCAD, our EDLDNet not only achieves higher Dice score but also maintains comparable computational efficiency. The outstanding performance across diverse datasets establishes EDLDNet's strong generalization, computational efficiency, and robustness. The source code, pre-processed data, and pre-trained weights will be available at this https URL .</li>
</ul>

<h3>Title: EduRABSA: An Education Review Dataset for Aspect-based Sentiment Analysis Tasks</h3>
<ul>
<li><strong>Authors: </strong>Yan Cathy Hua, Paul Denny, J√∂rg Wicker, Katerina Taskova</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.17008">https://arxiv.org/abs/2508.17008</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.17008">https://arxiv.org/pdf/2508.17008</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.17008]] EduRABSA: An Education Review Dataset for Aspect-based Sentiment Analysis Tasks(https://arxiv.org/abs/2508.17008)</code><input type="text"></li>
<li><strong>Keywords: </strong>protect, extraction</a></li>
<li><strong>Abstract: </strong>Every year, most educational institutions seek and receive an enormous volume of text feedback from students on courses, teaching, and overall experience. Yet, turning this raw feedback into useful insights is far from straightforward. It has been a long-standing challenge to adopt automatic opinion mining solutions for such education review text data due to the content complexity and low-granularity reporting requirements. Aspect-based Sentiment Analysis (ABSA) offers a promising solution with its rich, sub-sentence-level opinion mining capabilities. However, existing ABSA research and resources are very heavily focused on the commercial domain. In education, they are scarce and hard to develop due to limited public datasets and strict data protection. A high-quality, annotated dataset is urgently needed to advance research in this under-resourced area. In this work, we present EduRABSA (Education Review ABSA), the first public, annotated ABSA education review dataset that covers three review subject types (course, teaching staff, university) in the English language and all main ABSA tasks, including the under-explored implicit aspect and implicit opinion extraction. We also share ASQE-DPT (Data Processing Tool), an offline, lightweight, installation-free manual data annotation tool that generates labelled datasets for comprehensive ABSA tasks from a single-task annotation. Together, these resources contribute to the ABSA community and education domain by removing the dataset barrier, supporting research transparency and reproducibility, and enabling the creation and sharing of further resources. The dataset, annotation tool, and scripts and statistics for dataset processing and sampling are available at this https URL.</li>
</ul>

<h3>Title: Contrastive Prompt Clustering for Weakly Supervised Semantic Segmentation</h3>
<ul>
<li><strong>Authors: </strong>Wangyu Wu, Zhenhong Chen, Xiaowen Ma, Wenqiao Zhang, Xianglin Qiu, Siqi Song, Xiaowei Huang, Fei Ma, Jimin Xiao</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.17009">https://arxiv.org/abs/2508.17009</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.17009">https://arxiv.org/pdf/2508.17009</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.17009]] Contrastive Prompt Clustering for Weakly Supervised Semantic Segmentation(https://arxiv.org/abs/2508.17009)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model, segmentation</a></li>
<li><strong>Abstract: </strong>Weakly Supervised Semantic Segmentation (WSSS) with image-level labels has gained attention for its cost-effectiveness. Most existing methods emphasize inter-class separation, often neglecting the shared semantics among related categories and lacking fine-grained discrimination. To address this, we propose Contrastive Prompt Clustering (CPC), a novel WSSS framework. CPC exploits Large Language Models (LLMs) to derive category clusters that encode intrinsic inter-class relationships, and further introduces a class-aware patch-level contrastive loss to enforce intra-class consistency and inter-class separation. This hierarchical design leverages clusters as coarse-grained semantic priors while preserving fine-grained boundaries, thereby reducing confusion among visually similar categories. Experiments on PASCAL VOC 2012 and MS COCO 2014 demonstrate that CPC surpasses existing state-of-the-art methods in WSSS.</li>
</ul>

<h3>Title: Dual Orthogonal Guidance for Robust Diffusion-based Handwritten Text Generation</h3>
<ul>
<li><strong>Authors: </strong>Konstantina Nikolaidou, George Retsinas, Giorgos Sfikas, Silvia Cascianelli, Rita Cucchiara, Marcus Liwicki</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.17017">https://arxiv.org/abs/2508.17017</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.17017">https://arxiv.org/pdf/2508.17017</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.17017]] Dual Orthogonal Guidance for Robust Diffusion-based Handwritten Text Generation(https://arxiv.org/abs/2508.17017)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, diffusion</a></li>
<li><strong>Abstract: </strong>Diffusion-based Handwritten Text Generation (HTG) approaches achieve impressive results on frequent, in-vocabulary words observed at training time and on regular styles. However, they are prone to memorizing training samples and often struggle with style variability and generation clarity. In particular, standard diffusion models tend to produce artifacts or distortions that negatively affect the readability of the generated text, especially when the style is hard to produce. To tackle these issues, we propose a novel sampling guidance strategy, Dual Orthogonal Guidance (DOG), that leverages an orthogonal projection of a negatively perturbed prompt onto the original positive prompt. This approach helps steer the generation away from artifacts while maintaining the intended content, and encourages more diverse, yet plausible, outputs. Unlike standard Classifier-Free Guidance (CFG), which relies on unconditional predictions and produces noise at high guidance scales, DOG introduces a more stable, disentangled direction in the latent space. To control the strength of the guidance across the denoising process, we apply a triangular schedule: weak at the start and end of denoising, when the process is most sensitive, and strongest in the middle steps. Experimental results on the state-of-the-art DiffusionPen and One-DM demonstrate that DOG improves both content clarity and style variability, even for out-of-vocabulary words and challenging writing styles.</li>
</ul>

<h3>Title: Probabilistic Temporal Masked Attention for Cross-view Online Action Detection</h3>
<ul>
<li><strong>Authors: </strong>Liping Xie, Yang Tan, Shicheng Jing, Huimin Lu, Kanjian Zhang</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.MM</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.17025">https://arxiv.org/abs/2508.17025</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.17025">https://arxiv.org/pdf/2508.17025</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.17025]] Probabilistic Temporal Masked Attention for Cross-view Online Action Detection(https://arxiv.org/abs/2508.17025)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction</a></li>
<li><strong>Abstract: </strong>As a critical task in video sequence classification within computer vision, Online Action Detection (OAD) has garnered significant attention. The sensitivity of mainstream OAD models to varying video viewpoints often hampers their generalization when confronted with unseen sources. To address this limitation, we propose a novel Probabilistic Temporal Masked Attention (PTMA) model, which leverages probabilistic modeling to derive latent compressed representations of video frames in a cross-view setting. The PTMA model incorporates a GRU-based temporal masked attention (TMA) cell, which leverages these representations to effectively query the input video sequence, thereby enhancing information interaction and facilitating autoregressive frame-level video analysis. Additionally, multi-view information can be integrated into the probabilistic modeling to facilitate the extraction of view-invariant features. Experiments conducted under three evaluation protocols: cross-subject (cs), cross-view (cv), and cross-subject-view (csv) show that PTMA achieves state-of-the-art performance on the DAHLIA, IKEA ASM, and Breakfast datasets.</li>
</ul>

<h3>Title: Improving Table Understanding with LLMs and Entity-Oriented Search</h3>
<ul>
<li><strong>Authors: </strong>Thi-Nhung Nguyen, Hoang Ngo, Dinh Phung, Thuy-Trang Vu, Dat Quoc Nguyen</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.17028">https://arxiv.org/abs/2508.17028</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.17028">https://arxiv.org/pdf/2508.17028</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.17028]] Improving Table Understanding with LLMs and Entity-Oriented Search(https://arxiv.org/abs/2508.17028)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Our work addresses the challenges of understanding tables. Existing methods often struggle with the unpredictable nature of table content, leading to a reliance on preprocessing and keyword matching. They also face limitations due to the lack of contextual information, which complicates the reasoning processes of large language models (LLMs). To overcome these challenges, we introduce an entity-oriented search method to improve table understanding with LLMs. This approach effectively leverages the semantic similarities between questions and table data, as well as the implicit relationships between table cells, minimizing the need for data preprocessing and keyword matching. Additionally, it focuses on table entities, ensuring that table cells are semantically tightly bound, thereby enhancing contextual clarity. Furthermore, we pioneer the use of a graph query language for table understanding, establishing a new research direction. Experiments show that our approach achieves new state-of-the-art performances on standard benchmarks WikiTableQuestions and TabFact.</li>
</ul>

<h3>Title: A Novel Local Focusing Mechanism for Deepfake Detection Generalization</h3>
<ul>
<li><strong>Authors: </strong>Mingliang Li, Lin Yuanbo Wu, Changhong Liu, Hanxi Li</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.17029">https://arxiv.org/abs/2508.17029</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.17029">https://arxiv.org/pdf/2508.17029</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.17029]] A Novel Local Focusing Mechanism for Deepfake Detection Generalization(https://arxiv.org/abs/2508.17029)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, diffusion</a></li>
<li><strong>Abstract: </strong>The rapid advancement of deepfake generation techniques has intensified the need for robust and generalizable detection methods. Existing approaches based on reconstruction learning typically leverage deep convolutional networks to extract differential features. However, these methods show poor generalization across object categories (e.g., from faces to cars) and generation domains (e.g., from GANs to Stable Diffusion), due to intrinsic limitations of deep CNNs. First, models trained on a specific category tend to overfit to semantic feature distributions, making them less transferable to other categories, especially as network depth increases. Second, Global Average Pooling (GAP) compresses critical local forgery cues into a single vector, thus discarding discriminative patterns vital for real-fake classification. To address these issues, we propose a novel Local Focus Mechanism (LFM) that explicitly attends to discriminative local features for differentiating fake from real images. LFM integrates a Salience Network (SNet) with a task-specific Top-K Pooling (TKP) module to select the K most informative local patterns. To mitigate potential overfitting introduced by Top-K pooling, we introduce two regularization techniques: Rank-Based Linear Dropout (RBLD) and Random-K Sampling (RKS), which enhance the model's robustness. LFM achieves a 3.7 improvement in accuracy and a 2.8 increase in average precision over the state-of-the-art Neighboring Pixel Relationships (NPR) method, while maintaining exceptional efficiency at 1789 FPS on a single NVIDIA A6000 GPU. Our approach sets a new benchmark for cross-domain deepfake detection. The source code are available in this https URL</li>
</ul>

<h3>Title: F4-ITS: Fine-grained Feature Fusion for Food Image-Text Search</h3>
<ul>
<li><strong>Authors: </strong>Raghul Asokan</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.17037">https://arxiv.org/abs/2508.17037</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.17037">https://arxiv.org/pdf/2508.17037</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.17037]] F4-ITS: Fine-grained Feature Fusion for Food Image-Text Search(https://arxiv.org/abs/2508.17037)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>The proliferation of digital food content has intensified the need for robust and accurate systems capable of fine-grained visual understanding and retrieval. In this work, we address the challenging task of food image-to-text matching, a critical component in applications such as dietary monitoring, smart kitchens, and restaurant automation. We propose F4-ITS: Fine-grained Feature Fusion for Food Image-Text Search, a training-free, vision-language model (VLM)-guided framework that significantly improves retrieval performance through enhanced multi-modal feature representations. Our approach introduces two key contributions: (1) a uni-directional(and bi-directional) multi-modal fusion strategy that combines image embeddings with VLM-generated textual descriptions to improve query expressiveness, and (2) a novel feature-based re-ranking mechanism for top-k retrieval, leveraging predicted food ingredients to refine results and boost precision. Leveraging open-source image-text encoders, we demonstrate substantial gains over standard baselines - achieving ~10% and ~7.7% improvements in top-1 retrieval under dense and sparse caption scenarios, and a ~28.6% gain in top-k ingredient-level retrieval. Additionally, we show that smaller models (e.g., ViT-B/32) can match or outperform larger counterparts (e.g., ViT-H, ViT-G, ViT-bigG) when augmented with textual fusion, highlighting the effectiveness of our method in resource-constrained settings. Code and test datasets will be made publicly available at: this https URL</li>
</ul>

<h3>Title: ZAPS: A Zero-Knowledge Proof Protocol for Secure UAV Authentication with Flight Path Privacy</h3>
<ul>
<li><strong>Authors: </strong>Shayesta Naziri, Xu Wang, Guangsheng Yu, Christy Jie Liang, Wei Ni</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.17043">https://arxiv.org/abs/2508.17043</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.17043">https://arxiv.org/pdf/2508.17043</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.17043]] ZAPS: A Zero-Knowledge Proof Protocol for Secure UAV Authentication with Flight Path Privacy(https://arxiv.org/abs/2508.17043)</code><input type="text"></li>
<li><strong>Keywords: </strong>secure, security, privacy, attack</a></li>
<li><strong>Abstract: </strong>The increasing deployment of Unmanned Aerial Vehicles (UAVs) for military, commercial, and logistics applications has raised significant concerns regarding flight path privacy. Conventional UAV communication systems often expose flight path data to third parties, making them vulnerable to tracking, surveillance, and location inference attacks. Existing encryption techniques provide security but fail to ensure complete privacy, as adversaries can still infer movement patterns through metadata analysis. To address these challenges, we propose a zk-SNARK(Zero-Knowledge Succinct Non-Interactive Argument of Knowledge)-based privacy-preserving flight path authentication and verification framework. Our approach ensures that a UAV can prove its authorisation, validate its flight path with a control centre, and comply with regulatory constraints without revealing any sensitive trajectory information. By leveraging zk-SNARKs, the UAV can generate cryptographic proofs that verify compliance with predefined flight policies while keeping the exact path and location undisclosed. This method mitigates risks associated with real-time tracking, identity exposure, and unauthorised interception, thereby enhancing UAV operational security in adversarial environments. Our proposed solution balances privacy, security, and computational efficiency, making it suitable for resource-constrained UAVs in both civilian and military applications.</li>
</ul>

<h3>Title: M3DMap: Object-aware Multimodal 3D Mapping for Dynamic Environments</h3>
<ul>
<li><strong>Authors: </strong>Dmitry Yudin</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.RO</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.17044">https://arxiv.org/abs/2508.17044</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.17044">https://arxiv.org/pdf/2508.17044</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.17044]] M3DMap: Object-aware Multimodal 3D Mapping for Dynamic Environments(https://arxiv.org/abs/2508.17044)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>3D mapping in dynamic environments poses a challenge for modern researchers in robotics and autonomous transportation. There are no universal representations for dynamic 3D scenes that incorporate multimodal data such as images, point clouds, and text. This article takes a step toward solving this problem. It proposes a taxonomy of methods for constructing multimodal 3D maps, classifying contemporary approaches based on scene types and representations, learning methods, and practical applications. Using this taxonomy, a brief structured analysis of recent methods is provided. The article also describes an original modular method called M3DMap, designed for object-aware construction of multimodal 3D maps for both static and dynamic scenes. It consists of several interconnected components: a neural multimodal object segmentation and tracking module; an odometry estimation module, including trainable algorithms; a module for 3D map construction and updating with various implementations depending on the desired scene representation; and a multimodal data retrieval module. The article highlights original implementations of these modules and their advantages in solving various practical tasks, from 3D object grounding to mobile manipulation. Additionally, it presents theoretical propositions demonstrating the positive effect of using multimodal data and modern foundational models in 3D mapping methods. Details of the taxonomy and method implementation are available at this https URL.</li>
</ul>

<h3>Title: Styleclone: Face Stylization with Diffusion Based Data Augmentation</h3>
<ul>
<li><strong>Authors: </strong>Neeraj Matiyali, Siddharth Srivastava, Gaurav Sharma</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.17045">https://arxiv.org/abs/2508.17045</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.17045">https://arxiv.org/pdf/2508.17045</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.17045]] Styleclone: Face Stylization with Diffusion Based Data Augmentation(https://arxiv.org/abs/2508.17045)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>We present StyleClone, a method for training image-to-image translation networks to stylize faces in a specific style, even with limited style images. Our approach leverages textual inversion and diffusion-based guided image generation to augment small style datasets. By systematically generating diverse style samples guided by both the original style images and real face images, we significantly enhance the diversity of the style dataset. Using this augmented dataset, we train fast image-to-image translation networks that outperform diffusion-based methods in speed and quality. Experiments on multiple styles demonstrate that our method improves stylization quality, better preserves source image content, and significantly accelerates inference. Additionally, we provide a systematic evaluation of the augmentation techniques and their impact on stylization performance.</li>
</ul>

<h3>Title: PVNet: Point-Voxel Interaction LiDAR Scene Upsampling Via Diffusion Models</h3>
<ul>
<li><strong>Authors: </strong>Xianjing Cheng, Lintai Wu, Zuowen Wang, Junhui Hou, Jie Wen, Yong Xu</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.17050">https://arxiv.org/abs/2508.17050</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.17050">https://arxiv.org/pdf/2508.17050</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.17050]] PVNet: Point-Voxel Interaction LiDAR Scene Upsampling Via Diffusion Models(https://arxiv.org/abs/2508.17050)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>Accurate 3D scene understanding in outdoor environments heavily relies on high-quality point clouds. However, LiDAR-scanned data often suffer from extreme sparsity, severely hindering downstream 3D perception tasks. Existing point cloud upsampling methods primarily focus on individual objects, thus demonstrating limited generalization capability for complex outdoor scenes. To address this issue, we propose PVNet, a diffusion model-based point-voxel interaction framework to perform LiDAR point cloud upsampling without dense supervision. Specifically, we adopt the classifier-free guidance-based DDPMs to guide the generation, in which we employ a sparse point cloud as the guiding condition and the synthesized point clouds derived from its nearby frames as the input. Moreover, we design a voxel completion module to refine and complete the coarse voxel features for enriching the feature representation. In addition, we propose a point-voxel interaction module to integrate features from both points and voxels, which efficiently improves the environmental perception capability of each upsampled point. To the best of our knowledge, our approach is the first scene-level point cloud upsampling method supporting arbitrary upsampling rates. Extensive experiments on various benchmarks demonstrate that our method achieves state-of-the-art performance. The source code will be available at this https URL.</li>
</ul>

<h3>Title: TabResFlow: A Normalizing Spline Flow Model for Probabilistic Univariate Tabular Regression</h3>
<ul>
<li><strong>Authors: </strong>Kiran Madhusudhanan, Vijaya Krishna Yalavarthi, Jonas Sonntag, Maximilian Stubbemann, Lars Schmidt-Thieme</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.17056">https://arxiv.org/abs/2508.17056</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.17056">https://arxiv.org/pdf/2508.17056</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.17056]] TabResFlow: A Normalizing Spline Flow Model for Probabilistic Univariate Tabular Regression(https://arxiv.org/abs/2508.17056)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction</a></li>
<li><strong>Abstract: </strong>Tabular regression is a well-studied problem with numerous industrial applications, yet most existing approaches focus on point estimation, often leading to overconfident predictions. This issue is particularly critical in industrial automation, where trustworthy decision-making is essential. Probabilistic regression models address this challenge by modeling prediction uncertainty. However, many conventional methods assume a fixed-shape distribution (typically Gaussian), and resort to estimating distribution parameters. This assumption is often restrictive, as real-world target distributions can be highly complex. To overcome this limitation, we introduce TabResFlow, a Normalizing Spline Flow model designed specifically for univariate tabular regression, where commonly used simple flow networks like RealNVP and Masked Autoregressive Flow (MAF) are unsuitable. TabResFlow consists of three key components: (1) An MLP encoder for each numerical feature. (2) A fully connected ResNet backbone for expressive feature extraction. (3) A conditional spline-based normalizing flow for flexible and tractable density estimation. We evaluate TabResFlow on nine public benchmark datasets, demonstrating that it consistently surpasses existing probabilistic regression models on likelihood scores. Our results demonstrate 9.64% improvement compared to the strongest probabilistic regression model (TreeFlow), and on average 5.6 times speed-up in inference time compared to the strongest deep learning alternative (NodeFlow). Additionally, we validate the practical applicability of TabResFlow in a real-world used car price prediction task under selective regression. To measure performance in this setting, we introduce a novel Area Under Risk Coverage (AURC) metric and show that TabResFlow achieves superior results across this metric.</li>
</ul>

<h3>Title: GRAID: Synthetic Data Generation with Geometric Constraints and Multi-Agentic Reflection for Harmful Content Detection</h3>
<ul>
<li><strong>Authors: </strong>Melissa Kazemi Rad, Alberto Purpura, Himanshu Kumar, Emily Chen, Mohammad Shahed Sorower</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.CR, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.17057">https://arxiv.org/abs/2508.17057</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.17057">https://arxiv.org/pdf/2508.17057</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.17057]] GRAID: Synthetic Data Generation with Geometric Constraints and Multi-Agentic Reflection for Harmful Content Detection(https://arxiv.org/abs/2508.17057)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>We address the problem of data scarcity in harmful text classification for guardrailing applications and introduce GRAID (Geometric and Reflective AI-Driven Data Augmentation), a novel pipeline that leverages Large Language Models (LLMs) for dataset augmentation. GRAID consists of two stages: (i) generation of geometrically controlled examples using a constrained LLM, and (ii) augmentation through a multi-agentic reflective process that promotes stylistic diversity and uncovers edge cases. This combination enables both reliable coverage of the input space and nuanced exploration of harmful content. Using two benchmark data sets, we demonstrate that augmenting a harmful text classification dataset with GRAID leads to significant improvements in downstream guardrail model performance.</li>
</ul>

<h3>Title: REGEN: Real-Time Photorealism Enhancement in Games via a Dual-Stage Generative Network Framework</h3>
<ul>
<li><strong>Authors: </strong>Stefanos Pasios, Nikos Nikolaidis</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.17061">https://arxiv.org/abs/2508.17061</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.17061">https://arxiv.org/pdf/2508.17061</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.17061]] REGEN: Real-Time Photorealism Enhancement in Games via a Dual-Stage Generative Network Framework(https://arxiv.org/abs/2508.17061)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, generative</a></li>
<li><strong>Abstract: </strong>Photorealism is an important aspect of modern video games since it can shape the player experience and simultaneously impact the immersion, narrative engagement, and visual fidelity. Although recent hardware technological breakthroughs, along with state-of-the-art rendering technologies, have significantly improved the visual realism of video games, achieving true photorealism in dynamic environments at real-time frame rates still remains a major challenge due to the tradeoff between visual quality and performance. In this short paper, we present a novel approach for enhancing the photorealism of rendered game frames using generative adversarial networks. To this end, we propose Real-time photorealism Enhancement in Games via a dual-stage gEnerative Network framework (REGEN), which employs a robust unpaired image-to-image translation model to produce semantically consistent photorealistic frames that transform the problem into a simpler paired image-to-image translation task. This enables training with a lightweight method that can achieve real-time inference time without compromising visual quality. We demonstrate the effectiveness of our framework on Grand Theft Auto V, showing that the approach achieves visual results comparable to the ones produced by the robust unpaired Im2Im method while improving inference speed by 32.14 times. Our findings also indicate that the results outperform the photorealism-enhanced frames produced by directly training a lightweight unpaired Im2Im translation method to translate the video game frames towards the visual characteristics of real-world images. Code, pre-trained models, and demos for this work are available at: this https URL.</li>
</ul>

<h3>Title: SSG-Dit: A Spatial Signal Guided Framework for Controllable Video Generation</h3>
<ul>
<li><strong>Authors: </strong>Peng Hu, Yu Gu, Liang Luo, Fuji Ren</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.17062">https://arxiv.org/abs/2508.17062</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.17062">https://arxiv.org/pdf/2508.17062</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.17062]] SSG-Dit: A Spatial Signal Guided Framework for Controllable Video Generation(https://arxiv.org/abs/2508.17062)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, transformer, generative</a></li>
<li><strong>Abstract: </strong>Controllable video generation aims to synthesize video content that aligns precisely with user-provided conditions, such as text descriptions and initial images. However, a significant challenge persists in this domain: existing models often struggle to maintain strong semantic consistency, frequently generating videos that deviate from the nuanced details specified in the prompts. To address this issue, we propose SSG-DiT (Spatial Signal Guided Diffusion Transformer), a novel and efficient framework for high-fidelity controllable video generation. Our approach introduces a decoupled two-stage process. The first stage, Spatial Signal Prompting, generates a spatially aware visual prompt by leveraging the rich internal representations of a pre-trained multi-modal model. This prompt, combined with the original text, forms a joint condition that is then injected into a frozen video DiT backbone via our lightweight and parameter-efficient SSG-Adapter. This unique design, featuring a dual-branch attention mechanism, allows the model to simultaneously harness its powerful generative priors while being precisely steered by external spatial signals. Extensive experiments demonstrate that SSG-DiT achieves state-of-the-art performance, outperforming existing models on multiple key metrics in the VBench benchmark, particularly in spatial relationship control and overall consistency.</li>
</ul>

<h3>Title: Post-Quantum Blockchain: Challenges and Opportunities</h3>
<ul>
<li><strong>Authors: </strong>Sufyan Al-Janabi</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.17071">https://arxiv.org/abs/2508.17071</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.17071">https://arxiv.org/pdf/2508.17071</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.17071]] Post-Quantum Blockchain: Challenges and Opportunities(https://arxiv.org/abs/2508.17071)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, attack</a></li>
<li><strong>Abstract: </strong>Blockchain is a Distributed Ledger Technology (DLT) that offers numerous benefits including decentralization, transparency, efficiency, and reduced costs. Hence, blockchain has been included in many fields. Blockchain relies on cryptographic protocols (especially public-key cryptography and hash functions) to achieve many essential sub-routines. However, the increased progress of quantum computation and algorithms has threatened the security of many traditional cryptosystems. Therefore, this represents a serious risk for the existing blockchain technology. For example, SHA-256 and the Elliptic Curve Digital Signature Algorithm (ECDSA) cryptosystems can be compromised by Shor s and Grover s quantum algorithms in the foreseeable future. Post-Quantum Cryptography (PQC) is a basic solution for resisting these quantum attacks. Applying PQC to blockchains results in creating Post-Quantum Blockchains (PQB). Thus, this paper aims to review the threats imposed by quantum computers on classical blockchain technology and provide useful guidelines on PQB security to blockchain researchers. The paper focuses on the challenges and opportunities of future work direction in this field.</li>
</ul>

<h3>Title: Linguistic Neuron Overlap Patterns to Facilitate Cross-lingual Transfer on Low-resource Languages</h3>
<ul>
<li><strong>Authors: </strong>Yuemei Xu, Kexin Xu, Jian Zhou, Ling Hu, Lin Gui</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.17078">https://arxiv.org/abs/2508.17078</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.17078">https://arxiv.org/pdf/2508.17078</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.17078]] Linguistic Neuron Overlap Patterns to Facilitate Cross-lingual Transfer on Low-resource Languages(https://arxiv.org/abs/2508.17078)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>The current Large Language Models (LLMs) face significant challenges in improving performance on low-resource languages and urgently need data-efficient methods without costly fine-tuning. From the perspective of language-bridge, we propose BridgeX-ICL, a simple yet effective method to improve zero-shot Cross-lingual In-Context Learning (X-ICL) for low-resource languages. Unlike existing works focusing on language-specific neurons, BridgeX-ICL explores whether sharing neurons can improve cross-lingual performance in LLMs or not. We construct neuron probe data from the ground-truth MUSE bilingual dictionaries, and define a subset of language overlap neurons accordingly, to ensure full activation of these anchored neurons. Subsequently, we propose an HSIC-based metric to quantify LLMs' internal linguistic spectrum based on overlap neurons, which guides optimal bridge selection. The experiments conducted on 2 cross-lingual tasks and 15 language pairs from 7 diverse families (covering both high-low and moderate-low pairs) validate the effectiveness of BridgeX-ICL and offer empirical insights into the underlying multilingual mechanisms of LLMs.</li>
</ul>

<h3>Title: Proximal Vision Transformer: Enhancing Feature Representation through Two-Stage Manifold Geometry</h3>
<ul>
<li><strong>Authors: </strong>Haoyu Yun, Hamid Krim</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.17081">https://arxiv.org/abs/2508.17081</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.17081">https://arxiv.org/pdf/2508.17081</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.17081]] Proximal Vision Transformer: Enhancing Feature Representation through Two-Stage Manifold Geometry(https://arxiv.org/abs/2508.17081)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>The Vision Transformer (ViT) architecture has become widely recognized in computer vision, leveraging its self-attention mechanism to achieve remarkable success across various tasks. Despite its strengths, ViT's optimization remains confined to modeling local relationships within individual images, limiting its ability to capture the global geometric relationships between data points. To address this limitation, this paper proposes a novel framework that integrates ViT with the proximal tools, enabling a unified geometric optimization approach to enhance feature representation and classification performance. In this framework, ViT constructs the tangent bundle of the manifold through its self-attention mechanism, where each attention head corresponds to a tangent space, offering geometric representations from diverse local perspectives. Proximal iterations are then introduced to define sections within the tangent bundle and project data from tangent spaces onto the base space, achieving global feature alignment and optimization. Experimental results confirm that the proposed method outperforms traditional ViT in terms of classification accuracy and data distribution.</li>
</ul>

<h3>Title: Convolutional Neural Networks for Accurate Measurement of Train Speed</h3>
<ul>
<li><strong>Authors: </strong>Haitao Tian, Argyrios Zolotas, Miguel Arana-Catania</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, eess.SY</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.17096">https://arxiv.org/abs/2508.17096</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.17096">https://arxiv.org/pdf/2508.17096</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.17096]] Convolutional Neural Networks for Accurate Measurement of Train Speed(https://arxiv.org/abs/2508.17096)</code><input type="text"></li>
<li><strong>Keywords: </strong>protect, robust</a></li>
<li><strong>Abstract: </strong>In this study, we explore the use of Convolutional Neural Networks for improving train speed estimation accuracy, addressing the complex challenges of modern railway systems. We investigate three CNN architectures - single-branch 2D, single-branch 1D, and multiple-branch models - and compare them with the Adaptive Kalman Filter. We analyse their performance using simulated train operation datasets with and without Wheel Slide Protection activation. Our results reveal that CNN-based approaches, especially the multiple-branch model, demonstrate superior accuracy and robustness compared to traditional methods, particularly under challenging operational conditions. These findings highlight the potential of deep learning techniques to enhance railway safety and operational efficiency by more effectively capturing intricate patterns in complex transportation datasets.</li>
</ul>

<h3>Title: Two Birds with One Stone: Enhancing Uncertainty Quantification and Interpretability with Graph Functional Neural Process</h3>
<ul>
<li><strong>Authors: </strong>Lingkai Kong, Haotian Sun, Yuchen Zhuang, Haorui Wang, Wenhao Mu, Chao Zhang</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.17097">https://arxiv.org/abs/2508.17097</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.17097">https://arxiv.org/pdf/2508.17097</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.17097]] Two Birds with One Stone: Enhancing Uncertainty Quantification and Interpretability with Graph Functional Neural Process(https://arxiv.org/abs/2508.17097)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability, generative</a></li>
<li><strong>Abstract: </strong>Graph neural networks (GNNs) are powerful tools on graph data. However, their predictions are mis-calibrated and lack interpretability, limiting their adoption in critical applications. To address this issue, we propose a new uncertainty-aware and interpretable graph classification model that combines graph functional neural process and graph generative model. The core of our method is to assume a set of latent rationales which can be mapped to a probabilistic embedding space; the predictive distribution of the classifier is conditioned on such rationale embeddings by learning a stochastic correlation matrix. The graph generator serves to decode the graph structure of the rationales from the embedding space for model interpretability. For efficient model training, we adopt an alternating optimization procedure which mimics the well known Expectation-Maximization (EM) algorithm. The proposed method is general and can be applied to any existing GNN architecture. Extensive experiments on five graph classification datasets demonstrate that our framework outperforms state-of-the-art methods in both uncertainty quantification and GNN interpretability. We also conduct case studies to show that the decoded rationale structure can provide meaningful explanations.</li>
</ul>

<h3>Title: GRASP: Geospatial pixel Reasoning viA Structured Policy learning</h3>
<ul>
<li><strong>Authors: </strong>Chengjie Jiang, Yunqi Zhou, Jiafeng Yan, Jing Li</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.17102">https://arxiv.org/abs/2508.17102</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.17102">https://arxiv.org/pdf/2508.17102</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.17102]] GRASP: Geospatial pixel Reasoning viA Structured Policy learning(https://arxiv.org/abs/2508.17102)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, large language model, segmentation</a></li>
<li><strong>Abstract: </strong>Geospatial pixel reasoning is a nascent remote-sensing task that aims to generate segmentation masks directly from natural-language instructions. Prevailing MLLM-based systems co-train a language model and a mask decoder with dense pixel supervision, which is expensive and often weak on out-of-domain (OOD) data. We introduce GRASP, a structured policy-learning framework. In our design, a multimodal large language model first emits task-relevant bounding boxes and positive points from a vision-language instruction. These outputs are then passed to a pre-trained segmentation model, which consumes them as prompts to generate the final mask. Instead of supervised fine-tuning, we optimize the system purely with reinforcement learning: the model is trained solely with GRPO, guided by format rewards and accuracy rewards computed on boxes and points (no mask supervision). This leverages strong priors in foundation models, minimizes trainable parameters, and enables learning from inexpensive annotations. We additionally curate GRASP-1k, which contains reasoning-intensive queries, detailed reasoning traces, and fine-grained segmentation annotations. Evaluations on both in-domain and out-of-domain test sets show state-of-the-art results: about 4% improvement in-domain and up to 54% on OOD benchmarks. The experiment results evidence our model's robust generalization and demonstrate that complex geospatial segmentation behaviors can be learned via RL from weak spatial cues. Code and the dataset will be released open-source.</li>
</ul>

<h3>Title: SyncGuard: Robust Audio Watermarking Capable of Countering Desynchronization Attacks</h3>
<ul>
<li><strong>Authors: </strong>Zhenliang Gan, Xiaoxiao Hu, Sheng Li, Zhenxing Qian, Xinpeng Zhang</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.MM, cs.SD</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.17121">https://arxiv.org/abs/2508.17121</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.17121">https://arxiv.org/pdf/2508.17121</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.17121]] SyncGuard: Robust Audio Watermarking Capable of Countering Desynchronization Attacks(https://arxiv.org/abs/2508.17121)</code><input type="text"></li>
<li><strong>Keywords: </strong>protect, attack, robust, extraction, watermark</a></li>
<li><strong>Abstract: </strong>Audio watermarking has been widely applied in copyright protection and source tracing. However, due to the inherent characteristics of audio signals, watermark localization and resistance to desynchronization attacks remain significant challenges. In this paper, we propose a learning-based scheme named SyncGuard to address these challenges. Specifically, we design a frame-wise broadcast embedding strategy to embed the watermark in arbitrary-length audio, enhancing time-independence and eliminating the need for localization during watermark extraction. To further enhance robustness, we introduce a meticulously designed distortion layer. Additionally, we employ dilated residual blocks in conjunction with dilated gated blocks to effectively capture multi-resolution time-frequency features. Extensive experimental results show that SyncGuard efficiently handles variable-length audio segments, outperforms state-of-the-art methods in robustness against various attacks, and delivers superior auditory quality.</li>
</ul>

<h3>Title: Token Homogenization under Positional Bias</h3>
<ul>
<li><strong>Authors: </strong>Viacheslav Yusupov, Danil Maksimov, Ameliia Alaeva, Tatiana Zaitceva, Antipina Anna, Anna Vasileva, Chenlin Liu, Rayuth Chheng, Danil Sazanakov, Andrey Chetvergov, Alina Ermilova, Egor Shvetsov</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.17126">https://arxiv.org/abs/2508.17126</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.17126">https://arxiv.org/pdf/2508.17126</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.17126]] Token Homogenization under Positional Bias(https://arxiv.org/abs/2508.17126)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer, large language model</a></li>
<li><strong>Abstract: </strong>This paper investigates token homogenization - the convergence of token representations toward uniformity across transformer layers and its relationship to positional bias in large language models. We empirically examine whether homogenization occurs and how positional bias amplifies this effect. Through layer-wise similarity analysis and controlled experiments, we demonstrate that tokens systematically lose distinctiveness during processing, particularly when biased toward extremal positions. Our findings confirm both the existence of homogenization and its dependence on positional attention mechanisms.</li>
</ul>

<h3>Title: A Straightforward Pipeline for Targeted Entailment and Contradiction Detection</h3>
<ul>
<li><strong>Authors: </strong>Antonin Sulc</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.LO</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.17127">https://arxiv.org/abs/2508.17127</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.17127">https://arxiv.org/pdf/2508.17127</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.17127]] A Straightforward Pipeline for Targeted Entailment and Contradiction Detection(https://arxiv.org/abs/2508.17127)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Finding the relationships between sentences in a document is crucial for tasks like fact-checking, argument mining, and text summarization. A key challenge is to identify which sentences act as premises or contradictions for a specific claim. Existing methods often face a trade-off: transformer attention mechanisms can identify salient textual connections but lack explicit semantic labels, while Natural Language Inference (NLI) models can classify relationships between sentence pairs but operate independently of contextual saliency. In this work, we introduce a method that combines the strengths of both approaches for a targeted analysis. Our pipeline first identifies candidate sentences that are contextually relevant to a user-selected target sentence by aggregating token-level attention scores. It then uses a pretrained NLI model to classify each candidate as a premise (entailment) or contradiction. By filtering NLI-identified relationships with attention-based saliency scores, our method efficiently isolates the most significant semantic relationships for any given claim in a text.</li>
</ul>

<h3>Title: CE-RS-SBCIT A Novel Channel Enhanced Hybrid CNN Transformer with Residual, Spatial, and Boundary-Aware Learning for Brain Tumor MRI Analysis</h3>
<ul>
<li><strong>Authors: </strong>Mirza Mumtaz Zahoor (1), Saddam Hussain Khan (2) ((1) Faculty of Computer Sciences, Ibadat International University, Islamabad, 44000, Pakistan (2) Artificial Intelligence Lab, Department of Computer Systems Engineering, University of Engineering and Applied Sciences (UEAS), Swat 19060, Pakistan)</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.17128">https://arxiv.org/abs/2508.17128</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.17128">https://arxiv.org/pdf/2508.17128</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.17128]] CE-RS-SBCIT A Novel Channel Enhanced Hybrid CNN Transformer with Residual, Spatial, and Boundary-Aware Learning for Brain Tumor MRI Analysis(https://arxiv.org/abs/2508.17128)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Brain tumors remain among the most lethal human diseases, where early detection and accurate classification are critical for effective diagnosis and treatment planning. Although deep learning-based computer-aided diagnostic (CADx) systems have shown remarkable progress. However, conventional convolutional neural networks (CNNs) and Transformers face persistent challenges, including high computational cost, sensitivity to minor contrast variations, structural heterogeneity, and texture inconsistencies in MRI data. Therefore, a novel hybrid framework, CE-RS-SBCIT, is introduced, integrating residual and spatial learning-based CNNs with transformer-driven modules. The proposed framework exploits local fine-grained and global contextual cues through four core innovations: (i) a smoothing and boundary-based CNN-integrated Transformer (SBCIT), (ii) tailored residual and spatial learning CNNs, (iii) a channel enhancement (CE) strategy, and (iv) a novel spatial attention mechanism. The developed SBCIT employs stem convolution and contextual interaction transformer blocks with systematic smoothing and boundary operations, enabling efficient global feature modeling. Moreover, Residual and spatial CNNs, enhanced by auxiliary transfer-learned feature maps, enrich the representation space, while the CE module amplifies discriminative channels and mitigates redundancy. Furthermore, the spatial attention mechanism selectively emphasizes subtle contrast and textural variations across tumor classes. Extensive evaluation on challenging MRI datasets from Kaggle and Figshare, encompassing glioma, meningioma, pituitary tumors, and healthy controls, demonstrates superior performance, achieving 98.30% accuracy, 98.08% sensitivity, 98.25% F1-score, and 98.43% precision.</li>
</ul>

<h3>Title: Reconciling Communication Compression and Byzantine-Robustness in Distributed Learning</h3>
<ul>
<li><strong>Authors: </strong>Diksha Gupta, Nirupam Gupta, Chuan Xu, Giovanni Neglia</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.17129">https://arxiv.org/abs/2508.17129</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.17129">https://arxiv.org/pdf/2508.17129</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.17129]] Reconciling Communication Compression and Byzantine-Robustness in Distributed Learning(https://arxiv.org/abs/2508.17129)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Distributed learning (DL) enables scalable model training over decentralized data, but remains challenged by Byzantine faults and high communication costs. While both issues have been studied extensively in isolation, their interaction is less explored. Prior work shows that naively combining communication compression with Byzantine-robust aggregation degrades resilience to faulty nodes (or workers). The state-of-the-art algorithm, namely Byz-DASHA-PAGE [29], makes use of the momentum variance reduction scheme to mitigate the detrimental impact of compression noise on Byzantine-robustness. We propose a new algorithm, named RoSDHB, that integrates the classic Polyak's momentum with a new coordinated compression mechanism. We show that RoSDHB performs comparably to Byz-DASHA-PAGE under the standard (G, B)-gradient dissimilarity heterogeneity model, while it relies on fewer assumptions. In particular, we only assume Lipschitz smoothness of the average loss function of the honest workers, in contrast to [29]that additionally assumes a special smoothness of bounded global Hessian variance. Empirical results on benchmark image classification task show that RoSDHB achieves strong robustness with significant communication savings.</li>
</ul>

<h3>Title: Structural Damage Detection Using AI Super Resolution and Visual Language Model</h3>
<ul>
<li><strong>Authors: </strong>Catherine Hoier, Khandaker Mamun Ahmed</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.17130">https://arxiv.org/abs/2508.17130</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.17130">https://arxiv.org/pdf/2508.17130</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.17130]] Structural Damage Detection Using AI Super Resolution and Visual Language Model(https://arxiv.org/abs/2508.17130)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Natural disasters pose significant challenges to timely and accurate damage assessment due to their sudden onset and the extensive areas they affect. Traditional assessment methods are often labor-intensive, costly, and hazardous to personnel, making them impractical for rapid response, especially in resource-limited settings. This study proposes a novel, cost-effective framework that leverages aerial drone footage, an advanced AI-based video super-resolution model, Video Restoration Transformer (VRT), and Gemma3:27b, a 27 billion parameter Visual Language Model (VLM). This integrated system is designed to improve low-resolution disaster footage, identify structural damage, and classify buildings into four damage categories, ranging from no/slight damage to total destruction, along with associated risk levels. The methodology was validated using pre- and post-event drone imagery from the 2023 Turkey earthquakes (courtesy of The Guardian) and satellite data from the 2013 Moore Tornado (xBD dataset). The framework achieved a classification accuracy of 84.5%, demonstrating its ability to provide highly accurate results. Furthermore, the system's accessibility allows non-technical users to perform preliminary analyses, thereby improving the responsiveness and efficiency of disaster management efforts.</li>
</ul>

<h3>Title: MoE-Beyond: Learning-Based Expert Activation Prediction on Edge Devices</h3>
<ul>
<li><strong>Authors: </strong>Nishant Gavhane, Arush Mehrotra, Rohit Chawla, Peter Proenca</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.17137">https://arxiv.org/abs/2508.17137</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.17137">https://arxiv.org/pdf/2508.17137</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.17137]] MoE-Beyond: Learning-Based Expert Activation Prediction on Edge Devices(https://arxiv.org/abs/2508.17137)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>The deployment of large-scale Mixture-of-Experts (MoE) models on edge devices presents significant challenges due to memory constraints. While MoE architectures enable efficient utilization of computational resources by activating only a subset of experts per inference, they require careful memory management to operate efficiently in resource-constrained environments. Traditional heuristic-based expert caching strategies such as MoE-Infinity struggle to maintain high cache hit rates as models parameters scale. In this work, we introduce MoE-Beyond, a learning-based expert activation predictor trained to predict expert activations during autoregressive decoding. By framing the task as a multi-label sequence prediction problem, we train a lightweight transformer model on 66 million expert activation traces extracted from LDJnr-Puffin dataset [5] using DeepSeek-V2-Chat-Lite MoE. Our predictor generalizes effectively across unseen prompts from WebGLM-QA dataset [6], achieving 97.5% accuracy and an 86.6% F1-score. Simulation results show that MoE-Beyond improves GPU cache hit rate from 17% to 72% when only 10% of experts fit in GPU cache, outperforming heuristic baselines.</li>
</ul>

<h3>Title: Geolocation-Aware Robust Spoken Language Identification</h3>
<ul>
<li><strong>Authors: </strong>Qingzheng Wang, Hye-jin Shim, Jiancheng Sun, Shinji Watanabe</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.SD</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.17148">https://arxiv.org/abs/2508.17148</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.17148">https://arxiv.org/pdf/2508.17148</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.17148]] Geolocation-Aware Robust Spoken Language Identification(https://arxiv.org/abs/2508.17148)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>While Self-supervised Learning (SSL) has significantly improved Spoken Language Identification (LID), existing models often struggle to consistently classify dialects and accents of the same language as a unified class. To address this challenge, we propose geolocation-aware LID, a novel approach that incorporates language-level geolocation information into the SSL-based LID model. Specifically, we introduce geolocation prediction as an auxiliary task and inject the predicted vectors into intermediate representations as conditioning signals. This explicit conditioning encourages the model to learn more unified representations for dialectal and accented variations. Experiments across six multilingual datasets demonstrate that our approach improves robustness to intra-language variations and unseen domains, achieving new state-of-the-art accuracy on FLEURS (97.7%) and 9.7% relative improvement on ML-SUPERB 2.0 dialect set.</li>
</ul>

<h3>Title: SACA: Selective Attention-Based Clustering Algorithm</h3>
<ul>
<li><strong>Authors: </strong>Meysam Shirdel Bilehsavar, Razieh Ghaedi, Samira Seyed Taheri, Xinqi Fan, Christian O'Reilly</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.17150">https://arxiv.org/abs/2508.17150</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.17150">https://arxiv.org/pdf/2508.17150</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.17150]] SACA: Selective Attention-Based Clustering Algorithm(https://arxiv.org/abs/2508.17150)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Clustering algorithms are widely used in various applications, with density-based methods such as Density-Based Spatial Clustering of Applications with Noise (DBSCAN) being particularly prominent. These algorithms identify clusters in high-density regions while treating sparser areas as noise. However, reliance on user-defined parameters often poses optimization challenges that require domain expertise. This paper presents a novel density-based clustering method inspired by the concept of selective attention, which minimizes the need for user-defined parameters under standard conditions. Initially, the algorithm operates without requiring user-defined parameters. If parameter adjustment is needed, the method simplifies the process by introducing a single integer parameter that is straightforward to tune. The approach computes a threshold to filter out the most sparsely distributed points and outliers, forms a preliminary cluster structure, and then reintegrates the excluded points to finalize the results. Experimental evaluations on diverse data sets highlight the accessibility and robust performance of the method, providing an effective alternative for density-based clustering tasks.</li>
</ul>

<h3>Title: Natural Language Satisfiability: Exploring the Problem Distribution and Evaluating Transformer-based Language Models</h3>
<ul>
<li><strong>Authors: </strong>Tharindu Madusanka, Ian Pratt-Hartmann, Riza Batista-Navarro</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.17153">https://arxiv.org/abs/2508.17153</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.17153">https://arxiv.org/pdf/2508.17153</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.17153]] Natural Language Satisfiability: Exploring the Problem Distribution and Evaluating Transformer-based Language Models(https://arxiv.org/abs/2508.17153)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Efforts to apply transformer-based language models (TLMs) to the problem of reasoning in natural language have enjoyed ever-increasing success in recent years. The most fundamental task in this area to which nearly all others can be reduced is that of determining satisfiability. However, from a logical point of view, satisfiability problems vary along various dimensions, which may affect TLMs' ability to learn how to solve them. The problem instances of satisfiability in natural language can belong to different computational complexity classes depending on the language fragment in which they are expressed. Although prior research has explored the problem of natural language satisfiability, the above-mentioned point has not been discussed adequately. Hence, we investigate how problem instances from varying computational complexity classes and having different grammatical constructs impact TLMs' ability to learn rules of inference. Furthermore, to faithfully evaluate TLMs, we conduct an empirical study to explore the distribution of satisfiability problems.</li>
</ul>

<h3>Title: Mind the Gap: Time-of-Check to Time-of-Use Vulnerabilities in LLM-Enabled Agents</h3>
<ul>
<li><strong>Authors: </strong>Derek Lilienthal, Sanghyun Hong</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.17155">https://arxiv.org/abs/2508.17155</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.17155">https://arxiv.org/pdf/2508.17155</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.17155]] Mind the Gap: Time-of-Check to Time-of-Use Vulnerabilities in LLM-Enabled Agents(https://arxiv.org/abs/2508.17155)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, attack, large language model</a></li>
<li><strong>Abstract: </strong>Large Language Model (LLM)-enabled agents are rapidly emerging across a wide range of applications, but their deployment introduces vulnerabilities with security implications. While prior work has examined prompt-based attacks (e.g., prompt injection) and data-oriented threats (e.g., data exfiltration), time-of-check to time-of-use (TOCTOU) remain largely unexplored in this context. TOCTOU arises when an agent validates external state (e.g., a file or API response) that is later modified before use, enabling practical attacks such as malicious configuration swaps or payload injection. In this work, we present the first study of TOCTOU vulnerabilities in LLM-enabled agents. We introduce TOCTOU-Bench, a benchmark with 66 realistic user tasks designed to evaluate this class of vulnerabilities. As countermeasures, we adapt detection and mitigation techniques from systems security to this setting and propose prompt rewriting, state integrity monitoring, and tool-fusing. Our study highlights challenges unique to agentic workflows, where we achieve up to 25% detection accuracy using automated detection methods, a 3% decrease in vulnerable plan generation, and a 95% reduction in the attack window. When combining all three approaches, we reduce the TOCTOU vulnerabilities from an executed trajectory from 12% to 8%. Our findings open a new research direction at the intersection of AI safety and systems security.</li>
</ul>

<h3>Title: SPORTSQL: An Interactive System for Real-Time Sports Reasoning and Visualization</h3>
<ul>
<li><strong>Authors: </strong>Sebastian Martinez, Naman Ahuja, Fenil Bardoliya, Chris Bryan, Vivek Gupta</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.17157">https://arxiv.org/abs/2508.17157</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.17157">https://arxiv.org/pdf/2508.17157</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.17157]] SPORTSQL: An Interactive System for Real-Time Sports Reasoning and Visualization(https://arxiv.org/abs/2508.17157)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>We present a modular, interactive system, SPORTSQL, for natural language querying and visualization of dynamic sports data, with a focus on the English Premier League (EPL). The system translates user questions into executable SQL over a live, temporally indexed database constructed from real-time Fantasy Premier League (FPL) data. It supports both tabular and visual outputs, leveraging the symbolic reasoning capabilities of Large Language Models (LLMs) for query parsing, schema linking, and visualization selection. To evaluate system performance, we introduce the Dynamic Sport Question Answering benchmark (DSQABENCH), comprising 1,700+ queries annotated with SQL programs, gold answers, and database snapshots. Our demo highlights how non-expert users can seamlessly explore evolving sports statistics through a natural, conversational interface.</li>
</ul>

<h3>Title: Towards Safeguarding LLM Fine-tuning APIs against Cipher Attacks</h3>
<ul>
<li><strong>Authors: </strong>Jack Youstra, Mohammed Mahfoud, Yang Yan, Henry Sleight, Ethan Perez, Mrinank Sharma</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.17158">https://arxiv.org/abs/2508.17158</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.17158">https://arxiv.org/pdf/2508.17158</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.17158]] Towards Safeguarding LLM Fine-tuning APIs against Cipher Attacks(https://arxiv.org/abs/2508.17158)</code><input type="text"></li>
<li><strong>Keywords: </strong>defense, attack, robust, large language model</a></li>
<li><strong>Abstract: </strong>Large language model fine-tuning APIs enable widespread model customization, yet pose significant safety risks. Recent work shows that adversaries can exploit access to these APIs to bypass model safety mechanisms by encoding harmful content in seemingly harmless fine-tuning data, evading both human monitoring and standard content filters. We formalize the fine-tuning API defense problem, and introduce the Cipher Fine-tuning Robustness benchmark (CIFR), a benchmark for evaluating defense strategies' ability to retain model safety in the face of cipher-enabled attackers while achieving the desired level of fine-tuning functionality. We include diverse cipher encodings and families, with some kept exclusively in the test set to evaluate for generalization across unseen ciphers and cipher families. We then evaluate different defenses on the benchmark and train probe monitors on model internal activations from multiple fine-tunes. We show that probe monitors achieve over 99% detection accuracy, generalize to unseen cipher variants and families, and compare favorably to state-of-the-art monitoring approaches. We open-source CIFR and the code to reproduce our experiments to facilitate further research in this critical area. Code and data are available online this https URL</li>
</ul>

<h3>Title: Quantifying Language Disparities in Multilingual Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Songbo Hu, Ivan Vuliƒá, Anna Korhonen</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.17162">https://arxiv.org/abs/2508.17162</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.17162">https://arxiv.org/pdf/2508.17162</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.17162]] Quantifying Language Disparities in Multilingual Large Language Models(https://arxiv.org/abs/2508.17162)</code><input type="text"></li>
<li><strong>Keywords: </strong>fair, large language model</a></li>
<li><strong>Abstract: </strong>Results reported in large-scale multilingual evaluations are often fragmented and confounded by factors such as target languages, differences in experimental setups, and model choices. We propose a framework that disentangles these confounding variables and introduces three interpretable metrics--the performance realisation ratio, its coefficient of variation, and language potential--enabling a finer-grained and more insightful quantification of actual performance disparities across both (i) models and (ii) languages. Through a case study of 13 model variants on 11 multilingual datasets, we demonstrate that our framework provides a more reliable measurement of model performance and language disparities, particularly for low-resource languages, which have so far proven challenging to evaluate. Importantly, our results reveal that higher overall model performance does not necessarily imply greater fairness across languages.</li>
</ul>

<h3>Title: The Impact of Annotator Personas on LLM Behavior Across the Perspectivism Spectrum</h3>
<ul>
<li><strong>Authors: </strong>Olufunke O. Sarumi, Charles Welch, Daniel Braun, J√∂rg Schl√∂tterer</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.17164">https://arxiv.org/abs/2508.17164</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.17164">https://arxiv.org/pdf/2508.17164</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.17164]] The Impact of Annotator Personas on LLM Behavior Across the Perspectivism Spectrum(https://arxiv.org/abs/2508.17164)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>In this work, we explore the capability of Large Language Models (LLMs) to annotate hate speech and abusiveness while considering predefined annotator personas within the strong-to-weak data perspectivism spectra. We evaluated LLM-generated annotations against existing annotator modeling techniques for perspective modeling. Our findings show that LLMs selectively use demographic attributes from the personas. We identified prototypical annotators, with persona features that show varying degrees of alignment with the original human annotators. Within the data perspectivism paradigm, annotator modeling techniques that do not explicitly rely on annotator information performed better under weak data perspectivism compared to both strong data perspectivism and human annotations, suggesting LLM-generated views tend towards aggregation despite subjective prompting. However, for more personalized datasets tailored to strong perspectivism, the performance of LLM annotator modeling approached, but did not exceed, human annotators.</li>
</ul>

<h3>Title: Development of an isotropic segmentation model for medial temporal lobe subregions on anisotropic MRI atlas using implicit neural representation</h3>
<ul>
<li><strong>Authors: </strong>Yue Li, Pulkit Khandelwal, Rohit Jena, Long Xie, Michael Duong, Amanda E. Denning, Christopher A. Brown, Laura E. M. Wisse, Sandhitsu R. Das, David A. Wolk, Paul A. Yushkevich</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.17171">https://arxiv.org/abs/2508.17171</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.17171">https://arxiv.org/pdf/2508.17171</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.17171]] Development of an isotropic segmentation model for medial temporal lobe subregions on anisotropic MRI atlas using implicit neural representation(https://arxiv.org/abs/2508.17171)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction, segmentation</a></li>
<li><strong>Abstract: </strong>Imaging biomarkers in magnetic resonance imaging (MRI) are important tools for diagnosing and tracking Alzheimer's disease (AD). As medial temporal lobe (MTL) is the earliest region to show AD-related hallmarks, brain atrophy caused by AD can first be observed in the MTL. Accurate segmentation of MTL subregions and extraction of imaging biomarkers from them are important. However, due to imaging limitations, the resolution of T2-weighted (T2w) MRI is anisotropic, which makes it difficult to accurately extract the thickness of cortical subregions in the MTL. In this study, we used an implicit neural representation method to combine the resolution advantages of T1-weighted and T2w MRI to accurately upsample an MTL subregion atlas set from anisotropic space to isotropic space, establishing a multi-modality, high-resolution atlas set. Based on this atlas, we developed an isotropic MTL subregion segmentation model. In an independent test set, the cortical subregion thickness extracted using this isotropic model showed higher significance than an anisotropic method in distinguishing between participants with mild cognitive impairment and cognitively unimpaired (CU) participants. In longitudinal analysis, the biomarkers extracted using isotropic method showed greater stability in CU participants. This study improved the accuracy of AD imaging biomarkers without increasing the amount of atlas annotation work, which may help to more accurately quantify the relationship between AD and brain atrophy and provide more accurate measures for disease tracking.</li>
</ul>

<h3>Title: Sharpness-Aware Geometric Defense for Robust Out-Of-Distribution Detection</h3>
<ul>
<li><strong>Authors: </strong>Jeng-Lin Li, Ming-Ching Chang, Wei-Chao Chen</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.17174">https://arxiv.org/abs/2508.17174</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.17174">https://arxiv.org/pdf/2508.17174</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.17174]] Sharpness-Aware Geometric Defense for Robust Out-Of-Distribution Detection(https://arxiv.org/abs/2508.17174)</code><input type="text"></li>
<li><strong>Keywords: </strong>defense, attack, robust</a></li>
<li><strong>Abstract: </strong>Out-of-distribution (OOD) detection ensures safe and reliable model deployment. Contemporary OOD algorithms using geometry projection can detect OOD or adversarial samples from clean in-distribution (ID) samples. However, this setting regards adversarial ID samples as OOD, leading to incorrect OOD predictions. Existing efforts on OOD detection with ID and OOD data under attacks are minimal. In this paper, we develop a robust OOD detection method that distinguishes adversarial ID samples from OOD ones. The sharp loss landscape created by adversarial training hinders model convergence, impacting the latent embedding quality for OOD score calculation. Therefore, we introduce a {\bf Sharpness-aware Geometric Defense (SaGD)} framework to smooth out the rugged adversarial loss landscape in the projected latent geometry. Enhanced geometric embedding convergence enables accurate ID data characterization, benefiting OOD detection against adversarial attacks. We use Jitter-based perturbation in adversarial training to extend the defense ability against unseen attacks. Our SaGD framework significantly improves FPR and AUC over the state-of-the-art defense approaches in differentiating CIFAR-100 from six other OOD datasets under various attacks. We further examine the effects of perturbations at various adversarial training levels, revealing the relationship between the sharp loss landscape and adversarial OOD detection.</li>
</ul>

<h3>Title: Scaling Graph Transformers: A Comparative Study of Sparse and Dense Attention</h3>
<ul>
<li><strong>Authors: </strong>Leon Dimitrov</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.17175">https://arxiv.org/abs/2508.17175</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.17175">https://arxiv.org/pdf/2508.17175</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.17175]] Scaling Graph Transformers: A Comparative Study of Sparse and Dense Attention(https://arxiv.org/abs/2508.17175)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Graphs have become a central representation in machine learning for capturing relational and structured data across various domains. Traditional graph neural networks often struggle to capture long-range dependencies between nodes due to their local structure. Graph transformers overcome this by using attention mechanisms that allow nodes to exchange information globally. However, there are two types of attention in graph transformers: dense and sparse. In this paper, we compare these two attention mechanisms, analyze their trade-offs, and highlight when to use each. We also outline current challenges and problems in designing attention for graph transformers.</li>
</ul>

<h3>Title: LLM Assertiveness can be Mechanistically Decomposed into Emotional and Logical Components</h3>
<ul>
<li><strong>Authors: </strong>Hikaru Tsujimura, Arush Tagade</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.17182">https://arxiv.org/abs/2508.17182</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.17182">https://arxiv.org/pdf/2508.17182</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.17182]] LLM Assertiveness can be Mechanistically Decomposed into Emotional and Logical Components(https://arxiv.org/abs/2508.17182)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability, large language model</a></li>
<li><strong>Abstract: </strong>Large Language Models (LLMs) often display overconfidence, presenting information with unwarranted certainty in high-stakes contexts. We investigate the internal basis of this behavior via mechanistic interpretability. Using open-sourced Llama 3.2 models fine-tuned on human annotated assertiveness datasets, we extract residual activations across all layers, and compute similarity metrics to localize assertive representations. Our analysis identifies layers most sensitive to assertiveness contrasts and reveals that high-assertive representations decompose into two orthogonal sub-components of emotional and logical clusters-paralleling the dual-route Elaboration Likelihood Model in Psychology. Steering vectors derived from these sub-components show distinct causal effects: emotional vectors broadly influence prediction accuracy, while logical vectors exert more localized effects. These findings provide mechanistic evidence for the multi-component structure of LLM assertiveness and highlight avenues for mitigating overconfident behavior.</li>
</ul>

<h3>Title: Towards Alignment-Centric Paradigm: A Survey of Instruction Tuning in Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Xudong Han, Junjie Yang, Tianyang Wang, Ziqian Bi, Junfeng Hao, Junhao Song</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.17184">https://arxiv.org/abs/2508.17184</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.17184">https://arxiv.org/pdf/2508.17184</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.17184]] Towards Alignment-Centric Paradigm: A Survey of Instruction Tuning in Large Language Models(https://arxiv.org/abs/2508.17184)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, large language model</a></li>
<li><strong>Abstract: </strong>Instruction tuning is a pivotal technique for aligning large language models (LLMs) with human intentions, safety constraints, and domain-specific requirements. This survey provides a comprehensive overview of the full pipeline, encompassing (i) data collection methodologies, (ii) full-parameter and parameter-efficient fine-tuning strategies, and (iii) evaluation protocols. We categorized data construction into three major paradigms: expert annotation, distillation from larger models, and self-improvement mechanisms, each offering distinct trade-offs between quality, scalability, and resource cost. Fine-tuning techniques range from conventional supervised training to lightweight approaches, such as low-rank adaptation (LoRA) and prefix tuning, with a focus on computational efficiency and model reusability. We further examine the challenges of evaluating faithfulness, utility, and safety across multilingual and multimodal scenarios, highlighting the emergence of domain-specific benchmarks in healthcare, legal, and financial applications. Finally, we discuss promising directions for automated data generation, adaptive optimization, and robust evaluation frameworks, arguing that a closer integration of data, algorithms, and human feedback is essential for advancing instruction-tuned LLMs. This survey aims to serve as a practical reference for researchers and practitioners seeking to design LLMs that are both effective and reliably aligned with human intentions.</li>
</ul>

<h3>Title: Advancing Weakly-Supervised Change Detection in Satellite Images via Adversarial Class Prompting</h3>
<ul>
<li><strong>Authors: </strong>Zhenghui Zhao, Chen Wu, Di Wang, Hongruixuan Chen, Cuiqun Chen, Zhuo Zheng, Bo Du, Liangpei Zhang</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.17186">https://arxiv.org/abs/2508.17186</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.17186">https://arxiv.org/pdf/2508.17186</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.17186]] Advancing Weakly-Supervised Change Detection in Satellite Images via Adversarial Class Prompting(https://arxiv.org/abs/2508.17186)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Weakly-Supervised Change Detection (WSCD) aims to distinguish specific object changes (e.g., objects appearing or disappearing) from background variations (e.g., environmental changes due to light, weather, or seasonal shifts) in paired satellite images, relying only on paired image (i.e., image-level) classification labels. This technique significantly reduces the need for dense annotations required in fully-supervised change detection. However, as image-level supervision only indicates whether objects have changed in a scene, WSCD methods often misclassify background variations as object changes, especially in complex remote-sensing scenarios. In this work, we propose an Adversarial Class Prompting (AdvCP) method to address this co-occurring noise problem, including two phases: a) Adversarial Prompt Mining: After each training iteration, we introduce adversarial prompting perturbations, using incorrect one-hot image-level labels to activate erroneous feature mappings. This process reveals co-occurring adversarial samples under weak supervision, namely background variation features that are likely to be misclassified as object changes. b) Adversarial Sample Rectification: We integrate these adversarially prompt-activated pixel samples into training by constructing an online global prototype. This prototype is built from an exponentially weighted moving average of the current batch and all historical training data. Our AdvCP can be seamlessly integrated into current WSCD methods without adding additional inference cost. Experiments on ConvNet, Transformer, and Segment Anything Model (SAM)-based baselines demonstrate significant performance enhancements. Furthermore, we demonstrate the generalizability of AdvCP to other multi-class weakly-supervised dense prediction scenarios. Code is available at this https URL</li>
</ul>

<h3>Title: BudgetThinker: Empowering Budget-aware LLM Reasoning with Control Tokens</h3>
<ul>
<li><strong>Authors: </strong>Hao Wen, Xinrui Wu, Yi Sun, Feifei Zhang, Liye Chen, Jie Wang, Yunxin Liu, Ya-Qin Zhang, Yuanchun Li</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.17196">https://arxiv.org/abs/2508.17196</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.17196">https://arxiv.org/pdf/2508.17196</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.17196]] BudgetThinker: Empowering Budget-aware LLM Reasoning with Control Tokens(https://arxiv.org/abs/2508.17196)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Recent advancements in Large Language Models (LLMs) have leveraged increased test-time computation to enhance reasoning capabilities, a strategy that, while effective, incurs significant latency and resource costs, limiting their applicability in real-world time-constrained or cost-sensitive scenarios. This paper introduces BudgetThinker, a novel framework designed to empower LLMs with budget-aware reasoning, enabling precise control over the length of their thought processes. We propose a methodology that periodically inserts special control tokens during inference to continuously inform the model of its remaining token budget. This approach is coupled with a comprehensive two-stage training pipeline, beginning with Supervised Fine-Tuning (SFT) to familiarize the model with budget constraints, followed by a curriculum-based Reinforcement Learning (RL) phase that utilizes a length-aware reward function to optimize for both accuracy and budget adherence. We demonstrate that BudgetThinker significantly surpasses strong baselines in maintaining performance across a variety of reasoning budgets on challenging mathematical benchmarks. Our method provides a scalable and effective solution for developing efficient and controllable LLM reasoning, making advanced models more practical for deployment in resource-constrained and real-time environments.</li>
</ul>

<h3>Title: Active Domain Knowledge Acquisition with \$100 Budget: Enhancing LLMs via Cost-Efficient, Expert-Involved Interaction in Sensitive Domains</h3>
<ul>
<li><strong>Authors: </strong>Yang Wu, Raha Moraffah, Rujing Yao, Jinhong Yu, Zhimin Tao, Xiaozhong Liu</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.17202">https://arxiv.org/abs/2508.17202</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.17202">https://arxiv.org/pdf/2508.17202</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.17202]] Active Domain Knowledge Acquisition with \$100 Budget: Enhancing LLMs via Cost-Efficient, Expert-Involved Interaction in Sensitive Domains(https://arxiv.org/abs/2508.17202)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large Language Models (LLMs) have demonstrated an impressive level of general knowledge. However, they often struggle in highly specialized and cost-sensitive domains such as drug discovery and rare disease research due to the lack of expert knowledge. In this paper, we propose a novel framework (PU-ADKA) designed to efficiently enhance domain-specific LLMs by actively engaging domain experts within a fixed budget. Unlike traditional fine-tuning approaches, PU-ADKA selectively identifies and queries the most appropriate expert from a team, taking into account each expert's availability, knowledge boundaries, and consultation costs. We train PU-ADKA using simulations on PubMed data and validate it through both controlled expert interactions and real-world deployment with a drug development team, demonstrating its effectiveness in enhancing LLM performance in specialized domains under strict budget constraints. In addition to outlining our methodological innovations and experimental results, we introduce a new benchmark dataset, CKAD, for cost-effective LLM domain knowledge acquisition to foster further research in this challenging area.</li>
</ul>

<h3>Title: Multi-Agent Visual-Language Reasoning for Comprehensive Highway Scene Understanding</h3>
<ul>
<li><strong>Authors: </strong>Yunxiang Yang, Ningning Xu, Jidong J. Yang</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI, cs.CL, eess.IV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.17205">https://arxiv.org/abs/2508.17205</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.17205">https://arxiv.org/pdf/2508.17205</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.17205]] Multi-Agent Visual-Language Reasoning for Comprehensive Highway Scene Understanding(https://arxiv.org/abs/2508.17205)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>This paper introduces a multi-agent framework for comprehensive highway scene understanding, designed around a mixture-of-experts strategy. In this framework, a large generic vision-language model (VLM), such as GPT-4o, is contextualized with domain knowledge to generates task-specific chain-of-thought (CoT) prompts. These fine-grained prompts are then used to guide a smaller, efficient VLM (e.g., Qwen2.5-VL-7B) in reasoning over short videos, along with complementary modalities as applicable. The framework simultaneously addresses multiple critical perception tasks, including weather classification, pavement wetness assessment, and traffic congestion detection, achieving robust multi-task reasoning while balancing accuracy and computational efficiency. To support empirical validation, we curated three specialized datasets aligned with these tasks. Notably, the pavement wetness dataset is multimodal, combining video streams with road weather sensor data, highlighting the benefits of multimodal reasoning. Experimental results demonstrate consistently strong performance across diverse traffic and environmental conditions. From a deployment perspective, the framework can be readily integrated with existing traffic camera systems and strategically applied to high-risk rural locations, such as sharp curves, flood-prone lowlands, or icy bridges. By continuously monitoring the targeted sites, the system enhances situational awareness and delivers timely alerts, even in resource-constrained environments.</li>
</ul>

<h3>Title: How to make Medical AI Systems safer? Simulating Vulnerabilities, and Threats in Multimodal Medical RAG System</h3>
<ul>
<li><strong>Authors: </strong>Kaiwen Zuo, Zelin Liu, Raman Dutt, Ziyang Wang, Zhongtian Sun, Yeming Wang, Fan Mo, Pietro Li√≤</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.17215">https://arxiv.org/abs/2508.17215</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.17215">https://arxiv.org/pdf/2508.17215</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.17215]] How to make Medical AI Systems safer? Simulating Vulnerabilities, and Threats in Multimodal Medical RAG System(https://arxiv.org/abs/2508.17215)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, attack, robust</a></li>
<li><strong>Abstract: </strong>Large Vision-Language Models (LVLMs) augmented with Retrieval-Augmented Generation (RAG) are increasingly employed in medical AI to enhance factual grounding through external clinical image-text retrieval. However, this reliance creates a significant attack surface. We propose MedThreatRAG, a novel multimodal poisoning framework that systematically probes vulnerabilities in medical RAG systems by injecting adversarial image-text pairs. A key innovation of our approach is the construction of a simulated semi-open attack environment, mimicking real-world medical systems that permit periodic knowledge base updates via user or pipeline contributions. Within this setting, we introduce and emphasize Cross-Modal Conflict Injection (CMCI), which embeds subtle semantic contradictions between medical images and their paired reports. These mismatches degrade retrieval and generation by disrupting cross-modal alignment while remaining sufficiently plausible to evade conventional filters. While basic textual and visual attacks are included for completeness, CMCI demonstrates the most severe degradation. Evaluations on IU-Xray and MIMIC-CXR QA tasks show that MedThreatRAG reduces answer F1 scores by up to 27.66% and lowers LLaVA-Med-1.5 F1 rates to as low as 51.36%. Our findings expose fundamental security gaps in clinical RAG systems and highlight the urgent need for threat-aware design and robust multimodal consistency checks. Finally, we conclude with a concise set of guidelines to inform the safe development of future multimodal medical RAG systems.</li>
</ul>

<h3>Title: Deep Learning with Self-Attention and Enhanced Preprocessing for Precise Diagnosis of Acute Lymphoblastic Leukemia from Bone Marrow Smears in Hemato-Oncology</h3>
<ul>
<li><strong>Authors: </strong>Md. Maruf, Md.Mahbubul Haque, Bishowjit Paul</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.17216">https://arxiv.org/abs/2508.17216</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.17216">https://arxiv.org/pdf/2508.17216</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.17216]] Deep Learning with Self-Attention and Enhanced Preprocessing for Precise Diagnosis of Acute Lymphoblastic Leukemia from Bone Marrow Smears in Hemato-Oncology(https://arxiv.org/abs/2508.17216)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Acute lymphoblastic leukemia (ALL) is a prevalent hematological malignancy in both pediatric and adult populations. Early and accurate detection with precise subtyping is essential for guiding therapy. Conventional workflows are complex, time-consuming, and prone to human error. We present a deep learning framework for automated ALL diagnosis from bone marrow smear images. The method combines a robust preprocessing pipeline with convolutional neural networks (CNNs) to standardize image quality and improve inference efficiency. As a key design, we insert a multi-head self-attention (MHSA) block into a VGG19 backbone to model long-range dependencies and contextual relationships among cellular features. To mitigate class imbalance, we train with Focal Loss. Across evaluated architectures, the enhanced VGG19+MHSA trained with Focal Loss achieves 99.25% accuracy, surpassing a strong ResNet101 baseline (98.62%). These results indicate that attention-augmented CNNs, coupled with targeted loss optimization and preprocessing, yield more discriminative representations of leukemic cell morphology. Our approach offers a highly accurate and computationally efficient tool for automated ALL recognition and subtyping, with potential to accelerate diagnostic workflows and support reliable decision-making in clinical settings.</li>
</ul>

<h3>Title: GPG-HT: Generalized Policy Gradient with History-Aware Decision Transformer for Probabilistic Path Planning</h3>
<ul>
<li><strong>Authors: </strong>Xing Wei, Yuqi Ouyang</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.17218">https://arxiv.org/abs/2508.17218</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.17218">https://arxiv.org/pdf/2508.17218</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.17218]] GPG-HT: Generalized Policy Gradient with History-Aware Decision Transformer for Probabilistic Path Planning(https://arxiv.org/abs/2508.17218)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>With the rapidly increased number of vehicles in urban areas, existing road infrastructure struggles to accommodate modern traffic demands, resulting in the issue of congestion. This highlights the importance of efficient path planning strategies. However, most recent navigation models focus solely on deterministic or time-dependent networks, while overlooking the correlations and the stochastic nature of traffic flows. In this work, we address the reliable shortest path problem within stochastic transportation networks under certain dependencies. We propose a path planning solution that integrates the decision Transformer with the Generalized Policy Gradient (GPG) framework. Based on the decision Transformer's capability to model long-term dependencies, our proposed solution improves the accuracy and stability of path decisions. Experimental results on the Sioux Falls Network (SFN) demonstrate that our approach outperforms previous baselines in terms of on-time arrival probability, providing more accurate path planning solutions.</li>
</ul>

<h3>Title: Exposing Privacy Risks in Graph Retrieval-Augmented Generation</h3>
<ul>
<li><strong>Authors: </strong>Jiale Liu, Jiahao Zhang, Suhang Wang</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.AI, cs.IR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.17222">https://arxiv.org/abs/2508.17222</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.17222">https://arxiv.org/pdf/2508.17222</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.17222]] Exposing Privacy Risks in Graph Retrieval-Augmented Generation(https://arxiv.org/abs/2508.17222)</code><input type="text"></li>
<li><strong>Keywords: </strong>secure, privacy, defense, attack, extraction, large language model</a></li>
<li><strong>Abstract: </strong>Retrieval-Augmented Generation (RAG) is a powerful technique for enhancing Large Language Models (LLMs) with external, up-to-date knowledge. Graph RAG has emerged as an advanced paradigm that leverages graph-based knowledge structures to provide more coherent and contextually rich answers. However, the move from plain document retrieval to structured graph traversal introduces new, under-explored privacy risks. This paper investigates the data extraction vulnerabilities of the Graph RAG systems. We design and execute tailored data extraction attacks to probe their susceptibility to leaking both raw text and structured data, such as entities and their relationships. Our findings reveal a critical trade-off: while Graph RAG systems may reduce raw text leakage, they are significantly more vulnerable to the extraction of structured entity and relationship information. We also explore potential defense mechanisms to mitigate these novel attack surfaces. This work provides a foundational analysis of the unique privacy challenges in Graph RAG and offers insights for building more secure systems.</li>
</ul>

<h3>Title: SSFO: Self-Supervised Faithfulness Optimization for Retrieval-Augmented Generation</h3>
<ul>
<li><strong>Authors: </strong>Xiaqiang Tang, Yi Wang, Keyu Hu, Rui Xu, Chuang Li, Weigao Sun, Jian Li, Sihong Xie</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.17225">https://arxiv.org/abs/2508.17225</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.17225">https://arxiv.org/pdf/2508.17225</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.17225]] SSFO: Self-Supervised Faithfulness Optimization for Retrieval-Augmented Generation(https://arxiv.org/abs/2508.17225)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Retrieval-Augmented Generation (RAG) systems require Large Language Models (LLMs) to generate responses that are faithful to the retrieved context. However, faithfulness hallucination remains a critical challenge, as existing methods often require costly supervision and post-training or significant inference burdens. To overcome these limitations, we introduce Self-Supervised Faithfulness Optimization (SSFO), the first self-supervised alignment approach for enhancing RAG faithfulness. SSFO constructs preference data pairs by contrasting the model's outputs generated with and without the context. Leveraging Direct Preference Optimization (DPO), SSFO aligns model faithfulness without incurring labeling costs or additional inference burden. We theoretically and empirically demonstrate that SSFO leverages a benign form of \emph{likelihood displacement}, transferring probability mass from parametric-based tokens to context-aligned tokens. Based on this insight, we propose a modified DPO loss function to encourage likelihood displacement. Comprehensive evaluations show that SSFO significantly outperforms existing methods, achieving state-of-the-art faithfulness on multiple context-based question-answering datasets. Notably, SSFO exhibits strong generalization, improving cross-lingual faithfulness and preserving general instruction-following capabilities. We release our code and model at the anonymous link: this https URL</li>
</ul>

<h3>Title: 4D Visual Pre-training for Robot Learning</h3>
<ul>
<li><strong>Authors: </strong>Chengkai Hou, Yanjie Ze, Yankai Fu, Zeyu Gao, Songbo Hu, Yue Yu, Shanghang Zhang, Huazhe Xu</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.17230">https://arxiv.org/abs/2508.17230</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.17230">https://arxiv.org/pdf/2508.17230</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.17230]] 4D Visual Pre-training for Robot Learning(https://arxiv.org/abs/2508.17230)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>General visual representations learned from web-scale datasets for robotics have achieved great success in recent years, enabling data-efficient robot learning on manipulation tasks; yet these pre-trained representations are mostly on 2D images, neglecting the inherent 3D nature of the world. However, due to the scarcity of large-scale 3D data, it is still hard to extract a universal 3D representation from web datasets. Instead, we are seeking a general visual pre-training framework that could improve all 3D representations as an alternative. Our framework, called FVP, is a novel 4D Visual Pre-training framework for real-world robot learning. FVP frames the visual pre-training objective as a next-point-cloud-prediction problem, models the prediction model as a diffusion model, and pre-trains the model on the larger public datasets directly. Across twelve real-world manipulation tasks, FVP boosts the average success rate of 3D Diffusion Policy (DP3) for these tasks by 28%. The FVP pre-trained DP3 achieves state-of-the-art performance across imitation learning methods. Moreover, the efficacy of FVP adapts across various point cloud encoders and datasets. Finally, we apply FVP to the RDT-1B, a larger Vision-Language-Action robotic model, enhancing its performance on various robot tasks. Our project page is available at: https://4d- this http URL.</li>
</ul>

<h3>Title: Module-Aware Parameter-Efficient Machine Unlearning on Transformers</h3>
<ul>
<li><strong>Authors: </strong>Wenjie Bao, Jian Lou, Yuke Hu, Xiaochen Li, Zhihao Liu, Jiaqi Liu, Zhan Qin, Kui Ren</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.17233">https://arxiv.org/abs/2508.17233</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.17233">https://arxiv.org/pdf/2508.17233</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.17233]] Module-Aware Parameter-Efficient Machine Unlearning on Transformers(https://arxiv.org/abs/2508.17233)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, robust, transformer</a></li>
<li><strong>Abstract: </strong>Transformer has become fundamental to a vast series of pre-trained large models that have achieved remarkable success across diverse applications. Machine unlearning, which focuses on efficiently removing specific data influences to comply with privacy regulations, shows promise in restricting updates to influence-critical parameters. However, existing parameter-efficient unlearning methods are largely devised in a module-oblivious manner, which tends to inaccurately identify these parameters and leads to inferior unlearning performance for Transformers. In this paper, we propose {\tt MAPE-Unlearn}, a module-aware parameter-efficient machine unlearning approach that uses a learnable pair of masks to pinpoint influence-critical parameters in the heads and filters of Transformers. The learning objective of these masks is derived by desiderata of unlearning and optimized through an efficient algorithm featured by a greedy search with a warm start. Extensive experiments on various Transformer models and datasets demonstrate the effectiveness and robustness of {\tt MAPE-Unlearn} for unlearning.</li>
</ul>

<h3>Title: ClaimGen-CN: A Large-scale Chinese Dataset for Legal Claim Generation</h3>
<ul>
<li><strong>Authors: </strong>Siying Zhou, Yiquan Wu, Hui Chen, Xavier Hu, Kun Kuang, Adam Jatowt, Ming Hu, Chunyan Zheng, Fei Wu</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.17234">https://arxiv.org/abs/2508.17234</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.17234">https://arxiv.org/pdf/2508.17234</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.17234]] ClaimGen-CN: A Large-scale Chinese Dataset for Legal Claim Generation(https://arxiv.org/abs/2508.17234)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Legal claims refer to the plaintiff's demands in a case and are essential to guiding judicial reasoning and case resolution. While many works have focused on improving the efficiency of legal professionals, the research on helping non-professionals (e.g., plaintiffs) remains unexplored. This paper explores the problem of legal claim generation based on the given case's facts. First, we construct ClaimGen-CN, the first dataset for Chinese legal claim generation task, from various real-world legal disputes. Additionally, we design an evaluation metric tailored for assessing the generated claims, which encompasses two essential dimensions: factuality and clarity. Building on this, we conduct a comprehensive zero-shot evaluation of state-of-the-art general and legal-domain large language models. Our findings highlight the limitations of the current models in factual precision and expressive clarity, pointing to the need for more targeted development in this domain. To encourage further exploration of this important task, we will make the dataset publicly available.</li>
</ul>

<h3>Title: Uncovering and Mitigating Destructive Multi-Embedding Attacks in Deepfake Proactive Forensics</h3>
<ul>
<li><strong>Authors: </strong>Lixin Jia, Haiyang Sun, Zhiqing Guo, Yunfeng Diao, Dan Ma, Gaobo Yang</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.17247">https://arxiv.org/abs/2508.17247</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.17247">https://arxiv.org/pdf/2508.17247</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.17247]] Uncovering and Mitigating Destructive Multi-Embedding Attacks in Deepfake Proactive Forensics(https://arxiv.org/abs/2508.17247)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, privacy, protect, defense, attack, robust, watermark</a></li>
<li><strong>Abstract: </strong>With the rapid evolution of deepfake technologies and the wide dissemination of digital media, personal privacy is facing increasingly serious security threats. Deepfake proactive forensics, which involves embedding imperceptible watermarks to enable reliable source tracking, serves as a crucial defense against these threats. Although existing methods show strong forensic ability, they rely on an idealized assumption of single watermark embedding, which proves impractical in real-world scenarios. In this paper, we formally define and demonstrate the existence of Multi-Embedding Attacks (MEA) for the first time. When a previously protected image undergoes additional rounds of watermark embedding, the original forensic watermark can be destroyed or removed, rendering the entire proactive forensic mechanism ineffective. To address this vulnerability, we propose a general training paradigm named Adversarial Interference Simulation (AIS). Rather than modifying the network architecture, AIS explicitly simulates MEA scenarios during fine-tuning and introduces a resilience-driven loss function to enforce the learning of sparse and stable watermark representations. Our method enables the model to maintain the ability to extract the original watermark correctly even after a second embedding. Extensive experiments demonstrate that our plug-and-play AIS training paradigm significantly enhances the robustness of various existing methods against MEA.</li>
</ul>

<h3>Title: Routing Distilled Knowledge via Mixture of LoRA Experts for Large Language Model based Bundle Generation</h3>
<ul>
<li><strong>Authors: </strong>Kaidong Feng, Zhu Sun, Hui Fang, Jie Yang, Wenyuan Liu, Yew-Soon Ong</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.IR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.17250">https://arxiv.org/abs/2508.17250</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.17250">https://arxiv.org/pdf/2508.17250</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.17250]] Routing Distilled Knowledge via Mixture of LoRA Experts for Large Language Model based Bundle Generation(https://arxiv.org/abs/2508.17250)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large Language Models (LLMs) have shown potential in automatic bundle generation but suffer from prohibitive computational costs. Although knowledge distillation offers a pathway to more efficient student models, our preliminary study reveals that naively integrating diverse types of distilled knowledge from teacher LLMs into student LLMs leads to knowledge conflict, negatively impacting the performance of bundle generation. To address this, we propose RouteDK, a framework for routing distilled knowledge through a mixture of LoRA expert architecture. Specifically, we first distill knowledge from the teacher LLM for bundle generation in two complementary types: high-level knowledge (generalizable rules) and fine-grained knowledge (session-specific reasoning). We then train knowledge-specific LoRA experts for each type of knowledge together with a base LoRA expert. For effective integration, we propose a dynamic fusion module, featuring an input-aware router, where the router balances expert contributions by dynamically determining optimal weights based on input, thereby effectively mitigating knowledge conflicts. To further improve inference reliability, we design an inference-time enhancement module to reduce variance and mitigate suboptimal reasoning. Experiments on three public datasets show that our RouteDK achieves accuracy comparable to or even better than the teacher LLM, while maintaining strong computational efficiency. In addition, it outperforms state-of-the-art approaches for bundle generation.</li>
</ul>

<h3>Title: SEER-VAR: Semantic Egocentric Environment Reasoner for Vehicle Augmented Reality</h3>
<ul>
<li><strong>Authors: </strong>Yuzhi Lai, Shenghai Yuan, Peizheng Li, Jun Lou, Andreas Zell</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.RO</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.17255">https://arxiv.org/abs/2508.17255</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.17255">https://arxiv.org/pdf/2508.17255</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.17255]] SEER-VAR: Semantic Egocentric Environment Reasoner for Vehicle Augmented Reality(https://arxiv.org/abs/2508.17255)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>We present SEER-VAR, a novel framework for egocentric vehicle-based augmented reality (AR) that unifies semantic decomposition, Context-Aware SLAM Branches (CASB), and LLM-driven recommendation. Unlike existing systems that assume static or single-view settings, SEER-VAR dynamically separates cabin and road scenes via depth-guided vision-language grounding. Two SLAM branches track egocentric motion in each context, while a GPT-based module generates context-aware overlays such as dashboard cues and hazard alerts. To support evaluation, we introduce EgoSLAM-Drive, a real-world dataset featuring synchronized egocentric views, 6DoF ground-truth poses, and AR annotations across diverse driving scenarios. Experiments demonstrate that SEER-VAR achieves robust spatial alignment and perceptually coherent AR rendering across varied environments. As one of the first to explore LLM-based AR recommendation in egocentric driving, we address the lack of comparable systems through structured prompting and detailed user studies. Results show that SEER-VAR enhances perceived scene understanding, overlay relevance, and driver ease, providing an effective foundation for future research in this direction. Code and dataset will be made open source.</li>
</ul>

<h3>Title: Provable Generalization in Overparameterized Neural Nets</h3>
<ul>
<li><strong>Authors: </strong>Aviral Dhingra</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.17256">https://arxiv.org/abs/2508.17256</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.17256">https://arxiv.org/pdf/2508.17256</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.17256]] Provable Generalization in Overparameterized Neural Nets(https://arxiv.org/abs/2508.17256)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer, large language model</a></li>
<li><strong>Abstract: </strong>Deep neural networks often contain far more parameters than training examples, yet they still manage to generalize well in practice. Classical complexity measures such as VC-dimension or PAC-Bayes bounds usually become vacuous in this overparameterized regime, offering little explanation for the empirical success of models like Transformers. In this work, I explore an alternative notion of capacity for attention-based models, based on the effective rank of their attention matrices. The intuition is that, although the parameter count is enormous, the functional dimensionality of attention is often much lower. I show that this quantity leads to a generalization bound whose dependence on sample size matches empirical scaling laws observed in large language models, up to logarithmic factors. While the analysis is not a complete theory of overparameterized learning, it provides evidence that spectral properties of attention, rather than raw parameter counts, may be the right lens for understanding why these models generalize.</li>
</ul>

<h3>Title: Are You Sure You're Positive? Consolidating Chain-of-Thought Agents with Uncertainty Quantification for Aspect-Category Sentiment Analysis</h3>
<ul>
<li><strong>Authors: </strong>Filippos Ventirozos, Peter Appleby, Matthew Shardlow</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.IR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.17258">https://arxiv.org/abs/2508.17258</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.17258">https://arxiv.org/pdf/2508.17258</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.17258]] Are You Sure You're Positive? Consolidating Chain-of-Thought Agents with Uncertainty Quantification for Aspect-Category Sentiment Analysis(https://arxiv.org/abs/2508.17258)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Aspect-category sentiment analysis provides granular insights by identifying specific themes within product reviews that are associated with particular opinions. Supervised learning approaches dominate the field. However, data is scarce and expensive to annotate for new domains. We argue that leveraging large language models in a zero-shot setting is beneficial where the time and resources required for dataset annotation are limited. Furthermore, annotation bias may lead to strong results using supervised methods but transfer poorly to new domains in contexts that lack annotations and demand reproducibility. In our work, we propose novel techniques that combine multiple chain-of-thought agents by leveraging large language models' token-level uncertainty scores. We experiment with the 3B and 70B+ parameter size variants of Llama and Qwen models, demonstrating how these approaches can fulfil practical needs and opening a discussion on how to gauge accuracy in label-scarce conditions.</li>
</ul>

<h3>Title: ResLink: A Novel Deep Learning Architecture for Brain Tumor Classification with Area Attention and Residual Connections</h3>
<ul>
<li><strong>Authors: </strong>Sumedha Arya, Nirmal Gaud</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.17259">https://arxiv.org/abs/2508.17259</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.17259">https://arxiv.org/pdf/2508.17259</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.17259]] ResLink: A Novel Deep Learning Architecture for Brain Tumor Classification with Area Attention and Residual Connections(https://arxiv.org/abs/2508.17259)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Brain tumors show significant health challenges due to their potential to cause critical neurological functions. Early and accurate diagnosis is crucial for effective treatment. In this research, we propose ResLink, a novel deep learning architecture for brain tumor classification using CT scan images. ResLink integrates novel area attention mechanisms with residual connections to enhance feature learning and spatial understanding for spatially rich image classification tasks. The model employs a multi-stage convolutional pipeline, incorporating dropout, regularization, and downsampling, followed by a final attention-based refinement for classification. Trained on a balanced dataset, ResLink achieves a high accuracy of 95% and demonstrates strong generalizability. This research demonstrates the potential of ResLink in improving brain tumor classification, offering a robust and efficient technique for medical imaging applications.</li>
</ul>

<h3>Title: AdaGAT: Adaptive Guidance Adversarial Training for the Robustness of Deep Neural Networks</h3>
<ul>
<li><strong>Authors: </strong>Zhenyu Liu, Huizhi Liang, Xinrun Li, Vaclav Snasel, Varun Ojha</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.17265">https://arxiv.org/abs/2508.17265</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.17265">https://arxiv.org/pdf/2508.17265</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.17265]] AdaGAT: Adaptive Guidance Adversarial Training for the Robustness of Deep Neural Networks(https://arxiv.org/abs/2508.17265)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack, robust</a></li>
<li><strong>Abstract: </strong>Adversarial distillation (AD) is a knowledge distillation technique that facilitates the transfer of robustness from teacher deep neural network (DNN) models to lightweight target (student) DNN models, enabling the target models to perform better than only training the student model independently. Some previous works focus on using a small, learnable teacher (guide) model to improve the robustness of a student model. Since a learnable guide model starts learning from scratch, maintaining its optimal state for effective knowledge transfer during co-training is challenging. Therefore, we propose a novel Adaptive Guidance Adversarial Training (AdaGAT) method. Our method, AdaGAT, dynamically adjusts the training state of the guide model to install robustness to the target model. Specifically, we develop two separate loss functions as part of the AdaGAT method, allowing the guide model to participate more actively in backpropagation to achieve its optimal state. We evaluated our approach via extensive experiments on three datasets: CIFAR-10, CIFAR-100, and TinyImageNet, using the WideResNet-34-10 model as the target model. Our observations reveal that appropriately adjusting the guide model within a certain accuracy range enhances the target model's robustness across various adversarial attacks compared to a variety of baseline models.</li>
</ul>

<h3>Title: Deep Learning-Assisted Detection of Sarcopenia in Cross-Sectional Computed Tomography Imaging</h3>
<ul>
<li><strong>Authors: </strong>Manish Bhardwaj, Huizhi Liang, Ashwin Sivaharan, Sandip Nandhra, Vaclav Snasel, Tamer El-Sayed, Varun Ojha</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.17275">https://arxiv.org/abs/2508.17275</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.17275">https://arxiv.org/pdf/2508.17275</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.17275]] Deep Learning-Assisted Detection of Sarcopenia in Cross-Sectional Computed Tomography Imaging(https://arxiv.org/abs/2508.17275)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>Sarcopenia is a progressive loss of muscle mass and function linked to poor surgical outcomes such as prolonged hospital stays, impaired mobility, and increased mortality. Although it can be assessed through cross-sectional imaging by measuring skeletal muscle area (SMA), the process is time-consuming and adds to clinical workloads, limiting timely detection and management; however, this process could become more efficient and scalable with the assistance of artificial intelligence applications. This paper presents high-quality three-dimensional cross-sectional computed tomography (CT) images of patients with sarcopenia collected at the Freeman Hospital, Newcastle upon Tyne Hospitals NHS Foundation Trust. Expert clinicians manually annotated the SMA at the third lumbar vertebra, generating precise segmentation masks. We develop deep-learning models to measure SMA in CT images and automate this task. Our methodology employed transfer learning and self-supervised learning approaches using labelled and unlabeled CT scan datasets. While we developed qualitative assessment models for detecting sarcopenia, we observed that the quantitative assessment of SMA is more precise and informative. This approach also mitigates the issue of class imbalance and limited data availability. Our model predicted the SMA, on average, with an error of +-3 percentage points against the manually measured SMA. The average dice similarity coefficient of the predicted masks was 93%. Our results, therefore, show a pathway to full automation of sarcopenia assessment and detection.</li>
</ul>

<h3>Title: MTNet: Learning modality-aware representation with transformer for RGBT tracking</h3>
<ul>
<li><strong>Authors: </strong>Ruichao Hou, Boyue Xu, Tongwei Ren, Gangshan Wu</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.MM</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.17280">https://arxiv.org/abs/2508.17280</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.17280">https://arxiv.org/pdf/2508.17280</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.17280]] MTNet: Learning modality-aware representation with transformer for RGBT tracking(https://arxiv.org/abs/2508.17280)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, transformer</a></li>
<li><strong>Abstract: </strong>The ability to learn robust multi-modality representation has played a critical role in the development of RGBT tracking. However, the regular fusion paradigm and the invariable tracking template remain restrictive to the feature interaction. In this paper, we propose a modality-aware tracker based on transformer, termed MTNet. Specifically, a modality-aware network is presented to explore modality-specific cues, which contains both channel aggregation and distribution module(CADM) and spatial similarity perception module (SSPM). A transformer fusion network is then applied to capture global dependencies to reinforce instance representations. To estimate the precise location and tackle the challenges, such as scale variation and deformation, we design a trident prediction head and a dynamic update strategy which jointly maintain a reliable template for facilitating inter-frame communication. Extensive experiments validate that the proposed method achieves satisfactory results compared with the state-of-the-art competitors on three RGBT benchmarks while reaching real-time speed.</li>
</ul>

<h3>Title: From Language to Action: A Review of Large Language Models as Autonomous Agents and Tool Users</h3>
<ul>
<li><strong>Authors: </strong>Sadia Sultana Chowa, Riasad Alvi, Subhey Sadi Rahman, Md Abdur Rahman, Mohaimenul Azam Khan Raiaan, Md Rafiqul Islam, Mukhtar Hussain, Sami Azam</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.17281">https://arxiv.org/abs/2508.17281</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.17281">https://arxiv.org/pdf/2508.17281</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.17281]] From Language to Action: A Review of Large Language Models as Autonomous Agents and Tool Users(https://arxiv.org/abs/2508.17281)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>The pursuit of human-level artificial intelligence (AI) has significantly advanced the development of autonomous agents and Large Language Models (LLMs). LLMs are now widely utilized as decision-making agents for their ability to interpret instructions, manage sequential tasks, and adapt through feedback. This review examines recent developments in employing LLMs as autonomous agents and tool users and comprises seven research questions. We only used the papers published between 2023 and 2025 in conferences of the A* and A rank and Q1 journals. A structured analysis of the LLM agents' architectural design principles, dividing their applications into single-agent and multi-agent systems, and strategies for integrating external tools is presented. In addition, the cognitive mechanisms of LLM, including reasoning, planning, and memory, and the impact of prompting methods and fine-tuning procedures on agent performance are also investigated. Furthermore, we evaluated current benchmarks and assessment protocols and have provided an analysis of 68 publicly available datasets to assess the performance of LLM-based agents in various tasks. In conducting this review, we have identified critical findings on verifiable reasoning of LLMs, the capacity for self-improvement, and the personalization of LLM-based agents. Finally, we have discussed ten future research directions to overcome these gaps.</li>
</ul>

<h3>Title: Quickly Tuning Foundation Models for Image Segmentation</h3>
<ul>
<li><strong>Authors: </strong>Breenda Das, Lennart Purucker, Timur Carstensen, Frank Hutter</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.17283">https://arxiv.org/abs/2508.17283</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.17283">https://arxiv.org/pdf/2508.17283</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.17283]] Quickly Tuning Foundation Models for Image Segmentation(https://arxiv.org/abs/2508.17283)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>Foundation models like SAM (Segment Anything Model) exhibit strong zero-shot image segmentation performance, but often fall short on domain-specific tasks. Fine-tuning these models typically requires significant manual effort and domain expertise. In this work, we introduce QTT-SEG, a meta-learning-driven approach for automating and accelerating the fine-tuning of SAM for image segmentation. Built on the Quick-Tune hyperparameter optimization framework, QTT-SEG predicts high-performing configurations using meta-learned cost and performance models, efficiently navigating a search space of over 200 million possibilities. We evaluate QTT-SEG on eight binary and five multiclass segmentation datasets under tight time constraints. Our results show that QTT-SEG consistently improves upon SAM's zero-shot performance and surpasses AutoGluon Multimodal, a strong AutoML baseline, on most binary tasks within three minutes. On multiclass datasets, QTT-SEG delivers consistent gains as well. These findings highlight the promise of meta-learning in automating model adaptation for specialized segmentation tasks. Code available at: this https URL</li>
</ul>

<h3>Title: Explainable AI (XAI) for Arrhythmia detection from electrocardiograms</h3>
<ul>
<li><strong>Authors: </strong>Joschka Beck, Arlene John</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.17294">https://arxiv.org/abs/2508.17294</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.17294">https://arxiv.org/pdf/2508.17294</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.17294]] Explainable AI (XAI) for Arrhythmia detection from electrocardiograms(https://arxiv.org/abs/2508.17294)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability, segmentation</a></li>
<li><strong>Abstract: </strong>Advancements in deep learning have enabled highly accurate arrhythmia detection from electrocardiogram (ECG) signals, but limited interpretability remains a barrier to clinical adoption. This study investigates the application of Explainable AI (XAI) techniques specifically adapted for time-series ECG analysis. Using the MIT-BIH arrhythmia dataset, a convolutional neural network-based model was developed for arrhythmia classification, with R-peak-based segmentation via the Pan-Tompkins algorithm. To increase the dataset size and to reduce class imbalance, an additional 12-lead ECG dataset was incorporated. A user needs assessment was carried out to identify what kind of explanation would be preferred by medical professionals. Medical professionals indicated a preference for saliency map-based explanations over counterfactual visualisations, citing clearer correspondence with ECG interpretation workflows. Four SHapley Additive exPlanations (SHAP)-based approaches: permutation importance, KernelSHAP, gradient-based methods, and Deep Learning Important FeaTures (DeepLIFT), were implemented and compared. The model achieved 98.3% validation accuracy on MIT-BIH but showed performance degradation on the combined dataset, underscoring dataset variability challenges. Permutation importance and KernelSHAP produced cluttered visual outputs, while gradient-based and DeepLIFT methods highlighted waveform regions consistent with clinical reasoning, but with variability across samples. Findings emphasize the need for domain-specific XAI adaptations in ECG analysis and highlight saliency mapping as a more clinically intuitive approach</li>
</ul>

<h3>Title: Literature Review of the Effect of Quantum Computing on Cryptocurrencies using Blockchain Technology</h3>
<ul>
<li><strong>Authors: </strong>Adi Mutha, Jitendra Sandu</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.17296">https://arxiv.org/abs/2508.17296</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.17296">https://arxiv.org/pdf/2508.17296</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.17296]] Literature Review of the Effect of Quantum Computing on Cryptocurrencies using Blockchain Technology(https://arxiv.org/abs/2508.17296)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, attack</a></li>
<li><strong>Abstract: </strong>With the advent of quantum computing, cryptocurrencies that rely on blockchain technology face mounting cryptographic vulnerabilities. This paper presents a comprehensive literature review evaluating how quantum algorithms, specifically Shors and Grovers, could disrupt the foundational security mechanisms of cryptocurrencies. Shors algorithm poses a threat to public-key cryptographic schemes by enabling efficient factorization and discrete logarithm solving, thereby endangering digital signature systems. Grovers algorithm undermines hash-based functions, increasing the feasibility of fifty one percent attacks and hash collisions. By examining the internal mechanisms of major cryptocurrencies such as Bitcoin, Ethereum, Litecoin, Monero, and Zcash, this review identifies specific vulnerabilities in transaction and consensus processes. It further analyses the current hardware limitations of quantum systems and estimates when such attacks could become feasible. In anticipation, it investigates countermeasures including Post-Quantum Cryptography (PQC), Quantum Key Distribution (QKD), and protocol-level modifications such as memory-intensive proof-of-work algorithms and multi-signature schemes. The discussion integrates recent advancements in quantum error correction, hardware scalability, and NIST-standardized cryptographic algorithms. This review concludes that while quantum computers are not yet advanced enough to pose an immediate threat, proactive integration of quantum-resistant solutions is essential. The findings underscore the urgent need for cryptocurrencies to adopt post-quantum cryptographic standards to preserve the decentralized trust, integrity, and security that define blockchain-based digital cryptocurrencies.</li>
</ul>

<h3>Title: Explain Before You Answer: A Survey on Compositional Visual Reasoning</h3>
<ul>
<li><strong>Authors: </strong>Fucai Ke, Joy Hsu, Zhixi Cai, Zixian Ma, Xin Zheng, Xindi Wu, Sukai Huang, Weiqing Wang, Pari Delir Haghighi, Gholamreza Haffari, Ranjay Krishna, Jiajun Wu, Hamid Rezatofighi</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.17298">https://arxiv.org/abs/2508.17298</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.17298">https://arxiv.org/pdf/2508.17298</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.17298]] Explain Before You Answer: A Survey on Compositional Visual Reasoning(https://arxiv.org/abs/2508.17298)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, interpretability</a></li>
<li><strong>Abstract: </strong>Compositional visual reasoning has emerged as a key research frontier in multimodal AI, aiming to endow machines with the human-like ability to decompose visual scenes, ground intermediate concepts, and perform multi-step logical inference. While early surveys focus on monolithic vision-language models or general multimodal reasoning, a dedicated synthesis of the rapidly expanding compositional visual reasoning literature is still missing. We fill this gap with a comprehensive survey spanning 2023 to 2025 that systematically reviews 260+ papers from top venues (CVPR, ICCV, NeurIPS, ICML, ACL, etc.). We first formalize core definitions and describe why compositional approaches offer advantages in cognitive alignment, semantic fidelity, robustness, interpretability, and data efficiency. Next, we trace a five-stage paradigm shift: from prompt-enhanced language-centric pipelines, through tool-enhanced LLMs and tool-enhanced VLMs, to recently minted chain-of-thought reasoning and unified agentic VLMs, highlighting their architectural designs, strengths, and limitations. We then catalog 60+ benchmarks and corresponding metrics that probe compositional visual reasoning along dimensions such as grounding accuracy, chain-of-thought faithfulness, and high-resolution perception. Drawing on these analyses, we distill key insights, identify open challenges (e.g., limitations of LLM-based reasoning, hallucination, a bias toward deductive reasoning, scalable supervision, tool integration, and benchmark limitations), and outline future directions, including world-model integration, human-AI collaborative reasoning, and richer evaluation protocols. By offering a unified taxonomy, historical roadmap, and critical outlook, this survey aims to serve as a foundational reference and inspire the next generation of compositional visual reasoning research.</li>
</ul>

<h3>Title: FoundDiff: Foundational Diffusion Model for Generalizable Low-Dose CT Denoising</h3>
<ul>
<li><strong>Authors: </strong>Zhihao Chen, Qi Gao, Zilong Li, Junping Zhang, Yi Zhang, Jun Zhao, Hongming Shan</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.17299">https://arxiv.org/abs/2508.17299</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.17299">https://arxiv.org/pdf/2508.17299</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.17299]] FoundDiff: Foundational Diffusion Model for Generalizable Low-Dose CT Denoising(https://arxiv.org/abs/2508.17299)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, diffusion</a></li>
<li><strong>Abstract: </strong>Low-dose computed tomography (CT) denoising is crucial for reduced radiation exposure while ensuring diagnostically acceptable image quality. Despite significant advancements driven by deep learning (DL) in recent years, existing DL-based methods, typically trained on a specific dose level and anatomical region, struggle to handle diverse noise characteristics and anatomical heterogeneity during varied scanning conditions, limiting their generalizability and robustness in clinical scenarios. In this paper, we propose FoundDiff, a foundational diffusion model for unified and generalizable LDCT denoising across various dose levels and anatomical regions. FoundDiff employs a two-stage strategy: (i) dose-anatomy perception and (ii) adaptive denoising. First, we develop a dose- and anatomy-aware contrastive language image pre-training model (DA-CLIP) to achieve robust dose and anatomy perception by leveraging specialized contrastive learning strategies to learn continuous representations that quantify ordinal dose variations and identify salient anatomical regions. Second, we design a dose- and anatomy-aware diffusion model (DA-Diff) to perform adaptive and generalizable denoising by synergistically integrating the learned dose and anatomy embeddings from DACLIP into diffusion process via a novel dose and anatomy conditional block (DACB) based on Mamba. Extensive experiments on two public LDCT datasets encompassing eight dose levels and three anatomical regions demonstrate superior denoising performance of FoundDiff over existing state-of-the-art methods and the remarkable generalization to unseen dose levels. The codes and models are available at this https URL.</li>
</ul>

<h3>Title: PosBridge: Multi-View Positional Embedding Transplant for Identity-Aware Image Editing</h3>
<ul>
<li><strong>Authors: </strong>Peilin Xiong, Junwen Chen, Honghui Yuan, Keiji Yanai</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.17302">https://arxiv.org/abs/2508.17302</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.17302">https://arxiv.org/pdf/2508.17302</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.17302]] PosBridge: Multi-View Positional Embedding Transplant for Identity-Aware Image Editing(https://arxiv.org/abs/2508.17302)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, generative</a></li>
<li><strong>Abstract: </strong>Localized subject-driven image editing aims to seamlessly integrate user-specified objects into target scenes. As generative models continue to scale, training becomes increasingly costly in terms of memory and computation, highlighting the need for training-free and scalable editing this http URL this end, we propose PosBridge an efficient and flexible framework for inserting custom objects. A key component of our method is positional embedding transplant, which guides the diffusion model to faithfully replicate the structural characteristics of reference this http URL, we introduce the Corner Centered Layout, which concatenates reference images and the background image as input to the FLUX.1-Fill model. During progressive denoising, positional embedding transplant is applied to guide the noise distribution in the target region toward that of the reference object. In this way, Corner Centered Layout effectively directs the FLUX.1-Fill model to synthesize identity-consistent content at the desired location. Extensive experiments demonstrate that PosBridge outperforms mainstream baselines in structural consistency, appearance fidelity, and computational efficiency, showcasing its practical value and potential for broad adoption.</li>
</ul>

<h3>Title: An Efficient Recommendation Filtering-based Trust Model for Securing Internet of Things</h3>
<ul>
<li><strong>Authors: </strong>Muhammad Ibn Ziauddin, Rownak Rahad Rabbi, SM Mehrab, Fardin Faiyaz, Mosarrat Jahan</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.17304">https://arxiv.org/abs/2508.17304</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.17304">https://arxiv.org/pdf/2508.17304</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.17304]] An Efficient Recommendation Filtering-based Trust Model for Securing Internet of Things(https://arxiv.org/abs/2508.17304)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, attack, robust</a></li>
<li><strong>Abstract: </strong>Trust computation is crucial for ensuring the security of the Internet of Things (IoT). However, current trust-based mechanisms for IoT have limitations that impact data security. Sliding window-based trust schemes cannot ensure reliable trust computation due to their inability to select appropriate window lengths. Besides, recent trust scores are emphasized when considering the effect of time on trust. This can cause a sudden change in overall trust score based on recent behavior, potentially misinterpreting an honest service provider as malicious and vice versa. Moreover, clustering mechanisms used to filter recommendations in trust computation often lead to slower results. In this paper, we propose a robust trust model to address these limitations. The proposed approach determines the window length dynamically to guarantee accurate trust computation. It uses the harmonic mean of average trust score and time to prevent sudden fluctuations in trust scores. Additionally, an efficient personalized subspace clustering algorithm is used to exclude recommendations. We present a security analysis demonstrating the resiliency of the proposed scheme against bad-mouthing, ballot-stuffing, and on-off attacks. The proposed scheme demonstrates a competitive performance in detecting bad-mouthing attacks, while outperforming existing works with an approximately 44% improvement in accuracy for detecting on-off attacks. It maintains its effectiveness even when the percentage of on-off attackers increases and in scenarios where multiple attacks occur simultaneously. Additionally, the proposed scheme reduces the recommendation filtering time by 95%.</li>
</ul>

<h3>Title: First Place Solution to the MLCAS 2025 GWFSS Challenge: The Devil is in the Detail and Minority</h3>
<ul>
<li><strong>Authors: </strong>Songliang Cao, Tianqi Hu, Hao Lu</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.17305">https://arxiv.org/abs/2508.17305</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.17305">https://arxiv.org/pdf/2508.17305</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.17305]] First Place Solution to the MLCAS 2025 GWFSS Challenge: The Devil is in the Detail and Minority(https://arxiv.org/abs/2508.17305)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>In this report, we present our solution during the participation of the MLCAS 2025 GWFSS Challenge. This challenge hosts a semantic segmentation competition specific to wheat plants, which requires to segment three wheat organs including the head, leaf, and stem, and another background class. In 2025, participating a segmentation competition is significantly different from that in previous years where many tricks can play important roles. Nowadays most segmentation tricks have been well integrated into existing codebases such that our naive ViT-Adapter baseline has already achieved sufficiently good performance. Hence, we believe the key to stand out among other competitors is to focus on the problem nature of wheat per se. By probing visualizations, we identify the key -- the stem matters. In contrast to heads and leaves, stems exhibit fine structure and occupy only few pixels, which suffers from fragile predictions and class imbalance. Building on our baseline, we present three technical improvements tailored to stems: i) incorporating a dynamic upsampler SAPA used to enhance detail delineation; ii) leveraging semi-supervised guided distillation with stem-aware sample selection to mine the treasure beneath unlabeled data; and iii) applying a test-time scaling strategy to zoom in and segment twice the image. Despite being simple, the three improvements bring us to the first place of the competition, outperforming the second place by clear margins. Code and models will be released at this https URL.</li>
</ul>

<h3>Title: Defending Deepfake via Texture Feature Perturbation</h3>
<ul>
<li><strong>Authors: </strong>Xiao Zhang, Changfang Chen, Tianyi Wang</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.17315">https://arxiv.org/abs/2508.17315</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.17315">https://arxiv.org/pdf/2508.17315</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.17315]] Defending Deepfake via Texture Feature Perturbation(https://arxiv.org/abs/2508.17315)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, defense, attack</a></li>
<li><strong>Abstract: </strong>The rapid development of Deepfake technology poses severe challenges to social trust and information security. While most existing detection methods primarily rely on passive analyses, due to unresolvable high-quality Deepfake contents, proactive defense has recently emerged by inserting invisible signals in advance of image editing. In this paper, we introduce a proactive Deepfake detection approach based on facial texture features. Since human eyes are more sensitive to perturbations in smooth regions, we invisibly insert perturbations within texture regions that have low perceptual saliency, applying localized perturbations to key texture regions while minimizing unwanted noise in non-textured areas. Our texture-guided perturbation framework first extracts preliminary texture features via Local Binary Patterns (LBP), and then introduces a dual-model attention strategy to generate and optimize texture perturbations. Experiments on CelebA-HQ and LFW datasets demonstrate the promising performance of our method in distorting Deepfake generation and producing obvious visual defects under multiple attack models, providing an efficient and scalable solution for proactive Deepfake detection.</li>
</ul>

<h3>Title: AdaptiveK Sparse Autoencoders: Dynamic Sparsity Allocation for Interpretable LLM Representations</h3>
<ul>
<li><strong>Authors: </strong>Yifei Yao, Mengnan Du</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.17320">https://arxiv.org/abs/2508.17320</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.17320">https://arxiv.org/pdf/2508.17320</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.17320]] AdaptiveK Sparse Autoencoders: Dynamic Sparsity Allocation for Interpretable LLM Representations(https://arxiv.org/abs/2508.17320)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability, large language model</a></li>
<li><strong>Abstract: </strong>Understanding the internal representations of large language models (LLMs) remains a central challenge for interpretability research. Sparse autoencoders (SAEs) offer a promising solution by decomposing activations into interpretable features, but existing approaches rely on fixed sparsity constraints that fail to account for input complexity. We propose Adaptive Top K Sparse Autoencoders (AdaptiveK), a novel framework that dynamically adjusts sparsity levels based on the semantic complexity of each input. Leveraging linear probes, we demonstrate that context complexity is linearly encoded in LLM representations, and we use this signal to guide feature allocation during training. Experiments across three language models (Pythia-70M, Pythia-160M, and Gemma-2-2B) demonstrate that this complexity-driven adaptation significantly outperforms fixed-sparsity approaches on reconstruction fidelity, explained variance, and cosine similarity metrics while eliminating the computational burden of extensive hyperparameter tuning.</li>
</ul>

<h3>Title: CultranAI at PalmX 2025: Data Augmentation for Cultural Knowledge Representation</h3>
<ul>
<li><strong>Authors: </strong>Hunzalah Hassan Bhatti, Youssef Ahmed, Md Arid Hasan, Firoj Alam</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.17324">https://arxiv.org/abs/2508.17324</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.17324">https://arxiv.org/pdf/2508.17324</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.17324]] CultranAI at PalmX 2025: Data Augmentation for Cultural Knowledge Representation(https://arxiv.org/abs/2508.17324)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>In this paper, we report our participation to the PalmX cultural evaluation shared task. Our system, CultranAI, focused on data augmentation and LoRA fine-tuning of large language models (LLMs) for Arabic cultural knowledge representation. We benchmarked several LLMs to identify the best-performing model for the task. In addition to utilizing the PalmX dataset, we augmented it by incorporating the Palm dataset and curated a new dataset of over 22K culturally grounded multiple-choice questions (MCQs). Our experiments showed that the Fanar-1-9B-Instruct model achieved the highest performance. We fine-tuned this model on the combined augmented dataset of 22K+ MCQs. On the blind test set, our submitted system ranked 5th with an accuracy of 70.50%, while on the PalmX development set, it achieved an accuracy of 84.1%.</li>
</ul>

<h3>Title: Risk Assessment and Security Analysis of Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Xiaoyan Zhang, Dongyang Lyu, Xiaoqi Li</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.17329">https://arxiv.org/abs/2508.17329</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.17329">https://arxiv.org/pdf/2508.17329</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.17329]] Risk Assessment and Security Analysis of Large Language Models(https://arxiv.org/abs/2508.17329)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, privacy, protect, attack, watermark, transformer, large language model</a></li>
<li><strong>Abstract: </strong>As large language models (LLMs) expose systemic security challenges in high risk applications, including privacy leaks, bias amplification, and malicious abuse, there is an urgent need for a dynamic risk assessment and collaborative defence framework that covers their entire life cycle. This paper focuses on the security problems of large language models (LLMs) in critical application scenarios, such as the possibility of disclosure of user data, the deliberate input of harmful instructions, or the models bias. To solve these problems, we describe the design of a system for dynamic risk assessment and a hierarchical defence system that allows different levels of protection to cooperate. This paper presents a risk assessment system capable of evaluating both static and dynamic indicators simultaneously. It uses entropy weighting to calculate essential data, such as the frequency of sensitive words, whether the API call is typical, the realtime risk entropy value is significant, and the degree of context deviation. The experimental results show that the system is capable of identifying concealed attacks, such as role escape, and can perform rapid risk evaluation. The paper uses a hybrid model called BERT-CRF (Bidirectional Encoder Representation from Transformers) at the input layer to identify and filter malicious commands. The model layer uses dynamic adversarial training and differential privacy noise injection technology together. The output layer also has a neural watermarking system that can track the source of the content. In practice, the quality of this method, especially important in terms of customer service in the financial industry.</li>
</ul>

<h3>Title: DropLoRA: Sparse Low-Rank Adaptation for Parameter-Efficient Fine-Tuning</h3>
<ul>
<li><strong>Authors: </strong>Haojie Zhang</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.17337">https://arxiv.org/abs/2508.17337</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.17337">https://arxiv.org/pdf/2508.17337</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.17337]] DropLoRA: Sparse Low-Rank Adaptation for Parameter-Efficient Fine-Tuning(https://arxiv.org/abs/2508.17337)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>LoRA-based large model parameter-efficient fine-tuning (PEFT) methods use low-rank de- composition to approximate updates to model parameters. However, compared to full- parameter fine-tuning, low-rank updates often lead to a performance gap in downstream tasks. To address this, we introduce DropLoRA, a novel pruning-based approach that focuses on pruning the rank dimension. Unlike conven- tional methods that attempt to overcome the low-rank bottleneck, DropLoRA innovatively integrates a pruning module between the two low-rank matrices in LoRA to simulate dy- namic subspace learning. This dynamic low- rank subspace learning allows DropLoRA to overcome the limitations of traditional LoRA, which operates within a static subspace. By continuously adapting the learning subspace, DropLoRA significantly boosts performance without incurring additional training or infer- ence costs. Our experimental results demon- strate that DropLoRA consistently outperforms LoRA in fine-tuning the LLaMA series across a wide range of large language model gener- ation tasks, including commonsense reason- ing, mathematical reasoning, code generation, and instruction-following. Our code is avail- able at this https URL.</li>
</ul>

<h3>Title: Capturing Legal Reasoning Paths from Facts to Law in Court Judgments using Knowledge Graphs</h3>
<ul>
<li><strong>Authors: </strong>Ryoma Kondo, Riona Matsuoka, Takahiro Yoshida, Kazuyuki Yamasawa, Ryohei Hisano</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.DB, cs.IR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.17340">https://arxiv.org/abs/2508.17340</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.17340">https://arxiv.org/pdf/2508.17340</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.17340]] Capturing Legal Reasoning Paths from Facts to Law in Court Judgments using Knowledge Graphs(https://arxiv.org/abs/2508.17340)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Court judgments reveal how legal rules have been interpreted and applied to facts, providing a foundation for understanding structured legal reasoning. However, existing automated approaches for capturing legal reasoning, including large language models, often fail to identify the relevant legal context, do not accurately trace how facts relate to legal norms, and may misrepresent the layered structure of judicial reasoning. These limitations hinder the ability to capture how courts apply the law to facts in practice. In this paper, we address these challenges by constructing a legal knowledge graph from 648 Japanese administrative court decisions. Our method extracts components of legal reasoning using prompt-based large language models, normalizes references to legal provisions, and links facts, norms, and legal applications through an ontology of legal inference. The resulting graph captures the full structure of legal reasoning as it appears in real court decisions, making implicit reasoning explicit and machine-readable. We evaluate our system using expert annotated data, and find that it achieves more accurate retrieval of relevant legal provisions from facts than large language model baselines and retrieval-augmented methods.</li>
</ul>

<h3>Title: MetaFed: Advancing Privacy, Performance, and Sustainability in Federated Metaverse Systems</h3>
<ul>
<li><strong>Authors: </strong>Muhammet Anil Yagiz, Zeynep Sude Cengiz, Polat Goktas</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CR, cs.CY, cs.DC, cs.ET</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.17341">https://arxiv.org/abs/2508.17341</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.17341">https://arxiv.org/pdf/2508.17341</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.17341]] MetaFed: Advancing Privacy, Performance, and Sustainability in Federated Metaverse Systems(https://arxiv.org/abs/2508.17341)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, federate</a></li>
<li><strong>Abstract: </strong>The rapid expansion of immersive Metaverse applications introduces complex challenges at the intersection of performance, privacy, and environmental sustainability. Centralized architectures fall short in addressing these demands, often resulting in elevated energy consumption, latency, and privacy concerns. This paper proposes MetaFed, a decentralized federated learning (FL) framework that enables sustainable and intelligent resource orchestration for Metaverse environments. MetaFed integrates (i) multi-agent reinforcement learning for dynamic client selection, (ii) privacy-preserving FL using homomorphic encryption, and (iii) carbon-aware scheduling aligned with renewable energy availability. Evaluations on MNIST and CIFAR-10 using lightweight ResNet architectures demonstrate that MetaFed achieves up to 25\% reduction in carbon emissions compared to conventional approaches, while maintaining high accuracy and minimal communication overhead. These results highlight MetaFed as a scalable solution for building environmentally responsible and privacy-compliant Metaverse infrastructures.</li>
</ul>

<h3>Title: ShortListing Model: A Streamlined SimplexDiffusion for Discrete Variable Generation</h3>
<ul>
<li><strong>Authors: </strong>Yuxuan Song, Zhe Zhang, Yu Pei, Jingjing Gong, Qiying Yu, Zheng Zhang, Mingxuan Wang, Hao Zhou, Jingjing Liu, Wei-Ying Ma</a></li>
<li><strong>Subjects: </strong>cs.LG, q-bio.GN</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.17345">https://arxiv.org/abs/2508.17345</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.17345">https://arxiv.org/pdf/2508.17345</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.17345]] ShortListing Model: A Streamlined SimplexDiffusion for Discrete Variable Generation(https://arxiv.org/abs/2508.17345)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, generative</a></li>
<li><strong>Abstract: </strong>Generative modeling of discrete variables is challenging yet crucial for applications in natural language processing and biological sequence design. We introduce the Shortlisting Model (SLM), a novel simplex-based diffusion model inspired by progressive candidate pruning. SLM operates on simplex centroids, reducing generation complexity and enhancing scalability. Additionally, SLM incorporates a flexible implementation of classifier-free guidance, enhancing unconditional generation performance. Extensive experiments on DNA promoter and enhancer design, protein design, character-level and large-vocabulary language modeling demonstrate the competitive performance and strong potential of SLM. Our code can be found at this https URL</li>
</ul>

<h3>Title: No Pixel Left Behind: A Detail-Preserving Architecture for Robust High-Resolution AI-Generated Image Detection</h3>
<ul>
<li><strong>Authors: </strong>Lianrui Mu, Zou Xingze, Jianhong Bai, Jiaqi Hu, Wenjie Zheng, Jiangnan Ye, Jiedong Zhuang, Mudassar Ali, Jing Wang, Haoji Hu</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.17346">https://arxiv.org/abs/2508.17346</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.17346">https://arxiv.org/pdf/2508.17346</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.17346]] No Pixel Left Behind: A Detail-Preserving Architecture for Robust High-Resolution AI-Generated Image Detection(https://arxiv.org/abs/2508.17346)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, generative</a></li>
<li><strong>Abstract: </strong>The rapid growth of high-resolution, meticulously crafted AI-generated images poses a significant challenge to existing detection methods, which are often trained and evaluated on low-resolution, automatically generated datasets that do not align with the complexities of high-resolution scenarios. A common practice is to resize or center-crop high-resolution images to fit standard network inputs. However, without full coverage of all pixels, such strategies risk either obscuring subtle, high-frequency artifacts or discarding information from uncovered regions, leading to input information loss. In this paper, we introduce the High-Resolution Detail-Aggregation Network (HiDA-Net), a novel framework that ensures no pixel is left behind. We use the Feature Aggregation Module (FAM), which fuses features from multiple full-resolution local tiles with a down-sampled global view of the image. These local features are aggregated and fused with global representations for final prediction, ensuring that native-resolution details are preserved and utilized for detection. To enhance robustness against challenges such as localized AI manipulations and compression, we introduce Token-wise Forgery Localization (TFL) module for fine-grained spatial sensitivity and JPEG Quality Factor Estimation (QFE) module to disentangle generative artifacts from compression noise explicitly. Furthermore, to facilitate future research, we introduce HiRes-50K, a new challenging benchmark consisting of 50,568 images with up to 64 megapixels. Extensive experiments show that HiDA-Net achieves state-of-the-art, increasing accuracy by over 13% on the challenging Chameleon dataset and 10% on our HiRes-50K.</li>
</ul>

<h3>Title: DiCache: Let Diffusion Model Determine Its Own Cache</h3>
<ul>
<li><strong>Authors: </strong>Jiazi Bu, Pengyang Ling, Yujie Zhou, Yibin Wang, Yuhang Zang, Tong Wu, Dahua Lin, Jiaqi Wang</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.17356">https://arxiv.org/abs/2508.17356</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.17356">https://arxiv.org/pdf/2508.17356</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.17356]] DiCache: Let Diffusion Model Determine Its Own Cache(https://arxiv.org/abs/2508.17356)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>Recent years have witnessed the rapid development of acceleration techniques for diffusion models, especially caching-based acceleration methods. These studies seek to answer two fundamental questions: "When to cache" and "How to use cache", typically relying on predefined empirical laws or dataset-level priors to determine the timing of caching and utilizing handcrafted rules for leveraging multi-step caches. However, given the highly dynamic nature of the diffusion process, they often exhibit limited generalizability and fail on outlier samples. In this paper, a strong correlation is revealed between the variation patterns of the shallow-layer feature differences in the diffusion model and those of final model outputs. Moreover, we have observed that the features from different model layers form similar trajectories. Based on these observations, we present DiCache, a novel training-free adaptive caching strategy for accelerating diffusion models at runtime, answering both when and how to cache within a unified framework. Specifically, DiCache is composed of two principal components: (1) Online Probe Profiling Scheme leverages a shallow-layer online probe to obtain a stable prior for the caching error in real time, enabling the model to autonomously determine caching schedules. (2) Dynamic Cache Trajectory Alignment combines multi-step caches based on shallow-layer probe feature trajectory to better approximate the current feature, facilitating higher visual quality. Extensive experiments validate DiCache's capability in achieving higher efficiency and improved visual fidelity over state-of-the-art methods on various leading diffusion models including WAN 2.1, HunyuanVideo for video generation, and Flux for image generation.</li>
</ul>

<h3>Title: Trust Me, I Know This Function: Hijacking LLM Static Analysis using Bias</h3>
<ul>
<li><strong>Authors: </strong>Shir Bernstein, David Beste, Daniel Ayzenshteyn, Lea Schonherr, Yisroel Mirsky</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.17361">https://arxiv.org/abs/2508.17361</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.17361">https://arxiv.org/pdf/2508.17361</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.17361]] Trust Me, I Know This Function: Hijacking LLM Static Analysis using Bias(https://arxiv.org/abs/2508.17361)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack, robust, large language model</a></li>
<li><strong>Abstract: </strong>Large Language Models (LLMs) are increasingly trusted to perform automated code review and static analysis at scale, supporting tasks such as vulnerability detection, summarization, and refactoring. In this paper, we identify and exploit a critical vulnerability in LLM-based code analysis: an abstraction bias that causes models to overgeneralize familiar programming patterns and overlook small, meaningful bugs. Adversaries can exploit this blind spot to hijack the control flow of the LLM's interpretation with minimal edits and without affecting actual runtime behavior. We refer to this attack as a Familiar Pattern Attack (FPA). We develop a fully automated, black-box algorithm that discovers and injects FPAs into target code. Our evaluation shows that FPAs are not only effective, but also transferable across models (GPT-4o, Claude 3.5, Gemini 2.0) and universal across programming languages (Python, C, Rust, Go). Moreover, FPAs remain effective even when models are explicitly warned about the attack via robust system prompts. Finally, we explore positive, defensive uses of FPAs and discuss their broader implications for the reliability and safety of code-oriented LLMs.</li>
</ul>

<h3>Title: ShaLa: Multimodal Shared Latent Space Modelling</h3>
<ul>
<li><strong>Authors: </strong>Jiali Cui, Yan-Ying Chen, Yanxia Zhang, Matthew Klenk</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.17376">https://arxiv.org/abs/2508.17376</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.17376">https://arxiv.org/pdf/2508.17376</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.17376]] ShaLa: Multimodal Shared Latent Space Modelling(https://arxiv.org/abs/2508.17376)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, generative</a></li>
<li><strong>Abstract: </strong>This paper presents a novel generative framework for learning shared latent representations across multimodal data. Many advanced multimodal methods focus on capturing all combinations of modality-specific details across inputs, which can inadvertently obscure the high-level semantic concepts that are shared across modalities. Notably, Multimodal VAEs with low-dimensional latent variables are designed to capture shared representations, enabling various tasks such as joint multimodal synthesis and cross-modal inference. However, multimodal VAEs often struggle to design expressive joint variational posteriors and suffer from low-quality synthesis. In this work, ShaLa addresses these challenges by integrating a novel architectural inference model and a second-stage expressive diffusion prior, which not only facilitates effective inference of shared latent representation but also significantly improves the quality of downstream multimodal synthesis. We validate ShaLa extensively across multiple benchmarks, demonstrating superior coherence and synthesis quality compared to state-of-the-art multimodal VAEs. Furthermore, ShaLa scales to many more modalities while prior multimodal VAEs have fallen short in capturing the increasing complexity of the shared latent space.</li>
</ul>

<h3>Title: UI-Level Evaluation of ALLaM 34B: Measuring an Arabic-Centric LLM via HUMAIN Chat</h3>
<ul>
<li><strong>Authors: </strong>Omer Nacar</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.17378">https://arxiv.org/abs/2508.17378</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.17378">https://arxiv.org/pdf/2508.17378</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.17378]] UI-Level Evaluation of ALLaM 34B: Measuring an Arabic-Centric LLM via HUMAIN Chat(https://arxiv.org/abs/2508.17378)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, large language model</a></li>
<li><strong>Abstract: </strong>Large language models (LLMs) trained primarily on English corpora often struggle to capture the linguistic and cultural nuances of Arabic. To address this gap, the Saudi Data and AI Authority (SDAIA) introduced the $ALLaM$ family of Arabic-focused models. The most capable of these available to the public, $ALLaM-34B$, was subsequently adopted by HUMAIN, who developed and deployed HUMAIN Chat, a closed conversational web service built on this model. This paper presents an expanded and refined UI-level evaluation of $ALLaM-34B$. Using a prompt pack spanning modern standard Arabic, five regional dialects, code-switching, factual knowledge, arithmetic and temporal reasoning, creative generation, and adversarial safety, we collected 115 outputs (23 prompts times 5 runs) and scored each with three frontier LLM judges (GPT-5, Gemini 2.5 Pro, Claude Sonnet-4). We compute category-level means with 95\% confidence intervals, analyze score distributions, and visualize dialect-wise metric heat maps. The updated analysis reveals consistently high performance on generation and code-switching tasks (both averaging 4.92/5), alongside strong results in MSA handling (4.74/5), solid reasoning ability (4.64/5), and improved dialect fidelity (4.21/5). Safety-related prompts show stable, reliable performance of (4.54/5). Taken together, these results position $ALLaM-34B$ as a robust and culturally grounded Arabic LLM, demonstrating both technical strength and practical readiness for real-world deployment.</li>
</ul>

<h3>Title: FedERL: Federated Efficient and Robust Learning for Common Corruptions</h3>
<ul>
<li><strong>Authors: </strong>Omar Bekdache, Naresh Shanbhag</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.17381">https://arxiv.org/abs/2508.17381</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.17381">https://arxiv.org/pdf/2508.17381</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.17381]] FedERL: Federated Efficient and Robust Learning for Common Corruptions(https://arxiv.org/abs/2508.17381)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, robust, federate</a></li>
<li><strong>Abstract: </strong>Federated learning (FL) accelerates the deployment of deep learning models on edge devices while preserving data privacy. However, FL systems face challenges due to client-side constraints on computational resources, and from a lack of robustness to common corruptions such as noise, blur, and weather effects. Existing robust training methods are computationally expensive and unsuitable for resource-constrained clients. We propose FedERL, federated efficient and robust learning, as the first work to explicitly address corruption robustness under time and energy constraints on the client side. At its core, FedERL employs a novel data-agnostic robust training (DART) method on the server to enhance robustness without access to the training data. In doing so, FedERL ensures zero robustness overhead for clients. Extensive experiments demonstrate FedERL's ability to handle common corruptions at a fraction of the time and energy cost of traditional robust training methods. In scenarios with limited time and energy budgets, FedERL surpasses the performance of traditional robust training, establishing it as a practical and scalable solution for real-world FL applications.</li>
</ul>

<h3>Title: Graph-R1: Incentivizing the Zero-Shot Graph Learning Capability in LLMs via Explicit Reasoning</h3>
<ul>
<li><strong>Authors: </strong>Yicong Wu, Guangyue Lu, Yuan Zuo, Huarong Zhang, Junjie Wu</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.17387">https://arxiv.org/abs/2508.17387</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.17387">https://arxiv.org/pdf/2508.17387</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.17387]] Graph-R1: Incentivizing the Zero-Shot Graph Learning Capability in LLMs via Explicit Reasoning(https://arxiv.org/abs/2508.17387)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Generalizing to unseen graph tasks without task-pecific supervision remains challenging. Graph Neural Networks (GNNs) are limited by fixed label spaces, while Large Language Models (LLMs) lack structural inductive biases. Recent advances in Large Reasoning Models (LRMs) provide a zero-shot alternative via explicit, long chain-of-thought reasoning. Inspired by this, we propose a GNN-free approach that reformulates graph tasks--node classification, link prediction, and graph classification--as textual reasoning problems solved by LRMs. We introduce the first datasets with detailed reasoning traces for these tasks and develop Graph-R1, a reinforcement learning framework that leverages task-specific rethink templates to guide reasoning over linearized graphs. Experiments demonstrate that Graph-R1 outperforms state-of-the-art baselines in zero-shot settings, producing interpretable and effective predictions. Our work highlights the promise of explicit reasoning for graph learning and provides new resources for future research.</li>
</ul>

<h3>Title: Enhancing Underwater Images via Deep Learning: A Comparative Study of VGG19 and ResNet50-Based Approaches</h3>
<ul>
<li><strong>Authors: </strong>Aoqi Li, Yanghui Song, Jichao Dao, Chengfu Yang</a></li>
<li><strong>Subjects: </strong>cs.CV, eess.IV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.17397">https://arxiv.org/abs/2508.17397</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.17397">https://arxiv.org/pdf/2508.17397</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.17397]] Enhancing Underwater Images via Deep Learning: A Comparative Study of VGG19 and ResNet50-Based Approaches(https://arxiv.org/abs/2508.17397)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction</a></li>
<li><strong>Abstract: </strong>This paper addresses the challenging problem of image enhancement in complex underwater scenes by proposing a solution based on deep learning. The proposed method skillfully integrates two deep convolutional neural network models, VGG19 and ResNet50, leveraging their powerful feature extraction capabilities to perform multi-scale and multi-level deep feature analysis of underwater images. By constructing a unified model, the complementary advantages of the two models are effectively integrated, achieving a more comprehensive and accurate image enhancement this http URL objectively evaluate the enhancement effect, this paper introduces image quality assessment metrics such as PSNR, UCIQE, and UIQM to quantitatively compare images before and after enhancement and deeply analyzes the performance of different models in different this http URL, to improve the practicality and stability of the underwater visual enhancement system, this paper also provides practical suggestions from aspects such as model optimization, multi-model fusion, and hardware selection, aiming to provide strong technical support for visual enhancement tasks in complex underwater environments.</li>
</ul>

<h3>Title: Retrieval Capabilities of Large Language Models Scale with Pretraining FLOPs</h3>
<ul>
<li><strong>Authors: </strong>Jacob Portes, Connor Jennings, Erica Ji Yuen, Sasha Doubov, Michael Carbin</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.IR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.17400">https://arxiv.org/abs/2508.17400</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.17400">https://arxiv.org/pdf/2508.17400</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.17400]] Retrieval Capabilities of Large Language Models Scale with Pretraining FLOPs(https://arxiv.org/abs/2508.17400)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>How does retrieval performance scale with pretraining FLOPs? We benchmark retrieval performance across LLM model sizes from 125 million parameters to 7 billion parameters pretrained on datasets ranging from 1 billion tokens to more than 2 trillion tokens. We find that retrieval performance on zero-shot BEIR tasks predictably scales with LLM size, training duration, and estimated FLOPs. We also show that In-Context Learning scores are strongly correlated with retrieval scores across retrieval tasks. Finally, we highlight the implications this has for the development of LLM-based retrievers.</li>
</ul>

<h3>Title: FRAME : Comprehensive Risk Assessment Framework for Adversarial Machine Learning Threats</h3>
<ul>
<li><strong>Authors: </strong>Avishag Shapira, Simon Shigol, Asaf Shabtai</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.17405">https://arxiv.org/abs/2508.17405</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.17405">https://arxiv.org/pdf/2508.17405</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.17405]] FRAME : Comprehensive Risk Assessment Framework for Adversarial Machine Learning Threats(https://arxiv.org/abs/2508.17405)</code><input type="text"></li>
<li><strong>Keywords: </strong>secure, security, attack, robust</a></li>
<li><strong>Abstract: </strong>The widespread adoption of machine learning (ML) systems increased attention to their security and emergence of adversarial machine learning (AML) techniques that exploit fundamental vulnerabilities in ML systems, creating an urgent need for comprehensive risk assessment for ML-based systems. While traditional risk assessment frameworks evaluate conventional cybersecurity risks, they lack ability to address unique challenges posed by AML threats. Existing AML threat evaluation approaches focus primarily on technical attack robustness, overlooking crucial real-world factors like deployment environments, system dependencies, and attack feasibility. Attempts at comprehensive AML risk assessment have been limited to domain-specific solutions, preventing application across diverse systems. Addressing these limitations, we present FRAME, the first comprehensive and automated framework for assessing AML risks across diverse ML-based systems. FRAME includes a novel risk assessment method that quantifies AML risks by systematically evaluating three key dimensions: target system's deployment environment, characteristics of diverse AML techniques, and empirical insights from prior research. FRAME incorporates a feasibility scoring mechanism and LLM-based customization for system-specific assessments. Additionally, we developed a comprehensive structured dataset of AML attacks enabling context-aware risk assessment. From an engineering application perspective, FRAME delivers actionable results designed for direct use by system owners with only technical knowledge of their systems, without expertise in AML. We validated it across six diverse real-world applications. Our evaluation demonstrated exceptional accuracy and strong alignment with analysis by AML experts. FRAME enables organizations to prioritize AML risks, supporting secure AI deployment in real-world environments.</li>
</ul>

<h3>Title: E-BayesSAM: Efficient Bayesian Adaptation of SAM with Self-Optimizing KAN-Based Interpretation for Uncertainty-Aware Ultrasonic Segmentation</h3>
<ul>
<li><strong>Authors: </strong>Bin Huang, Zhong Liu, Huiying Wen, Bingsheng Huang, Xin Chen, Shuo Li</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.17408">https://arxiv.org/abs/2508.17408</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.17408">https://arxiv.org/pdf/2508.17408</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.17408]] E-BayesSAM: Efficient Bayesian Adaptation of SAM with Self-Optimizing KAN-Based Interpretation for Uncertainty-Aware Ultrasonic Segmentation(https://arxiv.org/abs/2508.17408)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability, segmentation</a></li>
<li><strong>Abstract: </strong>Although the Segment Anything Model (SAM) has advanced medical image segmentation, its Bayesian adaptation for uncertainty-aware segmentation remains hindered by three key issues: (1) instability in Bayesian fine-tuning of large pre-trained SAMs; (2) high computation cost due to SAM's massive parameters; (3) SAM's black-box design limits interpretability. To overcome these, we propose E-BayesSAM, an efficient framework combining Token-wise Variational Bayesian Inference (T-VBI) for efficienty Bayesian adaptation and Self-Optimizing Kolmogorov-Arnold Network (SO-KAN) for improving interpretability. T-VBI innovatively reinterprets SAM's output tokens as dynamic probabilistic weights and reparameterizes them as latent variables without auxiliary training, enabling training-free VBI for uncertainty estimation. SO-KAN improves token prediction with learnable spline activations via self-supervised learning, providing insight to prune redundant tokens to boost efficiency and accuracy. Experiments on five ultrasound datasets demonstrated that E-BayesSAM achieves: (i) real-time inference (0.03s/image), (ii) superior segmentation accuracy (average DSC: Pruned E-BayesSAM's 89.0\% vs. E-BayesSAM's 88.0% vs. MedSAM's 88.3%), and (iii) identification of four critical tokens governing SAM's decisions. By unifying efficiency, reliability, and interpretability, E-BayesSAM bridges SAM's versatility with clinical needs, advancing deployment in safety-critical medical applications. The source code is available at this https URL.</li>
</ul>

<h3>Title: Convergence and Generalization of Anti-Regularization for Parametric Models</h3>
<ul>
<li><strong>Authors: </strong>Dongseok Kim, Wonjun Jeong, Gisung Oh</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.17412">https://arxiv.org/abs/2508.17412</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.17412">https://arxiv.org/pdf/2508.17412</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.17412]] Convergence and Generalization of Anti-Regularization for Parametric Models(https://arxiv.org/abs/2508.17412)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>We propose Anti-regularization (AR), which adds a sign-reversed reward term to the loss to intentionally increase model expressivity in the small-sample regime, and then attenuates this intervention with a power-law decay as the sample size grows. We formalize spectral safety and trust-region conditions, and design a lightweight stability safeguard that combines a projection operator with gradient clipping, ensuring stable intervention under stated assumptions. Our analysis spans linear smoothers and the Neural Tangent Kernel (NTK) regime, providing practical guidance on selecting the decay exponent by balancing empirical risk against variance. Empirically, AR reduces underfitting while preserving generalization and improving calibration in both regression and classification. Ablation studies confirm that the decay schedule and the stability safeguard are critical to preventing overfitting and numerical instability. We further examine a degrees-of-freedom targeting schedule that keeps per-sample complexity approximately constant. AR is simple to implement and reproducible, integrating cleanly into standard empirical risk minimization pipelines. It enables robust learning in data- and resource-constrained settings by intervening only when beneficial and fading away when unnecessary.</li>
</ul>

<h3>Title: Cyber Security Educational Games for Children: A Systematic Literature Review</h3>
<ul>
<li><strong>Authors: </strong>Temesgen Kitaw Damenu, ƒ∞nci Zaim G√∂kbay, Alexandra Covaci, Shujun Li</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.CY, cs.HC</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.17414">https://arxiv.org/abs/2508.17414</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.17414">https://arxiv.org/pdf/2508.17414</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.17414]] Cyber Security Educational Games for Children: A Systematic Literature Review(https://arxiv.org/abs/2508.17414)</code><input type="text"></li>
<li><strong>Keywords: </strong>security</a></li>
<li><strong>Abstract: </strong>Educational games have been widely used to teach children about cyber security. This systematic literature review reveals evidence of positive learning outcomes, after analysing 91 such games reported in 68 papers published between 2010 and 2024. However, critical gaps have also been identified regarding the design processes and the methodological rigour, including lack of systematic design, misalignment between proposed and achieved learning outcomes, rare use of control groups, limited discussions on ethical considerations, and underutilisation of emerging technologies. We recommend multiple future research directions, e.g., a hybrid approach to game design and evaluation that combines bottom-up and top-down approaches.</li>
</ul>

<h3>Title: Data Leakage in Visual Datasets</h3>
<ul>
<li><strong>Authors: </strong>Patrick Ramos, Ryan Ramos, Noa Garcia</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.17416">https://arxiv.org/abs/2508.17416</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.17416">https://arxiv.org/pdf/2508.17416</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.17416]] Data Leakage in Visual Datasets(https://arxiv.org/abs/2508.17416)</code><input type="text"></li>
<li><strong>Keywords: </strong>fair</a></li>
<li><strong>Abstract: </strong>We analyze data leakage in visual datasets. Data leakage refers to images in evaluation benchmarks that have been seen during training, compromising fair model evaluation. Given that large-scale datasets are often sourced from the internet, where many computer vision benchmarks are publicly available, our efforts are focused into identifying and studying this phenomenon. We characterize visual leakage into different types according to its modality, coverage, and degree. By applying image retrieval techniques, we unequivocally show that all the analyzed datasets present some form of leakage, and that all types of leakage, from severe instances to more subtle cases, compromise the reliability of model evaluation in downstream tasks.</li>
</ul>

<h3>Title: Constrained Prompt Enhancement for Improving Zero-Shot Generalization of Vision-Language Models</h3>
<ul>
<li><strong>Authors: </strong>Xiaojie Yin, Qilong Wang, Qinghua Hu</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.17417">https://arxiv.org/abs/2508.17417</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.17417">https://arxiv.org/pdf/2508.17417</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.17417]] Constrained Prompt Enhancement for Improving Zero-Shot Generalization of Vision-Language Models(https://arxiv.org/abs/2508.17417)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Vision-language models (VLMs) pre-trained on web-scale data exhibit promising zero-shot generalization but often suffer from semantic misalignment due to domain gaps between pre-training and downstream tasks. Existing approaches primarily focus on text prompting with class-specific descriptions and visual-text adaptation via aligning cropped image regions with textual descriptions. However, they still face the issues of incomplete textual prompts and noisy visual prompts. In this paper, we propose a novel constrained prompt enhancement (CPE) method to improve visual-textual alignment by constructing comprehensive textual prompts and compact visual prompts from the semantic perspective. Specifically, our approach consists of two key components: Topology-Guided Synonymous Semantic Generation (TGSSG) and Category-Agnostic Discriminative Region Selection (CADRS). Textually, to address the issue of incomplete semantic expression in textual prompts, our TGSSG first generates synonymous semantic set for each category via large language models, and constructs comprehensive textual prompts based on semantic ambiguity entropy and persistent homology analysis. Visually, to mitigate the irrelevant visual noise introduced by random cropping, our CADRS identifies discriminative regions with activation maps outputted by a pre-trained vision model, effectively filtering out noisy regions and generating compact visual prompts. Given the comprehensive set of textual prompts and compact set of visual prompts, we introduce two set-to-set matching strategies based on test-time adaptation (TTA) and optimal transport (OT) to achieve effective visual-textual alignment, and so improve zero-shot generalization of VLMs.</li>
</ul>

<h3>Title: Modular MeanFlow: Towards Stable and Scalable One-Step Generative Modeling</h3>
<ul>
<li><strong>Authors: </strong>Haochen You, Baojing Liu, Hongyang He</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.17426">https://arxiv.org/abs/2508.17426</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.17426">https://arxiv.org/pdf/2508.17426</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.17426]] Modular MeanFlow: Towards Stable and Scalable One-Step Generative Modeling(https://arxiv.org/abs/2508.17426)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, diffusion, generative</a></li>
<li><strong>Abstract: </strong>One-step generative modeling seeks to generate high-quality data samples in a single function evaluation, significantly improving efficiency over traditional diffusion or flow-based models. In this work, we introduce Modular MeanFlow (MMF), a flexible and theoretically grounded approach for learning time-averaged velocity fields. Our method derives a family of loss functions based on a differential identity linking instantaneous and average velocities, and incorporates a gradient modulation mechanism that enables stable training without sacrificing expressiveness. We further propose a curriculum-style warmup schedule to smoothly transition from coarse supervision to fully differentiable training. The MMF formulation unifies and generalizes existing consistency-based and flow-matching methods, while avoiding expensive higher-order derivatives. Empirical results across image synthesis and trajectory modeling tasks demonstrate that MMF achieves competitive sample quality, robust convergence, and strong generalization, particularly under low-data or out-of-distribution settings.</li>
</ul>

<h3>Title: Robust Point Cloud Registration via Geometric Overlapping Guided Rotation Search</h3>
<ul>
<li><strong>Authors: </strong>Zhao Zheng, Jingfan Fan, Long Shao, Hong Song, Danni Ai, Tianyu Fu, Deqiang Xiao, Yongtian Wang, Jian Yang</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.RO</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.17427">https://arxiv.org/abs/2508.17427</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.17427">https://arxiv.org/pdf/2508.17427</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.17427]] Robust Point Cloud Registration via Geometric Overlapping Guided Rotation Search(https://arxiv.org/abs/2508.17427)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Point cloud registration based on correspondences computes the rigid transformation that maximizes the number of inliers constrained within the noise threshold. Current state-of-the-art (SOTA) methods employing spatial compatibility graphs or branch-and-bound (BnB) search mainly focus on registration under high outlier ratios. However, graph-based methods require at least quadratic space and time complexity for graph construction, while multi-stage BnB search methods often suffer from inaccuracy due to local optima between decomposed stages. This paper proposes a geometric maximum overlapping registration framework via rotation-only BnB search. The rigid transformation is decomposed using Chasles' theorem into a translation along rotation axis and a 2D rigid transformation. The optimal rotation axis and angle are searched via BnB, with residual parameters formulated as range maximum query (RMQ) problems. Firstly, the top-k candidate rotation axes are searched within a hemisphere parameterized by cube mapping, and the translation along each axis is estimated through interval stabbing of the correspondences projected onto that axis. Secondly, the 2D registration is relaxed to 1D rotation angle search with 2D RMQ of geometric overlapping for axis-aligned rectangles, which is solved deterministically in polynomial time using sweep line algorithm with segment tree. Experimental results on 3DMatch, 3DLoMatch, and KITTI datasets demonstrate superior accuracy and efficiency over SOTA methods, while the time complexity is polynomial and the space complexity increases linearly with the number of points, even in the worst case.</li>
</ul>

<h3>Title: FedKLPR: Personalized Federated Learning for Person Re-Identification with Adaptive Pruning</h3>
<ul>
<li><strong>Authors: </strong>Po-Hsien Yu, Yu-Syuan Tseng, Shao-Yi Chien</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.17431">https://arxiv.org/abs/2508.17431</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.17431">https://arxiv.org/pdf/2508.17431</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.17431]] FedKLPR: Personalized Federated Learning for Person Re-Identification with Adaptive Pruning(https://arxiv.org/abs/2508.17431)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, robust, federate</a></li>
<li><strong>Abstract: </strong>Person re-identification (Re-ID) is a fundamental task in intelligent surveillance and public safety. Federated learning (FL) offers a privacy-preserving solution by enabling collaborative model training without centralized data collection. However, applying FL to real-world re-ID systems faces two major challenges: statistical heterogeneity across clients due to non-IID data distributions, and substantial communication overhead caused by frequent transmission of large-scale models. To address these issues, we propose FedKLPR, a lightweight and communication-efficient federated learning framework for person re-identification. FedKLPR introduces four key components. First, the KL-Divergence Regularization Loss (KLL) constrains local models by minimizing the divergence from the global feature distribution, effectively mitigating the effects of statistical heterogeneity and improving convergence stability under non-IID conditions. Secondly, KL-Divergence-Prune Weighted Aggregation (KLPWA) integrates pruning ratio and distributional similarity into the aggregation process, thereby improving the robustness of the global model while significantly reducing communication overhead. Furthermore, sparse Activation Skipping (SAS) mitigates the dilution of critical parameters during the aggregation of pruned client models by excluding zero-valued weights from the update process. Finally, Cross-Round Recovery (CRR) introduces a dynamic pruning control mechanism that halts pruning when necessary, enabling deeper compression while maintaining model accuracy. Experimental results on eight benchmark datasets demonstrate that FedKLPR achieves significant communication reduction. Compared with the state-of-the-art, FedKLPR reduces 33\%-38\% communication cost on ResNet-50 and 20\%-40\% communication cost on ResNet-34, while maintaining model accuracy within 1\% degradation.</li>
</ul>

<h3>Title: TinySR: Pruning Diffusion for Real-World Image Super-Resolution</h3>
<ul>
<li><strong>Authors: </strong>Linwei Dong, Qingnan Fan, Yuhang Yu, Qi Zhang, Jinwei Chen, Yawei Luo, Changqing Zou</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.17434">https://arxiv.org/abs/2508.17434</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.17434">https://arxiv.org/pdf/2508.17434</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.17434]] TinySR: Pruning Diffusion for Real-World Image Super-Resolution(https://arxiv.org/abs/2508.17434)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, generative</a></li>
<li><strong>Abstract: </strong>Real-world image super-resolution (Real-ISR) focuses on recovering high-quality images from low-resolution inputs that suffer from complex degradations like noise, blur, and compression. Recently, diffusion models (DMs) have shown great potential in this area by leveraging strong generative priors to restore fine details. However, their iterative denoising process incurs high computational overhead, posing challenges for real-time applications. Although one-step distillation methods, such as OSEDiff and TSD-SR, offer faster inference, they remain fundamentally constrained by their large, over-parameterized model architectures. In this work, we present TinySR, a compact yet effective diffusion model specifically designed for Real-ISR that achieves real-time performance while maintaining perceptual quality. We introduce a Dynamic Inter-block Activation and an Expansion-Corrosion Strategy to facilitate more effective decision-making in depth pruning. We achieve VAE compression through channel pruning, attention removal and lightweight SepConv. We eliminate time- and prompt-related modules and perform pre-caching techniques to further speed up the model. TinySR significantly reduces computational cost and model size, achieving up to 5.68x speedup and 83% parameter reduction compared to its teacher TSD-SR, while still providing high quality results.</li>
</ul>

<h3>Title: An LLM-LVLM Driven Agent for Iterative and Fine-Grained Image Editing</h3>
<ul>
<li><strong>Authors: </strong>Zihan Liang, Jiahao Sun, Haoran Ma</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.17435">https://arxiv.org/abs/2508.17435</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.17435">https://arxiv.org/pdf/2508.17435</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.17435]] An LLM-LVLM Driven Agent for Iterative and Fine-Grained Image Editing(https://arxiv.org/abs/2508.17435)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, large language model</a></li>
<li><strong>Abstract: </strong>Despite the remarkable capabilities of text-to-image (T2I) generation models, real-world applications often demand fine-grained, iterative image editing that existing methods struggle to provide. Key challenges include granular instruction understanding, robust context preservation during modifications, and the lack of intelligent feedback mechanisms for iterative refinement. This paper introduces RefineEdit-Agent, a novel, training-free intelligent agent framework designed to address these limitations by enabling complex, iterative, and context-aware image editing. RefineEdit-Agent leverages the powerful planning capabilities of Large Language Models (LLMs) and the advanced visual understanding and evaluation prowess of Vision-Language Large Models (LVLMs) within a closed-loop system. Our framework comprises an LVLM-driven instruction parser and scene understanding module, a multi-level LLM-driven editing planner for goal decomposition, tool selection, and sequence generation, an iterative image editing module, and a crucial LVLM-driven feedback and evaluation loop. To rigorously evaluate RefineEdit-Agent, we propose LongBench-T2I-Edit, a new benchmark featuring 500 initial images with complex, multi-turn editing instructions across nine visual dimensions. Extensive experiments demonstrate that RefineEdit-Agent significantly outperforms state-of-the-art baselines, achieving an average score of 3.67 on LongBench-T2I-Edit, compared to 2.29 for Direct Re-Prompting, 2.91 for InstructPix2Pix, 3.16 for GLIGEN-based Edit, and 3.39 for ControlNet-XL. Ablation studies, human evaluations, and analyses of iterative refinement, backbone choices, tool usage, and robustness to instruction complexity further validate the efficacy of our agentic design in delivering superior edit fidelity and context preservation.</li>
</ul>

<h3>Title: Disentangled Geometry and Appearance for Efficient Multi-View Surface Reconstruction and Rendering</h3>
<ul>
<li><strong>Authors: </strong>Qitong Zhang, Jieqing Feng</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.17436">https://arxiv.org/abs/2508.17436</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.17436">https://arxiv.org/pdf/2508.17436</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.17436]] Disentangled Geometry and Appearance for Efficient Multi-View Surface Reconstruction and Rendering(https://arxiv.org/abs/2508.17436)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction</a></li>
<li><strong>Abstract: </strong>This paper addresses the limitations of neural rendering-based multi-view surface reconstruction methods, which require an additional mesh extraction step that is inconvenient and would produce poor-quality surfaces with mesh aliasing, restricting downstream applications. Building on the explicit mesh representation and differentiable rasterization framework, this work proposes an efficient solution that preserves the high efficiency of this framework while significantly improving reconstruction quality and versatility. Specifically, we introduce a disentangled geometry and appearance model that does not rely on deep networks, enhancing learning and broadening applicability. A neural deformation field is constructed to incorporate global geometric context, enhancing geometry learning, while a novel regularization constrains geometric features passed to a neural shader to ensure its accuracy and boost shading. For appearance, a view-invariant diffuse term is separated and baked into mesh vertices, further improving rendering efficiency. Experimental results demonstrate that the proposed method achieves state-of-the-art training (4.84 minutes) and rendering (0.023 seconds) speeds, with reconstruction quality that is competitive with top-performing methods. Moreover, the method enables practical applications such as mesh and texture editing, showcasing its versatility and application potential. This combination of efficiency, competitive quality, and broad applicability makes our approach a valuable contribution to multi-view surface reconstruction and rendering.</li>
</ul>

<h3>Title: Multi-Level LVLM Guidance for Untrimmed Video Action Recognition</h3>
<ul>
<li><strong>Authors: </strong>Liyang Peng, Sihan Zhu, Yunjie Guo</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.17442">https://arxiv.org/abs/2508.17442</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.17442">https://arxiv.org/pdf/2508.17442</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.17442]] Multi-Level LVLM Guidance for Untrimmed Video Action Recognition(https://arxiv.org/abs/2508.17442)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction, transformer</a></li>
<li><strong>Abstract: </strong>Action recognition and localization in complex, untrimmed videos remain a formidable challenge in computer vision, largely due to the limitations of existing methods in capturing fine-grained actions, long-term temporal dependencies, and high-level semantic information from low-level visual features. This paper introduces the Event-Contextualized Video Transformer (ECVT), a novel architecture that leverages the advanced semantic understanding capabilities of Large Vision-Language Models (LVLMs) to bridge this gap. ECVT employs a dual-branch design, comprising a Video Encoding Branch for spatio-temporal feature extraction and a Cross-Modal Guidance Branch. The latter utilizes an LVLM to generate multi-granularity semantic descriptions, including Global Event Prompting for macro-level narrative and Temporal Sub-event Prompting for fine-grained action details. These multi-level textual cues are integrated into the video encoder's learning process through sophisticated mechanisms such as adaptive gating for high-level semantic fusion, cross-modal attention for fine-grained feature refinement, and an event graph module for temporal context calibration. Trained end-to-end with a comprehensive loss function incorporating semantic consistency and temporal calibration terms, ECVT significantly enhances the model's ability to understand video temporal structures and event logic. Extensive experiments on ActivityNet v1.3 and THUMOS14 datasets demonstrate that ECVT achieves state-of-the-art performance, with an average mAP of 40.5% on ActivityNet v1.3 and mAP@0.5 of 67.1% on THUMOS14, outperforming leading baselines.</li>
</ul>

<h3>Title: MahaParaphrase: A Marathi Paraphrase Detection Corpus and BERT-based Models</h3>
<ul>
<li><strong>Authors: </strong>Suramya Jadhav, Abhay Shanbhag, Amogh Thakurdesai, Ridhima Sinare, Ananya Joshi, Raviraj Joshi</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.17444">https://arxiv.org/abs/2508.17444</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.17444">https://arxiv.org/pdf/2508.17444</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.17444]] MahaParaphrase: A Marathi Paraphrase Detection Corpus and BERT-based Models(https://arxiv.org/abs/2508.17444)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Paraphrases are a vital tool to assist language understanding tasks such as question answering, style transfer, semantic parsing, and data augmentation tasks. Indic languages are complex in natural language processing (NLP) due to their rich morphological and syntactic variations, diverse scripts, and limited availability of annotated data. In this work, we present the L3Cube-MahaParaphrase Dataset, a high-quality paraphrase corpus for Marathi, a low resource Indic language, consisting of 8,000 sentence pairs, each annotated by human experts as either Paraphrase (P) or Non-paraphrase (NP). We also present the results of standard transformer-based BERT models on these datasets. The dataset and model are publicly shared at this https URL</li>
</ul>

<h3>Title: TreePO: Bridging the Gap of Policy Optimization and Efficacy and Inference Efficiency with Heuristic Tree-based Modeling</h3>
<ul>
<li><strong>Authors: </strong>Yizhi Li, Qingshui Gu, Zhoufutu Wen, Ziniu Li, Tianshun Xing, Shuyue Guo, Tianyu Zheng, Xin Zhou, Xingwei Qu, Wangchunshu Zhou, Zheng Zhang, Wei Shen, Qian Liu, Chenghua Lin, Jian Yang, Ge Zhang, Wenhao Huang</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.17445">https://arxiv.org/abs/2508.17445</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.17445">https://arxiv.org/pdf/2508.17445</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.17445]] TreePO: Bridging the Gap of Policy Optimization and Efficacy and Inference Efficiency with Heuristic Tree-based Modeling(https://arxiv.org/abs/2508.17445)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Recent advancements in aligning large language models via reinforcement learning have achieved remarkable gains in solving complex reasoning problems, but at the cost of expensive on-policy rollouts and limited exploration of diverse reasoning paths. In this work, we introduce TreePO, involving a self-guided rollout algorithm that views sequence generation as a tree-structured searching process. Composed of dynamic tree sampling policy and fixed-length segment decoding, TreePO leverages local uncertainty to warrant additional branches. By amortizing computation across common prefixes and pruning low-value paths early, TreePO essentially reduces the per-update compute burden while preserving or enhancing exploration diversity. Key contributions include: (1) a segment-wise sampling algorithm that alleviates the KV cache burden through contiguous segments and spawns new branches along with an early-stop mechanism; (2) a tree-based segment-level advantage estimation that considers both global and local proximal policy optimization. and (3) analysis on the effectiveness of probability and quality-driven dynamic divergence and fallback strategy. We empirically validate the performance gain of TreePO on a set reasoning benchmarks and the efficiency saving of GPU hours from 22\% up to 43\% of the sampling design for the trained models, meanwhile showing up to 40\% reduction at trajectory-level and 35\% at token-level sampling compute for the existing models. While offering a free lunch of inference efficiency, TreePO reveals a practical path toward scaling RL-based post-training with fewer samples and less compute. Home page locates at this https URL.</li>
</ul>

<h3>Title: Rectified Robust Policy Optimization for Model-Uncertain Constrained Reinforcement Learning without Strong Duality</h3>
<ul>
<li><strong>Authors: </strong>Shaocong Ma, Ziyi Chen, Yi Zhou, Heng Huang</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.17448">https://arxiv.org/abs/2508.17448</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.17448">https://arxiv.org/pdf/2508.17448</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.17448]] Rectified Robust Policy Optimization for Model-Uncertain Constrained Reinforcement Learning without Strong Duality(https://arxiv.org/abs/2508.17448)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>The goal of robust constrained reinforcement learning (RL) is to optimize an agent's performance under the worst-case model uncertainty while satisfying safety or resource constraints. In this paper, we demonstrate that strong duality does not generally hold in robust constrained RL, indicating that traditional primal-dual methods may fail to find optimal feasible policies. To overcome this limitation, we propose a novel primal-only algorithm called Rectified Robust Policy Optimization (RRPO), which operates directly on the primal problem without relying on dual formulations. We provide theoretical convergence guarantees under mild regularity assumptions, showing convergence to an approximately optimal feasible policy with iteration complexity matching the best-known lower bound when the uncertainty set diameter is controlled in a specific level. Empirical results in a grid-world environment validate the effectiveness of our approach, demonstrating that RRPO achieves robust and safe performance under model uncertainties while the non-robust method can violate the worst-case safety constraints.</li>
</ul>

<h3>Title: Persuasion Dynamics in LLMs: Investigating Robustness and Adaptability in Knowledge and Safety with DuET-PD</h3>
<ul>
<li><strong>Authors: </strong>Bryan Chen Zhengyu Tan, Daniel Wai Kit Chin, Zhengyuan Liu, Nancy F. Chen, Roy Ka-Wei Lee</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.CY</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.17450">https://arxiv.org/abs/2508.17450</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.17450">https://arxiv.org/pdf/2508.17450</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.17450]] Persuasion Dynamics in LLMs: Investigating Robustness and Adaptability in Knowledge and Safety with DuET-PD(https://arxiv.org/abs/2508.17450)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, large language model</a></li>
<li><strong>Abstract: </strong>Large Language Models (LLMs) can struggle to balance gullibility to misinformation and resistance to valid corrections in persuasive dialogues, a critical challenge for reliable deployment. We introduce DuET-PD (Dual Evaluation for Trust in Persuasive Dialogues), a framework evaluating multi-turn stance-change dynamics across dual dimensions: persuasion type (corrective/misleading) and domain (knowledge via MMLU-Pro, and safety via SALAD-Bench). We find that even a state-of-the-art model like GPT-4o achieves only 27.32% accuracy in MMLU-Pro under sustained misleading persuasions. Moreover, results reveal a concerning trend of increasing sycophancy in newer open-source models. To address this, we introduce Holistic DPO, a training approach balancing positive and negative persuasion examples. Unlike prompting or resist-only training, Holistic DPO enhances both robustness to misinformation and receptiveness to corrections, improving Llama-3.1-8B-Instruct's accuracy under misleading persuasion in safety contexts from 4.21% to 76.54%. These contributions offer a pathway to developing more reliable and adaptable LLMs for multi-turn dialogue. Code is available at this https URL.</li>
</ul>

<h3>Title: ReviBranch: Deep Reinforcement Learning for Branch-and-Bound with Revived Trajectories</h3>
<ul>
<li><strong>Authors: </strong>Dou Jiabao, Nie Jiayi, Yihang Cheng, Jinwei Liu, Yingrui Ji, Canran Xiao, Feixiang Du, Jiaping Xiao</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.17452">https://arxiv.org/abs/2508.17452</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.17452">https://arxiv.org/pdf/2508.17452</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.17452]] ReviBranch: Deep Reinforcement Learning for Branch-and-Bound with Revived Trajectories(https://arxiv.org/abs/2508.17452)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>The Branch-and-bound (B&B) algorithm is the main solver for Mixed Integer Linear Programs (MILPs), where the selection of branching variable is essential to computational efficiency. However, traditional heuristics for branching often fail to generalize across heterogeneous problem instances, while existing learning-based methods such as imitation learning (IL) suffers from dependence on expert demonstration quality, and reinforcement learning (RL) struggles with limitations in sparse rewards and dynamic state representation challenges. To address these issues, we propose ReviBranch, a novel deep RL framework that constructs revived trajectories by reviving explicit historical correspondences between branching decisions and their corresponding graph states along search-tree paths. During training, ReviBranch enables agents to learn from complete structural evolution and temporal dependencies within the branching process. Additionally, we introduce an importance-weighted reward redistribution mechanism that transforms sparse terminal rewards into dense stepwise feedback, addressing the sparse reward challenge. Extensive experiments on different MILP benchmarks demonstrate that ReviBranch outperforms state-of-the-art RL methods, reducing B&B nodes by 4.0% and LP iterations by 2.2% on large-scale instances. The results highlight the robustness and generalizability of ReviBranch across heterogeneous MILP problem classes.</li>
</ul>

<h3>Title: Adversarial Examples Are Not Bugs, They Are Superposition</h3>
<ul>
<li><strong>Authors: </strong>Liv Gorton, Owen Lewis</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.17456">https://arxiv.org/abs/2508.17456</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.17456">https://arxiv.org/pdf/2508.17456</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.17456]] Adversarial Examples Are Not Bugs, They Are Superposition(https://arxiv.org/abs/2508.17456)</code><input type="text"></li>
<li><strong>Keywords: </strong>defense, robust, interpretability</a></li>
<li><strong>Abstract: </strong>Adversarial examples -- inputs with imperceptible perturbations that fool neural networks -- remain one of deep learning's most perplexing phenomena despite nearly a decade of research. While numerous defenses and explanations have been proposed, there is no consensus on the fundamental mechanism. One underexplored hypothesis is that superposition, a concept from mechanistic interpretability, may be a major contributing factor, or even the primary cause. We present four lines of evidence in support of this hypothesis, greatly extending prior arguments by Elhage et al. (2022): (1) superposition can theoretically explain a range of adversarial phenomena, (2) in toy models, intervening on superposition controls robustness, (3) in toy models, intervening on robustness (via adversarial training) controls superposition, and (4) in ResNet18, intervening on robustness (via adversarial training) controls superposition.</li>
</ul>

<h3>Title: MoE-Inference-Bench: Performance Evaluation of Mixture of Expert Large Language and Vision Models</h3>
<ul>
<li><strong>Authors: </strong>Krishna Teja Chitty-Venkata, Sylvia Howland, Golara Azar, Daria Soboleva, Natalia Vassilieva, Siddhisanket Raskar, Murali Emani, Venkatram Vishwanath</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.PF</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.17467">https://arxiv.org/abs/2508.17467</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.17467">https://arxiv.org/pdf/2508.17467</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.17467]] MoE-Inference-Bench: Performance Evaluation of Mixture of Expert Large Language and Vision Models(https://arxiv.org/abs/2508.17467)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Mixture of Experts (MoE) models have enabled the scaling of Large Language Models (LLMs) and Vision Language Models (VLMs) by achieving massive parameter counts while maintaining computational efficiency. However, MoEs introduce several inference-time challenges, including load imbalance across experts and the additional routing computational overhead. To address these challenges and fully harness the benefits of MoE, a systematic evaluation of hardware acceleration techniques is essential. We present MoE-Inference-Bench, a comprehensive study to evaluate MoE performance across diverse scenarios. We analyze the impact of batch size, sequence length, and critical MoE hyperparameters such as FFN dimensions and number of experts on throughput. We evaluate several optimization techniques on Nvidia H100 GPUs, including pruning, Fused MoE operations, speculative decoding, quantization, and various parallelization strategies. Our evaluation includes MoEs from the Mixtral, DeepSeek, OLMoE and Qwen families. The results reveal performance differences across configurations and provide insights for the efficient deployment of MoEs.</li>
</ul>

<h3>Title: A Synthetic Dataset for Manometry Recognition in Robotic Applications</h3>
<ul>
<li><strong>Authors: </strong>Pedro Antonio Rabelo Saraiva, Enzo Ferreira de Souza, Joao Manoel Herrera Pinheiro, Thiago H. Segreto, Ricardo V. Godoy, Marcelo Becker</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI, cs.LG, cs.RO</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.17468">https://arxiv.org/abs/2508.17468</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.17468">https://arxiv.org/pdf/2508.17468</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.17468]] A Synthetic Dataset for Manometry Recognition in Robotic Applications(https://arxiv.org/abs/2508.17468)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>This work addresses the challenges of data scarcity and high acquisition costs for training robust object detection models in complex industrial environments, such as offshore oil platforms. The practical and economic barriers to collecting real-world data in these hazardous settings often hamper the development of autonomous inspection systems. To overcome this, in this work we propose and validate a hybrid data synthesis pipeline that combines procedural rendering with AI-driven video generation. Our methodology leverages BlenderProc to create photorealistic images with precise annotations and controlled domain randomization, and integrates NVIDIA's Cosmos-Predict2 world-foundation model to synthesize physically plausible video sequences with temporal diversity, capturing rare viewpoints and adverse conditions. We demonstrate that a YOLO-based detection network trained on a composite dataset, blending real images with our synthetic data, achieves superior performance compared to models trained exclusively on real-world data. Notably, a 1:1 mixture of real and synthetic data yielded the highest accuracy, surpassing the real-only baseline. These findings highlight the viability of a synthetic-first approach as an efficient, cost-effective, and safe alternative for developing reliable perception systems in safety-critical and resource-constrained industrial applications.</li>
</ul>

<h3>Title: A Human-In-The-Loop Approach for Improving Fairness in Predictive Business Process Monitoring</h3>
<ul>
<li><strong>Authors: </strong>Martin K√§ppel, Julian Neuberger, Felix M√∂hrlein, Sven Weinzierl, Martin Matzner, Stefan Jablonski</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CY</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.17477">https://arxiv.org/abs/2508.17477</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.17477">https://arxiv.org/pdf/2508.17477</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.17477]] A Human-In-The-Loop Approach for Improving Fairness in Predictive Business Process Monitoring(https://arxiv.org/abs/2508.17477)</code><input type="text"></li>
<li><strong>Keywords: </strong>fair</a></li>
<li><strong>Abstract: </strong>Predictive process monitoring enables organizations to proactively react and intervene in running instances of a business process. Given an incomplete process instance, predictions about the outcome, next activity, or remaining time are created. This is done by powerful machine learning models, which have shown impressive predictive performance. However, the data-driven nature of these models makes them susceptible to finding unfair, biased, or unethical patterns in the data. Such patterns lead to biased predictions based on so-called sensitive attributes, such as the gender or age of process participants. Previous work has identified this problem and offered solutions that mitigate biases by removing sensitive attributes entirely from the process instance. However, sensitive attributes can be used both fairly and unfairly in the same process instance. For example, during a medical process, treatment decisions could be based on gender, while the decision to accept a patient should not be based on gender. This paper proposes a novel, model-agnostic approach for identifying and rectifying biased decisions in predictive business process monitoring models, even when the same sensitive attribute is used both fairly and unfairly. The proposed approach uses a human-in-the-loop approach to differentiate between fair and unfair decisions through simple alterations on a decision tree model distilled from the original prediction model. Our results show that the proposed approach achieves a promising tradeoff between fairness and accuracy in the presence of biased data. All source code and data are publicly available at this https URL.</li>
</ul>

<h3>Title: SoK: Cybersecurity Assessment of Humanoid Ecosystem</h3>
<ul>
<li><strong>Authors: </strong>Priyanka Prakash Surve, Asaf Shabtai, Yuval Elovici</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.RO</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.17481">https://arxiv.org/abs/2508.17481</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.17481">https://arxiv.org/pdf/2508.17481</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.17481]] SoK: Cybersecurity Assessment of Humanoid Ecosystem(https://arxiv.org/abs/2508.17481)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, defense, attack</a></li>
<li><strong>Abstract: </strong>Humanoids are progressing toward practical deployment across healthcare, industrial, defense, and service sectors. While typically considered cyber-physical systems (CPSs), their dependence on traditional networked software stacks (e.g., Linux operating systems), robot operating system (ROS) middleware, and over-the-air update channels, creates a distinct security profile that exposes them to vulnerabilities conventional CPS models do not fully address. Prior studies have mainly examined specific threats, such as LiDAR spoofing or adversarial machine learning (AML). This narrow focus overlooks how an attack targeting one component can cascade harm throughout the robot's interconnected systems. We address this gap through a systematization of knowledge (SoK) that takes a comprehensive approach, consolidating fragmented research from robotics, CPS, and network security domains. We introduce a seven-layer security model for humanoid robots, organizing 39 known attacks and 35 defenses across the humanoid ecosystem-from hardware to human-robot interaction. Building on this security model, we develop a quantitative 39x35 attack-defense matrix with risk-weighted scoring, validated through Monte Carlo analysis. We demonstrate our method by evaluating three real-world robots: Pepper, G1 EDU, and Digit. The scoring analysis revealed varying security maturity levels, with scores ranging from 39.9% to 79.5% across the platforms. This work introduces a structured, evidence-based assessment method that enables systematic security evaluation, supports cross-platform benchmarking, and guides prioritization of security investments in humanoid robotics.</li>
</ul>

<h3>Title: Efficient Zero-Shot Long Document Classification by Reducing Context Through Sentence Ranking</h3>
<ul>
<li><strong>Authors: </strong>Prathamesh Kokate, Mitali Sarnaik, Manavi Khopade, Mukta Takalikar, Raviraj Joshi</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.17490">https://arxiv.org/abs/2508.17490</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.17490">https://arxiv.org/pdf/2508.17490</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.17490]] Efficient Zero-Shot Long Document Classification by Reducing Context Through Sentence Ranking(https://arxiv.org/abs/2508.17490)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Transformer-based models like BERT excel at short text classification but struggle with long document classification (LDC) due to input length limitations and computational inefficiencies. In this work, we propose an efficient, zero-shot approach to LDC that leverages sentence ranking to reduce input context without altering the model architecture. Our method enables the adaptation of models trained on short texts, such as headlines, to long-form documents by selecting the most informative sentences using a TF-IDF-based ranking strategy. Using the MahaNews dataset of long Marathi news articles, we evaluate three context reduction strategies that prioritize essential content while preserving classification accuracy. Our results show that retaining only the top 50\% ranked sentences maintains performance comparable to full-document inference while reducing inference time by up to 35\%. This demonstrates that sentence ranking is a simple yet effective technique for scalable and efficient zero-shot LDC.</li>
</ul>

<h3>Title: Improving French Synthetic Speech Quality via SSML Prosody Control</h3>
<ul>
<li><strong>Authors: </strong>Nassima Ould Ouali, Awais Hussain Sani, Ruben Bueno, Jonah Dauvet, Tim Luka Horstmann, Eric Moulines</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.SD</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.17494">https://arxiv.org/abs/2508.17494</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.17494">https://arxiv.org/pdf/2508.17494</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.17494]] Improving French Synthetic Speech Quality via SSML Prosody Control(https://arxiv.org/abs/2508.17494)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Despite recent advances, synthetic voices often lack expressiveness due to limited prosody control in commercial text-to-speech (TTS) systems. We introduce the first end-to-end pipeline that inserts Speech Synthesis Markup Language (SSML) tags into French text to control pitch, speaking rate, volume, and pause duration. We employ a cascaded architecture with two QLoRA-fine-tuned Qwen 2.5-7B models: one predicts phrase-break positions and the other performs regression on prosodic targets, generating commercial TTS-compatible SSML markup. Evaluated on a 14-hour French podcast corpus, our method achieves 99.2% F1 for break placement and reduces mean absolute error on pitch, rate, and volume by 25-40% compared with prompting-only large language models (LLMs) and a BiLSTM baseline. In perceptual evaluation involving 18 participants across over 9 hours of synthesized audio, SSML-enhanced speech generated by our pipeline significantly improves naturalness, with the mean opinion score increasing from 3.20 to 3.87 (p < 0.005). Additionally, 15 of 18 listeners preferred our enhanced synthesis. These results demonstrate substantial progress in bridging the expressiveness gap between synthetic and natural French speech. Our code is publicly available at this https URL.</li>
</ul>

<h3>Title: Multimodal Representation Learning Conditioned on Semantic Relations</h3>
<ul>
<li><strong>Authors: </strong>Yang Qiao, Yuntong Hu, Liang Zhao</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.17497">https://arxiv.org/abs/2508.17497</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.17497">https://arxiv.org/pdf/2508.17497</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.17497]] Multimodal Representation Learning Conditioned on Semantic Relations(https://arxiv.org/abs/2508.17497)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction</a></li>
<li><strong>Abstract: </strong>Multimodal representation learning has advanced rapidly with contrastive models such as CLIP, which align image-text pairs in a shared embedding space. However, these models face limitations: (1) they typically focus on image-text pairs, underutilizing the semantic relations across different pairs. (2) they directly match global embeddings without contextualization, overlooking the need for semantic alignment along specific subspaces or relational dimensions; and (3) they emphasize cross-modal contrast, with limited support for intra-modal consistency. To address these issues, we propose Relation-Conditioned Multimodal Learning RCML, a framework that learns multimodal representations under natural-language relation descriptions to guide both feature extraction and alignment. Our approach constructs many-to-many training pairs linked by semantic relations and introduces a relation-guided cross-attention mechanism that modulates multimodal representations under each relation context. The training objective combines inter-modal and intra-modal contrastive losses, encouraging consistency across both modalities and semantically related samples. Experiments on different datasets show that RCML consistently outperforms strong baselines on both retrieval and classification tasks, highlighting the effectiveness of leveraging semantic relations to guide multimodal representation learning.</li>
</ul>

<h3>Title: Social-MAE: A Transformer-Based Multimodal Autoencoder for Face and Voice</h3>
<ul>
<li><strong>Authors: </strong>Hugo Bohy, Minh Tran, Kevin El Haddad, Thierry Dutoit, Mohammad Soleymani</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.17502">https://arxiv.org/abs/2508.17502</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.17502">https://arxiv.org/pdf/2508.17502</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.17502]] Social-MAE: A Transformer-Based Multimodal Autoencoder for Face and Voice(https://arxiv.org/abs/2508.17502)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Human social behaviors are inherently multimodal necessitating the development of powerful audiovisual models for their perception. In this paper, we present Social-MAE, our pre-trained audiovisual Masked Autoencoder based on an extended version of Contrastive Audio-Visual Masked Auto-Encoder (CAV-MAE), which is pre-trained on audiovisual social data. Specifically, we modify CAV-MAE to receive a larger number of frames as input and pre-train it on a large dataset of human social interaction (VoxCeleb2) in a self-supervised manner. We demonstrate the effectiveness of this model by finetuning and evaluating the model on different social and affective downstream tasks, namely, emotion recognition, laughter detection and apparent personality estimation. The model achieves state-of-the-art results on multimodal emotion recognition and laughter recognition and competitive results for apparent personality estimation, demonstrating the effectiveness of in-domain self-supervised pre-training. Code and model weight are available here this https URL.</li>
</ul>

<h3>Title: DinoTwins: Combining DINO and Barlow Twins for Robust, Label-Efficient Vision Transformers</h3>
<ul>
<li><strong>Authors: </strong>Michael Podsiadly, Brendon K Lay</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.17509">https://arxiv.org/abs/2508.17509</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.17509">https://arxiv.org/pdf/2508.17509</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.17509]] DinoTwins: Combining DINO and Barlow Twins for Robust, Label-Efficient Vision Transformers(https://arxiv.org/abs/2508.17509)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, transformer, segmentation</a></li>
<li><strong>Abstract: </strong>Training AI models to understand images without costly labeled data remains a challenge. We combine two techniques--DINO (teacher-student learning) and Barlow Twins (redundancy reduction)--to create a model that learns better with fewer labels and less compute. While both DINO and Barlow Twins have independently demonstrated strong performance in self-supervised learning, each comes with limitations--DINO may be sensitive to certain augmentations, and Barlow Twins often requires batch sizes too large to fit on consumer hardware. By combining the redundancy-reduction objective of Barlow Twins with the self-distillation strategy of DINO, we aim to leverage their complementary strengths. We train a hybrid model on the MS COCO dataset using only 10\% of labeled data for linear probing, and evaluate its performance against standalone DINO and Barlow Twins implementations. Preliminary results show that the combined approach achieves comparable loss and classification accuracy to DINO while maintaining strong feature representations. Attention visualizations further suggest improved semantic segmentation capability in the hybrid model. This combined method offers a scalable, label-efficient alternative for training ViTs in resource-constrained environments.</li>
</ul>

<h3>Title: Learning Interpretable Differentiable Logic Networks for Time-Series Classification</h3>
<ul>
<li><strong>Authors: </strong>Chang Yue, Niraj K. Jha</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.17512">https://arxiv.org/abs/2508.17512</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.17512">https://arxiv.org/pdf/2508.17512</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.17512]] Learning Interpretable Differentiable Logic Networks for Time-Series Classification(https://arxiv.org/abs/2508.17512)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability</a></li>
<li><strong>Abstract: </strong>Differentiable logic networks (DLNs) have shown promising results in tabular domains by combining accuracy, interpretability, and computational efficiency. In this work, we apply DLNs to the domain of TSC for the first time, focusing on univariate datasets. To enable DLN application in this context, we adopt feature-based representations relying on Catch22 and TSFresh, converting sequential time series into vectorized forms suitable for DLN classification. Unlike prior DLN studies that fix the training configuration and vary various settings in isolation via ablation, we integrate all such configurations into the hyperparameter search space, enabling the search process to select jointly optimal settings. We then analyze the distribution of selected configurations to better understand DLN training dynamics. We evaluate our approach on 51 publicly available univariate TSC benchmarks. The results confirm that classification DLNs maintain their core strengths in this new domain: they deliver competitive accuracy, retain low inference cost, and provide transparent, interpretable decision logic, thus aligning well with previous DLN findings in the realm of tabular classification and regression tasks.</li>
</ul>

<h3>Title: GateTS: Versatile and Efficient Forecasting via Attention-Inspired routed Mixture-of-Experts</h3>
<ul>
<li><strong>Authors: </strong>Kyrylo Yemets, Mykola Lukashchuk, Ivan Izonin</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.17515">https://arxiv.org/abs/2508.17515</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.17515">https://arxiv.org/pdf/2508.17515</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.17515]] GateTS: Versatile and Efficient Forecasting via Attention-Inspired routed Mixture-of-Experts(https://arxiv.org/abs/2508.17515)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Accurate univariate forecasting remains a pressing need in real-world systems, such as energy markets, hydrology, retail demand, and IoT monitoring, where signals are often intermittent and horizons span both short- and long-term. While transformers and Mixture-of-Experts (MoE) architectures are increasingly favored for time-series forecasting, a key gap persists: MoE models typically require complicated training with both the main forecasting loss and auxiliary load-balancing losses, along with careful routing/temperature tuning, which hinders practical adoption. In this paper, we propose a model architecture that simplifies the training process for univariate time series forecasting and effectively addresses both long- and short-term horizons, including intermittent patterns. Our approach combines sparse MoE computation with a novel attention-inspired gating mechanism that replaces the traditional one-layer softmax router. Through extensive empirical evaluation, we demonstrate that our gating design naturally promotes balanced expert utilization and achieves superior predictive accuracy without requiring the auxiliary load-balancing losses typically used in classical MoE implementations. The model achieves better performance while utilizing only a fraction of the parameters required by state-of-the-art transformer models, such as PatchTST. Furthermore, experiments across diverse datasets confirm that our MoE architecture with the proposed gating mechanism is more computationally efficient than LSTM for both long- and short-term forecasting, enabling cost-effective inference. These results highlight the potential of our approach for practical time-series forecasting applications where both accuracy and computational efficiency are critical.</li>
</ul>

<h3>Title: Modeling Irregular Astronomical Time Series with Neural Stochastic Delay Differential Equations</h3>
<ul>
<li><strong>Authors: </strong>YongKyung Oh, Seungsu Kam, Dong-Young Lim, Sungil Kim</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.17521">https://arxiv.org/abs/2508.17521</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.17521">https://arxiv.org/pdf/2508.17521</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.17521]] Modeling Irregular Astronomical Time Series with Neural Stochastic Delay Differential Equations(https://arxiv.org/abs/2508.17521)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Astronomical time series from large-scale surveys like LSST are often irregularly sampled and incomplete, posing challenges for classification and anomaly detection. We introduce a new framework based on Neural Stochastic Delay Differential Equations (Neural SDDEs) that combines stochastic modeling with neural networks to capture delayed temporal dynamics and handle irregular observations. Our approach integrates a delay-aware neural architecture, a numerical solver for SDDEs, and mechanisms to robustly learn from noisy, sparse sequences. Experiments on irregularly sampled astronomical data demonstrate strong classification accuracy and effective detection of novel astrophysical events, even with partial labels. This work highlights Neural SDDEs as a principled and practical tool for time series analysis under observational constraints.</li>
</ul>

<h3>Title: OmniMRI: A Unified Vision--Language Foundation Model for Generalist MRI Interpretation</h3>
<ul>
<li><strong>Authors: </strong>Xingxin He, Aurora Rofena, Ruimin Feng, Haozhe Liao, Zhaoye Zhou, Albert Jang, Fang Liu</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.17524">https://arxiv.org/abs/2508.17524</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.17524">https://arxiv.org/pdf/2508.17524</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.17524]] OmniMRI: A Unified Vision--Language Foundation Model for Generalist MRI Interpretation(https://arxiv.org/abs/2508.17524)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, segmentation</a></li>
<li><strong>Abstract: </strong>Magnetic Resonance Imaging (MRI) is indispensable in clinical practice but remains constrained by fragmented, multi-stage workflows encompassing acquisition, reconstruction, segmentation, detection, diagnosis, and reporting. While deep learning has achieved progress in individual tasks, existing approaches are often anatomy- or application-specific and lack generalizability across diverse clinical settings. Moreover, current pipelines rarely integrate imaging data with complementary language information that radiologists rely on in routine practice. Here, we introduce OmniMRI, a unified vision-language foundation model designed to generalize across the entire MRI workflow. OmniMRI is trained on a large-scale, heterogeneous corpus curated from 60 public datasets, over 220,000 MRI volumes and 19 million MRI slices, incorporating image-only data, paired vision-text data, and instruction-response data. Its multi-stage training paradigm, comprising self-supervised vision pretraining, vision-language alignment, multimodal pretraining, and multi-task instruction tuning, progressively equips the model with transferable visual representations, cross-modal reasoning, and robust instruction-following capabilities. Qualitative results demonstrate OmniMRI's ability to perform diverse tasks within a single architecture, including MRI reconstruction, anatomical and pathological segmentation, abnormality detection, diagnostic suggestion, and radiology report generation. These findings highlight OmniMRI's potential to consolidate fragmented pipelines into a scalable, generalist framework, paving the way toward foundation models that unify imaging and clinical language for comprehensive, end-to-end MRI interpretation.</li>
</ul>

<h3>Title: Debate or Vote: Which Yields Better Decisions in Multi-Agent Large Language Models?</h3>
<ul>
<li><strong>Authors: </strong>Hyeong Kyu Choi, Xiaojin Zhu, Yixuan Li</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.MA</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.17536">https://arxiv.org/abs/2508.17536</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.17536">https://arxiv.org/pdf/2508.17536</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.17536]] Debate or Vote: Which Yields Better Decisions in Multi-Agent Large Language Models?(https://arxiv.org/abs/2508.17536)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Multi-Agent Debate~(MAD) has emerged as a promising paradigm for improving the performance of large language models through collaborative reasoning. Despite recent advances, the key factors driving MAD's effectiveness remain unclear. In this work, we disentangle MAD into two key components--Majority Voting and inter-agent Debate--and assess their respective contributions. Through extensive experiments across seven NLP benchmarks, we find that Majority Voting alone accounts for most of the performance gains typically attributed to MAD. To explain this, we propose a theoretical framework that models debate as a stochastic process. We prove that it induces a martingale over agents' belief trajectories, implying that debate alone does not improve expected correctness. Guided by these insights, we demonstrate that targeted interventions, by biasing the belief update toward correction, can meaningfully enhance debate effectiveness. Overall, our findings suggest that while MAD has potential, simple ensembling methods remain strong and more reliable alternatives in many practical settings. Code is released in this https URL.</li>
</ul>

<h3>Title: Activation Transport Operators</h3>
<ul>
<li><strong>Authors: </strong>Andrzej Szablewski, Marek Masiak</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.17540">https://arxiv.org/abs/2508.17540</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.17540">https://arxiv.org/pdf/2508.17540</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.17540]] Activation Transport Operators(https://arxiv.org/abs/2508.17540)</code><input type="text"></li>
<li><strong>Keywords: </strong>protect, transformer</a></li>
<li><strong>Abstract: </strong>The residual stream mediates communication between transformer decoder layers via linear reads and writes of non-linear computations. While sparse-dictionary learning-based methods locate features in the residual stream, and activation patching methods discover circuits within the model, the mechanism by which features flow through the residual stream remains understudied. Understanding this dynamic can better inform jailbreaking protections, enable early detection of model mistakes, and their correction. In this work, we propose Activation Transport Operators (ATO), linear maps from upstream to downstream residuals $k$ layers later, evaluated in feature space using downstream SAE decoder projections. We empirically demonstrate that these operators can determine whether a feature has been linearly transported from a previous layer or synthesised from non-linear layer computation. We develop the notion of transport efficiency, for which we provide an upper bound, and use it to estimate the size of the residual stream subspace that corresponds to linear transport. We empirically demonstrate the linear transport, report transport efficiency and the size of the residual stream's subspace involved in linear transport. This compute-light (no finetuning, <50 GPU-h) method offers practical tools for safety, debugging, and a clearer picture of where computation in LLMs behaves linearly.</li>
</ul>

<h3>Title: In-Context Algorithm Emulation in Fixed-Weight Transformers</h3>
<ul>
<li><strong>Authors: </strong>Jerry Yao-Chieh Hu, Hude Liu, Jennifer Yuntong Zhang, Han Liu</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.17550">https://arxiv.org/abs/2508.17550</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.17550">https://arxiv.org/pdf/2508.17550</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.17550]] In-Context Algorithm Emulation in Fixed-Weight Transformers(https://arxiv.org/abs/2508.17550)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>We prove that a minimal Transformer architecture with frozen weights is capable of emulating a broad class of algorithms by in-context prompting. In particular, for any algorithm implementable by a fixed-weight attention head (e.g. one-step gradient descent or linear/ridge regression), there exists a prompt that drives a two-layer softmax attention module to reproduce the algorithm's output with arbitrary precision. This guarantee extends even to a single-head attention layer (using longer prompts if necessary), achieving architectural minimality. Our key idea is to construct prompts that encode an algorithm's parameters into token representations, creating sharp dot-product gaps that force the softmax attention to follow the intended computation. This construction requires no feed-forward layers and no parameter updates. All adaptation happens through the prompt alone. These findings forge a direct link between in-context learning and algorithmic emulation, and offer a simple mechanism for large Transformers to serve as prompt-programmable libraries of algorithms. They illuminate how GPT-style foundation models may swap algorithms via prompts alone, establishing a form of algorithmic universality in modern Transformer models.</li>
</ul>

<h3>Title: Bridging Graph and State-Space Modeling for Intensive Care Unit Length of Stay Prediction</h3>
<ul>
<li><strong>Authors: </strong>Shuqi Zi, Haitz S√°ez de Oc√°riz Borde, Emma Rocheteau, Pietro Lio'</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.17554">https://arxiv.org/abs/2508.17554</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.17554">https://arxiv.org/pdf/2508.17554</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.17554]] Bridging Graph and State-Space Modeling for Intensive Care Unit Length of Stay Prediction(https://arxiv.org/abs/2508.17554)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability, transformer</a></li>
<li><strong>Abstract: </strong>Predicting a patient's length of stay (LOS) in the intensive care unit (ICU) is a critical task for hospital resource management, yet remains challenging due to the heterogeneous and irregularly sampled nature of electronic health records (EHRs). In this work, we propose S$^2$G-Net, a novel neural architecture that unifies state-space sequence modeling with multi-view Graph Neural Networks (GNNs) for ICU LOS prediction. The temporal path employs Mamba state-space models (SSMs) to capture patient trajectories, while the graph path leverages an optimized GraphGPS backbone, designed to integrate heterogeneous patient similarity graphs derived from diagnostic, administrative, and semantic features. Experiments on the large-scale MIMIC-IV cohort dataset show that S$^2$G-Net consistently outperforms sequence models (BiLSTM, Mamba, Transformer), graph models (classic GNNs, GraphGPS), and hybrid approaches across all primary metrics. Extensive ablation studies and interpretability analyses highlight the complementary contributions of each component of our architecture and underscore the importance of principled graph construction. These results demonstrate that S$^2$G-Net provides an effective and scalable solution for ICU LOS prediction with multi-modal clinical data.</li>
</ul>

<h3>Title: Towards Optimal Convolutional Transfer Learning Architectures for Breast Lesion Classification and ACL Tear Detection</h3>
<ul>
<li><strong>Authors: </strong>Daniel Frees, Moritz Bolling, Aditri Bhagirath</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.17567">https://arxiv.org/abs/2508.17567</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.17567">https://arxiv.org/pdf/2508.17567</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.17567]] Towards Optimal Convolutional Transfer Learning Architectures for Breast Lesion Classification and ACL Tear Detection(https://arxiv.org/abs/2508.17567)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>Modern computer vision models have proven to be highly useful for medical imaging classification and segmentation tasks, but the scarcity of medical imaging data often limits the efficacy of models trained from scratch. Transfer learning has emerged as a pivotal solution to this, enabling the fine-tuning of high-performance models on small data. Mei et al. (2022) found that pre-training CNNs on a large dataset of radiologist-labeled images (RadImageNet) enhanced model performance on downstream tasks compared to ImageNet pretraining. The present work extends Mei et al. (2022) by conducting a comprehensive investigation to determine optimal CNN architectures for breast lesion malignancy detection and ACL tear detection, as well as performing statistical analysis to compare the effect of RadImageNet and ImageNet pre-training on downstream model performance. Our findings suggest that 1-dimensional convolutional classifiers with skip connections, ResNet50 pre-trained backbones, and partial backbone unfreezing yields optimal downstream medical classification performance. Our best models achieve AUCs of 0.9969 for ACL tear detection and 0.9641 for breast nodule malignancy detection, competitive with the results reported by Mei et al. (2022) and surpassing other previous works. We do not find evidence confirming RadImageNet pre-training to provide superior downstream performance for ACL tear and breast lesion classification tasks.</li>
</ul>

<h3>Title: Humanizing Machines: Rethinking LLM Anthropomorphism Through a Multi-Level Framework of Design</h3>
<ul>
<li><strong>Authors: </strong>Yunze Xiao, Lynnette Hui Xian Ng, Jiarui Liu, Mona T. Diab</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.17573">https://arxiv.org/abs/2508.17573</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.17573">https://arxiv.org/pdf/2508.17573</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.17573]] Humanizing Machines: Rethinking LLM Anthropomorphism Through a Multi-Level Framework of Design(https://arxiv.org/abs/2508.17573)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large Language Models (LLMs) increasingly exhibit \textbf{anthropomorphism} characteristics -- human-like qualities portrayed across their outlook, language, behavior, and reasoning functions. Such characteristics enable more intuitive and engaging human-AI interactions. However, current research on anthropomorphism remains predominantly risk-focused, emphasizing over-trust and user deception while offering limited design guidance. We argue that anthropomorphism should instead be treated as a \emph{concept of design} that can be intentionally tuned to support user goals. Drawing from multiple disciplines, we propose that the anthropomorphism of an LLM-based artifact should reflect the interaction between artifact designers and interpreters. This interaction is facilitated by cues embedded in the artifact by the designers and the (cognitive) responses of the interpreters to the cues. Cues are categorized into four dimensions: \textit{perceptive, linguistic, behavioral}, and \textit{cognitive}. By analyzing the manifestation and effectiveness of each cue, we provide a unified taxonomy with actionable levers for practitioners. Consequently, we advocate for function-oriented evaluations of anthropomorphic design.</li>
</ul>

<h3>Title: CausalSent: Interpretable Sentiment Classification with RieszNet</h3>
<ul>
<li><strong>Authors: </strong>Daniel Frees, Martin Pollack</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.17576">https://arxiv.org/abs/2508.17576</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.17576">https://arxiv.org/pdf/2508.17576</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.17576]] CausalSent: Interpretable Sentiment Classification with RieszNet(https://arxiv.org/abs/2508.17576)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability</a></li>
<li><strong>Abstract: </strong>Despite the overwhelming performance improvements offered by recent natural language procesing (NLP) models, the decisions made by these models are largely a black box. Towards closing this gap, the field of causal NLP combines causal inference literature with modern NLP models to elucidate causal effects of text features. We replicate and extend Bansal et al's work on regularizing text classifiers to adhere to estimated effects, focusing instead on model interpretability. Specifically, we focus on developing a two-headed RieszNet-based neural network architecture which achieves better treatment effect estimation accuracy. Our framework, CausalSent, accurately predicts treatment effects in semi-synthetic IMDB movie reviews, reducing MAE of effect estimates by 2-3x compared to Bansal et al's MAE on synthetic Civil Comments data. With an ensemble of validated models, we perform an observational case study on the causal effect of the word "love" in IMDB movie reviews, finding that the presence of the word "love" causes a +2.9% increase in the probability of a positive sentiment.</li>
</ul>

<h3>Title: IDU: Incremental Dynamic Update of Existing 3D Virtual Environments with New Imagery Data</h3>
<ul>
<li><strong>Authors: </strong>Meida Chen, Luis Leal, Yue Hu, Rong Liu, Butian Xiong, Andrew Feng, Jiuyi Xu, Yangming Shi</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.17579">https://arxiv.org/abs/2508.17579</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.17579">https://arxiv.org/pdf/2508.17579</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.17579]] IDU: Incremental Dynamic Update of Existing 3D Virtual Environments with New Imagery Data(https://arxiv.org/abs/2508.17579)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>For simulation and training purposes, military organizations have made substantial investments in developing high-resolution 3D virtual environments through extensive imaging and 3D scanning. However, the dynamic nature of battlefield conditions-where objects may appear or vanish over time-makes frequent full-scale updates both time-consuming and costly. In response, we introduce the Incremental Dynamic Update (IDU) pipeline, which efficiently updates existing 3D reconstructions, such as 3D Gaussian Splatting (3DGS), with only a small set of newly acquired images. Our approach starts with camera pose estimation to align new images with the existing 3D model, followed by change detection to pinpoint modifications in the scene. A 3D generative AI model is then used to create high-quality 3D assets of the new elements, which are seamlessly integrated into the existing 3D model. The IDU pipeline incorporates human guidance to ensure high accuracy in object identification and placement, with each update focusing on a single new object at a time. Experimental results confirm that our proposed IDU pipeline significantly reduces update time and labor, offering a cost-effective and targeted solution for maintaining up-to-date 3D models in rapidly evolving military scenarios.</li>
</ul>

<h3>Title: Exploring Efficient Learning of Small BERT Networks with LoRA and DoRA</h3>
<ul>
<li><strong>Authors: </strong>Daniel Frees, Aditri Bhagirath, Moritz Bolling</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.17586">https://arxiv.org/abs/2508.17586</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.17586">https://arxiv.org/pdf/2508.17586</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.17586]] Exploring Efficient Learning of Small BERT Networks with LoRA and DoRA(https://arxiv.org/abs/2508.17586)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>While Large Language Models (LLMs) have revolutionized artificial intelligence, fine-tuning LLMs is extraordinarily computationally expensive, preventing smaller businesses and research teams with limited GPU resources from engaging with new research. Hu et al and Liu et al introduce Low-Rank Adaptation (LoRA) and Weight-Decomposed Low-Rank Adaptation (DoRA) as highly efficient and performant solutions to the computational challenges of LLM fine-tuning, demonstrating huge speedups and memory usage savings for models such as GPT-3 and RoBERTa. We seek to expand upon the original LoRA and DoRA papers by benchmarking efficiency and performance of LoRA and DoRA when applied to a much smaller scale of language model: our case study here is the compact minBERT model. Our findings reveal that optimal custom configurations of LoRA and DoRA, coupled with Automatic Mixed Precision (AMP), significantly enhance training efficiency without compromising performance. Furthermore, while the parameterization of minBERT is significantly smaller than GPT-3, our results validate the observation that gradient updates to language models are inherently low-rank even in small model space, observing that rank 1 decompositions yield negligible performance deficits. Furthermore, aided by our highly efficient minBERT implementation, we investigate numerous architectures, custom loss functions, and hyperparameters to ultimately train an optimal ensembled multitask minBERT model to simultaneously perform sentiment analysis, paraphrase detection, and similarity scoring.</li>
</ul>

<h3>Title: HERO: Hierarchical Extrapolation and Refresh for Efficient World Models</h3>
<ul>
<li><strong>Authors: </strong>Quanjian Song, Xinyu Wang, Donghao Zhou, Jingyu Lin, Cunjian Chen, Yue Ma, Xiu Li</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.17588">https://arxiv.org/abs/2508.17588</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.17588">https://arxiv.org/pdf/2508.17588</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.17588]] HERO: Hierarchical Extrapolation and Refresh for Efficient World Models(https://arxiv.org/abs/2508.17588)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>Generation-driven world models create immersive virtual environments but suffer slow inference due to the iterative nature of diffusion models. While recent advances have improved diffusion model efficiency, directly applying these techniques to world models introduces limitations such as quality degradation. In this paper, we present HERO, a training-free hierarchical acceleration framework tailored for efficient world models. Owing to the multi-modal nature of world models, we identify a feature coupling phenomenon, wherein shallow layers exhibit high temporal variability, while deeper layers yield more stable feature representations. Motivated by this, HERO adopts hierarchical strategies to accelerate inference: (i) In shallow layers, a patch-wise refresh mechanism efficiently selects tokens for recomputation. With patch-wise sampling and frequency-aware tracking, it avoids extra metric computation and remain compatible with FlashAttention. (ii) In deeper layers, a linear extrapolation scheme directly estimates intermediate features. This completely bypasses the computations in attention modules and feed-forward networks. Our experiments show that HERO achieves a 1.73$\times$ speedup with minimal quality degradation, significantly outperforming existing diffusion acceleration methods.</li>
</ul>

<h3>Title: Less Is More? Examining Fairness in Pruned Large Language Models for Summarising Opinions</h3>
<ul>
<li><strong>Authors: </strong>Nannan Huang, Haytham Fayek, Xiuzhen Zhang</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.17610">https://arxiv.org/abs/2508.17610</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.17610">https://arxiv.org/pdf/2508.17610</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.17610]] Less Is More? Examining Fairness in Pruned Large Language Models for Summarising Opinions(https://arxiv.org/abs/2508.17610)</code><input type="text"></li>
<li><strong>Keywords: </strong>fair, large language model</a></li>
<li><strong>Abstract: </strong>Model compression through post-training pruning offers a way to reduce model size and computational requirements without significantly impacting model performance. However, the effect of pruning on the fairness of LLM-generated summaries remains unexplored, particularly for opinion summarisation where biased outputs could influence public this http URL this paper, we present a comprehensive empirical analysis of opinion summarisation, examining three state-of-the-art pruning methods and various calibration sets across three open-source LLMs using four fairness metrics. Our systematic analysis reveals that pruning methods have a greater impact on fairness than calibration sets. Building on these insights, we propose High Gradient Low Activation (HGLA) pruning, which identifies and removes parameters that are redundant for input processing but influential in output generation. Our experiments demonstrate that HGLA can better maintain or even improve fairness compared to existing methods, showing promise across models and tasks where traditional methods have limitations. Our human evaluation shows HGLA-generated outputs are fairer than existing state-of-the-art pruning methods. Code is available at: this https URL.</li>
</ul>

<h3>Title: A Weighted Vision Transformer-Based Multi-Task Learning Framework for Predicting ADAS-Cog Scores</h3>
<ul>
<li><strong>Authors: </strong>Nur Amirah Abd Hamid, Mohd Ibrahim Shapiai, Daphne Teck Ching Lai</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.17613">https://arxiv.org/abs/2508.17613</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.17613">https://arxiv.org/pdf/2508.17613</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.17613]] A Weighted Vision Transformer-Based Multi-Task Learning Framework for Predicting ADAS-Cog Scores(https://arxiv.org/abs/2508.17613)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability, transformer</a></li>
<li><strong>Abstract: </strong>Prognostic modeling is essential for forecasting future clinical scores and enabling early detection of Alzheimers disease (AD). While most existing methods focus on predicting the ADAS-Cog global score, they often overlook the predictive value of its 13 sub-scores, which reflect distinct cognitive domains. Some sub-scores may exert greater influence on determining global scores. Assigning higher loss weights to these clinically meaningful sub-scores can guide the model to focus on more relevant cognitive domains, enhancing both predictive accuracy and interpretability. In this study, we propose a weighted Vision Transformer (ViT)-based multi-task learning (MTL) framework to jointly predict the ADAS-Cog global score using baseline MRI scans and its 13 sub-scores at Month 24. Our framework integrates ViT as a feature extractor and systematically investigates the impact of sub-score-specific loss weighting on model performance. Results show that our proposed weighting strategies are group-dependent: strong weighting improves performance for MCI subjects with more heterogeneous MRI patterns, while moderate weighting is more effective for CN subjects with lower variability. Our findings suggest that uniform weighting underutilizes key sub-scores and limits generalization. The proposed framework offers a flexible, interpretable approach to AD prognosis using end-to-end MRI-based learning. (Github repo link will be provided after review)</li>
</ul>

<h3>Title: JCo-MVTON: Jointly Controllable Multi-Modal Diffusion Transformer for Mask-Free Virtual Try-on</h3>
<ul>
<li><strong>Authors: </strong>Aowen Wang, Wei Li, Hao Luo, Mengxing Ao, Chenyu Zhu, Xinyang Li, Fan Wang</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.17614">https://arxiv.org/abs/2508.17614</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.17614">https://arxiv.org/pdf/2508.17614</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.17614]] JCo-MVTON: Jointly Controllable Multi-Modal Diffusion Transformer for Mask-Free Virtual Try-on(https://arxiv.org/abs/2508.17614)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, transformer</a></li>
<li><strong>Abstract: </strong>Virtual try-on systems have long been hindered by heavy reliance on human body masks, limited fine-grained control over garment attributes, and poor generalization to real-world, in-the-wild scenarios. In this paper, we propose JCo-MVTON (Jointly Controllable Multi-Modal Diffusion Transformer for Mask-Free Virtual Try-On), a novel framework that overcomes these limitations by integrating diffusion-based image generation with multi-modal conditional fusion. Built upon a Multi-Modal Diffusion Transformer (MM-DiT) backbone, our approach directly incorporates diverse control signals -- such as the reference person image and the target garment image -- into the denoising process through dedicated conditional pathways that fuse features within the self-attention layers. This fusion is further enhanced with refined positional encodings and attention masks, enabling precise spatial alignment and improved garment-person integration. To address data scarcity and quality, we introduce a bidirectional generation strategy for dataset construction: one pipeline uses a mask-based model to generate realistic reference images, while a symmetric ``Try-Off'' model, trained in a self-supervised manner, recovers the corresponding garment images. The synthesized dataset undergoes rigorous manual curation, allowing iterative improvement in visual fidelity and diversity. Experiments demonstrate that JCo-MVTON achieves state-of-the-art performance on public benchmarks including DressCode, significantly outperforming existing methods in both quantitative metrics and human evaluations. Moreover, it shows strong generalization in real-world applications, surpassing commercial systems.</li>
</ul>

<h3>Title: Improving Interpretability in Alzheimer's Prediction via Joint Learning of ADAS-Cog Scores</h3>
<ul>
<li><strong>Authors: </strong>Nur Amirah Abd Hamid, Mohd Shahrizal Rusli, Muhammad Thaqif Iman Mohd Taufek, Mohd Ibrahim Shapiai, Daphne Teck Ching Lai</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.17619">https://arxiv.org/abs/2508.17619</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.17619">https://arxiv.org/pdf/2508.17619</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.17619]] Improving Interpretability in Alzheimer's Prediction via Joint Learning of ADAS-Cog Scores(https://arxiv.org/abs/2508.17619)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, interpretability, transformer</a></li>
<li><strong>Abstract: </strong>Accurate prediction of clinical scores is critical for early detection and prognosis of Alzheimers disease (AD). While existing approaches primarily focus on forecasting the ADAS-Cog global score, they often overlook the predictive value of its sub-scores (13 items), which capture domain-specific cognitive decline. In this study, we propose a multi task learning (MTL) framework that jointly predicts the global ADAS-Cog score and its sub-scores (13 items) at Month 24 using baseline MRI and longitudinal clinical scores from baseline and Month 6. The main goal is to examine how each sub scores particularly those associated with MRI features contribute to the prediction of the global score, an aspect largely neglected in prior MTL studies. We employ Vision Transformer (ViT) and Swin Transformer architectures to extract imaging features, which are fused with longitudinal clinical inputs to model cognitive progression. Our results show that incorporating sub-score learning improves global score prediction. Subscore level analysis reveals that a small subset especially Q1 (Word Recall), Q4 (Delayed Recall), and Q8 (Word Recognition) consistently dominates the predicted global score. However, some of these influential sub-scores exhibit high prediction errors, pointing to model instability. Further analysis suggests that this is caused by clinical feature dominance, where the model prioritizes easily predictable clinical scores over more complex MRI derived features. These findings emphasize the need for improved multimodal fusion and adaptive loss weighting to achieve more balanced learning. Our study demonstrates the value of sub score informed modeling and provides insights into building more interpretable and clinically robust AD prediction frameworks. (Github repo provided)</li>
</ul>

<h3>Title: Steering When Necessary: Flexible Steering Large Language Models with Backtracking</h3>
<ul>
<li><strong>Authors: </strong>Jinwei Gan, Zifeng Cheng, Zhiwei Jiang, Cong Wang, Yafeng Yin, Xiang Luo, Yuchen Fu, Qing Gu</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.17621">https://arxiv.org/abs/2508.17621</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.17621">https://arxiv.org/pdf/2508.17621</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.17621]] Steering When Necessary: Flexible Steering Large Language Models with Backtracking(https://arxiv.org/abs/2508.17621)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large language models (LLMs) have achieved remarkable performance across many generation tasks. Nevertheless, effectively aligning them with desired behaviors remains a significant challenge. Activation steering is an effective and cost-efficient approach that directly modifies the activations of LLMs during the inference stage, aligning their responses with the desired behaviors and avoiding the high cost of fine-tuning. Existing methods typically indiscriminately intervene to all generations or rely solely on the question to determine intervention, which limits the accurate assessment of the intervention strength. To this end, we propose the Flexible Activation Steering with Backtracking (FASB) framework, which dynamically determines both the necessity and strength of intervention by tracking the internal states of the LLMs during generation, considering both the question and the generated content. Since intervening after detecting a deviation from the desired behavior is often too late, we further propose the backtracking mechanism to correct the deviated tokens and steer the LLMs toward the desired behavior. Extensive experiments on the TruthfulQA dataset and six multiple-choice datasets demonstrate that our method outperforms baselines. Our code will be released at this https URL.</li>
</ul>

<h3>Title: Stop Spinning Wheels: Mitigating LLM Overthinking via Mining Patterns for Early Reasoning Exit</h3>
<ul>
<li><strong>Authors: </strong>Zihao Wei, Liang Pang, Jiahao Liu, Jingcheng Deng, Shicheng Xu, Zenghao Duan, Jingang Wang, Fei Sun, Xunliang Cai, Huawei Shen, Xueqi Cheng</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.17627">https://arxiv.org/abs/2508.17627</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.17627">https://arxiv.org/pdf/2508.17627</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.17627]] Stop Spinning Wheels: Mitigating LLM Overthinking via Mining Patterns for Early Reasoning Exit(https://arxiv.org/abs/2508.17627)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large language models (LLMs) enhance complex reasoning tasks by scaling the individual thinking process. However, prior work shows that overthinking can degrade overall performance. Motivated by observed patterns in thinking length and content length, we categorize reasoning into three stages: insufficient exploration stage, compensatory reasoning stage, and reasoning convergence stage. Typically, LLMs produce correct answers in the compensatory reasoning stage, whereas reasoning convergence often triggers overthinking, causing increased resource usage or even infinite loops. Therefore, mitigating overthinking hinges on detecting the end of the compensatory reasoning stage, defined as the Reasoning Completion Point (RCP). RCP typically appears at the end of the first complete reasoning cycle and can be identified by querying the LLM sentence by sentence or monitoring the probability of an end-of-thinking token (e.g., \texttt{</think>}), though these methods lack an efficient and precise balance. To improve this, we mine more sensitive and consistent RCP patterns and develop a lightweight thresholding strategy based on heuristic rules. Experimental evaluations on benchmarks (AIME24, AIME25, GPQA-D) demonstrate that the proposed method reduces token consumption while preserving or enhancing reasoning accuracy.</li>
</ul>

<h3>Title: Quantum Graph Attention Network: A Novel Quantum Multi-Head Attention Mechanism for Graph Learning</h3>
<ul>
<li><strong>Authors: </strong>An Ning, Tai Yue Li, Nan Yow Chen</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.17630">https://arxiv.org/abs/2508.17630</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.17630">https://arxiv.org/pdf/2508.17630</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.17630]] Quantum Graph Attention Network: A Novel Quantum Multi-Head Attention Mechanism for Graph Learning(https://arxiv.org/abs/2508.17630)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>We propose the Quantum Graph Attention Network (QGAT), a hybrid graph neural network that integrates variational quantum circuits into the attention mechanism. At its core, QGAT employs strongly entangling quantum circuits with amplitude-encoded node features to enable expressive nonlinear interactions. Distinct from classical multi-head attention that separately computes each head, QGAT leverages a single quantum circuit to simultaneously generate multiple attention coefficients. This quantum parallelism facilitates parameter sharing across heads, substantially reducing computational overhead and model complexity. Classical projection weights and quantum circuit parameters are optimized jointly in an end-to-end manner, ensuring flexible adaptation to learning tasks. Empirical results demonstrate QGAT's effectiveness in capturing complex structural dependencies and improved generalization in inductive scenarios, highlighting its potential for scalable quantum-enhanced learning across domains such as chemistry, biology, and network analysis. Furthermore, experiments confirm that quantum embedding enhances robustness against feature and structural noise, suggesting advantages in handling real-world noisy data. The modularity of QGAT also ensures straightforward integration into existing architectures, allowing it to easily augment classical attention-based models.</li>
</ul>

<h3>Title: ControlEchoSynth: Boosting Ejection Fraction Estimation Models via Controlled Video Diffusion</h3>
<ul>
<li><strong>Authors: </strong>Nima Kondori, Hanwen Liang, Hooman Vaseli, Bingyu Xie, Christina Luong, Purang Abolmaesumi, Teresa Tsang, Renjie Liao</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.17631">https://arxiv.org/abs/2508.17631</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.17631">https://arxiv.org/pdf/2508.17631</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.17631]] ControlEchoSynth: Boosting Ejection Fraction Estimation Models via Controlled Video Diffusion(https://arxiv.org/abs/2508.17631)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, diffusion, generative</a></li>
<li><strong>Abstract: </strong>Synthetic data generation represents a significant advancement in boosting the performance of machine learning (ML) models, particularly in fields where data acquisition is challenging, such as echocardiography. The acquisition and labeling of echocardiograms (echo) for heart assessment, crucial in point-of-care ultrasound (POCUS) settings, often encounter limitations due to the restricted number of echo views available, typically captured by operators with varying levels of experience. This study proposes a novel approach for enhancing clinical diagnosis accuracy by synthetically generating echo views. These views are conditioned on existing, real views of the heart, focusing specifically on the estimation of ejection fraction (EF), a critical parameter traditionally measured from biplane apical views. By integrating a conditional generative model, we demonstrate an improvement in EF estimation accuracy, providing a comparative analysis with traditional methods. Preliminary results indicate that our synthetic echoes, when used to augment existing datasets, not only enhance EF estimation but also show potential in advancing the development of more robust, accurate, and clinically relevant ML models. This approach is anticipated to catalyze further research in synthetic data applications, paving the way for innovative solutions in medical imaging diagnostics.</li>
</ul>

<h3>Title: Finding Outliers in a Haystack: Anomaly Detection for Large Pointcloud Scenes</h3>
<ul>
<li><strong>Authors: </strong>Ryan Faulkner, Ian Reid, Simon Ratcliffe, Tat-Jun Chin</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.17634">https://arxiv.org/abs/2508.17634</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.17634">https://arxiv.org/pdf/2508.17634</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.17634]] Finding Outliers in a Haystack: Anomaly Detection for Large Pointcloud Scenes(https://arxiv.org/abs/2508.17634)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>LiDAR scanning in outdoor scenes acquires accurate distance measurements over wide areas, producing large-scale point clouds. Application examples for this data include robotics, automotive vehicles, and land surveillance. During such applications, outlier objects from outside the training data will inevitably appear. Our research contributes a novel approach to open-set segmentation, leveraging the learnings of object defect-detection research. We also draw on the Mamba architecture's strong performance in utilising long-range dependencies and scalability to large data. Combining both, we create a reconstruction based approach for the task of outdoor scene open-set segmentation. We show that our approach improves performance not only when applied to our our own open-set segmentation method, but also when applied to existing methods. Furthermore we contribute a Mamba based architecture which is competitive with existing voxel-convolution based methods on challenging, large-scale pointclouds.</li>
</ul>

<h3>Title: Wound3DAssist: A Practical Framework for 3D Wound Assessment</h3>
<ul>
<li><strong>Authors: </strong>Remi Chierchia, Rodrigo Santa Cruz, L√©o Lebrat, Yulia Arzhaeva, Mohammad Ali Armin, Jeremy Oorloff, Chuong Nguyen, Olivier Salvado, Clinton Fookes, David Ahmedt-Aristizabal</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.17635">https://arxiv.org/abs/2508.17635</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.17635">https://arxiv.org/pdf/2508.17635</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.17635]] Wound3DAssist: A Practical Framework for 3D Wound Assessment(https://arxiv.org/abs/2508.17635)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, segmentation</a></li>
<li><strong>Abstract: </strong>Managing chronic wounds remains a major healthcare challenge, with clinical assessment often relying on subjective and time-consuming manual documentation methods. Although 2D digital videometry frameworks aided the measurement process, these approaches struggle with perspective distortion, a limited field of view, and an inability to capture wound depth, especially in anatomically complex or curved regions. To overcome these limitations, we present Wound3DAssist, a practical framework for 3D wound assessment using monocular consumer-grade videos. Our framework generates accurate 3D models from short handheld smartphone video recordings, enabling non-contact, automatic measurements that are view-independent and robust to camera motion. We integrate 3D reconstruction, wound segmentation, tissue classification, and periwound analysis into a modular workflow. We evaluate Wound3DAssist across digital models with known geometry, silicone phantoms, and real patients. Results show that the framework supports high-quality wound bed visualization, millimeter-level accuracy, and reliable tissue composition analysis. Full assessments are completed in under 20 minutes, demonstrating feasibility for real-world clinical use.</li>
</ul>

<h3>Title: Weights-Rotated Preference Optimization for Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Chenxu Yang, Ruipeng Jia, Mingyu Zheng, Naibin Gu, Zheng Lin, Siyuan Chen, Weichong Yin, Hua Wu, Weiping Wang</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.17637">https://arxiv.org/abs/2508.17637</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.17637">https://arxiv.org/pdf/2508.17637</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.17637]] Weights-Rotated Preference Optimization for Large Language Models(https://arxiv.org/abs/2508.17637)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Despite the efficacy of Direct Preference Optimization (DPO) in aligning Large Language Models (LLMs), reward hacking remains a pivotal challenge. This issue emerges when LLMs excessively reduce the probability of rejected completions to achieve high rewards, without genuinely meeting their intended goals. As a result, this leads to overly lengthy generation lacking diversity, as well as catastrophic forgetting of knowledge. We investigate the underlying reason behind this issue, which is representation redundancy caused by neuron collapse in the parameter space. Hence, we propose a novel Weights-Rotated Preference Optimization (RoPO) algorithm, which implicitly constrains the output layer logits with the KL divergence inherited from DPO and explicitly constrains the intermediate hidden states by fine-tuning on a multi-granularity orthogonal matrix. This design prevents the policy model from deviating too far from the reference model, thereby retaining the knowledge and expressive capabilities acquired during pre-training and SFT stages. Our RoPO achieves up to a 3.27-point improvement on AlpacaEval 2, and surpasses the best baseline by 6.2 to 7.5 points on MT-Bench with merely 0.015% of the trainable parameters, demonstrating its effectiveness in alleviating the reward hacking problem of DPO.</li>
</ul>

<h3>Title: Dynamic Embedding of Hierarchical Visual Features for Efficient Vision-Language Fine-Tuning</h3>
<ul>
<li><strong>Authors: </strong>Xinyu Wei, Guoli Yang, Jialu Zhou, Mingyue Yang, Leqian Li, Kedi Zhang, Chunping Qiu</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.17638">https://arxiv.org/abs/2508.17638</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.17638">https://arxiv.org/pdf/2508.17638</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.17638]] Dynamic Embedding of Hierarchical Visual Features for Efficient Vision-Language Fine-Tuning(https://arxiv.org/abs/2508.17638)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large Vision-Language Models (LVLMs) commonly follow a paradigm that projects visual features and then concatenates them with text tokens to form a unified sequence input for Large Language Models (LLMs). However, this paradigm leads to a significant increase in the length of the input sequence, resulting in substantial computational overhead. Existing methods attempt to fuse visual information into the intermediate layers of LLMs, which alleviate the sequence length issue but often neglect the hierarchical semantic representations within the model and the fine-grained visual information available in the shallower visual encoding layers. To address this limitation, we propose DEHVF, an efficient vision-language fine-tuning method based on dynamic embedding and fusion of hierarchical visual features. Its core lies in leveraging the inherent hierarchical representation characteristics of visual encoders and language models. Through a lightweight hierarchical visual fuser, it dynamically selects and fuses hierarchical features corresponding to semantic granularity based on the internal representations of each layer in LLMs. The fused layer-related visual features are then projected and aligned before being directly embedded into the Feed-Forward Network (FFN) of the corresponding layer in LLMs. This approach not only avoids sequence expansion but also dynamically fuses multi-layer visual information. By fine-tuning only a small number of parameters, DEHVF achieves precise alignment and complementarity of cross-modal information at the same semantic granularity. We conducted experiments across various VL benchmarks, including visual question answering on ScienceQA and image captioning on COCO Captions. The results demonstrate that DEHVF achieves higher accuracy than existing parameter-efficient fine-tuning (PEFT) baselines while maintaining efficient training and inference.</li>
</ul>

<h3>Title: HyTver: A Novel Loss Function for Longitudinal Multiple Sclerosis Lesion Segmentation</h3>
<ul>
<li><strong>Authors: </strong>Dayan Perera, Ting Fung Fung, Vishnu Monn</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.17639">https://arxiv.org/abs/2508.17639</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.17639">https://arxiv.org/pdf/2508.17639</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.17639]] HyTver: A Novel Loss Function for Longitudinal Multiple Sclerosis Lesion Segmentation(https://arxiv.org/abs/2508.17639)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>Longitudinal Multiple Sclerosis Lesion Segmentation is a particularly challenging problem that involves both input and output imbalance in the data and segmentation. Therefore in order to develop models that are practical, one of the solutions is to develop better loss functions. Most models naively use either Dice loss or Cross-Entropy loss or their combination without too much consideration. However, one must select an appropriate loss function as the imbalance can be mitigated by selecting a proper loss function. In order to solve the imbalance problem, multiple loss functions were proposed that claimed to solve it. They come with problems of their own which include being too computationally complex due to hyperparameters as exponents or having detrimental performance in metrics other than region-based ones. We propose a novel hybrid loss called HyTver that achieves good segmentation performance while maintaining performance in other metrics. We achieve a Dice score of 0.659 while also ensuring that the distance-based metrics are comparable to other popular functions. In addition, we also evaluate the stability of the loss functions when used on a pre- trained model and perform extensive comparisons with other popular loss functions</li>
</ul>

<h3>Title: SurveyGen: Quality-Aware Scientific Survey Generation with Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Tong Bao, Mir Tafseer Nayeem, Davood Rafiei, Chengzhi Zhang</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.DL, cs.IR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.17647">https://arxiv.org/abs/2508.17647</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.17647">https://arxiv.org/pdf/2508.17647</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.17647]] SurveyGen: Quality-Aware Scientific Survey Generation with Large Language Models(https://arxiv.org/abs/2508.17647)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Automatic survey generation has emerged as a key task in scientific document processing. While large language models (LLMs) have shown promise in generating survey texts, the lack of standardized evaluation datasets critically hampers rigorous assessment of their performance against human-written surveys. In this work, we present SurveyGen, a large-scale dataset comprising over 4,200 human-written surveys across diverse scientific domains, along with 242,143 cited references and extensive quality-related metadata for both the surveys and the cited papers. Leveraging this resource, we build QUAL-SG, a novel quality-aware framework for survey generation that enhances the standard Retrieval-Augmented Generation (RAG) pipeline by incorporating quality-aware indicators into literature retrieval to assess and select higher-quality source papers. Using this dataset and framework, we systematically evaluate state-of-the-art LLMs under varying levels of human involvement - from fully automatic generation to human-guided writing. Experimental results and human evaluations show that while semi-automatic pipelines can achieve partially competitive outcomes, fully automatic survey generation still suffers from low citation quality and limited critical analysis.</li>
</ul>

<h3>Title: Longitudinal Progression Prediction of Alzheimer's Disease with Tabular Foundation Model</h3>
<ul>
<li><strong>Authors: </strong>Yilang Ding, Jiawen Ren, Jiaying Lu, Gloria Hyunjung Kwak, Armin Iraji, Alex Fedorov</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.17649">https://arxiv.org/abs/2508.17649</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.17649">https://arxiv.org/pdf/2508.17649</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.17649]] Longitudinal Progression Prediction of Alzheimer's Disease with Tabular Foundation Model(https://arxiv.org/abs/2508.17649)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, generative</a></li>
<li><strong>Abstract: </strong>Alzheimer's disease is a progressive neurodegenerative disorder that remains challenging to predict due to its multifactorial etiology and the complexity of multimodal clinical data. Accurate forecasting of clinically relevant biomarkers, including diagnostic and quantitative measures, is essential for effective monitoring of disease progression. This work introduces L2C-TabPFN, a method that integrates a longitudinal-to-cross-sectional (L2C) transformation with a pre-trained Tabular Foundation Model (TabPFN) to predict Alzheimer's disease outcomes using the TADPOLE dataset. L2C-TabPFN converts sequential patient records into fixed-length feature vectors, enabling robust prediction of diagnosis, cognitive scores, and ventricular volume. Experimental results demonstrate that, while L2C-TabPFN achieves competitive performance on diagnostic and cognitive outcomes, it provides state-of-the-art results in ventricular volume prediction. This key imaging biomarker reflects neurodegeneration and progression in Alzheimer's disease. These findings highlight the potential of tabular foundational models for advancing longitudinal prediction of clinically relevant imaging markers in Alzheimer's disease.</li>
</ul>

<h3>Title: FloraSyntropy-Net: Scalable Deep Learning with Novel FloraSyntropy Archive for Large-Scale Plant Disease Diagnosis</h3>
<ul>
<li><strong>Authors: </strong>Saif Ur Rehman Khan, Muhammad Nabeel Asim, Sebastian Vollmer, Andreas Dengel</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.17653">https://arxiv.org/abs/2508.17653</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.17653">https://arxiv.org/pdf/2508.17653</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.17653]] FloraSyntropy-Net: Scalable Deep Learning with Novel FloraSyntropy Archive for Large-Scale Plant Disease Diagnosis(https://arxiv.org/abs/2508.17653)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, robust, federate</a></li>
<li><strong>Abstract: </strong>Early diagnosis of plant diseases is critical for global food safety, yet most AI solutions lack the generalization required for real-world agricultural diversity. These models are typically constrained to specific species, failing to perform accurately across the broad spectrum of cultivated plants. To address this gap, we first introduce the FloraSyntropy Archive, a large-scale dataset of 178,922 images across 35 plant species, annotated with 97 distinct disease classes. We establish a benchmark by evaluating numerous existing models on this archive, revealing a significant performance gap. We then propose FloraSyntropy-Net, a novel federated learning framework (FL) that integrates a Memetic Algorithm (MAO) for optimal base model selection (DenseNet201), a novel Deep Block for enhanced feature representation, and a client-cloning strategy for scalable, privacy-preserving training. FloraSyntropy-Net achieves a state-of-the-art accuracy of 96.38% on the FloraSyntropy benchmark. Crucially, to validate its generalization capability, we test the model on the unrelated multiclass Pest dataset, where it demonstrates exceptional adaptability, achieving 99.84% accuracy. This work provides not only a valuable new resource but also a robust and highly generalizable framework that advances the field towards practical, large-scale agricultural AI applications.</li>
</ul>

<h3>Title: Rethinking the Detail-Preserved Completion of Complex Tubular Structures based on Point Cloud: a Dataset and a Benchmark</h3>
<ul>
<li><strong>Authors: </strong>Yaolei Qi, Yikai Yang, Wenbo Peng, Shumei Miao, Yutao Hu, Guanyu Yang</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.17658">https://arxiv.org/abs/2508.17658</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.17658">https://arxiv.org/pdf/2508.17658</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.17658]] Rethinking the Detail-Preserved Completion of Complex Tubular Structures based on Point Cloud: a Dataset and a Benchmark(https://arxiv.org/abs/2508.17658)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>Complex tubular structures are essential in medical imaging and computer-assisted diagnosis, where their integrity enhances anatomical visualization and lesion detection. However, existing segmentation algorithms struggle with structural discontinuities, particularly in severe clinical cases such as coronary artery stenosis and vessel occlusions, which leads to undesired discontinuity and compromising downstream diagnostic accuracy. Therefore, it is imperative to reconnect discontinuous structures to ensure their completeness. In this study, we explore the tubular structure completion based on point cloud for the first time and establish a Point Cloud-based Coronary Artery Completion (PC-CAC) dataset, which is derived from real clinical data. This dataset provides a novel benchmark for tubular structure completion. Additionally, we propose TSRNet, a Tubular Structure Reconnection Network that integrates a detail-preservated feature extractor, a multiple dense refinement strategy, and a global-to-local loss function to ensure accurate reconnection while maintaining structural integrity. Comprehensive experiments on our PC-CAC and two additional public datasets (PC-ImageCAS and PC-PTR) demonstrate that our method consistently outperforms state-of-the-art approaches across multiple evaluation metrics, setting a new benchmark for point cloud-based tubular structure reconstruction. Our benchmark is available at this https URL.</li>
</ul>

<h3>Title: M^3-GloDets: Multi-Region and Multi-Scale Analysis of Fine-Grained Diseased Glomerular Detection</h3>
<ul>
<li><strong>Authors: </strong>Tianyu Shi, Xinzi He, Kenji Ikemura, Mert R. Sabuncu, Yihe Yang, Ruining Deng</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.17666">https://arxiv.org/abs/2508.17666</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.17666">https://arxiv.org/pdf/2508.17666</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.17666]] M^3-GloDets: Multi-Region and Multi-Scale Analysis of Fine-Grained Diseased Glomerular Detection(https://arxiv.org/abs/2508.17666)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, segmentation</a></li>
<li><strong>Abstract: </strong>Accurate detection of diseased glomeruli is fundamental to progress in renal pathology and underpins the delivery of reliable clinical diagnoses. Although recent advances in computer vision have produced increasingly sophisticated detection algorithms, the majority of research efforts have focused on normal glomeruli or instances of global sclerosis, leaving the wider spectrum of diseased glomerular subtypes comparatively understudied. This disparity is not without consequence; the nuanced and highly variable morphological characteristics that define these disease variants frequently elude even the most advanced computational models. Moreover, ongoing debate surrounds the choice of optimal imaging magnifications and region-of-view dimensions for fine-grained glomerular analysis, adding further complexity to the pursuit of accurate classification and robust segmentation. To bridge these gaps, we present M^3-GloDet, a systematic framework designed to enable thorough evaluation of detection models across a broad continuum of regions, scales, and classes. Within this framework, we evaluate both long-standing benchmark architectures and recently introduced state-of-the-art models that have achieved notable performance, using an experimental design that reflects the diversity of region-of-interest sizes and imaging resolutions encountered in routine digital renal pathology. As the results, we found that intermediate patch sizes offered the best balance between context and efficiency. Additionally, moderate magnifications enhanced generalization by reducing overfitting. Through systematic comparison of these approaches on a multi-class diseased glomerular dataset, our aim is to advance the understanding of model strengths and limitations, and to offer actionable insights for the refinement of automated detection strategies and clinical workflows in the digital pathology domain.</li>
</ul>

<h3>Title: CoCoA: Confidence- and Context-Aware Adaptive Decoding for Resolving Knowledge Conflicts in Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Anant Khandelwal, Manish Gupta, Puneet Agrawal</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.17670">https://arxiv.org/abs/2508.17670</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.17670">https://arxiv.org/pdf/2508.17670</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.17670]] CoCoA: Confidence- and Context-Aware Adaptive Decoding for Resolving Knowledge Conflicts in Large Language Models(https://arxiv.org/abs/2508.17670)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Faithful generation in large language models (LLMs) is challenged by knowledge conflicts between parametric memory and external context. Existing contrastive decoding methods tuned specifically to handle conflict often lack adaptability and can degrade performance in low conflict settings. We introduce CoCoA (Confidence- and Context-Aware Adaptive Decoding), a novel token-level algorithm for principled conflict resolution and enhanced faithfulness. CoCoA resolves conflict by utilizing confidence-aware measures (entropy gap and contextual peakedness) and the generalized divergence between the parametric and contextual distributions. Crucially, CoCoA maintains strong performance even in low conflict settings. Extensive experiments across multiple LLMs on diverse Question Answering (QA), Summarization, and Long-Form Question Answering (LFQA) benchmarks demonstrate CoCoA's state-of-the-art performance over strong baselines like AdaCAD. It yields significant gains in QA accuracy, up to 9.2 points on average compared to the strong baseline AdaCAD, and improves factuality in summarization and LFQA by up to 2.5 points on average across key benchmarks. Additionally, it demonstrates superior sensitivity to conflict variations. CoCoA enables more informed, context-aware, and ultimately more faithful token generation.</li>
</ul>

<h3>Title: Attacking LLMs and AI Agents: Advertisement Embedding Attacks Against Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Qiming Guo, Jinwen Tang, Xingran Huang</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.17674">https://arxiv.org/abs/2508.17674</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.17674">https://arxiv.org/pdf/2508.17674</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.17674]] Attacking LLMs and AI Agents: Advertisement Embedding Attacks Against Large Language Models(https://arxiv.org/abs/2508.17674)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, defense, attack, steal, large language model</a></li>
<li><strong>Abstract: </strong>We introduce Advertisement Embedding Attacks (AEA), a new class of LLM security threats that stealthily inject promotional or malicious content into model outputs and AI agents. AEA operate through two low-cost vectors: (1) hijacking third-party service-distribution platforms to prepend adversarial prompts, and (2) publishing back-doored open-source checkpoints fine-tuned with attacker data. Unlike conventional attacks that degrade accuracy, AEA subvert information integrity, causing models to return covert ads, propaganda, or hate speech while appearing normal. We detail the attack pipeline, map five stakeholder victim groups, and present an initial prompt-based self-inspection defense that mitigates these injections without additional model retraining. Our findings reveal an urgent, under-addressed gap in LLM security and call for coordinated detection, auditing, and policy responses from the AI-safety community.</li>
</ul>

<h3>Title: Towards Synthesizing Normative Data for Cognitive Assessments Using Generative Multimodal Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Victoria Yan, Honor Chotkowski, Fengran Wang, Alex Fedorov</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.17675">https://arxiv.org/abs/2508.17675</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.17675">https://arxiv.org/pdf/2508.17675</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.17675]] Towards Synthesizing Normative Data for Cognitive Assessments Using Generative Multimodal Large Language Models(https://arxiv.org/abs/2508.17675)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, generative, large language model</a></li>
<li><strong>Abstract: </strong>Cognitive assessments require normative data as essential benchmarks for evaluating individual performance. Hence, developing new cognitive tests based on novel image stimuli is challenging due to the lack of readily available normative data. Traditional data collection methods are costly, time-consuming, and infrequently updated, limiting their practical utility. Recent advancements in generative multimodal large language models (MLLMs) offer a new approach to generate synthetic normative data from existing cognitive test images. We investigated the feasibility of using MLLMs, specifically GPT-4o and GPT-4o-mini, to synthesize normative textual responses for established image-based cognitive assessments, such as the "Cookie Theft" picture description task. Two distinct prompting strategies-naive prompts with basic instructions and advanced prompts enriched with contextual guidance-were evaluated. Responses were analyzed using embeddings to assess their capacity to distinguish diagnostic groups and demographic variations. Performance metrics included BLEU, ROUGE, BERTScore, and an LLM-as-a-judge evaluation. Advanced prompting strategies produced synthetic responses that more effectively distinguished between diagnostic groups and captured demographic diversity compared to naive prompts. Superior models generated responses exhibiting higher realism and diversity. BERTScore emerged as the most reliable metric for contextual similarity assessment, while BLEU was less effective for evaluating creative outputs. The LLM-as-a-judge approach provided promising preliminary validation results. Our study demonstrates that generative multimodal LLMs, guided by refined prompting methods, can feasibly generate robust synthetic normative data for existing cognitive tests, thereby laying the groundwork for developing novel image-based cognitive assessments without the traditional limitations.</li>
</ul>

<h3>Title: Characterizing the Behavior of Training Mamba-based State Space Models on GPUs</h3>
<ul>
<li><strong>Authors: </strong>Trinayan Baruah, Kaustubh Shivdikar, Sara Prescott, David Kaeli</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AR, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.17679">https://arxiv.org/abs/2508.17679</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.17679">https://arxiv.org/pdf/2508.17679</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.17679]] Characterizing the Behavior of Training Mamba-based State Space Models on GPUs(https://arxiv.org/abs/2508.17679)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Mamba-based State Space Models (SSM) have emerged as a promising alternative to the ubiquitous transformers. Despite the expressive power of transformers, the quadratic complexity of computing attention is a major impediment to scaling performance as we increase the sequence length. SSMs provide an alternative path that addresses this problem, reducing the computational complexity requirements of self-attention with novel model architectures for different domains and fields such as video, text generation and graphs. Thus, it is important to characterize the behavior of these emerging workloads on GPUs and understand their requirements during GPU microarchitectural design. In this work we evaluate Mamba-based SSMs and characterize their behavior during training on GPUs. We construct a workload suite that offers representative models that span different model architectures. We then use this suite to analyze the architectural implications of running Mamba-based SSMs on GPUs. Our work sheds new light on potential optimizations to continue scaling the performance for such models.</li>
</ul>

<h3>Title: Robustness Feature Adapter for Efficient Adversarial Training</h3>
<ul>
<li><strong>Authors: </strong>Quanwei Wu, Jun Guo, Wei Wang, Yi Wang</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.17680">https://arxiv.org/abs/2508.17680</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.17680">https://arxiv.org/pdf/2508.17680</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.17680]] Robustness Feature Adapter for Efficient Adversarial Training(https://arxiv.org/abs/2508.17680)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack, robust</a></li>
<li><strong>Abstract: </strong>Adversarial training (AT) with projected gradient descent is the most popular method to improve model robustness under adversarial attacks. However, computational overheads become prohibitively large when AT is applied to large backbone models. AT is also known to have the issue of robust overfitting. This paper contributes to solving both problems simultaneously towards building more trustworthy foundation models. In particular, we propose a new adapter-based approach for efficient AT directly in the feature space. We show that the proposed adapter-based approach can improve the inner-loop convergence quality by eliminating robust overfitting. As a result, it significantly increases computational efficiency and improves model accuracy by generalizing adversarial robustness to unseen attacks. We demonstrate the effectiveness of the new adapter-based approach in different backbone architectures and in AT at scale.</li>
</ul>

<h3>Title: Unlearning as Ablation: Toward a Falsifiable Benchmark for Generative Scientific Discovery</h3>
<ul>
<li><strong>Authors: </strong>Robert Yang</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.17681">https://arxiv.org/abs/2508.17681</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.17681">https://arxiv.org/pdf/2508.17681</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.17681]] Unlearning as Ablation: Toward a Falsifiable Benchmark for Generative Scientific Discovery(https://arxiv.org/abs/2508.17681)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, generative, large language model</a></li>
<li><strong>Abstract: </strong>Bold claims about AI's role in science-from "AGI will cure all diseases" to promises of radically accelerated discovery-raise a central epistemic question: do large language models (LLMs) truly generate new knowledge, or do they merely remix memorized fragments? We propose unlearning-as-ablation as a falsifiable test of constructive scientific discovery. The method systematically removes a target result and its entire forget-closure (lemmas, paraphrases, and multi-hop entailments) and then evaluates whether the model can re-derive the result from only permitted axioms and tools. Success provides evidence for genuine generative capability; failure exposes current limits. Unlike prevailing motivations for unlearning-privacy, copyright, or safety-our framing repositions it as an epistemic probe for AI-for-Science. We argue that such tests could serve as the next generation of benchmarks, much as ImageNet catalyzed progress in vision: distinguishing models that can merely recall from those that can constructively generate new scientific knowledge. We outline a minimal pilot in mathematics and algorithms, and discuss extensions to physics, chemistry, and biology. Whether models succeed or fail, unlearning-as-ablation provides a principled framework to map the true reach and limits of AI scientific discovery. This is a position paper: we advance a conceptual and methodological argument rather than new empirical results.</li>
</ul>

<h3>Title: On the Edge of Memorization in Diffusion Models</h3>
<ul>
<li><strong>Authors: </strong>Sam Buchanan, Druv Pai, Yi Ma, Valentin De Bortoli</a></li>
<li><strong>Subjects: </strong>cs.LG, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.17689">https://arxiv.org/abs/2508.17689</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.17689">https://arxiv.org/pdf/2508.17689</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.17689]] On the Edge of Memorization in Diffusion Models(https://arxiv.org/abs/2508.17689)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, diffusion</a></li>
<li><strong>Abstract: </strong>When do diffusion models reproduce their training data, and when are they able to generate samples beyond it? A practically relevant theoretical understanding of this interplay between memorization and generalization may significantly impact real-world deployments of diffusion models with respect to issues such as copyright infringement and data privacy. In this work, to disentangle the different factors that influence memorization and generalization in practical diffusion models, we introduce a scientific and mathematical "laboratory" for investigating these phenomena in diffusion models trained on fully synthetic or natural image-like structured data. Within this setting, we hypothesize that the memorization or generalization behavior of an underparameterized trained model is determined by the difference in training loss between an associated memorizing model and a generalizing model. To probe this hypothesis, we theoretically characterize a crossover point wherein the weighted training loss of a fully generalizing model becomes greater than that of an underparameterized memorizing model at a critical value of model (under)parameterization. We then demonstrate via carefully-designed experiments that the location of this crossover predicts a phase transition in diffusion models trained via gradient descent, validating our hypothesis. Ultimately, our theory enables us to analytically predict the model size at which memorization becomes predominant. Our work provides an analytically tractable and practically meaningful setting for future theoretical and empirical investigations. Code for our experiments is available at this https URL.</li>
</ul>

<h3>Title: Rethinking Federated Learning Over the Air: The Blessing of Scaling Up</h3>
<ul>
<li><strong>Authors: </strong>Jiaqi Zhu, Bikramjit Das, Yong Xie, Nikolaos Pappas, Howard H. Yang</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.17697">https://arxiv.org/abs/2508.17697</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.17697">https://arxiv.org/pdf/2508.17697</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.17697]] Rethinking Federated Learning Over the Air: The Blessing of Scaling Up(https://arxiv.org/abs/2508.17697)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, federate</a></li>
<li><strong>Abstract: </strong>Federated learning facilitates collaborative model training across multiple clients while preserving data privacy. However, its performance is often constrained by limited communication resources, particularly in systems supporting a large number of clients. To address this challenge, integrating over-the-air computations into the training process has emerged as a promising solution to alleviate communication bottlenecks. The system significantly increases the number of clients it can support in each communication round by transmitting intermediate parameters via analog signals rather than digital ones. This improvement, however, comes at the cost of channel-induced distortions, such as fading and noise, which affect the aggregated global parameters. To elucidate these effects, this paper develops a theoretical framework to analyze the performance of over-the-air federated learning in large-scale client scenarios. Our analysis reveals three key advantages of scaling up the number of participating clients: (1) Enhanced Privacy: The mutual information between a client's local gradient and the server's aggregated gradient diminishes, effectively reducing privacy leakage. (2) Mitigation of Channel Fading: The channel hardening effect eliminates the impact of small-scale fading in the noisy global gradient. (3) Improved Convergence: Reduced thermal noise and gradient estimation errors benefit the convergence rate. These findings solidify over-the-air model training as a viable approach for federated learning in networks with a large number of clients. The theoretical insights are further substantiated through extensive experimental evaluations.</li>
</ul>

<h3>Title: Benchmarking Class Activation Map Methods for Explainable Brain Hemorrhage Classification on Hemorica Dataset</h3>
<ul>
<li><strong>Authors: </strong>Z. Rafati, M. Hoseyni, J. Khoramdel, A. Nikoofard</a></li>
<li><strong>Subjects: </strong>cs.CV, q-bio.QM</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.17699">https://arxiv.org/abs/2508.17699</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.17699">https://arxiv.org/pdf/2508.17699</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.17699]] Benchmarking Class Activation Map Methods for Explainable Brain Hemorrhage Classification on Hemorica Dataset(https://arxiv.org/abs/2508.17699)</code><input type="text"></li>
<li><strong>Keywords: </strong>explainability, segmentation</a></li>
<li><strong>Abstract: </strong>Explainable Artificial Intelligence (XAI) has become an essential component of medical imaging research, aiming to increase transparency and clinical trust in deep learning models. This study investigates brain hemorrhage diagnosis with a focus on explainability through Class Activation Mapping (CAM) techniques. A pipeline was developed to extract pixellevel segmentation and detection annotations from classification models using nine state-of-the-art CAM algorithms, applied across multiple network stages, and quantitatively evaluated on the Hemorica dataset, which uniquely provides both slice-level labels and high-quality segmentation masks. Metrics including Dice, IoU, and pixel-wise overlap were employed to benchmark CAM variants. Results show that the strongest localization performance occurred at stage 5 of EfficientNetV2S, with HiResCAM yielding the highest bounding-box alignment and AblationCAM achieving the best pixel-level Dice (0.57) and IoU (0.40), representing strong accuracy given that models were trained solely for classification without segmentation supervision. To the best of current knowledge, this is among the f irst works to quantitatively compare CAM methods for brain hemorrhage detection, establishing a reproducible benchmark and underscoring the potential of XAI-driven pipelines for clinically meaningful AI-assisted diagnosis.</li>
</ul>

<h3>Title: Adaptive Ensemble Learning with Gaussian Copula for Load Forecasting</h3>
<ul>
<li><strong>Authors: </strong>Junying Yang, Gang Lu, Xiaoqing Yan, Peng Xia, Di Wu</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.17700">https://arxiv.org/abs/2508.17700</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.17700">https://arxiv.org/pdf/2508.17700</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.17700]] Adaptive Ensemble Learning with Gaussian Copula for Load Forecasting(https://arxiv.org/abs/2508.17700)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Machine learning (ML) is capable of accurate Load Forecasting from complete data. However, there are many uncertainties that affect data collection, leading to sparsity. This article proposed a model called Adaptive Ensemble Learning with Gaussian Copula to deal with sparsity, which contains three modules: data complementation, ML construction, and adaptive ensemble. First, it applies Gaussian Copula to eliminate sparsity. Then, we utilise five ML models to make predictions individually. Finally, it employs adaptive ensemble to get final weighted-sum result. Experiments have demonstrated that our model are robust.</li>
</ul>

<h3>Title: Copyright Protection for 3D Molecular Structures with Watermarking</h3>
<ul>
<li><strong>Authors: </strong>Runwen Hu, Peilin Chen, Keyan Ding, Shiqi Wang</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.17702">https://arxiv.org/abs/2508.17702</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.17702">https://arxiv.org/pdf/2508.17702</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.17702]] Copyright Protection for 3D Molecular Structures with Watermarking(https://arxiv.org/abs/2508.17702)</code><input type="text"></li>
<li><strong>Keywords: </strong>secure, protect, robust, watermark, generative</a></li>
<li><strong>Abstract: </strong>Artificial intelligence (AI) revolutionizes molecule generation in bioengineering and biological research, significantly accelerating discovery processes. However, this advancement introduces critical concerns regarding intellectual property protection. To address these challenges, we propose the first robust watermarking method designed for molecules, which utilizes atom-level features to preserve molecular integrity and invariant features to ensure robustness against affine transformations. Comprehensive experiments validate the effectiveness of our method using the datasets QM9 and GEOM-DRUG, and generative models GeoBFN and GeoLDM. We demonstrate the feasibility of embedding watermarks, maintaining basic properties higher than 90.00\% while achieving watermark accuracy greater than 95.00\%. Furthermore, downstream docking simulations reveal comparable performance between original and watermarked molecules, with binding affinities reaching -6.00 kcal/mol and root mean square deviations below 1.602 √Ö. These results confirm that our watermarking technique effectively safeguards molecular intellectual property without compromising scientific utility, enabling secure and responsible AI integration in molecular discovery and research applications.</li>
</ul>

<h3>Title: EMPOWER: Evolutionary Medical Prompt Optimization With Reinforcement Learning</h3>
<ul>
<li><strong>Authors: </strong>Yinda Chen, Yangfan He, Jing Yang, Dapeng Zhang, Zhenlong Yuan, Muhammad Attique Khan, Jamel Baili, Por Lip Yee</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.17703">https://arxiv.org/abs/2508.17703</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.17703">https://arxiv.org/pdf/2508.17703</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.17703]] EMPOWER: Evolutionary Medical Prompt Optimization With Reinforcement Learning(https://arxiv.org/abs/2508.17703)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Prompt engineering significantly influences the reliability and clinical utility of Large Language Models (LLMs) in medical applications. Current optimization approaches inadequately address domain-specific medical knowledge and safety requirements. This paper introduces EMPOWER, a novel evolutionary framework that enhances medical prompt quality through specialized representation learning, multi-dimensional evaluation, and structure-preserving algorithms. Our methodology incorporates: (1) a medical terminology attention mechanism, (2) a comprehensive assessment architecture evaluating clarity, specificity, clinical relevance, and factual accuracy, (3) a component-level evolutionary algorithm preserving clinical reasoning integrity, and (4) a semantic verification module ensuring adherence to medical knowledge. Evaluation across diagnostic, therapeutic, and educational tasks demonstrates significant improvements: 24.7% reduction in factually incorrect content, 19.6% enhancement in domain specificity, and 15.3% higher clinician preference in blinded evaluations. The framework addresses critical challenges in developing clinically appropriate prompts, facilitating more responsible integration of LLMs into healthcare settings.</li>
</ul>

<h3>Title: CATformer: Contrastive Adversarial Transformer for Image Super-Resolution</h3>
<ul>
<li><strong>Authors: </strong>Qinyi Tian, Spence Cox, Laura E. Dalton</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.17708">https://arxiv.org/abs/2508.17708</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.17708">https://arxiv.org/pdf/2508.17708</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.17708]] CATformer: Contrastive Adversarial Transformer for Image Super-Resolution(https://arxiv.org/abs/2508.17708)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, diffusion, transformer</a></li>
<li><strong>Abstract: </strong>Super-resolution remains a promising technique to enhance the quality of low-resolution images. This study introduces CATformer (Contrastive Adversarial Transformer), a novel neural network integrating diffusion-inspired feature refinement with adversarial and contrastive learning. CATformer employs a dual-branch architecture combining a primary diffusion-inspired transformer, which progressively refines latent representations, with an auxiliary transformer branch designed to enhance robustness to noise through learned latent contrasts. These complementary representations are fused and decoded using deep Residual-in-Residual Dense Blocks for enhanced reconstruction quality. Extensive experiments on benchmark datasets demonstrate that CATformer outperforms recent transformer-based and diffusion-inspired methods both in efficiency and visual image quality. This work bridges the performance gap among transformer-, diffusion-, and GAN-based methods, laying a foundation for practical applications of diffusion-inspired transformers in super-resolution.</li>
</ul>

<h3>Title: F2RVLM: Boosting Fine-grained Fragment Retrieval for Multi-Modal Long-form Dialogue with Vision Language Model</h3>
<ul>
<li><strong>Authors: </strong>Hanbo Bi, Zhiqiang Yuan, Zexi Jia, Jiapei Zhang, Chongyang Li, Peixiang Luo, Ying Deng, Xiaoyue Duan, Jinchao Zhang</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.17714">https://arxiv.org/abs/2508.17714</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.17714">https://arxiv.org/pdf/2508.17714</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.17714]] F2RVLM: Boosting Fine-grained Fragment Retrieval for Multi-Modal Long-form Dialogue with Vision Language Model(https://arxiv.org/abs/2508.17714)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>Traditional dialogue retrieval aims to select the most appropriate utterance or image from recent dialogue history. However, they often fail to meet users' actual needs for revisiting semantically coherent content scattered across long-form conversations. To fill this gap, we define the Fine-grained Fragment Retrieval (FFR) task, requiring models to locate query-relevant fragments, comprising both utterances and images, from multimodal long-form dialogues. As a foundation for FFR, we construct MLDR, the longest-turn multimodal dialogue retrieval dataset to date, averaging 25.45 turns per dialogue, with each naturally spanning three distinct topics. To evaluate generalization in real-world scenarios, we curate and annotate a WeChat-based test set comprising real-world multimodal dialogues with an average of 75.38 turns. Building on these resources, we explore existing generation-based Vision-Language Models (VLMs) on FFR and observe that they often retrieve incoherent utterance-image fragments. While optimized for generating responses from visual-textual inputs, these models lack explicit supervision to ensure semantic coherence within retrieved fragments. To this end, we propose F2RVLM, a generative retrieval model trained in a two-stage paradigm: (1) supervised fine-tuning to inject fragment-level retrieval knowledge, and (2) GRPO-based reinforcement learning with multi-objective rewards promoting semantic precision, relevance, and contextual coherence. To handle varying intra-fragment complexity, from locally dense to sparsely distributed, we introduce difficulty-aware curriculum sampling that ranks training instances by model-predicted difficulty and gradually exposes the model to harder samples. This boosts reasoning ability in long, multi-turn contexts. F2RVLM outperforms popular VLMs in both in-domain and real-domain settings, demonstrating superior retrieval performance.</li>
</ul>

<h3>Title: Instant Preference Alignment for Text-to-Image Diffusion Models</h3>
<ul>
<li><strong>Authors: </strong>Yang Li, Songlin Yang, Xiaoxuan Han, Wei Wang, Jing Dong, Yueming Lyu, Ziyu Xue</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.17718">https://arxiv.org/abs/2508.17718</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.17718">https://arxiv.org/pdf/2508.17718</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.17718]] Instant Preference Alignment for Text-to-Image Diffusion Models(https://arxiv.org/abs/2508.17718)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, large language model</a></li>
<li><strong>Abstract: </strong>Text-to-image (T2I) generation has greatly enhanced creative expression, yet achieving preference-aligned generation in a real-time and training-free manner remains challenging. Previous methods often rely on static, pre-collected preferences or fine-tuning, limiting adaptability to evolving and nuanced user intents. In this paper, we highlight the need for instant preference-aligned T2I generation and propose a training-free framework grounded in multimodal large language model (MLLM) priors. Our framework decouples the task into two components: preference understanding and preference-guided generation. For preference understanding, we leverage MLLMs to automatically extract global preference signals from a reference image and enrich a given prompt using structured instruction design. Our approach supports broader and more fine-grained coverage of user preferences than existing methods. For preference-guided generation, we integrate global keyword-based control and local region-aware cross-attention modulation to steer the diffusion model without additional training, enabling precise alignment across both global attributes and local elements. The entire framework supports multi-round interactive refinement, facilitating real-time and context-aware image generation. Extensive experiments on the Viper dataset and our collected benchmark demonstrate that our method outperforms prior approaches in both quantitative metrics and human evaluations, and opens up new possibilities for dialog-based generation and MLLM-diffusion integration.</li>
</ul>

<h3>Title: Few-shot Human Action Anomaly Detection via a Unified Contrastive Learning Framework</h3>
<ul>
<li><strong>Authors: </strong>Koichiro Kamide, Shunsuke Sakai, Shun Maeda, Chunzhi Gu, Chao Zhang</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.17726">https://arxiv.org/abs/2508.17726</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.17726">https://arxiv.org/pdf/2508.17726</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.17726]] Few-shot Human Action Anomaly Detection via a Unified Contrastive Learning Framework(https://arxiv.org/abs/2508.17726)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, diffusion, generative</a></li>
<li><strong>Abstract: </strong>Human Action Anomaly Detection (HAAD) aims to identify anomalous actions given only normal action data during training. Existing methods typically follow a one-model-per-category paradigm, requiring separate training for each action category and a large number of normal samples. These constraints hinder scalability and limit applicability in real-world scenarios, where data is often scarce or novel categories frequently appear. To address these limitations, we propose a unified framework for HAAD that is compatible with few-shot scenarios. Our method constructs a category-agnostic representation space via contrastive learning, enabling AD by comparing test samples with a given small set of normal examples (referred to as the support set). To improve inter-category generalization and intra-category robustness, we introduce a generative motion augmentation strategy harnessing a diffusion-based foundation model for creating diverse and realistic training samples. Notably, to the best of our knowledge, our work is the first to introduce such a strategy specifically tailored to enhance contrastive learning for action AD. Extensive experiments on the HumanAct12 dataset demonstrate the state-of-the-art effectiveness of our approach under both seen and unseen category settings, regarding training efficiency and model scalability for few-shot HAAD.</li>
</ul>

<h3>Title: Segmentation and Classification of Pap Smear Images for Cervical Cancer Detection Using Deep Learning</h3>
<ul>
<li><strong>Authors: </strong>Nisreen Albzour, Sarah S. Lam</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.17728">https://arxiv.org/abs/2508.17728</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.17728">https://arxiv.org/pdf/2508.17728</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.17728]] Segmentation and Classification of Pap Smear Images for Cervical Cancer Detection Using Deep Learning(https://arxiv.org/abs/2508.17728)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction, segmentation</a></li>
<li><strong>Abstract: </strong>Cervical cancer remains a significant global health concern and a leading cause of cancer-related deaths among women. Early detection through Pap smear tests is essential to reduce mortality rates; however, the manual examination is time consuming and prone to human error. This study proposes a deep learning framework that integrates U-Net for segmentation and a classification model to enhance diagnostic performance. The Herlev Pap Smear Dataset, a publicly available cervical cell dataset, was utilized for training and evaluation. The impact of segmentation on classification performance was evaluated by comparing the model trained on segmented images and another trained on non-segmented images. Experimental results showed that the use of segmented images marginally improved the model performance on precision (about 0.41 percent higher) and F1-score (about 1.30 percent higher), which suggests a slightly more balanced classification performance. While segmentation helps in feature extraction, the results showed that its impact on classification performance appears to be limited. The proposed framework offers a supplemental tool for clinical applications, which may aid pathologists in early diagnosis.</li>
</ul>

<h3>Title: CMFDNet: Cross-Mamba and Feature Discovery Network for Polyp Segmentation</h3>
<ul>
<li><strong>Authors: </strong>Feng Jiang, Zongfei Zhang, Xin Xu</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.17729">https://arxiv.org/abs/2508.17729</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.17729">https://arxiv.org/pdf/2508.17729</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.17729]] CMFDNet: Cross-Mamba and Feature Discovery Network for Polyp Segmentation(https://arxiv.org/abs/2508.17729)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>Automated colonic polyp segmentation is crucial for assisting doctors in screening of precancerous polyps and diagnosis of colorectal neoplasms. Although existing methods have achieved promising results, polyp segmentation remains hindered by the following limitations,including: (1) significant variation in polyp shapes and sizes, (2) indistinct boundaries between polyps and adjacent tissues, and (3) small-sized polyps are easily overlooked during the segmentation process. Driven by these practical difficulties, an innovative architecture, CMFDNet, is proposed with the CMD module, MSA module, and FD module. The CMD module, serving as an innovative decoder, introduces a cross-scanning method to reduce blurry boundaries. The MSA module adopts a multi-branch parallel structure to enhance the recognition ability for polyps with diverse geometries and scale distributions. The FD module establishes dependencies among all decoder features to alleviate the under-detection of polyps with small-scale features. Experimental results show that CMFDNet outperforms six SOTA methods used for comparison, especially on ETIS and ColonDB datasets, where mDice scores exceed the best SOTA method by 1.83% and 1.55%, respectively.</li>
</ul>

<h3>Title: Layerwise Importance Analysis of Feed-Forward Networks in Transformer-based Language Models</h3>
<ul>
<li><strong>Authors: </strong>Wataru Ikeda, Kazuki Yano, Ryosuke Takahashi, Jaesung Lee, Keigo Shibata, Jun Suzuki</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.17734">https://arxiv.org/abs/2508.17734</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.17734">https://arxiv.org/pdf/2508.17734</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.17734]] Layerwise Importance Analysis of Feed-Forward Networks in Transformer-based Language Models(https://arxiv.org/abs/2508.17734)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>This study investigates the layerwise importance of feed-forward networks (FFNs) in Transformer-based language models during pretraining. We introduce an experimental approach that, while maintaining the total parameter count, increases the FFN dimensions in some layers and completely removes the FFNs from other layers. Furthermore, since our focus is on the importance of FFNs during pretraining, we train models from scratch to examine whether the importance of FFNs varies depending on their layer positions, rather than using publicly available pretrained models as is frequently done. Through comprehensive evaluations of models with varying sizes (285M, 570M, and 1.2B parameters) and layer counts (12, 24, and 40 layers), we demonstrate that concentrating FFNs in 70% of the consecutive middle layers consistently outperforms standard configurations for multiple downstream tasks.</li>
</ul>

<h3>Title: SMITE: Enhancing Fairness in LLMs through Optimal In-Context Example Selection via Dynamic Validation</h3>
<ul>
<li><strong>Authors: </strong>Garima Chhikara, Kripabandhu Ghosh, Abhijnan Chakraborty</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.17735">https://arxiv.org/abs/2508.17735</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.17735">https://arxiv.org/pdf/2508.17735</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.17735]] SMITE: Enhancing Fairness in LLMs through Optimal In-Context Example Selection via Dynamic Validation(https://arxiv.org/abs/2508.17735)</code><input type="text"></li>
<li><strong>Keywords: </strong>fair, large language model</a></li>
<li><strong>Abstract: </strong>Large Language Models (LLMs) are widely used for downstream tasks such as tabular classification, where ensuring fairness in their outputs is critical for inclusivity, equal representation, and responsible AI deployment. This study introduces a novel approach to enhancing LLM performance and fairness through the concept of a dynamic validation set, which evolves alongside the test set, replacing the traditional static validation approach. We also propose an iterative algorithm, SMITE, to select optimal in-context examples, with each example set validated against its corresponding dynamic validation set. The in-context set with the lowest total error is used as the final demonstration set. Our experiments across four different LLMs show that our proposed techniques significantly improve both predictive accuracy and fairness compared to baseline methods. To our knowledge, this is the first study to apply dynamic validation in the context of in-context learning for LLMs.</li>
</ul>

<h3>Title: Speculative Safety-Aware Decoding</h3>
<ul>
<li><strong>Authors: </strong>Xuekang Wang, Shengyu Zhu, Xueqi Cheng</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.17739">https://arxiv.org/abs/2508.17739</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.17739">https://arxiv.org/pdf/2508.17739</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.17739]] Speculative Safety-Aware Decoding(https://arxiv.org/abs/2508.17739)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack, large language model</a></li>
<li><strong>Abstract: </strong>Despite extensive efforts to align Large Language Models (LLMs) with human values and safety rules, jailbreak attacks that exploit certain vulnerabilities continuously emerge, highlighting the need to strengthen existing LLMs with additional safety properties to defend against these attacks. However, tuning large models has become increasingly resource-intensive and may have difficulty ensuring consistent performance. We introduce Speculative Safety-Aware Decoding (SSD), a lightweight decoding-time approach that equips LLMs with the desired safety property while accelerating inference. We assume that there exists a small language model that possesses this desired property. SSD integrates speculative sampling during decoding and leverages the match ratio between the small and composite models to quantify jailbreak risks. This enables SSD to dynamically switch between decoding schemes to prioritize utility or safety, to handle the challenge of different model capacities. The output token is then sampled from a new distribution that combines the distributions of the original and the small models. Experimental results show that SSD successfully equips the large model with the desired safety property, and also allows the model to remain helpful to benign queries. Furthermore, SSD accelerates the inference time, thanks to the speculative sampling design.</li>
</ul>

<h3>Title: Randomly Removing 50% of Dimensions in Text Embeddings has Minimal Impact on Retrieval and Classification Tasks</h3>
<ul>
<li><strong>Authors: </strong>Sotaro Takeshita, Yurina Takeshita, Daniel Ruffinelli, Simone Paolo Ponzetto</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.17744">https://arxiv.org/abs/2508.17744</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.17744">https://arxiv.org/pdf/2508.17744</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.17744]] Randomly Removing 50% of Dimensions in Text Embeddings has Minimal Impact on Retrieval and Classification Tasks(https://arxiv.org/abs/2508.17744)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative, large language model</a></li>
<li><strong>Abstract: </strong>In this paper, we study the surprising impact that truncating text embeddings has on downstream performance. We consistently observe across 6 state-of-the-art text encoders and 26 downstream tasks, that randomly removing up to 50% of embedding dimensions results in only a minor drop in performance, less than 10%, in retrieval and classification tasks. Given the benefits of using smaller-sized embeddings, as well as the potential insights about text encoding, we study this phenomenon and find that, contrary to what is suggested in prior work, this is not the result of an ineffective use of representation space. Instead, we find that a large number of uniformly distributed dimensions actually cause an increase in performance when removed. This would explain why, on average, removing a large number of embedding dimensions results in a marginal drop in performance. We make similar observations when truncating the embeddings used by large language models to make next-token predictions on generative tasks, suggesting that this phenomenon is not isolated to classification or retrieval tasks.</li>
</ul>

<h3>Title: DroneKey: Drone 3D Pose Estimation in Image Sequences using Gated Key-representation and Pose-adaptive Learning</h3>
<ul>
<li><strong>Authors: </strong>Seo-Bin Hwang, Yeong-Jun Cho</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.17746">https://arxiv.org/abs/2508.17746</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.17746">https://arxiv.org/pdf/2508.17746</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.17746]] DroneKey: Drone 3D Pose Estimation in Image Sequences using Gated Key-representation and Pose-adaptive Learning(https://arxiv.org/abs/2508.17746)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Estimating the 3D pose of a drone is important for anti-drone systems, but existing methods struggle with the unique challenges of drone keypoint detection. Drone propellers serve as keypoints but are difficult to detect due to their high visual similarity and diversity of poses. To address these challenges, we propose DroneKey, a framework that combines a 2D keypoint detector and a 3D pose estimator specifically designed for drones. In the keypoint detection stage, we extract two key-representations (intermediate and compact) from each transformer encoder layer and optimally combine them using a gated sum. We also introduce a pose-adaptive Mahalanobis distance in the loss function to ensure stable keypoint predictions across extreme poses. We built new datasets of drone 2D keypoints and 3D pose to train and evaluate our method, which have been publicly released. Experiments show that our method achieves an AP of 99.68% (OKS) in keypoint detection, outperforming existing methods. Ablation studies confirm that the pose-adaptive Mahalanobis loss function improves keypoint prediction stability and accuracy. Additionally, improvements in the encoder design enable real-time processing at 44 FPS. For 3D pose estimation, our method achieved an MAE-angle of 10.62¬∞, an RMSE of 0.221m, and an MAE-absolute of 0.076m, demonstrating high accuracy and reliability. The code and dataset are available at this https URL.</li>
</ul>

<h3>Title: Multi-layer Abstraction for Nested Generation of Options (MANGO) in Hierarchical Reinforcement Learning</h3>
<ul>
<li><strong>Authors: </strong>Alessio Arcudi, Davide Sartor, Alberto Sinigaglia, Vincent Fran√ßois-Lavet, Gian Antonio Susto</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.17751">https://arxiv.org/abs/2508.17751</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.17751">https://arxiv.org/pdf/2508.17751</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.17751]] Multi-layer Abstraction for Nested Generation of Options (MANGO) in Hierarchical Reinforcement Learning(https://arxiv.org/abs/2508.17751)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, interpretability</a></li>
<li><strong>Abstract: </strong>This paper introduces MANGO (Multilayer Abstraction for Nested Generation of Options), a novel hierarchical reinforcement learning framework designed to address the challenges of long-term sparse reward environments. MANGO decomposes complex tasks into multiple layers of abstraction, where each layer defines an abstract state space and employs options to modularize trajectories into macro-actions. These options are nested across layers, allowing for efficient reuse of learned movements and improved sample efficiency. The framework introduces intra-layer policies that guide the agent's transitions within the abstract state space, and task actions that integrate task-specific components such as reward functions. Experiments conducted in procedurally-generated grid environments demonstrate substantial improvements in both sample efficiency and generalization capabilities compared to standard RL methods. MANGO also enhances interpretability by making the agent's decision-making process transparent across layers, which is particularly valuable in safety-critical and industrial applications. Future work will explore automated discovery of abstractions and abstract actions, adaptation to continuous or fuzzy environments, and more robust multi-layer training strategies.</li>
</ul>

<h3>Title: SuperGen: An Efficient Ultra-high-resolution Video Generation System with Sketching and Tiling</h3>
<ul>
<li><strong>Authors: </strong>Fanjiang Ye, Zepeng Zhao, Yi Mu, Jucheng Shen, Renjie Li, Kaijian Wang, Desen Sun, Saurabh Agarwal, Myungjin Lee, Triston Cao, Aditya Akella, Arvind Krishnamurthy, T.S. Eugene Ng, Zhengzhong Tu, Yuke Wang</a></li>
<li><strong>Subjects: </strong>cs.LG, eess.SY</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.17756">https://arxiv.org/abs/2508.17756</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.17756">https://arxiv.org/pdf/2508.17756</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.17756]] SuperGen: An Efficient Ultra-high-resolution Video Generation System with Sketching and Tiling(https://arxiv.org/abs/2508.17756)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, generative</a></li>
<li><strong>Abstract: </strong>Diffusion models have recently achieved remarkable success in generative tasks (e.g., image and video generation), and the demand for high-quality content (e.g., 2K/4K videos) is rapidly increasing across various domains. However, generating ultra-high-resolution videos on existing standard-resolution (e.g., 720p) platforms remains challenging due to the excessive re-training requirements and prohibitively high computational and memory costs. To this end, we introduce SuperGen, an efficient tile-based framework for ultra-high-resolution video generation. SuperGen features a novel training-free algorithmic innovation with tiling to successfully support a wide range of resolutions without additional training efforts while significantly reducing both memory footprint and computational complexity. Moreover, SuperGen incorporates a tile-tailored, adaptive, region-aware caching strategy that accelerates video generation by exploiting redundancy across denoising steps and spatial regions. SuperGen also integrates cache-guided, communication-minimized tile parallelism for enhanced throughput and minimized latency. Evaluations demonstrate that SuperGen harvests the maximum performance gains while achieving high output quality across various benchmarks.</li>
</ul>

<h3>Title: CEIDM: A Controlled Entity and Interaction Diffusion Model for Enhanced Text-to-Image Generation</h3>
<ul>
<li><strong>Authors: </strong>Mingyue Yang, Dianxi Shi, Jialu Zhou, Xinyu Wei, Leqian Li, Shaowu Yang, Chunping Qiu</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.17760">https://arxiv.org/abs/2508.17760</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.17760">https://arxiv.org/pdf/2508.17760</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.17760]] CEIDM: A Controlled Entity and Interaction Diffusion Model for Enhanced Text-to-Image Generation(https://arxiv.org/abs/2508.17760)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, large language model</a></li>
<li><strong>Abstract: </strong>In Text-to-Image (T2I) generation, the complexity of entities and their intricate interactions pose a significant challenge for T2I method based on diffusion model: how to effectively control entity and their interactions to produce high-quality images. To address this, we propose CEIDM, a image generation method based on diffusion model with dual controls for entity and interaction. First, we propose an entity interactive relationships mining approach based on Large Language Models (LLMs), extracting reasonable and rich implicit interactive relationships through chain of thought to guide diffusion models to generate high-quality images that are closer to realistic logic and have more reasonable interactive relationships. Furthermore, We propose an interactive action clustering and offset method to cluster and offset the interactive action features contained in each text prompts. By constructing global and local bidirectional offsets, we enhance semantic understanding and detail supplementation of original actions, making the model's understanding of the concept of interactive "actions" more accurate and generating images with more accurate interactive actions. Finally, we design an entity control network which generates masks with entity semantic guidance, then leveraging multi-scale convolutional network to enhance entity feature and dynamic network to fuse feature. It effectively controls entities and significantly improves image quality. Experiments show that the proposed CEIDM method is better than the most representative existing methods in both entity control and their interaction control.</li>
</ul>

<h3>Title: ISACL: Internal State Analyzer for Copyrighted Training Data Leakage</h3>
<ul>
<li><strong>Authors: </strong>Guangwei Zhang, Qisheng Su, Jiateng Liu, Cheng Qian, Yanzhou Pan, Yanjie Fu, Denghui Zhang</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.17767">https://arxiv.org/abs/2508.17767</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.17767">https://arxiv.org/pdf/2508.17767</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.17767]] ISACL: Internal State Analyzer for Copyrighted Training Data Leakage(https://arxiv.org/abs/2508.17767)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, large language model</a></li>
<li><strong>Abstract: </strong>Large Language Models (LLMs) have revolutionized Natural Language Processing (NLP) but pose risks of inadvertently exposing copyrighted or proprietary data, especially when such data is used for training but not intended for distribution. Traditional methods address these leaks only after content is generated, which can lead to the exposure of sensitive information. This study introduces a proactive approach: examining LLMs' internal states before text generation to detect potential leaks. By using a curated dataset of copyrighted materials, we trained a neural network classifier to identify risks, allowing for early intervention by stopping the generation process or altering outputs to prevent disclosure. Integrated with a Retrieval-Augmented Generation (RAG) system, this framework ensures adherence to copyright and licensing requirements while enhancing data privacy and ethical standards. Our results show that analyzing internal states effectively mitigates the risk of copyrighted data leakage, offering a scalable solution that fits smoothly into AI workflows, ensuring compliance with copyright regulations while maintaining high-quality text generation. The implementation is available on GitHub.\footnote{this https URL}</li>
</ul>

<h3>Title: Robust Anomaly Detection in Industrial Environments via Meta-Learning</h3>
<ul>
<li><strong>Authors: </strong>Muhammad Aqeel, Shakiba Sharifi, Marco Cristani, Francesco Setti</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.17789">https://arxiv.org/abs/2508.17789</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.17789">https://arxiv.org/pdf/2508.17789</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.17789]] Robust Anomaly Detection in Industrial Environments via Meta-Learning(https://arxiv.org/abs/2508.17789)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Anomaly detection is fundamental for ensuring quality control and operational efficiency in industrial environments, yet conventional approaches face significant challenges when training data contains mislabeled samples-a common occurrence in real-world scenarios. This paper presents RAD, a robust anomaly detection framework that integrates Normalizing Flows with Model-Agnostic Meta-Learning to address the critical challenge of label noise in industrial settings. Our approach employs a bi-level optimization strategy where meta-learning enables rapid adaptation to varying noise conditions, while uncertainty quantification guides adaptive L2 regularization to maintain model stability. The framework incorporates multiscale feature processing through pretrained feature extractors and leverages the precise likelihood estimation capabilities of Normalizing Flows for robust anomaly scoring. Comprehensive evaluation on MVTec-AD and KSDD2 datasets demonstrates superior performance, achieving I-AUROC scores of 95.4% and 94.6% respectively under clean conditions, while maintaining robust detection capabilities above 86.8% and 92.1% even when 50% of training samples are mislabeled. The results highlight RAD's exceptional resilience to noisy training conditions and its ability to detect subtle anomalies across diverse industrial scenarios, making it a practical solution for real-world anomaly detection applications where perfect data curation is challenging.</li>
</ul>

<h3>Title: Sketchpose: Learning to Segment Cells with Partial Annotations</h3>
<ul>
<li><strong>Authors: </strong>Cl√©ment Cazorla, Nathana√´l Munier, Renaud Morin, Pierre Weiss</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.17798">https://arxiv.org/abs/2508.17798</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.17798">https://arxiv.org/pdf/2508.17798</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.17798]] Sketchpose: Learning to Segment Cells with Partial Annotations(https://arxiv.org/abs/2508.17798)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>The most popular networks used for cell segmentation (e.g. Cellpose, Stardist, HoverNet,...) rely on a prediction of a distance map. It yields unprecedented accuracy but hinges on fully annotated datasets. This is a serious limitation to generate training sets and perform transfer learning. In this paper, we propose a method that still relies on the distance map and handles partially annotated objects. We evaluate the performance of the proposed approach in the contexts of frugal learning, transfer learning and regular learning on regular databases. Our experiments show that it can lead to substantial savings in time and resources without sacrificing segmentation quality. The proposed algorithm is embedded in a user-friendly Napari plugin.</li>
</ul>

<h3>Title: DRQA: Dynamic Reasoning Quota Allocation for Controlling Overthinking in Reasoning Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Kaiwen Yan, Xuanqing Shi, Hongcheng Guo, Wenxuan Wang, Zhuosheng Zhang, Chengwei Qin</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.17803">https://arxiv.org/abs/2508.17803</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.17803">https://arxiv.org/pdf/2508.17803</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.17803]] DRQA: Dynamic Reasoning Quota Allocation for Controlling Overthinking in Reasoning Large Language Models(https://arxiv.org/abs/2508.17803)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Reasoning large language models (RLLMs), such as OpenAI-O3 and DeepSeek-R1, have recently demonstrated remarkable capabilities by performing structured and multi-step reasoning. However, recent studies reveal that RLLMs often suffer from overthinking, i.e., producing unnecessarily lengthy reasoning chains even for simple questions, leading to excessive token consumption and computational inefficiency. Interestingly, we observe that when processing multiple questions in batch mode, RLLMs exhibit more resource-efficient behavior by dynamically compressing reasoning steps for easier problems, due to implicit resource competition. Inspired by this, we propose Dynamic Reasoning Quota Allocation (DRQA), a novel method that transfers the benefits of resource competition from batch processing to single-question inference. Specifically, DRQA leverages batch-generated preference data and reinforcement learning to train the model to allocate reasoning resources adaptively. By encouraging the model to internalize a preference for responses that are both accurate and concise, DRQA enables it to generate concise answers for simple questions while retaining sufficient reasoning depth for more challenging ones. Extensive experiments on a wide range of mathematical and scientific reasoning benchmarks demonstrate that DRQA significantly reduces token usage while maintaining, and in many cases improving, answer accuracy. By effectively mitigating the overthinking problem, DRQA offers a promising direction for more efficient and scalable deployment of RLLMs, and we hope it inspires further exploration into fine-grained control of reasoning behaviors.</li>
</ul>

<h3>Title: TLGLock: A New Approach in Logic Locking Using Key-Driven Charge Recycling in Threshold Logic Gates</h3>
<ul>
<li><strong>Authors: </strong>Abdullah Sahruri, Martin Margala</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.AR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.17809">https://arxiv.org/abs/2508.17809</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.17809">https://arxiv.org/pdf/2508.17809</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.17809]] TLGLock: A New Approach in Logic Locking Using Key-Driven Charge Recycling in Threshold Logic Gates(https://arxiv.org/abs/2508.17809)</code><input type="text"></li>
<li><strong>Keywords: </strong>secure, security, defense, attack</a></li>
<li><strong>Abstract: </strong>Logic locking remains one of the most promising defenses against hardware piracy, yet current approaches often face challenges in scalability and design overhead. In this paper, we present TLGLock, a new design paradigm that leverages the structural expressiveness of Threshold Logic Gates (TLGs) and the energy efficiency of charge recycling to enforce key-dependent functionality at the gate level. By embedding the key into the gate's weighted logic and utilizing dynamic charge sharing, TLGLock provides a stateless and compact alternative to conventional locking techniques. We implement a complete synthesis-to-locking flow and evaluate it using ISCAS, ITC, and MCNC benchmarks. Results show that TLGLock achieves up to 30% area, 50% delay, and 20% power savings compared to latch-based locking schemes. In comparison with XOR and SFLL-HD methods, TLGLock offers up to 3x higher SAT attack resistance with significantly lower overhead. Furthermore, randomized key-weight experiments demonstrate that TLGLock can reach up to 100% output corruption under incorrect keys, enabling tunable security at minimal cost. These results position TLGLock as a scalable and resilient solution for secure hardware design.</li>
</ul>

<h3>Title: Multi-domain Distribution Learning for De Novo Drug Design</h3>
<ul>
<li><strong>Authors: </strong>Arne Schneuing, Ilia Igashov, Adrian W. Dobbelstein, Thomas Castiglione, Michael Bronstein, Bruno Correia</a></li>
<li><strong>Subjects: </strong>cs.LG, q-bio.BM</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.17815">https://arxiv.org/abs/2508.17815</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.17815">https://arxiv.org/pdf/2508.17815</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.17815]] Multi-domain Distribution Learning for De Novo Drug Design(https://arxiv.org/abs/2508.17815)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>We introduce DrugFlow, a generative model for structure-based drug design that integrates continuous flow matching with discrete Markov bridges, demonstrating state-of-the-art performance in learning chemical, geometric, and physical aspects of three-dimensional protein-ligand data. We endow DrugFlow with an uncertainty estimate that is able to detect out-of-distribution samples. To further enhance the sampling process towards distribution regions with desirable metric values, we propose a joint preference alignment scheme applicable to both flow matching and Markov bridge frameworks. Furthermore, we extend our model to also explore the conformational landscape of the protein by jointly sampling side chain angles and molecules.</li>
</ul>

<h3>Title: UniSino: Physics-Driven Foundational Model for Universal CT Sinogram Standardization</h3>
<ul>
<li><strong>Authors: </strong>Xingyu Ai, Shaoyu Wang, Zhiyuan Jia, Ao Xu, Hongming Shan, Jianhua Ma, Qiegen Liu</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.17816">https://arxiv.org/abs/2508.17816</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.17816">https://arxiv.org/pdf/2508.17816</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.17816]] UniSino: Physics-Driven Foundational Model for Universal CT Sinogram Standardization(https://arxiv.org/abs/2508.17816)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>During raw-data acquisition in CT imaging, diverse factors can degrade the collected sinograms, with undersampling and noise leading to severe artifacts and noise in reconstructed images and compromising diagnostic accuracy. Conventional correction methods rely on manually designed algorithms or fixed empirical parameters, but these approaches often lack generalizability across heterogeneous artifact types. To address these limitations, we propose UniSino, a foundation model for universal CT sinogram standardization. Unlike existing foundational models that operate in image domain, UniSino directly standardizes data in the projection domain, which enables stronger generalization across diverse undersampling scenarios. Its training framework incorporates the physical characteristics of sinograms, enhancing generalization and enabling robust performance across multiple subtasks spanning four benchmark datasets. Experimental results demonstrate thatUniSino achieves superior reconstruction quality both single and mixed undersampling case, demonstrating exceptional robustness and generalization in sinogram enhancement for CT imaging. The code is available at: this https URL.</li>
</ul>

<h3>Title: Limitations of Normalization in Attention Mechanism</h3>
<ul>
<li><strong>Authors: </strong>Timur Mudarisov, Mikhail Burtsev, Tatiana Petrova, Radu State</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.17821">https://arxiv.org/abs/2508.17821</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.17821">https://arxiv.org/pdf/2508.17821</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.17821]] Limitations of Normalization in Attention Mechanism(https://arxiv.org/abs/2508.17821)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>This paper investigates the limitations of the normalization in attention mechanisms. We begin with a theoretical framework that enables the identification of the model's selective ability and the geometric separation involved in token selection. Our analysis includes explicit bounds on distances and separation criteria for token vectors under softmax scaling. Through experiments with pre-trained GPT-2 model, we empirically validate our theoretical results and analyze key behaviors of the attention mechanism. Notably, we demonstrate that as the number of selected tokens increases, the model's ability to distinguish informative tokens declines, often converging toward a uniform selection pattern. We also show that gradient sensitivity under softmax normalization presents challenges during training, especially at low temperature settings. These findings advance current understanding of softmax-based attention mechanism and motivate the need for more robust normalization and selection strategies in future attention architectures.</li>
</ul>

<h3>Title: Diffusion-Based Data Augmentation for Medical Image Segmentation</h3>
<ul>
<li><strong>Authors: </strong>Maham Nazir, Muhammad Aqeel, Francesco Setti</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.17844">https://arxiv.org/abs/2508.17844</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.17844">https://arxiv.org/pdf/2508.17844</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.17844]] Diffusion-Based Data Augmentation for Medical Image Segmentation(https://arxiv.org/abs/2508.17844)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, segmentation</a></li>
<li><strong>Abstract: </strong>Medical image segmentation models struggle with rare abnormalities due to scarce annotated pathological data. We propose DiffAug a novel framework that combines textguided diffusion-based generation with automatic segmentation validation to address this challenge. Our proposed approach uses latent diffusion models conditioned on medical text descriptions and spatial masks to synthesize abnormalities via inpainting on normal images. Generated samples undergo dynamic quality validation through a latentspace segmentation network that ensures accurate localization while enabling single-step inference. The text prompts, derived from medical literature, guide the generation of diverse abnormality types without requiring manual annotation. Our validation mechanism filters synthetic samples based on spatial accuracy, maintaining quality while operating efficiently through direct latent estimation. Evaluated on three medical imaging benchmarks (CVC-ClinicDB, Kvasir-SEG, REFUGE2), our framework achieves state-of-the-art performance with 8-10% Dice improvements over baselines and reduces false negative rates by up to 28% for challenging cases like small polyps and flat lesions critical for early detection in screening applications.</li>
</ul>

<h3>Title: Group Expectation Policy Optimization for Stable Heterogeneous Reinforcement Learning in LLMs</h3>
<ul>
<li><strong>Authors: </strong>Han Zhang, Ruibin Zheng, Zexuan Yi, Hanyang Peng, Hui Wang, Yue Yu</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.17850">https://arxiv.org/abs/2508.17850</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.17850">https://arxiv.org/pdf/2508.17850</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.17850]] Group Expectation Policy Optimization for Stable Heterogeneous Reinforcement Learning in LLMs(https://arxiv.org/abs/2508.17850)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, large language model</a></li>
<li><strong>Abstract: </strong>As single-center computing approaches power constraints, decentralized training is becoming essential. Reinforcement Learning (RL) post-training enhances Large Language Models (LLMs) but faces challenges in heterogeneous distributed environments due to its tightly-coupled sampling-learning alternation. We propose HeteroRL, an asynchronous RL architecture that decouples rollout sampling from parameter learning, enabling robust deployment across geographically distributed nodes under network delays. We identify that latency-induced KL divergence causes importance sampling failure due to high variance. To address this, we propose Group Expectation Policy Optimization (GEPO), which reduces importance weight variance through a refined sampling mechanism. Theoretically, GEPO achieves exponential variance reduction. Experiments show it maintains superior stability over methods like GRPO, with less than 3% performance degradation under 1800-second delays, demonstrating strong potential for decentralized RL in heterogeneous networks.</li>
</ul>

<h3>Title: Software Unclonable Functions for IoT Devices Identification and Security</h3>
<ul>
<li><strong>Authors: </strong>Saeed Alshehhi</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.17853">https://arxiv.org/abs/2508.17853</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.17853">https://arxiv.org/pdf/2508.17853</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.17853]] Software Unclonable Functions for IoT Devices Identification and Security(https://arxiv.org/abs/2508.17853)</code><input type="text"></li>
<li><strong>Keywords: </strong>security</a></li>
<li><strong>Abstract: </strong>In the evolving landscape of IoT ecosystem, distinguishing between legitimate and compromised devices is a critical challenge. This research investigates the effectiveness of hardware performance counter (HPC)-derived signatures' uniqueness under the umbrella of a concept that we introduced as software unclonable functions (SUFs).</li>
</ul>

<h3>Title: Beyond Demographics: Enhancing Cultural Value Survey Simulation with Multi-Stage Personality-Driven Cognitive Reasoning</h3>
<ul>
<li><strong>Authors: </strong>Haijiang Liu, Qiyuan Li, Chao Gao, Yong Cao, Xiangyu Xu, Xun Wu, Daniel Hershcovich, Jinguang Gu</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.CY</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.17855">https://arxiv.org/abs/2508.17855</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.17855">https://arxiv.org/pdf/2508.17855</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.17855]] Beyond Demographics: Enhancing Cultural Value Survey Simulation with Multi-Stage Personality-Driven Cognitive Reasoning(https://arxiv.org/abs/2508.17855)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability, large language model</a></li>
<li><strong>Abstract: </strong>Introducing MARK, the Multi-stAge Reasoning frameworK for cultural value survey response simulation, designed to enhance the accuracy, steerability, and interpretability of large language models in this task. The system is inspired by the type dynamics theory in the MBTI psychological framework for personality research. It effectively predicts and utilizes human demographic information for simulation: life-situational stress analysis, group-level personality prediction, and self-weighted cognitive imitation. Experiments on the World Values Survey show that MARK outperforms existing baselines by 10% accuracy and reduces the divergence between model predictions and human preferences. This highlights the potential of our framework to improve zero-shot personalization and help social scientists interpret model predictions.</li>
</ul>

<h3>Title: MalLoc: Toward Fine-grained Android Malicious Payload Localization via LLMs</h3>
<ul>
<li><strong>Authors: </strong>Tiezhu Sun, Marco Alecci, Aleksandr Pilgun, Yewei Song, Xunzhu Tang, Jordan Samhi, Tegawend√© F. Bissyand√©, Jacques Klein</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.SE</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.17856">https://arxiv.org/abs/2508.17856</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.17856">https://arxiv.org/pdf/2508.17856</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.17856]] MalLoc: Toward Fine-grained Android Malicious Payload Localization via LLMs(https://arxiv.org/abs/2508.17856)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, interpretability, large language model</a></li>
<li><strong>Abstract: </strong>The rapid evolution of Android malware poses significant challenges to the maintenance and security of mobile applications (apps). Traditional detection techniques often struggle to keep pace with emerging malware variants that employ advanced tactics such as code obfuscation and dynamic behavior triggering. One major limitation of these approaches is their inability to localize malicious payloads at a fine-grained level, hindering precise understanding of malicious behavior. This gap in understanding makes the design of effective and targeted mitigation strategies difficult, leaving mobile apps vulnerable to continuously evolving threats. To address this gap, we propose MalLoc, a novel approach that leverages the code understanding capabilities of large language models (LLMs) to localize malicious payloads at a fine-grained level within Android malware. Our experimental results demonstrate the feasibility and effectiveness of using LLMs for this task, highlighting the potential of MalLoc to enhance precision and interpretability in malware analysis. This work advances beyond traditional detection and classification by enabling deeper insights into behavior-level malicious logic and opens new directions for research, including dynamic modeling of localized threats and targeted countermeasure development.</li>
</ul>

<h3>Title: VISA: Group-wise Visual Token Selection and Aggregation via Graph Summarization for Efficient MLLMs Inference</h3>
<ul>
<li><strong>Authors: </strong>Pengfei Jiang, Hanjun Li, Linglan Zhao, Fei Chao, Ke Yan, Shouhong Ding, Rongrong Ji</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.17857">https://arxiv.org/abs/2508.17857</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.17857">https://arxiv.org/pdf/2508.17857</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.17857]] VISA: Group-wise Visual Token Selection and Aggregation via Graph Summarization for Efficient MLLMs Inference(https://arxiv.org/abs/2508.17857)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction, large language model</a></li>
<li><strong>Abstract: </strong>In this study, we introduce a novel method called group-wise \textbf{VI}sual token \textbf{S}election and \textbf{A}ggregation (VISA) to address the issue of inefficient inference stemming from excessive visual tokens in multimoal large language models (MLLMs). Compared with previous token pruning approaches, our method can preserve more visual information while compressing visual tokens. We first propose a graph-based visual token aggregation (VTA) module. VTA treats each visual token as a node, forming a graph based on semantic similarity among visual tokens. It then aggregates information from removed tokens into kept tokens based on this graph, producing a more compact visual token representation. Additionally, we introduce a group-wise token selection strategy (GTS) to divide visual tokens into kept and removed ones, guided by text tokens from the final layers of each group. This strategy progressively aggregates visual information, enhancing the stability of the visual information extraction process. We conduct comprehensive experiments on LLaVA-1.5, LLaVA-NeXT, and Video-LLaVA across various benchmarks to validate the efficacy of VISA. Our method consistently outperforms previous methods, achieving a superior trade-off between model performance and inference speed. The code is available at this https URL.</li>
</ul>

<h3>Title: AVAM: Universal Training-free Adaptive Visual Anchoring Embedded into Multimodal Large Language Model for Multi-image Question Answering</h3>
<ul>
<li><strong>Authors: </strong>Kang Zeng, Guojin Zhong, Jintao Cheng, Jin Yuan, Zhiyong Li</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.17860">https://arxiv.org/abs/2508.17860</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.17860">https://arxiv.org/pdf/2508.17860</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.17860]] AVAM: Universal Training-free Adaptive Visual Anchoring Embedded into Multimodal Large Language Model for Multi-image Question Answering(https://arxiv.org/abs/2508.17860)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>The advancement of Multimodal Large Language Models (MLLMs) has driven significant progress in Visual Question Answering (VQA), evolving from Single to Multi Image VQA (MVQA). However, the increased number of images in MVQA inevitably introduces substantial visual redundancy that is irrelevant to question answering, negatively impacting both accuracy and efficiency. To address this issue, existing methods lack flexibility in controlling the number of compressed visual tokens and tend to produce discrete visual fragments, which hinder MLLMs' ability to comprehend images holistically. In this paper, we propose a straightforward yet universal Adaptive Visual Anchoring strategy, which can be seamlessly integrated into existing MLLMs, offering significant accuracy improvements through adaptive compression. Meanwhile, to balance the results derived from both global and compressed visual input, we further introduce a novel collaborative decoding mechanism, enabling optimal performance. Extensive experiments validate the effectiveness of our method, demonstrating consistent performance improvements across various MLLMs. The code will be publicly available.</li>
</ul>

<h3>Title: Speech Discrete Tokens or Continuous Features? A Comparative Analysis for Spoken Language Understanding in SpeechLLMs</h3>
<ul>
<li><strong>Authors: </strong>Dingdong Wang, Junan Li, Mingyu Cui, Dongchao Yang, Xueyuan Chen, Helen Meng</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.SD</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.17863">https://arxiv.org/abs/2508.17863</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.17863">https://arxiv.org/pdf/2508.17863</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.17863]] Speech Discrete Tokens or Continuous Features? A Comparative Analysis for Spoken Language Understanding in SpeechLLMs(https://arxiv.org/abs/2508.17863)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, fair, large language model</a></li>
<li><strong>Abstract: </strong>With the rise of Speech Large Language Models (SpeechLLMs), two dominant approaches have emerged for speech processing: discrete tokens and continuous features. Each approach has demonstrated strong capabilities in audio-related processing tasks. However, the performance gap between these two paradigms has not been thoroughly explored. To address this gap, we present a fair comparison of self-supervised learning (SSL)-based discrete and continuous features under the same experimental settings. We evaluate their performance across six spoken language understanding-related tasks using both small and large-scale LLMs (Qwen1.5-0.5B and Llama3.1-8B). We further conduct in-depth analyses, including efficient comparison, SSL layer analysis, LLM layer analysis, and robustness comparison. Our findings reveal that continuous features generally outperform discrete tokens in various tasks. Each speech processing method exhibits distinct characteristics and patterns in how it learns and processes speech information. We hope our results will provide valuable insights to advance spoken language understanding in SpeechLLMs.</li>
</ul>

<h3>Title: Ada-TransGNN: An Air Quality Prediction Model Based On Adaptive Graph Convolutional Networks</h3>
<ul>
<li><strong>Authors: </strong>Dan Wang, Feng Jiang, Zhanquan Wang</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.17867">https://arxiv.org/abs/2508.17867</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.17867">https://arxiv.org/pdf/2508.17867</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.17867]] Ada-TransGNN: An Air Quality Prediction Model Based On Adaptive Graph Convolutional Networks(https://arxiv.org/abs/2508.17867)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Accurate air quality prediction is becoming increasingly important in the environmental field. To address issues such as low prediction accuracy and slow real-time updates in existing models, which lead to lagging prediction results, we propose a Transformer-based spatiotemporal data prediction method (Ada-TransGNN) that integrates global spatial semantics and temporal behavior. The model constructs an efficient and collaborative spatiotemporal block set comprising a multi-head attention mechanism and a graph convolutional network to extract dynamically changing spatiotemporal dependency features from complex air quality monitoring data. Considering the interaction relationships between different monitoring points, we propose an adaptive graph structure learning module, which combines spatiotemporal dependency features in a data-driven manner to learn the optimal graph structure, thereby more accurately capturing the spatial relationships between monitoring points. Additionally, we design an auxiliary task learning module that enhances the decoding capability of temporal relationships by integrating spatial context information into the optimal graph structure representation, effectively improving the accuracy of prediction results. We conducted comprehensive evaluations on a benchmark dataset and a novel dataset (Mete-air). The results demonstrate that our model outperforms existing state-of-the-art prediction models in short-term and long-term predictions.</li>
</ul>

<h3>Title: Edge-Enhanced Vision Transformer Framework for Accurate AI-Generated Image Detection</h3>
<ul>
<li><strong>Authors: </strong>Dabbrata Das, Mahshar Yahan, Md Tareq Zaman, Md Rishadul Bayesh</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.17877">https://arxiv.org/abs/2508.17877</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.17877">https://arxiv.org/pdf/2508.17877</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.17877]] Edge-Enhanced Vision Transformer Framework for Accurate AI-Generated Image Detection(https://arxiv.org/abs/2508.17877)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer, generative</a></li>
<li><strong>Abstract: </strong>The rapid advancement of generative models has led to a growing prevalence of highly realistic AI-generated images, posing significant challenges for digital forensics and content authentication. Conventional detection methods mainly rely on deep learning models that extract global features, which often overlook subtle structural inconsistencies and demand substantial computational resources. To address these limitations, we propose a hybrid detection framework that combines a fine-tuned Vision Transformer (ViT) with a novel edge-based image processing module. The edge-based module computes variance from edge-difference maps generated before and after smoothing, exploiting the observation that AI-generated images typically exhibit smoother textures, weaker edges, and reduced noise compared to real images. When applied as a post-processing step on ViT predictions, this module enhances sensitivity to fine-grained structural cues while maintaining computational efficiency. Extensive experiments on the CIFAKE, Artistic, and Custom Curated datasets demonstrate that the proposed framework achieves superior detection performance across all benchmarks, attaining 97.75% accuracy and a 97.77% F1-score on CIFAKE, surpassing widely adopted state-of-the-art models. These results establish the proposed method as a lightweight, interpretable, and effective solution for both still images and video frames, making it highly suitable for real-world applications in automated content verification and digital forensics.</li>
</ul>

<h3>Title: PhantomLint: Principled Detection of Hidden LLM Prompts in Structured Documents</h3>
<ul>
<li><strong>Authors: </strong>Toby Murray</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.17884">https://arxiv.org/abs/2508.17884</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.17884">https://arxiv.org/pdf/2508.17884</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.17884]] PhantomLint: Principled Detection of Hidden LLM Prompts in Structured Documents(https://arxiv.org/abs/2508.17884)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack</a></li>
<li><strong>Abstract: </strong>Hidden LLM prompts have appeared in online documents with increasing frequency. Their goal is to trigger indirect prompt injection attacks while remaining undetected from human oversight, to manipulate LLM-powered automated document processing systems, against applications as diverse as r√©sum√© screeners through to academic peer review processes. Detecting hidden LLM prompts is therefore important for ensuring trust in AI-assisted human decision making. This paper presents the first principled approach to hidden LLM prompt detection in structured documents. We implement our approach in a prototype tool called PhantomLint. We evaluate PhantomLint against a corpus of 3,402 documents, including both PDF and HTML documents, and covering academic paper preprints, CVs, theses and more. We find that our approach is generally applicable against a wide range of methods for hiding LLM prompts from visual inspection, has a very low false positive rate (approx. 0.092%), is practically useful for detecting hidden LLM prompts in real documents, while achieving acceptable performance.</li>
</ul>

<h3>Title: ISALux: Illumination and Segmentation Aware Transformer Employing Mixture of Experts for Low Light Image Enhancement</h3>
<ul>
<li><strong>Authors: </strong>Raul Balmez, Alexandru Brateanu, Ciprian Orhei, Codruta Ancuti, Cosmin Ancuti</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.17885">https://arxiv.org/abs/2508.17885</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.17885">https://arxiv.org/pdf/2508.17885</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.17885]] ISALux: Illumination and Segmentation Aware Transformer Employing Mixture of Experts for Low Light Image Enhancement(https://arxiv.org/abs/2508.17885)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction, transformer, segmentation</a></li>
<li><strong>Abstract: </strong>We introduce ISALux, a novel transformer-based approach for Low-Light Image Enhancement (LLIE) that seamlessly integrates illumination and semantic priors. Our architecture includes an original self-attention block, Hybrid Illumination and Semantics-Aware Multi-Headed Self- Attention (HISA-MSA), which integrates illumination and semantic segmentation maps for en- hanced feature extraction. ISALux employs two self-attention modules to independently process illumination and semantic features, selectively enriching each other to regulate luminance and high- light structural variations in real-world scenarios. A Mixture of Experts (MoE)-based Feed-Forward Network (FFN) enhances contextual learning, with a gating mechanism conditionally activating the top K experts for specialized processing. To address overfitting in LLIE methods caused by distinct light patterns in benchmarking datasets, we enhance the HISA-MSA module with low-rank matrix adaptations (LoRA). Extensive qualitative and quantitative evaluations across multiple specialized datasets demonstrate that ISALux is competitive with state-of-the-art (SOTA) methods. Addition- ally, an ablation study highlights the contribution of each component in the proposed model. Code will be released upon publication.</li>
</ul>

<h3>Title: UniAPO: Unified Multimodal Automated Prompt Optimization</h3>
<ul>
<li><strong>Authors: </strong>Qipeng Zhu, Yanzhe Chen, Huasong Zhong, Yan Li, Jie Chen, Zhixin Zhang, Junping Zhang, Zhenheng Yang</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.17890">https://arxiv.org/abs/2508.17890</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.17890">https://arxiv.org/pdf/2508.17890</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.17890]] UniAPO: Unified Multimodal Automated Prompt Optimization(https://arxiv.org/abs/2508.17890)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Prompting is fundamental to unlocking the full potential of large language models. To automate and enhance this process, automatic prompt optimization (APO) has been developed, demonstrating effectiveness primarily in text-only input scenarios. However, extending existing APO methods to multimodal tasks, such as video-language generation introduces two core challenges: (i) visual token inflation, where long visual token sequences restrict context capacity and result in insufficient feedback signals; (ii) a lack of process-level supervision, as existing methods focus on outcome-level supervision and overlook intermediate supervision, limiting prompt optimization. We present UniAPO: Unified Multimodal Automated Prompt Optimization, the first framework tailored for multimodal APO. UniAPO adopts an EM-inspired optimization process that decouples feedback modeling and prompt refinement, making the optimization more stable and goal-driven. To further address the aforementioned challenges, we introduce a short-long term memory mechanism: historical feedback mitigates context limitations, while historical prompts provide directional guidance for effective prompt optimization. UniAPO achieves consistent gains across text, image, and video benchmarks, establishing a unified framework for efficient and transferable prompt optimization.</li>
</ul>

<h3>Title: ILRe: Intermediate Layer Retrieval for Context Compression in Causal Language Models</h3>
<ul>
<li><strong>Authors: </strong>Manlai Liang, Mandi Liu, Jiangzhou Ji, Huaijun Li, Haobo Yang, Yaohan He, Jinlong Li</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.17892">https://arxiv.org/abs/2508.17892</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.17892">https://arxiv.org/pdf/2508.17892</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.17892]] ILRe: Intermediate Layer Retrieval for Context Compression in Causal Language Models(https://arxiv.org/abs/2508.17892)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large Language Models (LLMs) have demonstrated success across many benchmarks. However, they still exhibit limitations in long-context scenarios, primarily due to their short effective context length, quadratic computational complexity, and high memory overhead when processing lengthy inputs. To mitigate these issues, we introduce a novel context compression pipeline, called Intermediate Layer Retrieval (ILRe), which determines one intermediate decoder layer offline, encodes context by streaming chunked prefill only up to that layer, and recalls tokens by the attention scores between the input query and full key cache in that specified layer. In particular, we propose a multi-pooling kernels allocating strategy in the token recalling process to maintain the completeness of semantics. Our approach not only reduces the prefilling complexity from $O(L^2)$ to $O(L)$, but also achieves performance comparable to or better than the full context in the long context scenarios. Without additional post training or operator development, ILRe can process a single $1M$ tokens request in less than half a minute (speedup $\approx 180\times$) and scores RULER-$1M$ benchmark of $\approx 79.8$ with model Llama-3.1-UltraLong-8B-1M-Instruct on a Huawei Ascend 910B NPU.</li>
</ul>

<h3>Title: Designing Practical Models for Isolated Word Visual Speech Recognition</h3>
<ul>
<li><strong>Authors: </strong>Iason Ioannis Panagos, Giorgos Sfikas, Christophoros Nikou</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.17894">https://arxiv.org/abs/2508.17894</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.17894">https://arxiv.org/pdf/2508.17894</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.17894]] Designing Practical Models for Isolated Word Visual Speech Recognition(https://arxiv.org/abs/2508.17894)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction</a></li>
<li><strong>Abstract: </strong>Visual speech recognition (VSR) systems decode spoken words from an input sequence using only the video data. Practical applications of such systems include medical assistance as well as human-machine interactions. A VSR system is typically employed in a complementary role in cases where the audio is corrupt or not available. In order to accurately predict the spoken words, these architectures often rely on deep neural networks in order to extract meaningful representations from the input sequence. While deep architectures achieve impressive recognition performance, relying on such models incurs significant computation costs which translates into increased resource demands in terms of hardware requirements and results in limited applicability in real-world scenarios where resources might be constrained. This factor prevents wider adoption and deployment of speech recognition systems in more practical applications. In this work, we aim to alleviate this issue by developing architectures for VSR that have low hardware costs. Following the standard two-network design paradigm, where one network handles visual feature extraction and another one utilizes the extracted features to classify the entire sequence, we develop lightweight end-to-end architectures by first benchmarking efficient models from the image classification literature, and then adopting lightweight block designs in a temporal convolution network backbone. We create several unified models with low resource requirements but strong recognition performance. Experiments on the largest public database for English words demonstrate the effectiveness and practicality of our developed models. Code and trained models will be made publicly available.</li>
</ul>

<h3>Title: Riemannian Optimization for LoRA on the Stiefel Manifold</h3>
<ul>
<li><strong>Authors: </strong>Juneyoung Park, Minjae Kang, Seongbae Lee, Haegang Lee, Seongwan Kim, Jaeho Lee</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.17901">https://arxiv.org/abs/2508.17901</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.17901">https://arxiv.org/pdf/2508.17901</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.17901]] Riemannian Optimization for LoRA on the Stiefel Manifold(https://arxiv.org/abs/2508.17901)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>While powerful, large language models (LLMs) present significant fine-tuning challenges due to their size. Parameter-efficient fine-tuning (PEFT) methods like LoRA provide solutions, yet suffer from critical optimizer inefficiencies; notably basis redundancy in LoRA's $B$ matrix when using AdamW, which fundamentally limits performance. We address this by optimizing the $B$ matrix on the Stiefel manifold, imposing explicit orthogonality constraints that achieve near-perfect orthogonality and full effective rank. This geometric approach dramatically enhances parameter efficiency and representational capacity. Our Stiefel optimizer consistently outperforms AdamW across benchmarks with both LoRA and DoRA, demonstrating that geometric constraints are the key to unlocking LoRA's full potential for effective LLM fine-tuning.</li>
</ul>

<h3>Title: PRZK-Bind: A Physically Rooted Zero-Knowledge Authentication Protocol for Secure Digital Twin Binding in Smart Cities</h3>
<ul>
<li><strong>Authors: </strong>Yagmur Yigit, Mehmet Ali Erturk, Kerem Gursu, Berk Canberk</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.ET, cs.NI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.17913">https://arxiv.org/abs/2508.17913</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.17913">https://arxiv.org/pdf/2508.17913</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.17913]] PRZK-Bind: A Physically Rooted Zero-Knowledge Authentication Protocol for Secure Digital Twin Binding in Smart Cities(https://arxiv.org/abs/2508.17913)</code><input type="text"></li>
<li><strong>Keywords: </strong>secure</a></li>
<li><strong>Abstract: </strong>Digital twin (DT) technology is rapidly becoming essential for smart city ecosystems, enabling real-time synchronisation and autonomous decision-making across physical and digital domains. However, as DTs take active roles in control loops, securely binding them to their physical counterparts in dynamic and adversarial environments remains a significant challenge. Existing authentication solutions either rely on static trust models, require centralised authorities, or fail to provide live and verifiable physical-digital binding, making them unsuitable for latency-sensitive and distributed deployments. To address this gap, we introduce PRZK-Bind, a lightweight and decentralised authentication protocol that combines Schnorr-based zero-knowledge proofs with elliptic curve cryptography to establish secure, real-time correspondence between physical entities and DTs without relying on pre-shared secrets. Simulation results show that PRZK-Bind significantly improves performance, offering up to 4.5 times lower latency and 4 times reduced energy consumption compared to cryptography-heavy baselines, while maintaining false acceptance rates more than 10 times lower. These findings highlight its suitability for future smart city deployments requiring efficient, resilient, and trustworthy DT authentication.</li>
</ul>

<h3>Title: Evaluating the Representation of Vowels in Wav2Vec Feature Extractor: A Layer-Wise Analysis Using MFCCs</h3>
<ul>
<li><strong>Authors: </strong>Domenico De Cristofaro, Vincenzo Norman Vitale, Alessandro Vietti</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.17914">https://arxiv.org/abs/2508.17914</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.17914">https://arxiv.org/pdf/2508.17914</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.17914]] Evaluating the Representation of Vowels in Wav2Vec Feature Extractor: A Layer-Wise Analysis Using MFCCs(https://arxiv.org/abs/2508.17914)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction, transformer</a></li>
<li><strong>Abstract: </strong>Automatic Speech Recognition has advanced with self-supervised learning, enabling feature extraction directly from raw audio. In Wav2Vec, a CNN first transforms audio into feature vectors before the transformer processes them. This study examines CNN-extracted information for monophthong vowels using the TIMIT corpus. We compare MFCCs, MFCCs with formants, and CNN activations by training SVM classifiers for front-back vowel identification, assessing their classification accuracy to evaluate phonetic representation.</li>
</ul>

<h3>Title: Gaze into the Heart: A Multi-View Video Dataset for rPPG and Health Biomarkers Estimation</h3>
<ul>
<li><strong>Authors: </strong>Konstantin Egorov, Stepan Botman, Pavel Blinov, Galina Zubkova, Anton Ivaschenko, Alexander Kolsanov, Andrey Savchenko</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.17924">https://arxiv.org/abs/2508.17924</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.17924">https://arxiv.org/pdf/2508.17924</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.17924]] Gaze into the Heart: A Multi-View Video Dataset for rPPG and Health Biomarkers Estimation(https://arxiv.org/abs/2508.17924)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy</a></li>
<li><strong>Abstract: </strong>Progress in remote PhotoPlethysmoGraphy (rPPG) is limited by the critical issues of existing publicly available datasets: small size, privacy concerns with facial videos, and lack of diversity in conditions. The paper introduces a novel comprehensive large-scale multi-view video dataset for rPPG and health biomarkers estimation. Our dataset comprises 3600 synchronized video recordings from 600 subjects, captured under varied conditions (resting and post-exercise) using multiple consumer-grade cameras at different angles. To enable multimodal analysis of physiological states, each recording is paired with a 100 Hz PPG signal and extended health metrics, such as electrocardiogram, arterial blood pressure, biomarkers, temperature, oxygen saturation, respiratory rate, and stress level. Using this data, we train an efficient rPPG model and compare its quality with existing approaches in cross-dataset scenarios. The public release of our dataset and model should significantly speed up the progress in the development of AI medical assistants.</li>
</ul>

<h3>Title: AMELIA: A Family of Multi-task End-to-end Language Models for Argumentation</h3>
<ul>
<li><strong>Authors: </strong>Henri Savigny, Bruno Yun</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.17926">https://arxiv.org/abs/2508.17926</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.17926">https://arxiv.org/pdf/2508.17926</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.17926]] AMELIA: A Family of Multi-task End-to-end Language Models for Argumentation(https://arxiv.org/abs/2508.17926)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Argument mining is a subfield of argumentation that aims to automatically extract argumentative structures and their relations from natural language texts. This paper investigates how a single large language model can be leveraged to perform one or several argument mining tasks. Our contributions are two-fold. First, we construct a multi-task dataset by surveying and converting 19 well-known argument mining datasets from the literature into a unified format. Second, we explore various training strategies using Meta AI's Llama-3.1-8B-Instruct model: (1) fine-tuning on individual tasks, (2) fine-tuning jointly on multiple tasks, and (3) merging models fine-tuned separately on individual tasks. Our experiments show that task-specific fine-tuning significantly improves individual performance across all tasks. Moreover, multi-task fine-tuning maintains strong performance without degradation, suggesting effective transfer learning across related tasks. Finally, we demonstrate that model merging offers a viable compromise: it yields competitive performance while mitigating the computational costs associated with full multi-task fine-tuning.</li>
</ul>

<h3>Title: Learning to Detect Label Errors by Making Them: A Method for Segmentation and Object Detection Datasets</h3>
<ul>
<li><strong>Authors: </strong>Sarina Penquitt, Tobias Riedlinger, Timo Heller, Markus Reischl, Matthias Rottmann</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.17930">https://arxiv.org/abs/2508.17930</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.17930">https://arxiv.org/pdf/2508.17930</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.17930]] Learning to Detect Label Errors by Making Them: A Method for Segmentation and Object Detection Datasets(https://arxiv.org/abs/2508.17930)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>Recently, detection of label errors and improvement of label quality in datasets for supervised learning tasks has become an increasingly important goal in both research and industry. The consequences of incorrectly annotated data include reduced model performance, biased benchmark results, and lower overall accuracy. Current state-of-the-art label error detection methods often focus on a single computer vision task and, consequently, a specific type of dataset, containing, for example, either bounding boxes or pixel-wise annotations. Furthermore, previous methods are not learning-based. In this work, we overcome this research gap. We present a unified method for detecting label errors in object detection, semantic segmentation, and instance segmentation datasets. In a nutshell, our approach - learning to detect label errors by making them - works as follows: we inject different kinds of label errors into the ground truth. Then, the detection of label errors, across all mentioned primary tasks, is framed as an instance segmentation problem based on a composite input. In our experiments, we compare the label error detection performance of our method with various baselines and state-of-the-art approaches of each task's domain on simulated label errors across multiple tasks, datasets, and base models. This is complemented by a generalization study on real-world label errors. Additionally, we release 459 real label errors identified in the Cityscapes dataset and provide a benchmark for real label error detection in Cityscapes.</li>
</ul>

<h3>Title: See What You Need: Query-Aware Visual Intelligence through Reasoning-Perception Loops</h3>
<ul>
<li><strong>Authors: </strong>Zixuan Dong, Baoyun Peng, Yufei Wang, Lin Liu, Xinxin Dong, Yunlong Cao, Xiaodong Wang</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.17932">https://arxiv.org/abs/2508.17932</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.17932">https://arxiv.org/pdf/2508.17932</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.17932]] See What You Need: Query-Aware Visual Intelligence through Reasoning-Perception Loops(https://arxiv.org/abs/2508.17932)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction</a></li>
<li><strong>Abstract: </strong>Human video comprehension demonstrates dynamic coordination between reasoning and visual attention, adaptively focusing on query-relevant details. However, current long-form video question answering systems employ rigid pipelines that decouple reasoning from perception, leading to either information loss through premature visual abstraction or computational inefficiency through exhaustive processing. The core limitation lies in the inability to adapt visual extraction to specific reasoning requirements, different queries demand fundamentally different visual evidence from the same video content. In this work, we present CAVIA, a training-free framework that revolutionizes video understanding through reasoning, perception coordination. Unlike conventional approaches where visual processing operates independently of reasoning, CAVIA creates a closed-loop system where reasoning continuously guides visual extraction based on identified information gaps. CAVIA introduces three innovations: (1) hierarchical reasoning, guided localization to precise frames; (2) cross-modal semantic bridging for targeted extraction; (3) confidence-driven iterative synthesis. CAVIA achieves state-of-the-art performance on challenging benchmarks: EgoSchema (65.7%, +5.3%), NExT-QA (76.1%, +2.6%), and IntentQA (73.8%, +6.9%), demonstrating that dynamic reasoning-perception coordination provides a scalable paradigm for video understanding.</li>
</ul>

<h3>Title: Debiasing Multilingual LLMs in Cross-lingual Latent Space</h3>
<ul>
<li><strong>Authors: </strong>Qiwei Peng, Guimin Hu, Yekun Chai, Anders S√∏gaard</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.17948">https://arxiv.org/abs/2508.17948</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.17948">https://arxiv.org/pdf/2508.17948</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.17948]] Debiasing Multilingual LLMs in Cross-lingual Latent Space(https://arxiv.org/abs/2508.17948)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Debiasing techniques such as SentDebias aim to reduce bias in large language models (LLMs). Previous studies have evaluated their cross-lingual transferability by directly applying these methods to LLM representations, revealing their limited effectiveness across languages. In this work, we therefore propose to perform debiasing in a joint latent space rather than directly on LLM representations. We construct a well-aligned cross-lingual latent space using an autoencoder trained on parallel TED talk scripts. Our experiments with Aya-expanse and two debiasing techniques across four languages (English, French, German, Dutch) demonstrate that a) autoencoders effectively construct a well-aligned cross-lingual latent space, and b) applying debiasing techniques in the learned cross-lingual latent space significantly improves both the overall debiasing performance and cross-lingual transferability.</li>
</ul>

<h3>Title: Understanding Subword Compositionality of Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Qiwei Peng, Yekun Chai, Anders S√∏gaard</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.17953">https://arxiv.org/abs/2508.17953</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.17953">https://arxiv.org/pdf/2508.17953</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.17953]] Understanding Subword Compositionality of Large Language Models(https://arxiv.org/abs/2508.17953)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large language models (LLMs) take sequences of subwords as input, requiring them to effective compose subword representations into meaningful word-level representations. In this paper, we present a comprehensive set of experiments to probe how LLMs compose subword information, focusing on three key aspects: structural similarity, semantic decomposability, and form retention. Our analysis of the experiments suggests that these five LLM families can be classified into three distinct groups, likely reflecting difference in their underlying composition strategies. Specifically, we observe (i) three distinct patterns in the evolution of structural similarity between subword compositions and whole-word representations across layers; (ii) great performance when probing layer by layer their sensitivity to semantic decompositionality; and (iii) three distinct patterns when probing sensitivity to formal features, e.g., character sequence length. These findings provide valuable insights into the compositional dynamics of LLMs and highlight different compositional pattens in how LLMs encode and integrate subword information.</li>
</ul>

<h3>Title: Choice Outweighs Effort: Facilitating Complementary Knowledge Fusion in Federated Learning via Re-calibration and Merit-discrimination</h3>
<ul>
<li><strong>Authors: </strong>Ming Yang, Dongrun Li, Xin Wang, Xiaoyang Yu, Xiaoming Wu, Shibo He</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.17954">https://arxiv.org/abs/2508.17954</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.17954">https://arxiv.org/pdf/2508.17954</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.17954]] Choice Outweighs Effort: Facilitating Complementary Knowledge Fusion in Federated Learning via Re-calibration and Merit-discrimination(https://arxiv.org/abs/2508.17954)</code><input type="text"></li>
<li><strong>Keywords: </strong>federate, segmentation</a></li>
<li><strong>Abstract: </strong>Cross-client data heterogeneity in federated learning induces biases that impede unbiased consensus condensation and the complementary fusion of generalization- and personalization-oriented knowledge. While existing approaches mitigate heterogeneity through model decoupling and representation center loss, they often rely on static and restricted metrics to evaluate local knowledge and adopt global alignment too rigidly, leading to consensus distortion and diminished model adaptability. To address these limitations, we propose FedMate, a method that implements bilateral optimization: On the server side, we construct a dynamic global prototype, with aggregation weights calibrated by holistic integration of sample size, current parameters, and future prediction; a category-wise classifier is then fine-tuned using this prototype to preserve global consistency. On the client side, we introduce complementary classification fusion to enable merit-based discrimination training and incorporate cost-aware feature transmission to balance model performance and communication efficiency. Experiments on five datasets of varying complexity demonstrate that FedMate outperforms state-of-the-art methods in harmonizing generalization and adaptation. Additionally, semantic segmentation experiments on autonomous driving datasets validate the method's real-world scalability.</li>
</ul>

<h3>Title: Generative Feature Imputing - A Technique for Error-resilient Semantic Communication</h3>
<ul>
<li><strong>Authors: </strong>Jianhao Huang, Qunsong Zeng, Hongyang Du, Kaibin Huang</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.17957">https://arxiv.org/abs/2508.17957</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.17957">https://arxiv.org/pdf/2508.17957</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.17957]] Generative Feature Imputing - A Technique for Error-resilient Semantic Communication(https://arxiv.org/abs/2508.17957)</code><input type="text"></li>
<li><strong>Keywords: </strong>protect, robust, diffusion, generative</a></li>
<li><strong>Abstract: </strong>Semantic communication (SemCom) has emerged as a promising paradigm for achieving unprecedented communication efficiency in sixth-generation (6G) networks by leveraging artificial intelligence (AI) to extract and transmit the underlying meanings of source data. However, deploying SemCom over digital systems presents new challenges, particularly in ensuring robustness against transmission errors that may distort semantically critical content. To address this issue, this paper proposes a novel framework, termed generative feature imputing, which comprises three key techniques. First, we introduce a spatial error concentration packetization strategy that spatially concentrates feature distortions by encoding feature elements based on their channel mappings, a property crucial for both the effectiveness and reduced complexity of the subsequent techniques. Second, building on this strategy, we propose a generative feature imputing method that utilizes a diffusion model to efficiently reconstruct missing features caused by packet losses. Finally, we develop a semantic-aware power allocation scheme that enables unequal error protection by allocating transmission power according to the semantic importance of each packet. Experimental results demonstrate that the proposed framework outperforms conventional approaches, such as Deep Joint Source-Channel Coding (DJSCC) and JPEG2000, under block fading conditions, achieving higher semantic accuracy and lower Learned Perceptual Image Patch Similarity (LPIPS) scores.</li>
</ul>

<h3>Title: MoveScanner: Analysis of Security Risks of Move Smart Contracts</h3>
<ul>
<li><strong>Authors: </strong>Yuhe Lu, Zhongwen Li, Xiaoqi Li</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.17964">https://arxiv.org/abs/2508.17964</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.17964">https://arxiv.org/pdf/2508.17964</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.17964]] MoveScanner: Analysis of Security Risks of Move Smart Contracts(https://arxiv.org/abs/2508.17964)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, protect</a></li>
<li><strong>Abstract: </strong>As blockchain technology continues to evolve, the security of smart contracts has increasingly drawn attention from both academia and industry. The Move language, with its unique resource model and linear type system, provides a solid foundation for the security of digital assets. However, smart contracts still face new security challenges due to developer programming errors and the potential risks associated with cross-module interactions. This paper systematically analyzes the limitations of existing security tools within the Move ecosystem and reveals their unique vulnerability patterns. To address these issues, it introduces MoveScanner, a static analysis tool based on a control flow graph and data flow analysis architecture. By incorporating cross-module call graph tracking, MoveScanner can effectively identify five key types of security vulnerabilities, including resource leaks, weak permission management, and arithmetic overflows. In terms of design, MoveScanner adheres to a modular principle, supports bytecode-level analysis and multi-chain adaptation, and introduces innovative resource trajectory tracking algorithms and capability matrix analysis methods, thereby significantly reducing the false positive rate. Empirical results show that MoveScanner achieved 88.2% detection accuracy in benchmark testing, filling the gap in security tools in the Move ecosystem. Furthermore, this paper identifies twelve new types of security risks based on the resource-oriented programming paradigm and provides a theoretical foundation and practical experience for the development of smart contract security mechanisms. Future work will focus on combining formal verification and dynamic analysis techniques to build a security protection framework covering the entire contract lifecycle</li>
</ul>

<h3>Title: SAIL-Recon: Large SfM by Augmenting Scene Regression with Localization</h3>
<ul>
<li><strong>Authors: </strong>Junyuan Deng, Heng Li, Tao Xie, Weiqiang Ren, Qian Zhang, Ping Tan, Xiaoyang Guo</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.17972">https://arxiv.org/abs/2508.17972</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.17972">https://arxiv.org/pdf/2508.17972</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.17972]] SAIL-Recon: Large SfM by Augmenting Scene Regression with Localization(https://arxiv.org/abs/2508.17972)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Scene regression methods, such as VGGT, solve the Structure-from-Motion (SfM) problem by directly regressing camera poses and 3D scene structures from input images. They demonstrate impressive performance in handling images under extreme viewpoint changes. However, these methods struggle to handle a large number of input images. To address this problem, we introduce SAIL-Recon, a feed-forward Transformer for large scale SfM, by augmenting the scene regression network with visual localization capabilities. Specifically, our method first computes a neural scene representation from a subset of anchor images. The regression network is then fine-tuned to reconstruct all input images conditioned on this neural scene representation. Comprehensive experiments show that our method not only scales efficiently to large-scale scenes, but also achieves state-of-the-art results on both camera pose estimation and novel view synthesis benchmarks, including TUM-RGBD, CO3Dv2, and Tanks & Temples. We will publish our model and code. Code and models are publicly available at: this https URL sail-recon/.</li>
</ul>

<h3>Title: Enhanced Drift-Aware Computer Vision Architecture for Autonomous Driving</h3>
<ul>
<li><strong>Authors: </strong>Md Shahi Amran Hossain, Abu Shad Ahammed, Sayeri Mukherjee, Roman Obermaisser</a></li>
<li><strong>Subjects: </strong>cs.CV, math.LO</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.17975">https://arxiv.org/abs/2508.17975</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.17975">https://arxiv.org/pdf/2508.17975</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.17975]] Enhanced Drift-Aware Computer Vision Architecture for Autonomous Driving(https://arxiv.org/abs/2508.17975)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, robust</a></li>
<li><strong>Abstract: </strong>The use of computer vision in automotive is a trending research in which safety and security are a primary concern. In particular, for autonomous driving, preventing road accidents requires highly accurate object detection under diverse conditions. To address this issue, recently the International Organization for Standardization (ISO) released the 8800 norm, providing structured frameworks for managing associated AI relevant risks. However, challenging scenarios such as adverse weather or low lighting often introduce data drift, leading to degraded model performance and potential safety violations. In this work, we present a novel hybrid computer vision architecture trained with thousands of synthetic image data from the road environment to improve robustness in unseen drifted environments. Our dual mode framework utilized YOLO version 8 for swift detection and incorporated a five-layer CNN for verification. The system functioned in sequence and improved the detection accuracy by more than 90\% when tested with drift-augmented road images. The focus was to demonstrate how such a hybrid model can provide better road safety when working together in a hybrid structure.</li>
</ul>

<h3>Title: Propose and Rectify: A Forensics-Driven MLLM Framework for Image Manipulation Localization</h3>
<ul>
<li><strong>Authors: </strong>Keyang Zhang, Chenqi Kong, Hui Liu, Bo Ding, Xinghao Jiang, Haoliang Li</a></li>
<li><strong>Subjects: </strong>cs.CV, eess.IV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.17976">https://arxiv.org/abs/2508.17976</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.17976">https://arxiv.org/pdf/2508.17976</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.17976]] Propose and Rectify: A Forensics-Driven MLLM Framework for Image Manipulation Localization(https://arxiv.org/abs/2508.17976)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, large language model, segmentation</a></li>
<li><strong>Abstract: </strong>The increasing sophistication of image manipulation techniques demands robust forensic solutions that can both reliably detect alterations and precisely localize tampered regions. Recent Multimodal Large Language Models (MLLMs) show promise by leveraging world knowledge and semantic understanding for context-aware detection, yet they struggle with perceiving subtle, low-level forensic artifacts crucial for accurate manipulation localization. This paper presents a novel Propose-Rectify framework that effectively bridges semantic reasoning with forensic-specific analysis. In the proposal stage, our approach utilizes a forensic-adapted LLaVA model to generate initial manipulation analysis and preliminary localization of suspicious regions based on semantic understanding and contextual reasoning. In the rectification stage, we introduce a Forensics Rectification Module that systematically validates and refines these initial proposals through multi-scale forensic feature analysis, integrating technical evidence from several specialized filters. Additionally, we present an Enhanced Segmentation Module that incorporates critical forensic cues into SAM's encoded image embeddings, thereby overcoming inherent semantic biases to achieve precise delineation of manipulated regions. By synergistically combining advanced multimodal reasoning with established forensic methodologies, our framework ensures that initial semantic proposals are systematically validated and enhanced through concrete technical evidence, resulting in comprehensive detection accuracy and localization precision. Extensive experimental validation demonstrates state-of-the-art performance across diverse datasets with exceptional robustness and generalization capabilities.</li>
</ul>

<h3>Title: A Retail-Corpus for Aspect-Based Sentiment Analysis with Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Oleg Silcenco, Marcos R. Machad, Wallace C. Ugulino, Daniel Braun</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.17994">https://arxiv.org/abs/2508.17994</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.17994">https://arxiv.org/pdf/2508.17994</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.17994]] A Retail-Corpus for Aspect-Based Sentiment Analysis with Large Language Models(https://arxiv.org/abs/2508.17994)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Aspect-based sentiment analysis enhances sentiment detection by associating it with specific aspects, offering deeper insights than traditional sentiment analysis. This study introduces a manually annotated dataset of 10,814 multilingual customer reviews covering brick-and-mortar retail stores, labeled with eight aspect categories and their sentiment. Using this dataset, the performance of GPT-4 and LLaMA-3 in aspect based sentiment analysis is evaluated to establish a baseline for the newly introduced data. The results show both models achieving over 85% accuracy, while GPT-4 outperforms LLaMA-3 overall with regard to all relevant metrics.</li>
</ul>

<h3>Title: A Novel Framework for Uncertainty Quantification via Proper Scores for Classification and Beyond</h3>
<ul>
<li><strong>Authors: </strong>Sebastian G. Gruber</a></li>
<li><strong>Subjects: </strong>cs.LG, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.18001">https://arxiv.org/abs/2508.18001</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.18001">https://arxiv.org/pdf/2508.18001</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.18001]] A Novel Framework for Uncertainty Quantification via Proper Scores for Classification and Beyond(https://arxiv.org/abs/2508.18001)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative, large language model</a></li>
<li><strong>Abstract: </strong>In this PhD thesis, we propose a novel framework for uncertainty quantification in machine learning, which is based on proper scores. Uncertainty quantification is an important cornerstone for trustworthy and reliable machine learning applications in practice. Usually, approaches to uncertainty quantification are problem-specific, and solutions and insights cannot be readily transferred from one task to another. Proper scores are loss functions minimized by predicting the target distribution. Due to their very general definition, proper scores apply to regression, classification, or even generative modeling tasks. We contribute several theoretical results, that connect epistemic uncertainty, aleatoric uncertainty, and model calibration with proper scores, resulting in a general and widely applicable framework. We achieve this by introducing a general bias-variance decomposition for strictly proper scores via functional Bregman divergences. Specifically, we use the kernel score, a kernel-based proper score, for evaluating sample-based generative models in various domains, like image, audio, and natural language generation. This includes a novel approach for uncertainty estimation of large language models, which outperforms state-of-the-art baselines. Further, we generalize the calibration-sharpness decomposition beyond classification, which motivates the definition of proper calibration errors. We then introduce a novel estimator for proper calibration errors in classification, and a novel risk-based approach to compare different estimators for squared calibration errors. Last, we offer a decomposition of the kernel spherical score, another kernel-based proper score, allowing a more fine-grained and interpretable evaluation of generative image models.</li>
</ul>

<h3>Title: Does simple trump complex? Comparing strategies for adversarial robustness in DNNs</h3>
<ul>
<li><strong>Authors: </strong>William Brooks, Marelie H. Davel, Coenraad Mouton</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.18019">https://arxiv.org/abs/2508.18019</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.18019">https://arxiv.org/pdf/2508.18019</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.18019]] Does simple trump complex? Comparing strategies for adversarial robustness in DNNs(https://arxiv.org/abs/2508.18019)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack, robust</a></li>
<li><strong>Abstract: </strong>Deep Neural Networks (DNNs) have shown substantial success in various applications but remain vulnerable to adversarial attacks. This study aims to identify and isolate the components of two different adversarial training techniques that contribute most to increased adversarial robustness, particularly through the lens of margins in the input space -- the minimal distance between data points and decision boundaries. Specifically, we compare two methods that maximize margins: a simple approach which modifies the loss function to increase an approximation of the margin, and a more complex state-of-the-art method (Dynamics-Aware Robust Training) which builds upon this approach. Using a VGG-16 model as our base, we systematically isolate and evaluate individual components from these methods to determine their relative impact on adversarial robustness. We assess the effect of each component on the model's performance under various adversarial attacks, including AutoAttack and Projected Gradient Descent (PGD). Our analysis on the CIFAR-10 dataset reveals which elements most effectively enhance adversarial robustness, providing insights for designing more robust DNNs.</li>
</ul>

<h3>Title: AQ-PCDSys: An Adaptive Quantized Planetary Crater Detection System for Autonomous Space Exploration</h3>
<ul>
<li><strong>Authors: </strong>Aditri Paul, Archan Paul</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CV, cs.ET, eess.SY</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.18025">https://arxiv.org/abs/2508.18025</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.18025">https://arxiv.org/pdf/2508.18025</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.18025]] AQ-PCDSys: An Adaptive Quantized Planetary Crater Detection System for Autonomous Space Exploration(https://arxiv.org/abs/2508.18025)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Autonomous planetary exploration missions are critically dependent on real-time, accurate environmental perception for navigation and hazard avoidance. However, deploying deep learning models on the resource-constrained computational hardware of planetary exploration platforms remains a significant challenge. This paper introduces the Adaptive Quantized Planetary Crater Detection System (AQ-PCDSys), a novel framework specifically engineered for real-time, onboard deployment in the computationally constrained environments of space exploration missions. AQ-PCDSys synergistically integrates a Quantized Neural Network (QNN) architecture, trained using Quantization-Aware Training (QAT), with an Adaptive Multi-Sensor Fusion (AMF) module. The QNN architecture significantly optimizes model size and inference latency suitable for real-time onboard deployment in space exploration missions, while preserving high accuracy. The AMF module intelligently fuses data from Optical Imagery (OI) and Digital Elevation Models (DEMs) at the feature level, utilizing an Adaptive Weighting Mechanism (AWM) to dynamically prioritize the most relevant and reliable sensor modality based on planetary ambient conditions. This approach enhances detection robustness across diverse planetary landscapes. Paired with Multi-Scale Detection Heads specifically designed for robust and efficient detection of craters across a wide range of sizes, AQ-PCDSys provides a computationally efficient, reliable and accurate solution for planetary crater detection, a critical capability for enabling the next generation of autonomous planetary landing, navigation, and scientific exploration.</li>
</ul>

<h3>Title: FCR: Investigating Generative AI models for Forensic Craniofacial Reconstruction</h3>
<ul>
<li><strong>Authors: </strong>Ravi Shankar Prasad, Dinesh Singh</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.18031">https://arxiv.org/abs/2508.18031</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.18031">https://arxiv.org/pdf/2508.18031</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.18031]] FCR: Investigating Generative AI models for Forensic Craniofacial Reconstruction(https://arxiv.org/abs/2508.18031)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>Craniofacial reconstruction in forensics is one of the processes to identify victims of crime and natural disasters. Identifying an individual from their remains plays a crucial role when all other identification methods fail. Traditional methods for this task, such as clay-based craniofacial reconstruction, require expert domain knowledge and are a time-consuming process. At the same time, other probabilistic generative models like the statistical shape model or the Basel face model fail to capture the skull and face cross-domain attributes. Looking at these limitations, we propose a generic framework for craniofacial reconstruction from 2D X-ray images. Here, we used various generative models (i.e., CycleGANs, cGANs, etc) and fine-tune the generator and discriminator parts to generate more realistic images in two distinct domains, which are the skull and face of an individual. This is the first time where 2D X-rays are being used as a representation of the skull by generative models for craniofacial reconstruction. We have evaluated the quality of generated faces using FID, IS, and SSIM scores. Finally, we have proposed a retrieval framework where the query is the generated face image and the gallery is the database of real faces. By experimental results, we have found that this can be an effective tool for forensic science.</li>
</ul>

<h3>Title: Enhancing Differentially Private Linear Regression via Public Second-Moment</h3>
<ul>
<li><strong>Authors: </strong>Zilong Cao (1), Hai Zhang (1) ((1) The School of Mathematics, Northwest University)</a></li>
<li><strong>Subjects: </strong>cs.LG, stat.ME, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.18037">https://arxiv.org/abs/2508.18037</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.18037">https://arxiv.org/pdf/2508.18037</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.18037]] Enhancing Differentially Private Linear Regression via Public Second-Moment(https://arxiv.org/abs/2508.18037)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Leveraging information from public data has become increasingly crucial in enhancing the utility of differentially private (DP) methods. Traditional DP approaches often require adding noise based solely on private data, which can significantly degrade utility. In this paper, we address this limitation in the context of the ordinary least squares estimator (OLSE) of linear regression based on sufficient statistics perturbation (SSP) under the unbounded data assumption. We propose a novel method that involves transforming private data using the public second-moment matrix to compute a transformed SSP-OLSE, whose second-moment matrix yields a better condition number and improves the OLSE accuracy and robustness. We derive theoretical error bounds about our method and the standard SSP-OLSE to the non-DP OLSE, which reveal the improved robustness and accuracy achieved by our approach. Experiments on synthetic and real-world datasets demonstrate the utility and effectiveness of our method.</li>
</ul>

<h3>Title: Riemannian Change Point Detection on Manifolds with Robust Centroid Estimation</h3>
<ul>
<li><strong>Authors: </strong>Xiuheng Wang, Ricardo Borsoi, Arnaud Breloy, C√©dric Richard</a></li>
<li><strong>Subjects: </strong>cs.LG, eess.SP</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.18045">https://arxiv.org/abs/2508.18045</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.18045">https://arxiv.org/pdf/2508.18045</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.18045]] Riemannian Change Point Detection on Manifolds with Robust Centroid Estimation(https://arxiv.org/abs/2508.18045)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Non-parametric change-point detection in streaming time series data is a long-standing challenge in signal processing. Recent advancements in statistics and machine learning have increasingly addressed this problem for data residing on Riemannian manifolds. One prominent strategy involves monitoring abrupt changes in the center of mass of the time series. Implemented in a streaming fashion, this strategy, however, requires careful step size tuning when computing the updates of the center of mass. In this paper, we propose to leverage robust centroid on manifolds from M-estimation theory to address this issue. Our proposal consists of comparing two centroid estimates: the classical Karcher mean (sensitive to change) versus one defined from Huber's function (robust to change). This comparison leads to the definition of a test statistic whose performance is less sensitive to the underlying estimation method. We propose a stochastic Riemannian optimization algorithm to estimate both robust centroids efficiently. Experiments conducted on both simulated and real-world data across two representative manifolds demonstrate the superior performance of our proposed method.</li>
</ul>

<h3>Title: ArgusCogito: Chain-of-Thought for Cross-Modal Synergy and Omnidirectional Reasoning in Camouflaged Object Segmentation</h3>
<ul>
<li><strong>Authors: </strong>Jianwen Tan, Huiyao Zhang, Rui Xiong, Han Zhou, Hongfei Wang, Ye Li</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.18050">https://arxiv.org/abs/2508.18050</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.18050">https://arxiv.org/pdf/2508.18050</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.18050]] ArgusCogito: Chain-of-Thought for Cross-Modal Synergy and Omnidirectional Reasoning in Camouflaged Object Segmentation(https://arxiv.org/abs/2508.18050)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, segmentation</a></li>
<li><strong>Abstract: </strong>Camouflaged Object Segmentation (COS) poses a significant challenge due to the intrinsic high similarity between targets and backgrounds, demanding models capable of profound holistic understanding beyond superficial cues. Prevailing methods, often limited by shallow feature representation, inadequate reasoning mechanisms, and weak cross-modal integration, struggle to achieve this depth of cognition, resulting in prevalent issues like incomplete target separation and imprecise segmentation. Inspired by the perceptual strategy of the Hundred-eyed Giant-emphasizing holistic observation, omnidirectional focus, and intensive scrutiny-we introduce ArgusCogito, a novel zero-shot, chain-of-thought framework underpinned by cross-modal synergy and omnidirectional reasoning within Vision-Language Models (VLMs). ArgusCogito orchestrates three cognitively-inspired stages: (1) Conjecture: Constructs a strong cognitive prior through global reasoning with cross-modal fusion (RGB, depth, semantic maps), enabling holistic scene understanding and enhanced target-background disambiguation. (2) Focus: Performs omnidirectional, attention-driven scanning and focused reasoning, guided by semantic priors from Conjecture, enabling precise target localization and region-of-interest refinement. (3) Sculpting: Progressively sculpts high-fidelity segmentation masks by integrating cross-modal information and iteratively generating dense positive/negative point prompts within focused regions, emulating Argus' intensive scrutiny. Extensive evaluations on four challenging COS benchmarks and three Medical Image Segmentation (MIS) benchmarks demonstrate that ArgusCogito achieves state-of-the-art (SOTA) performance, validating the framework's exceptional efficacy, superior generalization capability, and robustness.</li>
</ul>

<h3>Title: Training Transformers for Mesh-Based Simulations</h3>
<ul>
<li><strong>Authors: </strong>Paul Garnier, Vincent Lannelongue, Jonathan Viquerat, Elie Hachem</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.18051">https://arxiv.org/abs/2508.18051</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.18051">https://arxiv.org/pdf/2508.18051</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.18051]] Training Transformers for Mesh-Based Simulations(https://arxiv.org/abs/2508.18051)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Simulating physics using Graph Neural Networks (GNNs) is predominantly driven by message-passing architectures, which face challenges in scaling and efficiency, particularly in handling large, complex meshes. These architectures have inspired numerous enhancements, including multigrid approaches and $K$-hop aggregation (using neighbours of distance $K$), yet they often introduce significant complexity and suffer from limited in-depth investigations. In response to these challenges, we propose a novel Graph Transformer architecture that leverages the adjacency matrix as an attention mask. The proposed approach incorporates innovative augmentations, including Dilated Sliding Windows and Global Attention, to extend receptive fields without sacrificing computational efficiency. Through extensive experimentation, we evaluate model size, adjacency matrix augmentations, positional encoding and $K$-hop configurations using challenging 3D computational fluid dynamics (CFD) datasets. We also train over 60 models to find a scaling law between training FLOPs and parameters. The introduced models demonstrate remarkable scalability, performing on meshes with up to 300k nodes and 3 million edges. Notably, the smallest model achieves parity with MeshGraphNet while being $7\times$ faster and $6\times$ smaller. The largest model surpasses the previous state-of-the-art by $38.8$\% on average and outperforms MeshGraphNet by $52$\% on the all-rollout RMSE, while having a similar training speed. Code and datasets are available at this https URL.</li>
</ul>

<h3>Title: FedGreed: A Byzantine-Robust Loss-Based Aggregation Method for Federated Learning</h3>
<ul>
<li><strong>Authors: </strong>Emmanouil Kritharakis, Antonios Makris, Dusan Jakovetic, Konstantinos Tserpes</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.18060">https://arxiv.org/abs/2508.18060</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.18060">https://arxiv.org/pdf/2508.18060</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.18060]] FedGreed: A Byzantine-Robust Loss-Based Aggregation Method for Federated Learning(https://arxiv.org/abs/2508.18060)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, attack, robust, federate</a></li>
<li><strong>Abstract: </strong>Federated Learning (FL) enables collaborative model training across multiple clients while preserving data privacy by keeping local datasets on-device. In this work, we address FL settings where clients may behave adversarially, exhibiting Byzantine attacks, while the central server is trusted and equipped with a reference dataset. We propose FedGreed, a resilient aggregation strategy for federated learning that does not require any assumptions about the fraction of adversarial participants. FedGreed orders clients' local model updates based on their loss metrics evaluated against a trusted dataset on the server and greedily selects a subset of clients whose models exhibit the minimal evaluation loss. Unlike many existing approaches, our method is designed to operate reliably under heterogeneous (non-IID) data distributions, which are prevalent in real-world deployments. FedGreed exhibits convergence guarantees and bounded optimality gaps under strong adversarial behavior. Experimental evaluations on MNIST, FMNIST, and CIFAR-10 demonstrate that our method significantly outperforms standard and robust federated learning baselines, such as Mean, Trimmed Mean, Median, Krum, and Multi-Krum, in the majority of adversarial scenarios considered, including label flipping and Gaussian noise injection attacks. All experiments were conducted using the Flower federated learning framework.</li>
</ul>

<h3>Title: Annotation-Free Open-Vocabulary Segmentation for Remote-Sensing Images</h3>
<ul>
<li><strong>Authors: </strong>Kaiyu Li, Xiangyong Cao, Ruixun Liu, Shihong Wang, Zixuan Jiang, Zhi Wang, Deyu Meng</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.18067">https://arxiv.org/abs/2508.18067</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.18067">https://arxiv.org/pdf/2508.18067</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.18067]] Annotation-Free Open-Vocabulary Segmentation for Remote-Sensing Images(https://arxiv.org/abs/2508.18067)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, segmentation</a></li>
<li><strong>Abstract: </strong>Semantic segmentation of remote sensing (RS) images is pivotal for comprehensive Earth observation, but the demand for interpreting new object categories, coupled with the high expense of manual annotation, poses significant challenges. Although open-vocabulary semantic segmentation (OVSS) offers a promising solution, existing frameworks designed for natural images are insufficient for the unique complexities of RS data. They struggle with vast scale variations and fine-grained details, and their adaptation often relies on extensive, costly annotations. To address this critical gap, this paper introduces SegEarth-OV, the first framework for annotation-free open-vocabulary segmentation of RS images. Specifically, we propose SimFeatUp, a universal upsampler that robustly restores high-resolution spatial details from coarse features, correcting distorted target shapes without any task-specific post-training. We also present a simple yet effective Global Bias Alleviation operation to subtract the inherent global context from patch features, significantly enhancing local semantic fidelity. These components empower SegEarth-OV to effectively harness the rich semantics of pre-trained VLMs, making OVSS possible in optical RS contexts. Furthermore, to extend the framework's universality to other challenging RS modalities like SAR images, where large-scale VLMs are unavailable and expensive to create, we introduce AlignEarth, which is a distillation-based strategy and can efficiently transfer semantic knowledge from an optical VLM encoder to an SAR encoder, bypassing the need to build SAR foundation models from scratch and enabling universal OVSS across diverse sensor types. Extensive experiments on both optical and SAR datasets validate that SegEarth-OV can achieve dramatic improvements over the SOTA methods, establishing a robust foundation for annotation-free and open-world Earth observation.</li>
</ul>

<h3>Title: Neither Valid nor Reliable? Investigating the Use of LLMs as Judges</h3>
<ul>
<li><strong>Authors: </strong>Khaoula Chehbouni, Mohammed Haddou, Jackie Chi Kit Cheung, Golnoosh Farnadi</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.18076">https://arxiv.org/abs/2508.18076</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.18076">https://arxiv.org/pdf/2508.18076</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.18076]] Neither Valid nor Reliable? Investigating the Use of LLMs as Judges(https://arxiv.org/abs/2508.18076)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Evaluating natural language generation (NLG) systems remains a core challenge of natural language processing (NLP), further complicated by the rise of large language models (LLMs) that aims to be general-purpose. Recently, large language models as judges (LLJs) have emerged as a promising alternative to traditional metrics, but their validity remains underexplored. This position paper argues that the current enthusiasm around LLJs may be premature, as their adoption has outpaced rigorous scrutiny of their reliability and validity as evaluators. Drawing on measurement theory from the social sciences, we identify and critically assess four core assumptions underlying the use of LLJs: their ability to act as proxies for human judgment, their capabilities as evaluators, their scalability, and their cost-effectiveness. We examine how each of these assumptions may be challenged by the inherent limitations of LLMs, LLJs, or current practices in NLG evaluation. To ground our analysis, we explore three applications of LLJs: text summarization, data annotation, and safety alignment. Finally, we highlight the need for more responsible evaluation practices in LLJs evaluation, to ensure that their growing role in the field supports, rather than undermines, progress in NLG.</li>
</ul>

<h3>Title: Quantum-Classical Hybrid Framework for Zero-Day Time-Push GNSS Spoofing Detection</h3>
<ul>
<li><strong>Authors: </strong>Abyad Enan, Mashrur Chowdhury, Sagar Dasgupta, Mizanur Rahman</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.18085">https://arxiv.org/abs/2508.18085</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.18085">https://arxiv.org/pdf/2508.18085</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.18085]] Quantum-Classical Hybrid Framework for Zero-Day Time-Push GNSS Spoofing Detection(https://arxiv.org/abs/2508.18085)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack</a></li>
<li><strong>Abstract: </strong>Global Navigation Satellite Systems (GNSS) are critical for Positioning, Navigation, and Timing (PNT) applications. However, GNSS are highly vulnerable to spoofing attacks, where adversaries transmit counterfeit signals to mislead receivers. Such attacks can lead to severe consequences, including misdirected navigation, compromised data integrity, and operational disruptions. Most existing spoofing detection methods depend on supervised learning techniques and struggle to detect novel, evolved, and unseen attacks. To overcome this limitation, we develop a zero-day spoofing detection method using a Hybrid Quantum-Classical Autoencoder (HQC-AE), trained solely on authentic GNSS signals without exposure to spoofed data. By leveraging features extracted during the tracking stage, our method enables proactive detection before PNT solutions are computed. We focus on spoofing detection in static GNSS receivers, which are particularly susceptible to time-push spoofing attacks, where attackers manipulate timing information to induce incorrect time computations at the receiver. We evaluate our model against different unseen time-push spoofing attack scenarios: simplistic, intermediate, and sophisticated. Our analysis demonstrates that the HQC-AE consistently outperforms its classical counterpart, traditional supervised learning-based models, and existing unsupervised learning-based methods in detecting zero-day, unseen GNSS time-push spoofing attacks, achieving an average detection accuracy of 97.71% with an average false negative rate of 0.62% (when an attack occurs but is not detected). For sophisticated spoofing attacks, the HQC-AE attains an accuracy of 98.23% with a false negative rate of 1.85%. These findings highlight the effectiveness of our method in proactively detecting zero-day GNSS time-push spoofing attacks across various stationary GNSS receiver platforms.</li>
</ul>

<h3>Title: How Quantization Shapes Bias in Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Federico Marcuzzi, Xuefei Ning, Roy Schwartz, Iryna Gurevych</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.18088">https://arxiv.org/abs/2508.18088</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.18088">https://arxiv.org/pdf/2508.18088</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.18088]] How Quantization Shapes Bias in Large Language Models(https://arxiv.org/abs/2508.18088)</code><input type="text"></li>
<li><strong>Keywords: </strong>fair, generative, large language model</a></li>
<li><strong>Abstract: </strong>This work presents a comprehensive evaluation of how quantization affects model bias, with particular attention to its impact on individual demographic subgroups. We focus on weight and activation quantization strategies and examine their effects across a broad range of bias types, including stereotypes, toxicity, sentiment, and fairness. We employ both probabilistic and generated text-based metrics across nine benchmarks and evaluate models varying in architecture family and reasoning ability. Our findings show that quantization has a nuanced impact on bias: while it can reduce model toxicity and does not significantly impact sentiment, it tends to slightly increase stereotypes and unfairness in generative tasks, especially under aggressive compression. These trends are generally consistent across demographic categories and model types, although their magnitude depends on the specific setting. Overall, our results highlight the importance of carefully balancing efficiency and ethical considerations when applying quantization in practice.</li>
</ul>

<h3>Title: Speech-Based Depressive Mood Detection in the Presence of Multiple Sclerosis: A Cross-Corpus and Cross-Lingual Study</h3>
<ul>
<li><strong>Authors: </strong>Monica Gonzalez-Machorro, Uwe Reichel, Pascal Hecker, Helly Hammer, Hesam Sagha, Florian Eyben, Robert Hoepner, Bj√∂rn W. Schuller</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.18092">https://arxiv.org/abs/2508.18092</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.18092">https://arxiv.org/pdf/2508.18092</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.18092]] Speech-Based Depressive Mood Detection in the Presence of Multiple Sclerosis: A Cross-Corpus and Cross-Lingual Study(https://arxiv.org/abs/2508.18092)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>Depression commonly co-occurs with neurodegenerative disorders like Multiple Sclerosis (MS), yet the potential of speech-based Artificial Intelligence for detecting depression in such contexts remains unexplored. This study examines the transferability of speech-based depression detection methods to people with MS (pwMS) through cross-corpus and cross-lingual analysis using English data from the general population and German data from pwMS. Our approach implements supervised machine learning models using: 1) conventional speech and language features commonly used in the field, 2) emotional dimensions derived from a Speech Emotion Recognition (SER) model, and 3) exploratory speech feature analysis. Despite limited data, our models detect depressive mood in pwMS with moderate generalisability, achieving a 66% Unweighted Average Recall (UAR) on a binary task. Feature selection further improved performance, boosting UAR to 74%. Our findings also highlight the relevant role emotional changes have as an indicator of depressive mood in both the general population and within PwMS. This study provides an initial exploration into generalising speech-based depression detection, even in the presence of co-occurring conditions, such as neurodegenerative diseases.</li>
</ul>

<h3>Title: Agri-Query: A Case Study on RAG vs. Long-Context LLMs for Cross-Lingual Technical Question Answering</h3>
<ul>
<li><strong>Authors: </strong>Julius Gun, Timo Oksanen</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.18093">https://arxiv.org/abs/2508.18093</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.18093">https://arxiv.org/pdf/2508.18093</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.18093]] Agri-Query: A Case Study on RAG vs. Long-Context LLMs for Cross-Lingual Technical Question Answering(https://arxiv.org/abs/2508.18093)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>We present a case study evaluating large language models (LLMs) with 128K-token context windows on a technical question answering (QA) task. Our benchmark is built on a user manual for an agricultural machine, available in English, French, and German. It simulates a cross-lingual information retrieval scenario where questions are posed in English against all three language versions of the manual. The evaluation focuses on realistic "needle-in-a-haystack" challenges and includes unanswerable questions to test for hallucinations. We compare nine long-context LLMs using direct prompting against three Retrieval-Augmented Generation (RAG) strategies (keyword, semantic, hybrid), with an LLM-as-a-judge for evaluation. Our findings for this specific manual show that Hybrid RAG consistently outperforms direct long-context prompting. Models like Gemini 2.5 Flash and the smaller Qwen 2.5 7B achieve high accuracy (over 85%) across all languages with RAG. This paper contributes a detailed analysis of LLM performance in a specialized industrial domain and an open framework for similar evaluations, highlighting practical trade-offs and challenges.</li>
</ul>

<h3>Title: Incorporating Pre-trained Diffusion Models in Solving the Schr√∂dinger Bridge Problem</h3>
<ul>
<li><strong>Authors: </strong>Zhicong Tang, Tiankai Hang, Shuyang Gu, Dong Chen, Baining Guo</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.18095">https://arxiv.org/abs/2508.18095</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.18095">https://arxiv.org/pdf/2508.18095</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.18095]] Incorporating Pre-trained Diffusion Models in Solving the Schr√∂dinger Bridge Problem(https://arxiv.org/abs/2508.18095)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, generative</a></li>
<li><strong>Abstract: </strong>This paper aims to unify Score-based Generative Models (SGMs), also known as Diffusion models, and the Schr√∂dinger Bridge (SB) problem through three reparameterization techniques: Iterative Proportional Mean-Matching (IPMM), Iterative Proportional Terminus-Matching (IPTM), and Iterative Proportional Flow-Matching (IPFM). These techniques significantly accelerate and stabilize the training of SB-based models. Furthermore, the paper introduces novel initialization strategies that use pre-trained SGMs to effectively train SB-based models. By using SGMs as initialization, we leverage the advantages of both SB-based models and SGMs, ensuring efficient training of SB-based models and further improving the performance of SGMs. Extensive experiments demonstrate the significant effectiveness and improvements of the proposed methods. We believe this work contributes to and paves the way for future research on generative models.</li>
</ul>

<h3>Title: Detecting and Characterizing Planning in Language Models</h3>
<ul>
<li><strong>Authors: </strong>Jatin Nainani, Sankaran Vaidyanathan, Connor Watts, Andre N. Assis, Alice Rigg</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.18098">https://arxiv.org/abs/2508.18098</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.18098">https://arxiv.org/pdf/2508.18098</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.18098]] Detecting and Characterizing Planning in Language Models(https://arxiv.org/abs/2508.18098)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Modern large language models (LLMs) have demonstrated impressive performance across a wide range of multi-step reasoning tasks. Recent work suggests that LLMs may perform planning - selecting a future target token in advance and generating intermediate tokens that lead towards it - rather than merely improvising one token at a time. However, existing studies assume fixed planning horizons and often focus on single prompts or narrow domains. To distinguish planning from improvisation across models and tasks, we present formal and causally grounded criteria for detecting planning and operationalize them as a semi-automated annotation pipeline. We apply this pipeline to both base and instruction-tuned Gemma-2-2B models on the MBPP code generation benchmark and a poem generation task where Claude 3.5 Haiku was previously shown to plan. Our findings show that planning is not universal: unlike Haiku, Gemma-2-2B solves the same poem generation task through improvisation, and on MBPP it switches between planning and improvisation across similar tasks and even successive token predictions. We further show that instruction tuning refines existing planning behaviors in the base model rather than creating them from scratch. Together, these studies provide a reproducible and scalable foundation for mechanistic studies of planning in LLMs.</li>
</ul>

<h3>Title: Aligning Core Aspects: Improving Vulnerability Proof-of-Concepts via Cross-Source Insights</h3>
<ul>
<li><strong>Authors: </strong>Lingxiao Wang, Wenjing Dang, Mengyao Zhang, Yue Wang, Xianzong Wu, Sen Chen</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.18109">https://arxiv.org/abs/2508.18109</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.18109">https://arxiv.org/pdf/2508.18109</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.18109]] Aligning Core Aspects: Improving Vulnerability Proof-of-Concepts via Cross-Source Insights(https://arxiv.org/abs/2508.18109)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction</a></li>
<li><strong>Abstract: </strong>For vulnerabilities, Proof-of-Concept (PoC) plays an irreplaceable role in demonstrating the exploitability. PoC reports may include critical information such as specific usage, test platforms, and more, providing essential insights for researchers. However, in reality, due to various PoC templates across PoC platforms, PoC reports extensively suffer from information deficiency, leading the suboptimal quality and limited usefulness. Fortunately, we found that information deficiency of PoC reports could be mitigated by the completion from multiple sources given the same referred vulnerability. In this paper, we conduct the first study on the deficiency of information in PoC reports across public platforms. We began by collecting 173,170 PoC reports from 4 different platforms and defined 8 key aspects that PoCs should contain. By integrating rule-based matching and a fine-tuned BERT-NER model for extraction of key aspects, we discovered that all PoC reports available on public platforms have at least one missing key aspect. Subsequently, we developed a multi-source information fusion method to complete the missing aspect information in PoC reports by leveraging CVE entries and related PoC reports from different sources. Finally, we successfully completed 69,583 PoC reports (40.18% of all reports).</li>
</ul>

<h3>Title: Provable Mixed-Noise Learning with Flow-Matching</h3>
<ul>
<li><strong>Authors: </strong>Paul Hagemann, Robert Gruhlke, Bernhard Stankewitz, Claudia Schillings, Gabriele Steidl</a></li>
<li><strong>Subjects: </strong>cs.LG, math.OC</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.18122">https://arxiv.org/abs/2508.18122</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.18122">https://arxiv.org/pdf/2508.18122</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.18122]] Provable Mixed-Noise Learning with Flow-Matching(https://arxiv.org/abs/2508.18122)</code><input type="text"></li>
<li><strong>Keywords: </strong>noise learning, generative</a></li>
<li><strong>Abstract: </strong>We study Bayesian inverse problems with mixed noise, modeled as a combination of additive and multiplicative Gaussian components. While traditional inference methods often assume fixed or known noise characteristics, real-world applications, particularly in physics and chemistry, frequently involve noise with unknown and heterogeneous structure. Motivated by recent advances in flow-based generative modeling, we propose a novel inference framework based on conditional flow matching embedded within an Expectation-Maximization (EM) algorithm to jointly estimate posterior samplers and noise parameters. To enable high-dimensional inference and improve scalability, we use simulation-free ODE-based flow matching as the generative model in the E-step of the EM algorithm. We prove that, under suitable assumptions, the EM updates converge to the true noise parameters in the population limit of infinite observations. Our numerical results illustrate the effectiveness of combining EM inference with flow matching for mixed-noise Bayesian inverse problems.</li>
</ul>

<h3>Title: CMPhysBench: A Benchmark for Evaluating Large Language Models in Condensed Matter Physics</h3>
<ul>
<li><strong>Authors: </strong>Weida Wang, Dongchen Huang, Jiatong Li, Tengchao Yang, Ziyang Zheng, Di Zhang, Dong Han, Benteng Chen, Binzhao Luo, Zhiyu Liu, Kunling Liu, Zhiyuan Gao, Shiqi Geng, Wei Ma, Jiaming Su, Xin Li, Shuchen Pu, Yuhan Shui, Qianjia Cheng, Zhihao Dou, Dongfei Cui, Changyong He, Jin Zeng, Zeke Xie, Mao Su, Dongzhan Zhou, Yuqiang Li, Wanli Ouyang, Lei Bai, Yunqi Cai, Xi Dai, Shufei Zhang, Jinguang Cheng, Zhong Fang, Hongming Weng</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.18124">https://arxiv.org/abs/2508.18124</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.18124">https://arxiv.org/pdf/2508.18124</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.18124]] CMPhysBench: A Benchmark for Evaluating Large Language Models in Condensed Matter Physics(https://arxiv.org/abs/2508.18124)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>We introduce CMPhysBench, designed to assess the proficiency of Large Language Models (LLMs) in Condensed Matter Physics, as a novel Benchmark. CMPhysBench is composed of more than 520 graduate-level meticulously curated questions covering both representative subfields and foundational theoretical frameworks of condensed matter physics, such as magnetism, superconductivity, strongly correlated systems, etc. To ensure a deep understanding of the problem-solving process,we focus exclusively on calculation problems, requiring LLMs to independently generate comprehensive solutions. Meanwhile, leveraging tree-based representations of expressions, we introduce the Scalable Expression Edit Distance (SEED) score, which provides fine-grained (non-binary) partial credit and yields a more accurate assessment of similarity between prediction and ground-truth. Our results show that even the best models, Grok-4, reach only 36 average SEED score and 28% accuracy on CMPhysBench, underscoring a significant capability gap, especially for this practical and frontier domain relative to traditional physics. The code anddataset are publicly available at this https URL.</li>
</ul>

<h3>Title: Frozen in Time: Parameter-Efficient Time Series Transformers via Reservoir-Induced Feature Expansion and Fixed Random Dynamics</h3>
<ul>
<li><strong>Authors: </strong>Pradeep Singh, Mehak Sharma, Anupriya Dey, Balasubramanian Raman</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.18130">https://arxiv.org/abs/2508.18130</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.18130">https://arxiv.org/pdf/2508.18130</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.18130]] Frozen in Time: Parameter-Efficient Time Series Transformers via Reservoir-Induced Feature Expansion and Fixed Random Dynamics(https://arxiv.org/abs/2508.18130)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Transformers are the de-facto choice for sequence modelling, yet their quadratic self-attention and weak temporal bias can make long-range forecasting both expensive and brittle. We introduce FreezeTST, a lightweight hybrid that interleaves frozen random-feature (reservoir) blocks with standard trainable Transformer layers. The frozen blocks endow the network with rich nonlinear memory at no optimisation cost; the trainable layers learn to query this memory through self-attention. The design cuts trainable parameters and also lowers wall-clock training time, while leaving inference complexity unchanged. On seven standard long-term forecasting benchmarks, FreezeTST consistently matches or surpasses specialised variants such as Informer, Autoformer, and PatchTST; with substantially lower compute. Our results show that embedding reservoir principles within Transformers offers a simple, principled route to efficient long-term time-series prediction.</li>
</ul>

<h3>Title: BirdRecorder's AI on Sky: Safeguarding birds of prey by detection and classification of tiny objects around wind turbines</h3>
<ul>
<li><strong>Authors: </strong>Nico Klar, Nizam Gifary, Felix P. G. Ziegler, Frank Sehnke, Anton Kaifel, Eric Price, Aamir Ahmad</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.LG, cs.RO, eess.SY</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.18136">https://arxiv.org/abs/2508.18136</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.18136">https://arxiv.org/pdf/2508.18136</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.18136]] BirdRecorder's AI on Sky: Safeguarding birds of prey by detection and classification of tiny objects around wind turbines(https://arxiv.org/abs/2508.18136)</code><input type="text"></li>
<li><strong>Keywords: </strong>protect</a></li>
<li><strong>Abstract: </strong>The urgent need for renewable energy expansion, particularly wind power, is hindered by conflicts with wildlife conservation. To address this, we developed BirdRecorder, an advanced AI-based anti-collision system to protect endangered birds, especially the red kite (Milvus milvus). Integrating robotics, telemetry, and high-performance AI algorithms, BirdRecorder aims to detect, track, and classify avian species within a range of 800 m to minimize bird-turbine collisions. BirdRecorder integrates advanced AI methods with optimized hardware and software architectures to enable real-time image processing. Leveraging Single Shot Detector (SSD) for detection, combined with specialized hardware acceleration and tracking algorithms, our system achieves high detection precision while maintaining the speed necessary for real-time decision-making. By combining these components, BirdRecorder outperforms existing approaches in both accuracy and efficiency. In this paper, we summarize results on field tests and performance of the BirdRecorder system. By bridging the gap between renewable energy expansion and wildlife conservation, BirdRecorder contributes to a more sustainable coexistence of technology and nature.</li>
</ul>

<h3>Title: Learning from Few Samples: A Novel Approach for High-Quality Malcode Generation</h3>
<ul>
<li><strong>Authors: </strong>Haijian Ma, Daizong Liu, Xiaowen Cai, Pan Zhou, Yulai Xie</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.18148">https://arxiv.org/abs/2508.18148</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.18148">https://arxiv.org/pdf/2508.18148</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.18148]] Learning from Few Samples: A Novel Approach for High-Quality Malcode Generation(https://arxiv.org/abs/2508.18148)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, defense, generative, large language model</a></li>
<li><strong>Abstract: </strong>Intrusion Detection Systems (IDS) play a crucial role in network security defense. However, a significant challenge for IDS in training detection models is the shortage of adequately labeled malicious samples. To address these issues, this paper introduces a novel semi-supervised framework \textbf{GANGRL-LLM}, which integrates Generative Adversarial Networks (GANs) with Large Language Models (LLMs) to enhance malicious code generation and SQL Injection (SQLi) detection capabilities in few-sample learning scenarios. Specifically, our framework adopts a collaborative training paradigm where: (1) the GAN-based discriminator improves malicious pattern recognition through adversarial learning with generated samples and limited real samples; and (2) the LLM-based generator refines the quality of malicious code synthesis using reward signals from the discriminator. The experimental results demonstrate that even with a limited number of labeled samples, our training framework is highly effective in enhancing both malicious code generation and detection capabilities. This dual enhancement capability offers a promising solution for developing adaptive defense systems capable of countering evolving cyber threats.</li>
</ul>

<h3>Title: Assessing the Noise Robustness of Class Activation Maps: A Framework for Reliable Model Interpretability</h3>
<ul>
<li><strong>Authors: </strong>Syamantak Sarkar, Revoti P. Bora, Bhupender Kaushal, Sudhish N George, Kiran Raja</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.18154">https://arxiv.org/abs/2508.18154</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.18154">https://arxiv.org/pdf/2508.18154</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.18154]] Assessing the Noise Robustness of Class Activation Maps: A Framework for Reliable Model Interpretability(https://arxiv.org/abs/2508.18154)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, interpretability</a></li>
<li><strong>Abstract: </strong>Class Activation Maps (CAMs) are one of the important methods for visualizing regions used by deep learning models. Yet their robustness to different noise remains underexplored. In this work, we evaluate and report the resilience of various CAM methods for different noise perturbations across multiple architectures and datasets. By analyzing the influence of different noise types on CAM explanations, we assess the susceptibility to noise and the extent to which dataset characteristics may impact explanation stability. The findings highlight considerable variability in noise sensitivity for various CAMs. We propose a robustness metric for CAMs that captures two key properties: consistency and responsiveness. Consistency reflects the ability of CAMs to remain stable under input perturbations that do not alter the predicted class, while responsiveness measures the sensitivity of CAMs to changes in the prediction caused by such perturbations. The metric is evaluated empirically across models, different perturbations, and datasets along with complementary statistical tests to exemplify the applicability of our proposed approach.</li>
</ul>

<h3>Title: $AutoGuardX$: A Comprehensive Cybersecurity Framework for Connected Vehicles</h3>
<ul>
<li><strong>Authors: </strong>Muhammad Ali Nadeem, Bishwo Prakash Pokharel, Naresh Kshetri, Achyut Shankar, Gokarna Sharma</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.ET</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.18155">https://arxiv.org/abs/2508.18155</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.18155">https://arxiv.org/pdf/2508.18155</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.18155]] $AutoGuardX$: A Comprehensive Cybersecurity Framework for Connected Vehicles(https://arxiv.org/abs/2508.18155)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, attack</a></li>
<li><strong>Abstract: </strong>The rapid integration of Internet of Things (IoT) and interconnected systems in modern vehicles not only introduced a new era of convenience, automation, and connected vehicles but also elevated their exposure to sophisticated cyber threats. This is especially evident in US and Canada, where cyber-enabled auto theft has surged in recent years, revealing the limitations of existing security measures for connected vehicles. In response, this paper proposes $AutoGuardX$, a comprehensive cybersecurity framework designed specifically for connected vehicles. $AutoGuardX$ combines key elements from existing recognized standards for vehicle security, such as ISO/SAE 21434 and ISO 26262, with advanced technologies, including machine learning-based anomaly detection, IoT security protocols, and encrypted communication channels. The framework addresses major attack vectors like relay attacks, controller area network (CAN) bus intrusions, and vulnerabilities introduced by emerging technologies such as 5G and quantum computing. $AutoGuardX$ is extensively evaluated through security simulations across a mix of Sedans and SUVs from four major vehicle brands manufactured between 2019 and 2023. The results demonstrate the framework's adaptability, scalability, and practical effectiveness against existing and emerging threats.</li>
</ul>

<h3>Title: SpotEdit: Evaluating Visually-Guided Image Editing Methods</h3>
<ul>
<li><strong>Authors: </strong>Sara Ghazanfari, Wei-An Lin, Haitong Tian, Ersin Yumer</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.18159">https://arxiv.org/abs/2508.18159</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.18159">https://arxiv.org/pdf/2508.18159</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.18159]] SpotEdit: Evaluating Visually-Guided Image Editing Methods(https://arxiv.org/abs/2508.18159)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, generative</a></li>
<li><strong>Abstract: </strong>Visually-guided image editing, where edits are conditioned on both visual cues and textual prompts, has emerged as a powerful paradigm for fine-grained, controllable content generation. Although recent generative models have shown remarkable capabilities, existing evaluations remain simple and insufficiently representative of real-world editing challenges. We present SpotEdit, a comprehensive benchmark designed to systematically assess visually-guided image editing methods across diverse diffusion, autoregressive, and hybrid generative models, uncovering substantial performance disparities. To address a critical yet underexplored challenge, our benchmark includes a dedicated component on hallucination, highlighting how leading models, such as GPT-4o, often hallucinate the existence of a visual cue and erroneously perform the editing task. Our code and benchmark are publicly released at this https URL.</li>
</ul>

<h3>Title: S2Sent: Nested Selectivity Aware Sentence Representation Learning</h3>
<ul>
<li><strong>Authors: </strong>Jianxiang Zang, Nijia Mo, Yonda Wei, Meiling Ning, Hui Liu</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.18164">https://arxiv.org/abs/2508.18164</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.18164">https://arxiv.org/pdf/2508.18164</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.18164]] S2Sent: Nested Selectivity Aware Sentence Representation Learning(https://arxiv.org/abs/2508.18164)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability, transformer</a></li>
<li><strong>Abstract: </strong>The combination of Transformer-based encoders with contrastive learning represents the current mainstream paradigm for sentence representation learning. This paradigm is typically based on the hidden states of the last Transformer block of the encoder. However, within Transformer-based encoders, different blocks exhibit varying degrees of semantic perception ability. From the perspective of interpretability, the semantic perception potential of knowledge neurons is modulated by stimuli, thus rational cross-block representation fusion is a direction worth optimizing. To balance the semantic redundancy and loss across block fusion, we propose a sentence representation selection mechanism S\textsuperscript{2}Sent, which integrates a parameterized nested selector downstream of the Transformer-based encoder. This selector performs spatial selection (SS) and nested frequency selection (FS) from a modular perspective. The SS innovatively employs a spatial squeeze based self-gating mechanism to obtain adaptive weights, which not only achieves fusion with low information redundancy but also captures the dependencies between embedding features. The nested FS replaces GAP with different DCT basis functions to achieve spatial squeeze with low semantic loss. Extensive experiments have demonstrated that S\textsuperscript{2}Sent achieves significant improvements over baseline methods with negligible additional parameters and inference latency, while highlighting high integrability and scalability.</li>
</ul>

<h3>Title: DiscussLLM: Teaching Large Language Models When to Speak</h3>
<ul>
<li><strong>Authors: </strong>Deep Anil Patel, Iain Melvin, Christopher Malon, Martin Renqiang Min</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.HC</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.18167">https://arxiv.org/abs/2508.18167</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.18167">https://arxiv.org/pdf/2508.18167</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.18167]] DiscussLLM: Teaching Large Language Models When to Speak(https://arxiv.org/abs/2508.18167)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large Language Models (LLMs) have demonstrated remarkable capabilities in understanding and generating human-like text, yet they largely operate as reactive agents, responding only when directly prompted. This passivity creates an "awareness gap," limiting their potential as truly collaborative partners in dynamic human discussions. We introduce $\textit{DiscussLLM}$, a framework designed to bridge this gap by training models to proactively decide not just $\textit{what}$ to say, but critically, $\textit{when}$ to speak. Our primary contribution is a scalable two-stage data generation pipeline that synthesizes a large-scale dataset of realistic multi-turn human discussions. Each discussion is annotated with one of five intervention types (e.g., Factual Correction, Concept Definition) and contains an explicit conversational trigger where an AI intervention adds value. By training models to predict a special silent token when no intervention is needed, they learn to remain quiet until a helpful contribution can be made. We explore two architectural baselines: an integrated end-to-end model and a decoupled classifier-generator system optimized for low-latency inference. We evaluate these models on their ability to accurately time interventions and generate helpful responses, paving the way for more situationally aware and proactive conversational AI.</li>
</ul>

<h3>Title: Unveiling the Actual Performance of Neural-based Models for Equation Discovery on Graph Dynamical Systems</h3>
<ul>
<li><strong>Authors: </strong>Riccardo Cappi, Paolo Frazzetto, Nicol√≤ Navarin, Alessandro Sperduti</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.18173">https://arxiv.org/abs/2508.18173</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.18173">https://arxiv.org/pdf/2508.18173</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.18173]] Unveiling the Actual Performance of Neural-based Models for Equation Discovery on Graph Dynamical Systems(https://arxiv.org/abs/2508.18173)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, interpretability</a></li>
<li><strong>Abstract: </strong>The ``black-box'' nature of deep learning models presents a significant barrier to their adoption for scientific discovery, where interpretability is paramount. This challenge is especially pronounced in discovering the governing equations of dynamical processes on networks or graphs, since even their topological structure further affects the processes' behavior. This paper provides a rigorous, comparative assessment of state-of-the-art symbolic regression techniques for this task. We evaluate established methods, including sparse regression and MLP-based architectures, and introduce a novel adaptation of Kolmogorov-Arnold Networks (KANs) for graphs, designed to exploit their inherent interpretability. Across a suite of synthetic and real-world dynamical systems, our results demonstrate that both MLP and KAN-based architectures can successfully identify the underlying symbolic equations, significantly surpassing existing baselines. Critically, we show that KANs achieve this performance with greater parsimony and transparency, as their learnable activation functions provide a clearer mapping to the true physical dynamics. This study offers a practical guide for researchers, clarifying the trade-offs between model expressivity and interpretability, and establishes the viability of neural-based architectures for robust scientific discovery on complex systems.</li>
</ul>

<h3>Title: Amortized Sampling with Transferable Normalizing Flows</h3>
<ul>
<li><strong>Authors: </strong>Charlie B. Tan, Majdi Hassan, Leon Klein, Saifuddin Syed, Dominique Beaini, Michael M. Bronstein, Alexander Tong, Kirill Neklyudov</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.18175">https://arxiv.org/abs/2508.18175</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.18175">https://arxiv.org/pdf/2508.18175</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.18175]] Amortized Sampling with Transferable Normalizing Flows(https://arxiv.org/abs/2508.18175)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>Efficient equilibrium sampling of molecular conformations remains a core challenge in computational chemistry and statistical inference. Classical approaches such as molecular dynamics or Markov chain Monte Carlo inherently lack amortization; the computational cost of sampling must be paid in-full for each system of interest. The widespread success of generative models has inspired interest into overcoming this limitation through learning sampling algorithms. Despite performing on par with conventional methods when trained on a single system, learned samplers have so far demonstrated limited ability to transfer across systems. We prove that deep learning enables the design of scalable and transferable samplers by introducing Prose, a 280 million parameter all-atom transferable normalizing flow trained on a corpus of peptide molecular dynamics trajectories up to 8 residues in length. Prose draws zero-shot uncorrelated proposal samples for arbitrary peptide systems, achieving the previously intractable transferability across sequence length, whilst retaining the efficient likelihood evaluation of normalizing flows. Through extensive empirical evaluation we demonstrate the efficacy of Prose as a proposal for a variety of sampling algorithms, finding a simple importance sampling-based finetuning procedure to achieve superior performance to established methods such as sequential Monte Carlo on unseen tetrapeptides. We open-source the Prose codebase, model weights, and training dataset, to further stimulate research into amortized sampling methods and finetuning objectives.</li>
</ul>

<h3>Title: AdLoCo: adaptive batching significantly improves communications efficiency and convergence for Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Nikolay Kutuzov, Makar Baderko, Stepan Kulibaba, Artem Dzhalilov, Daniel Bobrov, Maxim Mashtaler, Alexander Gasnikov</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, math.OC</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.18182">https://arxiv.org/abs/2508.18182</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.18182">https://arxiv.org/pdf/2508.18182</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.18182]] AdLoCo: adaptive batching significantly improves communications efficiency and convergence for Large Language Models(https://arxiv.org/abs/2508.18182)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Scaling distributed training of Large Language Models (LLMs) requires not only algorithmic advances but also efficient utilization of heterogeneous hardware resources. While existing methods such as DiLoCo have demonstrated promising results, they often fail to fully exploit computational clusters under dynamic workloads. To address this limitation, we propose a three-stage method that combines Multi-Instance Training (MIT), Adaptive Batched DiLoCo, and switch mode mechanism. MIT allows individual nodes to run multiple lightweight training streams with different model instances in parallel and merge them to combine knowledge, increasing throughput and reducing idle time. Adaptive Batched DiLoCo dynamically adjusts local batch sizes to balance computation and communication, substantially lowering synchronization delays. Switch mode further stabilizes training by seamlessly introducing gradient accumulation once adaptive batch sizes grow beyond hardware-friendly limits. Together, these innovations improve both convergence speed and system efficiency. We also provide a theoretical estimate of the number of communications required for the full convergence of a model trained using our method.</li>
</ul>

<h3>Title: Leveraging Large Language Models for Accurate Sign Language Translation in Low-Resource Scenarios</h3>
<ul>
<li><strong>Authors: </strong>Luana Bulla, Gabriele Tuccio, Misael Mongiov√¨, Aldo Gangemi</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.CY</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.18183">https://arxiv.org/abs/2508.18183</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.18183">https://arxiv.org/pdf/2508.18183</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.18183]] Leveraging Large Language Models for Accurate Sign Language Translation in Low-Resource Scenarios(https://arxiv.org/abs/2508.18183)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, large language model</a></li>
<li><strong>Abstract: </strong>Translating natural languages into sign languages is a highly complex and underexplored task. Despite growing interest in accessibility and inclusivity, the development of robust translation systems remains hindered by the limited availability of parallel corpora which align natural language with sign language data. Existing methods often struggle to generalize in these data-scarce environments, as the few datasets available are typically domain-specific, lack standardization, or fail to capture the full linguistic richness of sign languages. To address this limitation, we propose Advanced Use of LLMs for Sign Language Translation (AulSign), a novel method that leverages Large Language Models via dynamic prompting and in-context learning with sample selection and subsequent sign association. Despite their impressive abilities in processing text, LLMs lack intrinsic knowledge of sign languages; therefore, they are unable to natively perform this kind of translation. To overcome this limitation, we associate the signs with compact descriptions in natural language and instruct the model to use them. We evaluate our method on both English and Italian languages using SignBank+, a recognized benchmark in the field, as well as the Italian LaCAM CNR-ISTC dataset. We demonstrate superior performance compared to state-of-the-art models in low-data scenario. Our findings demonstrate the effectiveness of AulSign, with the potential to enhance accessibility and inclusivity in communication technologies for underrepresented linguistic communities.</li>
</ul>

<h3>Title: Emerging Semantic Segmentation from Positive and Negative Coarse Label Learning</h3>
<ul>
<li><strong>Authors: </strong>Le Zhang, Fuping Wu, Arun Thirunavukarasu, Kevin Bronik, Thomas Nichols, Bartlomiej W. Papiez</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.18186">https://arxiv.org/abs/2508.18186</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.18186">https://arxiv.org/pdf/2508.18186</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.18186]] Emerging Semantic Segmentation from Positive and Negative Coarse Label Learning(https://arxiv.org/abs/2508.18186)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>Large annotated datasets are vital for training segmentation models, but pixel-level labeling is time-consuming, error-prone, and often requires scarce expert annotators, especially in medical imaging. In contrast, coarse annotations are quicker, cheaper, and easier to produce, even by non-experts. In this paper, we propose to use coarse drawings from both positive (target) and negative (background) classes in the image, even with noisy pixels, to train a convolutional neural network (CNN) for semantic segmentation. We present a method for learning the true segmentation label distributions from purely noisy coarse annotations using two coupled CNNs. The separation of the two CNNs is achieved by high fidelity with the characters of the noisy training annotations. We propose to add a complementary label learning that encourages estimating negative label distribution. To illustrate the properties of our method, we first use a toy segmentation dataset based on MNIST. We then present the quantitative results of experiments using publicly available datasets: Cityscapes dataset for multi-class segmentation, and retinal images for medical applications. In all experiments, our method outperforms state-of-the-art methods, particularly in the cases where the ratio of coarse annotations is small compared to the given dense annotations.</li>
</ul>

<h3>Title: Explain and Monitor Deep Learning Models for Computer Vision using Obz AI</h3>
<ul>
<li><strong>Authors: </strong>Neo Christopher Chung, Jakub Binda</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI, cs.HC, cs.SE</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.18188">https://arxiv.org/abs/2508.18188</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.18188">https://arxiv.org/pdf/2508.18188</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.18188]] Explain and Monitor Deep Learning Models for Computer Vision using Obz AI(https://arxiv.org/abs/2508.18188)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, explainability, transformer, segmentation</a></li>
<li><strong>Abstract: </strong>Deep learning has transformed computer vision (CV), achieving outstanding performance in classification, segmentation, and related tasks. Such AI-based CV systems are becoming prevalent, with applications spanning from medical imaging to surveillance. State of the art models such as convolutional neural networks (CNNs) and vision transformers (ViTs) are often regarded as ``black boxes,'' offering limited transparency into their decision-making processes. Despite a recent advancement in explainable AI (XAI), explainability remains underutilized in practical CV deployments. A primary obstacle is the absence of integrated software solutions that connect XAI techniques with robust knowledge management and monitoring frameworks. To close this gap, we have developed Obz AI, a comprehensive software ecosystem designed to facilitate state-of-the-art explainability and observability for vision AI systems. Obz AI provides a seamless integration pipeline, from a Python client library to a full-stack analytics dashboard. With Obz AI, a machine learning engineer can easily incorporate advanced XAI methodologies, extract and analyze features for outlier detection, and continuously monitor AI models in real time. By making the decision-making mechanisms of deep models interpretable, Obz AI promotes observability and responsible deployment of computer vision systems.</li>
</ul>

<h3>Title: Why Synthetic Isn't Real Yet: A Diagnostic Framework for Contact Center Dialogue Generation</h3>
<ul>
<li><strong>Authors: </strong>Rishikesh Devanathan, Varun Nathan, Ayush Kumar</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.18210">https://arxiv.org/abs/2508.18210</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.18210">https://arxiv.org/pdf/2508.18210</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.18210]] Why Synthetic Isn't Real Yet: A Diagnostic Framework for Contact Center Dialogue Generation(https://arxiv.org/abs/2508.18210)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy</a></li>
<li><strong>Abstract: </strong>Synthetic transcript generation is critical in contact center domains, where privacy and data scarcity limit model training and evaluation. Unlike prior synthetic dialogue generation work on open-domain or medical dialogues, contact center conversations are goal-oriented, role-asymmetric, and behaviorally complex, featuring disfluencies, ASR noise, and compliance-driven agent actions. In deployments where transcripts are unavailable, standard pipelines still yield derived call attributes such as Intent Summaries, Topic Flow, and QA Evaluation Forms. We leverage these as supervision signals to guide generation. To assess the quality of such outputs, we introduce a diagnostic framework of 18 linguistically and behaviorally grounded metrics for comparing real and synthetic transcripts. We benchmark four language-agnostic generation strategies, from simple prompting to characteristic-aware multi-stage approaches, alongside reference-free baselines. Results reveal persistent challenges: no method excels across all traits, with notable deficits in disfluency, sentiment, and behavioral realism. Our diagnostic tool exposes these gaps, enabling fine-grained evaluation and stress testing of synthetic dialogue across languages.</li>
</ul>

<h3>Title: Better Language Model-Based Judging Reward Modeling through Scaling Comprehension Boundaries</h3>
<ul>
<li><strong>Authors: </strong>Meiling Ning, Zhongbao Zhang, Junda Ye, Jiabao Guo, Qingyuan Guan</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.18212">https://arxiv.org/abs/2508.18212</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.18212">https://arxiv.org/pdf/2508.18212</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.18212]] Better Language Model-Based Judging Reward Modeling through Scaling Comprehension Boundaries(https://arxiv.org/abs/2508.18212)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>The emergence of LM-based judging reward modeling, represented by generative reward models, has successfully made reinforcement learning from AI feedback (RLAIF) efficient and scalable. To further advance this paradigm, we propose a core insight: this form of reward modeling shares fundamental formal consistency with natural language inference (NLI), a core task in natural language understanding. This reframed perspective points to a key path for building superior reward models: scaling the model's comprehension boundaries. Pursuing this path, exploratory experiments on NLI tasks demonstrate that the slot prediction masked language models (MLMs) incorporating contextual explanations achieve significantly better performance compared to mainstream autoregressive models. Based on this key finding, we propose ESFP-RM, a two-stage LM-based judging reward model that utilizes an explanation based slot framework for prediction to fully leverage the advantages of MLMs. Extensive experiments demonstrate that in both reinforcement learning from human feedback (RLHF) and out-of-distribution (OOD) scenarios, the ESFP-RM framework delivers more stable and generalizable reward signals compared to generative reward models.</li>
</ul>

<h3>Title: Follow My Hold: Hand-Object Interaction Reconstruction through Geometric Guidance</h3>
<ul>
<li><strong>Authors: </strong>Ayce Idil Aytekin, Helge Rhodin, Rishabh Dabral, Christian Theobalt</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.18213">https://arxiv.org/abs/2508.18213</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.18213">https://arxiv.org/pdf/2508.18213</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.18213]] Follow My Hold: Hand-Object Interaction Reconstruction through Geometric Guidance(https://arxiv.org/abs/2508.18213)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, diffusion</a></li>
<li><strong>Abstract: </strong>We propose a novel diffusion-based framework for reconstructing 3D geometry of hand-held objects from monocular RGB images by leveraging hand-object interaction as geometric guidance. Our method conditions a latent diffusion model on an inpainted object appearance and uses inference-time guidance to optimize the object reconstruction, while simultaneously ensuring plausible hand-object interactions. Unlike prior methods that rely on extensive post-processing or produce low-quality reconstructions, our approach directly generates high-quality object geometry during the diffusion process by introducing guidance with an optimization-in-the-loop design. Specifically, we guide the diffusion model by applying supervision to the velocity field while simultaneously optimizing the transformations of both the hand and the object being reconstructed. This optimization is driven by multi-modal geometric cues, including normal and depth alignment, silhouette consistency, and 2D keypoint reprojection. We further incorporate signed distance field supervision and enforce contact and non-intersection constraints to ensure physical plausibility of hand-object interaction. Our method yields accurate, robust and coherent reconstructions under occlusion while generalizing well to in-the-wild scenarios.</li>
</ul>

<h3>Title: GM-Skip: Metric-Guided Transformer Block Skipping for Efficient Vision-Language Models</h3>
<ul>
<li><strong>Authors: </strong>Lianming Huang, Haibo Hu, Qiao Li, Xin He, Nan Guan, Chun Jason Xue</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.18227">https://arxiv.org/abs/2508.18227</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.18227">https://arxiv.org/pdf/2508.18227</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.18227]] GM-Skip: Metric-Guided Transformer Block Skipping for Efficient Vision-Language Models(https://arxiv.org/abs/2508.18227)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Transformer-based Vision-Language Models (VLMs) have achieved impressive performance on tasks such as image captioning, object recognition, and visual reasoning, but their high computational cost hinders deployment in latency-sensitive applications like autonomous driving. We introduce GM-Skip, a flexible and metric-adaptive framework for Transformer block skipping that accelerates VLM inference while preserving output quality. GM-Skip features a greedy, metric-guided block selection strategy that uses metric feedback (e.g., accuracy, CIDEr) to identify redundant layers, along with a reverse-order deletion mechanism that preserves early foundational blocks to avoid performance collapse. To support diverse deployment needs, it incorporates a tunable trade-off between sparsity and performance via a score-sparsity balance objective. Experiments across multiple tasks and datasets, including COCO and CODA, show that GM-Skip consistently improves inference speed while maintaining task performance. On the COCO dataset, GM-Skip improves single-object classification accuracy on the Person category from 19.1 percent to 87.3 percent while skipping more than 40 percent of Transformer blocks. In real-world deployment, it achieves up to 45.4 percent latency reduction on single-object detection when integrated into an autonomous vehicle running this http URL, validating the effectiveness of its skip configurations and confirming its practical value in accelerating real-world inference.</li>
</ul>

<h3>Title: KillChainGraph: ML Framework for Predicting and Mapping ATT&CK Techniques</h3>
<ul>
<li><strong>Authors: </strong>Chitraksh Singh, Monisha Dhanraj, Ken Huang</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.18230">https://arxiv.org/abs/2508.18230</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.18230">https://arxiv.org/pdf/2508.18230</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.18230]] KillChainGraph: ML Framework for Predicting and Mapping ATT&CK Techniques(https://arxiv.org/abs/2508.18230)</code><input type="text"></li>
<li><strong>Keywords: </strong>defense, attack, transformer</a></li>
<li><strong>Abstract: </strong>The escalating complexity and volume of cyberattacks demand proactive detection strategies that go beyond traditional rule-based systems. This paper presents a phase-aware, multi-model machine learning framework that emulates adversarial behavior across the seven phases of the Cyber Kill Chain using the MITRE ATT&CK Enterprise dataset. Techniques are semantically mapped to phases via ATTACK-BERT, producing seven phase-specific datasets. We evaluate LightGBM, a custom Transformer encoder, fine-tuned BERT, and a Graph Neural Network (GNN), integrating their outputs through a weighted soft voting ensemble. Inter-phase dependencies are modeled using directed graphs to capture attacker movement from reconnaissance to objectives. The ensemble consistently achieved the highest scores, with F1-scores ranging from 97.47% to 99.83%, surpassing GNN performance (97.36% to 99.81%) by 0.03%--0.20% across phases. This graph-driven, ensemble-based approach enables interpretable attack path forecasting and strengthens proactive cyber defense.</li>
</ul>

<h3>Title: Sealing The Backdoor: Unlearning Adversarial Text Triggers In Diffusion Models Using Knowledge Distillation</h3>
<ul>
<li><strong>Authors: </strong>Ashwath Vaithinathan Aravindan, Abha Jha, Matthew Salaway, Atharva Sandeep Bhide, Duygu Nur Yaldiz</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.18235">https://arxiv.org/abs/2508.18235</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.18235">https://arxiv.org/pdf/2508.18235</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.18235]] Sealing The Backdoor: Unlearning Adversarial Text Triggers In Diffusion Models Using Knowledge Distillation(https://arxiv.org/abs/2508.18235)</code><input type="text"></li>
<li><strong>Keywords: </strong>secure, security, defense, attack, robust, diffusion, generative</a></li>
<li><strong>Abstract: </strong>Text-to-image diffusion models have revolutionized generative AI, but their vulnerability to backdoor attacks poses significant security risks. Adversaries can inject imperceptible textual triggers into training data, causing models to generate manipulated outputs. Although text-based backdoor defenses in classification models are well-explored, generative models lack effective mitigation techniques against. We address this by selectively erasing the model's learned associations between adversarial text triggers and poisoned outputs, while preserving overall generation quality. Our approach, Self-Knowledge Distillation with Cross-Attention Guidance (SKD-CAG), uses knowledge distillation to guide the model in correcting responses to poisoned prompts while maintaining image quality by exploiting the fact that the backdoored model still produces clean outputs in the absence of triggers. Using the cross-attention mechanism, SKD-CAG neutralizes backdoor influences at the attention level, ensuring the targeted removal of adversarial effects. Extensive experiments show that our method outperforms existing approaches, achieving removal accuracy 100\% for pixel backdoors and 93\% for style-based attacks, without sacrificing robustness or image fidelity. Our findings highlight targeted unlearning as a promising defense to secure generative models. Code and model weights can be found at this https URL .</li>
</ul>

<h3>Title: Interpretable Evaluation of AI-Generated Content with Language-Grounded Sparse Encoders</h3>
<ul>
<li><strong>Authors: </strong>Yiming Tang, Arash Lagzian, Srinivas Anumasa, Qiran Zou, Trang Nguyen, Ehsan Adeli, Ching-Yu Cheng, Yilun Du, Dianbo Liu</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.18236">https://arxiv.org/abs/2508.18236</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.18236">https://arxiv.org/pdf/2508.18236</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.18236]] Interpretable Evaluation of AI-Generated Content with Language-Grounded Sparse Encoders(https://arxiv.org/abs/2508.18236)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability, generative</a></li>
<li><strong>Abstract: </strong>While the quality of AI-generated contents, such as synthetic images, has become remarkably high, current evaluation metrics provide only coarse-grained assessments, failing to identify specific strengths and weaknesses that researchers and practitioners need for model selection and development, further limiting the scientific understanding and commercial deployment of these generative models. To address this, we introduce Language-Grounded Sparse Encoders (LanSE), a novel architecture that creates interpretable evaluation metrics by identifying interpretable visual patterns and automatically describing them in natural language. Through large-scale human evaluation (more than 11,000 annotations) and large multimodal model (LMM) based analysis, LanSE demonstrates reliable capabilities to detect interpretable visual patterns in synthetic images with more than 93\% accuracy in natural images. LanSE further provides a fine-grained evaluation framework that quantifies four key dimensions of generation quality, prompt match, visual realism, physical plausibility, and content diversity. LanSE reveals nuanced model differences invisible to existing metrics, for instance, FLUX's superior physical plausibility and SDXL-medium's strong content diversity, while aligning with human judgments. By bridging interpretability with practical evaluation needs, LanSE offers all users of generative AI models a powerful tool for model selection, quality control of synthetic content, and model improvement. These capabilities directly address the need for public confidence and safety in AI-generated content, both critical for the future of generative AI applications.</li>
</ul>

<h3>Title: PriorFormer: A Transformer for Real-time Monocular 3D Human Pose Estimation with Versatile Geometric Priors</h3>
<ul>
<li><strong>Authors: </strong>Mohamed Adjel (LAAS-GEPETTO), Vincent Bonnet (IPAL, LAAS-GEPETTO, CNRS-AIST JRL)</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.18238">https://arxiv.org/abs/2508.18238</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.18238">https://arxiv.org/pdf/2508.18238</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.18238]] PriorFormer: A Transformer for Real-time Monocular 3D Human Pose Estimation with Versatile Geometric Priors(https://arxiv.org/abs/2508.18238)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>This paper proposes a new lightweight Transformer-based lifter that maps short sequences of human 2D joint positions to 3D poses using a single camera. The proposed model takes as input geometric priors including segment lengths and camera intrinsics and is designed to operate in both calibrated and uncalibrated settings. To this end, a masking mechanism enables the model to ignore missing priors during training and inference. This yields a single versatile network that can adapt to different deployment scenarios, from fully calibrated lab environments to in-the-wild monocular videos without calibration.  The model was trained using 3D keypoints from AMASS dataset with corresponding 2D synthetic data generated by sampling random camera poses and intrinsics. It was then compared to an expert model trained, only on complete priors, and the validation was done by conducting an ablation study. Results show that both, camera and segment length priors, improve performance and that the versatile model outperforms the expert, even when all priors are available, and maintains high accuracy when priors are missing. Overall the average 3D joint center positions estimation accuracy was as low as 36mm improving state of the art by half a centimeter and at a much lower computational cost. Indeed, the proposed model runs in 380$\mu$s on GPU and 1800$\mu$s on CPU, making it suitable for deployment on embedded platforms and low-power devices.</li>
</ul>

<h3>Title: MTalk-Bench: Evaluating Speech-to-Speech Models in Multi-Turn Dialogues via Arena-style and Rubrics Protocols</h3>
<ul>
<li><strong>Authors: </strong>Yuhao Du, Qianwei Huang, Guo Zhu, Zhanchen Dai, Sunian Chen, Qiming Zhu, Yuhao Zhang, Li Zhou, Benyou Wang</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.18240">https://arxiv.org/abs/2508.18240</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.18240">https://arxiv.org/pdf/2508.18240</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.18240]] MTalk-Bench: Evaluating Speech-to-Speech Models in Multi-Turn Dialogues via Arena-style and Rubrics Protocols(https://arxiv.org/abs/2508.18240)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, large language model</a></li>
<li><strong>Abstract: </strong>The rapid advancement of speech-to-speech (S2S) large language models (LLMs) has significantly improved real-time spoken interaction. However, current evaluation frameworks remain inadequate for assessing performance in complex, multi-turn dialogues. To address this, we introduce MTalk-Bench, a multi-turn S2S benchmark covering three core dimensions: Semantic Information, Paralinguistic Information, and Ambient Sound. Each dimension includes nine realistic scenarios, along with targeted tasks to assess specific capabilities such as reasoning. Our dual-method evaluation framework combines Arena-style evaluation (pairwise comparison) and Rubrics-based evaluation (absolute scoring) for relative and absolute assessment. The benchmark includes both model and human outputs, evaluated by human evaluators and LLMs. Experimental results reveal two sets of findings. Overall performance of S2S LLMs: (1) models excel at semantic information processing yet underperform on paralinguistic information and ambient sounds perception; (2) models typically regain coherence by increasing response length, sacrificing efficiency in multi-turn dialogues; (3) modality-aware, task-specific designs outperform brute scaling. Evaluation framework and reliability: (1) Arena and Rubrics yield consistent, complementary rankings, but reliable distinctions emerge only when performance gaps are large; (2) LLM-as-a-judge aligns with humans when gaps are clear or criteria explicit, but exhibits position and length biases and is reliable on nonverbal evaluation only with text annotations. These results highlight current limitations in S2S evaluation and the need for more robust, speech-aware assessment frameworks.</li>
</ul>

<h3>Title: GSVisLoc: Generalizable Visual Localization for Gaussian Splatting Scene Representations</h3>
<ul>
<li><strong>Authors: </strong>Fadi Khatib, Dror Moran, Guy Trostianetsky, Yoni Kasten, Meirav Galun, Ronen Basri</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.18242">https://arxiv.org/abs/2508.18242</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.18242">https://arxiv.org/pdf/2508.18242</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.18242]] GSVisLoc: Generalizable Visual Localization for Gaussian Splatting Scene Representations(https://arxiv.org/abs/2508.18242)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>We introduce GSVisLoc, a visual localization method designed for 3D Gaussian Splatting (3DGS) scene representations. Given a 3DGS model of a scene and a query image, our goal is to estimate the camera's position and orientation. We accomplish this by robustly matching scene features to image features. Scene features are produced by downsampling and encoding the 3D Gaussians while image features are obtained by encoding image patches. Our algorithm proceeds in three steps, starting with coarse matching, then fine matching, and finally by applying pose refinement for an accurate final estimate. Importantly, our method leverages the explicit 3DGS scene representation for visual localization without requiring modifications, retraining, or additional reference images. We evaluate GSVisLoc on both indoor and outdoor scenes, demonstrating competitive localization performance on standard benchmarks while outperforming existing 3DGS-based baselines. Moreover, our approach generalizes effectively to novel scenes without additional training.</li>
</ul>

<h3>Title: Type-Compliant Adaptation Cascades: Adapting Programmatic LM Workflows to Data</h3>
<ul>
<li><strong>Authors: </strong>Chu-Cheng Lin, Daiyi Peng, Yifeng Lu, Ming Zhang, Eugene Ie</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.18244">https://arxiv.org/abs/2508.18244</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.18244">https://arxiv.org/pdf/2508.18244</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.18244]] Type-Compliant Adaptation Cascades: Adapting Programmatic LM Workflows to Data(https://arxiv.org/abs/2508.18244)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, large language model</a></li>
<li><strong>Abstract: </strong>Reliably composing Large Language Models (LLMs) for complex, multi-step workflows remains a significant challenge. The dominant paradigm-optimizing discrete prompts in a pipeline-is notoriously brittle and struggles to enforce the formal compliance required for structured tasks. We introduce Type-Compliant Adaptation Cascades (TACs), a framework that recasts workflow adaptation as learning typed probabilistic programs. TACs treats the entire workflow, which is composed of parameter-efficiently adapted LLMs and deterministic logic, as an unnormalized joint distribution. This enables principled, gradient-based training even with latent intermediate structures. We provide theoretical justification for our tractable optimization objective, proving that the optimization bias vanishes as the model learns type compliance. Empirically, TACs significantly outperforms state-of-the-art prompt-optimization baselines. Gains are particularly pronounced on structured tasks, improving MGSM-SymPy from $57.1\%$ to $75.9\%$ for a 27B model, MGSM from $1.6\%$ to $27.3\%$ for a 7B model. TACs offers a robust and theoretically grounded paradigm for developing reliable, task-compliant LLM systems.</li>
</ul>

<h3>Title: Demographic Biases and Gaps in the Perception of Sexism in Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Judith Tavarez-Rodr√≠guez, Fernando S√°nchez-Vega, A. Pastor L√≥pez-Monroy</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.18245">https://arxiv.org/abs/2508.18245</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.18245">https://arxiv.org/pdf/2508.18245</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.18245]] Demographic Biases and Gaps in the Perception of Sexism in Large Language Models(https://arxiv.org/abs/2508.18245)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>The use of Large Language Models (LLMs) has proven to be a tool that could help in the automatic detection of sexism. Previous studies have shown that these models contain biases that do not accurately reflect reality, especially for minority groups. Despite various efforts to improve the detection of sexist content, this task remains a significant challenge due to its subjective nature and the biases present in automated models. We explore the capabilities of different LLMs to detect sexism in social media text using the EXIST 2024 tweet dataset. It includes annotations from six distinct profiles for each tweet, allowing us to evaluate to what extent LLMs can mimic these groups' perceptions in sexism detection. Additionally, we analyze the demographic biases present in the models and conduct a statistical analysis to identify which demographic characteristics (age, gender) contribute most effectively to this task. Our results show that, while LLMs can to some extent detect sexism when considering the overall opinion of populations, they do not accurately replicate the diversity of perceptions among different demographic groups. This highlights the need for better-calibrated models that account for the diversity of perspectives across different populations.</li>
</ul>

<h3>Title: From BERT to LLMs: Comparing and Understanding Chinese Classifier Prediction in Language Models</h3>
<ul>
<li><strong>Authors: </strong>ZiqiZhang, Jianfei Ma, Emmanuele Chersoni, Jieshun You, Zhaoxin Feng</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.18253">https://arxiv.org/abs/2508.18253</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.18253">https://arxiv.org/pdf/2508.18253</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.18253]] From BERT to LLMs: Comparing and Understanding Chinese Classifier Prediction in Language Models(https://arxiv.org/abs/2508.18253)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Classifiers are an important and defining feature of the Chinese language, and their correct prediction is key to numerous educational applications. Yet, whether the most popular Large Language Models (LLMs) possess proper knowledge the Chinese classifiers is an issue that has largely remain unexplored in the Natural Language Processing (NLP) literature. To address such a question, we employ various masking strategies to evaluate the LLMs' intrinsic ability, the contribution of different sentence elements, and the working of the attention mechanisms during prediction. Besides, we explore fine-tuning for LLMs to enhance the classifier performance. Our findings reveal that LLMs perform worse than BERT, even with fine-tuning. The prediction, as expected, greatly benefits from the information about the following noun, which also explains the advantage of models with a bidirectional attention mechanism such as BERT.</li>
</ul>

<h3>Title: ANO : Faster is Better in Noisy Landscape</h3>
<ul>
<li><strong>Authors: </strong>Adrien Kegreisz</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.18258">https://arxiv.org/abs/2508.18258</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.18258">https://arxiv.org/pdf/2508.18258</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.18258]] ANO : Faster is Better in Noisy Landscape(https://arxiv.org/abs/2508.18258)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Stochastic optimizers are central to deep learning, yet widely used methods such as Adam and Adan can degrade in non-stationary or noisy environments, partly due to their reliance on momentum-based magnitude estimates. We introduce Ano, a novel optimizer that decouples direction and magnitude: momentum is used for directional smoothing, while instantaneous gradient magnitudes determine step size. This design improves robustness to gradient noise while retaining the simplicity and efficiency of first-order methods. We further propose Anolog, which removes sensitivity to the momentum coefficient by expanding its window over time via a logarithmic schedule. We establish non-convex convergence guarantees with a convergence rate similar to other sign-based methods, and empirically show that Ano provides substantial gains in noisy and non-stationary regimes such as reinforcement learning, while remaining competitive on low-noise tasks such as standard computer vision benchmarks.</li>
</ul>

<h3>Title: MIRAGE: Scaling Test-Time Inference with Parallel Graph-Retrieval-Augmented Reasoning Chains</h3>
<ul>
<li><strong>Authors: </strong>Kaiwen Wei, Rui Shan, Dongsheng Zou, Jianzhong Yang, Bi Zhao, Junnan Zhu, Jiang Zhong</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.18260">https://arxiv.org/abs/2508.18260</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.18260">https://arxiv.org/pdf/2508.18260</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.18260]] MIRAGE: Scaling Test-Time Inference with Parallel Graph-Retrieval-Augmented Reasoning Chains(https://arxiv.org/abs/2508.18260)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability</a></li>
<li><strong>Abstract: </strong>Large reasoning models (LRMs) have shown significant progress in test-time scaling through chain-of-thought prompting. Current approaches like search-o1 integrate retrieval augmented generation (RAG) into multi-step reasoning processes but rely on a single, linear reasoning chain while incorporating unstructured textual information in a flat, context-agnostic manner. As a result, these approaches can lead to error accumulation throughout the reasoning chain, which significantly limits its effectiveness in medical question-answering (QA) tasks where both accuracy and traceability are critical requirements. To address these challenges, we propose MIRAGE (Multi-chain Inference with Retrieval-Augmented Graph Exploration), a novel test-time scalable reasoning framework that performs dynamic multi-chain inference over structured medical knowledge graphs. Specifically, MIRAGE 1) decomposes complex queries into entity-grounded sub-questions, 2) executes parallel inference chains, 3) retrieves evidence adaptively via neighbor expansion and multi-hop traversal, and 4) integrates answers using cross-chain verification to resolve contradictions. Experiments on three medical QA benchmarks (GenMedGPT-5k, CMCQA, and ExplainCPE) show that MIRAGE consistently outperforms GPT-4o, Tree-of-Thought variants, and other retrieval-augmented baselines in both automatic and human evaluations. Additionally, MIRAGE improves interpretability by generating explicit reasoning chains that trace each factual claim to concrete chains within the knowledge graph, making it well-suited for complex medical reasoning scenarios. The code will be available for further research.</li>
</ul>

<h3>Title: ObjFiller-3D: Consistent Multi-view 3D Inpainting via Video Diffusion Models</h3>
<ul>
<li><strong>Authors: </strong>Haitang Feng, Jie Liu, Jie Tang, Gangshan Wu, Beiqi Chen, Jianhuang Lai, Guangcong Wang</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2508.18271">https://arxiv.org/abs/2508.18271</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2508.18271">https://arxiv.org/pdf/2508.18271</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2508.18271]] ObjFiller-3D: Consistent Multi-view 3D Inpainting via Video Diffusion Models(https://arxiv.org/abs/2508.18271)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>3D inpainting often relies on multi-view 2D image inpainting, where the inherent inconsistencies across different inpainted views can result in blurred textures, spatial discontinuities, and distracting visual artifacts. These inconsistencies pose significant challenges when striving for accurate and realistic 3D object completion, particularly in applications that demand high fidelity and structural coherence. To overcome these limitations, we propose ObjFiller-3D, a novel method designed for the completion and editing of high-quality and consistent 3D objects. Instead of employing a conventional 2D image inpainting model, our approach leverages a curated selection of state-of-the-art video editing model to fill in the masked regions of 3D objects. We analyze the representation gap between 3D and videos, and propose an adaptation of a video inpainting model for 3D scene inpainting. In addition, we introduce a reference-based 3D inpainting method to further enhance the quality of reconstruction. Experiments across diverse datasets show that compared to previous methods, ObjFiller-3D produces more faithful and fine-grained reconstructions (PSNR of 26.6 vs. NeRFiller (15.9) and LPIPS of 0.19 vs. Instant3dit (0.25)). Moreover, it demonstrates strong potential for practical deployment in real-world 3D editing applications. Project page: this https URL Code: this https URL .</li>
</ul>

<button id="copy">Copy All</button>
</article>
<script src="../../javascript/clipboard.min.js"></script>
<script src="../../javascript/clipboard.js"></script>
