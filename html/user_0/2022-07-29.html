<link rel="stylesheet" href="../../css/markdown.css" />
<article class="markdown-body">
<h2>secure</h2>
<h3>Title: Certified Everlasting Functional Encryption. (arXiv:2207.13878v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2207.13878">http://arxiv.org/abs/2207.13878</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2207.13878] Certified Everlasting Functional Encryption](http://arxiv.org/abs/2207.13878)</code></li>
<li>Summary: <p>Computational security in cryptography has a risk that computational
assumptions underlying the security are broken in the future. One solution is
to construct information-theoretically-secure protocols, but many cryptographic
primitives are known to be impossible (or unlikely) to have
information-theoretical security even in the quantum world. A nice compromise
(intrinsic to quantum) is certified everlasting security, which roughly means
the following. A receiver with possession of quantum encrypted data can issue a
certificate that shows that the receiver has deleted the encrypted data. If the
certificate is valid, the security is guaranteed even if the receiver becomes
computationally unbounded. Although several cryptographic primitives, such as
commitments and zero-knowledge, have been made certified everlasting secure,
there are many other important primitives that are not known to be certified
everlasting secure.
</p></li>
</ul>

<p>In this paper, we introduce certified everlasting FE. In this primitive, the
receiver with the ciphertext of a message m and the functional decryption key
of a function f can obtain f(m) and nothing else. The security holds even if
the adversary becomes computationally unbounded after issuing a valid
certificate. We, first, construct certified everlasting FE for P/poly circuits
where only a single key query is allowed for the adversary. We, then, extend it
to q-bounded one for NC1 circuits where q-bounded means that q key queries are
allowed for the adversary with an a priori bounded polynomial q. For the
construction of certified everlasting FE, we introduce and construct certified
everlasting versions of secret-key encryption, public-key encryption, receiver
non-committing encryption, and a garbling scheme, which are of independent
interest.
</p>

<h3>Title: Verifiable Encodings for Secure Homomorphic Analytics. (arXiv:2207.14071v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2207.14071">http://arxiv.org/abs/2207.14071</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2207.14071] Verifiable Encodings for Secure Homomorphic Analytics](http://arxiv.org/abs/2207.14071)</code></li>
<li>Summary: <p>Homomorphic encryption, which enables the execution of arithmetic operations
directly on ciphertexts, is a promising solution for protecting privacy of
cloud-delegated computations on sensitive data. However, the correctness of the
computation result is not ensured. We propose two error detection encodings and
build authenticators that enable practical client-verification of cloud-based
homomorphic computations under different trade-offs and without compromising on
the features of the encryption algorithm. Our authenticators operate on top of
trending ring learning with errors based fully homomorphic encryption schemes
over the integers. We implement our solution in VERITAS, a ready-to-use system
for verification of outsourced computations executed over encrypted data. We
show that contrary to prior work VERITAS supports verification of any
homomorphic operation and we demonstrate its practicality for various
applications, such as ride-hailing, genomic-data analysis, encrypted search,
and machine-learning training and inference.
</p></li>
</ul>

<h2>security</h2>
<h3>Title: Will AI Make Cyber Swords or Shields: A few mathematical models of technological progress. (arXiv:2207.13825v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2207.13825">http://arxiv.org/abs/2207.13825</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2207.13825] Will AI Make Cyber Swords or Shields: A few mathematical models of technological progress](http://arxiv.org/abs/2207.13825)</code></li>
<li>Summary: <p>We aim to demonstrate the value of mathematical models for policy debates
about technological progress in cybersecurity by considering phishing,
vulnerability discovery, and the dynamics between patching and exploitation. We
then adjust the inputs to those mathematical models to match some possible
advances in their underlying technology. We find that AI's impact on phishing
may be overestimated but could lead to more attacks going undetected. Advances
in vulnerability discovery have the potential to help attackers more than
defenders. And automation that writes exploits is more useful to attackers than
automation that writes patches, although advances that help deploy patches
faster have the potential to be more impactful than either.
</p></li>
</ul>

<h3>Title: Gotham Testbed: a Reproducible IoT Testbed for Security Experiments and Dataset Generation. (arXiv:2207.13981v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2207.13981">http://arxiv.org/abs/2207.13981</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2207.13981] Gotham Testbed: a Reproducible IoT Testbed for Security Experiments and Dataset Generation](http://arxiv.org/abs/2207.13981)</code></li>
<li>Summary: <p>The scarcity of available Internet of Things (IoT) datasets remains a
limiting factor in developing machine learning based security systems. Static
datasets get outdated due to evolving IoT threat landscape. Meanwhile, the
testbeds used to generate them are rarely published. This paper presents the
Gotham testbed, a reproducible and flexible network security testbed,
implemented as a middleware over the GNS3 emulator, that is extendable to
accommodate new emulated devices, services or attackers. The testbed is used to
build an IoT scenario composed of 100 emulated devices communicating via MQTT,
CoAP and RTSP protocols in a topology composed of 30 switches and 10 routers.
The scenario presents three threat actors, including the entire Mirai botnet
lifecycle and additional red-teaming tools performing DoS, scanning and various
attacks targeting the MQTT and CoAP protocols. The generated network traffic
and application logs can be used to capture datasets containing legitimate and
attacking traces. We hope that researchers can leverage the testbed and adapt
it to include other types of devices and state-of-the-art attacks to generate
new datasets that reflect the current threat landscape and IoT protocols. The
source code to reproduce the scenario is publicly accessible.
</p></li>
</ul>

<h3>Title: Analysis of Polkadot: Architecture, Internals, and Contradictions. (arXiv:2207.14128v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2207.14128">http://arxiv.org/abs/2207.14128</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2207.14128] Analysis of Polkadot: Architecture, Internals, and Contradictions](http://arxiv.org/abs/2207.14128)</code></li>
<li>Summary: <p>Polkadot is a network protocol launched in 2020 with the ambition of
unlocking the full potential of blockchain technologies. Its novel multi-chain
protocol allows arbitrary data to be transferred across heterogeneous
blockchains, enabling the implementation of a wide range of novel use cases.
The Polkadot architecture is based on the principles of sharding, which
promises to solve scalability and interoperability shortcomings that encumber
many existing blockchain-based systems. Lured by these impressive features,
investors immediately appreciated the Polkadot project, which is now firmly
ranked among the top 10 cryptocurrencies by capitalization (around 20 Billions
USD). However, Polkadot has not received the same level of attention from
academia that other proposals in the crypto domain have received so far, like
Bitcoin, Ethereum, and Algorand, to cite a few. Polkadot architecture is
described and discussed only in the grey literature, and very little is known
about its internals.
</p></li>
</ul>

<p>In this paper, we provide the first systematic study on the Polkadot
environment, detailing its protocols, governance, and economic model. Then, we
identify several limitations -- supported by an empirical analysis of its
ledger -- that could severely affect the scalability and overall security of
the network. Finally, based on our analysis, we provide future directions to
inspire researchers to investigate further the Polkadot ecosystem and its
pitfalls in terms of performance, security, and network aspects.
</p>

<h3>Title: Exploiting and Defending Against the Approximate Linearity of Apple's NeuralHash. (arXiv:2207.14258v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2207.14258">http://arxiv.org/abs/2207.14258</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2207.14258] Exploiting and Defending Against the Approximate Linearity of Apple's NeuralHash](http://arxiv.org/abs/2207.14258)</code></li>
<li>Summary: <p>Perceptual hashes map images with identical semantic content to the same
$n$-bit hash value, while mapping semantically-different images to different
hashes. These algorithms carry important applications in cybersecurity such as
copyright infringement detection, content fingerprinting, and surveillance.
Apple's NeuralHash is one such system that aims to detect the presence of
illegal content on users' devices without compromising consumer privacy. We
make the surprising discovery that NeuralHash is approximately linear, which
inspires the development of novel black-box attacks that can (i) evade
detection of "illegal" images, (ii) generate near-collisions, and (iii) leak
information about hashed images, all without access to model parameters. These
vulnerabilities pose serious threats to NeuralHash's security goals; to address
them, we propose a simple fix using classical cryptographic standards.
</p></li>
</ul>

<h2>privacy</h2>
<h3>Title: Progressive Voronoi Diagram Subdivision: Towards A Holistic Geometric Framework for Exemplar-free Class-Incremental Learning. (arXiv:2207.14202v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2207.14202">http://arxiv.org/abs/2207.14202</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2207.14202] Progressive Voronoi Diagram Subdivision: Towards A Holistic Geometric Framework for Exemplar-free Class-Incremental Learning](http://arxiv.org/abs/2207.14202)</code></li>
<li>Summary: <p>Exemplar-free Class-incremental Learning (CIL) is a challenging problem
because rehearsing data from previous phases is strictly prohibited, causing
catastrophic forgetting of Deep Neural Networks (DNNs). In this paper, we
present iVoro, a holistic framework for CIL, derived from computational
geometry. We found Voronoi Diagram (VD), a classical model for space
subdivision, is especially powerful for solving the CIL problem, because VD
itself can be constructed favorably in an incremental manner -- the newly added
sites (classes) will only affect the proximate classes, making the
non-contiguous classes hardly forgettable. Further, in order to find a better
set of centers for VD construction, we colligate DNN with VD using Power
Diagram and show that the VD structure can be optimized by integrating local
DNN models using a divide-and-conquer algorithm. Moreover, our VD construction
is not restricted to the deep feature space, but is also applicable to multiple
intermediate feature spaces, promoting VD to be multi-centered VD (CIVD) that
efficiently captures multi-grained features from DNN. Importantly, iVoro is
also capable of handling uncertainty-aware test-time Voronoi cell assignment
and has exhibited high correlations between geometric uncertainty and
predictive accuracy (up to ~0.9). Putting everything together, iVoro achieves
up to 25.26%, 37.09%, and 33.21% improvements on CIFAR-100, TinyImageNet, and
ImageNet-Subset, respectively, compared to the state-of-the-art non-exemplar
CIL approaches. In conclusion, iVoro enables highly accurate,
privacy-preserving, and geometrically interpretable CIL that is particularly
useful when cross-phase data sharing is forbidden, e.g. in medical
applications. Our code is available at https://machunwei.github.io/ivoro.
</p></li>
</ul>

<h3>Title: Precision-based attacks and interval refining: how to break, then fix, differential privacy on finite computers. (arXiv:2207.13793v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2207.13793">http://arxiv.org/abs/2207.13793</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2207.13793] Precision-based attacks and interval refining: how to break, then fix, differential privacy on finite computers](http://arxiv.org/abs/2207.13793)</code></li>
<li>Summary: <p>Despite being raised as a problem over ten years ago, the imprecision of
floating point arithmetic continues to cause privacy failures in the
implementations of differentially private noise mechanisms. In this paper, we
highlight a new class of vulnerabilities, which we call \emph{precision-based
attacks}, and which affect several open source libraries. To address this
vulnerability and implement differentially private mechanisms on floating-point
space in a safe way, we propose a novel technique, called \emph{interval
refining}. This technique has minimal error, provable privacy, and broad
applicability. We use interval refining to design and implement a variant of
the Laplace mechanism that is equivalent to sampling from the Laplace
distribution and rounding to a float. We report on the performance of this
approach, and discuss how interval refining can be used to implement other
mechanisms safely, including the Gaussian mechanism and the exponential
mechanism.
</p></li>
</ul>

<h3>Title: Privacy-Preserving Federated Recurrent Neural Networks. (arXiv:2207.13947v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2207.13947">http://arxiv.org/abs/2207.13947</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2207.13947] Privacy-Preserving Federated Recurrent Neural Networks](http://arxiv.org/abs/2207.13947)</code></li>
<li>Summary: <p>We present RHODE, a novel system that enables privacy-preserving training of
and prediction on Recurrent Neural Networks (RNNs) in a federated learning
setting by relying on multiparty homomorphic encryption (MHE). RHODE preserves
the confidentiality of the training data, the model, and the prediction data;
and it mitigates the federated learning attacks that target the gradients under
a passive-adversary threat model. We propose a novel packing scheme,
multi-dimensional packing, for a better utilization of Single Instruction,
Multiple Data (SIMD) operations under encryption. With multi-dimensional
packing, RHODE enables the efficient processing, in parallel, of a batch of
samples. To avoid the exploding gradients problem, we also provide several
clip-by-value approximations for enabling gradient clipping under encryption.
We experimentally show that the model performance with RHODE remains similar to
non-secure solutions both for homogeneous and heterogeneous data distribution
among the data holders. Our experimental evaluation shows that RHODE scales
linearly with the number of data holders and the number of timesteps,
sub-linearly and sub-quadratically with the number of features and the number
of hidden units of RNNs, respectively. To the best of our knowledge, RHODE is
the first system that provides the building blocks for the training of RNNs and
its variants, under encryption in a federated learning setting.
</p></li>
</ul>

<h3>Title: One-Pass Learning via Bridging Orthogonal Gradient Descent and Recursive Least-Squares. (arXiv:2207.13853v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2207.13853">http://arxiv.org/abs/2207.13853</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2207.13853] One-Pass Learning via Bridging Orthogonal Gradient Descent and Recursive Least-Squares](http://arxiv.org/abs/2207.13853)</code></li>
<li>Summary: <p>While deep neural networks are capable of achieving state-of-the-art
performance in various domains, their training typically requires iterating for
many passes over the dataset. However, due to computational and memory
constraints and potential privacy concerns, storing and accessing all the data
is impractical in many real-world scenarios where the data arrives in a stream.
In this paper, we investigate the problem of one-pass learning, in which a
model is trained on sequentially arriving data without retraining on previous
datapoints. Motivated by the increasing use of overparameterized models, we
develop Orthogonal Recursive Fitting (ORFit), an algorithm for one-pass
learning which seeks to perfectly fit every new datapoint while changing the
parameters in a direction that causes the least change to the predictions on
previous datapoints. By doing so, we bridge two seemingly distinct algorithms
in adaptive filtering and machine learning, namely the recursive least-squares
(RLS) algorithm and orthogonal gradient descent (OGD). Our algorithm uses the
memory efficiently by exploiting the structure of the streaming data via an
incremental principal component analysis (IPCA). Further, we show that, for
overparameterized linear models, the parameter vector obtained by our algorithm
is what stochastic gradient descent (SGD) would converge to in the standard
multi-pass setting. Finally, we generalize the results to the nonlinear setting
for highly overparameterized models, relevant for deep learning. Our
experiments show the effectiveness of the proposed method compared to the
baselines.
</p></li>
</ul>

<h3>Title: Gender In Gender Out: A Closer Look at User Attributes in Context-Aware Recommendation. (arXiv:2207.14218v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2207.14218">http://arxiv.org/abs/2207.14218</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2207.14218] Gender In Gender Out: A Closer Look at User Attributes in Context-Aware Recommendation](http://arxiv.org/abs/2207.14218)</code></li>
<li>Summary: <p>This paper studies user attributes in light of current concerns in the
recommender system community: diversity, coverage, calibration, and data
minimization. In experiments with a conventional context-aware recommender
system that leverages side information, we show that user attributes do not
always improve recommendation. Then, we demonstrate that user attributes can
negatively impact diversity and coverage. Finally, we investigate the amount of
information about users that ``survives'' from the training data into the
recommendation lists produced by the recommender. This information is a weak
signal that could in the future be exploited for calibration or studied further
as a privacy leak.
</p></li>
</ul>

<h2>protect</h2>
<h2>defense</h2>
<h2>attack</h2>
<h3>Title: Label-Only Membership Inference Attack against Node-Level Graph Neural Networks. (arXiv:2207.13766v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2207.13766">http://arxiv.org/abs/2207.13766</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2207.13766] Label-Only Membership Inference Attack against Node-Level Graph Neural Networks](http://arxiv.org/abs/2207.13766)</code></li>
<li>Summary: <p>Graph Neural Networks (GNNs), inspired by Convolutional Neural Networks
(CNNs), aggregate the message of nodes' neighbors and structure information to
acquire expressive representations of nodes for node classification, graph
classification, and link prediction. Previous studies have indicated that GNNs
are vulnerable to Membership Inference Attacks (MIAs), which infer whether a
node is in the training data of GNNs and leak the node's private information,
like the patient's disease history. The implementation of previous MIAs takes
advantage of the models' probability output, which is infeasible if GNNs only
provide the prediction label (label-only) for the input.
</p></li>
</ul>

<p>In this paper, we propose a label-only MIA against GNNs for node
classification with the help of GNNs' flexible prediction mechanism, e.g.,
obtaining the prediction label of one node even when neighbors' information is
unavailable. Our attacking method achieves around 60\% accuracy, precision, and
Area Under the Curve (AUC) for most datasets and GNN models, some of which are
competitive or even better than state-of-the-art probability-based MIAs
implemented under our environment and settings. Additionally, we analyze the
influence of the sampling method, model selection approach, and overfitting
level on the attack performance of our label-only MIA. Both of those factors
have an impact on the attack performance. Then, we consider scenarios where
assumptions about the adversary's additional dataset (shadow dataset) and extra
information about the target model are relaxed. Even in those scenarios, our
label-only MIA achieves a better attack performance in most cases. Finally, we
explore the effectiveness of possible defenses, including Dropout,
Regularization, Normalization, and Jumping knowledge. None of those four
defenses prevent our attack completely.
</p>

<h2>robust</h2>
<h3>Title: On the Effects of Different Types of Label Noise in Multi-Label Remote Sensing Image Classification. (arXiv:2207.13975v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2207.13975">http://arxiv.org/abs/2207.13975</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2207.13975] On the Effects of Different Types of Label Noise in Multi-Label Remote Sensing Image Classification](http://arxiv.org/abs/2207.13975)</code></li>
<li>Summary: <p>The development of accurate methods for multi-label classification (MLC) of
remote sensing (RS) images is one of the most important research topics in RS.
To address MLC problems, the use of deep neural networks that require a high
number of reliable training images annotated by multiple land-cover class
labels (multi-labels) have been found popular in RS. However, collecting such
annotations is time-consuming and costly. A common procedure to obtain
annotations at zero labeling cost is to rely on thematic products or
crowdsourced labels. As a drawback, these procedures come with the risk of
label noise that can distort the learning process of the MLC algorithms. In the
literature, most label noise robust methods are designed for single label
classification (SLC) problems in computer vision (CV), where each image is
annotated by a single label. Unlike SLC, label noise in MLC can be associated
with: 1) subtractive label-noise (a land cover class label is not assigned to
an image while that class is present in the image); 2) additive label-noise (a
land cover class label is assigned to an image although that class is not
present in the given image); and 3) mixed label-noise (a combination of both).
In this paper, we investigate three different noise robust CV SLC methods and
adapt them to be robust for multi-label noise scenarios in RS. During
experiments we study the effects of different types of multi-label noise and
evaluate the adapted methods rigorously. To this end, we also introduce a
synthetic multi-label noise injection strategy that is more adequate to
simulate operational scenarios compared to the uniform label noise injection
strategy, in which the labels of absent and present classes are flipped at
uniform probability. Further, we study the relevance of different evaluation
metrics in MLC problems under noisy multi-labels.
</p></li>
</ul>

<h3>Title: CuDi: Curve Distillation for Efficient and Controllable Exposure Adjustment. (arXiv:2207.14273v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2207.14273">http://arxiv.org/abs/2207.14273</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2207.14273] CuDi: Curve Distillation for Efficient and Controllable Exposure Adjustment](http://arxiv.org/abs/2207.14273)</code></li>
<li>Summary: <p>We present Curve Distillation, CuDi, for efficient and controllable exposure
adjustment without the requirement of paired or unpaired data during training.
Our method inherits the zero-reference learning and curve-based framework from
an effective low-light image enhancement method, Zero-DCE, with further speed
up in its inference speed, reduction in its model size, and extension to
controllable exposure adjustment. The improved inference speed and lightweight
model are achieved through novel curve distillation that approximates the
time-consuming iterative operation in the conventional curve-based framework by
high-order curve's tangent line. The controllable exposure adjustment is made
possible with a new self-supervised spatial exposure control loss that
constrains the exposure levels of different spatial regions of the output to be
close to the brightness distribution of an exposure map serving as an input
condition. Different from most existing methods that can only correct either
underexposed or overexposed photos, our approach corrects both underexposed and
overexposed photos with a single model. Notably, our approach can additionally
adjust the exposure levels of a photo globally or locally with the guidance of
an input condition exposure map, which can be pre-defined or manually set in
the inference stage. Through extensive experiments, we show that our method is
appealing for its fast, robust, and flexible performance, outperforming
state-of-the-art methods in real scenes. Project page:
https://li-chongyi.github.io/CuDi_files/.
</p></li>
</ul>

<h3>Title: Initialization and Alignment for Adversarial Texture Optimization. (arXiv:2207.14289v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2207.14289">http://arxiv.org/abs/2207.14289</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2207.14289] Initialization and Alignment for Adversarial Texture Optimization](http://arxiv.org/abs/2207.14289)</code></li>
<li>Summary: <p>While recovery of geometry from image and video data has received a lot of
attention in computer vision, methods to capture the texture for a given
geometry are less mature. Specifically, classical methods for texture
generation often assume clean geometry and reasonably well-aligned image data.
While very recent methods, e.g., adversarial texture optimization, better
handle lower-quality data obtained from hand-held devices, we find them to
still struggle frequently. To improve robustness, particularly of recent
adversarial texture optimization, we develop an explicit initialization and an
alignment procedure. It deals with complex geometry due to a robust mapping of
the geometry to the texture map and a hard-assignment-based initialization. It
deals with misalignment of geometry and images by integrating fast
image-alignment into the texture refinement optimization. We demonstrate
efficacy of our texture generation on a dataset of 11 scenes with a total of
2807 frames, observing 7.8% and 11.1% relative improvements regarding
perceptual and sharpness measurements.
</p></li>
</ul>

<h3>Title: Branch Ranking for Efficient Mixed-Integer Programming via Offline Ranking-based Policy Learning. (arXiv:2207.13701v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2207.13701">http://arxiv.org/abs/2207.13701</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2207.13701] Branch Ranking for Efficient Mixed-Integer Programming via Offline Ranking-based Policy Learning](http://arxiv.org/abs/2207.13701)</code></li>
<li>Summary: <p>Deriving a good variable selection strategy in branch-and-bound is essential
for the efficiency of modern mixed-integer programming (MIP) solvers. With MIP
branching data collected during the previous solution process, learning to
branch methods have recently become superior over heuristics. As
branch-and-bound is naturally a sequential decision making task, one should
learn to optimize the utility of the whole MIP solving process instead of being
myopic on each step. In this work, we formulate learning to branch as an
offline reinforcement learning (RL) problem, and propose a long-sighted hybrid
search scheme to construct the offline MIP dataset, which values the long-term
utilities of branching decisions. During the policy training phase, we deploy a
ranking-based reward assignment scheme to distinguish the promising samples
from the long-term or short-term view, and train the branching model named
Branch Ranking via offline policy learning. Experiments on synthetic MIP
benchmarks and real-world tasks demonstrate that Branch Rankink is more
efficient and robust, and can better generalize to large scales of MIP
instances compared to the widely used heuristics and state-of-the-art
learning-based branching models.
</p></li>
</ul>

<h3>Title: Measuring Difficulty of Novelty Reaction. (arXiv:2207.13857v1 [cs.AI])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2207.13857">http://arxiv.org/abs/2207.13857</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2207.13857] Measuring Difficulty of Novelty Reaction](http://arxiv.org/abs/2207.13857)</code></li>
<li>Summary: <p>Current AI systems are designed to solve close-world problems with the
assumption that the underlying world is remaining more or less the same.
However, when dealing with real-world problems such assumptions can be invalid
as sudden and unexpected changes can occur. To effectively deploy AI-powered
systems in the real world, AI systems should be able to deal with open-world
novelty quickly. Inevitably, dealing with open-world novelty raises an
important question of novelty difficulty. Knowing whether one novelty is harder
to deal with than another, can help researchers to train their systems
systematically. In addition, it can also serve as a measurement of the
performance of novelty robust AI systems. In this paper, we propose to define
the novelty reaction difficulty as a relative difficulty of performing the
known task after the introduction of the novelty. We propose a universal method
that can be applied to approximate the difficulty. We present the
approximations of the difficulty using our method and show how it aligns with
the results of the evaluation of AI agents designed to deal with novelty.
</p></li>
</ul>

<h3>Title: Towards Robust Ad Hoc Teamwork Agents By Creating Diverse Training Teammates. (arXiv:2207.14138v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2207.14138">http://arxiv.org/abs/2207.14138</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2207.14138] Towards Robust Ad Hoc Teamwork Agents By Creating Diverse Training Teammates](http://arxiv.org/abs/2207.14138)</code></li>
<li>Summary: <p>Ad hoc teamwork (AHT) is the problem of creating an agent that must
collaborate with previously unseen teammates without prior coordination. Many
existing AHT methods can be categorised as type-based methods, which require a
set of predefined teammates for training. Designing teammate types for training
is a challenging issue that determines the generalisation performance of agents
when dealing with teammate types unseen during training. In this work, we
propose a method to discover diverse teammate types based on maximising best
response diversity metrics. We show that our proposed approach yields teammate
types that require a wider range of best responses from the learner during
collaboration, which potentially improves the robustness of a learner's
performance in AHT compared to alternative methods.
</p></li>
</ul>

<h3>Title: Diversity Boosted Learning for Domain Generalization with Large Number of Domains. (arXiv:2207.13865v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2207.13865">http://arxiv.org/abs/2207.13865</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2207.13865] Diversity Boosted Learning for Domain Generalization with Large Number of Domains](http://arxiv.org/abs/2207.13865)</code></li>
<li>Summary: <p>Machine learning algorithms minimizing the average training loss usually
suffer from poor generalization performance due to the greedy exploitation of
correlations among the training data, which are not stable under distributional
shifts. It inspires various works for domain generalization (DG), where a
series of methods, such as Causal Matching and FISH, work by pairwise domain
operations. They would need $O(n^2)$ pairwise domain operations with $n$
domains, where each one is often highly expensive. Moreover, while a common
objective in the DG literature is to learn invariant representations against
domain-induced spurious correlations, we highlight the importance of mitigating
spurious correlations caused by objects. Based on the observation that
diversity helps mitigate spurious correlations, we propose a Diversity boosted
twO-level saMplIng framework (DOMI) utilizing Determinantal Point Processes
(DPPs) to efficiently sample the most informative ones among large number of
domains. We show that DOMI helps train robust models against spurious
correlations from both domain-side and object-side, substantially enhancing the
performance of the backbone DG algorithms on rotated MNIST, rotated Fashion
MNIST, and iwildcam datasets.
</p></li>
</ul>

<h2>biometric</h2>
<h2>steal</h2>
<h2>extraction</h2>
<h3>Title: Meta-Learning based Degradation Representation for Blind Super-Resolution. (arXiv:2207.13963v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2207.13963">http://arxiv.org/abs/2207.13963</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2207.13963] Meta-Learning based Degradation Representation for Blind Super-Resolution](http://arxiv.org/abs/2207.13963)</code></li>
<li>Summary: <p>The most of CNN based super-resolution (SR) methods assume that the
degradation is known (\eg, bicubic). These methods will suffer a severe
performance drop when the degradation is different from their assumption.
Therefore, some approaches attempt to train SR networks with the complex
combination of multiple degradations to cover the real degradation space. To
adapt to multiple unknown degradations, introducing an explicit degradation
estimator can actually facilitate SR performance. However, previous explicit
degradation estimation methods usually predict Gaussian blur with the
supervision of groundtruth blur kernels, and estimation errors may lead to SR
failure. Thus, it is necessary to design a method that can extract implicit
discriminative degradation representation. To this end, we propose a
Meta-Learning based Region Degradation Aware SR Network (MRDA), including
Meta-Learning Network (MLN), Degradation Extraction Network (DEN), and Region
Degradation Aware SR Network (RDAN). To handle the lack of groundtruth
degradation, we use the MLN to rapidly adapt to the specific complex
degradation after several iterations and extract implicit degradation
information. Subsequently, a teacher network MRDA$_{T}$ is designed to further
utilize the degradation information extracted by MLN for SR. However, MLN
requires iterating on paired low-resolution (LR) and corresponding
high-resolution (HR) images, which is unavailable in the inference phase.
Therefore, we adopt knowledge distillation (KD) to make the student network
learn to directly extract the same implicit degradation representation (IDR) as
the teacher from LR images.
</p></li>
</ul>

<h3>Title: Combining human parsing with analytical feature extraction and ranking schemes for high-generalization person reidentification. (arXiv:2207.14243v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2207.14243">http://arxiv.org/abs/2207.14243</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2207.14243] Combining human parsing with analytical feature extraction and ranking schemes for high-generalization person reidentification](http://arxiv.org/abs/2207.14243)</code></li>
<li>Summary: <p>Person reidentification (re-ID) has been receiving increasing attention in
recent years due to its importance for both science and society. Machine
learning and particularly Deep Learning (DL) has become the main re-id tool
that allowed researches to achieve unprecedented accuracy levels on benchmark
datasets. However, there is a known problem of poor generalization of DL
models. That is, models trained to achieve high accuracy on one dataset perform
poorly on other ones and require re-training. To address this issue, we present
a model without trainable parameters which shows great potential for high
generalization. It combines a fully analytical feature extraction and
similarity ranking scheme with DL-based human parsing used to obtain the
initial subregion classification. We show that such combination to a high
extent eliminates the drawbacks of existing analytical methods. We use
interpretable color and texture features which have human-readable similarity
measures associated with them. To verify the proposed method we conduct
experiments on Market1501 and CUHK03 datasets achieving competitive rank-1
accuracy comparable with that of DL-models. Most importantly we show that our
method achieves 63.9% and 93.5% rank-1 cross-domain accuracy when applied to
transfer learning tasks. It is significantly higher than previously reported
30-50% transfer accuracy. We discuss the potential ways of adding new features
to further improve the model. We also show the advantage of interpretable
features for constructing human-generated queries from verbal description to
conduct search without a query image.
</p></li>
</ul>

<h3>Title: The Leaf Clinical Trials Corpus: a new resource for query generation from clinical trial eligibility criteria. (arXiv:2207.13757v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2207.13757">http://arxiv.org/abs/2207.13757</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2207.13757] The Leaf Clinical Trials Corpus: a new resource for query generation from clinical trial eligibility criteria](http://arxiv.org/abs/2207.13757)</code></li>
<li>Summary: <p>Identifying cohorts of patients based on eligibility criteria such as medical
conditions, procedures, and medication use is critical to recruitment for
clinical trials. Such criteria are often most naturally described in free-text,
using language familiar to clinicians and researchers. In order to identify
potential participants at scale, these criteria must first be translated into
queries on clinical databases, which can be labor-intensive and error-prone.
Natural language processing (NLP) methods offer a potential means of such
conversion into database queries automatically. However they must first be
trained and evaluated using corpora which capture clinical trials criteria in
sufficient detail. In this paper, we introduce the Leaf Clinical Trials (LCT)
corpus, a human-annotated corpus of over 1,000 clinical trial eligibility
criteria descriptions using highly granular structured labels capturing a range
of biomedical phenomena. We provide details of our schema, annotation process,
corpus quality, and statistics. Additionally, we present baseline information
extraction results on this corpus as benchmarks for future work.
</p></li>
</ul>

<h3>Title: MLRIP: Pre-training a military language representation model with informative factual knowledge and professional knowledge base. (arXiv:2207.13929v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2207.13929">http://arxiv.org/abs/2207.13929</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2207.13929] MLRIP: Pre-training a military language representation model with informative factual knowledge and professional knowledge base](http://arxiv.org/abs/2207.13929)</code></li>
<li>Summary: <p>Incorporating prior knowledge into pre-trained language models has proven to
be effective for knowledge-driven NLP tasks, such as entity typing and relation
extraction. Current pre-training procedures usually inject external knowledge
into models by using knowledge masking, knowledge fusion and knowledge
replacement. However, factual information contained in the input sentences have
not been fully mined, and the external knowledge for injecting have not been
strictly checked. As a result, the context information cannot be fully
exploited and extra noise will be introduced or the amount of knowledge
injected is limited. To address these issues, we propose MLRIP, which modifies
the knowledge masking strategies proposed by ERNIE-Baidu, and introduce a
two-stage entity replacement strategy. Extensive experiments with comprehensive
analyses illustrate the superiority of MLRIP over BERT-based models in military
knowledge-driven NLP tasks.
</p></li>
</ul>

<h3>Title: Unsupervised Frequent Pattern Mining for CEP. (arXiv:2207.14017v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2207.14017">http://arxiv.org/abs/2207.14017</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2207.14017] Unsupervised Frequent Pattern Mining for CEP](http://arxiv.org/abs/2207.14017)</code></li>
<li>Summary: <p>Complex Event Processing (CEP) is a set of methods that allow efficient
knowledge extraction from massive data streams using complex and highly
descriptive patterns. Numerous applications, such as online finance, healthcare
monitoring and fraud detection use CEP technologies to capture critical alerts,
potential threats, or vital notifications in real time. As of today, in many
fields, patterns are manually defined by human experts. However, desired
patterns often contain convoluted relations that are difficult for humans to
detect, and human expertise is scarce in many domains.
</p></li>
</ul>

<p>We present REDEEMER (REinforcement baseD cEp pattErn MinER), a novel
reinforcement and active learning approach aimed at mining CEP patterns that
allow expansion of the knowledge extracted while reducing the human effort
required. This approach includes a novel policy gradient method for vast
multivariate spaces and a new way to combine reinforcement and active learning
for CEP rule learning while minimizing the number of labels needed for
training.
</p>
<p>REDEEMER aims to enable CEP integration in domains that could not utilize it
before. To the best of our knowledge, REDEEMER is the first system that
suggests new CEP rules that were not observed beforehand, and is the first
method aimed for increasing pattern knowledge in fields where experts do not
possess sufficient information required for CEP tools.
</p>
<p>Our experiments on diverse data-sets demonstrate that REDEEMER is able to
extend pattern knowledge while outperforming several state-of-the-art
reinforcement learning methods for pattern mining.
</p>

<h2>membership infer</h2>
<h2>federate</h2>
<h3>Title: Federated Learning for IoUT: Concepts, Applications, Challenges and Opportunities. (arXiv:2207.13976v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2207.13976">http://arxiv.org/abs/2207.13976</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2207.13976] Federated Learning for IoUT: Concepts, Applications, Challenges and Opportunities](http://arxiv.org/abs/2207.13976)</code></li>
<li>Summary: <p>Internet of Underwater Things (IoUT) have gained rapid momentum over the past
decade with applications spanning from environmental monitoring and
exploration, defence applications, etc. The traditional IoUT systems use
machine learning (ML) approaches which cater the needs of reliability,
efficiency and timeliness. However, an extensive review of the various studies
conducted highlight the significance of data privacy and security in IoUT
frameworks as a predominant factor in achieving desired outcomes in mission
critical applications. Federated learning (FL) is a secured, decentralized
framework which is a recent development in machine learning, that will help in
fulfilling the challenges faced by conventional ML approaches in IoUT. This
paper presents an overview of the various applications of FL in IoUT, its
challenges, open issues and indicates direction of future research prospects.
</p></li>
</ul>

<h3>Title: FedVARP: Tackling the Variance Due to Partial Client Participation in Federated Learning. (arXiv:2207.14130v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2207.14130">http://arxiv.org/abs/2207.14130</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2207.14130] FedVARP: Tackling the Variance Due to Partial Client Participation in Federated Learning](http://arxiv.org/abs/2207.14130)</code></li>
<li>Summary: <p>Data-heterogeneous federated learning (FL) systems suffer from two
significant sources of convergence error: 1) client drift error caused by
performing multiple local optimization steps at clients, and 2) partial client
participation error caused by the fact that only a small subset of the edge
clients participate in every training round. We find that among these, only the
former has received significant attention in the literature. To remedy this, we
propose FedVARP, a novel variance reduction algorithm applied at the server
that eliminates error due to partial client participation. To do so, the server
simply maintains in memory the most recent update for each client and uses
these as surrogate updates for the non-participating clients in every round.
Further, to alleviate the memory requirement at the server, we propose a novel
clustering-based variance reduction algorithm ClusterFedVARP. Unlike previously
proposed methods, both FedVARP and ClusterFedVARP do not require additional
computation at clients or communication of additional optimization parameters.
Through extensive experiments, we show that FedVARP outperforms
state-of-the-art methods, and ClusterFedVARP achieves performance comparable to
FedVARP with much less memory requirements.
</p></li>
</ul>

<h2>fair</h2>
<h2>interpretability</h2>
<h3>Title: Safety-Enhanced Autonomous Driving Using Interpretable Sensor Fusion Transformer. (arXiv:2207.14024v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2207.14024">http://arxiv.org/abs/2207.14024</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2207.14024] Safety-Enhanced Autonomous Driving Using Interpretable Sensor Fusion Transformer](http://arxiv.org/abs/2207.14024)</code></li>
<li>Summary: <p>Large-scale deployment of autonomous vehicles has been continually delayed
due to safety concerns. On the one hand, comprehensive scene understanding is
indispensable, a lack of which would result in vulnerability to rare but
complex traffic situations, such as the sudden emergence of unknown objects.
However, reasoning from a global context requires access to sensors of multiple
types and adequate fusion of multi-modal sensor signals, which is difficult to
achieve. On the other hand, the lack of interpretability in learning models
also hampers the safety with unverifiable failure causes. In this paper, we
propose a safety-enhanced autonomous driving framework, named Interpretable
Sensor Fusion Transformer(InterFuser), to fully process and fuse information
from multi-modal multi-view sensors for achieving comprehensive scene
understanding and adversarial event detection. Besides, intermediate
interpretable features are generated from our framework, which provide more
semantics and are exploited to better constrain actions to be within the safe
sets. We conducted extensive experiments on CARLA benchmarks, where our model
outperforms prior methods, ranking the first on the public CARLA Leaderboard.
</p></li>
</ul>

<h3>Title: An Interpretability Evaluation Benchmark for Pre-trained Language Models. (arXiv:2207.13948v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2207.13948">http://arxiv.org/abs/2207.13948</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2207.13948] An Interpretability Evaluation Benchmark for Pre-trained Language Models](http://arxiv.org/abs/2207.13948)</code></li>
<li>Summary: <p>While pre-trained language models (LMs) have brought great improvements in
many NLP tasks, there is increasing attention to explore capabilities of LMs
and interpret their predictions. However, existing works usually focus only on
a certain capability with some downstream tasks. There is a lack of datasets
for directly evaluating the masked word prediction performance and the
interpretability of pre-trained LMs. To fill in the gap, we propose a novel
evaluation benchmark providing with both English and Chinese annotated data. It
tests LMs abilities in multiple dimensions, i.e., grammar, semantics,
knowledge, reasoning and computation. In addition, it provides carefully
annotated token-level rationales that satisfy sufficiency and compactness. It
contains perturbed instances for each original instance, so as to use the
rationale consistency under perturbations as the metric for faithfulness, a
perspective of interpretability. We conduct experiments on several widely-used
pre-trained LMs. The results show that they perform very poorly on the
dimensions of knowledge and computation. And their plausibility in all
dimensions is far from satisfactory, especially when the rationale is short. In
addition, the pre-trained LMs we evaluated are not robust on syntax-aware data.
We will release this evaluation benchmark at \url{<a href="http://xyz">this http URL</a>}, and hope it can
facilitate the research progress of pre-trained LMs.
</p></li>
</ul>

<h3>Title: Claim-Dissector: An Interpretable Fact-Checking System with Joint Re-ranking and Veracity Prediction. (arXiv:2207.14116v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2207.14116">http://arxiv.org/abs/2207.14116</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2207.14116] Claim-Dissector: An Interpretable Fact-Checking System with Joint Re-ranking and Veracity Prediction](http://arxiv.org/abs/2207.14116)</code></li>
<li>Summary: <p>We present Claim-Dissector: a novel latent variable model for fact-checking
and fact-analysis, which given a claim and a set of retrieved provenances
allows learning jointly: (i) what are the relevant provenances to this claim
(ii) what is the veracity of this claim. We propose to disentangle the
per-provenance relevance probability and its contribution to the final veracity
probability in an interpretable way - the final veracity probability is
proportional to a linear ensemble of per-provenance relevance probabilities.
This way, it can be clearly identified the relevance of which sources
contributes to what extent towards the final probability. We show that our
system achieves state-of-the-art results on FEVER dataset comparable to
two-stage systems typically used in traditional fact-checking pipelines, while
it often uses significantly less parameters and computation.
</p></li>
</ul>

<p>Our analysis shows that proposed approach further allows to learn not just
which provenances are relevant, but also which provenances lead to supporting
and which toward denying the claim, without direct supervision. This not only
adds interpretability, but also allows to detect claims with conflicting
evidence automatically. Furthermore, we study whether our model can learn
fine-grained relevance cues while using coarse-grained supervision. We show
that our model can achieve competitive sentence-recall while using only
paragraph-level relevance supervision. Finally, traversing towards the finest
granularity of relevance, we show that our framework is capable of identifying
relevance at the token-level. To do this, we present a new benchmark focusing
on token-level interpretability - humans annotate tokens in relevant
provenances they considered essential when making their judgement. Then we
measure how similar are these annotations to tokens our model is focusing on.
Our code, and dataset will be released online.
</p>

<h2>exlainability</h2>
<h2>watermark</h2>
<button id="copy">Copy All</button>
</article>
<script src="https://cdn.staticfile.org/clipboard.js/2.0.4/clipboard.min.js"></script>
<script src="../../javascript/clipboard.js"></script>
