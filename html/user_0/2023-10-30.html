<link rel="stylesheet" href="../../css/markdown.css" />
<article class="markdown-body">
<h2>secure</h2>
<h3>Title: BlackJack: Secure machine learning on IoT devices through hardware-based shuffling. (arXiv:2310.17804v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.17804">http://arxiv.org/abs/2310.17804</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.17804]] BlackJack: Secure machine learning on IoT devices through hardware-based shuffling(http://arxiv.org/abs/2310.17804)</code></li>
<li>Summary: <p>Neural networks are seeing increased use in diverse Internet of Things (IoT)
applications such as healthcare, smart homes and industrial monitoring. Their
widespread use makes neural networks a lucrative target for theft. An attacker
can obtain a model without having access to the training data or incurring the
cost of training. Also, networks trained using private data (e.g., medical
records) can reveal information about this data. Networks can be stolen by
leveraging side channels such as power traces of the IoT device when it is
running the network. Existing attacks require operations to occur in the same
order each time; an attacker must collect and analyze several traces of the
device to steal the network. Therefore, to prevent this type of attack, we
randomly shuffle the order of operations each time. With shuffling, each
operation can now happen at many different points in each execution, making the
attack intractable. However, we show that shuffling in software can leak
information which can be used to subvert this solution. Therefore, to perform
secure shuffling and reduce latency, we present BlackJack, hardware added as a
functional unit within the CPU. BlackJack secures neural networks on IoT
devices by increasing the time needed for an attack to centuries, while adding
just 2.46% area, 3.28% power and 0.56% latency overhead on an ARM M0+ SoC.
</p></li>
</ul>

<h2>security</h2>
<h3>Title: Measuring CDNs susceptible to Domain Fronting. (arXiv:2310.17851v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.17851">http://arxiv.org/abs/2310.17851</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.17851]] Measuring CDNs susceptible to Domain Fronting(http://arxiv.org/abs/2310.17851)</code></li>
<li>Summary: <p>Domain fronting is a network communication technique that involves leveraging
(or abusing) content delivery networks (CDNs) to disguise the final destination
of network packets by presenting them as if they were intended for a different
domain than their actual endpoint. This technique can be used for both benign
and malicious purposes, such as circumventing censorship or hiding
malware-related communications from network security systems. Since domain
fronting has been known for a few years, some popular CDN providers have
implemented traffic filtering approaches to curb its use at their CDN
infrastructure. However, it remains unclear to what extent domain fronting has
been mitigated.
</p>
<p>To better understand whether domain fronting can still be effectively used,
we propose a systematic approach to discover CDNs that are still prone to
domain fronting. To this end, we leverage passive and active DNS traffic
analysis to pinpoint domain names served by CDNs and build an automated tool
that can be used to discover CDNs that allow domain fronting in their
infrastructure. Our results reveal that domain fronting is feasible in 22 out
of 30 CDNs that we tested, including some major CDN providers like Akamai and
Fastly. This indicates that domain fronting remains widely available and can be
easily abused for malicious purposes.
</p></li>
</ul>

<h3>Title: Enhancing Enterprise Network Security: Comparing Machine-Level and Process-Level Analysis for Dynamic Malware Detection. (arXiv:2310.18165v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.18165">http://arxiv.org/abs/2310.18165</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.18165]] Enhancing Enterprise Network Security: Comparing Machine-Level and Process-Level Analysis for Dynamic Malware Detection(http://arxiv.org/abs/2310.18165)</code></li>
<li>Summary: <p>Analysing malware is important to understand how malicious software works and
to develop appropriate detection and prevention methods. Dynamic analysis can
overcome evasion techniques commonly used to bypass static analysis and provide
insights into malware runtime activities. Much research on dynamic analysis
focused on investigating machine-level information (e.g., CPU, memory, network
usage) to identify whether a machine is running malicious activities. A
malicious machine does not necessarily mean all running processes on the
machine are also malicious. If we can isolate the malicious process instead of
isolating the whole machine, we could kill the malicious process, and the
machine can keep doing its job. Another challenge dynamic malware detection
research faces is that the samples are executed in one machine without any
background applications running. It is unrealistic as a computer typically runs
many benign (background) applications when a malware incident happens. Our
experiment with machine-level data shows that the existence of background
applications decreases previous state-of-the-art accuracy by about 20.12% on
average. We also proposed a process-level Recurrent Neural Network (RNN)-based
detection model. Our proposed model performs better than the machine-level
detection model; 0.049 increase in detection rate and a false-positive rate
below 0.1.
</p></li>
</ul>

<h2>privacy</h2>
<h3>Title: DP-SGD with weight clipping. (arXiv:2310.18001v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.18001">http://arxiv.org/abs/2310.18001</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.18001]] DP-SGD with weight clipping(http://arxiv.org/abs/2310.18001)</code></li>
<li>Summary: <p>Recently, due to the popularity of deep neural networks and other methods
whose training typically relies on the optimization of an objective function,
and due to concerns for data privacy, there is a lot of interest in
differentially private gradient descent methods. To achieve differential
privacy guarantees with a minimum amount of noise, it is important to be able
to bound precisely the sensitivity of the information which the participants
will observe. In this study, we present a novel approach that mitigates the
bias arising from traditional gradient clipping. By leveraging public
information concerning the current global model and its location within the
search domain, we can achieve improved gradient bounds, leading to enhanced
sensitivity determinations and refined noise level adjustments. We extend the
state of the art algorithms, present improved differential privacy guarantees
requiring less noise and present an empirical evaluation.
</p></li>
</ul>

<h3>Title: $\alpha$-Mutual Information: A Tunable Privacy Measure for Privacy Protection in Data Sharing. (arXiv:2310.18241v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.18241">http://arxiv.org/abs/2310.18241</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.18241]] $\alpha$-Mutual Information: A Tunable Privacy Measure for Privacy Protection in Data Sharing(http://arxiv.org/abs/2310.18241)</code></li>
<li>Summary: <p>This paper adopts Arimoto's $\alpha$-Mutual Information as a tunable privacy
measure, in a privacy-preserving data release setting that aims to prevent
disclosing private data to adversaries. By fine-tuning the privacy metric, we
demonstrate that our approach yields superior models that effectively thwart
attackers across various performance dimensions. We formulate a general
distortion-based mechanism that manipulates the original data to offer privacy
protection. The distortion metrics are determined according to the data
structure of a specific experiment. We confront the problem expressed in the
formulation by employing a general adversarial deep learning framework that
consists of a releaser and an adversary, trained with opposite goals. This
study conducts empirical experiments on images and time-series data to verify
the functionality of $\alpha$-Mutual Information. We evaluate the
privacy-utility trade-off of customized models and compare them to mutual
information as the baseline measure. Finally, we analyze the consequence of an
attacker's access to side information about private data and witness that
adapting the privacy measure results in a more refined model than the
state-of-the-art in terms of resiliency against side information.
</p></li>
</ul>

<h3>Title: PockEngine: Sparse and Efficient Fine-tuning in a Pocket. (arXiv:2310.17752v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.17752">http://arxiv.org/abs/2310.17752</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.17752]] PockEngine: Sparse and Efficient Fine-tuning in a Pocket(http://arxiv.org/abs/2310.17752)</code></li>
<li>Summary: <p>On-device learning and efficient fine-tuning enable continuous and
privacy-preserving customization (e.g., locally fine-tuning large language
models on personalized data). However, existing training frameworks are
designed for cloud servers with powerful accelerators (e.g., GPUs, TPUs) and
lack the optimizations for learning on the edge, which faces challenges of
resource limitations and edge hardware diversity. We introduce PockEngine: a
tiny, sparse and efficient engine to enable fine-tuning on various edge
devices. PockEngine supports sparse backpropagation: it prunes the backward
graph and sparsely updates the model with measured memory saving and latency
reduction while maintaining the model quality. Secondly, PockEngine is
compilation first: the entire training graph (including forward, backward and
optimization steps) is derived at compile-time, which reduces the runtime
overhead and brings opportunities for graph transformations. PockEngine also
integrates a rich set of training graph optimizations, thus can further
accelerate the training cost, including operator reordering and backend
switching. PockEngine supports diverse applications, frontends and hardware
backends: it flexibly compiles and tunes models defined in
PyTorch/TensorFlow/Jax and deploys binaries to mobile CPU/GPU/DSPs. We
evaluated PockEngine on both vision models and large language models.
PockEngine achieves up to 15 $\times$ speedup over off-the-shelf TensorFlow
(Raspberry Pi), 5.6 $\times$ memory saving back-propagation (Jetson AGX Orin).
Remarkably, PockEngine enables fine-tuning LLaMav2-7B on NVIDIA Jetson AGX Orin
at 550 tokens/s, 7.9$\times$ faster than the PyTorch.
</p></li>
</ul>

<h2>protect</h2>
<h2>defense</h2>
<h3>Title: Elevating Code-mixed Text Handling through Auditory Information of Words. (arXiv:2310.18155v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.18155">http://arxiv.org/abs/2310.18155</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.18155]] Elevating Code-mixed Text Handling through Auditory Information of Words(http://arxiv.org/abs/2310.18155)</code></li>
<li>Summary: <p>With the growing popularity of code-mixed data, there is an increasing need
for better handling of this type of data, which poses a number of challenges,
such as dealing with spelling variations, multiple languages, different
scripts, and a lack of resources. Current language models face difficulty in
effectively handling code-mixed data as they primarily focus on the semantic
representation of words and ignore the auditory phonetic features. This leads
to difficulties in handling spelling variations in code-mixed text. In this
paper, we propose an effective approach for creating language models for
handling code-mixed textual data using auditory information of words from
SOUNDEX. Our approach includes a pre-training step based on
masked-language-modelling, which includes SOUNDEX representations (SAMLM) and a
new method of providing input data to the pre-trained model. Through
experimentation on various code-mixed datasets (of different languages) for
sentiment, offensive and aggression classification tasks, we establish that our
novel language modeling approach (SAMLM) results in improved robustness towards
adversarial attacks on code-mixed classification tasks. Additionally, our SAMLM
based approach also results in better classification results over the popular
baselines for code-mixed tasks. We use the explainability technique, SHAP
(SHapley Additive exPlanations) to explain how the auditory features
incorporated through SAMLM assist the model to handle the code-mixed text
effectively and increase robustness against adversarial attacks
\footnote{Source code has been made available on
\url{https://github.com/20118/DefenseWithPhonetics},
\url{https://www.iitp.ac.in/~ai-nlp-ml/resources.html\#Phonetics}}.
</p></li>
</ul>

<h2>attack</h2>
<h2>robust</h2>
<h3>Title: 3D-Aware Visual Question Answering about Parts, Poses and Occlusions. (arXiv:2310.17914v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.17914">http://arxiv.org/abs/2310.17914</a></li>
<li>Code URL: https://github.com/xingruiwang/3d-aware-vqa</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.17914]] 3D-Aware Visual Question Answering about Parts, Poses and Occlusions(http://arxiv.org/abs/2310.17914)</code></li>
<li>Summary: <p>Despite rapid progress in Visual question answering (VQA), existing datasets
and models mainly focus on testing reasoning in 2D. However, it is important
that VQA models also understand the 3D structure of visual scenes, for example
to support tasks like navigation or manipulation. This includes an
understanding of the 3D object pose, their parts and occlusions. In this work,
we introduce the task of 3D-aware VQA, which focuses on challenging questions
that require a compositional reasoning over the 3D structure of visual scenes.
We address 3D-aware VQA from both the dataset and the model perspective. First,
we introduce Super-CLEVR-3D, a compositional reasoning dataset that contains
questions about object parts, their 3D poses, and occlusions. Second, we
propose PO3D-VQA, a 3D-aware VQA model that marries two powerful ideas:
probabilistic neural symbolic program execution for reasoning and deep neural
networks with 3D generative representations of objects for robust visual
recognition. Our experimental results show our model PO3D-VQA outperforms
existing methods significantly, but we still observe a significant performance
gap compared to 2D VQA benchmarks, indicating that 3D-aware VQA remains an
important open research area.
</p></li>
</ul>

<h3>Title: LipSim: A Provably Robust Perceptual Similarity Metric. (arXiv:2310.18274v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.18274">http://arxiv.org/abs/2310.18274</a></li>
<li>Code URL: https://github.com/saraghazanfari/lipsim</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.18274]] LipSim: A Provably Robust Perceptual Similarity Metric(http://arxiv.org/abs/2310.18274)</code></li>
<li>Summary: <p>Recent years have seen growing interest in developing and applying perceptual
similarity metrics. Research has shown the superiority of perceptual metrics
over pixel-wise metrics in aligning with human perception and serving as a
proxy for the human visual system. On the other hand, as perceptual metrics
rely on neural networks, there is a growing concern regarding their resilience,
given the established vulnerability of neural networks to adversarial attacks.
It is indeed logical to infer that perceptual metrics may inherit both the
strengths and shortcomings of neural networks. In this work, we demonstrate the
vulnerability of state-of-the-art perceptual similarity metrics based on an
ensemble of ViT-based feature extractors to adversarial attacks. We then
propose a framework to train a robust perceptual similarity metric called
LipSim (Lipschitz Similarity Metric) with provable guarantees. By leveraging
1-Lipschitz neural networks as the backbone, LipSim provides guarded areas
around each data point and certificates for all perturbations within an
$\ell_2$ ball. Finally, a comprehensive set of experiments shows the
performance of LipSim in terms of natural and certified scores and on the image
retrieval application. The code is available at
https://github.com/SaraGhazanfari/LipSim.
</p></li>
</ul>

<h3>Title: ZeroQuant-HERO: Hardware-Enhanced Robust Optimized Post-Training Quantization Framework for W8A8 Transformers. (arXiv:2310.17723v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.17723">http://arxiv.org/abs/2310.17723</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.17723]] ZeroQuant-HERO: Hardware-Enhanced Robust Optimized Post-Training Quantization Framework for W8A8 Transformers(http://arxiv.org/abs/2310.17723)</code></li>
<li>Summary: <p>Quantization techniques are pivotal in reducing the memory and computational
demands of deep neural network inference. Existing solutions, such as
ZeroQuant, offer dynamic quantization for models like BERT and GPT but overlook
crucial memory-bounded operators and the complexities of per-token
quantization. Addressing these gaps, we present a novel, fully
hardware-enhanced robust optimized post-training W8A8 quantization framework,
ZeroQuant-HERO. This framework uniquely integrates both memory bandwidth and
compute-intensive operators, aiming for optimal hardware performance.
Additionally, it offers flexibility by allowing specific INT8 modules to switch
to FP16/BF16 mode, enhancing accuracy.
</p></li>
</ul>

<h3>Title: Social Contract AI: Aligning AI Assistants with Implicit Group Norms. (arXiv:2310.17769v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.17769">http://arxiv.org/abs/2310.17769</a></li>
<li>Code URL: https://github.com/janphilippfranken/scai</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.17769]] Social Contract AI: Aligning AI Assistants with Implicit Group Norms(http://arxiv.org/abs/2310.17769)</code></li>
<li>Summary: <p>We explore the idea of aligning an AI assistant by inverting a model of
users' (unknown) preferences from observed interactions. To validate our
proposal, we run proof-of-concept simulations in the economic ultimatum game,
formalizing user preferences as policies that guide the actions of simulated
players. We find that the AI assistant accurately aligns its behavior to match
standard policies from the economic literature (e.g., selfish, altruistic).
However, the assistant's learned policies lack robustness and exhibit limited
generalization in an out-of-distribution setting when confronted with a
currency (e.g., grams of medicine) that was not included in the assistant's
training distribution. Additionally, we find that when there is inconsistency
in the relationship between language use and an unknown policy (e.g., an
altruistic policy combined with rude language), the assistant's learning of the
policy is slowed. Overall, our preliminary results suggest that developing
simulation frameworks in which AI assistants need to infer preferences from
diverse users can provide a valuable approach for studying practical alignment
questions.
</p></li>
</ul>

<h3>Title: Detrimental Contexts in Open-Domain Question Answering. (arXiv:2310.18077v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.18077">http://arxiv.org/abs/2310.18077</a></li>
<li>Code URL: https://github.com/xfactlab/emnlp2023-damaging-retrieval</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.18077]] Detrimental Contexts in Open-Domain Question Answering(http://arxiv.org/abs/2310.18077)</code></li>
<li>Summary: <p>For knowledge intensive NLP tasks, it has been widely accepted that accessing
more information is a contributing factor to improvements in the model's
end-to-end performance. However, counter-intuitively, too much context can have
a negative impact on the model when evaluated on common question answering (QA)
datasets. In this paper, we analyze how passages can have a detrimental effect
on retrieve-then-read architectures used in question answering. Our empirical
evidence indicates that the current read architecture does not fully leverage
the retrieved passages and significantly degrades its performance when using
the whole passages compared to utilizing subsets of them. Our findings
demonstrate that model accuracy can be improved by 10% on two popular QA
datasets by filtering out detrimental passages. Additionally, these outcomes
are attained by utilizing existing retrieval methods without further training
or data. We further highlight the challenges associated with identifying the
detrimental passages. First, even with the correct context, the model can make
an incorrect prediction, posing a challenge in determining which passages are
most influential. Second, evaluation typically considers lexical matching,
which is not robust to variations of correct answers. Despite these
limitations, our experimental results underscore the pivotal role of
identifying and removing these detrimental passages for the context-efficient
retrieve-then-read pipeline. Code and data are available at
https://github.com/xfactlab/emnlp2023-damaging-retrieval
</p></li>
</ul>

<h3>Title: Fine tuning Pre trained Models for Robustness Under Noisy Labels. (arXiv:2310.17668v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.17668">http://arxiv.org/abs/2310.17668</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.17668]] Fine tuning Pre trained Models for Robustness Under Noisy Labels(http://arxiv.org/abs/2310.17668)</code></li>
<li>Summary: <p>The presence of noisy labels in a training dataset can significantly impact
the performance of machine learning models. To tackle this issue, researchers
have explored methods for Learning with Noisy Labels to identify clean samples
and reduce the influence of noisy labels. However, constraining the influence
of a certain portion of the training dataset can result in a reduction in
overall generalization performance. To alleviate this, recent studies have
considered the careful utilization of noisy labels by leveraging huge
computational resources. Therefore, the increasing training cost necessitates a
reevaluation of efficiency. In other areas of research, there has been a focus
on developing fine-tuning techniques for large pre-trained models that aim to
achieve both high generalization performance and efficiency. However, these
methods have mainly concentrated on clean datasets, and there has been limited
exploration of the noisy label scenario. In this research, our aim is to find
an appropriate way to fine-tune pre-trained models for noisy labeled datasets.
To achieve this goal, we investigate the characteristics of pre-trained models
when they encounter noisy datasets. Through empirical analysis, we introduce a
novel algorithm called TURN, which robustly and efficiently transfers the prior
knowledge of pre-trained models. The algorithm consists of two main steps: (1)
independently tuning the linear classifier to protect the feature extractor
from being distorted by noisy labels, and (2) reducing the noisy label ratio
and fine-tuning the entire model based on the noise-reduced dataset to adapt it
to the target dataset. The proposed algorithm has been extensively tested and
demonstrates efficient yet improved denoising performance on various benchmarks
compared to previous methods.
</p></li>
</ul>

<h3>Title: Spatio-Temporal Meta Contrastive Learning. (arXiv:2310.17678v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.17678">http://arxiv.org/abs/2310.17678</a></li>
<li>Code URL: https://github.com/hkuds/cl4st</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.17678]] Spatio-Temporal Meta Contrastive Learning(http://arxiv.org/abs/2310.17678)</code></li>
<li>Summary: <p>Spatio-temporal prediction is crucial in numerous real-world applications,
including traffic forecasting and crime prediction, which aim to improve public
transportation and safety management. Many state-of-the-art models demonstrate
the strong capability of spatio-temporal graph neural networks (STGNN) to
capture complex spatio-temporal correlations. However, despite their
effectiveness, existing approaches do not adequately address several key
challenges. Data quality issues, such as data scarcity and sparsity, lead to
data noise and a lack of supervised signals, which significantly limit the
performance of STGNN. Although recent STGNN models with contrastive learning
aim to address these challenges, most of them use pre-defined augmentation
strategies that heavily depend on manual design and cannot be customized for
different Spatio-Temporal Graph (STG) scenarios. To tackle these challenges, we
propose a new spatio-temporal contrastive learning (CL4ST) framework to encode
robust and generalizable STG representations via the STG augmentation paradigm.
Specifically, we design the meta view generator to automatically construct node
and edge augmentation views for each disentangled spatial and temporal graph in
a data-driven manner. The meta view generator employs meta networks with
parameterized generative model to customize the augmentations for each input.
This personalizes the augmentation strategies for every STG and endows the
learning framework with spatio-temporal-aware information. Additionally, we
integrate a unified spatio-temporal graph attention network with the proposed
meta view generator and two-branch graph contrastive learning paradigms.
Extensive experiments demonstrate that our CL4ST significantly improves
performance over various state-of-the-art baselines in traffic and crime
prediction.
</p></li>
</ul>

<h3>Title: Learning Optimal Classification Trees Robust to Distribution Shifts. (arXiv:2310.17772v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.17772">http://arxiv.org/abs/2310.17772</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.17772]] Learning Optimal Classification Trees Robust to Distribution Shifts(http://arxiv.org/abs/2310.17772)</code></li>
<li>Summary: <p>We consider the problem of learning classification trees that are robust to
distribution shifts between training and testing/deployment data. This problem
arises frequently in high stakes settings such as public health and social work
where data is often collected using self-reported surveys which are highly
sensitive to e.g., the framing of the questions, the time when and place where
the survey is conducted, and the level of comfort the interviewee has in
sharing information with the interviewer. We propose a method for learning
optimal robust classification trees based on mixed-integer robust optimization
technology. In particular, we demonstrate that the problem of learning an
optimal robust tree can be cast as a single-stage mixed-integer robust
optimization problem with a highly nonlinear and discontinuous objective. We
reformulate this problem equivalently as a two-stage linear robust optimization
problem for which we devise a tailored solution procedure based on constraint
generation. We evaluate the performance of our approach on numerous publicly
available datasets, and compare the performance to a regularized, non-robust
optimal tree. We show an increase of up to 12.48% in worst-case accuracy and of
up to 4.85% in average-case accuracy across several datasets and distribution
shifts from using our robust solution in comparison to the non-robust one.
</p></li>
</ul>

<h3>Title: Reward Scale Robustness for Proximal Policy Optimization via DreamerV3 Tricks. (arXiv:2310.17805v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.17805">http://arxiv.org/abs/2310.17805</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.17805]] Reward Scale Robustness for Proximal Policy Optimization via DreamerV3 Tricks(http://arxiv.org/abs/2310.17805)</code></li>
<li>Summary: <p>Most reinforcement learning methods rely heavily on dense, well-normalized
environment rewards. DreamerV3 recently introduced a model-based method with a
number of tricks that mitigate these limitations, achieving state-of-the-art on
a wide range of benchmarks with a single set of hyperparameters. This result
sparked discussion about the generality of the tricks, since they appear to be
applicable to other reinforcement learning algorithms. Our work applies
DreamerV3's tricks to PPO and is the first such empirical study outside of the
original work. Surprisingly, we find that the tricks presented do not transfer
as general improvements to PPO. We use a high quality PPO reference
implementation and present extensive ablation studies totaling over 10,000 A100
hours on the Arcade Learning Environment and the DeepMind Control Suite. Though
our experiments demonstrate that these tricks do not generally outperform PPO,
we identify cases where they succeed and offer insight into the relationship
between the implementation tricks. In particular, PPO with these tricks
performs comparably to PPO on Atari games with reward clipping and
significantly outperforms PPO without reward clipping.
</p></li>
</ul>

<h3>Title: Function Space Bayesian Pseudocoreset for Bayesian Neural Networks. (arXiv:2310.17852v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.17852">http://arxiv.org/abs/2310.17852</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.17852]] Function Space Bayesian Pseudocoreset for Bayesian Neural Networks(http://arxiv.org/abs/2310.17852)</code></li>
<li>Summary: <p>A Bayesian pseudocoreset is a compact synthetic dataset summarizing essential
information of a large-scale dataset and thus can be used as a proxy dataset
for scalable Bayesian inference. Typically, a Bayesian pseudocoreset is
constructed by minimizing a divergence measure between the posterior
conditioning on the pseudocoreset and the posterior conditioning on the full
dataset. However, evaluating the divergence can be challenging, particularly
for the models like deep neural networks having high-dimensional parameters. In
this paper, we propose a novel Bayesian pseudocoreset construction method that
operates on a function space. Unlike previous methods, which construct and
match the coreset and full data posteriors in the space of model parameters
(weights), our method constructs variational approximations to the coreset
posterior on a function space and matches it to the full data posterior in the
function space. By working directly on the function space, our method could
bypass several challenges that may arise when working on a weight space,
including limited scalability and multi-modality issue. Through various
experiments, we demonstrate that the Bayesian pseudocoresets constructed from
our method enjoys enhanced uncertainty quantification and better robustness
across various model architectures.
</p></li>
</ul>

<h3>Title: Robustness of Algorithms for Causal Structure Learning to Hyperparameter Choice. (arXiv:2310.18212v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.18212">http://arxiv.org/abs/2310.18212</a></li>
<li>Code URL: https://github.com/dmachlanski/benchpress-dm</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.18212]] Robustness of Algorithms for Causal Structure Learning to Hyperparameter Choice(http://arxiv.org/abs/2310.18212)</code></li>
<li>Summary: <p>Hyperparameters play a critical role in machine learning. Hyperparameter
tuning can make the difference between state-of-the-art and poor prediction
performance for any algorithm, but it is particularly challenging for structure
learning due to its unsupervised nature. As a result, hyperparameter tuning is
often neglected in favour of using the default values provided by a particular
implementation of an algorithm. While there have been numerous studies on
performance evaluation of causal discovery algorithms, how hyperparameters
affect individual algorithms, as well as the choice of the best algorithm for a
specific problem, has not been studied in depth before. This work addresses
this gap by investigating the influence of hyperparameters on causal structure
learning tasks. Specifically, we perform an empirical evaluation of
hyperparameter selection for some seminal learning algorithms on datasets of
varying levels of complexity. We find that, while the choice of algorithm
remains crucial to obtaining state-of-the-art performance, hyperparameter
selection in ensemble settings strongly influences the choice of algorithm, in
that a poor choice of hyperparameters can lead to analysts using algorithms
which do not give state-of-the-art performance for their data.
</p></li>
</ul>

<h2>biometric</h2>
<h2>steal</h2>
<h2>extraction</h2>
<h3>Title: Shape-centered Representation Learning for Visible-Infrared Person Re-identification. (arXiv:2310.17952v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.17952">http://arxiv.org/abs/2310.17952</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.17952]] Shape-centered Representation Learning for Visible-Infrared Person Re-identification(http://arxiv.org/abs/2310.17952)</code></li>
<li>Summary: <p>Current Visible-Infrared Person Re-Identification (VI-ReID) methods
prioritize extracting distinguishing appearance features, ignoring the natural
resistance of body shape against modality changes. Initially, we gauged the
discriminative potential of shapes by a straightforward concatenation of shape
and appearance features. However, two unresolved issues persist in the
utilization of shape features. One pertains to the dependence on auxiliary
models for shape feature extraction in the inference phase, along with the
errors in generated infrared shapes due to the intrinsic modality disparity.
The other issue involves the inadequately explored correlation between shape
and appearance features. To tackle the aforementioned challenges, we propose
the Shape-centered Representation Learning framework (ScRL), which focuses on
learning shape features and appearance features associated with shapes.
Specifically, we devise the Shape Feature Propagation (SFP), facilitating
direct extraction of shape features from original images with minimal
complexity costs during inference. To restitute inaccuracies in infrared body
shapes at the feature level, we present the Infrared Shape Restitution (ISR).
Furthermore, to acquire appearance features related to shape, we design the
Appearance Feature Enhancement (AFE), which accentuates identity-related
features while suppressing identity-unrelated features guided by shape
features. Extensive experiments are conducted to validate the effectiveness of
the proposed ScRL. Achieving remarkable results, the Rank-1 (mAP) accuracy
attains 76.1%, 71.2%, 92.4% (72.6%, 52.9%, 86.7%) on the SYSU-MM01, HITSZ-VCM,
RegDB datasets respectively, outperforming existing state-of-the-art methods.
</p></li>
</ul>

<h3>Title: Always Clear Days: Degradation Type and Severity Aware All-In-One Adverse Weather Removal. (arXiv:2310.18293v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.18293">http://arxiv.org/abs/2310.18293</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.18293]] Always Clear Days: Degradation Type and Severity Aware All-In-One Adverse Weather Removal(http://arxiv.org/abs/2310.18293)</code></li>
<li>Summary: <p>All-in-one adverse weather removal is an emerging topic on image restoration,
which aims to restore multiple weather degradation in an unified model, and the
challenging are twofold. First, discovering and handling the property of
multi-domain in target distribution formed by multiple weather conditions.
Second, design efficient and effective operations for different degradation
types. To address this problem, most prior works focus on the multi-domain
caused by weather type. Inspired by inter\&amp;intra-domain adaptation literature,
we observed that not only weather type but also weather severity introduce
multi-domain within each weather type domain, which is ignored by previous
methods, and further limit their performance. To this end, we proposed a
degradation type and severity aware model, called \textbf{UtilityIR}, for blind
all-in-one bad weather image restoration. To extract weather information from
single image, we proposed a novel Marginal Quality Ranking Loss (MQRL) and
utilized Contrastive Loss (CL) to guide weather severity and type extraction,
and leverage a bag of novel techniques such as Multi-Head Cross Attention
(MHCA) and Local-Global Adaptive Instance Normalization (LG-AdaIN) to
efficiently restore spatial varying weather degradation. The proposed method
can significantly outperform the SOTA methods subjectively and objectively on
different weather restoration tasks with a large margin, and enjoy less model
parameters. Proposed method even can restore \textbf{unseen} domain combined
multiple degradation images, and modulating restoration level. Implementation
code will be available at
{https://github.com/fordevoted/UtilityIR}{\textit{this repository}}
</p></li>
</ul>

<h3>Title: Nearest Neighbor Search over Vectorized Lexico-Syntactic Patterns for Relation Extraction from Financial Documents. (arXiv:2310.17714v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.17714">http://arxiv.org/abs/2310.17714</a></li>
<li>Code URL: https://github.com/pawan2411/pan-dl_refind</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.17714]] Nearest Neighbor Search over Vectorized Lexico-Syntactic Patterns for Relation Extraction from Financial Documents(http://arxiv.org/abs/2310.17714)</code></li>
<li>Summary: <p>Relation extraction (RE) has achieved remarkable progress with the help of
pre-trained language models. However, existing RE models are usually incapable
of handling two situations: implicit expressions and long-tail relation
classes, caused by language complexity and data sparsity. Further, these
approaches and models are largely inaccessible to users who don't have direct
access to large language models (LLMs) and/or infrastructure for supervised
training or fine-tuning. Rule-based systems also struggle with implicit
expressions. Apart from this, Real world financial documents such as various
10-X reports (including 10-K, 10-Q, etc.) of publicly traded companies pose
another challenge to rule-based systems in terms of longer and complex
sentences. In this paper, we introduce a simple approach that consults training
relations at test time through a nearest-neighbor search over dense vectors of
lexico-syntactic patterns and provides a simple yet effective means to tackle
the above issues. We evaluate our approach on REFinD and show that our method
achieves state-of-the-art performance. We further show that it can provide a
good start for human in the loop setup when a small number of annotations are
available and it is also beneficial when domain experts can provide high
quality patterns.
</p></li>
</ul>

<h3>Title: TIMELINE: Exhaustive Annotation of Temporal Relations Supporting the Automatic Ordering of Events in News Articles. (arXiv:2310.17802v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.17802">http://arxiv.org/abs/2310.17802</a></li>
<li>Code URL: https://github.com/alsayyahi/timeline</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.17802]] TIMELINE: Exhaustive Annotation of Temporal Relations Supporting the Automatic Ordering of Events in News Articles(http://arxiv.org/abs/2310.17802)</code></li>
<li>Summary: <p>Temporal relation extraction models have thus far been hindered by a number
of issues in existing temporal relation-annotated news datasets, including: (1)
low inter-annotator agreement due to the lack of specificity of their
annotation guidelines in terms of what counts as a temporal relation; (2) the
exclusion of long-distance relations within a given document (those spanning
across different paragraphs); and (3) the exclusion of events that are not
centred on verbs. This paper aims to alleviate these issues by presenting a new
annotation scheme that clearly defines the criteria based on which temporal
relations should be annotated. Additionally, the scheme includes events even if
they are not expressed as verbs (e.g., nominalised events). Furthermore, we
propose a method for annotating all temporal relations -- including
long-distance ones -- which automates the process, hence reducing time and
manual effort on the part of annotators. The result is a new dataset, the
TIMELINE corpus, in which improved inter-annotator agreement was obtained, in
comparison with previously reported temporal relation datasets. We report the
results of training and evaluating baseline temporal relation extraction models
on the new corpus, and compare them with results obtained on the widely used
MATRES corpus.
</p></li>
</ul>

<h3>Title: A Scalable Framework for Table of Contents Extraction from Complex ESG Annual Reports. (arXiv:2310.18073v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.18073">http://arxiv.org/abs/2310.18073</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.18073]] A Scalable Framework for Table of Contents Extraction from Complex ESG Annual Reports(http://arxiv.org/abs/2310.18073)</code></li>
<li>Summary: <p>Table of contents (ToC) extraction centres on structuring documents in a
hierarchical manner. In this paper, we propose a new dataset, ESGDoc,
comprising 1,093 ESG annual reports from 563 companies spanning from 2001 to
2022. These reports pose significant challenges due to their diverse structures
and extensive length. To address these challenges, we propose a new framework
for Toc extraction, consisting of three steps: (1) Constructing an initial tree
of text blocks based on reading order and font sizes; (2) Modelling each tree
node (or text block) independently by considering its contextual information
captured in node-centric subtree; (3) Modifying the original tree by taking
appropriate action on each tree node (Keep, Delete, or Move). This
construction-modelling-modification (CMM) process offers several benefits. It
eliminates the need for pairwise modelling of section headings as in previous
approaches, making document segmentation practically feasible. By incorporating
structured information, each section heading can leverage both local and
long-distance context relevant to itself. Experimental results show that our
approach outperforms the previous state-of-the-art baseline with a fraction of
running time. Our framework proves its scalability by effectively handling
documents of any length.
</p></li>
</ul>

<h3>Title: Positional Encoding-based Resident Identification in Multi-resident Smart Homes. (arXiv:2310.17836v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.17836">http://arxiv.org/abs/2310.17836</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.17836]] Positional Encoding-based Resident Identification in Multi-resident Smart Homes(http://arxiv.org/abs/2310.17836)</code></li>
<li>Summary: <p>We propose a novel resident identification framework to identify residents in
a multi-occupant smart environment. The proposed framework employs a feature
extraction model based on the concepts of positional encoding. The feature
extraction model considers the locations of homes as a graph. We design a novel
algorithm to build such graphs from layout maps of smart environments. The
Node2Vec algorithm is used to transform the graph into high-dimensional node
embeddings. A Long Short-Term Memory (LSTM) model is introduced to predict the
identities of residents using temporal sequences of sensor events with the node
embeddings. Extensive experiments show that our proposed scheme effectively
identifies residents in a multi-occupant environment. Evaluation results on two
real-world datasets demonstrate that our proposed approach achieves 94.5% and
87.9% accuracy, respectively.
</p></li>
</ul>

<h2>membership infer</h2>
<h2>federate</h2>
<h3>Title: Heterogeneous Federated Learning with Group-Aware Prompt Tuning. (arXiv:2310.18285v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.18285">http://arxiv.org/abs/2310.18285</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.18285]] Heterogeneous Federated Learning with Group-Aware Prompt Tuning(http://arxiv.org/abs/2310.18285)</code></li>
<li>Summary: <p>Transformers have achieved remarkable success in various machine-learning
tasks, prompting their widespread adoption. In this paper, we explore their
application in the context of federated learning (FL), with a particular focus
on heterogeneous scenarios where individual clients possess diverse local
datasets. To meet the computational and communication demands of FL, we
leverage pre-trained Transformers and use an efficient prompt-tuning strategy.
Our strategy introduces the concept of learning both shared and group prompts,
enabling the acquisition of universal knowledge and group-specific knowledge
simultaneously. Additionally, a prompt selection module assigns personalized
group prompts to each input, aligning the global model with the data
distribution of each client. This approach allows us to train a single global
model that can automatically adapt to various local client data distributions
without requiring local fine-tuning. In this way, our proposed method
effectively bridges the gap between global and personalized local models in
Federated Learning and surpasses alternative approaches that lack the
capability to adapt to previously unseen clients. The effectiveness of our
approach is rigorously validated through extensive experimentation and ablation
studies.
</p></li>
</ul>

<h3>Title: Submodel Partitioning in Hierarchical Federated Learning: Algorithm Design and Convergence Analysis. (arXiv:2310.17890v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.17890">http://arxiv.org/abs/2310.17890</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.17890]] Submodel Partitioning in Hierarchical Federated Learning: Algorithm Design and Convergence Analysis(http://arxiv.org/abs/2310.17890)</code></li>
<li>Summary: <p>Hierarchical federated learning (HFL) has demonstrated promising scalability
advantages over the traditional "star-topology" architecture-based federated
learning (FL). However, HFL still imposes significant computation,
communication, and storage burdens on the edge, especially when training a
large-scale model over resource-constrained Internet of Things (IoT) devices.
In this paper, we propose hierarchical independent submodel training (HIST), a
new FL methodology that aims to address these issues in hierarchical settings.
The key idea behind HIST is a hierarchical version of model partitioning, where
we partition the global model into disjoint submodels in each round, and
distribute them across different cells, so that each cell is responsible for
training only one partition of the full model. This enables each client to save
computation/storage costs while alleviating the communication loads throughout
the hierarchy. We characterize the convergence behavior of HIST for non-convex
loss functions under mild assumptions, showing the impact of several attributes
(e.g., number of cells, local and global aggregation frequency) on the
performance-efficiency tradeoff. Finally, through numerical experiments, we
verify that HIST is able to save communication costs by a wide margin while
achieving the same target testing accuracy.
</p></li>
</ul>

<h3>Title: CEFL: Carbon-Efficient Federated Learning. (arXiv:2310.17972v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.17972">http://arxiv.org/abs/2310.17972</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.17972]] CEFL: Carbon-Efficient Federated Learning(http://arxiv.org/abs/2310.17972)</code></li>
<li>Summary: <p>Federated Learning (FL) distributes machine learning (ML) training across
many edge devices to reduce data transfer overhead and protect data privacy.
Since FL model training may span millions of devices and is thus
resource-intensive, prior work has focused on improving its resource efficiency
to optimize time-to-accuracy. However, prior work generally treats all
resources the same, while, in practice, they may incur widely different costs,
which instead motivates optimizing cost-to-accuracy. To address the problem, we
design CEFL, which uses adaptive cost-aware client selection policies to
optimize an arbitrary cost metric when training FL models. Our policies extend
and combine prior work on utility-based client selection and critical learning
periods by making them cost-aware. We demonstrate CEFL by designing
carbon-efficient FL, where energy's carbon-intensity is the cost, and show that
it i) reduces carbon emissions by 93\% and reduces training time by 50%
compared to random client selection and ii) reduces carbon emissions by 80%,
while only increasing training time by 38%, compared to a state-of-the-art
approach that optimizes training time.
</p></li>
</ul>

<h2>fair</h2>
<h3>Title: DELPHI: Data for Evaluating LLMs' Performance in Handling Controversial Issues. (arXiv:2310.18130v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.18130">http://arxiv.org/abs/2310.18130</a></li>
<li>Code URL: https://github.com/zidixiu/delphi</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.18130]] DELPHI: Data for Evaluating LLMs' Performance in Handling Controversial Issues(http://arxiv.org/abs/2310.18130)</code></li>
<li>Summary: <p>Controversy is a reflection of our zeitgeist, and an important aspect to any
discourse. The rise of large language models (LLMs) as conversational systems
has increased public reliance on these systems for answers to their various
questions. Consequently, it is crucial to systematically examine how these
models respond to questions that pertaining to ongoing debates. However, few
such datasets exist in providing human-annotated labels reflecting the
contemporary discussions. To foster research in this area, we propose a novel
construction of a controversial questions dataset, expanding upon the publicly
released Quora Question Pairs Dataset. This dataset presents challenges
concerning knowledge recency, safety, fairness, and bias. We evaluate different
LLMs using a subset of this dataset, illuminating how they handle controversial
issues and the stances they adopt. This research ultimately contributes to our
understanding of LLMs' interaction with controversial issues, paving the way
for improvements in their comprehension and handling of complex societal
debates.
</p></li>
</ul>

<h3>Title: Counterfactual Fairness for Predictions using Generative Adversarial Networks. (arXiv:2310.17687v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.17687">http://arxiv.org/abs/2310.17687</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.17687]] Counterfactual Fairness for Predictions using Generative Adversarial Networks(http://arxiv.org/abs/2310.17687)</code></li>
<li>Summary: <p>Fairness in predictions is of direct importance in practice due to legal,
ethical, and societal reasons. It is often achieved through counterfactual
fairness, which ensures that the prediction for an individual is the same as
that in a counterfactual world under a different sensitive attribute. However,
achieving counterfactual fairness is challenging as counterfactuals are
unobservable. In this paper, we develop a novel deep neural network called
Generative Counterfactual Fairness Network (GCFN) for making predictions under
counterfactual fairness. Specifically, we leverage a tailored generative
adversarial network to directly learn the counterfactual distribution of the
descendants of the sensitive attribute, which we then use to enforce fair
predictions through a novel counterfactual mediator regularization. If the
counterfactual distribution is learned sufficiently well, our method is
mathematically guaranteed to ensure the notion of counterfactual fairness.
Thereby, our GCFN addresses key shortcomings of existing baselines that are
based on inferring latent variables, yet which (a) are potentially correlated
with the sensitive attributes and thus lead to bias, and (b) have weak
capability in constructing latent representations and thus low prediction
performance. Across various experiments, our method achieves state-of-the-art
performance. Using a real-world case study from recidivism prediction, we
further demonstrate that our method makes meaningful predictions in practice.
</p></li>
</ul>

<h3>Title: Proportional Fairness in Clustering: A Social Choice Perspective. (arXiv:2310.18162v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.18162">http://arxiv.org/abs/2310.18162</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.18162]] Proportional Fairness in Clustering: A Social Choice Perspective(http://arxiv.org/abs/2310.18162)</code></li>
<li>Summary: <p>We study the proportional clustering problem of Chen et al. [ICML'19] and
relate it to the area of multiwinner voting in computational social choice. We
show that any clustering satisfying a weak proportionality notion of Brill and
Peters [EC'23] simultaneously obtains the best known approximations to the
proportional fairness notion of Chen et al. [ICML'19], but also to individual
fairness [Jung et al., FORC'20] and the "core" [Li et al. ICML'21]. In fact, we
show that any approximation to proportional fairness is also an approximation
to individual fairness and vice versa. Finally, we also study stronger notions
of proportional representation, in which deviations do not only happen to
single, but multiple candidate centers, and show that stronger proportionality
notions of Brill and Peters [EC'23] imply approximations to these stronger
guarantees.
</p></li>
</ul>

<h2>interpretability</h2>
<h3>Title: Lifting the Veil: Unlocking the Power of Depth in Q-learning. (arXiv:2310.17915v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.17915">http://arxiv.org/abs/2310.17915</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.17915]] Lifting the Veil: Unlocking the Power of Depth in Q-learning(http://arxiv.org/abs/2310.17915)</code></li>
<li>Summary: <p>With the help of massive data and rich computational resources, deep
Q-learning has been widely used in operations research and management science
and has contributed to great success in numerous applications, including
recommender systems, supply chains, games, and robotic manipulation. However,
the success of deep Q-learning lacks solid theoretical verification and
interpretability. The aim of this paper is to theoretically verify the power of
depth in deep Q-learning. Within the framework of statistical learning theory,
we rigorously prove that deep Q-learning outperforms its traditional version by
demonstrating its good generalization error bound. Our results reveal that the
main reason for the success of deep Q-learning is the excellent performance of
deep neural networks (deep nets) in capturing the special properties of rewards
namely, spatial sparseness and piecewise constancy, rather than their large
capacities. In this paper, we make fundamental contributions to the field of
reinforcement learning by answering to the following three questions: Why does
deep Q-learning perform so well? When does deep Q-learning perform better than
traditional Q-learning? How many samples are required to achieve a specific
prediction accuracy for deep Q-learning? Our theoretical assertions are
verified by applying deep Q-learning in the well-known beer game in supply
chain management and a simulated recommender system.
</p></li>
</ul>

<h2>explainability</h2>
<h2>watermark</h2>
<h2>diffusion</h2>
<h3>Title: ZeroNVS: Zero-Shot 360-Degree View Synthesis from a Single Real Image. (arXiv:2310.17994v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.17994">http://arxiv.org/abs/2310.17994</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.17994]] ZeroNVS: Zero-Shot 360-Degree View Synthesis from a Single Real Image(http://arxiv.org/abs/2310.17994)</code></li>
<li>Summary: <p>We introduce a 3D-aware diffusion model, ZeroNVS, for single-image novel view
synthesis for in-the-wild scenes. While existing methods are designed for
single objects with masked backgrounds, we propose new techniques to address
challenges introduced by in-the-wild multi-object scenes with complex
backgrounds. Specifically, we train a generative prior on a mixture of data
sources that capture object-centric, indoor, and outdoor scenes. To address
issues from data mixture such as depth-scale ambiguity, we propose a novel
camera conditioning parameterization and normalization scheme. Further, we
observe that Score Distillation Sampling (SDS) tends to truncate the
distribution of complex backgrounds during distillation of 360-degree scenes,
and propose "SDS anchoring" to improve the diversity of synthesized novel
views. Our model sets a new state-of-the-art result in LPIPS on the DTU dataset
in the zero-shot setting, even outperforming methods specifically trained on
DTU. We further adapt the challenging Mip-NeRF 360 dataset as a new benchmark
for single-image novel view synthesis, and demonstrate strong performance in
this setting. Our code and data are at <a href="http://kylesargent.github.io/zeronvs/">this http URL</a>
</p></li>
</ul>

<h3>Title: Interacting Diffusion Processes for Event Sequence Forecasting. (arXiv:2310.17800v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.17800">http://arxiv.org/abs/2310.17800</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.17800]] Interacting Diffusion Processes for Event Sequence Forecasting(http://arxiv.org/abs/2310.17800)</code></li>
<li>Summary: <p>Neural Temporal Point Processes (TPPs) have emerged as the primary framework
for predicting sequences of events that occur at irregular time intervals, but
their sequential nature can hamper performance for long-horizon forecasts. To
address this, we introduce a novel approach that incorporates a diffusion
generative model. The model facilitates sequence-to-sequence prediction,
allowing multi-step predictions based on historical event sequences. In
contrast to previous approaches, our model directly learns the joint
probability distribution of types and inter-arrival times for multiple events.
This allows us to fully leverage the high dimensional modeling capability of
modern generative models. Our model is composed of two diffusion processes, one
for the time intervals and one for the event types. These processes interact
through their respective denoising functions, which can take as input
intermediate representations from both processes, allowing the model to learn
complex interactions. We demonstrate that our proposal outperforms
state-of-the-art baselines for long-horizon forecasting of TPP.
</p></li>
</ul>

<h2>noise learning</h2>
<h2>data-free</h2>
<h2>transformer</h2>
<h3>Title: What You See Is What You Detect: Towards better Object Densification in 3D detection. (arXiv:2310.17842v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.17842">http://arxiv.org/abs/2310.17842</a></li>
<li>Code URL: https://github.com/orbis36/wysiwyd</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.17842]] What You See Is What You Detect: Towards better Object Densification in 3D detection(http://arxiv.org/abs/2310.17842)</code></li>
<li>Summary: <p>Recent works have demonstrated the importance of object completion in 3D
Perception from Lidar signal. Several methods have been proposed in which
modules were used to densify the point clouds produced by laser scanners,
leading to better recall and more accurate results. Pursuing in that direction,
we present, in this work, a counter-intuitive perspective: the widely-used
full-shape completion approach actually leads to a higher error-upper bound
especially for far away objects and small objects like pedestrians. Based on
this observation, we introduce a visible part completion method that requires
only 11.3\% of the prediction points that previous methods generate. To recover
the dense representation, we propose a mesh-deformation-based method to augment
the point set associated with visible foreground objects. Considering that our
approach focuses only on the visible part of the foreground objects to achieve
accurate 3D detection, we named our method What You See Is What You Detect
(WYSIWYD). Our proposed method is thus a detector-independent model that
consists of 2 parts: an Intra-Frustum Segmentation Transformer (IFST) and a
Mesh Depth Completion Network(MDCNet) that predicts the foreground depth from
mesh deformation. This way, our model does not require the time-consuming
full-depth completion task used by most pseudo-lidar-based methods. Our
experimental evaluation shows that our approach can provide up to 12.2\%
performance improvements over most of the public baseline models on the KITTI
and NuScenes dataset bringing the state-of-the-art to a new level. The codes
will be available at
\textcolor[RGB]{0,0,255}{\url{{https://github.com/Orbis36/WYSIWYD}}
</p></li>
</ul>

<h3>Title: DocStormer: Revitalizing Multi-Degraded Colored Document Images to Pristine PDF. (arXiv:2310.17910v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.17910">http://arxiv.org/abs/2310.17910</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.17910]] DocStormer: Revitalizing Multi-Degraded Colored Document Images to Pristine PDF(http://arxiv.org/abs/2310.17910)</code></li>
<li>Summary: <p>For capturing colored document images, e.g. posters and magazines, it is
common that multiple degradations such as shadows, wrinkles, etc., are
simultaneously introduced due to external factors. Restoring multi-degraded
colored document images is a great challenge, yet overlooked, as most existing
algorithms focus on enhancing color-ignored document images via binarization.
Thus, we propose DocStormer, a novel algorithm designed to restore
multi-degraded colored documents to their potential pristine PDF. The
contributions are: firstly, we propose a "Perceive-then-Restore" paradigm with
a reinforced transformer block, which more effectively encodes and utilizes the
distribution of degradations. Secondly, we are the first to utilize GAN and
pristine PDF magazine images to narrow the distribution gap between the
enhanced results and PDF images, in pursuit of less degradation and better
visual quality. Thirdly, we propose a non-parametric strategy, PFILI, which
enables a smaller training scale and larger testing resolutions with acceptable
detail trade-off, while saving memory and inference time. Fourthly, we are the
first to propose a novel Multi-Degraded Colored Document image Enhancing
dataset, named MD-CDE, for both training and evaluation. Experimental results
show that the DocStormer exhibits superior performance, capable of revitalizing
multi-degraded colored documents into their potential pristine digital
versions, which fills the current academic gap from the perspective of method,
data, and task.
</p></li>
</ul>

<h3>Title: Qilin-Med-VL: Towards Chinese Large Vision-Language Model for General Healthcare. (arXiv:2310.17956v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.17956">http://arxiv.org/abs/2310.17956</a></li>
<li>Code URL: https://github.com/williamliujl/qilin-med-vl</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.17956]] Qilin-Med-VL: Towards Chinese Large Vision-Language Model for General Healthcare(http://arxiv.org/abs/2310.17956)</code></li>
<li>Summary: <p>Large Language Models (LLMs) have introduced a new era of proficiency in
comprehending complex healthcare and biomedical topics. However, there is a
noticeable lack of models in languages other than English and models that can
interpret multi-modal input, which is crucial for global healthcare
accessibility. In response, this study introduces Qilin-Med-VL, the first
Chinese large vision-language model designed to integrate the analysis of
textual and visual data. Qilin-Med-VL combines a pre-trained Vision Transformer
(ViT) with a foundational LLM. It undergoes a thorough two-stage curriculum
training process that includes feature alignment and instruction tuning. This
method enhances the model's ability to generate medical captions and answer
complex medical queries. We also release ChiMed-VL, a dataset consisting of
more than 1M image-text pairs. This dataset has been carefully curated to
enable detailed and comprehensive interpretation of medical data using various
types of images.
</p></li>
</ul>

<h3>Title: FaultSeg Swin-UNETR: Transformer-Based Self-Supervised Pretraining Model for Fault Recognition. (arXiv:2310.17974v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.17974">http://arxiv.org/abs/2310.17974</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.17974]] FaultSeg Swin-UNETR: Transformer-Based Self-Supervised Pretraining Model for Fault Recognition(http://arxiv.org/abs/2310.17974)</code></li>
<li>Summary: <p>This paper introduces an approach to enhance seismic fault recognition
through self-supervised pretraining. Seismic fault interpretation holds great
significance in the fields of geophysics and geology. However, conventional
methods for seismic fault recognition encounter various issues, including
dependence on data quality and quantity, as well as susceptibility to
interpreter subjectivity. Currently, automated fault recognition methods
proposed based on small synthetic datasets experience performance degradation
when applied to actual seismic data. To address these challenges, we have
introduced the concept of self-supervised learning, utilizing a substantial
amount of relatively easily obtainable unlabeled seismic data for pretraining.
Specifically, we have employed the Swin Transformer model as the core network
and employed the SimMIM pretraining task to capture unique features related to
discontinuities in seismic data. During the fine-tuning phase, inspired by edge
detection techniques, we have also refined the structure of the Swin-UNETR
model, enabling multiscale decoding and fusion for more effective fault
detection. Experimental results demonstrate that our proposed method attains
state-of-the-art performance on the Thebe dataset, as measured by the OIS and
ODS metrics.
</p></li>
</ul>

<h3>Title: ViCLEVR: A Visual Reasoning Dataset and Hybrid Multimodal Fusion Model for Visual Question Answering in Vietnamese. (arXiv:2310.18046v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.18046">http://arxiv.org/abs/2310.18046</a></li>
<li>Code URL: https://github.com/kvt0012/viclevr</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.18046]] ViCLEVR: A Visual Reasoning Dataset and Hybrid Multimodal Fusion Model for Visual Question Answering in Vietnamese(http://arxiv.org/abs/2310.18046)</code></li>
<li>Summary: <p>In recent years, Visual Question Answering (VQA) has gained significant
attention for its diverse applications, including intelligent car assistance,
aiding visually impaired individuals, and document image information retrieval
using natural language queries. VQA requires effective integration of
information from questions and images to generate accurate answers. Neural
models for VQA have made remarkable progress on large-scale datasets, with a
primary focus on resource-rich languages like English. To address this, we
introduce the ViCLEVR dataset, a pioneering collection for evaluating various
visual reasoning capabilities in Vietnamese while mitigating biases. The
dataset comprises over 26,000 images and 30,000 question-answer pairs (QAs),
each question annotated to specify the type of reasoning involved. Leveraging
this dataset, we conduct a comprehensive analysis of contemporary visual
reasoning systems, offering valuable insights into their strengths and
limitations. Furthermore, we present PhoVIT, a comprehensive multimodal fusion
that identifies objects in images based on questions. The architecture
effectively employs transformers to enable simultaneous reasoning over textual
and visual data, merging both modalities at an early model stage. The
experimental findings demonstrate that our proposed model achieves
state-of-the-art performance across four evaluation metrics. The accompanying
code and dataset have been made publicly accessible at
\url{https://github.com/kvt0012/ViCLEVR}. This provision seeks to stimulate
advancements within the research community, fostering the development of more
multimodal fusion algorithms, specifically tailored to address the nuances of
low-resource languages, exemplified by Vietnamese.
</p></li>
</ul>

<h3>Title: Transformers as Graph-to-Graph Models. (arXiv:2310.17936v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.17936">http://arxiv.org/abs/2310.17936</a></li>
<li>Code URL: https://github.com/idiap/g2g-transformer</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.17936]] Transformers as Graph-to-Graph Models(http://arxiv.org/abs/2310.17936)</code></li>
<li>Summary: <p>We argue that Transformers are essentially graph-to-graph models, with
sequences just being a special case. Attention weights are functionally
equivalent to graph edges. Our Graph-to-Graph Transformer architecture makes
this ability explicit, by inputting graph edges into the attention weight
computations and predicting graph edges with attention-like functions, thereby
integrating explicit graphs into the latent graphs learned by pretrained
Transformers. Adding iterative graph refinement provides a joint embedding of
input, output, and latent graphs, allowing non-autoregressive graph prediction
to optimise the complete graph without any bespoke pipeline or decoding
strategy. Empirical results show that this architecture achieves
state-of-the-art accuracies for modelling a variety of linguistic structures,
integrating very effectively with the latent linguistic representations learned
by pretraining.
</p></li>
</ul>

<h3>Title: SentMix-3L: A Bangla-English-Hindi Code-Mixed Dataset for Sentiment Analysis. (arXiv:2310.18023v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.18023">http://arxiv.org/abs/2310.18023</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.18023]] SentMix-3L: A Bangla-English-Hindi Code-Mixed Dataset for Sentiment Analysis(http://arxiv.org/abs/2310.18023)</code></li>
<li>Summary: <p>Code-mixing is a well-studied linguistic phenomenon when two or more
languages are mixed in text or speech. Several datasets have been build with
the goal of training computational models for code-mixing. Although it is very
common to observe code-mixing with multiple languages, most datasets available
contain code-mixed between only two languages. In this paper, we introduce
SentMix-3L, a novel dataset for sentiment analysis containing code-mixed data
between three languages Bangla, English, and Hindi. We carry out a
comprehensive evaluation using SentMix-3L. We show that zero-shot prompting
with GPT-3.5 outperforms all transformer-based models on SentMix-3L.
</p></li>
</ul>

<h3>Title: Revising with a Backward Glance: Regressions and Skips during Reading as Cognitive Signals for Revision Policies in Incremental Processing. (arXiv:2310.18229v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.18229">http://arxiv.org/abs/2310.18229</a></li>
<li>Code URL: https://github.com/briemadu/revreg</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.18229]] Revising with a Backward Glance: Regressions and Skips during Reading as Cognitive Signals for Revision Policies in Incremental Processing(http://arxiv.org/abs/2310.18229)</code></li>
<li>Summary: <p>In NLP, incremental processors produce output in instalments, based on
incoming prefixes of the linguistic input. Some tokens trigger revisions,
causing edits to the output hypothesis, but little is known about why models
revise when they revise. A policy that detects the time steps where revisions
should happen can improve efficiency. Still, retrieving a suitable signal to
train a revision policy is an open problem, since it is not naturally available
in datasets. In this work, we investigate the appropriateness of regressions
and skips in human reading eye-tracking data as signals to inform revision
policies in incremental sequence labelling. Using generalised mixed-effects
models, we find that the probability of regressions and skips by humans can
potentially serve as useful predictors for revisions in BiLSTMs and Transformer
models, with consistent results for various languages.
</p></li>
</ul>

<h3>Title: Sliceformer: Make Multi-head Attention as Simple as Sorting in Discriminative Tasks. (arXiv:2310.17683v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.17683">http://arxiv.org/abs/2310.17683</a></li>
<li>Code URL: https://github.com/sds-lab/sliceformer</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.17683]] Sliceformer: Make Multi-head Attention as Simple as Sorting in Discriminative Tasks(http://arxiv.org/abs/2310.17683)</code></li>
<li>Summary: <p>As one of the most popular neural network modules, Transformer plays a
central role in many fundamental deep learning models, e.g., the ViT in
computer vision and the BERT and GPT in natural language processing. The
effectiveness of the Transformer is often attributed to its multi-head
attention (MHA) mechanism. In this study, we discuss the limitations of MHA,
including the high computational complexity due to its ``query-key-value''
architecture and the numerical issue caused by its softmax operation.
Considering the above problems and the recent development tendency of the
attention layer, we propose an effective and efficient surrogate of the
Transformer, called Sliceformer. Our Sliceformer replaces the classic MHA
mechanism with an extremely simple ``slicing-sorting'' operation, i.e.,
projecting inputs linearly to a latent space and sorting them along different
feature dimensions (or equivalently, called channels). For each feature
dimension, the sorting operation implicitly generates an implicit attention map
with sparse, full-rank, and doubly-stochastic structures. We consider different
implementations of the slicing-sorting operation and analyze their impacts on
the Sliceformer. We test the Sliceformer in the Long-Range Arena benchmark,
image classification, text classification, and molecular property prediction,
demonstrating its advantage in computational complexity and universal
effectiveness in discriminative tasks. Our Sliceformer achieves comparable or
better performance with lower memory cost and faster speed than the Transformer
and its variants. Moreover, the experimental results reveal that applying our
Sliceformer can empirically suppress the risk of mode collapse when
representing data. The code is available at
\url{https://github.com/SDS-Lab/sliceformer}.
</p></li>
</ul>

<h2>generative</h2>
<h3>Title: One Style is All you Need to Generate a Video. (arXiv:2310.17835v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.17835">http://arxiv.org/abs/2310.17835</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.17835]] One Style is All you Need to Generate a Video(http://arxiv.org/abs/2310.17835)</code></li>
<li>Summary: <p>In this paper, we propose a style-based conditional video generative model.
We introduce a novel temporal generator based on a set of learned sinusoidal
bases. Our method learns dynamic representations of various actions that are
independent of image content and can be transferred between different actors.
Beyond the significant enhancement of video quality compared to prevalent
methods, we demonstrate that the disentangled dynamic and content permit their
independent manipulation, as well as temporal GAN-inversion to retrieve and
transfer a video motion from one content or identity to another without further
preprocessing such as landmark points.
</p></li>
</ul>

<h3>Title: Generative AI Model for Artistic Style Transfer Using Convolutional Neural Networks. (arXiv:2310.18237v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.18237">http://arxiv.org/abs/2310.18237</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.18237]] Generative AI Model for Artistic Style Transfer Using Convolutional Neural Networks(http://arxiv.org/abs/2310.18237)</code></li>
<li>Summary: <p>Artistic style transfer, a captivating application of generative artificial
intelligence, involves fusing the content of one image with the artistic style
of another to create unique visual compositions. This paper presents a
comprehensive overview of a novel technique for style transfer using
Convolutional Neural Networks (CNNs). By leveraging deep image representations
learned by CNNs, we demonstrate how to separate and manipulate image content
and style, enabling the synthesis of high-quality images that combine content
and style in a harmonious manner. We describe the methodology, including
content and style representations, loss computation, and optimization, and
showcase experimental results highlighting the effectiveness and versatility of
the approach across different styles and content
</p></li>
</ul>

<h3>Title: PlantPlotGAN: A Physics-Informed Generative Adversarial Network for Plant Disease Prediction. (arXiv:2310.18268v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.18268">http://arxiv.org/abs/2310.18268</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.18268]] PlantPlotGAN: A Physics-Informed Generative Adversarial Network for Plant Disease Prediction(http://arxiv.org/abs/2310.18268)</code></li>
<li>Summary: <p>Monitoring plantations is crucial for crop management and producing healthy
harvests. Unmanned Aerial Vehicles (UAVs) have been used to collect
multispectral images that aid in this monitoring. However, given the number of
hectares to be monitored and the limitations of flight, plant disease signals
become visually clear only in the later stages of plant growth and only if the
disease has spread throughout a significant portion of the plantation. This
limited amount of relevant data hampers the prediction models, as the
algorithms struggle to generalize patterns with unbalanced or unrealistic
augmented datasets effectively. To address this issue, we propose PlantPlotGAN,
a physics-informed generative model capable of creating synthetic multispectral
plot images with realistic vegetation indices. These indices served as a proxy
for disease detection and were used to evaluate if our model could help
increase the accuracy of prediction models. The results demonstrate that the
synthetic imagery generated from PlantPlotGAN outperforms state-of-the-art
methods regarding the Fr\'echet inception distance. Moreover, prediction models
achieve higher accuracy metrics when trained with synthetic and original
imagery for earlier plant disease detection compared to the training processes
based solely on real imagery.
</p></li>
</ul>

<h3>Title: FOUND: Foot Optimization with Uncertain Normals for Surface Deformation Using Synthetic Data. (arXiv:2310.18279v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.18279">http://arxiv.org/abs/2310.18279</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.18279]] FOUND: Foot Optimization with Uncertain Normals for Surface Deformation Using Synthetic Data(http://arxiv.org/abs/2310.18279)</code></li>
<li>Summary: <p>Surface reconstruction from multi-view images is a challenging task, with
solutions often requiring a large number of sampled images with high overlap.
We seek to develop a method for few-view reconstruction, for the case of the
human foot. To solve this task, we must extract rich geometric cues from RGB
images, before carefully fusing them into a final 3D object. Our FOUND approach
tackles this, with 4 main contributions: (i) SynFoot, a synthetic dataset of
50,000 photorealistic foot images, paired with ground truth surface normals and
keypoints; (ii) an uncertainty-aware surface normal predictor trained on our
synthetic dataset; (iii) an optimization scheme for fitting a generative foot
model to a series of images; and (iv) a benchmark dataset of calibrated images
and high resolution ground truth geometry. We show that our normal predictor
outperforms all off-the-shelf equivalents significantly on real images, and our
optimization scheme outperforms state-of-the-art photogrammetry pipelines,
especially for a few-view setting. We release our synthetic dataset and
baseline 3D scans to the research community.
</p></li>
</ul>

<h3>Title: A Framework for Automated Measurement of Responsible AI Harms in Generative AI Applications. (arXiv:2310.17750v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.17750">http://arxiv.org/abs/2310.17750</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.17750]] A Framework for Automated Measurement of Responsible AI Harms in Generative AI Applications(http://arxiv.org/abs/2310.17750)</code></li>
<li>Summary: <p>We present a framework for the automated measurement of responsible AI (RAI)
metrics for large language models (LLMs) and associated products and services.
Our framework for automatically measuring harms from LLMs builds on existing
technical and sociotechnical expertise and leverages the capabilities of
state-of-the-art LLMs, such as GPT-4. We use this framework to run through
several case studies investigating how different LLMs may violate a range of
RAI-related principles. The framework may be employed alongside domain-specific
sociotechnical expertise to create measurements for new harm areas in the
future. By implementing this framework, we aim to enable more advanced harm
measurement efforts and further the responsible use of LLMs.
</p></li>
</ul>

<h3>Title: DUMA: a Dual-Mind Conversational Agent with Fast and Slow Thinking. (arXiv:2310.18075v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.18075">http://arxiv.org/abs/2310.18075</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.18075]] DUMA: a Dual-Mind Conversational Agent with Fast and Slow Thinking(http://arxiv.org/abs/2310.18075)</code></li>
<li>Summary: <p>Inspired by the dual-process theory of human cognition, we introduce DUMA, a
novel conversational agent framework that embodies a dual-mind mechanism
through the utilization of two generative Large Language Models (LLMs)
dedicated to fast and slow thinking respectively. The fast thinking model
serves as the primary interface for external interactions and initial response
generation, evaluating the necessity for engaging the slow thinking model based
on the complexity of the complete response. When invoked, the slow thinking
model takes over the conversation, engaging in meticulous planning, reasoning,
and tool utilization to provide a well-analyzed response. This dual-mind
configuration allows for a seamless transition between intuitive responses and
deliberate problem-solving processes based on the situation. We have
constructed a conversational agent to handle online inquiries in the real
estate industry. The experiment proves that our method balances effectiveness
and efficiency, and has a significant improvement compared to the baseline.
</p></li>
</ul>

<h3>Title: Personas as a Way to Model Truthfulness in Language Models. (arXiv:2310.18168v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.18168">http://arxiv.org/abs/2310.18168</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.18168]] Personas as a Way to Model Truthfulness in Language Models(http://arxiv.org/abs/2310.18168)</code></li>
<li>Summary: <p>Large Language Models are trained on vast amounts of text from the internet,
which contains both factual and misleading information about the world. Can
language models discern truth from falsehood in this contradicting data?
Expanding on the view that LLMs can model different agents producing the
corpora, we hypothesize that they can cluster truthful text by modeling a
truthful persona: a group of agents that are likely to produce truthful text
and share similar features. For example, trustworthy sources like Wikipedia and
Science usually use formal writing styles and make consistent claims. By
modeling this persona, LLMs can generalize truthfulness beyond the specific
contexts in which each agent generated the training text. For example, the
model can infer that the agent "Wikipedia" will behave truthfully on topics
that were only generated by "Science" because they share a persona. We first
show evidence for the persona hypothesis via two observations: (1) we can probe
whether a model's answer will be truthful before it is generated; (2)
finetuning a model on a set of facts improves its truthfulness on unseen
topics. Next, using arithmetics as a synthetic environment, we show that
language models can separate true and false statements, and generalize
truthfulness across agents; but only if agents in the training data share a
truthful generative process that enables the creation of a truthful persona.
Overall, our findings suggest that models can exploit hierarchical structures
in the data to learn abstract concepts like truthfulness.
</p></li>
</ul>

<h3>Title: Lost in Translation, Found in Spans: Identifying Claims in Multilingual Social Media. (arXiv:2310.18205v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.18205">http://arxiv.org/abs/2310.18205</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.18205]] Lost in Translation, Found in Spans: Identifying Claims in Multilingual Social Media(http://arxiv.org/abs/2310.18205)</code></li>
<li>Summary: <p>Claim span identification (CSI) is an important step in fact-checking
pipelines, aiming to identify text segments that contain a checkworthy claim or
assertion in a social media post. Despite its importance to journalists and
human fact-checkers, it remains a severely understudied problem, and the scarce
research on this topic so far has only focused on English. Here we aim to
bridge this gap by creating a novel dataset, X-CLAIM, consisting of 7K
real-world claims collected from numerous social media platforms in five Indian
languages and English. We report strong baselines with state-of-the-art
encoder-only language models (e.g., XLM-R) and we demonstrate the benefits of
training on multiple languages over alternative cross-lingual transfer methods
such as zero-shot transfer, or training on translated data, from a
high-resource language such as English. We evaluate generative large language
models from the GPT series using prompting methods on the X-CLAIM dataset and
we find that they underperform the smaller encoder-only language models for
low-resource languages.
</p></li>
</ul>

<h3>Title: Adversarial Anomaly Detection using Gaussian Priors and Nonlinear Anomaly Scores. (arXiv:2310.18091v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.18091">http://arxiv.org/abs/2310.18091</a></li>
<li>Code URL: https://github.com/emundo/ecgan</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.18091]] Adversarial Anomaly Detection using Gaussian Priors and Nonlinear Anomaly Scores(http://arxiv.org/abs/2310.18091)</code></li>
<li>Summary: <p>Anomaly detection in imbalanced datasets is a frequent and crucial problem,
especially in the medical domain where retrieving and labeling irregularities
is often expensive. By combining the generative stability of a
$\beta$-variational autoencoder (VAE) with the discriminative strengths of
generative adversarial networks (GANs), we propose a novel model,
$\beta$-VAEGAN. We investigate methods for composing anomaly scores based on
the discriminative and reconstructive capabilities of our model. Existing work
focuses on linear combinations of these components to determine if data is
anomalous. We advance existing work by training a kernelized support vector
machine (SVM) on the respective error components to also consider nonlinear
relationships. This improves anomaly detection performance, while allowing
faster optimization. Lastly, we use the deviations from the Gaussian prior of
$\beta$-VAEGAN to form a novel anomaly score component. In comparison to
state-of-the-art work, we improve the $F_1$ score during anomaly detection from
0.85 to 0.92 on the widely used MITBIH Arrhythmia Database.
</p></li>
</ul>

<h3>Title: Sample Complexity Bounds for Score-Matching: Causal Discovery and Generative Modeling. (arXiv:2310.18123v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.18123">http://arxiv.org/abs/2310.18123</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.18123]] Sample Complexity Bounds for Score-Matching: Causal Discovery and Generative Modeling(http://arxiv.org/abs/2310.18123)</code></li>
<li>Summary: <p>This paper provides statistical sample complexity bounds for score-matching
and its applications in causal discovery. We demonstrate that accurate
estimation of the score function is achievable by training a standard deep ReLU
neural network using stochastic gradient descent. We establish bounds on the
error rate of recovering causal relationships using the score-matching-based
causal discovery method of Rolland et al. [2022], assuming a sufficiently good
estimation of the score function. Finally, we analyze the upper bound of
score-matching estimation within the score-based generative modeling, which has
been applied for causal discovery but is also of independent interest within
the domain of generative models.
</p></li>
</ul>

<h3>Title: MIM-GAN-based Anomaly Detection for Multivariate Time Series Data. (arXiv:2310.18257v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.18257">http://arxiv.org/abs/2310.18257</a></li>
<li>Code URL: https://github.com/explorerlu1024/mimad-gan</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.18257]] MIM-GAN-based Anomaly Detection for Multivariate Time Series Data(http://arxiv.org/abs/2310.18257)</code></li>
<li>Summary: <p>The loss function of Generative adversarial network(GAN) is an important
factor that affects the quality and diversity of the generated samples for
anomaly detection. In this paper, we propose an unsupervised multiple time
series anomaly detection algorithm based on the GAN with message importance
measure(MIM-GAN). In particular, the time series data is divided into
subsequences using a sliding window. Then a generator and a discriminator
designed based on the Long Short-Term Memory (LSTM) are employed to capture the
temporal correlations of the time series data. To avoid the local optimal
solution of loss function and the model collapse, we introduce an exponential
information measure into the loss function of GAN. Additionally, a discriminant
reconstruction score consisting on discrimination and reconstruction loss is
taken into account. The global optimal solution for the loss function is
derived and the model collapse is proved to be avoided in our proposed
MIM-GAN-based anomaly detection algorithm. Experimental results show that the
proposed MIM-GAN-based anomaly detection algorithm has superior performance in
terms of precision, recall, and F1 score.
</p></li>
</ul>

<h3>Title: Addressing GAN Training Instabilities via Tunable Classification Losses. (arXiv:2310.18291v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.18291">http://arxiv.org/abs/2310.18291</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.18291]] Addressing GAN Training Instabilities via Tunable Classification Losses(http://arxiv.org/abs/2310.18291)</code></li>
<li>Summary: <p>Generative adversarial networks (GANs), modeled as a zero-sum game between a
generator (G) and a discriminator (D), allow generating synthetic data with
formal guarantees. Noting that D is a classifier, we begin by reformulating the
GAN value function using class probability estimation (CPE) losses. We prove a
two-way correspondence between CPE loss GANs and $f$-GANs which minimize
$f$-divergences. We also show that all symmetric $f$-divergences are equivalent
in convergence. In the finite sample and model capacity setting, we define and
obtain bounds on estimation and generalization errors. We specialize these
results to $\alpha$-GANs, defined using $\alpha$-loss, a tunable CPE loss
family parametrized by $\alpha\in(0,\infty]$. We next introduce a class of
dual-objective GANs to address training instabilities of GANs by modeling each
player's objective using $\alpha$-loss to obtain $(\alpha_D,\alpha_G)$-GANs. We
show that the resulting non-zero sum game simplifies to minimizing an
$f$-divergence under appropriate conditions on $(\alpha_D,\alpha_G)$.
Generalizing this dual-objective formulation using CPE losses, we define and
obtain upper bounds on an appropriately defined estimation error. Finally, we
highlight the value of tuning $(\alpha_D,\alpha_G)$ in alleviating training
instabilities for the synthetic 2D Gaussian mixture ring as well as the large
publicly available Celeb-A and LSUN Classroom image datasets.
</p></li>
</ul>

<h2>large language model</h2>
<h3>Title: ControlLLM: Augment Language Models with Tools by Searching on Graphs. (arXiv:2310.17796v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.17796">http://arxiv.org/abs/2310.17796</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.17796]] ControlLLM: Augment Language Models with Tools by Searching on Graphs(http://arxiv.org/abs/2310.17796)</code></li>
<li>Summary: <p>We present ControlLLM, a novel framework that enables large language models
(LLMs) to utilize multi-modal tools for solving complex real-world tasks.
Despite the remarkable performance of LLMs, they still struggle with tool
invocation due to ambiguous user prompts, inaccurate tool selection and
parameterization, and inefficient tool scheduling. To overcome these
challenges, our framework comprises three key components: (1) a \textit{task
decomposer} that breaks down a complex task into clear subtasks with
well-defined inputs and outputs; (2) a \textit{Thoughts-on-Graph (ToG)
paradigm} that searches the optimal solution path on a pre-built tool graph,
which specifies the parameter and dependency relations among different tools;
and (3) an \textit{execution engine with a rich toolbox} that interprets the
solution path and runs the tools efficiently on different computational
devices. We evaluate our framework on diverse tasks involving image, audio, and
video processing, demonstrating its superior accuracy, efficiency, and
versatility compared to existing methods.
</p></li>
</ul>

<h3>Title: Image Clustering Conditioned on Text Criteria. (arXiv:2310.18297v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.18297">http://arxiv.org/abs/2310.18297</a></li>
<li>Code URL: https://github.com/sehyunkwon/ictc</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.18297]] Image Clustering Conditioned on Text Criteria(http://arxiv.org/abs/2310.18297)</code></li>
<li>Summary: <p>Classical clustering methods do not provide users with direct control of the
clustering results, and the clustering results may not be consistent with the
relevant criterion that a user has in mind. In this work, we present a new
methodology for performing image clustering based on user-specified text
criteria by leveraging modern vision-language models and large language models.
We call our method Image Clustering Conditioned on Text Criteria (IC$|$TC), and
it represents a different paradigm of image clustering. IC$|$TC requires a
minimal and practical degree of human intervention and grants the user
significant control over the clustering results in return. Our experiments show
that IC$|$TC can effectively cluster images with various criteria, such as
human action, physical location, or the person's mood, while significantly
outperforming baselines.
</p></li>
</ul>

<h3>Title: The impact of using an AI chatbot to respond to patient messages. (arXiv:2310.17703v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.17703">http://arxiv.org/abs/2310.17703</a></li>
<li>Code URL: https://github.com/aim-harvard/oncqa</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.17703]] The impact of using an AI chatbot to respond to patient messages(http://arxiv.org/abs/2310.17703)</code></li>
<li>Summary: <p>Documentation burden is a major contributor to clinician burnout, which is
rising nationally and is an urgent threat to our ability to care for patients.
Artificial intelligence (AI) chatbots, such as ChatGPT, could reduce clinician
burden by assisting with documentation. Although many hospitals are actively
integrating such systems into electronic medical record systems, AI chatbots
utility and impact on clinical decision-making have not been studied for this
intended use. We are the first to examine the utility of large language models
in assisting clinicians draft responses to patient questions. In our two-stage
cross-sectional study, 6 oncologists responded to 100 realistic synthetic
cancer patient scenarios and portal messages developed to reflect common
medical situations, first manually, then with AI assistance.
</p>
<p>We find AI-assisted responses were longer, less readable, but provided
acceptable drafts without edits 58% of time. AI assistance improved efficiency
77% of time, with low harm risk (82% safe). However, 7.7% unedited AI responses
could severely harm. In 31% cases, physicians thought AI drafts were
human-written. AI assistance led to more patient education recommendations,
fewer clinical actions than manual responses. Results show promise for AI to
improve clinician efficiency and patient care through assisting documentation,
if used judiciously. Monitoring model outputs and human-AI interaction remains
crucial for safe implementation.
</p></li>
</ul>

<h3>Title: Outlier Dimensions Encode Task-Specific Knowledge. (arXiv:2310.17715v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.17715">http://arxiv.org/abs/2310.17715</a></li>
<li>Code URL: https://github.com/wrudman/outlier_dimensions</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.17715]] Outlier Dimensions Encode Task-Specific Knowledge(http://arxiv.org/abs/2310.17715)</code></li>
<li>Summary: <p>Representations from large language models (LLMs) are known to be dominated
by a small subset of dimensions with exceedingly high variance. Previous works
have argued that although ablating these outlier dimensions in LLM
representations hurts downstream performance, outlier dimensions are
detrimental to the representational quality of embeddings. In this study, we
investigate how fine-tuning impacts outlier dimensions and show that 1) outlier
dimensions that occur in pre-training persist in fine-tuned models and 2) a
single outlier dimension can complete downstream tasks with a minimal error
rate. Our results suggest that outlier dimensions can encode crucial
task-specific knowledge and that the value of a representation in a single
outlier dimension drives downstream model decisions.
</p></li>
</ul>

<h3>Title: Large Language Models as Generalizable Policies for Embodied Tasks. (arXiv:2310.17722v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.17722">http://arxiv.org/abs/2310.17722</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.17722]] Large Language Models as Generalizable Policies for Embodied Tasks(http://arxiv.org/abs/2310.17722)</code></li>
<li>Summary: <p>We show that large language models (LLMs) can be adapted to be generalizable
policies for embodied visual tasks. Our approach, called Large LAnguage model
Reinforcement Learning Policy (LLaRP), adapts a pre-trained frozen LLM to take
as input text instructions and visual egocentric observations and output
actions directly in the environment. Using reinforcement learning, we train
LLaRP to see and act solely through environmental interactions. We show that
LLaRP is robust to complex paraphrasings of task instructions and can
generalize to new tasks that require novel optimal behavior. In particular, on
1,000 unseen tasks it achieves 42% success rate, 1.7x the success rate of other
common learned baselines or zero-shot applications of LLMs. Finally, to aid the
community in studying language conditioned, massively multi-task, embodied AI
problems we release a novel benchmark, Language Rearrangement, consisting of
150,000 training and 1,000 testing tasks for language-conditioned
rearrangement. Video examples of LLaRP in unseen Language Rearrangement
instructions are at https://llm-rl.github.io.
</p></li>
</ul>

<h3>Title: Salespeople vs SalesBot: Exploring the Role of Educational Value in Conversational Recommender Systems. (arXiv:2310.17749v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.17749">http://arxiv.org/abs/2310.17749</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.17749]] Salespeople vs SalesBot: Exploring the Role of Educational Value in Conversational Recommender Systems(http://arxiv.org/abs/2310.17749)</code></li>
<li>Summary: <p>Making big purchases requires consumers to research or consult a salesperson
to gain domain expertise. However, existing conversational recommender systems
(CRS) often overlook users' lack of background knowledge, focusing solely on
gathering preferences. In this work, we define a new problem space for
conversational agents that aim to provide both product recommendations and
educational value through mixed-type mixed-initiative dialog. We introduce
SalesOps, a framework that facilitates the simulation and evaluation of such
systems by leveraging recent advancements in large language models (LLMs). We
build SalesBot and ShopperBot, a pair of LLM-powered agents that can simulate
either side of the framework. A comprehensive human study compares SalesBot
against professional salespeople, revealing that although SalesBot approaches
professional performance in terms of fluency and informativeness, it lags
behind in recommendation quality. We emphasize the distinct limitations both
face in providing truthful information, highlighting the challenges of ensuring
faithfulness in the CRS context. We release our code and make all data
available.
</p></li>
</ul>

<h3>Title: Data-Centric Financial Large Language Models. (arXiv:2310.17784v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.17784">http://arxiv.org/abs/2310.17784</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.17784]] Data-Centric Financial Large Language Models(http://arxiv.org/abs/2310.17784)</code></li>
<li>Summary: <p>Large language models (LLMs) show promise for natural language tasks but
struggle when applied directly to complex domains like finance. LLMs have
difficulty reasoning about and integrating all relevant information. We propose
a data-centric approach to enable LLMs to better handle financial tasks. Our
key insight is that rather than overloading the LLM with everything at once, it
is more effective to preprocess and pre-understand the data. We create a
financial LLM (FLLM) using multitask prompt-based finetuning to achieve data
pre-processing and pre-understanding. However, labeled data is scarce for each
task. To overcome manual annotation costs, we employ abductive augmentation
reasoning (AAR) to automatically generate training data by modifying the pseudo
labels from FLLM's own outputs. Experiments show our data-centric FLLM with AAR
substantially outperforms baseline financial LLMs designed for raw text,
achieving state-of-the-art on financial analysis and interpretation tasks. We
also open source a new benchmark for financial analysis and interpretation. Our
methodology provides a promising path to unlock LLMs' potential for complex
real-world domains.
</p></li>
</ul>

<h3>Title: Evaluation of large language models using an Indian language LGBTI+ lexicon. (arXiv:2310.17787v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.17787">http://arxiv.org/abs/2310.17787</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.17787]] Evaluation of large language models using an Indian language LGBTI+ lexicon(http://arxiv.org/abs/2310.17787)</code></li>
<li>Summary: <p>Large language models (LLMs) are typically evaluated on the basis of
task-based benchmarks such as MMLU. Such benchmarks do not examine responsible
behaviour of LLMs in specific contexts. This is particularly true in the LGBTI+
context where social stereotypes may result in variation in LGBTI+ terminology.
Therefore, domain-specific lexicons or dictionaries may be useful as a
representative list of words against which the LLM's behaviour needs to be
evaluated. This paper presents a methodology for evaluation of LLMs using an
LGBTI+ lexicon in Indian languages. The methodology consists of four steps:
formulating NLP tasks relevant to the expected behaviour, creating prompts that
test LLMs, using the LLMs to obtain the output and, finally, manually
evaluating the results. Our qualitative analysis shows that the three LLMs we
experiment on are unable to detect underlying hateful content. Similarly, we
observe limitations in using machine translation as means to evaluate natural
language understanding in languages other than English. The methodology
presented in this paper can be useful for LGBTI+ lexicons in other languages as
well as other domain-specific lexicons. The work done in this paper opens
avenues for responsible behaviour of LLMs, as demonstrated in the context of
prevalent social perception of the LGBTI+ community.
</p></li>
</ul>

<h3>Title: "You Are An Expert Linguistic Annotator": Limits of LLMs as Analyzers of Abstract Meaning Representation. (arXiv:2310.17793v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.17793">http://arxiv.org/abs/2310.17793</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.17793]] "You Are An Expert Linguistic Annotator": Limits of LLMs as Analyzers of Abstract Meaning Representation(http://arxiv.org/abs/2310.17793)</code></li>
<li>Summary: <p>Large language models (LLMs) show amazing proficiency and fluency in the use
of language. Does this mean that they have also acquired insightful linguistic
knowledge about the language, to an extent that they can serve as an "expert
linguistic annotator"? In this paper, we examine the successes and limitations
of the GPT-3, ChatGPT, and GPT-4 models in analysis of sentence meaning
structure, focusing on the Abstract Meaning Representation (AMR; Banarescu et
al. 2013) parsing formalism, which provides rich graphical representations of
sentence meaning structure while abstracting away from surface forms. We
compare models' analysis of this semantic structure across two settings: 1)
direct production of AMR parses based on zero- and few-shot prompts, and 2)
indirect partial reconstruction of AMR via metalinguistic natural language
queries (e.g., "Identify the primary event of this sentence, and the predicate
corresponding to that event."). Across these settings, we find that models can
reliably reproduce the basic format of AMR, and can often capture core event,
argument, and modifier structure -- however, model outputs are prone to
frequent and major errors, and holistic analysis of parse acceptability shows
that even with few-shot demonstrations, models have virtually 0% success in
producing fully accurate parses. Eliciting natural language responses produces
similar patterns of errors. Overall, our findings indicate that these models
out-of-the-box can capture aspects of semantic structure, but there remain key
limitations in their ability to support fully accurate semantic analyses or
parses.
</p></li>
</ul>

<h3>Title: From Values to Opinions: Predicting Human Behaviors and Stances Using Value-Injected Large Language Models. (arXiv:2310.17857v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.17857">http://arxiv.org/abs/2310.17857</a></li>
<li>Code URL: https://github.com/dongjunkang/vim</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.17857]] From Values to Opinions: Predicting Human Behaviors and Stances Using Value-Injected Large Language Models(http://arxiv.org/abs/2310.17857)</code></li>
<li>Summary: <p>Being able to predict people's opinions on issues and behaviors in realistic
scenarios can be helpful in various domains, such as politics and marketing.
However, conducting large-scale surveys like the European Social Survey to
solicit people's opinions on individual issues can incur prohibitive costs.
Leveraging prior research showing influence of core human values on individual
decisions and actions, we propose to use value-injected large language models
(LLM) to predict opinions and behaviors. To this end, we present Value
Injection Method (VIM), a collection of two methods -- argument generation and
question answering -- designed to inject targeted value distributions into LLMs
via fine-tuning. We then conduct a series of experiments on four tasks to test
the effectiveness of VIM and the possibility of using value-injected LLMs to
predict opinions and behaviors of people. We find that LLMs value-injected with
variations of VIM substantially outperform the baselines. Also, the results
suggest that opinions and behaviors can be better predicted using
value-injected LLMs than the baseline approaches.
</p></li>
</ul>

<h3>Title: TarGEN: Targeted Data Generation with Large Language Models. (arXiv:2310.17876v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.17876">http://arxiv.org/abs/2310.17876</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.17876]] TarGEN: Targeted Data Generation with Large Language Models(http://arxiv.org/abs/2310.17876)</code></li>
<li>Summary: <p>The rapid advancement of large language models (LLMs) has sparked interest in
data synthesis techniques, aiming to generate diverse and high-quality
synthetic datasets. However, these synthetic datasets often suffer from a lack
of diversity and added noise. In this paper, we present TarGEN, a multi-step
prompting strategy for generating high-quality synthetic datasets utilizing a
LLM. An advantage of TarGEN is its seedless nature; it does not require
specific task instances, broadening its applicability beyond task replication.
We augment TarGEN with a method known as self-correction empowering LLMs to
rectify inaccurately labeled instances during dataset creation, ensuring
reliable labels. To assess our technique's effectiveness, we emulate 8 tasks
from the SuperGLUE benchmark and finetune various language models, including
encoder-only, encoder-decoder, and decoder-only models on both synthetic and
original training sets. Evaluation on the original test set reveals that models
trained on datasets generated by TarGEN perform approximately 1-2% points
better than those trained on original datasets (82.84% via syn. vs. 81.12% on
og. using Flan-T5). When incorporating instruction tuning, the performance
increases to 84.54% on synthetic data vs. 81.49% on original data by Flan-T5. A
comprehensive analysis of the synthetic dataset compared to the original
dataset reveals that the synthetic dataset demonstrates similar or higher
levels of dataset complexity and diversity. Furthermore, the synthetic dataset
displays a bias level that aligns closely with the original dataset. Finally,
when pre-finetuned on our synthetic SuperGLUE dataset, T5-3B yields impressive
results on the OpenLLM leaderboard, surpassing the model trained on the
Self-Instruct dataset by 4.14% points. We hope that TarGEN can be helpful for
quality data generation and reducing the human efforts to create complex
benchmarks.
</p></li>
</ul>

<h3>Title: ASPIRO: Any-shot Structured Parsing-error-Induced ReprOmpting for Consistent Data-to-Text Generation. (arXiv:2310.17877v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.17877">http://arxiv.org/abs/2310.17877</a></li>
<li>Code URL: https://github.com/vejvarm/aspiro</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.17877]] ASPIRO: Any-shot Structured Parsing-error-Induced ReprOmpting for Consistent Data-to-Text Generation(http://arxiv.org/abs/2310.17877)</code></li>
<li>Summary: <p>We present ASPIRO, an approach for structured data verbalisation into short
template sentences in zero to few-shot settings. Unlike previous methods, our
approach prompts large language models (LLMs) to directly produce
entity-agnostic templates, rather than relying on LLMs to faithfully copy the
given example entities, or validating/crafting the templates manually. We
incorporate LLM re-prompting, triggered by algorithmic parsing checks, as well
as the PARENT metric induced consistency validation to identify and rectify
template generation problems in real-time. ASPIRO, compared to direct LLM
output, averages 66\% parsing error rate reduction in generated verbalisations
of RDF triples on the DART dataset. Our best 5-shot text-davinci-003 setup,
scoring BLEU of 50.62, METEOR of 45.16, BLEURT of 0.82, NUBIA of 0.87, and
PARENT of 0.8962 on the Rel2Text dataset, competes effectively with recent
fine-tuned pre-trained language models.
</p></li>
</ul>

<h3>Title: Natural Language Interfaces for Tabular Data Querying and Visualization: A Survey. (arXiv:2310.17894v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.17894">http://arxiv.org/abs/2310.17894</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.17894]] Natural Language Interfaces for Tabular Data Querying and Visualization: A Survey(http://arxiv.org/abs/2310.17894)</code></li>
<li>Summary: <p>The emergence of natural language processing has revolutionized the way users
interact with tabular data, enabling a shift from traditional query languages
and manual plotting to more intuitive, language-based interfaces. The rise of
large language models (LLMs) such as ChatGPT and its successors has further
advanced this field, opening new avenues for natural language processing
techniques. This survey presents a comprehensive overview of natural language
interfaces for tabular data querying and visualization, which allow users to
interact with data using natural language queries. We introduce the fundamental
concepts and techniques underlying these interfaces with a particular emphasis
on semantic parsing, the key technology facilitating the translation from
natural language to SQL queries or data visualization commands. We then delve
into the recent advancements in Text-to-SQL and Text-to-Vis problems from the
perspectives of datasets, methodologies, metrics, and system designs. This
includes a deep dive into the influence of LLMs, highlighting their strengths,
limitations, and potential for future improvements. Through this survey, we aim
to provide a roadmap for researchers and practitioners interested in developing
and applying natural language interfaces for data interaction in the era of
large language models.
</p></li>
</ul>

<h3>Title: Knowing What LLMs DO NOT Know: A Simple Yet Effective Self-Detection Method. (arXiv:2310.17918v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.17918">http://arxiv.org/abs/2310.17918</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.17918]] Knowing What LLMs DO NOT Know: A Simple Yet Effective Self-Detection Method(http://arxiv.org/abs/2310.17918)</code></li>
<li>Summary: <p>Large Language Models (LLMs) have shown great potential in Natural Language
Processing (NLP) tasks. However, recent literature reveals that LLMs generate
nonfactual responses intermittently, which impedes the LLMs' reliability for
further utilization. In this paper, we propose a novel self-detection method to
detect which questions that a LLM does not know that are prone to generate
nonfactual results. Specifically, we first diversify the textual expressions
for a given question and collect the corresponding answers. Then we examine the
divergencies between the generated answers to identify the questions that the
model may generate falsehoods. All of the above steps can be accomplished by
prompting the LLMs themselves without referring to any other external
resources. We conduct comprehensive experiments and demonstrate the
effectiveness of our method on recently released LLMs, e.g., Vicuna, ChatGPT,
and GPT-4.
</p></li>
</ul>

<h3>Title: SOUL: Towards Sentiment and Opinion Understanding of Language. (arXiv:2310.17924v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.17924">http://arxiv.org/abs/2310.17924</a></li>
<li>Code URL: https://github.com/damo-nlp-sg/soul</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.17924]] SOUL: Towards Sentiment and Opinion Understanding of Language(http://arxiv.org/abs/2310.17924)</code></li>
<li>Summary: <p>Sentiment analysis is a well-established natural language processing task,
with sentiment polarity classification being one of its most popular and
representative tasks. However, despite the success of pre-trained language
models in this area, they often fall short of capturing the broader
complexities of sentiment analysis. To address this issue, we propose a new
task called Sentiment and Opinion Understanding of Language (SOUL). SOUL aims
to evaluate sentiment understanding through two subtasks: Review Comprehension
(RC) and Justification Generation (JG). RC seeks to validate statements that
focus on subjective information based on a review text, while JG requires
models to provide explanations for their sentiment predictions. To enable
comprehensive evaluation, we annotate a new dataset comprising 15,028
statements from 3,638 reviews. Experimental results indicate that SOUL is a
challenging task for both small and large language models, with a performance
gap of up to 27% when compared to human performance. Furthermore, evaluations
conducted with both human experts and GPT-4 highlight the limitations of the
small language model in generating reasoning-based justifications. These
findings underscore the challenging nature of the SOUL task for existing
models, emphasizing the need for further advancements in sentiment analysis to
address its complexities. The new dataset and code are available at
https://github.com/DAMO-NLP-SG/SOUL.
</p></li>
</ul>

<h3>Title: NLP Evaluation in trouble: On the Need to Measure LLM Data Contamination for each Benchmark. (arXiv:2310.18018v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.18018">http://arxiv.org/abs/2310.18018</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.18018]] NLP Evaluation in trouble: On the Need to Measure LLM Data Contamination for each Benchmark(http://arxiv.org/abs/2310.18018)</code></li>
<li>Summary: <p>In this position paper, we argue that the classical evaluation on Natural
Language Processing (NLP) tasks using annotated benchmarks is in trouble. The
worst kind of data contamination happens when a Large Language Model (LLM) is
trained on the test split of a benchmark, and then evaluated in the same
benchmark. The extent of the problem is unknown, as it is not straightforward
to measure. Contamination causes an overestimation of the performance of a
contaminated model in a target benchmark and associated task with respect to
their non-contaminated counterparts. The consequences can be very harmful, with
wrong scientific conclusions being published while other correct ones are
discarded. This position paper defines different levels of data contamination
and argues for a community effort, including the development of automatic and
semi-automatic measures to detect when data from a benchmark was exposed to a
model, and suggestions for flagging papers with conclusions that are
compromised by data contamination.
</p></li>
</ul>

<h3>Title: Large language models for aspect-based sentiment analysis. (arXiv:2310.18025v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.18025">http://arxiv.org/abs/2310.18025</a></li>
<li>Code URL: https://github.com/qagentur/absa_llm</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.18025]] Large language models for aspect-based sentiment analysis(http://arxiv.org/abs/2310.18025)</code></li>
<li>Summary: <p>Large language models (LLMs) offer unprecedented text completion
capabilities. As general models, they can fulfill a wide range of roles,
including those of more specialized models. We assess the performance of GPT-4
and GPT-3.5 in zero shot, few shot and fine-tuned settings on the aspect-based
sentiment analysis (ABSA) task. Fine-tuned GPT-3.5 achieves a state-of-the-art
F1 score of 83.8 on the joint aspect term extraction and polarity
classification task of the SemEval-2014 Task 4, improving upon InstructABSA
[@scaria_instructabsa_2023] by 5.7%. However, this comes at the price of 1000
times more model parameters and thus increased inference cost. We discuss the
the cost-performance trade-offs of different models, and analyze the typical
errors that they make. Our results also indicate that detailed prompts improve
performance in zero-shot and few-shot settings but are not necessary for
fine-tuned models. This evidence is relevant for practioners that are faced
with the choice of prompt engineering versus fine-tuning when using LLMs for
ABSA.
</p></li>
</ul>

<h3>Title: Knowledge Corpus Error in Question Answering. (arXiv:2310.18076v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.18076">http://arxiv.org/abs/2310.18076</a></li>
<li>Code URL: https://github.com/xfactlab/emnlp2023-knowledge-corpus-error</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.18076]] Knowledge Corpus Error in Question Answering(http://arxiv.org/abs/2310.18076)</code></li>
<li>Summary: <p>Recent works in open-domain question answering (QA) have explored generating
context passages from large language models (LLMs), replacing the traditional
retrieval step in the QA pipeline. However, it is not well understood why
generated passages can be more effective than retrieved ones. This study
revisits the conventional formulation of QA and introduces the concept of
knowledge corpus error. This error arises when the knowledge corpus used for
retrieval is only a subset of the entire string space, potentially excluding
more helpful passages that exist outside the corpus. LLMs may mitigate this
shortcoming by generating passages in a larger space. We come up with an
experiment of paraphrasing human-annotated gold context using LLMs to observe
knowledge corpus error empirically. Our results across three QA benchmarks
reveal an increased performance (10% - 13%) when using paraphrased passage,
indicating a signal for the existence of knowledge corpus error. Our code is
available at https://github.com/xfactlab/emnlp2023-knowledge-corpus-error
</p></li>
</ul>

<h3>Title: Ask more, know better: Reinforce-Learned Prompt Questions for Decision Making with Large Language Models. (arXiv:2310.18127v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.18127">http://arxiv.org/abs/2310.18127</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.18127]] Ask more, know better: Reinforce-Learned Prompt Questions for Decision Making with Large Language Models(http://arxiv.org/abs/2310.18127)</code></li>
<li>Summary: <p>Large language models (LLMs) demonstrate their promise in tackling
complicated practical challenges by combining action-based policies with chain
of thought (CoT) reasoning. Having high-quality prompts on hand, however, is
vital to the framework's effectiveness. Currently, these prompts are
handcrafted utilizing extensive human labor, resulting in CoT policies that
frequently fail to generalize. Human intervention is also required in order to
develop grounding functions that ensure low-level controllers appropriately
process CoT reasoning. In this paper, we take the first step towards a fully
integrated end-to-end framework for task-solving in real settings employing
complicated reasoning. To that purpose, we offer a new leader-follower bilevel
framework capable of learning to ask relevant questions (prompts) and
subsequently undertaking reasoning to guide the learning of actions to be
performed in an environment. A good prompt should make introspective revisions
based on historical findings, leading the CoT to consider the anticipated
goals. A prompt-generator policy has its own aim in our system, allowing it to
adapt to the action policy and automatically root the CoT process towards
outputs that lead to decisive, high-performing actions. Meanwhile, the action
policy is learning how to use the CoT outputs to take specific actions. Our
empirical data reveal that our system outperforms leading methods in agent
learning benchmarks such as Overcooked and FourRoom.
</p></li>
</ul>

<h3>Title: Disentangled Representation Learning with Large Language Models for Text-Attributed Graphs. (arXiv:2310.18152v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.18152">http://arxiv.org/abs/2310.18152</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.18152]] Disentangled Representation Learning with Large Language Models for Text-Attributed Graphs(http://arxiv.org/abs/2310.18152)</code></li>
<li>Summary: <p>Text-attributed graphs (TAGs) are prevalent on the web and research over TAGs
such as citation networks, e-commerce networks and social networks has
attracted considerable attention in the web community. Recently, large language
models (LLMs) have demonstrated exceptional capabilities across a wide range of
tasks. However, the existing works focus on harnessing the potential of LLMs
solely relying on prompts to convey graph structure information to LLMs, thus
suffering from insufficient understanding of the complex structural
relationships within TAGs. To address this problem, in this paper we present
the Disentangled Graph-Text Learner (DGTL) model, which is able to enhance the
reasoning and predicting capabilities of LLMs for TAGs. Our proposed DGTL model
incorporates graph structure information through tailored disentangled graph
neural network (GNN) layers, enabling LLMs to capture the intricate
relationships hidden in text-attributed graphs from multiple structural
factors. Furthermore, DGTL operates with frozen pre-trained LLMs, reducing
computational costs and allowing much more flexibility in combining with
different LLM models. Experimental evaluations demonstrate the effectiveness of
the proposed DGTL model on achieving superior or comparable performance over
state-of-the-art baselines. Additionally, we also demonstrate that our DGTL
model can offer natural language explanations for predictions, thereby
significantly enhancing model interpretability.
</p></li>
</ul>

<h3>Title: MPrompt: Exploring Multi-level Prompt Tuning for Machine Reading Comprehension. (arXiv:2310.18167v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.18167">http://arxiv.org/abs/2310.18167</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.18167]] MPrompt: Exploring Multi-level Prompt Tuning for Machine Reading Comprehension(http://arxiv.org/abs/2310.18167)</code></li>
<li>Summary: <p>The large language models have achieved superior performance on various
natural language tasks. One major drawback of such approaches is they are
resource-intensive in fine-tuning new datasets. Soft-prompt tuning presents a
resource-efficient solution to fine-tune the pre-trained language models (PLMs)
while keeping their weight frozen. Existing soft prompt methods mainly focus on
designing the input-independent prompts that steer the model to fit the domain
of the new dataset. Those methods often ignore the fine-grained information
about the task and context of the text. In this paper, we propose a multi-level
prompt tuning (MPrompt) method for machine reading comprehension. It utilizes
prompts at task-specific, domain-specific, and context-specific levels to
enhance the comprehension of input semantics at different granularities. We
also propose an independence constraint to steer each domain-specific prompt to
focus on information within its domain to avoid redundancy. Moreover, we
present a prompt generator that incorporates context-related knowledge in the
prompt generation to enhance contextual relevancy. We conducted extensive
experiments on 12 benchmarks of various QA formats and achieved an average
improvement of 1.94\% over the state-of-the-art methods.
</p></li>
</ul>

<h3>Title: ArcheType: A Novel Framework for Open-Source Column Type Annotation using Large Language Models. (arXiv:2310.18208v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.18208">http://arxiv.org/abs/2310.18208</a></li>
<li>Code URL: https://github.com/penfever/archetype</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.18208]] ArcheType: A Novel Framework for Open-Source Column Type Annotation using Large Language Models(http://arxiv.org/abs/2310.18208)</code></li>
<li>Summary: <p>Existing deep-learning approaches to semantic column type annotation (CTA)
have important shortcomings: they rely on semantic types which are fixed at
training time; require a large number of training samples per type and incur
large run-time inference costs; and their performance can degrade when
evaluated on novel datasets, even when types remain constant. Large language
models have exhibited strong zero-shot classification performance on a wide
range of tasks and in this paper we explore their use for CTA. We introduce
ArcheType, a simple, practical method for context sampling, prompt
serialization, model querying, and label remapping, which enables large
language models to solve column type annotation problems in a fully zero-shot
manner. We ablate each component of our method separately, and establish that
improvements to context sampling and label remapping provide the most
consistent gains. ArcheType establishes new state-of-the-art performance on
both zero-shot and fine-tuned CTA, including three new domain-specific
benchmarks, which we release, along with the code to reproduce our results at
https://github.com/penfever/ArcheType.
</p></li>
</ul>

<h3>Title: FP8-LM: Training FP8 Large Language Models. (arXiv:2310.18313v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.18313">http://arxiv.org/abs/2310.18313</a></li>
<li>Code URL: https://github.com/azure/ms-amp</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.18313]] FP8-LM: Training FP8 Large Language Models(http://arxiv.org/abs/2310.18313)</code></li>
<li>Summary: <p>In this paper, we explore FP8 low-bit data formats for efficient training of
large language models (LLMs). Our key insight is that most variables, such as
gradients and optimizer states, in LLM training can employ low-precision data
formats without compromising model accuracy and requiring no changes to
hyper-parameters. Specifically, we propose a new FP8 automatic mixed-precision
framework for training LLMs. This framework offers three levels of FP8
utilization to streamline mixed-precision and distributed parallel training for
LLMs. It gradually incorporates 8-bit gradients, optimizer states, and
distributed learning in an incremental manner. Experiment results show that,
during the training of GPT-175B model on H100 GPU platform, our FP8
mixed-precision training framework not only achieved a remarkable 42% reduction
in real memory usage but also ran 64% faster than the widely adopted BF16
framework (i.e., Megatron-LM), surpassing the speed of Nvidia Transformer
Engine by 17%. This largely reduces the training costs for large foundation
models. Furthermore, our FP8 mixed-precision training methodology is generic.
It can be seamlessly applied to other tasks such as LLM instruction tuning and
reinforcement learning with human feedback, offering savings in fine-tuning
expenses. Our FP8 low-precision training framework is open-sourced at
{https://github.com/Azure/MS-AMP}{aka.ms/MS.AMP}.
</p></li>
</ul>

<h2>segmentation</h2>
<h3>Title: SynergyNet: Bridging the Gap between Discrete and Continuous Representations for Precise Medical Image Segmentation. (arXiv:2310.17764v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.17764">http://arxiv.org/abs/2310.17764</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.17764]] SynergyNet: Bridging the Gap between Discrete and Continuous Representations for Precise Medical Image Segmentation(http://arxiv.org/abs/2310.17764)</code></li>
<li>Summary: <p>In recent years, continuous latent space (CLS) and discrete latent space
(DLS) deep learning models have been proposed for medical image analysis for
improved performance. However, these models encounter distinct challenges. CLS
models capture intricate details but often lack interpretability in terms of
structural representation and robustness due to their emphasis on low-level
features. Conversely, DLS models offer interpretability, robustness, and the
ability to capture coarse-grained information thanks to their structured latent
space. However, DLS models have limited efficacy in capturing fine-grained
details. To address the limitations of both DLS and CLS models, we propose
SynergyNet, a novel bottleneck architecture designed to enhance existing
encoder-decoder segmentation frameworks. SynergyNet seamlessly integrates
discrete and continuous representations to harness complementary information
and successfully preserves both fine and coarse-grained details in the learned
representations. Our extensive experiment on multi-organ segmentation and
cardiac datasets demonstrates that SynergyNet outperforms other state of the
art methods, including TransUNet: dice scores improving by 2.16%, and Hausdorff
scores improving by 11.13%, respectively. When evaluating skin lesion and brain
tumor segmentation datasets, we observe a remarkable improvement of 1.71% in
Intersection-over Union scores for skin lesion segmentation and of 8.58% for
brain tumor segmentation. Our innovative approach paves the way for enhancing
the overall performance and capabilities of deep learning models in the
critical domain of medical image analysis.
</p></li>
</ul>

<h3>Title: Image Prior and Posterior Conditional Probability Representation for Efficient Damage Assessment. (arXiv:2310.17801v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.17801">http://arxiv.org/abs/2310.17801</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.17801]] Image Prior and Posterior Conditional Probability Representation for Efficient Damage Assessment(http://arxiv.org/abs/2310.17801)</code></li>
<li>Summary: <p>It is important to quantify Damage Assessment (DA) for Human Assistance and
Disaster Response (HADR) applications. In this paper, to achieve efficient and
scalable DA in HADR, an image prior and posterior conditional probability
(IP2CP) is developed as an effective computational imaging representation.
Equipped with the IP2CP representation, the matching pre- and post-disaster
images are effectively encoded into one image that is then processed using deep
learning approaches to determine the damage levels. Two scenarios of crucial
importance for the practical use of DA in HADR applications are examined:
pixel-wise semantic segmentation and patch-based contrastive learning-based
global damage classification. Results achieved by IP2CP in both scenarios
demonstrate promising performances, showing that our IP2CP-based methods within
the deep learning framework can effectively achieve data and computational
efficiency, which is of utmost importance for the DA in HADR applications.
</p></li>
</ul>

<h3>Title: SmooSeg: Smoothness Prior for Unsupervised Semantic Segmentation. (arXiv:2310.17874v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.17874">http://arxiv.org/abs/2310.17874</a></li>
<li>Code URL: https://github.com/mc-lan/smooseg</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.17874]] SmooSeg: Smoothness Prior for Unsupervised Semantic Segmentation(http://arxiv.org/abs/2310.17874)</code></li>
<li>Summary: <p>Unsupervised semantic segmentation is a challenging task that segments images
into semantic groups without manual annotation. Prior works have primarily
focused on leveraging prior knowledge of semantic consistency or priori
concepts from self-supervised learning methods, which often overlook the
coherence property of image segments. In this paper, we demonstrate that the
smoothness prior, asserting that close features in a metric space share the
same semantics, can significantly simplify segmentation by casting unsupervised
semantic segmentation as an energy minimization problem. Under this paradigm,
we propose a novel approach called SmooSeg that harnesses self-supervised
learning methods to model the closeness relationships among observations as
smoothness signals. To effectively discover coherent semantic segments, we
introduce a novel smoothness loss that promotes piecewise smoothness within
segments while preserving discontinuities across different segments.
Additionally, to further enhance segmentation quality, we design an asymmetric
teacher-student style predictor that generates smoothly updated pseudo labels,
facilitating an optimal fit between observations and labeling outputs. Thanks
to the rich supervision cues of the smoothness prior, our SmooSeg significantly
outperforms STEGO in terms of pixel accuracy on three datasets: COCOStuff
(+14.9%), Cityscapes (+13.0%), and Potsdam-3 (+5.7%).
</p></li>
</ul>

<h3>Title: Instance Segmentation under Occlusions via Location-aware Copy-Paste Data Augmentation. (arXiv:2310.17949v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.17949">http://arxiv.org/abs/2310.17949</a></li>
<li>Code URL: https://github.com/nguyendinhson-kaist/mmsports23-seg-autoid</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.17949]] Instance Segmentation under Occlusions via Location-aware Copy-Paste Data Augmentation(http://arxiv.org/abs/2310.17949)</code></li>
<li>Summary: <p>Occlusion is a long-standing problem in computer vision, particularly in
instance segmentation. ACM MMSports 2023 DeepSportRadar has introduced a
dataset that focuses on segmenting human subjects within a basketball context
and a specialized evaluation metric for occlusion scenarios. Given the modest
size of the dataset and the highly deformable nature of the objects to be
segmented, this challenge demands the application of robust data augmentation
techniques and wisely-chosen deep learning architectures. Our work (ranked 1st
in the competition) first proposes a novel data augmentation technique, capable
of generating more training samples with wider distribution. Then, we adopt a
new architecture - Hybrid Task Cascade (HTC) framework with CBNetV2 as backbone
and MaskIoU head to improve segmentation performance. Furthermore, we employ a
Stochastic Weight Averaging (SWA) training strategy to improve the model's
generalization. As a result, we achieve a remarkable occlusion score (OM) of
0.533 on the challenge dataset, securing the top-1 position on the leaderboard.
Source code is available at this
https://github.com/nguyendinhson-kaist/MMSports23-Seg-AutoID.
</p></li>
</ul>

<h3>Title: Text Augmented Spatial-aware Zero-shot Referring Image Segmentation. (arXiv:2310.18049v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.18049">http://arxiv.org/abs/2310.18049</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.18049]] Text Augmented Spatial-aware Zero-shot Referring Image Segmentation(http://arxiv.org/abs/2310.18049)</code></li>
<li>Summary: <p>In this paper, we study a challenging task of zero-shot referring image
segmentation. This task aims to identify the instance mask that is most related
to a referring expression without training on pixel-level annotations. Previous
research takes advantage of pre-trained cross-modal models, e.g., CLIP, to
align instance-level masks with referring expressions. %Yet, CLIP only
considers image-text pair level alignment, which neglects fine-grained image
region and complex sentence matching. Yet, CLIP only considers the global-level
alignment of image-text pairs, neglecting fine-grained matching between the
referring sentence and local image regions. To address this challenge, we
introduce a Text Augmented Spatial-aware (TAS) zero-shot referring image
segmentation framework that is training-free and robust to various visual
encoders. TAS incorporates a mask proposal network for instance-level mask
extraction, a text-augmented visual-text matching score for mining the
image-text correlation, and a spatial rectifier for mask post-processing.
Notably, the text-augmented visual-text matching score leverages a $P$ score
and an $N$-score in addition to the typical visual-text matching score. The
$P$-score is utilized to close the visual-text domain gap through a surrogate
captioning model, where the score is computed between the surrogate
model-generated texts and the referring expression. The $N$-score considers the
fine-grained alignment of region-text pairs via negative phrase mining,
encouraging the masked image to be repelled from the mined distracting phrases.
Extensive experiments are conducted on various datasets, including RefCOCO,
RefCOCO+, and RefCOCOg. The proposed method clearly outperforms
state-of-the-art zero-shot referring image segmentation methods.
</p></li>
</ul>

<h3>Title: A Chebyshev Confidence Guided Source-Free Domain Adaptation Framework for Medical Image Segmentation. (arXiv:2310.18087v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.18087">http://arxiv.org/abs/2310.18087</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.18087]] A Chebyshev Confidence Guided Source-Free Domain Adaptation Framework for Medical Image Segmentation(http://arxiv.org/abs/2310.18087)</code></li>
<li>Summary: <p>Source-free domain adaptation (SFDA) aims to adapt models trained on a
labeled source domain to an unlabeled target domain without the access to
source data. In medical imaging scenarios, the practical significance of SFDA
methods has been emphasized due to privacy concerns. Recent State-of-the-art
SFDA methods primarily rely on self-training based on pseudo-labels (PLs).
Unfortunately, PLs suffer from accuracy deterioration caused by domain shift,
and thus limit the effectiveness of the adaptation process. To address this
issue, we propose a Chebyshev confidence guided SFDA framework to accurately
assess the reliability of PLs and generate self-improving PLs for
self-training. The Chebyshev confidence is estimated by calculating probability
lower bound of the PL confidence, given the prediction and the corresponding
uncertainty. Leveraging the Chebyshev confidence, we introduce two
confidence-guided denoising methods: direct denoising and prototypical
denoising. Additionally, we propose a novel teacher-student joint training
scheme (TJTS) that incorporates a confidence weighting module to improve PLs
iteratively. The TJTS, in collaboration with the denoising methods, effectively
prevents the propagation of noise and enhances the accuracy of PLs. Extensive
experiments in diverse domain scenarios validate the effectiveness of our
proposed framework and establish its superiority over state-of-the-art SFDA
methods. Our paper contributes to the field of SFDA by providing a novel
approach for precisely estimating the reliability of pseudo-labels and a
framework for obtaining high-quality PLs, resulting in improved adaptation
performance.
</p></li>
</ul>

<h3>Title: Semi-Supervised Panoptic Narrative Grounding. (arXiv:2310.18142v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.18142">http://arxiv.org/abs/2310.18142</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.18142]] Semi-Supervised Panoptic Narrative Grounding(http://arxiv.org/abs/2310.18142)</code></li>
<li>Summary: <p>Despite considerable progress, the advancement of Panoptic Narrative
Grounding (PNG) remains hindered by costly annotations. In this paper, we
introduce a novel Semi-Supervised Panoptic Narrative Grounding (SS-PNG)
learning scheme, capitalizing on a smaller set of labeled image-text pairs and
a larger set of unlabeled pairs to achieve competitive performance. Unlike
visual segmentation tasks, PNG involves one pixel belonging to multiple
open-ended nouns. As a result, existing multi-class based semi-supervised
segmentation frameworks cannot be directly applied to this task. To address
this challenge, we first develop a novel SS-PNG Network (SS-PNG-NW) tailored to
the SS-PNG setting. We thoroughly investigate strategies such as Burn-In and
data augmentation to determine the optimal generic configuration for the
SS-PNG-NW. Additionally, to tackle the issue of imbalanced pseudo-label
quality, we propose a Quality-Based Loss Adjustment (QLA) approach to adjust
the semi-supervised objective, resulting in an enhanced SS-PNG-NW+. Employing
our proposed QLA, we improve BCE Loss and Dice loss at pixel and mask levels,
respectively. We conduct extensive experiments on PNG datasets, with our
SS-PNG-NW+ demonstrating promising results comparable to fully-supervised
models across all data ratios. Remarkably, our SS-PNG-NW+ outperforms
fully-supervised models with only 30% and 50% supervision data, exceeding their
performance by 0.8% and 1.1% respectively. This highlights the effectiveness of
our proposed SS-PNG-NW+ in overcoming the challenges posed by limited
annotations and enhancing the applicability of PNG tasks. The source code is
available at https://github.com/nini0919/SSPNG.
</p></li>
</ul>

<h3>Title: A Self-Supervised Approach to Land Cover Segmentation. (arXiv:2310.18251v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.18251">http://arxiv.org/abs/2310.18251</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.18251]] A Self-Supervised Approach to Land Cover Segmentation(http://arxiv.org/abs/2310.18251)</code></li>
<li>Summary: <p>Land use/land cover change (LULC) maps are integral resources in earth
science and agricultural research. Due to the nature of such maps, the creation
of LULC maps is often constrained by the time and human resources necessary to
accurately annotate satellite imagery and remote sensing data. While computer
vision models that perform semantic segmentation to create detailed labels from
such data are not uncommon, litle research has been done on self-supervised and
unsupervised approaches to labelling LULC maps without the use of ground-truth
masks. Here, we demonstrate a self-supervised method of land cover segmentation
that has no need for high-quality ground truth labels. The proposed deep
learning employs a frozen pre-trained ViT backbone transferred from DINO in a
STEGO architecture and is fine-tuned using a custom dataset consisting of very
high resolution (VHR) sattelite imagery. After only 10 epochs of fine-tuning,
an accuracy of roughly 52% was observed across 5 samples, signifying the
feasibility of self-supervised models for the automated labelling of VHR LULC
maps.
</p></li>
</ul>

<h3>Title: Words, Subwords, and Morphemes: What Really Matters in the Surprisal-Reading Time Relationship?. (arXiv:2310.17774v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.17774">http://arxiv.org/abs/2310.17774</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.17774]] Words, Subwords, and Morphemes: What Really Matters in the Surprisal-Reading Time Relationship?(http://arxiv.org/abs/2310.17774)</code></li>
<li>Summary: <p>An important assumption that comes with using LLMs on psycholinguistic data
has gone unverified. LLM-based predictions are based on subword tokenization,
not decomposition of words into morphemes. Does that matter? We carefully test
this by comparing surprisal estimates using orthographic, morphological, and
BPE tokenization against reading time data. Our results replicate previous
findings and provide evidence that in the aggregate, predictions using BPE
tokenization do not suffer relative to morphological and orthographic
segmentation. However, a finer-grained analysis points to potential issues with
relying on BPE-based tokenization, as well as providing promising results
involving morphologically-aware surprisal estimates and suggesting a new method
for evaluating morphological prediction.
</p></li>
</ul>

<h3>Title: A Stability Principle for Learning under Non-Stationarity. (arXiv:2310.18304v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.18304">http://arxiv.org/abs/2310.18304</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.18304]] A Stability Principle for Learning under Non-Stationarity(http://arxiv.org/abs/2310.18304)</code></li>
<li>Summary: <p>We develop a versatile framework for statistical learning in non-stationary
environments. In each time period, our approach applies a stability principle
to select a look-back window that maximizes the utilization of historical data
while keeping the cumulative bias within an acceptable range relative to the
stochastic error. Our theory showcases the adaptability of this approach to
unknown non-stationarity. The regret bound is minimax optimal up to logarithmic
factors when the population losses are strongly convex, or Lipschitz only. At
the heart of our analysis lie two novel components: a measure of similarity
between functions and a segmentation technique for dividing the non-stationary
data sequence into quasi-stationary pieces.
</p></li>
</ul>

<button id="copy">Copy All</button>
</article>
<script src="../../javascript/clipboard.min.js"></script>
<script src="../../javascript/clipboard.js"></script>
