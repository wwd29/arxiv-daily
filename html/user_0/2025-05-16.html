<link rel="stylesheet" href="../../css/markdown.css" />
<article class="markdown-body">
<h1>2025-05-16</h1>
<h3>Title: Next Word Suggestion using Graph Neural Network</h3>
<ul>
<li><strong>Authors: </strong>Abisha Thapa Magar, Anup Shakya</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.09649">https://arxiv.org/abs/2505.09649</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.09649">https://arxiv.org/pdf/2505.09649</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.09649]] Next Word Suggestion using Graph Neural Network(https://arxiv.org/abs/2505.09649)</code><input type="text"></li>
<li><strong>Keywords: </strong>fair</a></li>
<li><strong>Abstract: </strong>Language Modeling is a prevalent task in Natural Language Processing. The currently existing most recent and most successful language models often tend to build a massive model with billions of parameters, feed in a tremendous amount of text data, and train with enormous computation resources which require millions of dollars. In this project, we aim to address an important sub-task in language modeling, i.e., context embedding. We propose an approach to exploit the Graph Convolution operation in GNNs to encode the context and use it in coalition with LSTMs to predict the next word given a local context of preceding words. We test this on the custom Wikipedia text corpus using a very limited amount of resources and show that this approach works fairly well to predict the next word.</li>
</ul>

<h3>Title: DRA-GRPO: Exploring Diversity-Aware Reward Adjustment for R1-Zero-Like Training of Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Xiwen Chen, Wenhui Zhu, Peijie Qiu, Xuanzhao Dong, Hao Wang, Haiyu Wu, Huayu Li, Aristeidis Sotiras, Yalin Wang, Abolfazl Razi</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.09655">https://arxiv.org/abs/2505.09655</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.09655">https://arxiv.org/pdf/2505.09655</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.09655]] DRA-GRPO: Exploring Diversity-Aware Reward Adjustment for R1-Zero-Like Training of Large Language Models(https://arxiv.org/abs/2505.09655)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Recent advances in reinforcement learning for language model post-training, such as Group Relative Policy Optimization (GRPO), have shown promise in low-resource settings. However, GRPO typically relies on solution-level and scalar reward signals that fail to capture the semantic diversity among sampled completions. This leads to what we identify as a diversity-quality inconsistency, where distinct reasoning paths may receive indistinguishable rewards. To address this limitation, we propose $\textit{Diversity-aware Reward Adjustment}$ (DRA), a method that explicitly incorporates semantic diversity into the reward computation. DRA uses Submodular Mutual Information (SMI) to downweight redundant completions and amplify rewards for diverse ones. This encourages better exploration during learning, while maintaining stable exploitation of high-quality samples. Our method integrates seamlessly with both GRPO and its variant DR.~GRPO, resulting in $\textit{DRA-GRPO}$ and $\textit{DGA-DR.~GRPO}$. We evaluate our method on five mathematical reasoning benchmarks and find that it outperforms recent strong baselines. It achieves state-of-the-art performance with an average accuracy of 58.2%, using only 7,000 fine-tuning samples and a total training cost of approximately $55. The code is available at this https URL.</li>
</ul>

<h3>Title: LAS: Loss-less ANN-SNN Conversion for Fully Spike-Driven Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Long Chen, Xiaotian Song, Yanan Sun</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.09659">https://arxiv.org/abs/2505.09659</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.09659">https://arxiv.org/pdf/2505.09659</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.09659]] LAS: Loss-less ANN-SNN Conversion for Fully Spike-Driven Large Language Models(https://arxiv.org/abs/2505.09659)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer, large language model</a></li>
<li><strong>Abstract: </strong>Spiking Large Language Models (LLMs) have emerged as an energy-efficient alternative to conventional LLMs through their event-driven computation. To effectively obtain spiking LLMs, researchers develop different ANN-to-SNN conversion methods by leveraging pre-trained ANN parameters while inheriting the energy efficiency of SNN. However, existing conversion methods struggle with extreme activation outliers and incompatible nonlinear operations of ANN-based LLMs. To address this, we propose a loss-less ANN-SNN conversion for fully spike-driven LLMs, termed LAS. Specifically, LAS introduces two novel neurons to convert the activation outlier and nonlinear operation of ANN-based LLMs. Moreover, LAS tailors the spike-equivalent Transformer components for spiking LLMs, which can ensure full spiking conversion without any loss of performance. Experimental results on six language models and two vision-language models demonstrate that LAS achieves loss-less conversion. Notably, on OPT-66B, LAS even improves the accuracy of 2\% on the WSC task. In addition, the parameter and ablation studies further verify the effectiveness of LAS. The source code is available at this https URL</li>
</ul>

<h3>Title: Large Language Models Are More Persuasive Than Incentivized Human Persuaders</h3>
<ul>
<li><strong>Authors: </strong>Philipp Schoenegger, Francesco Salvi, Jiacheng Liu, Xiaoli Nan, Ramit Debnath, Barbara Fasolo, Evelina Leivada, Gabriel Recchia, Fritz Günther, Ali Zarifhonarvar, Joe Kwon, Zahoor Ul Islam, Marco Dehnert, Daryl Y. H. Lee, Madeline G. Reinecke, David G. Kamper, Mert Kobaş, Adam Sandford, Jonas Kgomo, Luke Hewitt, Shreya Kapoor, Kerem Oktar, Eyup Engin Kucuk, Bo Feng, Cameron R. Jones, Izzy Gainsburg, Sebastian Olschewski, Nora Heinzelmann, Francisco Cruz, Ben M. Tappin, Tao Ma, Peter S. Park, Rayan Onyonka, Arthur Hjorth, Peter Slattery, Qingcheng Zeng, Lennart Finke, Igor Grossmann, Alessandro Salatiello, Ezra Karger</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.09662">https://arxiv.org/abs/2505.09662</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.09662">https://arxiv.org/pdf/2505.09662</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.09662]] Large Language Models Are More Persuasive Than Incentivized Human Persuaders(https://arxiv.org/abs/2505.09662)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>We directly compare the persuasion capabilities of a frontier large language model (LLM; Claude Sonnet 3.5) against incentivized human persuaders in an interactive, real-time conversational quiz setting. In this preregistered, large-scale incentivized experiment, participants (quiz takers) completed an online quiz where persuaders (either humans or LLMs) attempted to persuade quiz takers toward correct or incorrect answers. We find that LLM persuaders achieved significantly higher compliance with their directional persuasion attempts than incentivized human persuaders, demonstrating superior persuasive capabilities in both truthful (toward correct answers) and deceptive (toward incorrect answers) contexts. We also find that LLM persuaders significantly increased quiz takers' accuracy, leading to higher earnings, when steering quiz takers toward correct answers, and significantly decreased their accuracy, leading to lower earnings, when steering them toward incorrect answers. Overall, our findings suggest that AI's persuasion capabilities already exceed those of humans that have real-money bonuses tied to performance. Our findings of increasingly capable AI persuaders thus underscore the urgency of emerging alignment and governance frameworks.</li>
</ul>

<h3>Title: Analog Foundation Models</h3>
<ul>
<li><strong>Authors: </strong>Julian Büchel, Iason Chalas, Giovanni Acampa, An Chen, Omobayode Fagbohungbe, Sidney Tsai, Kaoutar El Maghraoui, Manuel Le Gallo, Abbas Rahimi, Abu Sebastian</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.09663">https://arxiv.org/abs/2505.09663</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.09663">https://arxiv.org/pdf/2505.09663</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.09663]] Analog Foundation Models(https://arxiv.org/abs/2505.09663)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Analog in-memory computing (AIMC) is a promising compute paradigm to improve speed and power efficiency of neural network inference beyond the limits of conventional von Neumann-based architectures. However, AIMC introduces fundamental challenges such as noisy computations and strict constraints on input and output quantization. Because of these constraints and imprecisions, off-the-shelf LLMs are not able to achieve 4-bit-level performance when deployed on AIMC-based hardware. While researchers previously investigated recovering this accuracy gap on small, mostly vision-based models, a generic method applicable to LLMs pre-trained on trillions of tokens does not yet exist. In this work, we introduce a general and scalable method to robustly adapt LLMs for execution on noisy, low-precision analog hardware. Our approach enables state-of-the-art models $\unicode{x2013}$ including Phi-3-mini-4k-instruct and Llama-3.2-1B-Instruct $\unicode{x2013}$ to retain performance comparable to 4-bit weight, 8-bit activation baselines, despite the presence of analog noise and quantization constraints. Additionally, we show that as a byproduct of our training methodology, analog foundation models can be quantized for inference on low-precision digital hardware. Finally, we show that our models also benefit from test-time compute scaling, showing better scaling behavior than models trained with 4-bit weight and 8-bit static input quantization. Our work bridges the gap between high-capacity LLMs and efficient analog hardware, offering a path toward energy-efficient foundation models. Code is available at this https URL .</li>
</ul>

<h3>Title: System Prompt Optimization with Meta-Learning</h3>
<ul>
<li><strong>Authors: </strong>Yumin Choi, Jinheon Baek, Sung Ju Hwang</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.09666">https://arxiv.org/abs/2505.09666</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.09666">https://arxiv.org/pdf/2505.09666</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.09666]] System Prompt Optimization with Meta-Learning(https://arxiv.org/abs/2505.09666)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, large language model</a></li>
<li><strong>Abstract: </strong>Large Language Models (LLMs) have shown remarkable capabilities, with optimizing their input prompts playing a pivotal role in maximizing their performance. However, while LLM prompts consist of both the task-agnostic system prompts and task-specific user prompts, existing work on prompt optimization has focused on user prompts specific to individual queries or tasks, and largely overlooked the system prompt that is, once optimized, applicable across different tasks and domains. Motivated by this, we introduce the novel problem of bilevel system prompt optimization, whose objective is to design system prompts that are robust to diverse user prompts and transferable to unseen tasks. To tackle this problem, we then propose a meta-learning framework, which meta-learns the system prompt by optimizing it over various user prompts across multiple datasets, while simultaneously updating the user prompts in an iterative manner to ensure synergy between them. We conduct experiments on 14 unseen datasets spanning 5 different domains, on which we show that our approach produces system prompts that generalize effectively to diverse user prompts. Also, our findings reveal that the optimized system prompt enables rapid adaptation even to unseen tasks, requiring fewer optimization steps for test-time user prompts while achieving improved performance.</li>
</ul>

<h3>Title: VeriFact: Enhancing Long-Form Factuality Evaluation with Refined Fact Extraction and Reference Facts</h3>
<ul>
<li><strong>Authors: </strong>Xin Liu, Lechen Zhang, Sheza Munir, Yiyang Gu, Lu Wang</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.09701">https://arxiv.org/abs/2505.09701</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.09701">https://arxiv.org/pdf/2505.09701</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.09701]] VeriFact: Enhancing Long-Form Factuality Evaluation with Refined Fact Extraction and Reference Facts(https://arxiv.org/abs/2505.09701)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction, large language model</a></li>
<li><strong>Abstract: </strong>Large language models (LLMs) excel at generating long-form responses, but evaluating their factuality remains challenging due to complex inter-sentence dependencies within the generated facts. Prior solutions predominantly follow a decompose-decontextualize-verify pipeline but often fail to capture essential context and miss key relational facts. In this paper, we introduce VeriFact, a factuality evaluation framework designed to enhance fact extraction by identifying and resolving incomplete and missing facts to support more accurate verification results. Moreover, we introduce FactRBench , a benchmark that evaluates both precision and recall in long-form model responses, whereas prior work primarily focuses on precision. FactRBench provides reference fact sets from advanced LLMs and human-written answers, enabling recall assessment. Empirical evaluations show that VeriFact significantly enhances fact completeness and preserves complex facts with critical relational information, resulting in more accurate factuality evaluation. Benchmarking various open- and close-weight LLMs on FactRBench indicate that larger models within same model family improve precision and recall, but high precision does not always correlate with high recall, underscoring the importance of comprehensive factuality assessment.</li>
</ul>

<h3>Title: Enabling Group Fairness in Graph Unlearning via Bi-level Debiasing</h3>
<ul>
<li><strong>Authors: </strong>Yezi Liu, Prathyush Poduval, Wenjun Huang, Yang Ni, Hanning Chen, Mohsen Imani</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.09702">https://arxiv.org/abs/2505.09702</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.09702">https://arxiv.org/pdf/2505.09702</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.09702]] Enabling Group Fairness in Graph Unlearning via Bi-level Debiasing(https://arxiv.org/abs/2505.09702)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, protect, robust, fair</a></li>
<li><strong>Abstract: </strong>Graph unlearning is a crucial approach for protecting user privacy by erasing the influence of user data on trained graph models. Recent developments in graph unlearning methods have primarily focused on maintaining model prediction performance while removing user information. However, we have observed that when user information is deleted from the model, the prediction distribution across different sensitive groups often changes. Furthermore, graph models are shown to be prone to amplifying biases, making the study of fairness in graph unlearning particularly important. This raises the question: Does graph unlearning actually introduce bias? Our findings indicate that the predictions of post-unlearning models become highly correlated with sensitive attributes, confirming the introduction of bias in the graph unlearning process. To address this issue, we propose a fair graph unlearning method, FGU. To guarantee privacy, FGU trains shard models on partitioned subgraphs, unlearns the requested data from the corresponding subgraphs, and retrains the shard models on the modified subgraphs. To ensure fairness, FGU employs a bi-level debiasing process: it first enables shard-level fairness by incorporating a fairness regularizer in the shard model retraining, and then achieves global-level fairness by aligning all shard models to minimize global disparity. Our experiments demonstrate that FGU achieves superior fairness while maintaining privacy and accuracy. Additionally, FGU is robust to diverse unlearning requests, ensuring fairness and utility performance across various data distributions.</li>
</ul>

<h3>Title: Energy-Efficient Federated Learning for AIoT using Clustering Methods</h3>
<ul>
<li><strong>Authors: </strong>Roberto Pereira, Fernanda Famá, Charalampos Kalalas, Paolo Dini</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.09704">https://arxiv.org/abs/2505.09704</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.09704">https://arxiv.org/pdf/2505.09704</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.09704]] Energy-Efficient Federated Learning for AIoT using Clustering Methods(https://arxiv.org/abs/2505.09704)</code><input type="text"></li>
<li><strong>Keywords: </strong>federate</a></li>
<li><strong>Abstract: </strong>While substantial research has been devoted to optimizing model performance, convergence rates, and communication efficiency, the energy implications of federated learning (FL) within Artificial Intelligence of Things (AIoT) scenarios are often overlooked in the existing literature. This study examines the energy consumed during the FL process, focusing on three main energy-intensive processes: pre-processing, communication, and local learning, all contributing to the overall energy footprint. We rely on the observation that device/client selection is crucial for speeding up the convergence of model training in a distributed AIoT setting and propose two clustering-informed methods. These clustering solutions are designed to group AIoT devices with similar label distributions, resulting in clusters composed of nearly heterogeneous devices. Hence, our methods alleviate the heterogeneity often encountered in real-world distributed learning applications. Throughout extensive numerical experimentation, we demonstrate that our clustering strategies typically achieve high convergence rates while maintaining low energy consumption when compared to other recent approaches available in the literature.</li>
</ul>

<h3>Title: Out-of-distribution generalisation is hard: evidence from ARC-like tasks</h3>
<ul>
<li><strong>Authors: </strong>George Dimitriadis. Spyridon Samothrakis</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.09716">https://arxiv.org/abs/2505.09716</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.09716">https://arxiv.org/pdf/2505.09716</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.09716]] Out-of-distribution generalisation is hard: evidence from ARC-like tasks(https://arxiv.org/abs/2505.09716)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Out-of-distribution (OOD) generalisation is considered a hallmark of human and animal intelligence. To achieve OOD through composition, a system must discover the environment-invariant properties of experienced input-output mappings and transfer them to novel inputs. This can be realised if an intelligent system can identify appropriate, task-invariant, and composable input features, as well as the composition methods, thus allowing it to act based not on the interpolation between learnt data points but on the task-invariant composition of those features. We propose that in order to confirm that an algorithm does indeed learn compositional structures from data, it is not enough to just test on an OOD setup, but one also needs to confirm that the features identified are indeed compositional. We showcase this by exploring two tasks with clearly defined OOD metrics that are not OOD solvable by three commonly used neural networks: a Multi-Layer Perceptron (MLP), a Convolutional Neural Network (CNN), and a Transformer. In addition, we develop two novel network architectures imbued with biases that allow them to be successful in OOD scenarios. We show that even with correct biases and almost perfect OOD performance, an algorithm can still fail to learn the correct features for compositional generalisation.</li>
</ul>

<h3>Title: Robust Federated Learning with Confidence-Weighted Filtering and GAN-Based Completion under Noisy and Incomplete Data</h3>
<ul>
<li><strong>Authors: </strong>Alpaslan Gokcen, Ali Boyaci</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.09733">https://arxiv.org/abs/2505.09733</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.09733">https://arxiv.org/pdf/2505.09733</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.09733]] Robust Federated Learning with Confidence-Weighted Filtering and GAN-Based Completion under Noisy and Incomplete Data(https://arxiv.org/abs/2505.09733)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, robust, federate</a></li>
<li><strong>Abstract: </strong>Federated learning (FL) presents an effective solution for collaborative model training while maintaining data privacy across decentralized client datasets. However, data quality issues such as noisy labels, missing classes, and imbalanced distributions significantly challenge its effectiveness. This study proposes a federated learning methodology that systematically addresses data quality issues, including noise, class imbalance, and missing labels. The proposed approach systematically enhances data integrity through adaptive noise cleaning, collaborative conditional GAN-based synthetic data generation, and robust federated model training. Experimental evaluations conducted on benchmark datasets (MNIST and Fashion-MNIST) demonstrate significant improvements in federated model performance, particularly macro-F1 Score, under varying noise and class imbalance conditions. Additionally, the proposed framework carefully balances computational feasibility and substantial performance gains, ensuring practicality for resource constrained edge devices while rigorously maintaining data privacy. Our results indicate that this method effectively mitigates common data quality challenges, providing a robust, scalable, and privacy compliant solution suitable for diverse real-world federated learning scenarios.</li>
</ul>

<h3>Title: A Generative Neural Annealer for Black-Box Combinatorial Optimization</h3>
<ul>
<li><strong>Authors: </strong>Yuan-Hang Zhang, Massimiliano Di Ventra</a></li>
<li><strong>Subjects: </strong>cs.LG, cond-mat.dis-nn, cond-mat.stat-mech, cs.AI, cs.NE</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.09742">https://arxiv.org/abs/2505.09742</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.09742">https://arxiv.org/pdf/2505.09742</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.09742]] A Generative Neural Annealer for Black-Box Combinatorial Optimization(https://arxiv.org/abs/2505.09742)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>We propose a generative, end-to-end solver for black-box combinatorial optimization that emphasizes both sample efficiency and solution quality on NP problems. Drawing inspiration from annealing-based algorithms, we treat the black-box objective as an energy function and train a neural network to model the associated Boltzmann distribution. By conditioning on temperature, the network captures a continuum of distributions--from near-uniform at high temperatures to sharply peaked around global optima at low temperatures--thereby learning the structure of the energy landscape and facilitating global optimization. When queries are expensive, the temperature-dependent distributions naturally enable data augmentation and improve sample efficiency. When queries are cheap but the problem remains hard, the model learns implicit variable interactions, effectively "opening" the black box. We validate our approach on challenging combinatorial tasks under both limited and unlimited query budgets, showing competitive performance against state-of-the-art black-box optimizers.</li>
</ul>

<h3>Title: Guardian Positioning System (GPS) for Location Based Services</h3>
<ul>
<li><strong>Authors: </strong>Wenjie Liu, Panos Papadimitratos</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.09743">https://arxiv.org/abs/2505.09743</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.09743">https://arxiv.org/pdf/2505.09743</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.09743]] Guardian Positioning System (GPS) for Location Based Services(https://arxiv.org/abs/2505.09743)</code><input type="text"></li>
<li><strong>Keywords: </strong>defense, attack</a></li>
<li><strong>Abstract: </strong>Location-based service (LBS) applications proliferate and support transportation, entertainment, and more. Modern mobile platforms, with smartphones being a prominent example, rely on terrestrial and satellite infrastructures (e.g., global navigation satellite system (GNSS) and crowdsourced Wi-Fi, Bluetooth, cellular, and IP databases) for correct positioning. However, they are vulnerable to attacks that manipulate positions to control and undermine LBS functionality -- thus enabling the scamming of users or services. Our work reveals that GNSS spoofing attacks succeed even though smartphones have multiple sources of positioning information. Moreover, that Wi-Fi spoofing attacks with GNSS jamming are surprisingly effective. More concerning is the evidence that sophisticated, coordinated spoofing attacks are highly effective. Attacks can target GNSS in combination with other positioning methods, thus defenses that assume that only GNSS is under attack cannot be effective. More so, resilient GNSS receivers and special-purpose antennas are not feasible on smartphones. To address this gap, we propose an extended receiver autonomous integrity monitoring (RAIM) framework that leverages the readily available, redundant, often so-called opportunistic positioning information on off-the-shelf platforms. We jointly use onboard sensors, terrestrial infrastructures, and GNSS. We show that our extended RAIM framework improves resilience against location spoofing, e.g., achieving a detection accuracy improvement of up to 24-58% compared to the state-of-the-art algorithms and location providers; detecting attacks within 5 seconds, with a low false positive rate.</li>
</ul>

<h3>Title: A Computational Pipeline for Advanced Analysis of 4D Flow MRI in the Left Atrium</h3>
<ul>
<li><strong>Authors: </strong>Xabier Morales, Ayah Elsayed, Debbie Zhao, Filip Loncaric, Ainhoa Aguado, Mireia Masias, Gina Quill, Marc Ramos, Ada Doltra, Ana Garcia, Marta Sitges, David Marlevi, Alistair Young, Martyn Nash, Bart Bijnens, Oscar Camara</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.09746">https://arxiv.org/abs/2505.09746</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.09746">https://arxiv.org/pdf/2505.09746</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.09746]] A Computational Pipeline for Advanced Analysis of 4D Flow MRI in the Left Atrium(https://arxiv.org/abs/2505.09746)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, segmentation</a></li>
<li><strong>Abstract: </strong>The left atrium (LA) plays a pivotal role in modulating left ventricular filling, but our comprehension of its hemodynamics is significantly limited by the constraints of conventional ultrasound analysis. 4D flow magnetic resonance imaging (4D Flow MRI) holds promise for enhancing our understanding of atrial hemodynamics. However, the low velocities within the LA and the limited spatial resolution of 4D Flow MRI make analyzing this chamber challenging. Furthermore, the absence of dedicated computational frameworks, combined with diverse acquisition protocols and vendors, complicates gathering large cohorts for studying the prognostic value of hemodynamic parameters provided by 4D Flow MRI. In this study, we introduce the first open-source computational framework tailored for the analysis of 4D Flow MRI in the LA, enabling comprehensive qualitative and quantitative analysis of advanced hemodynamic parameters. Our framework proves robust to data from different centers of varying quality, producing high-accuracy automated segmentations (Dice $>$ 0.9 and Hausdorff 95 $<$ 3 mm), even with limited training data. Additionally, we conducted the first comprehensive assessment of energy, vorticity, and pressure parameters in the LA across a spectrum of disorders to investigate their potential as prognostic biomarkers.</li>
</ul>

<h3>Title: Self-Consuming Generative Models with Adversarially Curated Data</h3>
<ul>
<li><strong>Authors: </strong>Xiukun Wei, Xueru Zhang</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.09768">https://arxiv.org/abs/2505.09768</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.09768">https://arxiv.org/pdf/2505.09768</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.09768]] Self-Consuming Generative Models with Adversarially Curated Data(https://arxiv.org/abs/2505.09768)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack, robust, generative</a></li>
<li><strong>Abstract: </strong>Recent advances in generative models have made it increasingly difficult to distinguish real data from model-generated synthetic data. Using synthetic data for successive training of future model generations creates "self-consuming loops", which may lead to model collapse or training instability. Furthermore, synthetic data is often subject to human feedback and curated by users based on their preferences. Ferbach et al. (2024) recently showed that when data is curated according to user preferences, the self-consuming retraining loop drives the model to converge toward a distribution that optimizes those preferences. However, in practice, data curation is often noisy or adversarially manipulated. For example, competing platforms may recruit malicious users to adversarially curate data and disrupt rival models. In this paper, we study how generative models evolve under self-consuming retraining loops with noisy and adversarially curated data. We theoretically analyze the impact of such noisy data curation on generative models and identify conditions for the robustness of the retraining process. Building on this analysis, we design attack algorithms for competitive adversarial scenarios, where a platform with a limited budget employs malicious users to misalign a rival's model from actual user preferences. Experiments on both synthetic and real-world datasets demonstrate the effectiveness of the proposed algorithms.</li>
</ul>

<h3>Title: Interim Report on Human-Guided Adaptive Hyperparameter Optimization with Multi-Fidelity Sprints</h3>
<ul>
<li><strong>Authors: </strong>Michael Kamfonas</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.09792">https://arxiv.org/abs/2505.09792</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.09792">https://arxiv.org/pdf/2505.09792</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.09792]] Interim Report on Human-Guided Adaptive Hyperparameter Optimization with Multi-Fidelity Sprints(https://arxiv.org/abs/2505.09792)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction</a></li>
<li><strong>Abstract: </strong>This case study applies a phased hyperparameter optimization process to compare multitask natural language model variants that utilize multiphase learning rate scheduling and optimizer parameter grouping. We employ short, Bayesian optimization sessions that leverage multi-fidelity, hyperparameter space pruning, progressive halving, and a degree of human guidance. We utilize the Optuna TPE sampler and Hyperband pruner, as well as the Scikit-Learn Gaussian process minimization. Initially, we use efficient low-fidelity sprints to prune the hyperparameter space. Subsequent sprints progressively increase their model fidelity and employ hyperband pruning for efficiency. A second aspect of our approach is using a meta-learner to tune threshold values to resolve classification probabilities during inference. We demonstrate our method on a collection of variants of the 2021 Joint Entity and Relation Extraction model proposed by Eberts and Ulges.</li>
</ul>

<h3>Title: Automated Detection of Clinical Entities in Lung and Breast Cancer Reports Using NLP Techniques</h3>
<ul>
<li><strong>Authors: </strong>J. Moreno-Casanova, J.M. Auñón, A. Mártinez-Pérez, M.E. Pérez-Martínez, M.E. Gas-López</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.09794">https://arxiv.org/abs/2505.09794</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.09794">https://arxiv.org/pdf/2505.09794</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.09794]] Automated Detection of Clinical Entities in Lung and Breast Cancer Reports Using NLP Techniques(https://arxiv.org/abs/2505.09794)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction, transformer</a></li>
<li><strong>Abstract: </strong>Research projects, including those focused on cancer, rely on the manual extraction of information from clinical reports. This process is time-consuming and prone to errors, limiting the efficiency of data-driven approaches in healthcare. To address these challenges, Natural Language Processing (NLP) offers an alternative for automating the extraction of relevant data from electronic health records (EHRs). In this study, we focus on lung and breast cancer due to their high incidence and the significant impact they have on public health. Early detection and effective data management in both types of cancer are crucial for improving patient outcomes. To enhance the accuracy and efficiency of data extraction, we utilized GMV's NLP tool uQuery, which excels at identifying relevant entities in clinical texts and converting them into standardized formats such as SNOMED and OMOP. uQuery not only detects and classifies entities but also associates them with contextual information, including negated entities, temporal aspects, and patient-related details. In this work, we explore the use of NLP techniques, specifically Named Entity Recognition (NER), to automatically identify and extract key clinical information from EHRs related to these two cancers. A dataset from Health Research Institute Hospital La Fe (IIS La Fe), comprising 200 annotated breast cancer and 400 lung cancer reports, was used, with eight clinical entities manually labeled using the Doccano platform. To perform NER, we fine-tuned the bsc-bio-ehr-en3 model, a RoBERTa-based biomedical linguistic model pre-trained in Spanish. Fine-tuning was performed using the Transformers architecture, enabling accurate recognition of clinical entities in these cancer types. Our results demonstrate strong overall performance, particularly in identifying entities like MET and PAT, although challenges remain with less frequent entities like EVOL.</li>
</ul>

<h3>Title: Lossless Compression for LLM Tensor Incremental Snapshots</h3>
<ul>
<li><strong>Authors: </strong>Daniel Waddington, Cornel Constantinescu</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.09810">https://arxiv.org/abs/2505.09810</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.09810">https://arxiv.org/pdf/2505.09810</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.09810]] Lossless Compression for LLM Tensor Incremental Snapshots(https://arxiv.org/abs/2505.09810)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>During the training of Large Language Models (LLMs), tensor data is periodically "checkpointed" to persistent storage to allow recovery of work done in the event of failure. The volume of data that must be copied during each checkpoint, even when using reduced-precision representations such as bfloat16, often reaches hundreds of gigabytes. Furthermore, the data must be moved across a network and written to a storage system before the next epoch occurs. With a view to ultimately building an optimized checkpointing solution, this paper presents experimental analysis of checkpoint data used to derive a design that maximizes the use of lossless compression to reduce the volume of data. We examine how tensor data and its compressibility evolve during model training and evaluate the efficacy of existing common off-the-shelf general purpose compression engines combined with known data optimization techniques such as byte-grouping and incremental delta compression. Leveraging our analysis we have built an effective compression solution, known as Language Model Compressor (LMC), which is based on byte-grouping and Huffman encoding. LMC offers more compression performance than the best alternative (BZ2) but with an order-of-magnitude reduction in the time needed to perform the compression. We show that a 16-core parallel implementation of LMC can attain compression and decompression throughput of 2.78 GiB/s and 3.76 GiB/s respectively. This increase in performance ultimately reduces the CPU resources needed and provides more time to copy the data to the storage system before the next epoch thus allowing for higher-frequency checkpoints.</li>
</ul>

<h3>Title: Adversarial Attack on Large Language Models using Exponentiated Gradient Descent</h3>
<ul>
<li><strong>Authors: </strong>Sajib Biswas, Mao Nishino, Samuel Jacob Chacko, Xiuwen Liu</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.09820">https://arxiv.org/abs/2505.09820</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.09820">https://arxiv.org/pdf/2505.09820</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.09820]] Adversarial Attack on Large Language Models using Exponentiated Gradient Descent(https://arxiv.org/abs/2505.09820)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack, large language model</a></li>
<li><strong>Abstract: </strong>As Large Language Models (LLMs) are widely used, understanding them systematically is key to improving their safety and realizing their full potential. Although many models are aligned using techniques such as reinforcement learning from human feedback (RLHF), they are still vulnerable to jailbreaking attacks. Some of the existing adversarial attack methods search for discrete tokens that may jailbreak a target model while others try to optimize the continuous space represented by the tokens of the model's vocabulary. While techniques based on the discrete space may prove to be inefficient, optimization of continuous token embeddings requires projections to produce discrete tokens, which might render them ineffective. To fully utilize the constraints and the structures of the space, we develop an intrinsic optimization technique using exponentiated gradient descent with the Bregman projection method to ensure that the optimized one-hot encoding always stays within the probability simplex. We prove the convergence of the technique and implement an efficient algorithm that is effective in jailbreaking several widely used LLMs. We demonstrate the efficacy of the proposed technique using five open-source LLMs on four openly available datasets. The results show that the technique achieves a higher success rate with great efficiency compared to three other state-of-the-art jailbreaking techniques. The source code for our implementation is available at: this https URL</li>
</ul>

<h3>Title: KRISTEVA: Close Reading as a Novel Task for Benchmarking Interpretive Reasoning</h3>
<ul>
<li><strong>Authors: </strong>Peiqi Sui, Juan Diego Rodriguez, Philippe Laban, Dean Murphy, Joseph P. Dexter, Richard Jean So, Samuel Baker, Pramit Chaudhuri</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.09825">https://arxiv.org/abs/2505.09825</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.09825">https://arxiv.org/pdf/2505.09825</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.09825]] KRISTEVA: Close Reading as a Novel Task for Benchmarking Interpretive Reasoning(https://arxiv.org/abs/2505.09825)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Each year, tens of millions of essays are written and graded in college-level English courses. Students are asked to analyze literary and cultural texts through a process known as close reading, in which they gather textual details to formulate evidence-based arguments. Despite being viewed as a basis for critical thinking and widely adopted as a required element of university coursework, close reading has never been evaluated on large language models (LLMs), and multi-discipline benchmarks like MMLU do not include literature as a subject. To fill this gap, we present KRISTEVA, the first close reading benchmark for evaluating interpretive reasoning, consisting of 1331 multiple-choice questions adapted from classroom data. With KRISTEVA, we propose three progressively more difficult sets of tasks to approximate different elements of the close reading process, which we use to test how well LLMs may seem to understand and reason about literary works: 1) extracting stylistic features, 2) retrieving relevant contextual information from parametric knowledge, and 3) multi-hop reasoning between style and external contexts. Our baseline results find that, while state-of-the-art LLMs possess some college-level close reading competency (accuracy 49.7% - 69.7%), their performances still trail those of experienced human evaluators on 10 out of our 11 tasks.</li>
</ul>

<h3>Title: Dyadic Mamba: Long-term Dyadic Human Motion Synthesis</h3>
<ul>
<li><strong>Authors: </strong>Julian Tanke, Takashi Shibuya, Kengo Uchida, Koichi Saito, Yuki Mitsufuji</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.09827">https://arxiv.org/abs/2505.09827</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.09827">https://arxiv.org/pdf/2505.09827</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.09827]] Dyadic Mamba: Long-term Dyadic Human Motion Synthesis(https://arxiv.org/abs/2505.09827)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Generating realistic dyadic human motion from text descriptions presents significant challenges, particularly for extended interactions that exceed typical training sequence lengths. While recent transformer-based approaches have shown promising results for short-term dyadic motion synthesis, they struggle with longer sequences due to inherent limitations in positional encoding schemes. In this paper, we introduce Dyadic Mamba, a novel approach that leverages State-Space Models (SSMs) to generate high-quality dyadic human motion of arbitrary length. Our method employs a simple yet effective architecture that facilitates information flow between individual motion sequences through concatenation, eliminating the need for complex cross-attention mechanisms. We demonstrate that Dyadic Mamba achieves competitive performance on standard short-term benchmarks while significantly outperforming transformer-based approaches on longer sequences. Additionally, we propose a new benchmark for evaluating long-term motion synthesis quality, providing a standardized framework for future research. Our results demonstrate that SSM-based architectures offer a promising direction for addressing the challenging task of long-term dyadic human motion synthesis from text descriptions.</li>
</ul>

<h3>Title: BoundarySeg:An Embarrassingly Simple Method To Boost Medical Image Segmentation Performance for Low Data Regimes</h3>
<ul>
<li><strong>Authors: </strong>Tushar Kataria, Shireen Y. Elhabian</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.09829">https://arxiv.org/abs/2505.09829</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.09829">https://arxiv.org/pdf/2505.09829</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.09829]] BoundarySeg:An Embarrassingly Simple Method To Boost Medical Image Segmentation Performance for Low Data Regimes(https://arxiv.org/abs/2505.09829)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, protect, segmentation</a></li>
<li><strong>Abstract: </strong>Obtaining large-scale medical data, annotated or unannotated, is challenging due to stringent privacy regulations and data protection policies. In addition, annotating medical images requires that domain experts manually delineate anatomical structures, making the process both time-consuming and costly. As a result, semi-supervised methods have gained popularity for reducing annotation costs. However, the performance of semi-supervised methods is heavily dependent on the availability of unannotated data, and their effectiveness declines when such data are scarce or absent. To overcome this limitation, we propose a simple, yet effective and computationally efficient approach for medical image segmentation that leverages only existing annotations. We propose BoundarySeg , a multi-task framework that incorporates organ boundary prediction as an auxiliary task to full organ segmentation, leveraging consistency between the two task predictions to provide additional supervision. This strategy improves segmentation accuracy, especially in low data regimes, allowing our method to achieve performance comparable to or exceeding state-of-the-art semi supervised approaches all without relying on unannotated data or increasing computational demands. Code will be released upon acceptance.</li>
</ul>

<h3>Title: Automated Alert Classification and Triage (AACT): An Intelligent System for the Prioritisation of Cybersecurity Alerts</h3>
<ul>
<li><strong>Authors: </strong>Melissa Turcotte, François Labrèche, Serge-Olivier Paquette</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.LG, stat.AP</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.09843">https://arxiv.org/abs/2505.09843</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.09843">https://arxiv.org/pdf/2505.09843</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.09843]] Automated Alert Classification and Triage (AACT): An Intelligent System for the Prioritisation of Cybersecurity Alerts(https://arxiv.org/abs/2505.09843)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, attack</a></li>
<li><strong>Abstract: </strong>Enterprise networks are growing ever larger with a rapidly expanding attack surface, increasing the volume of security alerts generated from security controls. Security Operations Centre (SOC) analysts triage these alerts to identify malicious activity, but they struggle with alert fatigue due to the overwhelming number of benign alerts. Organisations are turning to managed SOC providers, where the problem is amplified by context switching and limited visibility into business processes. A novel system, named AACT, is introduced that automates SOC workflows by learning from analysts' triage actions on cybersecurity alerts. It accurately predicts triage decisions in real time, allowing benign alerts to be closed automatically and critical ones prioritised. This reduces the SOC queue allowing analysts to focus on the most severe, relevant or ambiguous threats. The system has been trained and evaluated on both real SOC data and an open dataset, obtaining high performance in identifying malicious alerts from benign alerts. Additionally, the system has demonstrated high accuracy in a real SOC environment, reducing alerts shown to analysts by 61% over six months, with a low false negative rate of 1.36% over millions of alerts.</li>
</ul>

<h3>Title: Causal Predictive Optimization and Generation for Business AI</h3>
<ul>
<li><strong>Authors: </strong>Liyang Zhao, Olurotimi Seton, Himadeep Reddy Reddivari, Suvendu Jena, Shadow Zhao, Rachit Kumar, Changshuai Wei</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.IR, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.09847">https://arxiv.org/abs/2505.09847</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.09847">https://arxiv.org/pdf/2505.09847</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.09847]] Causal Predictive Optimization and Generation for Business AI(https://arxiv.org/abs/2505.09847)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>The sales process involves sales functions converting leads or opportunities to customers and selling more products to existing customers. The optimization of the sales process thus is key to success of any B2B business. In this work, we introduce a principled approach to sales optimization and business AI, namely the Causal Predictive Optimization and Generation, which includes three layers: 1) prediction layer with causal ML 2) optimization layer with constraint optimization and contextual bandit 3) serving layer with Generative AI and feedback-loop for system enhancement. We detail the implementation and deployment of the system in LinkedIn, showcasing significant wins over legacy systems and sharing learning and insight broadly applicable to this field.</li>
</ul>

<h3>Title: ZENN: A Thermodynamics-Inspired Computational Framework for Heterogeneous Data-Driven Modeling</h3>
<ul>
<li><strong>Authors: </strong>Shun Wang, Shun-Li Shang, Zi-Kui Liu, Wenrui Hao</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.IT</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.09851">https://arxiv.org/abs/2505.09851</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.09851">https://arxiv.org/pdf/2505.09851</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.09851]] ZENN: A Thermodynamics-Inspired Computational Framework for Heterogeneous Data-Driven Modeling(https://arxiv.org/abs/2505.09851)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Traditional entropy-based methods - such as cross-entropy loss in classification problems - have long been essential tools for quantifying uncertainty and disorder in data and developing artificial intelligence algorithms. However, the rapid growth of data across various domains has introduced new challenges, particularly the integration of heterogeneous datasets with intrinsic disparities. In this paper, we extend zentropy theory into the data science domain by introducing intrinsic entropy, enabling more effective learning from heterogeneous data sources. We propose a zentropy-enhanced neural network (ZENN) that simultaneously learns both energy and intrinsic entropy components, capturing the underlying structure of multi-source data. To support this, we redesign the neural network architecture to better reflect the intrinsic properties and variability inherent in diverse datasets. We demonstrate the effectiveness of ZENN on classification tasks and energy landscape reconstructions, showing its superior generalization capabilities and robustness-particularly in predicting high-order derivatives. As a practical application, we employ ZENN to reconstruct the Helmholtz energy landscape of Fe3Pt using data generated from DFT and capture key material behaviors, including negative thermal expansion and the critical point in the temperature-pressure space. Overall, our study introduces a novel approach for data-driven machine learning grounded in zentropy theory, highlighting ZENN as a versatile and robust deep learning framework for scientific problems involving complex, heterogeneous datasets.</li>
</ul>

<h3>Title: Do Large Language Models Know Conflict? Investigating Parametric vs. Non-Parametric Knowledge of LLMs for Conflict Forecasting</h3>
<ul>
<li><strong>Authors: </strong>Apollinaire Poli Nemkova, Sarath Chandra Lingareddy, Sagnik Ray Choudhury, Mark V. Albert</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.09852">https://arxiv.org/abs/2505.09852</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.09852">https://arxiv.org/pdf/2505.09852</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.09852]] Do Large Language Models Know Conflict? Investigating Parametric vs. Non-Parametric Knowledge of LLMs for Conflict Forecasting(https://arxiv.org/abs/2505.09852)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large Language Models (LLMs) have shown impressive performance across natural language tasks, but their ability to forecast violent conflict remains underexplored. We investigate whether LLMs possess meaningful parametric knowledge-encoded in their pretrained weights-to predict conflict escalation and fatalities without external data. This is critical for early warning systems, humanitarian planning, and policy-making. We compare this parametric knowledge with non-parametric capabilities, where LLMs access structured and unstructured context from conflict datasets (e.g., ACLED, GDELT) and recent news reports via Retrieval-Augmented Generation (RAG). Incorporating external information could enhance model performance by providing up-to-date context otherwise missing from pretrained weights. Our two-part evaluation framework spans 2020-2024 across conflict-prone regions in the Horn of Africa and the Middle East. In the parametric setting, LLMs predict conflict trends and fatalities relying only on pretrained knowledge. In the non-parametric setting, models receive summaries of recent conflict events, indicators, and geopolitical developments. We compare predicted conflict trend labels (e.g., Escalate, Stable Conflict, De-escalate, Peace) and fatalities against historical data. Our findings highlight the strengths and limitations of LLMs for conflict forecasting and the benefits of augmenting them with structured external knowledge.</li>
</ul>

<h3>Title: Chisme: Fully Decentralized Differentiated Deep Learning for Edge Intelligence</h3>
<ul>
<li><strong>Authors: </strong>Harikrishna Kuttivelil, Katia Obraczka</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.ET, cs.MA, cs.SI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.09854">https://arxiv.org/abs/2505.09854</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.09854">https://arxiv.org/pdf/2505.09854</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.09854]] Chisme: Fully Decentralized Differentiated Deep Learning for Edge Intelligence(https://arxiv.org/abs/2505.09854)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, robust, federate</a></li>
<li><strong>Abstract: </strong>As demand for intelligent services rises and edge devices become more capable, distributed learning at the network edge has emerged as a key enabling technology. While existing paradigms like federated learning (FL) and decentralized FL (DFL) enable privacy-preserving distributed learning in many scenarios, they face potential challenges in connectivity and synchronization imposed by resource-constrained and infrastructure-less environments. While more robust, gossip learning (GL) algorithms have generally been designed for homogeneous data distributions and may not suit all contexts. This paper introduces Chisme, a novel suite of protocols designed to address the challenges of implementing robust intelligence in the network edge, characterized by heterogeneous data distributions, episodic connectivity, and lack of infrastructure. Chisme includes both synchronous DFL (Chisme-DFL) and asynchronous GL (Chisme-GL) variants that enable collaborative yet decentralized model training that considers underlying data heterogeneity. We introduce a data similarity heuristic that allows agents to opportunistically infer affinity with each other using the existing communication of model updates in decentralized FL and GL. We leverage the heuristic to extend DFL's model aggregation and GL's model merge mechanisms for better personalized training while maintaining collaboration. While Chisme-DFL is a synchronous decentralized approach whose resource utilization scales linearly with network size, Chisme-GL is fully asynchronous and has a lower, constant resource requirement independent of network size. We demonstrate that Chisme methods outperform their standard counterparts in model training over distributed and heterogeneous data in network scenarios ranging from less connected and reliable networks to fully connected and lossless networks.</li>
</ul>

<h3>Title: Predictability Shapes Adaptation: An Evolutionary Perspective on Modes of Learning in Transformers</h3>
<ul>
<li><strong>Authors: </strong>Alexander Y. Ku, Thomas L. Griffiths, Stephanie C.Y. Chan</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.09855">https://arxiv.org/abs/2505.09855</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.09855">https://arxiv.org/pdf/2505.09855</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.09855]] Predictability Shapes Adaptation: An Evolutionary Perspective on Modes of Learning in Transformers(https://arxiv.org/abs/2505.09855)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Transformer models learn in two distinct modes: in-weights learning (IWL), encoding knowledge into model weights, and in-context learning (ICL), adapting flexibly to context without weight modification. To better understand the interplay between these learning modes, we draw inspiration from evolutionary biology's analogous adaptive strategies: genetic encoding (akin to IWL, adapting over generations and fixed within an individual's lifetime) and phenotypic plasticity (akin to ICL, enabling flexible behavioral responses to environmental cues). In evolutionary biology, environmental predictability dictates the balance between these strategies: stability favors genetic encoding, while reliable predictive cues promote phenotypic plasticity. We experimentally operationalize these dimensions of predictability and systematically investigate their influence on the ICL/IWL balance in Transformers. Using regression and classification tasks, we show that high environmental stability decisively favors IWL, as predicted, with a sharp transition at maximal stability. Conversely, high cue reliability enhances ICL efficacy, particularly when stability is low. Furthermore, learning dynamics reveal task-contingent temporal evolution: while a canonical ICL-to-IWL shift occurs in some settings (e.g., classification with many classes), we demonstrate that scenarios with easier IWL (e.g., fewer classes) or slower ICL acquisition (e.g., regression) can exhibit an initial IWL phase later yielding to ICL dominance. These findings support a relative-cost hypothesis for explaining these learning mode transitions, establishing predictability as a critical factor governing adaptive strategies in Transformers, and offering novel insights for understanding ICL and guiding training methodologies.</li>
</ul>

<h3>Title: Mission Balance: Generating Under-represented Class Samples using Video Diffusion Models</h3>
<ul>
<li><strong>Authors: </strong>Danush Kumar Venkatesh, Isabel Funke, Micha Pfeiffer, Fiona Kolbinger, Hanna Maria Schmeiser, Juergen Weitz, Marius Distler, Stefanie Speidel</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.09858">https://arxiv.org/abs/2505.09858</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.09858">https://arxiv.org/pdf/2505.09858</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.09858]] Mission Balance: Generating Under-represented Class Samples using Video Diffusion Models(https://arxiv.org/abs/2505.09858)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>Computer-assisted interventions can improve intra-operative guidance, particularly through deep learning methods that harness the spatiotemporal information in surgical videos. However, the severe data imbalance often found in surgical video datasets hinders the development of high-performing models. In this work, we aim to overcome the data imbalance by synthesizing surgical videos. We propose a unique two-stage, text-conditioned diffusion-based method to generate high-fidelity surgical videos for under-represented classes. Our approach conditions the generation process on text prompts and decouples spatial and temporal modeling by utilizing a 2D latent diffusion model to capture spatial content and then integrating temporal attention layers to ensure temporal consistency. Furthermore, we introduce a rejection sampling strategy to select the most suitable synthetic samples, effectively augmenting existing datasets to address class imbalance. We evaluate our method on two downstream tasks-surgical action recognition and intra-operative event prediction-demonstrating that incorporating synthetic videos from our approach substantially enhances model performance. We open-source our implementation at this https URL.</li>
</ul>

<h3>Title: LiDDA: Data Driven Attribution at LinkedIn</h3>
<ul>
<li><strong>Authors: </strong>John Bencina, Erkut Aykutlug, Yue Chen, Zerui Zhang, Stephanie Sorenson, Shao Tang, Changshuai Wei</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.IR, stat.ME</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.09861">https://arxiv.org/abs/2505.09861</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.09861">https://arxiv.org/pdf/2505.09861</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.09861]] LiDDA: Data Driven Attribution at LinkedIn(https://arxiv.org/abs/2505.09861)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Data Driven Attribution, which assigns conversion credits to marketing interactions based on causal patterns learned from data, is the foundation of modern marketing intelligence and vital to any marketing businesses and advertising platform. In this paper, we introduce a unified transformer-based attribution approach that can handle member-level data, aggregate-level data, and integration of external macro factors. We detail the large scale implementation of the approach at LinkedIn, showcasing significant impact. We also share learning and insights that are broadly applicable to the marketing and ad tech fields.</li>
</ul>

<h3>Title: Correlating Account on Ethereum Mixing Service via Domain-Invariant feature learning</h3>
<ul>
<li><strong>Authors: </strong>Zheng Che, Taoyu Li, Meng Shen, Hanbiao Du, Liehuang Zhu</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.09892">https://arxiv.org/abs/2505.09892</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.09892">https://arxiv.org/pdf/2505.09892</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.09892]] Correlating Account on Ethereum Mixing Service via Domain-Invariant feature learning(https://arxiv.org/abs/2505.09892)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, privacy, robust, steal</a></li>
<li><strong>Abstract: </strong>The untraceability of transactions facilitated by Ethereum mixing services like Tornado Cash poses significant challenges to blockchain security and financial regulation. Existing methods for correlating mixing accounts suffer from limited labeled data and vulnerability to noisy annotations, which restrict their practical applicability. In this paper, we propose StealthLink, a novel framework that addresses these limitations through cross-task domain-invariant feature learning. Our key innovation lies in transferring knowledge from the well-studied domain of blockchain anomaly detection to the data-scarce task of mixing transaction tracing. Specifically, we design a MixFusion module that constructs and encodes mixing subgraphs to capture local transactional patterns, while introducing a knowledge transfer mechanism that aligns discriminative features across domains through adversarial discrepancy minimization. This dual approach enables robust feature learning under label scarcity and distribution shifts. Extensive experiments on real-world mixing transaction datasets demonstrate that StealthLink achieves state-of-the-art performance, with 96.98\% F1-score in 10-shot learning scenarios. Notably, our framework shows superior generalization capability in imbalanced data conditions than conventional supervised methods. This work establishes the first systematic approach for cross-domain knowledge transfer in blockchain forensics, providing a practical solution for combating privacy-enhanced financial crimes in decentralized ecosystems.</li>
</ul>

<h3>Title: Comparing Exploration-Exploitation Strategies of LLMs and Humans: Insights from Standard Multi-armed Bandit Tasks</h3>
<ul>
<li><strong>Authors: </strong>Ziyuan Zhang, Darcy Wang, Ningyuan Chen, Rodrigo Mansur, Vahid Sarhangian</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CL, cs.HC</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.09901">https://arxiv.org/abs/2505.09901</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.09901">https://arxiv.org/pdf/2505.09901</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.09901]] Comparing Exploration-Exploitation Strategies of LLMs and Humans: Insights from Standard Multi-armed Bandit Tasks(https://arxiv.org/abs/2505.09901)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large language models (LLMs) are increasingly used to simulate or automate human behavior in complex sequential decision-making tasks. A natural question is then whether LLMs exhibit similar decision-making behavior to humans, and can achieve comparable (or superior) performance. In this work, we focus on the exploration-exploitation (E&E) tradeoff, a fundamental aspect of dynamic decision-making under uncertainty. We employ canonical multi-armed bandit (MAB) tasks introduced in the cognitive science and psychiatry literature to conduct a comparative study of the E&E strategies of LLMs, humans, and MAB algorithms. We use interpretable choice models to capture the E&E strategies of the agents and investigate how explicit reasoning, through both prompting strategies and reasoning-enhanced models, shapes LLM decision-making. We find that reasoning shifts LLMs toward more human-like behavior, characterized by a mix of random and directed exploration. In simple stationary tasks, reasoning-enabled LLMs exhibit similar levels of random and directed exploration compared to humans. However, in more complex, non-stationary environments, LLMs struggle to match human adaptability, particularly in effective directed exploration, despite achieving similar regret in certain scenarios. Our findings highlight both the promise and limits of LLMs as simulators of human behavior and tools for automated decision-making and point to potential areas of improvements.</li>
</ul>

<h3>Title: Crossing Borders Without Crossing Boundaries: How Sociolinguistic Awareness Can Optimize User Engagement with Localized Spanish AI Models Across Hispanophone Countries</h3>
<ul>
<li><strong>Authors: </strong>Martin Capdevila, Esteban Villa Turek, Ellen Karina Chumbe Fernandez, Luis Felipe Polo Galvez, Luis Cadavid, Andrea Marroquin, Rebeca Vargas Quesada, Johanna Crew, Nicole Vallejo Galarraga, Christopher Rodriguez, Diego Gutierrez, Radhi Datla</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.09902">https://arxiv.org/abs/2505.09902</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.09902">https://arxiv.org/pdf/2505.09902</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.09902]] Crossing Borders Without Crossing Boundaries: How Sociolinguistic Awareness Can Optimize User Engagement with Localized Spanish AI Models Across Hispanophone Countries(https://arxiv.org/abs/2505.09902)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large language models are, by definition, based on language. In an effort to underscore the critical need for regional localized models, this paper examines primary differences between variants of written Spanish across Latin America and Spain, with an in-depth sociocultural and linguistic contextualization therein. We argue that these differences effectively constitute significant gaps in the quotidian use of Spanish among dialectal groups by creating sociolinguistic dissonances, to the extent that locale-sensitive AI models would play a pivotal role in bridging these divides. In doing so, this approach informs better and more efficient localization strategies that also serve to more adequately meet inclusivity goals, while securing sustainable active daily user growth in a major low-risk investment geographic area. Therefore, implementing at least the proposed five sub variants of Spanish addresses two lines of action: to foment user trust and reliance on AI language models while also demonstrating a level of cultural, historical, and sociolinguistic awareness that reflects positively on any internationalization strategy.</li>
</ul>

<h3>Title: Avocado Price Prediction Using a Hybrid Deep Learning Model: TCN-MLP-Attention Architecture</h3>
<ul>
<li><strong>Authors: </strong>Linwei Zhang, LuFeng, Ruijia Liang</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CE</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.09907">https://arxiv.org/abs/2505.09907</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.09907">https://arxiv.org/pdf/2505.09907</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.09907]] Avocado Price Prediction Using a Hybrid Deep Learning Model: TCN-MLP-Attention Architecture(https://arxiv.org/abs/2505.09907)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction</a></li>
<li><strong>Abstract: </strong>With the growing demand for healthy foods, agricultural product price forecasting has become increasingly important. Hass avocados, as a high-value crop, exhibit complex price fluctuations influenced by factors such as seasonality, region, and weather. Traditional prediction models often struggle with highly nonlinear and dynamic data. To address this, we propose a hybrid deep learning model, TCN-MLP-Attention Architecture, combining Temporal Convolutional Networks (TCN) for sequential feature extraction, Multi-Layer Perceptrons (MLP) for nonlinear interactions, and an Attention mechanism for dynamic feature weighting. The dataset used covers over 50,000 records of Hass avocado sales across the U.S. from 2015 to 2018, including variables such as sales volume, average price, time, region, weather, and variety type, collected from point-of-sale systems and the Hass Avocado Board. After systematic preprocessing, including missing value imputation and feature normalization, the proposed model was trained and evaluated. Experimental results demonstrate that the TCN-MLP-Attention model achieves excellent predictive performance, with an RMSE of 1.23 and an MSE of 1.51, outperforming traditional methods. This research provides a scalable and effective approach for time series forecasting in agricultural markets and offers valuable insights for intelligent supply chain management and price strategy optimization.</li>
</ul>

<h3>Title: Large-Scale Gaussian Splatting SLAM</h3>
<ul>
<li><strong>Authors: </strong>Zhe Xin, Chenyang Wu, Penghui Huang, Yanyong Zhang, Yinian Mao, Guoquan Huang</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.RO</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.09915">https://arxiv.org/abs/2505.09915</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.09915">https://arxiv.org/pdf/2505.09915</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.09915]] Large-Scale Gaussian Splatting SLAM(https://arxiv.org/abs/2505.09915)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>The recently developed Neural Radiance Fields (NeRF) and 3D Gaussian Splatting (3DGS) have shown encouraging and impressive results for visual SLAM. However, most representative methods require RGBD sensors and are only available for indoor environments. The robustness of reconstruction in large-scale outdoor scenarios remains unexplored. This paper introduces a large-scale 3DGS-based visual SLAM with stereo cameras, termed LSG-SLAM. The proposed LSG-SLAM employs a multi-modality strategy to estimate prior poses under large view changes. In tracking, we introduce feature-alignment warping constraints to alleviate the adverse effects of appearance similarity in rendering losses. For the scalability of large-scale scenarios, we introduce continuous Gaussian Splatting submaps to tackle unbounded scenes with limited memory. Loops are detected between GS submaps by place recognition and the relative pose between looped keyframes is optimized utilizing rendering and feature warping losses. After the global optimization of camera poses and Gaussian points, a structure refinement module enhances the reconstruction quality. With extensive evaluations on the EuRoc and KITTI datasets, LSG-SLAM achieves superior performance over existing Neural, 3DGS-based, and even traditional approaches. Project page: this https URL.</li>
</ul>

<h3>Title: PIG: Privacy Jailbreak Attack on LLMs via Gradient-based Iterative In-Context Optimization</h3>
<ul>
<li><strong>Authors: </strong>Yidan Wang, Yanan Cao, Yubing Ren, Fang Fang, Zheng Lin, Binxing Fang</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.09921">https://arxiv.org/abs/2505.09921</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.09921">https://arxiv.org/pdf/2505.09921</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.09921]] PIG: Privacy Jailbreak Attack on LLMs via Gradient-based Iterative In-Context Optimization(https://arxiv.org/abs/2505.09921)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, attack, large language model</a></li>
<li><strong>Abstract: </strong>Large Language Models (LLMs) excel in various domains but pose inherent privacy risks. Existing methods to evaluate privacy leakage in LLMs often use memorized prefixes or simple instructions to extract data, both of which well-alignment models can easily block. Meanwhile, Jailbreak attacks bypass LLM safety mechanisms to generate harmful content, but their role in privacy scenarios remains underexplored. In this paper, we examine the effectiveness of jailbreak attacks in extracting sensitive information, bridging privacy leakage and jailbreak attacks in LLMs. Moreover, we propose PIG, a novel framework targeting Personally Identifiable Information (PII) and addressing the limitations of current jailbreak methods. Specifically, PIG identifies PII entities and their types in privacy queries, uses in-context learning to build a privacy context, and iteratively updates it with three gradient-based strategies to elicit target PII. We evaluate PIG and existing jailbreak methods using two privacy-related datasets. Experiments on four white-box and two black-box LLMs show that PIG outperforms baseline methods and achieves state-of-the-art (SoTA) results. The results underscore significant privacy risks in LLMs, emphasizing the need for stronger safeguards. Our code is availble at \href{this https URL}{this https URL}.</li>
</ul>

<h3>Title: Improving the Euclidean Diffusion Generation of Manifold Data by Mitigating Score Function Singularity</h3>
<ul>
<li><strong>Authors: </strong>Zichen Liu, Wei Zhang, Tiejun Li</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.09922">https://arxiv.org/abs/2505.09922</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.09922">https://arxiv.org/pdf/2505.09922</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.09922]] Improving the Euclidean Diffusion Generation of Manifold Data by Mitigating Score Function Singularity(https://arxiv.org/abs/2505.09922)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, generative</a></li>
<li><strong>Abstract: </strong>Euclidean diffusion models have achieved remarkable success in generative modeling across diverse domains, and they have been extended to manifold case in recent advances. Instead of explicitly utilizing the structure of special manifolds as studied in previous works, we investigate direct sampling of the Euclidean diffusion models for general manifold-constrained data in this paper. We reveal the multiscale singularity of the score function in the embedded space of manifold, which hinders the accuracy of diffusion-generated samples. We then present an elaborate theoretical analysis of the singularity structure of the score function by separating it along the tangential and normal directions of the manifold. To mitigate the singularity and improve the sampling accuracy, we propose two novel methods: (1) Niso-DM, which introduces non-isotropic noise along the normal direction to reduce scale discrepancies, and (2) Tango-DM, which trains only the tangential component of the score function using a tangential-only loss function. Numerical experiments demonstrate that our methods achieve superior performance on distributions over various manifolds with complex geometries.</li>
</ul>

<h3>Title: From Trade-off to Synergy: A Versatile Symbiotic Watermarking Framework for Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Yidan Wang, Yubing Ren, Yanan Cao, Binxing Fang</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.09924">https://arxiv.org/abs/2505.09924</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.09924">https://arxiv.org/pdf/2505.09924</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.09924]] From Trade-off to Synergy: A Versatile Symbiotic Watermarking Framework for Large Language Models(https://arxiv.org/abs/2505.09924)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, robust, watermark, large language model</a></li>
<li><strong>Abstract: </strong>The rise of Large Language Models (LLMs) has heightened concerns about the misuse of AI-generated text, making watermarking a promising solution. Mainstream watermarking schemes for LLMs fall into two categories: logits-based and sampling-based. However, current schemes entail trade-offs among robustness, text quality, and security. To mitigate this, we integrate logits-based and sampling-based schemes, harnessing their respective strengths to achieve synergy. In this paper, we propose a versatile symbiotic watermarking framework with three strategies: serial, parallel, and hybrid. The hybrid framework adaptively embeds watermarks using token entropy and semantic entropy, optimizing the balance between detectability, robustness, text quality, and security. Furthermore, we validate our approach through comprehensive experiments on various datasets and models. Experimental results indicate that our method outperforms existing baselines and achieves state-of-the-art (SOTA) performance. We believe this framework provides novel insights into diverse watermarking paradigms. Our code is available at \href{this https URL}{this https URL}.</li>
</ul>

<h3>Title: Reinforced Interactive Continual Learning via Real-time Noisy Human Feedback</h3>
<ul>
<li><strong>Authors: </strong>Yutao Yang, Jie Zhou, Junsong Li, Qianjun Pan, Bihao Zhan, Qin Chen, Xipeng Qiu, Liang He</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.09925">https://arxiv.org/abs/2505.09925</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.09925">https://arxiv.org/pdf/2505.09925</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.09925]] Reinforced Interactive Continual Learning via Real-time Noisy Human Feedback(https://arxiv.org/abs/2505.09925)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, large language model</a></li>
<li><strong>Abstract: </strong>This paper introduces an interactive continual learning paradigm where AI models dynamically learn new skills from real-time human feedback while retaining prior knowledge. This paradigm distinctively addresses two major limitations of traditional continual learning: (1) dynamic model updates using streaming, real-time human-annotated data, rather than static datasets with fixed labels, and (2) the assumption of clean labels, by explicitly handling the noisy feedback common in real-world interactions. To tackle these problems, we propose RiCL, a Reinforced interactive Continual Learning framework leveraging Large Language Models (LLMs) to learn new skills effectively from dynamic feedback. RiCL incorporates three key components: a temporal consistency-aware purifier to automatically discern clean from noisy samples in data streams; an interaction-aware direct preference optimization strategy to align model behavior with human intent by reconciling AI-generated and human-provided feedback; and a noise-resistant contrastive learning module that captures robust representations by exploiting inherent data relationships, thus avoiding reliance on potentially unreliable labels. Extensive experiments on two benchmark datasets (FewRel and TACRED), contaminated with realistic noise patterns, demonstrate that our RiCL approach substantially outperforms existing combinations of state-of-the-art online continual learning and noisy-label learning methods.</li>
</ul>

<h3>Title: DDFP: Data-dependent Frequency Prompt for Source Free Domain Adaptation of Medical Image Segmentation</h3>
<ul>
<li><strong>Authors: </strong>Siqi Yin, Shaolei Liu, Manning Wang</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.09927">https://arxiv.org/abs/2505.09927</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.09927">https://arxiv.org/pdf/2505.09927</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.09927]] DDFP: Data-dependent Frequency Prompt for Source Free Domain Adaptation of Medical Image Segmentation(https://arxiv.org/abs/2505.09927)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, segmentation</a></li>
<li><strong>Abstract: </strong>Domain adaptation addresses the challenge of model performance degradation caused by domain gaps. In the typical setup for unsupervised domain adaptation, labeled data from a source domain and unlabeled data from a target domain are used to train a target model. However, access to labeled source domain data, particularly in medical datasets, can be restricted due to privacy policies. As a result, research has increasingly shifted to source-free domain adaptation (SFDA), which requires only a pretrained model from the source domain and unlabeled data from the target domain data for adaptation. Existing SFDA methods often rely on domain-specific image style translation and self-supervision techniques to bridge the domain gap and train the target domain model. However, the quality of domain-specific style-translated images and pseudo-labels produced by these methods still leaves room for improvement. Moreover, training the entire model during adaptation can be inefficient under limited supervision. In this paper, we propose a novel SFDA framework to address these challenges. Specifically, to effectively mitigate the impact of domain gap in the initial training phase, we introduce preadaptation to generate a preadapted model, which serves as an initialization of target model and allows for the generation of high-quality enhanced pseudo-labels without introducing extra parameters. Additionally, we propose a data-dependent frequency prompt to more effectively translate target domain images into a source-like style. To further enhance adaptation, we employ a style-related layer fine-tuning strategy, specifically designed for SFDA, to train the target model using the prompted target domain images and pseudo-labels. Extensive experiments on cross-modality abdominal and cardiac SFDA segmentation tasks demonstrate that our proposed method outperforms existing state-of-the-art methods.</li>
</ul>

<h3>Title: DeFeed: Secure Decentralized Cross-Contract Data Feed in Web 3.0 for Connected Autonomous Vehicles</h3>
<ul>
<li><strong>Authors: </strong>Xingchen Sun, Runhua Xu, Wei Ni, Li Duan, Chao Li</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.09928">https://arxiv.org/abs/2505.09928</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.09928">https://arxiv.org/pdf/2505.09928</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.09928]] DeFeed: Secure Decentralized Cross-Contract Data Feed in Web 3.0 for Connected Autonomous Vehicles(https://arxiv.org/abs/2505.09928)</code><input type="text"></li>
<li><strong>Keywords: </strong>secure</a></li>
<li><strong>Abstract: </strong>Smart contracts have been a topic of interest in blockchain research and are a key enabling technology for Connected Autonomous Vehicles (CAVs) in the era of Web 3.0. These contracts enable trustless interactions without the need for intermediaries, as they operate based on predefined rules encoded on the blockchain. However, smart contacts face significant challenges in cross-contract communication and information sharing, making it difficult to establish seamless connectivity and collaboration among CAVs with Web 3.0. In this paper, we propose DeFeed, a novel secure protocol that incorporates various gas-saving functions for CAVs, originated from in-depth research into the interaction among smart contracts for decentralized cross-contract data feed in Web 3.0. DeFeed allows smart contracts to obtain information from other contracts efficiently in a single click, without complicated operations. We judiciously design and complete various functions with DeFeed, including a pool function and a cache function for gas optimization, a subscribe function for facilitating data access, and an update function for the future iteration of our protocol. Tailored for CAVs with Web 3.0 use cases, DeFeed enables efficient data feed between smart contracts underpinning decentralized applications and vehicle coordination. Implemented and tested on the Ethereum official test network, DeFeed demonstrates significant improvements in contract interaction efficiency, reducing computational complexity and gas costs. Our solution represents a critical step towards seamless, decentralized communication in Web 3.0 ecosystems.</li>
</ul>

<h3>Title: Security and Privacy Measurement on Chinese Consumer IoT Traffic based on Device Lifecycle</h3>
<ul>
<li><strong>Authors: </strong>Chenghua Jin, Yan Jia, Yuxin Song, Qingyin Tan, Rui Yang, Zheli Liu</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.09929">https://arxiv.org/abs/2505.09929</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.09929">https://arxiv.org/pdf/2505.09929</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.09929]] Security and Privacy Measurement on Chinese Consumer IoT Traffic based on Device Lifecycle(https://arxiv.org/abs/2505.09929)</code><input type="text"></li>
<li><strong>Keywords: </strong>secure, security, privacy</a></li>
<li><strong>Abstract: </strong>In recent years, consumer Internet of Things (IoT) devices have become widely used in daily life. With the popularity of devices, related security and privacy risks arise at the same time as they collect user-related data and transmit it to various service providers. Although China accounts for a larger share of the consumer IoT industry, current analyses on consumer IoT device traffic primarily focus on regions such as Europe, the United States, and Australia. Research on China, however, is currently rather rare. This study constructs the first large-scale dataset about consumer IoT device traffic in China. Specifically, we propose a fine-grained traffic collection guidance covering the entire lifecycle of consumer IoT devices, gathering traffic from 70 devices spanning 36 brands and 8 device categories. Based on this dataset, we analyze traffic destinations and encryption practices across different device types during the entire lifecycle and compare the findings with the results of other regions. Compared to other regions, our results show that consumer IoT devices in China rely more on domestic services and overally perform better in terms of encryption practices. However, there are still 20/35 devices improperly conduct certificate validation, and 5/70 devices use insecure encryption protocols. To facilitate future research, we open-source our traffic collection guidance and make our dataset publicly available.</li>
</ul>

<h3>Title: Rethinking Prompt Optimizers: From Prompt Merits to Optimization</h3>
<ul>
<li><strong>Authors: </strong>Zixiao Zhu, Hanzhang Zhou, Zijian Feng, Tianjiao Li, Chua Jia Jim Deryl, Mak Lee Onn, Gee Wah Ng, Kezhi Mao</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.09930">https://arxiv.org/abs/2505.09930</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.09930">https://arxiv.org/pdf/2505.09930</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.09930]] Rethinking Prompt Optimizers: From Prompt Merits to Optimization(https://arxiv.org/abs/2505.09930)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, robust, large language model</a></li>
<li><strong>Abstract: </strong>Prompt optimization (PO) offers a practical alternative to fine-tuning large language models (LLMs), enabling performance improvements without altering model weights. Existing methods typically rely on advanced, large-scale LLMs like GPT-4 to generate optimized prompts. However, due to limited downward compatibility, verbose, instruction-heavy prompts from advanced LLMs can overwhelm lightweight inference models and degrade response quality. In this work, we rethink prompt optimization through the lens of interpretable design. We first identify a set of model-agnostic prompt quality merits and empirically validate their effectiveness in enhancing prompt and response quality. We then introduce MePO, a merit-guided, lightweight, and locally deployable prompt optimizer trained on our preference dataset built from merit-aligned prompts generated by a lightweight LLM. Unlike prior work, MePO avoids online optimization reliance, reduces cost and privacy concerns, and, by learning clear, interpretable merits, generalizes effectively to both large-scale and lightweight inference models. Experiments demonstrate that MePO achieves better results across diverse tasks and model types, offering a scalable and robust solution for real-world deployment. Our model and dataset are available at: this https URL</li>
</ul>

<h3>Title: VRU-CIPI: Crossing Intention Prediction at Intersections for Improving Vulnerable Road Users Safety</h3>
<ul>
<li><strong>Authors: </strong>Ahmed S. Abdelrahman, Mohamed Abdel-Aty, Quoc Dai Tran</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.09935">https://arxiv.org/abs/2505.09935</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.09935">https://arxiv.org/pdf/2505.09935</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.09935]] VRU-CIPI: Crossing Intention Prediction at Intersections for Improving Vulnerable Road Users Safety(https://arxiv.org/abs/2505.09935)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Understanding and predicting human behavior in-thewild, particularly at urban intersections, remains crucial for enhancing interaction safety between road users. Among the most critical behaviors are crossing intentions of Vulnerable Road Users (VRUs), where misinterpretation may result in dangerous conflicts with oncoming vehicles. In this work, we propose the VRU-CIPI framework with a sequential attention-based model designed to predict VRU crossing intentions at intersections. VRU-CIPI employs Gated Recurrent Unit (GRU) to capture temporal dynamics in VRU movements, combined with a multi-head Transformer self-attention mechanism to encode contextual and spatial dependencies critical for predicting crossing direction. Evaluated on UCF-VRU dataset, our proposed achieves state-of-the-art performance with an accuracy of 96.45% and achieving real-time inference speed reaching 33 frames per second. Furthermore, by integrating with Infrastructure-to-Vehicles (I2V) communication, our approach can proactively enhance intersection safety through timely activation of crossing signals and providing early warnings to connected vehicles, ensuring smoother and safer interactions for all road users.</li>
</ul>

<h3>Title: CSPENet: Contour-Aware and Saliency Priors Embedding Network for Infrared Small Target Detection</h3>
<ul>
<li><strong>Authors: </strong>Jiakun Deng, Kexuan Li, Xingye Cui, Jiaxuan Li, Chang Long, Tian Pu, Zhenming Peng</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.09943">https://arxiv.org/abs/2505.09943</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.09943">https://arxiv.org/pdf/2505.09943</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.09943]] CSPENet: Contour-Aware and Saliency Priors Embedding Network for Infrared Small Target Detection(https://arxiv.org/abs/2505.09943)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction</a></li>
<li><strong>Abstract: </strong>Infrared small target detection (ISTD) plays a critical role in a wide range of civilian and military applications. Existing methods suffer from deficiencies in the localization of dim targets and the perception of contour information under dense clutter environments, severely limiting their detection performance. To tackle these issues, we propose a contour-aware and saliency priors embedding network (CSPENet) for ISTD. We first design a surround-convergent prior extraction module (SCPEM) that effectively captures the intrinsic characteristic of target contour pixel gradients converging toward their center. This module concurrently extracts two collaborative priors: a boosted saliency prior for accurate target localization and multi-scale structural priors for comprehensively enriching contour detail representation. Building upon this, we propose a dual-branch priors embedding architecture (DBPEA) that establishes differentiated feature fusion pathways, embedding these two priors at optimal network positions to achieve performance enhancement. Finally, we develop an attention-guided feature enhancement module (AGFEM) to refine feature representations and improve saliency estimation accuracy. Experimental results on public datasets NUDT-SIRST, IRSTD-1k, and NUAA-SIRST demonstrate that our CSPENet outperforms other state-of-the-art methods in detection performance. The code is available at this https URL.</li>
</ul>

<h3>Title: Personalizing Large Language Models using Retrieval Augmented Generation and Knowledge Graph</h3>
<ul>
<li><strong>Authors: </strong>Deeksha Prahlad, Chanhee Lee, Dongha Kim, Hokeun Kim</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.09945">https://arxiv.org/abs/2505.09945</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.09945">https://arxiv.org/pdf/2505.09945</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.09945]] Personalizing Large Language Models using Retrieval Augmented Generation and Knowledge Graph(https://arxiv.org/abs/2505.09945)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>The advent of large language models (LLMs) has allowed numerous applications, including the generation of queried responses, to be leveraged in chatbots and other conversational assistants. Being trained on a plethora of data, LLMs often undergo high levels of over-fitting, resulting in the generation of extra and incorrect data, thus causing hallucinations in output generation. One of the root causes of such problems is the lack of timely, factual, and personalized information fed to the LLM. In this paper, we propose an approach to address these problems by introducing retrieval augmented generation (RAG) using knowledge graphs (KGs) to assist the LLM in personalized response generation tailored to the users. KGs have the advantage of storing continuously updated factual information in a structured way. While our KGs can be used for a variety of frequently updated personal data, such as calendar, contact, and location data, we focus on calendar data in this paper. Our experimental results show that our approach works significantly better in understanding personal information and generating accurate responses compared to the baseline LLMs using personal data as text inputs, with a moderate reduction in response time.</li>
</ul>

<h3>Title: Advanced Crash Causation Analysis for Freeway Safety: A Large Language Model Approach to Identifying Key Contributing Factors</h3>
<ul>
<li><strong>Authors: </strong>Ahmed S. Abdelrahman, Mohamed Abdel-Aty, Samgyu Yang, Abdulrahman Faden</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CL, stat.AP</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.09949">https://arxiv.org/abs/2505.09949</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.09949">https://arxiv.org/pdf/2505.09949</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.09949]] Advanced Crash Causation Analysis for Freeway Safety: A Large Language Model Approach to Identifying Key Contributing Factors(https://arxiv.org/abs/2505.09949)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Understanding the factors contributing to traffic crashes and developing strategies to mitigate their severity is essential. Traditional statistical methods and machine learning models often struggle to capture the complex interactions between various factors and the unique characteristics of each crash. This research leverages large language model (LLM) to analyze freeway crash data and provide crash causation analysis accordingly. By compiling 226 traffic safety studies related to freeway crashes, a training dataset encompassing environmental, driver, traffic, and geometric design factors was created. The Llama3 8B model was fine-tuned using QLoRA to enhance its understanding of freeway crashes and their contributing factors, as covered in these studies. The fine-tuned Llama3 8B model was then used to identify crash causation without pre-labeled data through zero-shot classification, providing comprehensive explanations to ensure that the identified causes were reasonable and aligned with existing research. Results demonstrate that LLMs effectively identify primary crash causes such as alcohol-impaired driving, speeding, aggressive driving, and driver inattention. Incorporating event data, such as road maintenance, offers more profound insights. The model's practical applicability and potential to improve traffic safety measures were validated by a high level of agreement among researchers in the field of traffic safety, as reflected in questionnaire results with 88.89%. This research highlights the complex nature of traffic crashes and how LLMs can be used for comprehensive analysis of crash causation and other contributing factors. Moreover, it provides valuable insights and potential countermeasures to aid planners and policymakers in developing more effective and efficient traffic safety practices.</li>
</ul>

<h3>Title: Task-Core Memory Management and Consolidation for Long-term Continual Learning</h3>
<ul>
<li><strong>Authors: </strong>Tianyu Huai, Jie Zhou, Yuxuan Cai, Qin Chen, Wen Wu, Xingjiao Wu, Xipeng Qiu, Liang He</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.09952">https://arxiv.org/abs/2505.09952</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.09952">https://arxiv.org/pdf/2505.09952</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.09952]] Task-Core Memory Management and Consolidation for Long-term Continual Learning(https://arxiv.org/abs/2505.09952)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>In this paper, we focus on a long-term continual learning (CL) task, where a model learns sequentially from a stream of vast tasks over time, acquiring new knowledge while retaining previously learned information in a manner akin to human learning. Unlike traditional CL settings, long-term CL involves handling a significantly larger number of tasks, which exacerbates the issue of catastrophic forgetting. Our work seeks to address two critical questions: 1) How do existing CL methods perform in the context of long-term CL? and 2) How can we mitigate the catastrophic forgetting that arises from prolonged sequential updates? To tackle these challenges, we propose a novel framework inspired by human memory mechanisms for long-term continual learning (Long-CL). Specifically, we introduce a task-core memory management strategy to efficiently index crucial memories and adaptively update them as learning progresses. Additionally, we develop a long-term memory consolidation mechanism that selectively retains hard and discriminative samples, ensuring robust knowledge retention. To facilitate research in this area, we construct and release two multi-modal and textual benchmarks, MMLongCL-Bench and TextLongCL-Bench, providing a valuable resource for evaluating long-term CL approaches. Experimental results show that Long-CL outperforms the previous state-of-the-art by 7.4\% and 6.5\% AP on the two benchmarks, respectively, demonstrating the effectiveness of our approach.</li>
</ul>

<h3>Title: Approximated Behavioral Metric-based State Projection for Federated Reinforcement Learning</h3>
<ul>
<li><strong>Authors: </strong>Zengxia Guo, Bohui An, Zhongqi Lu</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.09959">https://arxiv.org/abs/2505.09959</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.09959">https://arxiv.org/pdf/2505.09959</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.09959]] Approximated Behavioral Metric-based State Projection for Federated Reinforcement Learning(https://arxiv.org/abs/2505.09959)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, protect, federate</a></li>
<li><strong>Abstract: </strong>Federated reinforcement learning (FRL) methods usually share the encrypted local state or policy information and help each client to learn from others while preserving everyone's privacy. In this work, we propose that sharing the approximated behavior metric-based state projection function is a promising way to enhance the performance of FRL and concurrently provides an effective protection of sensitive information. We introduce FedRAG, a FRL framework to learn a computationally practical projection function of states for each client and aggregating the parameters of projection functions at a central server. The FedRAG approach shares no sensitive task-specific information, yet provides information gain for each client. We conduct extensive experiments on the DeepMind Control Suite to demonstrate insightful results.</li>
</ul>

<h3>Title: MambaControl: Anatomy Graph-Enhanced Mamba ControlNet with Fourier Refinement for Diffusion-Based Disease Trajectory Prediction</h3>
<ul>
<li><strong>Authors: </strong>Hao Yang, Tao Tan, Shuai Tan, Weiqin Yang, Kunyan Cai, Calvin Chen, Yue Sun</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.09965">https://arxiv.org/abs/2505.09965</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.09965">https://arxiv.org/pdf/2505.09965</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.09965]] MambaControl: Anatomy Graph-Enhanced Mamba ControlNet with Fourier Refinement for Diffusion-Based Disease Trajectory Prediction(https://arxiv.org/abs/2505.09965)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>Modelling disease progression in precision medicine requires capturing complex spatio-temporal dynamics while preserving anatomical integrity. Existing methods often struggle with longitudinal dependencies and structural consistency in progressive disorders. To address these limitations, we introduce MambaControl, a novel framework that integrates selective state-space modelling with diffusion processes for high-fidelity prediction of medical image trajectories. To better capture subtle structural changes over time while maintaining anatomical consistency, MambaControl combines Mamba-based long-range modelling with graph-guided anatomical control to more effectively represent anatomical correlations. Furthermore, we introduce Fourier-enhanced spectral graph representations to capture spatial coherence and multiscale detail, enabling MambaControl to achieve state-of-the-art performance in Alzheimer's disease prediction. Quantitative and regional evaluations demonstrate improved progression prediction quality and anatomical fidelity, highlighting its potential for personalised prognosis and clinical decision support.</li>
</ul>

<h3>Title: TKFNet: Learning Texture Key Factor Driven Feature for Facial Expression Recognition</h3>
<ul>
<li><strong>Authors: </strong>Liqian Deng</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.09967">https://arxiv.org/abs/2505.09967</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.09967">https://arxiv.org/pdf/2505.09967</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.09967]] TKFNet: Learning Texture Key Factor Driven Feature for Facial Expression Recognition(https://arxiv.org/abs/2505.09967)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Facial expression recognition (FER) in the wild remains a challenging task due to the subtle and localized nature of expression-related features, as well as the complex variations in facial appearance. In this paper, we introduce a novel framework that explicitly focuses on Texture Key Driver Factors (TKDF), localized texture regions that exhibit strong discriminative power across emotional categories. By carefully observing facial image patterns, we identify that certain texture cues, such as micro-changes in skin around the brows, eyes, and mouth, serve as primary indicators of emotional dynamics. To effectively capture and leverage these cues, we propose a FER architecture comprising a Texture-Aware Feature Extractor (TAFE) and Dual Contextual Information Filtering (DCIF). TAFE employs a ResNet-based backbone enhanced with multi-branch attention to extract fine-grained texture representations, while DCIF refines these features by filtering context through adaptive pooling and attention mechanisms. Experimental results on RAF-DB and KDEF datasets demonstrate that our method achieves state-of-the-art performance, verifying the effectiveness and robustness of incorporating TKDFs into FER pipelines.</li>
</ul>

<h3>Title: APCoTTA: Continual Test-Time Adaptation for Semantic Segmentation of Airborne LiDAR Point Clouds</h3>
<ul>
<li><strong>Authors: </strong>Yuan Gao, Shaobo Xia, Sheng Nie, Cheng Wang, Xiaohuan Xi, Bisheng Yang</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.09971">https://arxiv.org/abs/2505.09971</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.09971">https://arxiv.org/pdf/2505.09971</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.09971]] APCoTTA: Continual Test-Time Adaptation for Semantic Segmentation of Airborne LiDAR Point Clouds(https://arxiv.org/abs/2505.09971)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>Airborne laser scanning (ALS) point cloud segmentation is a fundamental task for large-scale 3D scene understanding. In real-world applications, models are typically fixed after training. However, domain shifts caused by changes in the environment, sensor types, or sensor degradation often lead to a decline in model performance. Continuous Test-Time Adaptation (CTTA) offers a solution by adapting a source-pretrained model to evolving, unlabeled target domains. Despite its potential, research on ALS point clouds remains limited, facing challenges such as the absence of standardized datasets and the risk of catastrophic forgetting and error accumulation during prolonged adaptation. To tackle these challenges, we propose APCoTTA, the first CTTA method tailored for ALS point cloud semantic segmentation. We propose a dynamic trainable layer selection module. This module utilizes gradient information to select low-confidence layers for training, and the remaining layers are kept frozen, mitigating catastrophic forgetting. To further reduce error accumulation, we propose an entropy-based consistency loss. By losing such samples based on entropy, we apply consistency loss only to the reliable samples, enhancing model stability. In addition, we propose a random parameter interpolation mechanism, which randomly blends parameters from the selected trainable layers with those of the source model. This approach helps balance target adaptation and source knowledge retention, further alleviating forgetting. Finally, we construct two benchmarks, ISPRSC and H3DC, to address the lack of CTTA benchmarks for ALS point cloud segmentation. Experimental results demonstrate that APCoTTA achieves the best performance on two benchmarks, with mIoU improvements of approximately 9% and 14% over direct inference. The new benchmarks and code are available at this https URL.</li>
</ul>

<h3>Title: Analysing Safety Risks in LLMs Fine-Tuned with Pseudo-Malicious Cyber Security Data</h3>
<ul>
<li><strong>Authors: </strong>Adel ElZemity, Budi Arief, Shujun Li</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.09974">https://arxiv.org/abs/2505.09974</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.09974">https://arxiv.org/pdf/2505.09974</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.09974]] Analysing Safety Risks in LLMs Fine-Tuned with Pseudo-Malicious Cyber Security Data(https://arxiv.org/abs/2505.09974)</code><input type="text"></li>
<li><strong>Keywords: </strong>secure, security, generative, large language model</a></li>
<li><strong>Abstract: </strong>The integration of large language models (LLMs) into cyber security applications presents significant opportunities, such as enhancing threat analysis and malware detection, but can also introduce critical risks and safety concerns, including personal data leakage and automated generation of new malware. We present a systematic evaluation of safety risks in fine-tuned LLMs for cyber security applications. Using the OWASP Top 10 for LLM Applications framework, we assessed seven open-source LLMs: Phi 3 Mini 3.8B, Mistral 7B, Qwen 2.5 7B, Llama 3 8B, Llama 3.1 8B, Gemma 2 9B, and Llama 2 70B. Our evaluation shows that fine-tuning reduces safety resilience across all tested LLMs (e.g., the safety score of Llama 3.1 8B against prompt injection drops from 0.95 to 0.15). We propose and evaluate a safety alignment approach that carefully rewords instruction-response pairs to include explicit safety precautions and ethical considerations. This approach demonstrates that it is possible to maintain or even improve model safety while preserving technical utility, offering a practical path forward for developing safer fine-tuning methodologies. This work offers a systematic evaluation for safety risks in LLMs, enabling safer adoption of generative AI in sensitive domains, and contributing towards the development of secure, trustworthy, and ethically aligned LLMs.</li>
</ul>

<h3>Title: Sybil-based Virtual Data Poisoning Attacks in Federated Learning</h3>
<ul>
<li><strong>Authors: </strong>Changxun Zhu, Qilong Wu, Lingjuan Lyu, Shibei Xue</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.09983">https://arxiv.org/abs/2505.09983</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.09983">https://arxiv.org/pdf/2505.09983</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.09983]] Sybil-based Virtual Data Poisoning Attacks in Federated Learning(https://arxiv.org/abs/2505.09983)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack, federate</a></li>
<li><strong>Abstract: </strong>Federated learning is vulnerable to poisoning attacks by malicious adversaries. Existing methods often involve high costs to achieve effective attacks. To address this challenge, we propose a sybil-based virtual data poisoning attack, where a malicious client generates sybil nodes to amplify the poisoning model's impact. To reduce neural network computational complexity, we develop a virtual data generation method based on gradient matching. We also design three schemes for target model acquisition, applicable to online local, online global, and offline scenarios. In simulation, our method outperforms other attack algorithms since our method can obtain a global target model under non-independent uniformly distributed data.</li>
</ul>

<h3>Title: Descriptive Image-Text Matching with Graded Contextual Similarity</h3>
<ul>
<li><strong>Authors: </strong>Jinhyun Jang, Jiyeong Lee, Kwanghoon Sohn</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.09997">https://arxiv.org/abs/2505.09997</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.09997">https://arxiv.org/pdf/2505.09997</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.09997]] Descriptive Image-Text Matching with Graded Contextual Similarity(https://arxiv.org/abs/2505.09997)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Image-text matching aims to build correspondences between visual and textual data by learning their pairwise similarities. Most existing approaches have adopted sparse binary supervision, indicating whether a pair of images and sentences matches or not. However, such sparse supervision covers a limited subset of image-text relationships, neglecting their inherent many-to-many correspondences; an image can be described in numerous texts at different descriptive levels. Moreover, existing approaches overlook the implicit connections from general to specific descriptions, which form the underlying rationale for the many-to-many relationships between vision and language. In this work, we propose descriptive image-text matching, called DITM, to learn the graded contextual similarity between image and text by exploring the descriptive flexibility of language. We formulate the descriptiveness score of each sentence with cumulative term frequency-inverse document frequency (TF-IDF) to balance the pairwise similarity according to the keywords in the sentence. Our method leverages sentence descriptiveness to learn robust image-text matching in two key ways: (1) to refine the false negative labeling, dynamically relaxing the connectivity between positive and negative pairs, and (2) to build more precise matching, aligning a set of relevant sentences in a generic-to-specific order. By moving beyond rigid binary supervision, DITM enhances the discovery of both optimal matches and potential positive pairs. Extensive experiments on MS-COCO, Flickr30K, and CxC datasets demonstrate the effectiveness of our method in representing complex image-text relationships compared to state-of-the-art approaches. In addition, DITM enhances the hierarchical reasoning ability of the model, supported by the extensive analysis on HierarCaps benchmark.</li>
</ul>

<h3>Title: From Air to Wear: Personalized 3D Digital Fashion with AR/VR Immersive 3D Sketching</h3>
<ul>
<li><strong>Authors: </strong>Ying Zang, Yuanqi Hu, Xinyu Chen, Yuxia Xu, Suhui Wang, Chunan Yu, Lanyun Zhu, Deyi Ji, Xin Xu, Tianrun Chen</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.09998">https://arxiv.org/abs/2505.09998</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.09998">https://arxiv.org/pdf/2505.09998</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.09998]] From Air to Wear: Personalized 3D Digital Fashion with AR/VR Immersive 3D Sketching(https://arxiv.org/abs/2505.09998)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>In the era of immersive consumer electronics, such as AR/VR headsets and smart devices, people increasingly seek ways to express their identity through virtual fashion. However, existing 3D garment design tools remain inaccessible to everyday users due to steep technical barriers and limited data. In this work, we introduce a 3D sketch-driven 3D garment generation framework that empowers ordinary users - even those without design experience - to create high-quality digital clothing through simple 3D sketches in AR/VR environments. By combining a conditional diffusion model, a sketch encoder trained in a shared latent space, and an adaptive curriculum learning strategy, our system interprets imprecise, free-hand input and produces realistic, personalized garments. To address the scarcity of training data, we also introduce KO3DClothes, a new dataset of paired 3D garments and user-created sketches. Extensive experiments and user studies confirm that our method significantly outperforms existing baselines in both fidelity and usability, demonstrating its promise for democratized fashion design on next-generation consumer platforms.</li>
</ul>

<h3>Title: AI2MMUM: AI-AI Oriented Multi-Modal Universal Model Leveraging Telecom Domain Large Model</h3>
<ul>
<li><strong>Authors: </strong>Tianyu Jiao, Zhuoran Xiao, Yihang Huang, Chenhui Ye, Yijia Feng, Liyu Cai, Jiang Chang, Fangkun Liu, Yin Xu, Dazhi He, Yunfeng Guan, Wenjun Zhang</a></li>
<li><strong>Subjects: </strong>cs.LG, eess.SP</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.10003">https://arxiv.org/abs/2505.10003</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.10003">https://arxiv.org/pdf/2505.10003</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.10003]] AI2MMUM: AI-AI Oriented Multi-Modal Universal Model Leveraging Telecom Domain Large Model(https://arxiv.org/abs/2505.10003)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, large language model</a></li>
<li><strong>Abstract: </strong>Designing a 6G-oriented universal model capable of processing multi-modal data and executing diverse air interface tasks has emerged as a common goal in future wireless systems. Building on our prior work in communication multi-modal alignment and telecom large language model (LLM), we propose a scalable, task-aware artificial intelligence-air interface multi-modal universal model (AI2MMUM), which flexibility and effectively perform various physical layer tasks according to subtle task instructions. The LLM backbone provides robust contextual comprehension and generalization capabilities, while a fine-tuning approach is adopted to incorporate domain-specific knowledge. To enhance task adaptability, task instructions consist of fixed task keywords and learnable, implicit prefix prompts. Frozen radio modality encoders extract universal representations and adapter layers subsequently bridge radio and language modalities. Moreover, lightweight task-specific heads are designed to directly output task objectives. Comprehensive evaluations demonstrate that AI2MMUM achieves SOTA performance across five representative physical environment/wireless channel-based downstream tasks using the WAIR-D and DeepMIMO datasets.</li>
</ul>

<h3>Title: Sample Complexity of Distributionally Robust Average-Reward Reinforcement Learning</h3>
<ul>
<li><strong>Authors: </strong>Zijun Chen, Shengbo Wang, Nian Si</a></li>
<li><strong>Subjects: </strong>cs.LG, math.OC, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.10007">https://arxiv.org/abs/2505.10007</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.10007">https://arxiv.org/pdf/2505.10007</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.10007]] Sample Complexity of Distributionally Robust Average-Reward Reinforcement Learning(https://arxiv.org/abs/2505.10007)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Motivated by practical applications where stable long-term performance is critical-such as robotics, operations research, and healthcare-we study the problem of distributionally robust (DR) average-reward reinforcement learning. We propose two algorithms that achieve near-optimal sample complexity. The first reduces the problem to a DR discounted Markov decision process (MDP), while the second, Anchored DR Average-Reward MDP, introduces an anchoring state to stabilize the controlled transition kernels within the uncertainty set. Assuming the nominal MDP is uniformly ergodic, we prove that both algorithms attain a sample complexity of $\widetilde{O}\left(|\mathbf{S}||\mathbf{A}| t_{\mathrm{mix}}^2\varepsilon^{-2}\right)$ for estimating the optimal policy as well as the robust average reward under KL and $f_k$-divergence-based uncertainty sets, provided the uncertainty radius is sufficiently small. Here, $\varepsilon$ is the target accuracy, $|\mathbf{S}|$ and $|\mathbf{A}|$ denote the sizes of the state and action spaces, and $t_{\mathrm{mix}}$ is the mixing time of the nominal MDP. This represents the first finite-sample convergence guarantee for DR average-reward reinforcement learning. We further validate the convergence rates of our algorithms through numerical experiments.</li>
</ul>

<h3>Title: ImagineBench: Evaluating Reinforcement Learning with Large Language Model Rollouts</h3>
<ul>
<li><strong>Authors: </strong>Jing-Cheng Pang, Kaiyuan Li, Yidi Wang, Si-Hang Yang, Shengyi Jiang, Yang Yu</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.10010">https://arxiv.org/abs/2505.10010</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.10010">https://arxiv.org/pdf/2505.10010</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.10010]] ImagineBench: Evaluating Reinforcement Learning with Large Language Model Rollouts(https://arxiv.org/abs/2505.10010)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>A central challenge in reinforcement learning (RL) is its dependence on extensive real-world interaction data to learn task-specific policies. While recent work demonstrates that large language models (LLMs) can mitigate this limitation by generating synthetic experience (noted as imaginary rollouts) for mastering novel tasks, progress in this emerging field is hindered due to the lack of a standard benchmark. To bridge this gap, we introduce ImagineBench, the first comprehensive benchmark for evaluating offline RL algorithms that leverage both real rollouts and LLM-imaginary rollouts. The key features of ImagineBench include: (1) datasets comprising environment-collected and LLM-imaginary rollouts; (2) diverse domains of environments covering locomotion, robotic manipulation, and navigation tasks; and (3) natural language task instructions with varying complexity levels to facilitate language-conditioned policy learning. Through systematic evaluation of state-of-the-art offline RL algorithms, we observe that simply applying existing offline RL algorithms leads to suboptimal performance on unseen tasks, achieving 35.44% success rate in hard tasks in contrast to 64.37% of method training on real rollouts for hard tasks. This result highlights the need for algorithm advancements to better leverage LLM-imaginary rollouts. Additionally, we identify key opportunities for future research: including better utilization of imaginary rollouts, fast online adaptation and continual learning, and extension to multi-modal tasks. Our code is publicly available at this https URL.</li>
</ul>

<h3>Title: DIF: A Framework for Benchmarking and Verifying Implicit Bias in LLMs</h3>
<ul>
<li><strong>Authors: </strong>Lake Yin, Fan Huang</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.10013">https://arxiv.org/abs/2505.10013</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.10013">https://arxiv.org/pdf/2505.10013</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.10013]] DIF: A Framework for Benchmarking and Verifying Implicit Bias in LLMs(https://arxiv.org/abs/2505.10013)</code><input type="text"></li>
<li><strong>Keywords: </strong>fair, large language model</a></li>
<li><strong>Abstract: </strong>As Large Language Models (LLMs) have risen in prominence over the past few years, there has been concern over the potential biases in LLMs inherited from the training data. Previous studies have examined how LLMs exhibit implicit bias, such as when response generation changes when different social contexts are introduced. We argue that this implicit bias is not only an ethical, but also a technical issue, as it reveals an inability of LLMs to accommodate extraneous information. However, unlike other measures of LLM intelligence, there are no standard methods to benchmark this specific subset of LLM bias. To bridge this gap, we developed a method for calculating an easily interpretable benchmark, DIF (Demographic Implicit Fairness), by evaluating preexisting LLM logic and math problem datasets with sociodemographic personas. We demonstrate that this method can statistically validate the presence of implicit bias in LLM behavior and find an inverse trend between question answering accuracy and implicit bias, supporting our argument.</li>
</ul>

<h3>Title: ORL-LDM: Offline Reinforcement Learning Guided Latent Diffusion Model Super-Resolution Reconstruction</h3>
<ul>
<li><strong>Authors: </strong>Shijie Lyu</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.10027">https://arxiv.org/abs/2505.10027</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.10027">https://arxiv.org/pdf/2505.10027</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.10027]] ORL-LDM: Offline Reinforcement Learning Guided Latent Diffusion Model Super-Resolution Reconstruction(https://arxiv.org/abs/2505.10027)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>With the rapid advancement of remote sensing technology, super-resolution image reconstruction is of great research and practical significance. Existing deep learning methods have made progress but still face limitations in handling complex scenes and preserving image details. This paper proposes a reinforcement learning-based latent diffusion model (LDM) fine-tuning method for remote sensing image super-resolution. The method constructs a reinforcement learning environment with states, actions, and rewards, optimizing decision objectives through proximal policy optimization (PPO) during the reverse denoising process of the LDM model. Experiments on the RESISC45 dataset show significant improvements over the baseline model in PSNR, SSIM, and LPIPS, with PSNR increasing by 3-4dB, SSIM improving by 0.08-0.11, and LPIPS reducing by 0.06-0.10, particularly in structured and complex natural scenes. The results demonstrate the method's effectiveness in enhancing super-resolution quality and adaptability across scenes.</li>
</ul>

<h3>Title: DeepSeqCoco: A Robust Mobile Friendly Deep Learning Model for Detection of Diseases in Cocos nucifera</h3>
<ul>
<li><strong>Authors: </strong>Miit Daga, Dhriti Parikh, Swarna Priya Ramu</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.10030">https://arxiv.org/abs/2505.10030</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.10030">https://arxiv.org/pdf/2505.10030</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.10030]] DeepSeqCoco: A Robust Mobile Friendly Deep Learning Model for Detection of Diseases in Cocos nucifera(https://arxiv.org/abs/2505.10030)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Coconut tree diseases are a serious risk to agricultural yield, particularly in developing countries where conventional farming practices restrict early diagnosis and intervention. Current disease identification methods are manual, labor-intensive, and non-scalable. In response to these limitations, we come up with DeepSeqCoco, a deep learning based model for accurate and automatic disease identification from coconut tree images. The model was tested under various optimizer settings, such as SGD, Adam, and hybrid configurations, to identify the optimal balance between accuracy, minimization of loss, and computational cost. Results from experiments indicate that DeepSeqCoco can achieve as much as 99.5% accuracy (achieving up to 5% higher accuracy than existing models) with the hybrid SGD-Adam showing the lowest validation loss of 2.81%. It also shows a drop of up to 18% in training time and up to 85% in prediction time for input images. The results point out the promise of the model to improve precision agriculture through an AI-based, scalable, and efficient disease monitoring system.</li>
</ul>

<h3>Title: Optimal normalization in quantum-classical hybrid models for anti-cancer drug response prediction</h3>
<ul>
<li><strong>Authors: </strong>Takafumi Ito, Lysenko Artem, Tatsuhiko Tsunoda</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.ET, quant-ph</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.10037">https://arxiv.org/abs/2505.10037</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.10037">https://arxiv.org/pdf/2505.10037</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.10037]] Optimal normalization in quantum-classical hybrid models for anti-cancer drug response prediction(https://arxiv.org/abs/2505.10037)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Quantum-classical Hybrid Machine Learning (QHML) models are recognized for their robust performance and high generalization ability even for relatively small datasets. These qualities offer unique advantages for anti-cancer drug response prediction, where the number of available samples is typically small. However, such hybrid models appear to be very sensitive to the data encoding used at the interface of a neural network and a quantum circuit, with suboptimal choices leading to stability issues. To address this problem, we propose a novel strategy that uses a normalization function based on a moderated gradient version of the $\tanh$. This method transforms the outputs of the neural networks without concentrating them at the extreme value ranges. Our idea was evaluated on a dataset of gene expression and drug response measurements for various cancer cell lines, where we compared the prediction performance of a classical deep learning model and several QHML models. These results confirmed that QHML performed better than the classical models when data was optimally normalized. This study opens up new possibilities for biomedical data analysis using quantum computers.</li>
</ul>

<h3>Title: Rethinking Circuit Completeness in Language Models: AND, OR, and ADDER Gates</h3>
<ul>
<li><strong>Authors: </strong>Hang Chen, Jiaying Zhu, Xinyu Yang, Wenya Wang</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.10039">https://arxiv.org/abs/2505.10039</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.10039">https://arxiv.org/pdf/2505.10039</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.10039]] Rethinking Circuit Completeness in Language Models: AND, OR, and ADDER Gates(https://arxiv.org/abs/2505.10039)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability</a></li>
<li><strong>Abstract: </strong>Circuit discovery has gradually become one of the prominent methods for mechanistic interpretability, and research on circuit completeness has also garnered increasing attention. Methods of circuit discovery that do not guarantee completeness not only result in circuits that are not fixed across different runs but also cause key mechanisms to be omitted. The nature of incompleteness arises from the presence of OR gates within the circuit, which are often only partially detected in standard circuit discovery methods. To this end, we systematically introduce three types of logic gates: AND, OR, and ADDER gates, and decompose the circuit into combinations of these logical gates. Through the concept of these gates, we derive the minimum requirements necessary to achieve faithfulness and completeness. Furthermore, we propose a framework that combines noising-based and denoising-based interventions, which can be easily integrated into existing circuit discovery methods without significantly increasing computational complexity. This framework is capable of fully identifying the logic gates and distinguishing them within the circuit. In addition to the extensive experimental validation of the framework's ability to restore the faithfulness, completeness, and sparsity of circuits, using this framework, we uncover fundamental properties of the three logic gates, such as their proportions and contributions to the output, and explore how they behave among the functionalities of language models.</li>
</ul>

<h3>Title: Instance-Prototype Affinity Learning for Non-Exemplar Continual Graph Learning</h3>
<ul>
<li><strong>Authors: </strong>Lei Song, Jiaxing Li, Shihan Guan, Youyong Kong</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.10040">https://arxiv.org/abs/2505.10040</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.10040">https://arxiv.org/pdf/2505.10040</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.10040]] Instance-Prototype Affinity Learning for Non-Exemplar Continual Graph Learning(https://arxiv.org/abs/2505.10040)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy</a></li>
<li><strong>Abstract: </strong>Graph Neural Networks (GNN) endure catastrophic forgetting, undermining their capacity to preserve previously acquired knowledge amid the assimilation of novel information. Rehearsal-based techniques revisit historical examples, adopted as a principal strategy to alleviate this phenomenon. However, memory explosion and privacy infringements impose significant constraints on their utility. Non-Exemplar methods circumvent the prior issues through Prototype Replay (PR), yet feature drift presents new challenges. In this paper, our empirical findings reveal that Prototype Contrastive Learning (PCL) exhibits less pronounced drift than conventional PR. Drawing upon PCL, we propose Instance-Prototype Affinity Learning (IPAL), a novel paradigm for Non-Exemplar Continual Graph Learning (NECGL). Exploiting graph structural information, we formulate Topology-Integrated Gaussian Prototypes (TIGP), guiding feature distributions towards high-impact nodes to augment the model's capacity for assimilating new knowledge. Instance-Prototype Affinity Distillation (IPAD) safeguards task memory by regularizing discontinuities in class relationships. Moreover, we embed a Decision Boundary Perception (DBP) mechanism within PCL, fostering greater inter-class discriminability. Evaluations on four node classification benchmark datasets demonstrate that our method outperforms existing state-of-the-art methods, achieving a better trade-off between plasticity and stability.</li>
</ul>

<h3>Title: Exploring the Deep Fusion of Large Language Models and Diffusion Transformers for Text-to-Image Synthesis</h3>
<ul>
<li><strong>Authors: </strong>Bingda Tang, Boyang Zheng, Xichen Pan, Sayak Paul, Saining Xie</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.10046">https://arxiv.org/abs/2505.10046</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.10046">https://arxiv.org/pdf/2505.10046</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.10046]] Exploring the Deep Fusion of Large Language Models and Diffusion Transformers for Text-to-Image Synthesis(https://arxiv.org/abs/2505.10046)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, transformer, large language model</a></li>
<li><strong>Abstract: </strong>This paper does not describe a new method; instead, it provides a thorough exploration of an important yet understudied design space related to recent advances in text-to-image synthesis -- specifically, the deep fusion of large language models (LLMs) and diffusion transformers (DiTs) for multi-modal generation. Previous studies mainly focused on overall system performance rather than detailed comparisons with alternative methods, and key design details and training recipes were often left undisclosed. These gaps create uncertainty about the real potential of this approach. To fill these gaps, we conduct an empirical study on text-to-image generation, performing controlled comparisons with established baselines, analyzing important design choices, and providing a clear, reproducible recipe for training at scale. We hope this work offers meaningful data points and practical guidelines for future research in multi-modal generation.</li>
</ul>

<h3>Title: Financial Fraud Detection Using Explainable AI and Stacking Ensemble Methods</h3>
<ul>
<li><strong>Authors: </strong>Fahad Almalki, Mehedi Masud</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.10050">https://arxiv.org/abs/2505.10050</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.10050">https://arxiv.org/pdf/2505.10050</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.10050]] Financial Fraud Detection Using Explainable AI and Stacking Ensemble Methods(https://arxiv.org/abs/2505.10050)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability</a></li>
<li><strong>Abstract: </strong>Traditional machine learning models often prioritize predictive accuracy, often at the expense of model transparency and interpretability. The lack of transparency makes it difficult for organizations to comply with regulatory requirements and gain stakeholders trust. In this research, we propose a fraud detection framework that combines a stacking ensemble of well-known gradient boosting models: XGBoost, LightGBM, and CatBoost. In addition, explainable artificial intelligence (XAI) techniques are used to enhance the transparency and interpretability of the model's decisions. We used SHAP (SHapley Additive Explanations) for feature selection to identify the most important features. Further efforts were made to explain the model's predictions using Local Interpretable Model-Agnostic Explanation (LIME), Partial Dependence Plots (PDP), and Permutation Feature Importance (PFI). The IEEE-CIS Fraud Detection dataset, which includes more than 590,000 real transaction records, was used to evaluate the proposed model. The model achieved a high performance with an accuracy of 99% and an AUC-ROC score of 0.99, outperforming several recent related approaches. These results indicate that combining high prediction accuracy with transparent interpretability is possible and could lead to a more ethical and trustworthy solution in financial fraud detection.</li>
</ul>

<h3>Title: PsOCR: Benchmarking Large Multimodal Models for Optical Character Recognition in Low-resource Pashto Language</h3>
<ul>
<li><strong>Authors: </strong>Ijazul Haq, Yingjie Zhang, Irfan Ali Khan</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.10055">https://arxiv.org/abs/2505.10055</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.10055">https://arxiv.org/pdf/2505.10055</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.10055]] PsOCR: Benchmarking Large Multimodal Models for Optical Character Recognition in Low-resource Pashto Language(https://arxiv.org/abs/2505.10055)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>This paper evaluates the performance of Large Multimodal Models (LMMs) on Optical Character Recognition (OCR) in the low-resource Pashto language. Natural Language Processing (NLP) in Pashto faces several challenges due to the cursive nature of its script and a scarcity of structured datasets. To address this, we developed a synthetic Pashto OCR dataset, PsOCR, consisting of one million images annotated with bounding boxes at word, line, and document levels, suitable for training and evaluating models based on different architectures, including Convolutional Neural Networks (CNNs) and Transformers. PsOCR covers variations across 1,000 unique font families, colors, image sizes, and layouts. A benchmark subset of 10K images was selected to evaluate the performance of several LMMs, including seven open-source models: DeepSeek's Janus, InternVL, MiniCPM, Florence, and Qwen (3B and 7B), and four closed-source models: GPT-4o, Gemini, Claude, and Grok. Experimental results demonstrate that Gemini achieves the best performance among all models, whereas among open-source models, Qwen-7B stands out. This work provides an insightful assessment of the capabilities and limitations of current LMMs for OCR tasks in Pashto and establishes a foundation for further research not only in Pashto OCR but also for other similar scripts such as Arabic, Persian, and Urdu. PsOCR is available at this https URL.</li>
</ul>

<h3>Title: JointDistill: Adaptive Multi-Task Distillation for Joint Depth Estimation and Scene Segmentation</h3>
<ul>
<li><strong>Authors: </strong>Tiancong Cheng, Ying Zhang, Yuxuan Liang, Roger Zimmermann, Zhiwen Yu, Bin Guo</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.10057">https://arxiv.org/abs/2505.10057</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.10057">https://arxiv.org/pdf/2505.10057</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.10057]] JointDistill: Adaptive Multi-Task Distillation for Joint Depth Estimation and Scene Segmentation(https://arxiv.org/abs/2505.10057)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>Depth estimation and scene segmentation are two important tasks in intelligent transportation systems. A joint modeling of these two tasks will reduce the requirement for both the storage and training efforts. This work explores how the multi-task distillation could be used to improve such unified modeling. While existing solutions transfer multiple teachers' knowledge in a static way, we propose a self-adaptive distillation method that can dynamically adjust the knowledge amount from each teacher according to the student's current learning ability. Furthermore, as multiple teachers exist, the student's gradient update direction in the distillation is more prone to be erroneous where knowledge forgetting may occur. To avoid this, we propose a knowledge trajectory to record the most essential information that a model has learnt in the past, based on which a trajectory-based distillation loss is designed to guide the student to follow the learning curve similarly in a cost-effective way. We evaluate our method on multiple benchmarking datasets including Cityscapes and NYU-v2. Compared to the state-of-the-art solutions, our method achieves a clearly improvement. The code is provided in the supplementary materials.</li>
</ul>

<h3>Title: CAFE: Retrieval Head-based Coarse-to-Fine Information Seeking to Enhance Multi-Document QA Capability</h3>
<ul>
<li><strong>Authors: </strong>Han Peng, Jinhao Jiang, Zican Dong, Wayne Xin Zhao, Lei Fang</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.10063">https://arxiv.org/abs/2505.10063</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.10063">https://arxiv.org/pdf/2505.10063</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.10063]] CAFE: Retrieval Head-based Coarse-to-Fine Information Seeking to Enhance Multi-Document QA Capability(https://arxiv.org/abs/2505.10063)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Advancements in Large Language Models (LLMs) have extended their input context length, yet they still struggle with retrieval and reasoning in long-context inputs. Existing methods propose to utilize the prompt strategy and retrieval head to alleviate this limitation. However, they still face challenges in balancing retrieval precision and recall, impacting their efficacy in answering questions. To address this, we introduce $\textbf{CAFE}$, a two-stage coarse-to-fine method to enhance multi-document question-answering capacities. By gradually eliminating the negative impacts of background and distracting documents, CAFE makes the responses more reliant on the evidence documents. Initially, a coarse-grained filtering method leverages retrieval heads to identify and rank relevant documents. Then, a fine-grained steering method guides attention to the most relevant content. Experiments across benchmarks show CAFE outperforms baselines, achieving up to 22.1% and 13.7% SubEM improvement over SFT and RAG methods on the Mistral model, respectively.</li>
</ul>

<h3>Title: Dark LLMs: The Growing Threat of Unaligned AI Models</h3>
<ul>
<li><strong>Authors: </strong>Michael Fire, Yitzhak Elbazis, Adi Wasenstein, Lior Rokach</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.CR, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.10066">https://arxiv.org/abs/2505.10066</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.10066">https://arxiv.org/pdf/2505.10066</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.10066]] Dark LLMs: The Growing Threat of Unaligned AI Models(https://arxiv.org/abs/2505.10066)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack, large language model</a></li>
<li><strong>Abstract: </strong>Large Language Models (LLMs) rapidly reshape modern life, advancing fields from healthcare to education and beyond. However, alongside their remarkable capabilities lies a significant threat: the susceptibility of these models to jailbreaking. The fundamental vulnerability of LLMs to jailbreak attacks stems from the very data they learn from. As long as this training data includes unfiltered, problematic, or 'dark' content, the models can inherently learn undesirable patterns or weaknesses that allow users to circumvent their intended safety controls. Our research identifies the growing threat posed by dark LLMs models deliberately designed without ethical guardrails or modified through jailbreak techniques. In our research, we uncovered a universal jailbreak attack that effectively compromises multiple state-of-the-art models, enabling them to answer almost any question and produce harmful outputs upon request. The main idea of our attack was published online over seven months ago. However, many of the tested LLMs were still vulnerable to this attack. Despite our responsible disclosure efforts, responses from major LLM providers were often inadequate, highlighting a concerning gap in industry practices regarding AI safety. As model training becomes more accessible and cheaper, and as open-source LLMs proliferate, the risk of widespread misuse escalates. Without decisive intervention, LLMs may continue democratizing access to dangerous knowledge, posing greater risks than anticipated.</li>
</ul>

<h3>Title: Designing and Contextualising Probes for African Languages</h3>
<ul>
<li><strong>Authors: </strong>Wisdom Aduah, Francois Meyer</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.10081">https://arxiv.org/abs/2505.10081</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.10081">https://arxiv.org/pdf/2505.10081</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.10081]] Designing and Contextualising Probes for African Languages(https://arxiv.org/abs/2505.10081)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability</a></li>
<li><strong>Abstract: </strong>Pretrained language models (PLMs) for African languages are continually improving, but the reasons behind these advances remain unclear. This paper presents the first systematic investigation into probing PLMs for linguistic knowledge about African languages. We train layer-wise probes for six typologically diverse African languages to analyse how linguistic features are distributed. We also design control tasks, a way to interpret probe performance, for the MasakhaPOS dataset. We find PLMs adapted for African languages to encode more linguistic information about target languages than massively multilingual PLMs. Our results reaffirm previous findings that token-level syntactic information concentrates in middle-to-last layers, while sentence-level semantic information is distributed across all layers. Through control tasks and probing baselines, we confirm that performance reflects the internal knowledge of PLMs rather than probe memorisation. Our study applies established interpretability techniques to African-language PLMs. In doing so, we highlight the internal mechanisms underlying the success of strategies like active learning and multilingual adaptation.</li>
</ul>

<h3>Title: ChronoSteer: Bridging Large Language Model and Time Series Foundation Model via Synthetic Data</h3>
<ul>
<li><strong>Authors: </strong>Chengsen Wang, Qi Qi, Zhongwen Rao, Lujia Pan, Jingyu Wang, Jianxin Liao</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.10083">https://arxiv.org/abs/2505.10083</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.10083">https://arxiv.org/pdf/2505.10083</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.10083]] ChronoSteer: Bridging Large Language Model and Time Series Foundation Model via Synthetic Data(https://arxiv.org/abs/2505.10083)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Conventional forecasting methods rely on unimodal time series data, limiting their ability to exploit rich textual information. Recently, large language models (LLMs) and time series foundation models (TSFMs) have demonstrated powerful capability in textual reasoning and temporal modeling, respectively. Integrating the strengths of both to construct a multimodal model that concurrently leverages both temporal and textual information for future inference has emerged as a critical research challenge. To address the scarcity of event-series paired data, we propose a decoupled framework: an LLM is employed to transform textual events into revision instructions, which are then used to steer the output of TSFM. To implement this framework, we introduce ChronoSteer, a multimodal TSFM that can be steered through textual revision instructions, effectively bridging LLM and TSFM. Moreover, to mitigate the shortage of cross-modal instruction-series paired data, we devise a two-stage training strategy based on synthetic data. In addition, we also construct a high-quality multimodal time series forecasting benchmark to address the information leakage concerns during evaluation. After integrating with an LLM, ChronoSteer, which is trained exclusively on synthetic data, achieves a 25.7% improvement in prediction accuracy compared to the unimodal backbone and a 22.5% gain over the previous state-of-the-art multimodal method.</li>
</ul>

<h3>Title: When Mitigations Backfire: Timing Channel Attacks and Defense for PRAC-Based RowHammer Mitigations</h3>
<ul>
<li><strong>Authors: </strong>Jeonghyun Woo, Joyce Qu, Gururaj Saileshwar, Prashant J. Nair</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.10111">https://arxiv.org/abs/2505.10111</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.10111">https://arxiv.org/pdf/2505.10111</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.10111]] When Mitigations Backfire: Timing Channel Attacks and Defense for PRAC-Based RowHammer Mitigations(https://arxiv.org/abs/2505.10111)</code><input type="text"></li>
<li><strong>Keywords: </strong>defense, attack, robust</a></li>
<li><strong>Abstract: </strong>Per Row Activation Counting (PRAC) has emerged as a robust framework for mitigating RowHammer (RH) vulnerabilities in modern DRAM systems. However, we uncover a critical vulnerability: a timing channel introduced by the Alert Back-Off (ABO) protocol and Refresh Management (RFM) commands. We present PRACLeak, a novel attack that exploits these timing differences to leak sensitive information, such as secret keys from vulnerable AES implementations, by monitoring memory access latencies. To counter this, we propose Timing-Safe PRAC (TPRAC), a defense that eliminates PRAC-induced timing channels without compromising RH mitigation efficacy. TPRAC uses Timing-Based RFMs, issued periodically and independent of memory activity. It requires only a single-entry in-DRAM mitigation queue per DRAM bank and is compatible with existing DRAM standards. Our evaluations demonstrate that TPRAC closes timing channels while incurring only 3.4% performance overhead at the RH threshold of 1024.</li>
</ul>

<h3>Title: What Does Neuro Mean to Cardio? Investigating the Role of Clinical Specialty Data in Medical LLMs</h3>
<ul>
<li><strong>Authors: </strong>Xinlan Yan, Di Wu, Yibin Lei, Christof Monz, Iacer Calixto</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.10113">https://arxiv.org/abs/2505.10113</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.10113">https://arxiv.org/pdf/2505.10113</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.10113]] What Does Neuro Mean to Cardio? Investigating the Role of Clinical Specialty Data in Medical LLMs(https://arxiv.org/abs/2505.10113)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>In this paper, we introduce S-MedQA, an English medical question-answering (QA) dataset for benchmarking large language models in fine-grained clinical specialties. We use S-MedQA to check the applicability of a popular hypothesis related to knowledge injection in the knowledge-intense scenario of medical QA, and show that: 1) training on data from a speciality does not necessarily lead to best performance on that specialty and 2) regardless of the specialty fine-tuned on, token probabilities of clinically relevant terms for all specialties increase consistently. Thus, we believe improvement gains come mostly from domain shifting (e.g., general to medical) rather than knowledge injection and suggest rethinking the role of fine-tuning data in the medical domain. We release S-MedQA and all code needed to reproduce all our experiments to the research community.</li>
</ul>

<h3>Title: Learning Virtual Machine Scheduling in Cloud Computing through Language Agents</h3>
<ul>
<li><strong>Authors: </strong>JieHao Wu, Ziwei Wang, Junjie Sheng, Wenhao Li, Xiangfei Wang, Jun Luo</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.10117">https://arxiv.org/abs/2505.10117</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.10117">https://arxiv.org/pdf/2505.10117</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.10117]] Learning Virtual Machine Scheduling in Cloud Computing through Language Agents(https://arxiv.org/abs/2505.10117)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability, large language model</a></li>
<li><strong>Abstract: </strong>In cloud services, virtual machine (VM) scheduling is a typical Online Dynamic Multidimensional Bin Packing (ODMBP) problem, characterized by large-scale complexity and fluctuating demands. Traditional optimization methods struggle to adapt to real-time changes, domain-expert-designed heuristic approaches suffer from rigid strategies, and existing learning-based methods often lack generalizability and interpretability. To address these limitations, this paper proposes a hierarchical language agent framework named MiCo, which provides a large language model (LLM)-driven heuristic design paradigm for solving ODMBP. Specifically, ODMBP is formulated as a Semi-Markov Decision Process with Options (SMDP-Option), enabling dynamic scheduling through a two-stage architecture, i.e., Option Miner and Option Composer. Option Miner utilizes LLMs to discover diverse and useful non-context-aware strategies by interacting with constructed environments. Option Composer employs LLMs to discover a composing strategy that integrates the non-context-aware strategies with the contextual ones. Extensive experiments on real-world enterprise datasets demonstrate that MiCo achieves a 96.9\% competitive ratio in large-scale scenarios involving more than 10,000 virtual machines. It maintains high performance even under nonstationary request flows and diverse configurations, thus validating its effectiveness in complex and large-scale cloud environments.</li>
</ul>

<h3>Title: All You Need Is Synthetic Task Augmentation</h3>
<ul>
<li><strong>Authors: </strong>Guillaume Godin</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.10120">https://arxiv.org/abs/2505.10120</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.10120">https://arxiv.org/pdf/2505.10120</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.10120]] All You Need Is Synthetic Task Augmentation(https://arxiv.org/abs/2505.10120)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Injecting rule-based models like Random Forests into differentiable neural network frameworks remains an open challenge in machine learning. Recent advancements have demonstrated that pretrained models can generate efficient molecular embeddings. However, these approaches often require extensive pretraining and additional techniques, such as incorporating posterior probabilities, to boost performance. In our study, we propose a novel strategy that jointly trains a single Graph Transformer neural network on both sparse multitask molecular property experimental targets and synthetic targets derived from XGBoost models trained on Osmordred molecular descriptors. These synthetic tasks serve as independent auxiliary tasks. Our results show consistent and significant performance improvement across all 19 molecular property prediction tasks. For 16 out of 19 targets, the multitask Graph Transformer outperforms the XGBoost single-task learner. This demonstrates that synthetic task augmentation is an effective method for enhancing neural model performance in multitask molecular property prediction without the need for feature injection or pretraining.</li>
</ul>

<h3>Title: Enhancing the Performance of Global Model by Improving the Adaptability of Local Models in Federated Learning</h3>
<ul>
<li><strong>Authors: </strong>Wujun Zhou, Shu Ding, ZeLin Li, Wei Wang</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.10125">https://arxiv.org/abs/2505.10125</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.10125">https://arxiv.org/pdf/2505.10125</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.10125]] Enhancing the Performance of Global Model by Improving the Adaptability of Local Models in Federated Learning(https://arxiv.org/abs/2505.10125)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, federate</a></li>
<li><strong>Abstract: </strong>Federated learning enables the clients to collaboratively train a global model, which is aggregated from local models. Due to the heterogeneous data distributions over clients and data privacy in federated learning, it is difficult to train local models to achieve a well-performed global model. In this paper, we introduce the adaptability of local models, i.e., the average performance of local models on data distributions over clients, and enhance the performance of the global model by improving the adaptability of local models. Since each client does not know the data distributions over other clients, the adaptability of the local model cannot be directly optimized. First, we provide the property of an appropriate local model which has good adaptability on the data distributions over clients. Then, we formalize the property into the local training objective with a constraint and propose a feasible solution to train the local model. Extensive experiments on federated learning benchmarks demonstrate that our method significantly improves the adaptability of local models and achieves a well-performed global model that consistently outperforms the baseline methods.</li>
</ul>

<h3>Title: Robust Federated Learning on Edge Devices with Domain Heterogeneity</h3>
<ul>
<li><strong>Authors: </strong>Huy Q. Le, Latif U. Khan, Choong Seon Hong</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.10128">https://arxiv.org/abs/2505.10128</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.10128">https://arxiv.org/pdf/2505.10128</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.10128]] Robust Federated Learning on Edge Devices with Domain Heterogeneity(https://arxiv.org/abs/2505.10128)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, robust, federate</a></li>
<li><strong>Abstract: </strong>Federated Learning (FL) allows collaborative training while ensuring data privacy across distributed edge devices, making it a popular solution for privacy-sensitive applications. However, FL faces significant challenges due to statistical heterogeneity, particularly domain heterogeneity, which impedes the global mode's convergence. In this study, we introduce a new framework to address this challenge by improving the generalization ability of the FL global model under domain heterogeneity, using prototype augmentation. Specifically, we introduce FedAPC (Federated Augmented Prototype Contrastive Learning), a prototype-based FL framework designed to enhance feature diversity and model robustness. FedAPC leverages prototypes derived from the mean features of augmented data to capture richer representations. By aligning local features with global prototypes, we enable the model to learn meaningful semantic features while reducing overfitting to any specific domain. Experimental results on the Office-10 and Digits datasets illustrate that our framework outperforms SOTA baselines, demonstrating superior performance.</li>
</ul>

<h3>Title: GE-Chat: A Graph Enhanced RAG Framework for Evidential Response Generation of LLMs</h3>
<ul>
<li><strong>Authors: </strong>Longchao Da, Parth Mitesh Shah, Kuan-Ru Liou, Jiaxing Zhang, Hua Wei</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.10143">https://arxiv.org/abs/2505.10143</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.10143">https://arxiv.org/pdf/2505.10143</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.10143]] GE-Chat: A Graph Enhanced RAG Framework for Evidential Response Generation of LLMs(https://arxiv.org/abs/2505.10143)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large Language Models are now key assistants in human decision-making processes. However, a common note always seems to follow: "LLMs can make mistakes. Be careful with important info." This points to the reality that not all outputs from LLMs are dependable, and users must evaluate them manually. The challenge deepens as hallucinated responses, often presented with seemingly plausible explanations, create complications and raise trust issues among users. To tackle such issue, this paper proposes GE-Chat, a knowledge Graph enhanced retrieval-augmented generation framework to provide Evidence-based response generation. Specifically, when the user uploads a material document, a knowledge graph will be created, which helps construct a retrieval-augmented agent, enhancing the agent's responses with additional knowledge beyond its training corpus. Then we leverage Chain-of-Thought (CoT) logic generation, n-hop sub-graph searching, and entailment-based sentence generation to realize accurate evidence retrieval. We demonstrate that our method improves the existing models' performance in terms of identifying the exact evidence in a free-form context, providing a reliable way to examine the resources of LLM's conclusion and help with the judgment of the trustworthiness.</li>
</ul>

<h3>Title: Multi-Source Collaborative Style Augmentation and Domain-Invariant Learning for Federated Domain Generalization</h3>
<ul>
<li><strong>Authors: </strong>Yikang Wei</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.10152">https://arxiv.org/abs/2505.10152</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.10152">https://arxiv.org/pdf/2505.10152</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.10152]] Multi-Source Collaborative Style Augmentation and Domain-Invariant Learning for Federated Domain Generalization(https://arxiv.org/abs/2505.10152)</code><input type="text"></li>
<li><strong>Keywords: </strong>federate</a></li>
<li><strong>Abstract: </strong>Federated domain generalization aims to learn a generalizable model from multiple decentralized source domains for deploying on the unseen target domain. The style augmentation methods have achieved great progress on domain generalization. However, the existing style augmentation methods either explore the data styles within isolated source domain or interpolate the style information across existing source domains under the data decentralization scenario, which leads to limited style space. To address this issue, we propose a Multi-source Collaborative Style Augmentation and Domain-invariant learning method (MCSAD) for federated domain generalization. Specifically, we propose a multi-source collaborative style augmentation module to generate data in the broader style space. Furthermore, we conduct domain-invariant learning between the original data and augmented data by cross-domain feature alignment within the same class and classes relation ensemble distillation between different classes to learn a domain-invariant model. By alternatively conducting collaborative style augmentation and domain-invariant learning, the model can generalize well on unseen target domain. Extensive experiments on multiple domain generalization datasets indicate that our method significantly outperforms the state-of-the-art federated domain generalization methods.</li>
</ul>

<h3>Title: QuXAI: Explainers for Hybrid Quantum Machine Learning Models</h3>
<ul>
<li><strong>Authors: </strong>Saikat Barua, Mostafizur Rahman, Shehenaz Khaled, Md Jafor Sadek, Rafiul Islam, Shahnewaz Siddique</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, quant-ph</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.10167">https://arxiv.org/abs/2505.10167</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.10167">https://arxiv.org/pdf/2505.10167</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.10167]] QuXAI: Explainers for Hybrid Quantum Machine Learning Models(https://arxiv.org/abs/2505.10167)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, interpretability, explainability</a></li>
<li><strong>Abstract: </strong>The emergence of hybrid quantum-classical machine learning (HQML) models opens new horizons of computational intelligence but their fundamental complexity frequently leads to black box behavior that undermines transparency and reliability in their application. Although XAI for quantum systems still in its infancy, a major research gap is evident in robust global and local explainability approaches that are designed for HQML architectures that employ quantized feature encoding followed by classical learning. The gap is the focus of this work, which introduces QuXAI, an framework based upon Q-MEDLEY, an explainer for explaining feature importance in these hybrid systems. Our model entails the creation of HQML models incorporating quantum feature maps, the use of Q-MEDLEY, which combines feature based inferences, preserving the quantum transformation stage and visualizing the resulting attributions. Our result shows that Q-MEDLEY delineates influential classical aspects in HQML models, as well as separates their noise, and competes well against established XAI techniques in classical validation settings. Ablation studies more significantly expose the virtues of the composite structure used in Q-MEDLEY. The implications of this work are critically important, as it provides a route to improve the interpretability and reliability of HQML models, thus promoting greater confidence and being able to engage in safer and more responsible use of quantum-enhanced AI technology.</li>
</ul>

<h3>Title: Does Scaling Law Apply in Time Series Forecasting?</h3>
<ul>
<li><strong>Authors: </strong>Zeyan Li, Libing Chen, Yin Tang</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.10172">https://arxiv.org/abs/2505.10172</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.10172">https://arxiv.org/pdf/2505.10172</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.10172]] Does Scaling Law Apply in Time Series Forecasting?(https://arxiv.org/abs/2505.10172)</code><input type="text"></li>
<li><strong>Keywords: </strong>fair, transformer</a></li>
<li><strong>Abstract: </strong>Rapid expansion of model size has emerged as a key challenge in time series forecasting. From early Transformer with tens of megabytes to recent architectures like TimesNet with thousands of megabytes, performance gains have often come at the cost of exponentially increasing parameter counts. But is this scaling truly necessary? To question the applicability of the scaling law in time series forecasting, we propose Alinear, an ultra-lightweight forecasting model that achieves competitive performance using only k-level parameters. We introduce a horizon-aware adaptive decomposition mechanism that dynamically rebalances component emphasis across different forecast lengths, alongside a progressive frequency attenuation strategy that achieves stable prediction in various forecasting horizons without incurring the computational overhead of attention mechanisms. Extensive experiments on seven benchmark datasets demonstrate that Alinear consistently outperforms large-scale models while using less than 1% of their parameters, maintaining strong accuracy across both short and ultra-long forecasting horizons. Moreover, to more fairly evaluate model efficiency, we propose a new parameter-aware evaluation metric that highlights the superiority of ALinear under constrained model budgets. Our analysis reveals that the relative importance of trend and seasonal components varies depending on data characteristics rather than following a fixed pattern, validating the necessity of our adaptive design. This work challenges the prevailing belief that larger models are inherently better and suggests a paradigm shift toward more efficient time series modeling.</li>
</ul>

<h3>Title: Mining Hidden Thoughts from Texts: Evaluating Continual Pretraining with Synthetic Data for LLM Reasoning</h3>
<ul>
<li><strong>Authors: </strong>Yoichi Ishibashi, Taro Yano, Masafumi Oyamada</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.10182">https://arxiv.org/abs/2505.10182</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.10182">https://arxiv.org/pdf/2505.10182</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.10182]] Mining Hidden Thoughts from Texts: Evaluating Continual Pretraining with Synthetic Data for LLM Reasoning(https://arxiv.org/abs/2505.10182)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large Language Models (LLMs) have demonstrated significant improvements in reasoning capabilities through supervised fine-tuning and reinforcement learning. However, when training reasoning models, these approaches are primarily applicable to specific domains such as mathematics and programming, which imposes fundamental constraints on the breadth and scalability of training data. In contrast, continual pretraining (CPT) offers the advantage of not requiring task-specific signals. Nevertheless, how to effectively synthesize training data for reasoning and how such data affect a wide range of domains remain largely unexplored. This study provides a detailed evaluation of Reasoning CPT, a form of CPT that uses synthetic data to reconstruct the hidden thought processes underlying texts, based on the premise that texts are the result of the author's thinking process. Specifically, we apply Reasoning CPT to Gemma2-9B using synthetic data with hidden thoughts derived from STEM and Law corpora, and compare it to standard CPT on the MMLU benchmark. Our analysis reveals that Reasoning CPT consistently improves performance across all evaluated domains. Notably, reasoning skills acquired in one domain transfer effectively to others; the performance gap with conventional methods widens as problem difficulty increases, with gains of up to 8 points on the most challenging problems. Furthermore, models trained with hidden thoughts learn to adjust the depth of their reasoning according to problem difficulty.</li>
</ul>

<h3>Title: The CoT Encyclopedia: Analyzing, Predicting, and Controlling how a Reasoning Model will Think</h3>
<ul>
<li><strong>Authors: </strong>Seongyun Lee, Seungone Kim, Minju Seo, Yongrae Jo, Dongyoung Go, Hyeonbin Hwang, Jinho Park, Xiang Yue, Sean Welleck, Graham Neubig, Moontae Lee, Minjoon Seo</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.10185">https://arxiv.org/abs/2505.10185</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.10185">https://arxiv.org/pdf/2505.10185</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.10185]] The CoT Encyclopedia: Analyzing, Predicting, and Controlling how a Reasoning Model will Think(https://arxiv.org/abs/2505.10185)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Long chain-of-thought (CoT) is an essential ingredient in effective usage of modern large language models, but our understanding of the reasoning strategies underlying these capabilities remains limited. While some prior works have attempted to categorize CoTs using predefined strategy types, such approaches are constrained by human intuition and fail to capture the full diversity of model behaviors. In this work, we introduce the CoT Encyclopedia, a bottom-up framework for analyzing and steering model reasoning. Our method automatically extracts diverse reasoning criteria from model-generated CoTs, embeds them into a semantic space, clusters them into representative categories, and derives contrastive rubrics to interpret reasoning behavior. Human evaluations show that this framework produces more interpretable and comprehensive analyses than existing methods. Moreover, we demonstrate that this understanding enables performance gains: we can predict which strategy a model is likely to use and guide it toward more effective alternatives. Finally, we provide practical insights, such as that training data format (e.g., free-form vs. multiple-choice) has a far greater impact on reasoning behavior than data domain, underscoring the importance of format-aware model design.</li>
</ul>

<h3>Title: Defect Detection in Photolithographic Patterns Using Deep Learning Models Trained on Synthetic Data</h3>
<ul>
<li><strong>Authors: </strong>Prashant P. Shinde, Priyadarshini P. Pai, Shashishekar P. Adiga, K. Subramanya Mayya, Yongbeom Seo, Myungsoo Hwang, Heeyoung Go, Changmin Park</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.10192">https://arxiv.org/abs/2505.10192</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.10192">https://arxiv.org/pdf/2505.10192</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.10192]] Defect Detection in Photolithographic Patterns Using Deep Learning Models Trained on Synthetic Data(https://arxiv.org/abs/2505.10192)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>In the photolithographic process vital to semiconductor manufacturing, various types of defects appear during EUV pattering. Due to ever-shrinking pattern size, these defects are extremely small and cause false or missed detection during inspection. Specifically, the lack of defect-annotated quality data with good representation of smaller defects has prohibited deployment of deep learning based defect detection models in fabrication lines. To resolve the problem of data unavailability, we artificially generate scanning electron microscopy (SEM) images of line patterns with known distribution of defects and autonomously annotate them. We then employ state-of-the-art object detection models to investigate defect detection performance as a function of defect size, much smaller than the pitch width. We find that the real-time object detector YOLOv8 has the best mean average precision of 96% as compared to EfficientNet, 83%, and SSD, 77%, with the ability to detect smaller defects. We report the smallest defect size that can be detected reliably. When tested on real SEM data, the YOLOv8 model correctly detected 84.6% of Bridge defects and 78.3% of Break defects across all relevant instances. These promising results suggest that synthetic data can be used as an alternative to real-world data in order to develop robust machine-learning models.</li>
</ul>

<h3>Title: A multi-head deep fusion model for recognition of cattle foraging events using sound and movement signals</h3>
<ul>
<li><strong>Authors: </strong>Mariano Ferrero, José Omar Chelotti, Luciano Sebastián Martinez-Rau, Leandro Vignolo, Martín Pires, Julio Ricardo Galli, Leonardo Luis Giovanini, Hugo Leonardo Rufiner</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.10198">https://arxiv.org/abs/2505.10198</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.10198">https://arxiv.org/pdf/2505.10198</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.10198]] A multi-head deep fusion model for recognition of cattle foraging events using sound and movement signals(https://arxiv.org/abs/2505.10198)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction</a></li>
<li><strong>Abstract: </strong>Monitoring feeding behaviour is a relevant task for efficient herd management and the effective use of available resources in grazing cattle. The ability to automatically recognise animals' feeding activities through the identification of specific jaw movements allows for the improvement of diet formulation, as well as early detection of metabolic problems and symptoms of animal discomfort, among other benefits. The use of sensors to obtain signals for such monitoring has become popular in the last two decades. The most frequently employed sensors include accelerometers, microphones, and cameras, each with its own set of advantages and drawbacks. An unexplored aspect is the simultaneous use of multiple sensors with the aim of combining signals in order to enhance the precision of the estimations. In this direction, this work introduces a deep neural network based on the fusion of acoustic and inertial signals, composed of convolutional, recurrent, and dense layers. The main advantage of this model is the combination of signals through the automatic extraction of features independently from each of them. The model has emerged from an exploration and comparison of different neural network architectures proposed in this work, which carry out information fusion at different levels. Feature-level fusion has outperformed data and decision-level fusion by at least a 0.14 based on the F1-score metric. Moreover, a comparison with state-of-the-art machine learning methods is presented, including traditional and deep learning approaches. The proposed model yielded an F1-score value of 0.802, representing a 14% increase compared to previous methods. Finally, results from an ablation study and post-training quantization evaluation are also reported.</li>
</ul>

<h3>Title: VQ-Logits: Compressing the Output Bottleneck of Large Language Models via Vector Quantized Logits</h3>
<ul>
<li><strong>Authors: </strong>Jintian Shao, Hongyi Huang, Jiayi Wu, YiMing Cheng, ZhiYu Wu, You Shan, MingKai Zheng</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.10202">https://arxiv.org/abs/2505.10202</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.10202">https://arxiv.org/pdf/2505.10202</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.10202]] VQ-Logits: Compressing the Output Bottleneck of Large Language Models via Vector Quantized Logits(https://arxiv.org/abs/2505.10202)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, large language model</a></li>
<li><strong>Abstract: </strong>Large Language Models (LLMs) have achieved remarkable success but face significant computational and memory challenges, particularly due to their extensive output vocabularies. The final linear projection layer, mapping hidden states to vocabulary-sized logits, often constitutes a substantial portion of the model's parameters and computational cost during inference. Existing methods like adaptive softmax or hierarchical softmax introduce structural complexities. In this paper, we propose VQ-Logits, a novel approach that leverages Vector Quantization (VQ) to drastically reduce the parameter count and computational load of the LLM output layer. VQ-Logits replaces the large V * dmodel output embedding matrix with a small, shared codebook of K embedding vectors (K << V ). Each token in the vocabulary is mapped to one of these K codebook vectors. The LLM predicts logits over this compact codebook, which are then efficiently "scattered" to the full vocabulary space using the learned or preassigned mapping. We demonstrate through extensive experiments on standard language modeling benchmarks (e.g., WikiText-103, C4) that VQ-Logits can achieve up to 99% parameter reduction in the output layer and 6x speedup in logit computation, with only a marginal 4% increase in perplexity compared to full softmax baselines. We further provide detailed ablation studies on codebook size, initialization, and learning strategies, showcasing the robustness and effectiveness of our approach.</li>
</ul>

<h3>Title: VolE: A Point-cloud Framework for Food 3D Reconstruction and Volume Estimation</h3>
<ul>
<li><strong>Authors: </strong>Umair Haroon, Ahmad AlMughrabi, Thanasis Zoumpekas, Ricardo Marques, Petia Radeva</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.10205">https://arxiv.org/abs/2505.10205</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.10205">https://arxiv.org/pdf/2505.10205</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.10205]] VolE: A Point-cloud Framework for Food 3D Reconstruction and Volume Estimation(https://arxiv.org/abs/2505.10205)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>Accurate food volume estimation is crucial for medical nutrition management and health monitoring applications, but current food volume estimation methods are often limited by mononuclear data, leveraging single-purpose hardware such as 3D scanners, gathering sensor-oriented information such as depth information, or relying on camera calibration using a reference object. In this paper, we present VolE, a novel framework that leverages mobile device-driven 3D reconstruction to estimate food volume. VolE captures images and camera locations in free motion to generate precise 3D models, thanks to AR-capable mobile devices. To achieve real-world measurement, VolE is a reference- and depth-free framework that leverages food video segmentation for food mask generation. We also introduce a new food dataset encompassing the challenging scenarios absent in the previous benchmarks. Our experiments demonstrate that VolE outperforms the existing volume estimation techniques across multiple datasets by achieving 2.22 % MAPE, highlighting its superior performance in food volume estimation.</li>
</ul>

<h3>Title: Informed Forecasting: Leveraging Auxiliary Knowledge to Boost LLM Performance on Time Series Forecasting</h3>
<ul>
<li><strong>Authors: </strong>Mohammadmahdi Ghasemloo, Alireza Moradi</a></li>
<li><strong>Subjects: </strong>cs.LG, stat.AP</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.10213">https://arxiv.org/abs/2505.10213</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.10213">https://arxiv.org/pdf/2505.10213</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.10213]] Informed Forecasting: Leveraging Auxiliary Knowledge to Boost LLM Performance on Time Series Forecasting(https://arxiv.org/abs/2505.10213)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>With the widespread adoption of Large Language Models (LLMs), there is a growing need to establish best practices for leveraging their capabilities beyond traditional natural language tasks. In this paper, a novel cross-domain knowledge transfer framework is proposed to enhance the performance of LLMs in time series forecasting -- a task of increasing relevance in fields such as energy systems, finance, and healthcare. The approach systematically infuses LLMs with structured temporal information to improve their forecasting accuracy. This study evaluates the proposed method on a real-world time series dataset and compares it to a naive baseline where the LLM receives no auxiliary information. Results show that knowledge-informed forecasting significantly outperforms the uninformed baseline in terms of predictive accuracy and generalization. These findings highlight the potential of knowledge transfer strategies to bridge the gap between LLMs and domain-specific forecasting tasks.</li>
</ul>

<h3>Title: RAIDEN-R1: Improving Role-awareness of LLMs via GRPO with Verifiable Reward</h3>
<ul>
<li><strong>Authors: </strong>Zongsheng Wang, Kaili Sun, Bowen Wu, Qun Yu, Ying Li, Baoxun Wang</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.10218">https://arxiv.org/abs/2505.10218</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.10218">https://arxiv.org/pdf/2505.10218</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.10218]] RAIDEN-R1: Improving Role-awareness of LLMs via GRPO with Verifiable Reward(https://arxiv.org/abs/2505.10218)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Role-playing conversational agents (RPCAs) face persistent challenges in maintaining role consistency. To address this, we propose RAIDEN-R1, a novel reinforcement learning framework that integrates Verifiable Role-Awareness Reward (VRAR). The method introduces both singular and multi-term mining strategies to generate quantifiable rewards by assessing role-specific keys. Additionally, we construct a high-quality, role-aware Chain-of-Thought dataset through multi-LLM collaboration, and implement experiments to enhance reasoning coherence. Experiments on the RAIDEN benchmark demonstrate RAIDEN-R1's superiority: our 14B-GRPO model achieves 88.04% and 88.65% accuracy on Script-Based Knowledge and Conversation Memory metrics, respectively, outperforming baseline models while maintaining robustness. Case analyses further reveal the model's enhanced ability to resolve conflicting contextual cues and sustain first-person narrative consistency. This work bridges the non-quantifiability gap in RPCA training and provides insights into role-aware reasoning patterns, advancing the development of RPCAs.</li>
</ul>

<h3>Title: ComplexFormer: Disruptively Advancing Transformer Inference Ability via Head-Specific Complex Vector Attention</h3>
<ul>
<li><strong>Authors: </strong>Jintian Shao, Hongyi Huang, Jiayi Wu, Beiwen Zhang, ZhiYu Wu, You Shan, MingKai Zheng</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.10222">https://arxiv.org/abs/2505.10222</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.10222">https://arxiv.org/pdf/2505.10222</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.10222]] ComplexFormer: Disruptively Advancing Transformer Inference Ability via Head-Specific Complex Vector Attention(https://arxiv.org/abs/2505.10222)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Transformer models rely on self-attention to capture token dependencies but face challenges in effectively integrating positional information while allowing multi-head attention (MHA) flexibility. Prior methods often model semantic and positional differences disparately or apply uniform positional adjustments across heads, potentially limiting representational capacity. This paper introduces ComplexFormer, featuring Complex Multi-Head Attention-CMHA. CMHA empowers each head to independently model semantic and positional differences unified within the complex plane, representing interactions as rotations and scaling. ComplexFormer incorporates two key improvements: (1) a per-head Euler transformation, converting real-valued query/key projections into polar-form complex vectors for head-specific complex subspace operation; and (2) a per-head adaptive differential rotation mechanism, exp[i(Adapt(ASmn,i) + Delta(Pmn),i)], allowing each head to learn distinct strategies for integrating semantic angle differences (ASmn,i) with relative positional encodings (Delta(Pmn),i). Extensive experiments on language modeling, text generation, code generation, and mathematical reasoning show ComplexFormer achieves superior performance, significantly lower generation perplexity , and improved long-context coherence compared to strong baselines like RoPE-Transformers. ComplexFormer demonstrates strong parameter efficiency, offering a more expressive, adaptable attention mechanism.</li>
</ul>

<h3>Title: Data-Agnostic Augmentations for Unknown Variations: Out-of-Distribution Generalisation in MRI Segmentation</h3>
<ul>
<li><strong>Authors: </strong>Puru Vaish, Felix Meister, Tobias Heimann, Christoph Brune, Jelmer M. Wolterink</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.10223">https://arxiv.org/abs/2505.10223</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.10223">https://arxiv.org/pdf/2505.10223</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.10223]] Data-Agnostic Augmentations for Unknown Variations: Out-of-Distribution Generalisation in MRI Segmentation(https://arxiv.org/abs/2505.10223)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, segmentation</a></li>
<li><strong>Abstract: </strong>Medical image segmentation models are often trained on curated datasets, leading to performance degradation when deployed in real-world clinical settings due to mismatches between training and test distributions. While data augmentation techniques are widely used to address these challenges, traditional visually consistent augmentation strategies lack the robustness needed for diverse real-world scenarios. In this work, we systematically evaluate alternative augmentation strategies, focusing on MixUp and Auxiliary Fourier Augmentation. These methods mitigate the effects of multiple variations without explicitly targeting specific sources of distribution shifts. We demonstrate how these techniques significantly improve out-of-distribution generalization and robustness to imaging variations across a wide range of transformations in cardiac cine MRI and prostate MRI segmentation. We quantitatively find that these augmentation methods enhance learned feature representations by promoting separability and compactness. Additionally, we highlight how their integration into nnU-Net training pipelines provides an easy-to-implement, effective solution for enhancing the reliability of medical segmentation models in real-world applications.</li>
</ul>

<h3>Title: On the Interplay of Human-AI Alignment,Fairness, and Performance Trade-offs in Medical Imaging</h3>
<ul>
<li><strong>Authors: </strong>Haozhe Luo, Ziyu Zhou, Zixin Shu, Aurélie Pahud de Mortanges, Robert Berke, Mauricio Reyes</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.10231">https://arxiv.org/abs/2505.10231</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.10231">https://arxiv.org/pdf/2505.10231</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.10231]] On the Interplay of Human-AI Alignment,Fairness, and Performance Trade-offs in Medical Imaging(https://arxiv.org/abs/2505.10231)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, fair</a></li>
<li><strong>Abstract: </strong>Deep neural networks excel in medical imaging but remain prone to biases, leading to fairness gaps across demographic groups. We provide the first systematic exploration of Human-AI alignment and fairness in this domain. Our results show that incorporating human insights consistently reduces fairness gaps and enhances out-of-domain generalization, though excessive alignment can introduce performance trade-offs, emphasizing the need for calibrated strategies. These findings highlight Human-AI alignment as a promising approach for developing fair, robust, and generalizable medical AI systems, striking a balance between expert guidance and automated efficiency. Our code is available at this https URL.</li>
</ul>

<h3>Title: MTVCrafter: 4D Motion Tokenization for Open-World Human Image Animation</h3>
<ul>
<li><strong>Authors: </strong>Yanbo Ding</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.10238">https://arxiv.org/abs/2505.10238</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.10238">https://arxiv.org/pdf/2505.10238</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.10238]] MTVCrafter: 4D Motion Tokenization for Open-World Human Image Animation(https://arxiv.org/abs/2505.10238)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Human image animation has gained increasing attention and developed rapidly due to its broad applications in digital humans. However, existing methods rely largely on 2D-rendered pose images for motion guidance, which limits generalization and discards essential 3D information for open-world animation. To tackle this problem, we propose MTVCrafter (Motion Tokenization Video Crafter), the first framework that directly models raw 3D motion sequences (i.e., 4D motion) for human image animation. Specifically, we introduce 4DMoT (4D motion tokenizer) to quantize 3D motion sequences into 4D motion tokens. Compared to 2D-rendered pose images, 4D motion tokens offer more robust spatio-temporal cues and avoid strict pixel-level alignment between pose image and character, enabling more flexible and disentangled control. Then, we introduce MV-DiT (Motion-aware Video DiT). By designing unique motion attention with 4D positional encodings, MV-DiT can effectively leverage motion tokens as 4D compact yet expressive context for human image animation in the complex 3D world. Hence, it marks a significant step forward in this field and opens a new direction for pose-guided human video generation. Experiments show that our MTVCrafter achieves state-of-the-art results with an FID-VID of 6.98, surpassing the second-best by 65%. Powered by robust motion tokens, MTVCrafter also generalizes well to diverse open-world characters (single/multiple, full/half-body) across various styles and scenarios. Our video demos and code are provided in the supplementary material and at this anonymous GitHub link: this https URL.</li>
</ul>

<h3>Title: ADHMR: Aligning Diffusion-based Human Mesh Recovery via Direct Preference Optimization</h3>
<ul>
<li><strong>Authors: </strong>Wenhao Shen, Wanqi Yin, Xiaofeng Yang, Cheng Chen, Chaoyue Song, Zhongang Cai, Lei Yang, Hao Wang, Guosheng Lin</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.10250">https://arxiv.org/abs/2505.10250</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.10250">https://arxiv.org/pdf/2505.10250</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.10250]] ADHMR: Aligning Diffusion-based Human Mesh Recovery via Direct Preference Optimization(https://arxiv.org/abs/2505.10250)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, diffusion</a></li>
<li><strong>Abstract: </strong>Human mesh recovery (HMR) from a single image is inherently ill-posed due to depth ambiguity and occlusions. Probabilistic methods have tried to solve this by generating numerous plausible 3D human mesh predictions, but they often exhibit misalignment with 2D image observations and weak robustness to in-the-wild images. To address these issues, we propose ADHMR, a framework that Aligns a Diffusion-based HMR model in a preference optimization manner. First, we train a human mesh prediction assessment model, HMR-Scorer, capable of evaluating predictions even for in-the-wild images without 3D annotations. We then use HMR-Scorer to create a preference dataset, where each input image has a pair of winner and loser mesh predictions. This dataset is used to finetune the base model using direct preference optimization. Moreover, HMR-Scorer also helps improve existing HMR models by data cleaning, even with fewer training samples. Extensive experiments show that ADHMR outperforms current state-of-the-art methods. Code is available at: this https URL.</li>
</ul>

<h3>Title: Inferring Driving Maps by Deep Learning-based Trail Map Extraction</h3>
<ul>
<li><strong>Authors: </strong>Michael Hubbertz, Pascal Colling, Qi Han, Tobias Meisen</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.RO</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.10258">https://arxiv.org/abs/2505.10258</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.10258">https://arxiv.org/pdf/2505.10258</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.10258]] Inferring Driving Maps by Deep Learning-based Trail Map Extraction(https://arxiv.org/abs/2505.10258)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, extraction, transformer</a></li>
<li><strong>Abstract: </strong>High-definition (HD) maps offer extensive and accurate environmental information about the driving scene, making them a crucial and essential element for planning within autonomous driving systems. To avoid extensive efforts from manual labeling, methods for automating the map creation have emerged. Recent trends have moved from offline mapping to online mapping, ensuring availability and actuality of the utilized maps. While the performance has increased in recent years, online mapping still faces challenges regarding temporal consistency, sensor occlusion, runtime, and generalization. We propose a novel offline mapping approach that integrates trails - informal routes used by drivers - into the map creation process. Our method aggregates trail data from the ego vehicle and other traffic participants to construct a comprehensive global map using transformer-based deep learning models. Unlike traditional offline mapping, our approach enables continuous updates while remaining sensor-agnostic, facilitating efficient data transfer. Our method demonstrates superior performance compared to state-of-the-art online mapping approaches, achieving improved generalization to previously unseen environments and sensor configurations. We validate our approach on two benchmark datasets, highlighting its robustness and applicability in autonomous driving systems.</li>
</ul>

<h3>Title: Comparing LLM Text Annotation Skills: A Study on Human Rights Violations in Social Media Data</h3>
<ul>
<li><strong>Authors: </strong>Poli Apollinaire Nemkova, Solomon Ubani, Mark V. Albert</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.10260">https://arxiv.org/abs/2505.10260</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.10260">https://arxiv.org/pdf/2505.10260</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.10260]] Comparing LLM Text Annotation Skills: A Study on Human Rights Violations in Social Media Data(https://arxiv.org/abs/2505.10260)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>In the era of increasingly sophisticated natural language processing (NLP) systems, large language models (LLMs) have demonstrated remarkable potential for diverse applications, including tasks requiring nuanced textual understanding and contextual reasoning. This study investigates the capabilities of multiple state-of-the-art LLMs - GPT-3.5, GPT-4, LLAMA3, Mistral 7B, and Claude-2 - for zero-shot and few-shot annotation of a complex textual dataset comprising social media posts in Russian and Ukrainian. Specifically, the focus is on the binary classification task of identifying references to human rights violations within the dataset. To evaluate the effectiveness of these models, their annotations are compared against a gold standard set of human double-annotated labels across 1000 samples. The analysis includes assessing annotation performance under different prompting conditions, with prompts provided in both English and Russian. Additionally, the study explores the unique patterns of errors and disagreements exhibited by each model, offering insights into their strengths, limitations, and cross-linguistic adaptability. By juxtaposing LLM outputs with human annotations, this research contributes to understanding the reliability and applicability of LLMs for sensitive, domain-specific tasks in multilingual contexts. It also sheds light on how language models handle inherently subjective and context-dependent judgments, a critical consideration for their deployment in real-world scenarios.</li>
</ul>

<h3>Title: The Evolving Landscape of Generative Large Language Models and Traditional Natural Language Processing in Medicine</h3>
<ul>
<li><strong>Authors: </strong>Rui Yang, Huitao Li, Matthew Yu Heng Wong, Yuhe Ke, Xin Li, Kunyu Yu, Jingchi Liao, Jonathan Chong Kai Liew, Sabarinath Vinod Nair, Jasmine Chiat Ling Ong, Irene Li, Douglas Teodoro, Chuan Hong, Daniel Shu Wei Ting, Nan Liu</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.10261">https://arxiv.org/abs/2505.10261</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.10261">https://arxiv.org/pdf/2505.10261</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.10261]] The Evolving Landscape of Generative Large Language Models and Traditional Natural Language Processing in Medicine(https://arxiv.org/abs/2505.10261)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction, generative, large language model</a></li>
<li><strong>Abstract: </strong>Natural language processing (NLP) has been traditionally applied to medicine, and generative large language models (LLMs) have become prominent recently. However, the differences between them across different medical tasks remain underexplored. We analyzed 19,123 studies, finding that generative LLMs demonstrate advantages in open-ended tasks, while traditional NLP dominates in information extraction and analysis tasks. As these technologies advance, ethical use of them is essential to ensure their potential in medical applications.</li>
</ul>

<h3>Title: Cutting Through Privacy: A Hyperplane-Based Data Reconstruction Attack in Federated Learning</h3>
<ul>
<li><strong>Authors: </strong>Francesco Diana, André Nusser, Chuan Xu, Giovanni Neglia</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.10264">https://arxiv.org/abs/2505.10264</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.10264">https://arxiv.org/pdf/2505.10264</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.10264]] Cutting Through Privacy: A Hyperplane-Based Data Reconstruction Attack in Federated Learning(https://arxiv.org/abs/2505.10264)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, attack, federate</a></li>
<li><strong>Abstract: </strong>Federated Learning (FL) enables collaborative training of machine learning models across distributed clients without sharing raw data, ostensibly preserving data privacy. Nevertheless, recent studies have revealed critical vulnerabilities in FL, showing that a malicious central server can manipulate model updates to reconstruct clients' private training data. Existing data reconstruction attacks have important limitations: they often rely on assumptions about the clients' data distribution or their efficiency significantly degrades when batch sizes exceed just a few tens of samples. In this work, we introduce a novel data reconstruction attack that overcomes these limitations. Our method leverages a new geometric perspective on fully connected layers to craft malicious model parameters, enabling the perfect recovery of arbitrarily large data batches in classification tasks without any prior knowledge of clients' data. Through extensive experiments on both image and tabular datasets, we demonstrate that our attack outperforms existing methods and achieves perfect reconstruction of data batches two orders of magnitude larger than the state of the art.</li>
</ul>

<h3>Title: RainPro-8: An Efficient Deep Learning Model to Estimate Rainfall Probabilities Over 8 Hours</h3>
<ul>
<li><strong>Authors: </strong>Rafael Pablos Sarabia, Joachim Nyborg, Morten Birk, Jeppe Liborius Sjørup, Anders Lillevang Vesterholt, Ira Assent</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.10271">https://arxiv.org/abs/2505.10271</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.10271">https://arxiv.org/pdf/2505.10271</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.10271]] RainPro-8: An Efficient Deep Learning Model to Estimate Rainfall Probabilities Over 8 Hours(https://arxiv.org/abs/2505.10271)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, interpretability</a></li>
<li><strong>Abstract: </strong>We present a deep learning model for high-resolution probabilistic precipitation forecasting over an 8-hour horizon in Europe, overcoming the limitations of radar-only deep learning models with short forecast lead times. Our model efficiently integrates multiple data sources - including radar, satellite, and physics-based numerical weather prediction (NWP) - while capturing long-range interactions, resulting in accurate forecasts with robust uncertainty quantification through consistent probabilistic maps. Featuring a compact architecture, it enables more efficient training and faster inference than existing models. Extensive experiments demonstrate that our model surpasses current operational NWP systems, extrapolation-based methods, and deep-learning nowcasting models, setting a new standard for high-resolution precipitation forecasting in Europe, ensuring a balance between accuracy, interpretability, and computational efficiency.</li>
</ul>

<h3>Title: AttentionGuard: Transformer-based Misbehavior Detection for Secure Vehicular Platoons</h3>
<ul>
<li><strong>Authors: </strong>Hexu Li, Konstantinos Kalogiannis, Ahmed Mohamed Hussain, Panos Papadimitratos</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.AI, cs.NI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.10273">https://arxiv.org/abs/2505.10273</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.10273">https://arxiv.org/pdf/2505.10273</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.10273]] AttentionGuard: Transformer-based Misbehavior Detection for Secure Vehicular Platoons(https://arxiv.org/abs/2505.10273)</code><input type="text"></li>
<li><strong>Keywords: </strong>secure, attack, robust, transformer</a></li>
<li><strong>Abstract: </strong>Vehicle platooning, with vehicles traveling in close formation coordinated through Vehicle-to-Everything (V2X) communications, offers significant benefits in fuel efficiency and road utilization. However, it is vulnerable to sophisticated falsification attacks by authenticated insiders that can destabilize the formation and potentially cause catastrophic collisions. This paper addresses this challenge: misbehavior detection in vehicle platooning systems. We present AttentionGuard, a transformer-based framework for misbehavior detection that leverages the self-attention mechanism to identify anomalous patterns in mobility data. Our proposal employs a multi-head transformer-encoder to process sequential kinematic information, enabling effective differentiation between normal mobility patterns and falsification attacks across diverse platooning scenarios, including steady-state (no-maneuver) operation, join, and exit maneuvers. Our evaluation uses an extensive simulation dataset featuring various attack vectors (constant, gradual, and combined falsifications) and operational parameters (controller types, vehicle speeds, and attacker positions). Experimental results demonstrate that AttentionGuard achieves up to 0.95 F1-score in attack detection, with robust performance maintained during complex maneuvers. Notably, our system performs effectively with minimal latency (100ms decision intervals), making it suitable for real-time transportation safety applications. Comparative analysis reveals superior detection capabilities and establishes the transformer-encoder as a promising approach for securing Cooperative Intelligent Transport Systems (C-ITS) against sophisticated insider threats.</li>
</ul>

<h3>Title: From Questions to Clinical Recommendations: Large Language Models Driving Evidence-Based Clinical Decision Making</h3>
<ul>
<li><strong>Authors: </strong>Dubai Li, Nan Jiang, Kangping Huang, Ruiqi Tu, Shuyu Ouyang, Huayu Yu, Lin Qiao, Chen Yu, Tianshu Zhou, Danyang Tong, Qian Wang, Mengtao Li, Xiaofeng Zeng, Yu Tian, Xinping Tian, Jingsong Li</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.10282">https://arxiv.org/abs/2505.10282</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.10282">https://arxiv.org/pdf/2505.10282</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.10282]] From Questions to Clinical Recommendations: Large Language Models Driving Evidence-Based Clinical Decision Making(https://arxiv.org/abs/2505.10282)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Clinical evidence, derived from rigorous research and data analysis, provides healthcare professionals with reliable scientific foundations for informed decision-making. Integrating clinical evidence into real-time practice is challenging due to the enormous workload, complex professional processes, and time constraints. This highlights the need for tools that automate evidence synthesis to support more efficient and accurate decision making in clinical settings. This study introduces Quicker, an evidence-based clinical decision support system powered by large language models (LLMs), designed to automate evidence synthesis and generate clinical recommendations modeled after standard clinical guideline development processes. Quicker implements a fully automated chain that covers all phases, from questions to clinical recommendations, and further enables customized decision-making through integrated tools and interactive user interfaces. To evaluate Quicker's capabilities, we developed the Q2CRBench-3 benchmark dataset, based on clinical guideline development records for three different diseases. Experimental results highlighted Quicker's strong performance, with fine-grained question decomposition tailored to user preferences, retrieval sensitivities comparable to human experts, and literature screening performance approaching comprehensive inclusion of relevant studies. In addition, Quicker-assisted evidence assessment effectively supported human reviewers, while Quicker's recommendations were more comprehensive and logically coherent than those of clinicians. In system-level testing, collaboration between a single reviewer and Quicker reduced the time required for recommendation development to 20-40 minutes. In general, our findings affirm the potential of Quicker to help physicians make quicker and more reliable evidence-based clinical decisions.</li>
</ul>

<h3>Title: Defending the Edge: Representative-Attention for Mitigating Backdoor Attacks in Federated Learning</h3>
<ul>
<li><strong>Authors: </strong>Chibueze Peace Obioma, Youcheng Sun, Mustafa A. Mustafa</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.10297">https://arxiv.org/abs/2505.10297</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.10297">https://arxiv.org/pdf/2505.10297</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.10297]] Defending the Edge: Representative-Attention for Mitigating Backdoor Attacks in Federated Learning(https://arxiv.org/abs/2505.10297)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, defense, attack, robust, federate</a></li>
<li><strong>Abstract: </strong>Federated learning (FL) enhances privacy and reduces communication cost for resource-constrained edge clients by supporting distributed model training at the edge. However, the heterogeneous nature of such devices produces diverse, non-independent, and identically distributed (non-IID) data, making the detection of backdoor attacks more challenging. In this paper, we propose a novel federated representative-attention-based defense mechanism, named FeRA, that leverages cross-client attention over internal feature representations to distinguish benign from malicious clients. FeRA computes an anomaly score based on representation reconstruction errors, effectively identifying clients whose internal activations significantly deviate from the group consensus. Our evaluation demonstrates FeRA's robustness across various FL scenarios, including challenging non-IID data distributions typical of edge devices. Experimental results show that it effectively reduces backdoor attack success rates while maintaining high accuracy on the main task. The method is model-agnostic, attack-agnostic, and does not require labeled reference data, making it well suited to heterogeneous and resource-limited edge deployments.</li>
</ul>

<h3>Title: Private Transformer Inference in MLaaS: A Survey</h3>
<ul>
<li><strong>Authors: </strong>Yang Li, Xinyu Zhou, Yitong Wang, Liangxin Qian, Jun Zhao</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.10315">https://arxiv.org/abs/2505.10315</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.10315">https://arxiv.org/pdf/2505.10315</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.10315]] Private Transformer Inference in MLaaS: A Survey(https://arxiv.org/abs/2505.10315)</code><input type="text"></li>
<li><strong>Keywords: </strong>secure, privacy, transformer</a></li>
<li><strong>Abstract: </strong>Transformer models have revolutionized AI, powering applications like content generation and sentiment analysis. However, their deployment in Machine Learning as a Service (MLaaS) raises significant privacy concerns, primarily due to the centralized processing of sensitive user data. Private Transformer Inference (PTI) offers a solution by utilizing cryptographic techniques such as secure multi-party computation and homomorphic encryption, enabling inference while preserving both user data and model privacy. This paper reviews recent PTI advancements, highlighting state-of-the-art solutions and challenges. We also introduce a structured taxonomy and evaluation framework for PTI, focusing on balancing resource efficiency with privacy and bridging the gap between high-performance inference and data privacy.</li>
</ul>

<h3>Title: One For All: Formally Verifying Protocols which use Aggregate Signatures (extended version)</h3>
<ul>
<li><strong>Authors: </strong>Xenia Hofmeier, Andrea Raguso, Ralf Sasse, Dennis Jackson, David Basin</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.10316">https://arxiv.org/abs/2505.10316</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.10316">https://arxiv.org/pdf/2505.10316</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.10316]] One For All: Formally Verifying Protocols which use Aggregate Signatures (extended version)(https://arxiv.org/abs/2505.10316)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, attack</a></li>
<li><strong>Abstract: </strong>Aggregate signatures are digital signatures that compress multiple signatures from different parties into a single signature, thereby reducing storage and bandwidth requirements. BLS aggregate signatures are a popular kind of aggregate signature, deployed by Ethereum, Dfinity, and Cloudflare amongst others, currently undergoing standardization at the IETF. However, BLS aggregate signatures are difficult to use correctly, with nuanced requirements that must be carefully handled by protocol developers. In this work, we design the first models of aggregate signatures that enable formal verification tools, such as Tamarin and ProVerif, to be applied to protocols using these signatures. We introduce general models that are based on the cryptographic security definition of generic aggregate signatures, allowing the attacker to exploit protocols where the security requirements are not satisfied. We also introduce a second family of models formalizing BLS aggregate signatures in particular. We demonstrate our approach's practical relevance by modelling and analyzing in Tamarin a device attestation protocol called SANA. Despite SANA's claimed correctness proof, with Tamarin we uncover undocumented assumptions that, when omitted, lead to attacks.</li>
</ul>

<h3>Title: AutoPentest: Enhancing Vulnerability Management With Autonomous LLM Agents</h3>
<ul>
<li><strong>Authors: </strong>Julius Henke</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.10321">https://arxiv.org/abs/2505.10321</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.10321">https://arxiv.org/pdf/2505.10321</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.10321]] AutoPentest: Enhancing Vulnerability Management With Autonomous LLM Agents(https://arxiv.org/abs/2505.10321)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>A recent area of increasing research is the use of Large Language Models (LLMs) in penetration testing, which promises to reduce costs and thus allow for higher frequency. We conduct a review of related work, identifying best practices and common evaluation issues. We then present AutoPentest, an application for performing black-box penetration tests with a high degree of autonomy. AutoPentest is based on the LLM GPT-4o from OpenAI and the LLM agent framework LangChain. It can perform complex multi-step tasks, augmented by external tools and knowledge bases. We conduct a study on three capture-the-flag style Hack The Box (HTB) machines, comparing our implementation AutoPentest with the baseline approach of manually using the ChatGPT-4o user interface. Both approaches are able to complete 15-25 % of the subtasks on the HTB machines, with AutoPentest slightly outperforming ChatGPT. We measure a total cost of \$96.20 US when using AutoPentest across all experiments, while a one-month subscription to ChatGPT Plus costs \$20. The results show that further implementation efforts and the use of more powerful LLMs released in the future are likely to make this a viable part of vulnerability management.</li>
</ul>

<h3>Title: Asynchronous Decentralized SGD under Non-Convexity: A Block-Coordinate Descent Framework</h3>
<ul>
<li><strong>Authors: </strong>Yijie Zhou, Shi Pu</a></li>
<li><strong>Subjects: </strong>cs.LG, math.OC</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.10322">https://arxiv.org/abs/2505.10322</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.10322">https://arxiv.org/pdf/2505.10322</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.10322]] Asynchronous Decentralized SGD under Non-Convexity: A Block-Coordinate Descent Framework(https://arxiv.org/abs/2505.10322)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy</a></li>
<li><strong>Abstract: </strong>Decentralized optimization has become vital for leveraging distributed data without central control, enhancing scalability and privacy. However, practical deployments face fundamental challenges due to heterogeneous computation speeds and unpredictable communication delays. This paper introduces a refined model of Asynchronous Decentralized Stochastic Gradient Descent (ADSGD) under practical assumptions of bounded computation and communication times. To understand the convergence of ADSGD, we first analyze Asynchronous Stochastic Block Coordinate Descent (ASBCD) as a tool, and then show that ADSGD converges under computation-delay-independent step sizes. The convergence result is established without assuming bounded data heterogeneity. Empirical experiments reveal that ADSGD outperforms existing methods in wall-clock convergence time across various scenarios. With its simplicity, efficiency in memory and communication, and resilience to communication and computation delays, ADSGD is well-suited for real-world decentralized learning tasks.</li>
</ul>

<h3>Title: Locally Differentially Private Frequency Estimation via Joint Randomized Response</h3>
<ul>
<li><strong>Authors: </strong>Ye Zheng, Shafizur Rahman Seeam, Yidan Hu, Rui Zhang, Yanchao Zhang</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.10349">https://arxiv.org/abs/2505.10349</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.10349">https://arxiv.org/pdf/2505.10349</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.10349]] Locally Differentially Private Frequency Estimation via Joint Randomized Response(https://arxiv.org/abs/2505.10349)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, protect</a></li>
<li><strong>Abstract: </strong>Local Differential Privacy (LDP) has been widely recognized as a powerful tool for providing a strong theoretical guarantee of data privacy to data contributors against an untrusted data collector. Under a typical LDP scheme, each data contributor independently randomly perturbs their data before submitting them to the data collector, which in turn infers valuable statistics about the original data from received perturbed data. Common to existing LDP mechanisms is an inherent trade-off between the level of privacy protection and data utility in the sense that strong data privacy often comes at the cost of reduced data utility. Frequency estimation based on Randomized Response (RR) is a fundamental building block of many LDP mechanisms. In this paper, we propose a novel Joint Randomized Response (JRR) mechanism based on correlated data perturbations to achieve locally differentially private frequency estimation. JRR divides data contributors into disjoint groups of two members and lets those in the same group jointly perturb their binary data to improve frequency-estimation accuracy and achieve the same level of data privacy by hiding the group membership information in contrast to the classical RR mechanism. Theoretical analysis and detailed simulation studies using both real and synthetic datasets show that JRR achieves the same level of data privacy as the classical RR mechanism while improving the frequency-estimation accuracy in the overwhelming majority of the cases by up to two orders of magnitude.</li>
</ul>

<h3>Title: A Unified and Scalable Membership Inference Method for Visual Self-supervised Encoder via Part-aware Capability</h3>
<ul>
<li><strong>Authors: </strong>Jie Zhu, Jirong Zha, Ding Li, Leye Wang</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.10351">https://arxiv.org/abs/2505.10351</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.10351">https://arxiv.org/pdf/2505.10351</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.10351]] A Unified and Scalable Membership Inference Method for Visual Self-supervised Encoder via Part-aware Capability(https://arxiv.org/abs/2505.10351)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, defense, attack, membership infer</a></li>
<li><strong>Abstract: </strong>Self-supervised learning shows promise in harnessing extensive unlabeled data, but it also confronts significant privacy concerns, especially in vision. In this paper, we perform membership inference on visual self-supervised models in a more realistic setting: self-supervised training method and details are unknown for an adversary when attacking as he usually faces a black-box system in practice. In this setting, considering that self-supervised model could be trained by completely different self-supervised paradigms, e.g., masked image modeling and contrastive learning, with complex training details, we propose a unified membership inference method called PartCrop. It is motivated by the shared part-aware capability among models and stronger part response on the training data. Specifically, PartCrop crops parts of objects in an image to query responses within the image in representation space. We conduct extensive attacks on self-supervised models with different training protocols and structures using three widely used image datasets. The results verify the effectiveness and generalization of PartCrop. Moreover, to defend against PartCrop, we evaluate two common approaches, i.e., early stop and differential privacy, and propose a tailored method called shrinking crop scale range. The defense experiments indicate that all of them are effective. Finally, besides prototype testing on toy visual encoders and small-scale image datasets, we quantitatively study the impacts of scaling from both data and model aspects in a realistic scenario and propose a scalable PartCrop-v2 by introducing two structural improvements to PartCrop. Our code is at this https URL.</li>
</ul>

<h3>Title: SpikeVideoFormer: An Efficient Spike-Driven Video Transformer with Hamming Attention and $\mathcal{O}(T)$ Complexity</h3>
<ul>
<li><strong>Authors: </strong>Shihao Zou, Qingfeng Li, Wei Ji, Jingjing Li, Yongkui Yang, Guoqi Li, Chao Dong</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.10352">https://arxiv.org/abs/2505.10352</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.10352">https://arxiv.org/pdf/2505.10352</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.10352]] SpikeVideoFormer: An Efficient Spike-Driven Video Transformer with Hamming Attention and $\mathcal{O}(T)$ Complexity(https://arxiv.org/abs/2505.10352)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer, segmentation</a></li>
<li><strong>Abstract: </strong>Spiking Neural Networks (SNNs) have shown competitive performance to Artificial Neural Networks (ANNs) in various vision tasks, while offering superior energy efficiency. However, existing SNN-based Transformers primarily focus on single-image tasks, emphasizing spatial features while not effectively leveraging SNNs' efficiency in video-based vision tasks. In this paper, we introduce SpikeVideoFormer, an efficient spike-driven video Transformer, featuring linear temporal complexity $\mathcal{O}(T)$. Specifically, we design a spike-driven Hamming attention (SDHA) which provides a theoretically guided adaptation from traditional real-valued attention to spike-driven attention. Building on SDHA, we further analyze various spike-driven space-time attention designs and identify an optimal scheme that delivers appealing performance for video tasks, while maintaining only linear temporal complexity. The generalization ability and efficiency of our model are demonstrated across diverse downstream video tasks, including classification, human pose tracking, and semantic segmentation. Empirical results show our method achieves state-of-the-art (SOTA) performance compared to existing SNN approaches, with over 15\% improvement on the latter two tasks. Additionally, it matches the performance of recent ANN-based methods while offering significant efficiency gains, achieving $\times 16$, $\times 10$ and $\times 5$ improvements on the three tasks. this https URL</li>
</ul>

<h3>Title: LDIR: Low-Dimensional Dense and Interpretable Text Embeddings with Relative Representations</h3>
<ul>
<li><strong>Authors: </strong>Yile Wang, Zhanyu Shen, Hui Huang</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.10354">https://arxiv.org/abs/2505.10354</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.10354">https://arxiv.org/pdf/2505.10354</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.10354]] LDIR: Low-Dimensional Dense and Interpretable Text Embeddings with Relative Representations(https://arxiv.org/abs/2505.10354)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability, large language model</a></li>
<li><strong>Abstract: </strong>Semantic text representation is a fundamental task in the field of natural language processing. Existing text embedding (e.g., SimCSE and LLM2Vec) have demonstrated excellent performance, but the values of each dimension are difficult to trace and interpret. Bag-of-words, as classic sparse interpretable embeddings, suffers from poor performance. Recently, Benara et al. (2024) propose interpretable text embeddings using large language models, which forms "0/1" embeddings based on responses to a series of questions. These interpretable text embeddings are typically high-dimensional (larger than 10,000). In this work, we propose Low-dimensional (lower than 500) Dense and Interpretable text embeddings with Relative representations (LDIR). The numerical values of its dimensions indicate semantic relatedness to different anchor texts through farthest point sampling, offering both semantic representation as well as a certain level of traceability and interpretability. We validate LDIR on multiple semantic textual similarity, retrieval, and clustering tasks. Extensive experimental results show that LDIR performs close to the black-box baseline models and outperforms the interpretable embeddings baselines with much fewer dimensions. Code is available at this https URL.</li>
</ul>

<h3>Title: FactsR: A Safer Method for Producing High Quality Healthcare Documentation</h3>
<ul>
<li><strong>Authors: </strong>Victor Petrén Bach Hansen, Lasse Krogsbøll, Jonas Lyngsø, Mathias Baltzersen, Andreas Motzfeldt, Kevin Pelgrims, Lars Maaløe</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, stat.AP</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.10360">https://arxiv.org/abs/2505.10360</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.10360">https://arxiv.org/pdf/2505.10360</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.10360]] FactsR: A Safer Method for Producing High Quality Healthcare Documentation(https://arxiv.org/abs/2505.10360)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>There are now a multitude of AI-scribing solutions for healthcare promising the utilization of large language models for ambient documentation. However, these AI scribes still rely on one-shot, or few-shot prompts for generating notes after the consultation has ended, employing little to no reasoning. This risks long notes with an increase in hallucinations, misrepresentation of the intent of the clinician, and reliance on the proofreading of the clinician to catch errors. A dangerous combination for patient safety if vigilance is compromised by workload and fatigue. In this paper, we introduce a method for extracting salient clinical information in real-time alongside the healthcare consultation, denoted Facts, and use that information recursively to generate the final note. The FactsR method results in more accurate and concise notes by placing the clinician-in-the-loop of note generation, while opening up new use cases within real-time decision support.</li>
</ul>

<h3>Title: Multi-domain Multilingual Sentiment Analysis in Industry: Predicting Aspect-based Opinion Quadruples</h3>
<ul>
<li><strong>Authors: </strong>Benjamin White, Anastasia Shimorina</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.10389">https://arxiv.org/abs/2505.10389</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.10389">https://arxiv.org/pdf/2505.10389</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.10389]] Multi-domain Multilingual Sentiment Analysis in Industry: Predicting Aspect-based Opinion Quadruples(https://arxiv.org/abs/2505.10389)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction, large language model</a></li>
<li><strong>Abstract: </strong>This paper explores the design of an aspect-based sentiment analysis system using large language models (LLMs) for real-world use. We focus on quadruple opinion extraction -- identifying aspect categories, sentiment polarity, targets, and opinion expressions from text data across different domains and languages. Using internal datasets, we investigate whether a single fine-tuned model can effectively handle multiple domain-specific taxonomies simultaneously. We demonstrate that a combined multi-domain model achieves performance comparable to specialized single-domain models while reducing operational complexity. We also share lessons learned for handling non-extractive predictions and evaluating various failure modes when developing LLM-based systems for structured prediction tasks.</li>
</ul>

<h3>Title: Two-Stage Generative Model for Intracranial Aneurysm Meshes with Morphological Marker Conditioning</h3>
<ul>
<li><strong>Authors: </strong>Wenhao Ding, Choon Hwai Yap, Kangjun Ji, Simão Castro</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.10407">https://arxiv.org/abs/2505.10407</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.10407">https://arxiv.org/pdf/2505.10407</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.10407]] Two-Stage Generative Model for Intracranial Aneurysm Meshes with Morphological Marker Conditioning(https://arxiv.org/abs/2505.10407)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>A generative model for the mesh geometry of intracranial aneurysms (IA) is crucial for training networks to predict blood flow forces in real time, which is a key factor affecting disease progression. This need is necessitated by the absence of a large IA image datasets. Existing shape generation methods struggle to capture realistic IA features and ignore the relationship between IA pouches and parent vessels, limiting physiological realism and their generation cannot be controlled to have specific morphological measurements. We propose AneuG, a two-stage Variational Autoencoder (VAE)-based IA mesh generator. In the first stage, AneuG generates low-dimensional Graph Harmonic Deformation (GHD) tokens to encode and reconstruct aneurysm pouch shapes, constrained to morphing energy statistics truths. GHD enables more accurate shape encoding than alternatives. In the second stage, AneuG generates parent vessels conditioned on GHD tokens, by generating vascular centreline and propagating the cross-section. AneuG's IA shape generation can further be conditioned to have specific clinically relevant morphological measurements. This is useful for studies to understand shape variations represented by clinical measurements, and for flow simulation studies to understand effects of specific clinical shape parameters on fluid dynamics. Source code and implementation details are available at this https URL.</li>
</ul>

<h3>Title: Are LLM-generated plain language summaries truly understandable? A large-scale crowdsourced evaluation</h3>
<ul>
<li><strong>Authors: </strong>Yue Guo, Jae Ho Sohn, Gondy Leroy, Trevor Cohen</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.10409">https://arxiv.org/abs/2505.10409</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.10409">https://arxiv.org/pdf/2505.10409</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.10409]] Are LLM-generated plain language summaries truly understandable? A large-scale crowdsourced evaluation(https://arxiv.org/abs/2505.10409)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Plain language summaries (PLSs) are essential for facilitating effective communication between clinicians and patients by making complex medical information easier for laypeople to understand and act upon. Large language models (LLMs) have recently shown promise in automating PLS generation, but their effectiveness in supporting health information comprehension remains unclear. Prior evaluations have generally relied on automated scores that do not measure understandability directly, or subjective Likert-scale ratings from convenience samples with limited generalizability. To address these gaps, we conducted a large-scale crowdsourced evaluation of LLM-generated PLSs using Amazon Mechanical Turk with 150 participants. We assessed PLS quality through subjective Likert-scale ratings focusing on simplicity, informativeness, coherence, and faithfulness; and objective multiple-choice comprehension and recall measures of reader understanding. Additionally, we examined the alignment between 10 automated evaluation metrics and human judgments. Our findings indicate that while LLMs can generate PLSs that appear indistinguishable from human-written ones in subjective evaluations, human-written PLSs lead to significantly better comprehension. Furthermore, automated evaluation metrics fail to reflect human judgment, calling into question their suitability for evaluating PLSs. This is the first study to systematically evaluate LLM-generated PLSs based on both reader preferences and comprehension outcomes. Our findings highlight the need for evaluation frameworks that move beyond surface-level quality and for generation methods that explicitly optimize for layperson comprehension.</li>
</ul>

<h3>Title: Learning to Think: Information-Theoretic Reinforcement Fine-Tuning for LLMs</h3>
<ul>
<li><strong>Authors: </strong>Jingyao Wang, Wenwen Qiang, Zeen Song, Changwen Zheng, Hui Xiong</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.10425">https://arxiv.org/abs/2505.10425</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.10425">https://arxiv.org/pdf/2505.10425</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.10425]] Learning to Think: Information-Theoretic Reinforcement Fine-Tuning for LLMs(https://arxiv.org/abs/2505.10425)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large language models (LLMs) excel at complex tasks thanks to advances in reasoning abilities. However, existing methods overlook the trade-off between reasoning effectiveness and computational efficiency, often encouraging unnecessarily long reasoning chains and wasting tokens. To address this, we propose Learning to Think (L2T), an information-theoretic reinforcement fine-tuning framework for LLMs to make the models achieve optimal reasoning with fewer tokens. Specifically, L2T treats each query-response interaction as a hierarchical session of multiple episodes and proposes a universal dense process reward, i.e., quantifies the episode-wise information gain in parameters, requiring no extra annotations or task-specific evaluators. We propose a method to quickly estimate this reward based on PAC-Bayes bounds and the Fisher information matrix. Theoretical analyses show that it significantly reduces computational complexity with high estimation accuracy. By immediately rewarding each episode's contribution and penalizing excessive updates, L2T optimizes the model via reinforcement learning to maximize the use of each episode and achieve effective updates. Empirical results on various reasoning benchmarks and base models demonstrate the advantage of L2T across different tasks, boosting both reasoning effectiveness and efficiency.</li>
</ul>

<h3>Title: The Ephemeral Threat: Assessing the Security of Algorithmic Trading Systems powered by Deep Learning</h3>
<ul>
<li><strong>Authors: </strong>Advije Rizvani, Giovanni Apruzzese, Pavel Laskov</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.10430">https://arxiv.org/abs/2505.10430</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.10430">https://arxiv.org/pdf/2505.10430</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.10430]] The Ephemeral Threat: Assessing the Security of Algorithmic Trading Systems powered by Deep Learning(https://arxiv.org/abs/2505.10430)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, attack</a></li>
<li><strong>Abstract: </strong>We study the security of stock price forecasting using Deep Learning (DL) in computational finance. Despite abundant prior research on the vulnerability of DL to adversarial perturbations, such work has hitherto hardly addressed practical adversarial threat models in the context of DL-powered algorithmic trading systems (ATS). Specifically, we investigate the vulnerability of ATS to adversarial perturbations launched by a realistically constrained attacker. We first show that existing literature has paid limited attention to DL security in the financial domain, which is naturally attractive for adversaries. Then, we formalize the concept of ephemeral perturbations (EP), which can be used to stage a novel type of attack tailored for DL-based ATS. Finally, we carry out an end-to-end evaluation of our EP against a profitable ATS. Our results reveal that the introduction of small changes to the input stock prices not only (i) induces the DL model to behave incorrectly but also (ii) leads the whole ATS to make suboptimal buy/sell decisions, resulting in a worse financial performance of the targeted ATS.</li>
</ul>

<h3>Title: Score-based diffusion nowcasting of GOES imagery</h3>
<ul>
<li><strong>Authors: </strong>Randy J. Chase, Katherine Haynes, Lander Ver Hoef, Imme Ebert-Uphoff</a></li>
<li><strong>Subjects: </strong>cs.LG, physics.ao-ph</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.10432">https://arxiv.org/abs/2505.10432</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.10432">https://arxiv.org/pdf/2505.10432</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.10432]] Score-based diffusion nowcasting of GOES imagery(https://arxiv.org/abs/2505.10432)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>Clouds and precipitation are important for understanding weather and climate. Simulating clouds and precipitation with traditional numerical weather prediction is challenging because of the sub-grid parameterizations required. Machine learning has been explored for forecasting clouds and precipitation, but early machine learning methods often created blurry forecasts. In this paper we explore a newer method, named score-based diffusion, to nowcast (zero to three hour forecast) clouds and precipitation. We discuss the background and intuition of score-based diffusion models - thus providing a starting point for the community - while exploring the methodology's use for nowcasting geostationary infrared imagery. We experiment with three main types of diffusion models: a standard score-based diffusion model (Diff); a residual correction diffusion model (CorrDiff); and a latent diffusion model (LDM). Our results show that the diffusion models are able to not only advect existing clouds, but also generate and decay clouds, including convective initiation. These results are surprising because the forecasts are initiated with only the past 20 mins of infrared satellite imagery. A case study qualitatively shows the preservation of high resolution features longer into the forecast than a conventional mean-squared error trained U-Net. The best of the three diffusion models tested was the CorrDiff approach, outperforming all other diffusion models, the traditional U-Net, and a persistence forecast by one to two kelvin on root mean squared error. The diffusion models also enable out-of-the-box ensemble generation, which shows skillful calibration, with the spread of the ensemble correlating well to the error.</li>
</ul>

<h3>Title: Reinforcing the Diffusion Chain of Lateral Thought with Diffusion Language Models</h3>
<ul>
<li><strong>Authors: </strong>Zemin Huang, Zhiyang Chen, Zijun Wang, Tiancheng Li, Guo-Jun Qi</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.10446">https://arxiv.org/abs/2505.10446</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.10446">https://arxiv.org/pdf/2505.10446</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.10446]] Reinforcing the Diffusion Chain of Lateral Thought with Diffusion Language Models(https://arxiv.org/abs/2505.10446)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>We introduce the \emph{Diffusion Chain of Lateral Thought (DCoLT)}, a reasoning framework for diffusion language models. DCoLT treats each intermediate step in the reverse diffusion process as a latent "thinking" action and optimizes the entire reasoning trajectory to maximize the reward on the correctness of the final answer with outcome-based Reinforcement Learning (RL). Unlike traditional Chain-of-Thought (CoT) methods that follow a causal, linear thinking process, DCoLT allows bidirectional, non-linear reasoning with no strict rule on grammatical correctness amid its intermediate steps of thought. We implement DCoLT on two representative Diffusion Language Models (DLMs). First, we choose SEDD as a representative continuous-time discrete diffusion model, where its concrete score derives a probabilistic policy to maximize the RL reward over the entire sequence of intermediate diffusion steps. We further consider the discrete-time masked diffusion language model -- LLaDA, and find that the order to predict and unmask tokens plays an essential role to optimize its RL action resulting from the ranking-based Unmasking Policy Module (UPM) defined by the Plackett-Luce model. Experiments on both math and code generation tasks show that using only public data and 16 H800 GPUs, DCoLT-reinforced DLMs outperform other DLMs trained by SFT or RL or even both. Notably, DCoLT-reinforced LLaDA boosts its reasoning accuracy by +9.8%, +5.7%, +11.4%, +19.5% on GSM8K, MATH, MBPP, and HumanEval.</li>
</ul>

<h3>Title: Superposition Yields Robust Neural Scaling</h3>
<ul>
<li><strong>Authors: </strong>Yizhou liu, Ziming Liu, Jeff Gore</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.10465">https://arxiv.org/abs/2505.10465</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.10465">https://arxiv.org/pdf/2505.10465</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.10465]] Superposition Yields Robust Neural Scaling(https://arxiv.org/abs/2505.10465)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, large language model</a></li>
<li><strong>Abstract: </strong>The success of today's large language models (LLMs) depends on the observation that larger models perform better. However, the origin of this neural scaling law -- the finding that loss decreases as a power law with model size -- remains unclear. Starting from two empirical principles -- that LLMs represent more things than the model dimensions (widths) they have (i.e., representations are superposed), and that words or concepts in language occur with varying frequencies -- we constructed a toy model to study the loss scaling with model size. We found that when superposition is weak, meaning only the most frequent features are represented without interference, the scaling of loss with model size depends on the underlying feature frequency; if feature frequencies follow a power law, so does the loss. In contrast, under strong superposition, where all features are represented but overlap with each other, the loss becomes inversely proportional to the model dimension across a wide range of feature frequency distributions. This robust scaling behavior is explained geometrically: when many more vectors are packed into a lower dimensional space, the interference (squared overlaps) between vectors scales inversely with that dimension. We then analyzed four families of open-sourced LLMs and found that they exhibit strong superposition and quantitatively match the predictions of our toy model. The Chinchilla scaling law turned out to also agree with our results. We conclude that representation superposition is an important mechanism underlying the observed neural scaling laws. We anticipate that these insights will inspire new training strategies and model architectures to achieve better performance with less computation and fewer parameters.</li>
</ul>

<h3>Title: Large Language Models for Cancer Communication: Evaluating Linguistic Quality, Safety, and Accessibility in Generative AI</h3>
<ul>
<li><strong>Authors: </strong>Agnik Saha, Victoria Churchill, Anny D. Rodriguez, Ugur Kursuncu, Muhammed Y. Idris</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.10472">https://arxiv.org/abs/2505.10472</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.10472">https://arxiv.org/pdf/2505.10472</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.10472]] Large Language Models for Cancer Communication: Evaluating Linguistic Quality, Safety, and Accessibility in Generative AI(https://arxiv.org/abs/2505.10472)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative, large language model</a></li>
<li><strong>Abstract: </strong>Effective communication about breast and cervical cancers remains a persistent health challenge, with significant gaps in public understanding of cancer prevention, screening, and treatment, potentially leading to delayed diagnoses and inadequate treatments. This study evaluates the capabilities and limitations of Large Language Models (LLMs) in generating accurate, safe, and accessible cancer-related information to support patient understanding. We evaluated five general-purpose and three medical LLMs using a mixed-methods evaluation framework across linguistic quality, safety and trustworthiness, and communication accessibility and affectiveness. Our approach utilized quantitative metrics, qualitative expert ratings, and statistical analysis using Welch's ANOVA, Games-Howell, and Hedges' g. Our results show that general-purpose LLMs produced outputs of higher linguistic quality and affectiveness, while medical LLMs demonstrate greater communication accessibility. However, medical LLMs tend to exhibit higher levels of potential harm, toxicity, and bias, reducing their performance in safety and trustworthiness. Our findings indicate a duality between domain-specific knowledge and safety in health communications. The results highlight the need for intentional model design with targeted improvements, particularly in mitigating harm and bias, and improving safety and affectiveness. This study provides a comprehensive evaluation of LLMs for cancer communication, offering critical insights for improving AI-generated health content and informing future development of accurate, safe, and accessible digital health tools.</li>
</ul>

<h3>Title: Fine-tuning Diffusion Policies with Backpropagation Through Diffusion Timesteps</h3>
<ul>
<li><strong>Authors: </strong>Ningyuan Yang, Jiaxuan Gao, Feng Gao, Yi Wu, Chao Yu</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.10482">https://arxiv.org/abs/2505.10482</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.10482">https://arxiv.org/pdf/2505.10482</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.10482]] Fine-tuning Diffusion Policies with Backpropagation Through Diffusion Timesteps(https://arxiv.org/abs/2505.10482)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, diffusion</a></li>
<li><strong>Abstract: </strong>Diffusion policies, widely adopted in decision-making scenarios such as robotics, gaming and autonomous driving, are capable of learning diverse skills from demonstration data due to their high representation power. However, the sub-optimal and limited coverage of demonstration data could lead to diffusion policies that generate sub-optimal trajectories and even catastrophic failures. While reinforcement learning (RL)-based fine-tuning has emerged as a promising solution to address these limitations, existing approaches struggle to effectively adapt Proximal Policy Optimization (PPO) to diffusion models. This challenge stems from the computational intractability of action likelihood estimation during the denoising process, which leads to complicated optimization objectives. In our experiments starting from randomly initialized policies, we find that online tuning of Diffusion Policies demonstrates much lower sample efficiency compared to directly applying PPO on MLP policies (MLP+PPO). To address these challenges, we introduce NCDPO, a novel framework that reformulates Diffusion Policy as a noise-conditioned deterministic policy. By treating each denoising step as a differentiable transformation conditioned on pre-sampled noise, NCDPO enables tractable likelihood evaluation and gradient backpropagation through all diffusion timesteps. Our experiments demonstrate that NCDPO achieves sample efficiency comparable to MLP+PPO when training from scratch, outperforming existing methods in both sample efficiency and final performance across diverse benchmarks, including continuous robot control and multi-agent game scenarios. Furthermore, our experimental results show that our method is robust to the number denoising timesteps in the Diffusion Policy.</li>
</ul>

<h3>Title: CL-RAG: Bridging the Gap in Retrieval-Augmented Generation with Curriculum Learning</h3>
<ul>
<li><strong>Authors: </strong>Shaohan Wang, Licheng Zhang, Zheren Fu, Zhendong Mao</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.10493">https://arxiv.org/abs/2505.10493</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.10493">https://arxiv.org/pdf/2505.10493</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.10493]] CL-RAG: Bridging the Gap in Retrieval-Augmented Generation with Curriculum Learning(https://arxiv.org/abs/2505.10493)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Retrieval-Augmented Generation (RAG) is an effective method to enhance the capabilities of large language models (LLMs). Existing methods focus on optimizing the retriever or generator in the RAG system by directly utilizing the top-k retrieved documents. However, the documents effectiveness are various significantly across user queries, i.e. some documents provide valuable knowledge while others totally lack critical information. It hinders the retriever and generator's adaptation during training. Inspired by human cognitive learning, curriculum learning trains models using samples progressing from easy to difficult, thus enhancing their generalization ability, and we integrate this effective paradigm to the training of the RAG system. In this paper, we propose a multi-stage Curriculum Learning based RAG system training framework, named CL-RAG. We first construct training data with multiple difficulty levels for the retriever and generator separately through sample evolution. Then, we train the model in stages based on the curriculum learning approach, thereby optimizing the overall performance and generalization of the RAG system more effectively. Our CL-RAG framework demonstrates consistent effectiveness across four open-domain QA datasets, achieving performance gains of 2% to 4% over multiple advanced methods.</li>
</ul>

<h3>Title: Can You Really Trust Code Copilots? Evaluating Large Language Models from a Code Security Perspective</h3>
<ul>
<li><strong>Authors: </strong>Yutao Mou, Xiao Deng, Yuxiao Luo, Shikun Zhang, Wei Ye</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.10494">https://arxiv.org/abs/2505.10494</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.10494">https://arxiv.org/pdf/2505.10494</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.10494]] Can You Really Trust Code Copilots? Evaluating Large Language Models from a Code Security Perspective(https://arxiv.org/abs/2505.10494)</code><input type="text"></li>
<li><strong>Keywords: </strong>secure, security, large language model</a></li>
<li><strong>Abstract: </strong>Code security and usability are both essential for various coding assistant applications driven by large language models (LLMs). Current code security benchmarks focus solely on single evaluation task and paradigm, such as code completion and generation, lacking comprehensive assessment across dimensions like secure code generation, vulnerability repair and discrimination. In this paper, we first propose CoV-Eval, a multi-task benchmark covering various tasks such as code completion, vulnerability repair, vulnerability detection and classification, for comprehensive evaluation of LLM code security. Besides, we developed VC-Judge, an improved judgment model that aligns closely with human experts and can review LLM-generated programs for vulnerabilities in a more efficient and reliable way. We conduct a comprehensive evaluation of 20 proprietary and open-source LLMs. Overall, while most LLMs identify vulnerable codes well, they still tend to generate insecure codes and struggle with recognizing specific vulnerability types and performing repairs. Extensive experiments and qualitative analyses reveal key challenges and optimization directions, offering insights for future research in LLM code security.</li>
</ul>

<h3>Title: RouteNator: A Router-Based Multi-Modal Architecture for Generating Synthetic Training Data for Function Calling LLMs</h3>
<ul>
<li><strong>Authors: </strong>Vibha Belavadi, Tushar Vatsa, Dewang Sultania, Suhas Suresha, Ishita Verma, Cheng Chen, Tracy Holloway King, Michael Friedrich</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.10495">https://arxiv.org/abs/2505.10495</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.10495">https://arxiv.org/pdf/2505.10495</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.10495]] RouteNator: A Router-Based Multi-Modal Architecture for Generating Synthetic Training Data for Function Calling LLMs(https://arxiv.org/abs/2505.10495)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, large language model</a></li>
<li><strong>Abstract: </strong>This paper addresses fine-tuning Large Language Models (LLMs) for function calling tasks when real user interaction data is unavailable. In digital content creation tools, where users express their needs through natural language queries that must be mapped to API calls, the lack of real-world task-specific data and privacy constraints for training on it necessitate synthetic data generation. Existing approaches to synthetic data generation fall short in diversity and complexity, failing to replicate real-world data distributions and leading to suboptimal performance after LLM fine-tuning. We present a novel router-based architecture that leverages domain resources like content metadata and structured knowledge graphs, along with text-to-text and vision-to-text language models to generate high-quality synthetic training data. Our architecture's flexible routing mechanism enables synthetic data generation that matches observed real-world distributions, addressing a fundamental limitation of traditional approaches. Evaluation on a comprehensive set of real user queries demonstrates significant improvements in both function classification accuracy and API parameter selection. Models fine-tuned with our synthetic data consistently outperform traditional approaches, establishing new benchmarks for function calling tasks.</li>
</ul>

<h3>Title: CheXGenBench: A Unified Benchmark For Fidelity, Privacy and Utility of Synthetic Chest Radiographs</h3>
<ul>
<li><strong>Authors: </strong>Raman Dutt, Pedro Sanchez, Yongchen Yao, Steven McDonagh, Sotirios A. Tsaftaris, Timothy Hospedales</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.10496">https://arxiv.org/abs/2505.10496</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.10496">https://arxiv.org/pdf/2505.10496</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.10496]] CheXGenBench: A Unified Benchmark For Fidelity, Privacy and Utility of Synthetic Chest Radiographs(https://arxiv.org/abs/2505.10496)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, generative</a></li>
<li><strong>Abstract: </strong>We introduce CheXGenBench, a rigorous and multifaceted evaluation framework for synthetic chest radiograph generation that simultaneously assesses fidelity, privacy risks, and clinical utility across state-of-the-art text-to-image generative models. Despite rapid advancements in generative AI for real-world imagery, medical domain evaluations have been hindered by methodological inconsistencies, outdated architectural comparisons, and disconnected assessment criteria that rarely address the practical clinical value of synthetic samples. CheXGenBench overcomes these limitations through standardised data partitioning and a unified evaluation protocol comprising over 20 quantitative metrics that systematically analyse generation quality, potential privacy vulnerabilities, and downstream clinical applicability across 11 leading text-to-image architectures. Our results reveal critical inefficiencies in the existing evaluation protocols, particularly in assessing generative fidelity, leading to inconsistent and uninformative comparisons. Our framework establishes a standardised benchmark for the medical AI community, enabling objective and reproducible comparisons while facilitating seamless integration of both existing and future generative models. Additionally, we release a high-quality, synthetic dataset, SynthCheX-75K, comprising 75K radiographs generated by the top-performing model (Sana 0.6B) in our benchmark to support further research in this critical domain. Through CheXGenBench, we establish a new state-of-the-art and release our framework, models, and SynthCheX-75K dataset at this https URL</li>
</ul>

<h3>Title: MorphGuard: Morph Specific Margin Loss for Enhancing Robustness to Face Morphing Attacks</h3>
<ul>
<li><strong>Authors: </strong>Iurii Medvedev, Nuno Goncalves</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.10497">https://arxiv.org/abs/2505.10497</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.10497">https://arxiv.org/pdf/2505.10497</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.10497]] MorphGuard: Morph Specific Margin Loss for Enhancing Robustness to Face Morphing Attacks(https://arxiv.org/abs/2505.10497)</code><input type="text"></li>
<li><strong>Keywords: </strong>secure, security, attack, robust</a></li>
<li><strong>Abstract: </strong>Face recognition has evolved significantly with the advancement of deep learning techniques, enabling its widespread adoption in various applications requiring secure authentication. However, this progress has also increased its exposure to presentation attacks, including face morphing, which poses a serious security threat by allowing one identity to impersonate another. Therefore, modern face recognition systems must be robust against such attacks. In this work, we propose a novel approach for training deep networks for face recognition with enhanced robustness to face morphing attacks. Our method modifies the classification task by introducing a dual-branch classification strategy that effectively handles the ambiguity in the labeling of face morphs. This adaptation allows the model to incorporate morph images into the training process, improving its ability to distinguish them from bona fide samples. Our strategy has been validated on public benchmarks, demonstrating its effectiveness in enhancing robustness against face morphing attacks. Furthermore, our approach is universally applicable and can be integrated into existing face recognition training pipelines to improve classification-based recognition methods.</li>
</ul>

<h3>Title: The Devil Is in the Word Alignment Details: On Translation-Based Cross-Lingual Transfer for Token Classification Tasks</h3>
<ul>
<li><strong>Authors: </strong>Benedikt Ebing, Goran Glavaš</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.10507">https://arxiv.org/abs/2505.10507</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.10507">https://arxiv.org/pdf/2505.10507</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.10507]] The Devil Is in the Word Alignment Details: On Translation-Based Cross-Lingual Transfer for Token Classification Tasks(https://arxiv.org/abs/2505.10507)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Translation-based strategies for cross-lingual transfer XLT such as translate-train -- training on noisy target language data translated from the source language -- and translate-test -- evaluating on noisy source language data translated from the target language -- are competitive XLT baselines. In XLT for token classification tasks, however, these strategies include label projection, the challenging step of mapping the labels from each token in the original sentence to its counterpart(s) in the translation. Although word aligners (WAs) are commonly used for label projection, the low-level design decisions for applying them to translation-based XLT have not been systematically investigated. Moreover, recent marker-based methods, which project labeled spans by inserting tags around them before (or after) translation, claim to outperform WAs in label projection for XLT. In this work, we revisit WAs for label projection, systematically investigating the effects of low-level design decisions on token-level XLT: (i) the algorithm for projecting labels between (multi-)token spans, (ii) filtering strategies to reduce the number of noisily mapped labels, and (iii) the pre-tokenization of the translated sentences. We find that all of these substantially impact translation-based XLT performance and show that, with optimized choices, XLT with WA offers performance at least comparable to that of marker-based methods. We then introduce a new projection strategy that ensembles translate-train and translate-test predictions and demonstrate that it substantially outperforms the marker-based projection. Crucially, we show that our proposed ensembling also reduces sensitivity to low-level WA design choices, resulting in more robust XLT for token classification tasks.</li>
</ul>

<h3>Title: Multi-Token Prediction Needs Registers</h3>
<ul>
<li><strong>Authors: </strong>Anastasios Gerontopoulos, Spyros Gidaris, Nikos Komodakis</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.CV, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.10518">https://arxiv.org/abs/2505.10518</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.10518">https://arxiv.org/pdf/2505.10518</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.10518]] Multi-Token Prediction Needs Registers(https://arxiv.org/abs/2505.10518)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>Multi-token prediction has emerged as a promising objective for improving language model pretraining, but its benefits have not consistently generalized to other settings such as fine-tuning. In this paper, we propose MuToR, a simple and effective approach to multi-token prediction that interleaves learnable register tokens into the input sequence, each tasked with predicting future targets. Compared to existing methods, MuToR offers several key advantages: it introduces only a negligible number of additional parameters, requires no architectural changes--ensuring compatibility with off-the-shelf pretrained language models--and remains aligned with the next-token pretraining objective, making it especially well-suited for supervised fine-tuning. Moreover, it naturally supports scalable prediction horizons. We demonstrate the effectiveness and versatility of MuToR across a range of use cases, including supervised fine-tuning, parameter-efficient fine-tuning (PEFT), and pretraining, on challenging generative tasks in both language and vision domains. Our code will be available at: this https URL.</li>
</ul>

<h3>Title: S3C2 Summit 2024-09: Industry Secure Software Supply Chain Summit</h3>
<ul>
<li><strong>Authors: </strong>Imranur Rahman, Yasemin Acar, Michel Cukier, William Enck, Christian Kastner, Alexandros Kapravelos, Dominik Wermke, Laurie Williams</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.10538">https://arxiv.org/abs/2505.10538</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.10538">https://arxiv.org/pdf/2505.10538</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.10538]] S3C2 Summit 2024-09: Industry Secure Software Supply Chain Summit(https://arxiv.org/abs/2505.10538)</code><input type="text"></li>
<li><strong>Keywords: </strong>secure, security, attack, large language model</a></li>
<li><strong>Abstract: </strong>While providing economic and software development value, software supply chains are only as strong as their weakest link. Over the past several years, there has been an exponential increase in cyberattacks, specifically targeting vulnerable links in critical software supply chains. These attacks disrupt the day-to-day functioning and threaten the security of nearly everyone on the internet, from billion-dollar companies and government agencies to hobbyist open-source developers. The ever-evolving threat of software supply chain attacks has garnered interest from the software industry and the US government in improving software supply chain security. On September 20, 2024, three researchers from the NSF-backed Secure Software Supply Chain Center (S3C2) conducted a Secure Software Supply Chain Summit with a diverse set of 12 practitioners from 9 companies. The goals of the Summit were to: (1) to enable sharing between individuals from different companies regarding practical experiences and challenges with software supply chain security, (2) to help form new collaborations, (3) to share our observations from our previous summits with industry, and (4) to learn about practitioners' challenges to inform our future research direction. The summit consisted of discussions of six topics relevant to the companies represented, including updating vulnerable dependencies, component and container choice, malicious commits, building infrastructure, large language models, and reducing entire classes of vulnerabilities.</li>
</ul>

<h3>Title: Exploring Implicit Visual Misunderstandings in Multimodal Large Language Models through Attention Analysis</h3>
<ul>
<li><strong>Authors: </strong>Pengfei Wang, Guohai Xu, Weinong Wang, Junjie Yang, Jie Lou, Yunhua Xue</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.10541">https://arxiv.org/abs/2505.10541</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.10541">https://arxiv.org/pdf/2505.10541</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.10541]] Exploring Implicit Visual Misunderstandings in Multimodal Large Language Models through Attention Analysis(https://arxiv.org/abs/2505.10541)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, large language model</a></li>
<li><strong>Abstract: </strong>Recent advancements have enhanced the capability of Multimodal Large Language Models (MLLMs) to comprehend multi-image information. However, existing benchmarks primarily evaluate answer correctness, overlooking whether models genuinely comprehend the visual input. To address this, we define implicit visual misunderstanding (IVM), where MLLMs provide correct answers without fully comprehending the visual input. Through our analysis, we decouple the visual and textual modalities within the causal attention module, revealing that attention distribution increasingly converges on the image associated with the correct answer as the network layers deepen. This insight leads to the introduction of a scale-agnostic metric, \textit{attention accuracy}, and a novel benchmark for quantifying IVMs. Attention accuracy directly evaluates the model's visual understanding via internal mechanisms, remaining robust to positional biases for more reliable assessments. Furthermore, we extend our approach to finer granularities and demonstrate its effectiveness in unimodal scenarios, underscoring its versatility and generalizability.</li>
</ul>

<h3>Title: Pharmacophore-Conditioned Diffusion Model for Ligand-Based De Novo Drug Design</h3>
<ul>
<li><strong>Authors: </strong>Amira Alakhdar, Barnabas Poczos, Newell Washburn</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.10545">https://arxiv.org/abs/2505.10545</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.10545">https://arxiv.org/pdf/2505.10545</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.10545]] Pharmacophore-Conditioned Diffusion Model for Ligand-Based De Novo Drug Design(https://arxiv.org/abs/2505.10545)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, transformer, generative</a></li>
<li><strong>Abstract: </strong>Developing bioactive molecules remains a central, time- and cost-heavy challenge in drug discovery, particularly for novel targets lacking structural or functional data. Pharmacophore modeling presents an alternative for capturing the key features required for molecular bioactivity against a biological target. In this work, we present PharmaDiff, a pharmacophore-conditioned diffusion model for 3D molecular generation. PharmaDiff employs a transformer-based architecture to integrate an atom-based representation of the 3D pharmacophore into the generative process, enabling the precise generation of 3D molecular graphs that align with predefined pharmacophore hypotheses. Through comprehensive testing, PharmaDiff demonstrates superior performance in matching 3D pharmacophore constraints compared to ligand-based drug design methods. Additionally, it achieves higher docking scores across a range of proteins in structure-based drug design, without the need for target protein structures. By integrating pharmacophore modeling with 3D generative techniques, PharmaDiff offers a powerful and flexible framework for rational drug design.</li>
</ul>

<h3>Title: Does Feasibility Matter? Understanding the Impact of Feasibility on Synthetic Training Data</h3>
<ul>
<li><strong>Authors: </strong>Yiwen Liu, Jessica Bader, Jae Myung Kim</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.10551">https://arxiv.org/abs/2505.10551</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.10551">https://arxiv.org/pdf/2505.10551</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.10551]] Does Feasibility Matter? Understanding the Impact of Feasibility on Synthetic Training Data(https://arxiv.org/abs/2505.10551)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, large language model</a></li>
<li><strong>Abstract: </strong>With the development of photorealistic diffusion models, models trained in part or fully on synthetic data achieve progressively better results. However, diffusion models still routinely generate images that would not exist in reality, such as a dog floating above the ground or with unrealistic texture artifacts. We define the concept of feasibility as whether attributes in a synthetic image could realistically exist in the real-world domain; synthetic images containing attributes that violate this criterion are considered infeasible. Intuitively, infeasible images are typically considered out-of-distribution; thus, training on such images is expected to hinder a model's ability to generalize to real-world data, and they should therefore be excluded from the training set whenever possible. However, does feasibility really matter? In this paper, we investigate whether enforcing feasibility is necessary when generating synthetic training data for CLIP-based classifiers, focusing on three target attributes: background, color, and texture. We introduce VariReal, a pipeline that minimally edits a given source image to include feasible or infeasible attributes given by the textual prompt generated by a large language model. Our experiments show that feasibility minimally affects LoRA-fine-tuned CLIP performance, with mostly less than 0.3% difference in top-1 accuracy across three fine-grained datasets. Also, the attribute matters on whether the feasible/infeasible images adversarially influence the classification performance. Finally, mixing feasible and infeasible images in training datasets does not significantly impact performance compared to using purely feasible or infeasible datasets.</li>
</ul>

<h3>Title: An AI-driven framework for the prediction of personalised health response to air pollution</h3>
<ul>
<li><strong>Authors: </strong>Nazanin Zounemat Kermani, Sadjad Naderi, Claire H. Dilliway, Claire E. Heaney, Shrreya Behll, Boyang Chen, Hisham Abubakar-Waziri, Alexandra E. Porter, Marc Chadeau-Hyam, Fangxin Fang, Ian M. Adcock, Kian Fan Chung, Christopher C. Pain</a></li>
<li><strong>Subjects: </strong>cs.LG, physics.ao-ph</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.10556">https://arxiv.org/abs/2505.10556</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.10556">https://arxiv.org/pdf/2505.10556</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.10556]] An AI-driven framework for the prediction of personalised health response to air pollution(https://arxiv.org/abs/2505.10556)</code><input type="text"></li>
<li><strong>Keywords: </strong>secure</a></li>
<li><strong>Abstract: </strong>Air pollution poses a significant threat to public health, causing or exacerbating many respiratory and cardiovascular diseases. In addition, climate change is bringing about more extreme weather events such as wildfires and heatwaves, which can increase levels of pollution and worsen the effects of pollution exposure. Recent advances in personal sensing have transformed the collection of behavioural and physiological data, leading to the potential for new improvements in healthcare. We wish to capitalise on this data, alongside new capabilities in AI for making time series predictions, in order to monitor and predict health outcomes for an individual. Thus, we present a novel workflow for predicting personalised health responses to pollution by integrating physiological data from wearable fitness devices with real-time environmental exposures. The data is collected from various sources in a secure and ethical manner, and is used to train an AI model to predict individual health responses to pollution exposure within a cloud-based, modular framework. We demonstrate that the AI model -- an Adversarial Autoencoder neural network in this case -- accurately reconstructs time-dependent health signals and captures nonlinear responses to pollution. Transfer learning is applied using data from a personal smartwatch, which increases the generalisation abilities of the AI model and illustrates the adaptability of the approach to real-world, user-generated data.</li>
</ul>

<h3>Title: Neural Thermodynamic Laws for Large Language Model Training</h3>
<ul>
<li><strong>Authors: </strong>Ziming Liu, Yizhou Liu, Jeff Gore, Max Tegmark</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, physics.data-an, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.10559">https://arxiv.org/abs/2505.10559</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.10559">https://arxiv.org/pdf/2505.10559</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.10559]] Neural Thermodynamic Laws for Large Language Model Training(https://arxiv.org/abs/2505.10559)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Beyond neural scaling laws, little is known about the laws underlying large language models (LLMs). We introduce Neural Thermodynamic Laws (NTL) -- a new framework that offers fresh insights into LLM training dynamics. On the theoretical side, we demonstrate that key thermodynamic quantities (e.g., temperature, entropy, heat capacity, thermal conduction) and classical thermodynamic principles (e.g., the three laws of thermodynamics and the equipartition theorem) naturally emerge under river-valley loss landscape assumptions. On the practical side, this scientific perspective yields intuitive guidelines for designing learning rate schedules.</li>
</ul>

<h3>Title: End-to-End Vision Tokenizer Tuning</h3>
<ul>
<li><strong>Authors: </strong>Wenxuan Wang, Fan Zhang, Yufeng Cui, Haiwen Diao, Zhuoyan Luo, Huchuan Lu, Jing Liu, Xinlong Wang</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.10562">https://arxiv.org/abs/2505.10562</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.10562">https://arxiv.org/pdf/2505.10562</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.10562]] End-to-End Vision Tokenizer Tuning(https://arxiv.org/abs/2505.10562)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Existing vision tokenization isolates the optimization of vision tokenizers from downstream training, implicitly assuming the visual tokens can generalize well across various tasks, e.g., image generation and visual question answering. The vision tokenizer optimized for low-level reconstruction is agnostic to downstream tasks requiring varied representations and semantics. This decoupled paradigm introduces a critical misalignment: The loss of the vision tokenization can be the representation bottleneck for target tasks. For example, errors in tokenizing text in a given image lead to poor results when recognizing or generating them. To address this, we propose ETT, an end-to-end vision tokenizer tuning approach that enables joint optimization between vision tokenization and target autoregressive tasks. Unlike prior autoregressive models that use only discrete indices from a frozen vision tokenizer, ETT leverages the visual embeddings of the tokenizer codebook, and optimizes the vision tokenizers end-to-end with both reconstruction and caption objectives. ETT can be seamlessly integrated into existing training pipelines with minimal architecture modifications. Our ETT is simple to implement and integrate, without the need to adjust the original codebooks or architectures of the employed large language models. Extensive experiments demonstrate that our proposed end-to-end vision tokenizer tuning unlocks significant performance gains, i.e., 2-6% for multimodal understanding and visual generation tasks compared to frozen tokenizer baselines, while preserving the original reconstruction capability. We hope this very simple and strong method can empower multimodal foundation models besides image generation and understanding.</li>
</ul>

<h3>Title: 3D-Fixup: Advancing Photo Editing with 3D Priors</h3>
<ul>
<li><strong>Authors: </strong>Yen-Chi Cheng, Krishna Kumar Singh, Jae Shin Yoon, Alex Schwing, Liangyan Gui, Matheus Gadelha, Paul Guerrero, Nanxuan Zhao</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2505.10566">https://arxiv.org/abs/2505.10566</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2505.10566">https://arxiv.org/pdf/2505.10566</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2505.10566]] 3D-Fixup: Advancing Photo Editing with 3D Priors(https://arxiv.org/abs/2505.10566)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, generative</a></li>
<li><strong>Abstract: </strong>Despite significant advances in modeling image priors via diffusion models, 3D-aware image editing remains challenging, in part because the object is only specified via a single image. To tackle this challenge, we propose 3D-Fixup, a new framework for editing 2D images guided by learned 3D priors. The framework supports difficult editing situations such as object translation and 3D rotation. To achieve this, we leverage a training-based approach that harnesses the generative power of diffusion models. As video data naturally encodes real-world physical dynamics, we turn to video data for generating training data pairs, i.e., a source and a target frame. Rather than relying solely on a single trained model to infer transformations between source and target frames, we incorporate 3D guidance from an Image-to-3D model, which bridges this challenging task by explicitly projecting 2D information into 3D space. We design a data generation pipeline to ensure high-quality 3D guidance throughout training. Results show that by integrating these 3D priors, 3D-Fixup effectively supports complex, identity coherent 3D-aware edits, achieving high-quality results and advancing the application of diffusion models in realistic image manipulation. The code is provided at this https URL</li>
</ul>

<button id="copy">Copy All</button>
</article>
<script src="../../javascript/clipboard.min.js"></script>
<script src="../../javascript/clipboard.js"></script>
